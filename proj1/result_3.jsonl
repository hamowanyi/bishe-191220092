{"code":"def write_format_data(self, format_dict):\r\n        \"\"\" function to<extra_id_0>\r\n        result_repr = format_dict['text\/plain']\r\n        if '\\n' in result_repr:\r\n            prompt_template = self.shell.prompt_manager.out_template\r\n            if prompt_template and not prompt_template.endswith('\\n'):\r\n                result_repr = '\\n' + result_repr\r\n        print >>io.stdout, result_repr","reference":"Write the format data dict to the frontend.\n\n        This default version of this method simply writes the plain text\n        representation of the object to ``io.stdout``. Subclasses should\n        override this method to send the entire `format_dict` to the\n        frontends.\n\n        Parameters\n        ----------\n        format_dict : dict\n            The format dict for the object passed to `sys.displayhook`.","result":"Write format data to stdout .","score":[0.0002,0.0422]}
{"code":"def log_output(self, format_dict):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.shell.logger.log_output:\r\n            self.shell.logger.log_write(format_dict['text\/plain'], 'output')\r\n        self.shell.history_manager.output_hist_reprs[self.prompt_count] = \\\r\n                                                    format_dict['text\/plain']","reference":"Log the output.","result":"Log output .","score":[0.4082,0.1667]}
{"code":"def raise_if_freezed(self):\r\n        \"\"\" function to<extra_id_0>\r\n        '''raise `InvalidOperationException` if is freezed.'''\r\n        if self.is_freezed:\r\n            name = type(self).__name__\r\n            raise InvalidOperationException('obj {name} is freezed.'.format(name=name))","reference":"raise `InvalidOperationException` if is freezed.","result":" is freezed .","score":[0.2096,0.1042]}
{"code":"def mysql_timestamp_converter(s):\r\n    \"\"\" function to<extra_id_0>\r\n    if s[4] == '-': return DateTime_or_None(s)\r\n    s = s + \"0\"*(14-len(s))\r\n    parts = map(int, filter(None, (s[:4],s[4:6],s[6:8],\r\n                                   s[8:10],s[10:12],s[12:14])))\r\n    try:\r\n        return Timestamp(*parts)\r\n    except (SystemExit, KeyboardInterrupt):\r\n        raise\r\n    except:\r\n        return None","reference":"Convert a MySQL TIMESTAMP to a Timestamp object.","result":"Def convert mysql timestamp to Timestamp.","score":[0.1383,0.2564]}
{"code":"def _eventloop_changed(self, name, old, new):\r\n        \"\"\" function to<extra_id_0>\r\n        loop = ioloop.IOLoop.instance()\r\n        loop.add_timeout(time.time()+0.1, self.enter_eventloop)","reference":"schedule call to eventloop from IOLoop","result":"Handle eventloop changes .","score":[0.1938,0.0862]}
{"code":"def dispatch_control(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        idents,msg = self.session.feed_identities(msg, copy=False)\r\n        try:\r\n            msg = self.session.unserialize(msg, content=True, copy=False)\r\n        except:\r\n            self.log.error(\"Invalid Control Message\", exc_info=True)\r\n            return\r\n        self.log.debug(\"Control received: %s\", msg)\r\n        header = msg['header']\r\n        msg_id = header['msg_id']\r\n        msg_type = header['msg_type']\r\n        handler = self.control_handlers.get(msg_type, None)\r\n        if handler is None:\r\n            self.log.error(\"UNKNOWN CONTROL MESSAGE TYPE: %r\", msg_type)\r\n        else:\r\n            try:\r\n                handler(self.control_stream, idents, msg)\r\n            except Exception:\r\n                self.log.error(\"Exception in control handler:\", exc_info=True)","reference":"dispatch control requests","result":"Handle incoming control messages .","score":[0.2403,0.1562]}
{"code":"def dispatch_shell(self, stream, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.control_stream:\r\n            self.control_stream.flush()\r\n                idents,msg = self.session.feed_identities(msg, copy=False)\r\n        try:\r\n            msg = self.session.unserialize(msg, content=True, copy=False)\r\n        except:\r\n            self.log.error(\"Invalid Message\", exc_info=True)\r\n            return\r\n        header = msg['header']\r\n        msg_id = header['msg_id']\r\n        msg_type = msg['header']['msg_type']\r\n                self.log.debug('\\n*** MESSAGE TYPE:%s***', msg_type)\r\n        self.log.debug('   Content: %s\\n   --->\\n   ', msg['content'])\r\n        if msg_id in self.aborted:\r\n            self.aborted.remove(msg_id)\r\n            reply_type = msg_type.split('_')[0] + '_reply'\r\n            status = {'status' : 'aborted'}\r\n            sub = {'engine' : self.ident}\r\n            sub.update(status)\r\n            reply_msg = self.session.send(stream, reply_type, subheader=sub,\r\n                        content=status, parent=msg, ident=idents)\r\n            return\r\n                handler = self.shell_handlers.get(msg_type, None)\r\n        if handler is None:\r\n            self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\r\n        else:\r\n            sig = signal(SIGINT, default_int_handler)\r\n            try:\r\n                handler(stream, idents, msg)\r\n            except Exception:\r\n                self.log.error(\"Exception in message handler:\", exc_info=True)\r\n            finally:\r\n                signal(SIGINT, sig)","reference":"dispatch shell requests","result":"Handle the shell message .","score":[0.2403,0.1562]}
{"code":"def start(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self.shell.exit_now = False\r\n        if self.control_stream:\r\n            self.control_stream.on_recv(self.dispatch_control, copy=False)\r\n        def make_dispatcher(stream):\r\n            def dispatcher(msg):\r\n                return self.dispatch_shell(stream, msg)\r\n            return dispatcher\r\n        for s in self.shell_streams:\r\n            s.on_recv(make_dispatcher(s), copy=False)","reference":"register dispatchers for streams","result":"Start the shell .","score":[0,0.0]}
{"code":"def do_one_iteration(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.control_stream:\r\n            self.control_stream.flush()\r\n        for stream in self.shell_streams:\r\n            stream.flush(zmq.POLLIN, 1)\r\n            stream.flush(zmq.POLLOUT)","reference":"step eventloop just once","result":"Do one iteration .","score":[0,0.0]}
{"code":"def _publish_pyin(self, code, parent, execution_count):\r\n        \"\"\" function to<extra_id_0>\r\n        self.session.send(self.iopub_socket, u'pyin',\r\n                            {u'code':code, u'execution_count': execution_count},\r\n                            parent=parent, ident=self._topic('pyin')\r\n        )","reference":"Publish the code request on the pyin stream.","result":"Publish pyin .","score":[0.0917,0.1333]}
{"code":"def abort_request(self, stream, ident, parent):\r\n        \"\"\" function to<extra_id_0>\r\n        msg_ids = parent['content'].get('msg_ids', None)\r\n        if isinstance(msg_ids, basestring):\r\n            msg_ids = [msg_ids]\r\n        if not msg_ids:\r\n            self.abort_queues()\r\n        for mid in msg_ids:\r\n            self.aborted.add(str(mid))\r\n        content = dict(status='ok')\r\n        reply_msg = self.session.send(stream, 'abort_reply', content=content,\r\n                parent=parent, ident=ident)\r\n        self.log.debug(\"%s\", reply_msg)","reference":"abort a specifig msg by id","result":"Abort a request .","score":[0.1938,0.3233]}
{"code":"def clear_request(self, stream, idents, parent):\r\n        \"\"\" function to<extra_id_0>\r\n        self.shell.reset(False)\r\n        msg = self.session.send(stream, 'clear_reply', ident=idents, parent=parent,\r\n                content = dict(status='ok'))","reference":"Clear our namespace.","result":"Clear the session .","score":[0.3195,0.1613]}
{"code":"def _topic(self, topic):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.int_id >= 0:\r\n            base = \"engine.%i\" % self.int_id\r\n        else:\r\n            base = \"kernel.%s\" % self.ident\r\n                return py3compat.cast_bytes(\"%s.%s\" % (base, topic))","reference":"prefixed topic for IOPub messages","result":"Return a topic .","score":[0.2488,0.102]}
{"code":"def _at_shutdown(self):\r\n   \"\"\" function to<extra_id_0>\r\n   if self._shutdown_message is not None:\r\n            self.session.send(self.iopub_socket, self._shutdown_message, ident=self._topic('shutdown'))\r\n            self.log.debug(\"%s\", self._shutdown_message)\r\n        [ s.flush(zmq.POLLOUT) for s in self.shell_streams ]","reference":"Actions taken at shutdown by the kernel, called by python's atexit.","result":" is shutting down .","score":[0,0.0]}
{"code":"def beforeContext(self):\r\n        \"\"\" function to<extra_id_0>\r\n        mods = sys.modules.copy()\r\n        self._mod_stack.append(mods)","reference":"Copy sys.modules onto my mod stack","result":"Be called before context .","score":[0,0.0]}
{"code":"def afterContext(self):\r\n        \"\"\" function to<extra_id_0>\r\n        mods = self._mod_stack.pop()\r\n        to_del = [ m for m in sys.modules.keys() if m not in mods ]\r\n        if to_del:\r\n            log.debug('removing sys modules entries: %s', to_del)\r\n            for mod in to_del:\r\n                del sys.modules[mod]\r\n        sys.modules.update(mods)","reference":"Pop my mod stack and restore sys.modules to the state\n        it was in when mod stack was pushed.","result":"Call after context .","score":[0,0.0]}
{"code":"def absdir(path):\r\n    \"\"\" function to<extra_id_0>\r\n    if not os.path.isabs(path):\r\n        path = os.path.normpath(os.path.abspath(os.path.join(os.getcwd(),\r\n                                                             path)))\r\n    if path is None or not os.path.isdir(path):\r\n        return None\r\n    return path","reference":"Return absolute, normalized path to directory, if it exists; None\n    otherwise.","result":"Return absolute path of a directory .","score":[0.1085,0.0943]}
{"code":"def file_like(name):\r\n    \"\"\" function to<extra_id_0>\r\n    return (os.path.exists(name)\r\n            or os.path.dirname(name)\r\n            or name.endswith('.py')\r\n            or not ident_re.match(os.path.splitext(name)[0]))","reference":"A name is file-like if it is a path that exists, or it has a\n    directory part, or it ends in .py, or it isn't a legal python\n    identifier.","result":" is file.","score":[0.0,0.019]}
{"code":"def isclass(obj):\r\n    \"\"\" function to<extra_id_0>\r\n    obj_type = type(obj)\r\n    return obj_type in class_types or issubclass(obj_type, type)","reference":"Is obj a class? Inspect's isclass is too liberal and returns True\n    for objects that can't be subclasses of anything.","result":" is a class .","score":[0.007,0.0543]}
{"code":"def ispackage(path):\r\n    \"\"\" function to<extra_id_0>\r\n    if os.path.isdir(path):\r\n        end = os.path.basename(path)\r\n        if ident_re.match(end):\r\n            for init in ('__init__.py', '__init__.pyc', '__init__.pyo'):\r\n                if os.path.isfile(os.path.join(path, init)):\r\n                    return True\r\n            if sys.platform.startswith('java') and \\\r\n                    os.path.isfile(os.path.join(path, '__init__$py.class')):\r\n                return True\r\n    return False","reference":"Is this path a package directory?\n\n    >>> ispackage('nose')\n    True\n    >>> ispackage('unit_tests')\n    False\n    >>> ispackage('nose\/plugins')\n    True\n    >>> ispackage('nose\/loader.py')\n    False","result":" is a package .","score":[0.0136,0.1539]}
{"code":"def getpackage(filename):\r\n    \"\"\" function to<extra_id_0>\r\n    src_file = src(filename)\r\n    if not src_file.endswith('.py') and not ispackage(src_file):\r\n        return None\r\n    base, ext = os.path.splitext(os.path.basename(src_file))\r\n    if base == '__init__':\r\n        mod_parts = []\r\n    else:\r\n        mod_parts = [base]\r\n    path, part = os.path.split(os.path.split(src_file)[0])\r\n    while part:\r\n        if ispackage(os.path.join(path, part)):\r\n            mod_parts.append(part)\r\n        else:\r\n            break\r\n        path, part = os.path.split(path)\r\n    mod_parts.reverse()\r\n    return '.'.join(mod_parts)","reference":"Find the full dotted package name for a given python source file\n    name. Returns None if the file is not a python source file.\n\n    >>> getpackage('foo.py')\n    'foo'\n    >>> getpackage('biff\/baf.py')\n    'baf'\n    >>> getpackage('nose\/util.py')\n    'nose.util'\n\n    Works for directories too.\n\n    >>> getpackage('nose')\n    'nose'\n    >>> getpackage('nose\/plugins')\n    'nose.plugins'\n\n    And __init__ files stuck onto directories\n\n    >>> getpackage('nose\/plugins\/__init__.py')\n    'nose.plugins'\n\n    Absolute paths also work.\n\n    >>> path = os.path.abspath(os.path.join('nose', 'plugins'))\n    >>> getpackage(path)\n    'nose.plugins'","result":"Get package name from filename .","score":[0.0,0.0439]}
{"code":"def ln(label):\r\n    \"\"\" function to<extra_id_0>\r\n    label_len = len(label) + 2\r\n    chunk = (70 - label_len) \/\/ 2\r\n    out = '%s %s %s' % ('-' * chunk, label, '-' * chunk)\r\n    pad = 70 - len(out)\r\n    if pad > 0:\r\n        out = out + ('-' * pad)\r\n    return out","reference":"Draw a 70-char-wide divider, with label in the middle.\n\n    >>> ln('hello there')\n    '---------------------------- hello there -----------------------------'","result":"Create a label line .","score":[0.0317,0.1007]}
{"code":"def regex_last_key(regex):\r\n    \"\"\" function to<extra_id_0>\r\n    def k(obj):\r\n        if regex.search(obj):\r\n            return (1, obj)\r\n        return (0, obj)\r\n    return k","reference":"Sort key function factory that puts items that match a\n    regular expression last.\n\n    >>> from nose.config import Config\n    >>> from nose.pyversion import sort_list\n    >>> c = Config()\n    >>> regex = c.testMatch\n    >>> entries = ['.', '..', 'a_test', 'src', 'lib', 'test', 'foo.py']\n    >>> sort_list(entries, regex_last_key(regex))\n    >>> entries\n    ['.', '..', 'foo.py', 'lib', 'src', 'a_test', 'test']","result":"Return the last key .","score":[0.0,0.0104]}
{"code":"def transplant_func(func, module):\r\n    \"\"\" function to<extra_id_0>\r\n    from nose.tools import make_decorator\r\n    def newfunc(*arg, **kw):\r\n        return func(*arg, **kw)\r\n    newfunc = make_decorator(func)(newfunc)\r\n    newfunc.__module__ = module\r\n    return newfunc","reference":"Make a function imported from module A appear as if it is located\n    in module B.\n\n    >>> from pprint import pprint\n    >>> pprint.__module__\n    'pprint'\n    >>> pp = transplant_func(pprint, __name__)\n    >>> pp.__module__\n    'nose.util'\n\n    The original function is not modified.\n\n    >>> pprint.__module__\n    'pprint'\n\n    Calling the transplanted function calls the original.\n\n    >>> pp([1, 2])\n    [1, 2]\n    >>> pprint([1,2])\n    [1, 2]","result":"Def transplant .","score":[0,0.0097]}
{"code":"def transplant_class(cls, module):\r\n    \"\"\" function to<extra_id_0>\r\n    class C(cls):\r\n        pass\r\n    C.__module__ = module\r\n    C.__name__ = cls.__name__\r\n    return C","reference":"Make a class appear to reside in `module`, rather than the module in which\n    it is actually defined.\n\n    >>> from nose.failure import Failure\n    >>> Failure.__module__\n    'nose.failure'\n    >>> Nf = transplant_class(Failure, __name__)\n    >>> Nf.__module__\n    'nose.util'\n    >>> Nf.__name__\n    'Failure'","result":"Transplant a class .","score":[0.0001,0.0556]}
{"code":"def get_system_cpu_times():\r\n    \"\"\" function to<extra_id_0>\r\n    user, nice, system, idle = _psutil_osx.get_system_cpu_times()\r\n    return _cputimes_ntuple(user, nice, system, idle)","reference":"Return system CPU times as a namedtuple.","result":"Get system cpu times .","score":[0.1915,0.433]}
{"code":"def get_process_cmdline(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if not pid_exists(self.pid):\r\n            raise NoSuchProcess(self.pid, self._process_name)\r\n        return _psutil_osx.get_process_cmdline(self.pid)","reference":"Return process cmdline as a list of arguments.","result":"Def get process cmdline .","score":[0.1865,0.2435]}
{"code":"def get_open_files(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.pid == 0:\r\n            return []\r\n        files = []\r\n        rawlist = _psutil_osx.get_process_open_files(self.pid)\r\n        for path, fd in rawlist:\r\n            if isfile_strict(path):\r\n                ntuple = nt_openfile(path, fd)\r\n                files.append(ntuple)\r\n        return files","reference":"Return files opened by process.","result":"Get open files from process .","score":[0.193,0.1961]}
{"code":"def get_connections(self, kind='inet'):\r\n        \"\"\" function to<extra_id_0>\r\n        if kind not in conn_tmap:\r\n            raise ValueError(\"invalid %r kind argument; choose between %s\"\r\n                             % (kind, ', '.join([repr(x) for x in conn_tmap])))\r\n        families, types = conn_tmap[kind]\r\n        ret = _psutil_osx.get_process_connections(self.pid, families, types)\r\n        return [nt_connection(*conn) for conn in ret]","reference":"Return etwork connections opened by a process as a list of\n        namedtuples.","result":"Get all connections for the process .","score":[0.094,0.087]}
{"code":"def user_has_group(user, group, superuser_skip=True):\r\n    \"\"\" function to<extra_id_0>\r\n    if user.is_superuser and superuser_skip:\r\n        return True\r\n    return user.groups.filter(name=group).exists()","reference":"Check if a user is in a certaing group.\n    By default, the check is skipped for superusers.","result":"Group check if user has group .","score":[0.0509,0.0938]}
{"code":"def resolve_class(class_path):\r\n    \"\"\" function to<extra_id_0>\r\n    modulepath, classname = class_path.rsplit('.', 1)\r\n    module = __import__(modulepath, fromlist=[classname])\r\n    return getattr(module, classname)","reference":"Load a class by a fully qualified class_path,\n    eg. myapp.models.ModelName","result":"Resolve class .","score":[0.0396,0.0538]}
{"code":"def usage_percent(used, total, _round=None):\r\n    \"\"\" function to<extra_id_0>\r\n    try:\r\n        ret = (used \/ total) * 100\r\n    except ZeroDivisionError:\r\n        ret = 0\r\n    if _round is not None:\r\n        return round(ret, _round)\r\n    else:\r\n        return ret","reference":"Calculate percentage usage of 'used' against 'total'.","result":"Calculate usage percent .","score":[0.1795,0.1493]}
{"code":"def memoize(f):\r\n    \"\"\" function to<extra_id_0>\r\n    cache= {}\r\n    def memf(*x):\r\n        if x not in cache:\r\n            cache[x] = f(*x)\r\n        return cache[x]\r\n    return memf","reference":"A simple memoize decorator for functions.","result":"Memoize a function .","score":[0,0.1724]}
{"code":"def deprecated(replacement=None):\r\n    \"\"\" function to<extra_id_0>\r\n    def outer(fun):\r\n        msg = \"psutil.%s is deprecated\" % fun.__name__\r\n        if replacement is not None:\r\n            msg += \"; use %s instead\" % replacement\r\n        if fun.__doc__ is None:\r\n            fun.__doc__ = msg\r\n        @wraps(fun)\r\n        def inner(*args, **kwargs):\r\n            warnings.warn(msg, category=DeprecationWarning, stacklevel=2)\r\n            return fun(*args, **kwargs)\r\n        return inner\r\n    return outer","reference":"A decorator which can be used to mark functions as deprecated.","result":"Mark psutil functions as deprecated.","score":[0.1491,0.3606]}
{"code":"def _login(self):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            self.gd_client = gdata.docs.client.DocsClient()\r\n            self.gd_client.ClientLogin(self.email, self.password, self.source)\r\n        except RequestError as e:\r\n            raise PODocsError(e)","reference":"Login into Google Docs with user authentication info.","result":"Def login to gdata.","score":[0,0.0658]}
{"code":"def _get_gdocs_key(self):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            args = urlparse.parse_qs(urlparse.urlparse(self.url).query)\r\n            self.key = args['key'][0]\r\n        except KeyError as e:\r\n            raise PODocsError(e)","reference":"Parse GDocs key from Spreadsheet url.","result":"Get the key from the query string .","score":[0.1964,0.3024]}
{"code":"def _ensure_temp_path_exists(self):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            if not os.path.exists(self.temp_path):\r\n                os.mkdir(self.temp_path)\r\n        except OSError as e:\r\n            raise PODocsError(e)","reference":"Make sure temp directory exists and create one if it does not.","result":"Ensure temp path exists .","score":[0.0705,0.0885]}
{"code":"def _clear_temp(self):\r\n        \"\"\" function to<extra_id_0>\r\n        temp_files = [LOCAL_ODS, GDOCS_TRANS_CSV, GDOCS_META_CSV,\r\n                      LOCAL_TRANS_CSV, LOCAL_META_CSV]\r\n        for temp_file in temp_files:\r\n            file_path = os.path.join(self.temp_path, temp_file)\r\n            if os.path.exists(file_path):\r\n                os.remove(file_path)","reference":"Clear temp directory from created csv and ods files during\n        communicator operations.","result":"Clear temp files .","score":[0.0677,0.2282]}
{"code":"def _upload_file_to_gdoc(\r\n            \"\"\" function to<extra_id_0>\r\n            self, file_path,\r\n            content_type='application\/x-vnd.oasis.opendocument.spreadsheet'):\r\n        try:\r\n            entry = self.gd_client.GetResourceById(self.key)\r\n            media = gdata.data.MediaSource(\r\n                file_path=file_path, content_type=content_type)\r\n            self.gd_client.UpdateResource(\r\n                entry, media=media, update_metadata=True)\r\n        except (RequestError, IOError) as e:\r\n            raise PODocsError(e)","reference":"Uploads file to GDocs spreadsheet.\n        Content type can be provided as argument, default is ods.","result":"Upload a file to the document .","score":[0.0728,0.18]}
{"code":"def synchronize(self):\r\n        \"\"\" function to<extra_id_0>\r\n        gdocs_trans_csv = os.path.join(self.temp_path, GDOCS_TRANS_CSV)\r\n        gdocs_meta_csv = os.path.join(self.temp_path, GDOCS_META_CSV)\r\n        local_trans_csv = os.path.join(self.temp_path, LOCAL_TRANS_CSV)\r\n        local_meta_csv = os.path.join(self.temp_path, LOCAL_META_CSV)\r\n        try:\r\n            entry = self._download_csv_from_gdocs(gdocs_trans_csv,\r\n                                                  gdocs_meta_csv)\r\n        except PODocsError as e:\r\n            if 'Sheet 1 not found' in str(e) \\\r\n                    or 'Conversion failed unexpectedly' in str(e):\r\n                self.upload()\r\n            else:\r\n                raise PODocsError(e)\r\n        else:\r\n            self._merge_local_and_gdoc(entry, local_trans_csv, local_meta_csv,\r\n                                       gdocs_trans_csv, gdocs_meta_csv)\r\n            try:\r\n                csv_to_po(local_trans_csv, local_meta_csv,\r\n                          self.locale_root, self.po_files_path, self.header)\r\n            except IOError as e:\r\n                raise PODocsError(e)\r\n        self._clear_temp()","reference":"Synchronize local po files with translations on GDocs Spreadsheet.\n        Downloads two csv files, merges them and converts into po files\n        structure. If new msgids appeared in po files, this method creates\n        new ods with appended content and sends it to GDocs.","result":"Synchronize the local and gdocs .","score":[0.0007,0.0533]}
{"code":"def download(self):\r\n        \"\"\" function to<extra_id_0>\r\n        trans_csv_path = os.path.realpath(\r\n            os.path.join(self.temp_path, GDOCS_TRANS_CSV))\r\n        meta_csv_path = os.path.realpath(\r\n            os.path.join(self.temp_path, GDOCS_META_CSV))\r\n        self._download_csv_from_gdocs(trans_csv_path, meta_csv_path)\r\n        try:\r\n            csv_to_po(trans_csv_path, meta_csv_path,\r\n                      self.locale_root, self.po_files_path, header=self.header)\r\n        except IOError as e:\r\n            raise PODocsError(e)\r\n        self._clear_temp()","reference":"Download csv files from GDocs and convert them into po files structure.","result":"Download the CSV file .","score":[0.0593,0.1327]}
{"code":"def upload(self):\r\n        \"\"\" function to<extra_id_0>\r\n        local_ods_path = os.path.join(self.temp_path, LOCAL_ODS)\r\n        try:\r\n            po_to_ods(self.languages, self.locale_root,\r\n                      self.po_files_path, local_ods_path)\r\n        except (IOError, OSError) as e:\r\n            raise PODocsError(e)\r\n        self._upload_file_to_gdoc(local_ods_path)\r\n        self._clear_temp()","reference":"Upload all po files to GDocs ignoring conflicts.\n        This method looks for all msgids in po_files and sends them\n        as ods to GDocs Spreadsheet.","result":"Upload the po files to the local po files .","score":[0.0593,0.1397]}
{"code":"def clear(self):\r\n        \"\"\" function to<extra_id_0>\r\n        empty_file_path = os.path.join(self.temp_path, 'empty.csv')\r\n        try:\r\n            empty_file = open(empty_file_path, 'w')\r\n            empty_file.write(',')\r\n            empty_file.close()\r\n        except IOError as e:\r\n            raise PODocsError(e)\r\n        self._upload_file_to_gdoc(empty_file_path, content_type='text\/csv')\r\n        os.remove(empty_file_path)","reference":"Clear GDoc Spreadsheet by sending empty csv file.","result":"Clear the database .","score":[0.1175,0.0658]}
{"code":"def new_qt_console(self, evt=None):\r\n        \"\"\" function to<extra_id_0>\r\n        return connect_qtconsole(self.ipkernel.connection_file, profile=self.ipkernel.profile)","reference":"start a new qtconsole connected to our kernel","result":"Create new qt console .","score":[0.1319,0.0649]}
{"code":"def check_url_accessibility(url, timeout=10):       \r\n    \"\"\" function to<extra_id_0>\r\n    '''\r\n    Check whether the URL accessible and returns HTTP 200 OK or not\r\n    if not raises ValidationError\r\n    '''\r\n    if(url=='localhost'):\r\n        url = 'http:\/\/127.0.0.1'\r\n    try:\r\n        req = urllib2.urlopen(url, timeout=timeout)\r\n        if (req.getcode()==200):\r\n            return True\r\n    except Exception:\r\n        pass\r\n    fail(\"URL '%s' is not accessible from this machine\" % url)","reference":"Check whether the URL accessible and returns HTTP 200 OK or not\n    if not raises ValidationError","result":"Check URL accessibility .","score":[0.0189,0.1727]}
{"code":"def url_has_contents(url, contents, case_sensitive=False, timeout=10):\r\n    \"\"\" function to<extra_id_0>\r\n    ''' \r\n    Check whether the HTML page contains the content or not and return boolean\r\n    '''\r\n    try:    \r\n        req = urllib2.urlopen(url, timeout=timeout)\r\n    except Exception, _:\r\n        False\r\n    else:\r\n        rep = req.read()\r\n        if (not case_sensitive and rep.lower().find(contents.lower()) >= 0) or (case_sensitive and rep.find(contents) >= 0):\r\n            return True\r\n        else:\r\n            return False","reference":"Check whether the HTML page contains the content or not and return boolean","result":"Check whether a URL has the contents .","score":[0.1163,0.3]}
{"code":"def get_response_code(url, timeout=10):\r\n    \"\"\" function to<extra_id_0>\r\n    '''\r\n    Visit the URL and return the HTTP response code in 'int'\r\n    '''\r\n    try:    \r\n        req = urllib2.urlopen(url, timeout=timeout)\r\n    except HTTPError, e:\r\n        return e.getcode()\r\n    except Exception, _:\r\n        fail(\"Couldn't reach the URL '%s'\" % url)\r\n    else:\r\n        return req.getcode()","reference":"Visit the URL and return the HTTP response code in 'int'","result":"Get the HTTP response code .","score":[0.2626,0.378]}
{"code":"def compare_content_type(url, content_type):\r\n    \"\"\" function to<extra_id_0>\r\n    '''\r\n    Compare the content type header of url param with content_type param and returns boolean \r\n    @param url -> string e.g. http:\/\/127.0.0.1\/index\r\n    @param content_type -> string e.g. text\/html\r\n    '''\r\n    try:    \r\n        response = urllib2.urlopen(url)\r\n    except:\r\n        return False\r\n    return response.headers.type == content_type","reference":"Compare the content type header of url param with content_type param and returns boolean \n    @param url -> string e.g. http:\/\/127.0.0.1\/index\n    @param content_type -> string e.g. text\/html","result":"Compare content type header of url with content.","score":[0.0663,0.2623]}
{"code":"def compare_response_code(url, code):\r\n    \"\"\" function to<extra_id_0>\r\n    '''\r\n    Compare the response code of url param with code param and returns boolean \r\n    @param url -> string e.g. http:\/\/127.0.0.1\/index\r\n    @param content_type -> int e.g. 404, 500, 400 ..etc\r\n    '''\r\n    try:\r\n        response = urllib2.urlopen(url)\r\n        except HTTPError as e:\r\n        return e.code == code\r\n        except:\r\n        return False\r\n    return response.code == code","reference":"Compare the response code of url param with code param and returns boolean \n    @param url -> string e.g. http:\/\/127.0.0.1\/index\n    @param content_type -> int e.g. 404, 500, 400 ..etc","result":"Compare response code of url with code .","score":[0.0434,0.2441]}
{"code":"def _validate_data(self, source, data, metadata=None):\r\n        \"\"\" function to<extra_id_0>\r\n        if not isinstance(source, basestring):\r\n            raise TypeError('source must be a str, got: %r' % source)\r\n        if not isinstance(data, dict):\r\n            raise TypeError('data must be a dict, got: %r' % data)\r\n        if metadata is not None:\r\n            if not isinstance(metadata, dict):\r\n                raise TypeError('metadata must be a dict, got: %r' % data)","reference":"Validate the display data.\n\n        Parameters\n        ----------\n        source : str\n            The fully dotted name of the callable that created the data, like\n            :func:`foo.bar.my_formatter`.\n        data : dict\n            The formata data dictionary.\n        metadata : dict\n            Any metadata for the data.","result":"Validate data .","score":[0.0,0.0298]}
{"code":"def clear_output(self, stdout=True, stderr=True, other=True):\r\n        \"\"\" function to<extra_id_0>\r\n        if stdout:\r\n            print('\\033[2K\\r', file=io.stdout, end='')\r\n            io.stdout.flush()\r\n        if stderr:\r\n            print('\\033[2K\\r', file=io.stderr, end='')\r\n            io.stderr.flush()","reference":"Clear the output of the cell receiving output.","result":"If clear output .","score":[0.1175,0.1316]}
{"code":"def find_cmd(cmd):\r\n    \"\"\" function to<extra_id_0>\r\n    if cmd == 'python':\r\n        return os.path.abspath(sys.executable)\r\n    try:\r\n        path = _find_cmd(cmd).rstrip()\r\n    except OSError:\r\n        raise FindCmdError('command could not be found: %s' % cmd)\r\n    if path == '':\r\n        raise FindCmdError('command could not be found: %s' % cmd)\r\n    return os.path.abspath(path)","reference":"Find absolute path to executable cmd in a cross platform manner.\n\n    This function tries to determine the full path to a command line program\n    using `which` on Unix\/Linux\/OS X and `win32api` on Windows.  Most of the\n    time it will use the version that is first on the users `PATH`.  If\n    cmd is `python` return `sys.executable`.\n\n    Warning, don't use this to find IPython command line programs as there\n    is a risk you will find the wrong one.  Instead find those using the\n    following code and looking for the application itself::\n\n        from IPython.utils.path import get_ipython_module_path\n        from IPython.utils.process import pycmd2argv\n        argv = pycmd2argv(get_ipython_module_path('IPython.frontend.terminal.ipapp'))\n\n    Parameters\n    ----------\n    cmd : str\n        The command line program to look for.","result":"Find a command .","score":[0.0,0.0148]}
{"code":"def code_unit_factory(morfs, file_locator):\r\n    \"\"\" function to<extra_id_0>\r\n    if not isinstance(morfs, (list, tuple)):\r\n        morfs = [morfs]\r\n    globbed = []\r\n    for morf in morfs:\r\n        if isinstance(morf, string_class) and ('?' in morf or '*' in morf):\r\n            globbed.extend(glob.glob(morf))\r\n        else:\r\n            globbed.append(morf)\r\n    morfs = globbed\r\n    code_units = [CodeUnit(morf, file_locator) for morf in morfs]\r\n    return code_units","reference":"Construct a list of CodeUnits from polymorphic inputs.\n\n    `morfs` is a module or a filename, or a list of same.\n\n    `file_locator` is a FileLocator that can help resolve filenames.\n\n    Returns a list of CodeUnit objects.","result":"Create code units .","score":[0,0.0]}
{"code":"def flat_rootname(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.modname:\r\n            return self.modname.replace('.', '_')\r\n        else:\r\n            root = os.path.splitdrive(self.name)[1]\r\n            return root.replace('\\\\', '_').replace('\/', '_').replace('.', '_')","reference":"A base for a flat filename to correspond to this code unit.\n\n        Useful for writing files about the code where you want all the files in\n        the same directory, but need to differentiate same-named files from\n        different directories.\n\n        For example, the file a\/b\/c.py might return 'a_b_c'","result":"Get flat rootname .","score":[0.0,0.012]}
{"code":"def source_file(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if os.path.exists(self.filename):\r\n            return open_source(self.filename)\r\n        source = self.file_locator.get_zip_data(self.filename)\r\n        if source is not None:\r\n            return StringIO(source)\r\n        raise CoverageException(\r\n            \"No source for code '%s'.\" % self.filename\r\n            )","reference":"Return an open file for reading the source of the code unit.","result":"Get source file .","score":[0.0514,0.0893]}
{"code":"def should_be_python(self):\r\n        \"\"\" function to<extra_id_0>\r\n        _, ext = os.path.splitext(self.filename)\r\n        if ext.startswith('.py'):\r\n            return True\r\n        if not ext:\r\n            return True\r\n        return False","reference":"Does it seem like this file should contain Python?\n\n        This is used to decide if a file reported as part of the exection of\n        a program was really likely to have contained Python in the first\n        place.","result":"Determine if file should be python .","score":[0.0035,0.0588]}
{"code":"def _total_seconds(td):\r\n    \"\"\" function to<extra_id_0>\r\n    try:\r\n        return td.total_seconds()\r\n    except AttributeError:\r\n        return 1e-6 * (td.microseconds + (td.seconds + td.days * 24 * 3600) * 10**6)","reference":"timedelta.total_seconds was added in 2.7","result":"Calculate total.","score":[0,0.0]}
{"code":"def get(self, timeout=-1):\r\n        \"\"\" function to<extra_id_0>\r\n        if not self.ready():\r\n            self.wait(timeout)\r\n        if self._ready:\r\n            if self._success:\r\n                return self._result\r\n            else:\r\n                raise self._exception\r\n        else:\r\n            raise error.TimeoutError(\"Result not ready.\")","reference":"Return the result when it arrives.\n\n        If `timeout` is not ``None`` and the result does not arrive within\n        `timeout` seconds then ``TimeoutError`` is raised. If the\n        remote call raised an exception then that exception will be reraised\n        by get() inside a `RemoteError`.","result":"Get a result from the result queue .","score":[0.0033,0.0518]}
{"code":"def wait(self, timeout=-1):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._ready:\r\n            return\r\n        self._ready = self._client.wait(self.msg_ids, timeout)\r\n        if self._ready:\r\n            try:\r\n                results = map(self._client.results.get, self.msg_ids)\r\n                self._result = results\r\n                if self._single_result:\r\n                    r = results[0]\r\n                    if isinstance(r, Exception):\r\n                        raise r\r\n                else:\r\n                    results = error.collect_exceptions(results, self._fname)\r\n                self._result = self._reconstruct_result(results)\r\n            except Exception, e:\r\n                self._exception = e\r\n                self._success = False\r\n            else:\r\n                self._success = True\r\n            finally:\r\n                self._metadata = map(self._client.metadata.get, self.msg_ids)\r\n                self._wait_for_outputs(10)","reference":"Wait until the result is available or until `timeout` seconds pass.\n\n        This method always returns None.","result":"Wait for messages to be sent .","score":[0.0446,0.0331]}
{"code":"def get_dict(self, timeout=-1):\r\n        \"\"\" function to<extra_id_0>\r\n        results = self.get(timeout)\r\n        engine_ids = [ md['engine_id'] for md in self._metadata ]\r\n        bycount = sorted(engine_ids, key=lambda k: engine_ids.count(k))\r\n        maxcount = bycount.count(bycount[-1])\r\n        if maxcount > 1:\r\n            raise ValueError(\"Cannot build dict, %i jobs ran on engine\r\n                    maxcount, bycount[-1]))\r\n        return dict(zip(engine_ids,results))","reference":"Get the results as a dict, keyed by engine_id.\n\n        timeout behavior is described in `get()`.","result":"Build a dict from the job results .","score":[0.0762,0.1049]}
{"code":"def abort(self):\r\n        \"\"\" function to<extra_id_0>\r\n        assert not self.ready(), \"Can't abort, I am already done!\"\r\n        return self._client.abort(self.msg_ids, targets=self._targets, block=True)","reference":"abort my tasks.","result":"Abort the message .","score":[0,0.1613]}
{"code":"def elapsed(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.ready():\r\n            return self.wall_time\r\n                now = submitted = datetime.now()\r\n        for msg_id in self.msg_ids:\r\n            if msg_id in self._client.metadata:\r\n                stamp = self._client.metadata[msg_id]['submitted']\r\n                if stamp and stamp < submitted:\r\n                    submitted = stamp\r\n        return _total_seconds(now-submitted)","reference":"elapsed time since initial submission","result":"Calculate elapsed time .","score":[0.3519,0.3827]}
{"code":"def wait_interactive(self, interval=1., timeout=None):\r\n        \"\"\" function to<extra_id_0>\r\n        N = len(self)\r\n        tic = time.time()\r\n        while not self.ready() and (timeout is None or time.time() - tic <= timeout):\r\n            self.wait(interval)\r\n            clear_output()\r\n            print(\"%4i\/%i tasks finished after %4i s\" % (self.progress, N, self.elapsed), end=\"\")\r\n            sys.stdout.flush()\r\n        print()\r\n        print(\"done\")","reference":"interactive wait, printing progress at regular intervals","result":"And wait for interactive tasks .","score":[0.1634,0.0725]}
{"code":"def _republish_displaypub(self, content, eid):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            ip = get_ipython()\r\n        except NameError:\r\n            return\r\n        md = content['metadata'] or {}\r\n        md['engine'] = eid\r\n        ip.display_pub.publish(content['source'], content['data'], md)","reference":"republish individual displaypub content dicts","result":"Def republish displaypub .","score":[0.2959,0.2041]}
{"code":"def _wait_for_outputs(self, timeout=-1):\r\n        \"\"\" function to<extra_id_0>\r\n        if not self._success:\r\n            return\r\n        tic = time.time()\r\n        while not all(md['outputs_ready'] for md in self._metadata):\r\n            time.sleep(0.01)\r\n            self._client._flush_iopub(self._client._iopub_socket)\r\n            if timeout >= 0 and time.time() > tic + timeout:\r\n                break","reference":"wait for the 'status=idle' message that indicates we have all outputs","result":"Wait for outputs to be ready .","score":[0.1085,0.2411]}
{"code":"def wait(self, timeout=-1):\r\n        \"\"\" function to<extra_id_0>\r\n        start = time.time()\r\n        if self._ready:\r\n            return\r\n        local_ids = filter(lambda msg_id: msg_id in self._client.outstanding, self.msg_ids)\r\n        local_ready = self._client.wait(local_ids, timeout)\r\n        if local_ready:\r\n            remote_ids = filter(lambda msg_id: msg_id not in self._client.results, self.msg_ids)\r\n            if not remote_ids:\r\n                self._ready = True\r\n            else:\r\n                rdict = self._client.result_status(remote_ids, status_only=False)\r\n                pending = rdict['pending']\r\n                while pending and (timeout < 0 or time.time() < start+timeout):\r\n                    rdict = self._client.result_status(remote_ids, status_only=False)\r\n                    pending = rdict['pending']\r\n                    if pending:\r\n                        time.sleep(0.1)\r\n                if not pending:\r\n                    self._ready = True\r\n        if self._ready:\r\n            try:\r\n                results = map(self._client.results.get, self.msg_ids)\r\n                self._result = results\r\n                if self._single_result:\r\n                    r = results[0]\r\n                    if isinstance(r, Exception):\r\n                        raise r\r\n                else:\r\n                    results = error.collect_exceptions(results, self._fname)\r\n                self._result = self._reconstruct_result(results)\r\n            except Exception, e:\r\n                self._exception = e\r\n                self._success = False\r\n            else:\r\n                self._success = True\r\n            finally:\r\n                self._metadata = map(self._client.metadata.get, self.msg_ids)","reference":"wait for result to complete.","result":"Wait for messages to be sent.","score":[0.2296,0.5011]}
{"code":"def abs_file(filename):\r\n    \"\"\" function to<extra_id_0>\r\n    path = os.path.expandvars(os.path.expanduser(filename))\r\n    path = os.path.abspath(os.path.realpath(path))\r\n    path = actual_path(path)\r\n    return path","reference":"Return the absolute normalized form of `filename`.","result":"Return absolute filename .","score":[0.1795,0.1493]}
{"code":"def prep_patterns(patterns):\r\n    \"\"\" function to<extra_id_0>\r\n    prepped = []\r\n    for p in patterns or []:\r\n        if p.startswith(\"*\") or p.startswith(\"?\"):\r\n            prepped.append(p)\r\n        else:\r\n            prepped.append(abs_file(p))\r\n    return prepped","reference":"Prepare the file patterns for use in a `FnmatchMatcher`.\n\n    If a pattern starts with a wildcard, it is used as a pattern\n    as-is.  If it does not start with a wildcard, then it is made\n    absolute with the current directory.\n\n    If `patterns` is None, an empty list is returned.","result":"Prep patterns .","score":[0.0,0.0113]}
{"code":"def sep(s):\r\n    \"\"\" function to<extra_id_0>\r\n    sep_match = re.search(r\"[\\\\\/]\", s)\r\n    if sep_match:\r\n        the_sep = sep_match.group(0)\r\n    else:\r\n        the_sep = os.sep\r\n    return the_sep","reference":"Find the path separator used in this string, or os.sep if none.","result":"Get the separator of a string .","score":[0.094,0.2222]}
{"code":"def find_python_files(dirname):\r\n    \"\"\" function to<extra_id_0>\r\n    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dirname)):\r\n        if i > 0 and '__init__.py' not in filenames:\r\n            del dirnames[:]\r\n            continue\r\n        for filename in filenames:\r\n            if re.match(r\"^[^.\r\n                yield os.path.join(dirpath, filename)","reference":"Yield all of the importable Python files in `dirname`, recursively.\n\n    To be importable, the files have to be in a directory with a __init__.py,\n    except for `dirname` itself, which isn't required to have one.  The\n    assumption is that `dirname` was specified directly, so the user knows\n    best, but subdirectories are checked for a __init__.py to be sure we only\n    find the importable files.","result":"Find python files in a directory .","score":[0.0001,0.0523]}
{"code":"def relative_filename(self, filename):\r\n        \"\"\" function to<extra_id_0>\r\n        fnorm = os.path.normcase(filename)\r\n        if fnorm.startswith(self.relative_dir):\r\n            filename = filename[len(self.relative_dir):]\r\n        return filename","reference":"Return the relative form of `filename`.\n\n        The filename will be relative to the current directory when the\n        `FileLocator` was constructed.","result":"Get relative filename .","score":[0.007,0.0543]}
{"code":"def canonical_filename(self, filename):\r\n        \"\"\" function to<extra_id_0>\r\n        if filename not in self.canonical_filename_cache:\r\n            if not os.path.isabs(filename):\r\n                for path in [os.curdir] + sys.path:\r\n                    if path is None:\r\n                        continue\r\n                    f = os.path.join(path, filename)\r\n                    if os.path.exists(f):\r\n                        filename = f\r\n                        break\r\n            cf = abs_file(filename)\r\n            self.canonical_filename_cache[filename] = cf\r\n        return self.canonical_filename_cache[filename]","reference":"Return a canonical filename for `filename`.\n\n        An absolute path with no redundant components and normalized case.","result":"Def get canonical filename .","score":[0.0377,0.1258]}
{"code":"def get_zip_data(self, filename):\r\n        \"\"\" function to<extra_id_0>\r\n        import zipimport\r\n        markers = ['.zip'+os.sep, '.egg'+os.sep]\r\n        for marker in markers:\r\n            if marker in filename:\r\n                parts = filename.split(marker)\r\n                try:\r\n                    zi = zipimport.zipimporter(parts[0]+marker[:-1])\r\n                except zipimport.ZipImportError:\r\n                    continue\r\n                try:\r\n                    data = zi.get_data(parts[1])\r\n                except IOError:\r\n                    continue\r\n                return to_string(data)\r\n        return None","reference":"Get data from `filename` if it is a zip file path.\n\n        Returns the string data read from the zip file, or None if no zip file\n        could be found or `filename` isn't in it.  The data returned will be\n        an empty string if the file is empty.","result":"Get zip data from filename .","score":[0.0003,0.0466]}
{"code":"def match(self, fpath):\r\n        \"\"\" function to<extra_id_0>\r\n        for d in self.dirs:\r\n            if fpath.startswith(d):\r\n                if fpath == d:\r\n                    return True\r\n                if fpath[len(d)] == os.sep:\r\n                    return True\r\n        return False","reference":"Does `fpath` indicate a file in one of our trees?","result":"Match a file path .","score":[0.125,0.1974]}
{"code":"def match(self, fpath):\r\n        \"\"\" function to<extra_id_0>\r\n        for pat in self.pats:\r\n            if fnmatch.fnmatch(fpath, pat):\r\n                return True\r\n        return False","reference":"Does `fpath` match one of our filename patterns?","result":"Match a file path .","score":[0,0.0649]}
{"code":"def map(self, path):\r\n        \"\"\" function to<extra_id_0>\r\n        for regex, result, pattern_sep, result_sep in self.aliases:\r\n            m = regex.match(path)\r\n            if m:\r\n                new = path.replace(m.group(0), result)\r\n                if pattern_sep != result_sep:\r\n                    new = new.replace(pattern_sep, result_sep)\r\n                if self.locator:\r\n                    new = self.locator.canonical_filename(new)\r\n                return new\r\n        return path","reference":"Map `path` through the aliases.\n\n        `path` is checked against all of the patterns.  The first pattern to\n        match is used to replace the root of the path with the result root.\n        Only one pattern is ever used.  If no patterns match, `path` is\n        returned unchanged.\n\n        The separator style in the result is made to match that of the result\n        in the alias.","result":"Map aliases to new path .","score":[0.0,0.0266]}
{"code":"def loop_qt4(kernel):\r\n    \"\"\" function to<extra_id_0>\r\n    from IPython.external.qt_for_kernel import QtCore\r\n    from IPython.lib.guisupport import get_app_qt4, start_event_loop_qt4\r\n    kernel.app = get_app_qt4([\" \"])\r\n    kernel.app.setQuitOnLastWindowClosed(False)\r\n    kernel.timer = QtCore.QTimer()\r\n    kernel.timer.timeout.connect(kernel.do_one_iteration)\r\n    kernel.timer.start(1000*kernel._poll_interval)\r\n    start_event_loop_qt4(kernel.app)","reference":"Start a kernel with PyQt4 event loop integration.","result":"Loop Qt.","score":[0,0.0676]}
{"code":"def loop_wx(kernel):\r\n    \"\"\" function to<extra_id_0>\r\n    import wx\r\n    from IPython.lib.guisupport import start_event_loop_wx\r\n    doi = kernel.do_one_iteration\r\n    poll_interval = int(1000*kernel._poll_interval)\r\n    class TimerFrame(wx.Frame):\r\n        def __init__(self, func):\r\n            wx.Frame.__init__(self, None, -1)\r\n            self.timer = wx.Timer(self)\r\n            self.timer.Start(poll_interval)\r\n            self.Bind(wx.EVT_TIMER, self.on_timer)\r\n            self.func = func\r\n        def on_timer(self, event):\r\n            self.func()\r\n    class IPWxApp(wx.App):\r\n        def OnInit(self):\r\n            self.frame = TimerFrame(doi)\r\n            self.frame.Show(False)\r\n            return True\r\n    kernel.app = IPWxApp(redirect=False)\r\n    import signal\r\n    if not callable(signal.getsignal(signal.SIGINT)):\r\n        signal.signal(signal.SIGINT, signal.default_int_handler)\r\n    start_event_loop_wx(kernel.app)","reference":"Start a kernel with wx event loop support.","result":"Def start wx event loop .","score":[0.2849,0.4808]}
{"code":"def loop_tk(kernel):\r\n    \"\"\" function to<extra_id_0>\r\n    import Tkinter\r\n    doi = kernel.do_one_iteration\r\n    poll_interval = int(1000*kernel._poll_interval)\r\n    class Timer(object):\r\n        def __init__(self, func):\r\n            self.app = Tkinter.Tk()\r\n            self.app.withdraw()\r\n            self.func = func\r\n        def on_timer(self):\r\n            self.func()\r\n            self.app.after(poll_interval, self.on_timer)\r\n        def start(self):\r\n            self.on_timer()\r\n            self.app.mainloop()\r\n    kernel.timer = Timer(doi)\r\n    kernel.timer.start()","reference":"Start a kernel with the Tk event loop.","result":"Loop the tk loop .","score":[0.1319,0.2435]}
{"code":"def loop_gtk(kernel):\r\n    \"\"\" function to<extra_id_0>\r\n    from .gui.gtkembed import GTKEmbed\r\n    gtk_kernel = GTKEmbed(kernel)\r\n    gtk_kernel.start()","reference":"Start the kernel, coordinating with the GTK event loop","result":"Def loop gtk .","score":[0.0915,0.1176]}
{"code":"def loop_cocoa(kernel):\r\n    \"\"\" function to<extra_id_0>\r\n    import matplotlib\r\n    if matplotlib.__version__ < '1.1.0':\r\n        kernel.log.warn(\r\n        \"MacOSX backend in matplotlib %s doesn't have a Timer, \"\r\n        \"falling back on Tk for CFRunLoop integration.  Note that \"\r\n        \"even this won't work if Tk is linked against X11 instead of \"\r\n        \"Cocoa (e.g. EPD).  To use the MacOSX backend in the kernel, \"\r\n        \"you must use matplotlib >= 1.1.0, or a native libtk.\"\r\n        )\r\n        return loop_tk(kernel)\r\n        from matplotlib.backends.backend_macosx import TimerMac, show\r\n    poll_interval = int(1000*kernel._poll_interval)\r\n    real_excepthook = sys.excepthook\r\n    def handle_int(etype, value, tb):\r\n        if etype is KeyboardInterrupt:\r\n            io.raw_print(\"KeyboardInterrupt caught in CFRunLoop\")\r\n        else:\r\n            real_excepthook(etype, value, tb)\r\n    def doi():\r\n        sys.excepthook = real_excepthook\r\n        kernel.do_one_iteration()\r\n        sys.excepthook = handle_int\r\n    t = TimerMac(poll_interval)\r\n    t.add_callback(doi)\r\n    t.start()\r\n    poller = zmq.Poller()\r\n    if kernel.control_stream:\r\n        poller.register(kernel.control_stream.socket, zmq.POLLIN)\r\n    for stream in kernel.shell_streams:\r\n        poller.register(stream.socket, zmq.POLLIN)\r\n    while True:\r\n        try:\r\n        try:\r\n                sys.excepthook = handle_int\r\n                show.mainloop()\r\n                sys.excepthook = real_excepthook\r\n                poller.poll(10*poll_interval)\r\n                kernel.do_one_iteration()\r\n            except:\r\n                raise\r\n        except KeyboardInterrupt:\r\n            io.raw_print(\"KeyboardInterrupt caught in kernel\")\r\n        finally:\r\n            sys.excepthook = real_excepthook","reference":"Start the kernel, coordinating with the Cocoa CFRunLoop event loop\n    via the matplotlib MacOSX backend.","result":"Run the Cocoa loop .","score":[0.0509,0.1071]}
{"code":"def enable_gui(gui, kernel=None):\r\n    \"\"\" function to<extra_id_0>\r\n    if gui not in loop_map:\r\n        raise ValueError(\"GUI %r not supported\" % gui)\r\n    if kernel is None:\r\n        if Application.initialized():\r\n            kernel = getattr(Application.instance(), 'kernel', None)\r\n        if kernel is None:\r\n            raise RuntimeError(\"You didn't specify a kernel,\"\r\n                \" and no IPython Application with a kernel appears to be running.\"\r\n            )\r\n    loop = loop_map[gui]\r\n    if kernel.eventloop is not None and kernel.eventloop is not loop:\r\n        raise RuntimeError(\"Cannot activate multiple GUI eventloops\")\r\n    kernel.eventloop = loop","reference":"Enable integration with a given GUI","result":"Enable a GUI .","score":[0.255,0.2586]}
{"code":"def GOE(N):\r\n    \"\"\" function to<extra_id_0>\r\n    m = ra.standard_normal((N,N))\r\n    m += m.T\r\n    return m\/2","reference":"Creates an NxN element of the Gaussian Orthogonal Ensemble","result":"Calculate the GOE .","score":[0.0915,0.0588]}
{"code":"def center_eigenvalue_diff(mat):\r\n    \"\"\" function to<extra_id_0>\r\n    N = len(mat)\r\n    evals = np.sort(la.eigvals(mat))\r\n    diff = np.abs(evals[N\/2] - evals[N\/2-1])\r\n    return diff","reference":"Compute the eigvals of mat and then find the center eigval difference.","result":"Calculate the center eigenvalue diff .","score":[0.1004,0.1645]}
{"code":"def ensemble_diffs(num, N):\r\n    \"\"\" function to<extra_id_0>\r\n    diffs = np.empty(num)\r\n    for i in xrange(num):\r\n        mat = GOE(N)\r\n        diffs[i] = center_eigenvalue_diff(mat)\r\n    return diffs","reference":"Return num eigenvalue diffs for the NxN GOE ensemble.","result":"Calculate ensemble differences .","score":[0,0.0]}
{"code":"def init(self, ctxt, step_addr):\r\n        \"\"\" function to<extra_id_0>\r\n        return self.cls(ctxt, self.name, self.conf, step_addr)","reference":"Initialize the item.  This calls the class constructor with the\n        appropriate arguments and returns the initialized object.\n\n        :param ctxt: The context object.\n        :param step_addr: The address of the step in the test\n                          configuration.","result":"Initialize the object .","score":[0.0003,0.0332]}
{"code":"def parse_file(cls, ctxt, fname, key=None, step_addr=None):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            with open(fname) as f:\r\n                step_data = yaml.load(f)\r\n        except Exception as exc:\r\n            raise ConfigError(\r\n                'Failed to read file \"%s\": %s' % (fname, exc),\r\n                step_addr,\r\n            )\r\n        if key is not None:\r\n            if (not isinstance(step_data, collections.Mapping) or\r\n                    key not in step_data):\r\n                raise ConfigError(\r\n                    'Bad step configuration file \"%s\": expecting dictionary '\r\n                    'with key \"%s\"' % (fname, key),\r\n                    step_addr,\r\n                )\r\n            step_data = step_data[key]\r\n        if not isinstance(step_data, collections.Sequence):\r\n            addr = ('%s[%s]' % (fname, key)) if key is not None else fname\r\n            raise ConfigError(\r\n                'Bad step configuration sequence at %s: expecting list, '\r\n                'not \"%s\"' % (addr, step_data.__class__.__name__),\r\n                step_addr,\r\n            )\r\n        steps = []\r\n        for idx, step_conf in enumerate(step_data):\r\n            steps.extend(cls.parse_step(\r\n                ctxt, StepAddress(fname, idx, key), step_conf))\r\n        return steps","reference":"Parse a YAML file containing test steps.\n\n        :param ctxt: The context object.\n        :param fname: The name of the file to parse.\n        :param key: An optional dictionary key.  If specified, the\n                    file must be a YAML dictionary, and the referenced\n                    value will be interpreted as a list of steps.  If\n                    not provided, the file must be a YAML list, which\n                    will be interpreted as the list of steps.\n        :param step_addr: The address of the step in the test\n                          configuration.  This may be used in the case\n                          of includes, for instance.\n\n        :returns: A list of ``Step`` objects.","result":"Parse a step configuration file.","score":[0.0,0.0174]}
{"code":"def parse_step(cls, ctxt, step_addr, step_conf):\r\n        \"\"\" function to<extra_id_0>\r\n        if isinstance(step_conf, six.string_types):\r\n            step_conf = {step_conf: None}\r\n        elif not isinstance(step_conf, collections.Mapping):\r\n            raise ConfigError(\r\n                'Unable to parse step configuration: expecting string or '\r\n                'dictionary, not \"%s\"' % step_conf.__class__.__name__,\r\n                step_addr,\r\n            )\r\n        action_item = None\r\n        mod_items = {}\r\n        kwargs = {}\r\n        for key, key_conf in step_conf.items():\r\n            if key in cls.schemas:\r\n                utils.schema_validate(key_conf, cls.schemas[key], ConfigError,\r\n                                      key, step_addr=step_addr)\r\n                kwargs[key] = key_conf\r\n            elif key in entry.points[NAMESPACE_ACTION]:\r\n                if action_item is not None:\r\n                    raise ConfigError(\r\n                        'Bad step configuration: action \"%s\" specified, '\r\n                        'but action \"%s\" already processed' %\r\n                        (key, action_item.name),\r\n                        step_addr,\r\n                    )\r\n                action_item = StepItem(\r\n                    entry.points[NAMESPACE_ACTION][key], key, key_conf)\r\n            elif key in entry.points[NAMESPACE_MODIFIER]:\r\n                mod_class = entry.points[NAMESPACE_MODIFIER][key]\r\n                mod_items.setdefault(mod_class.priority, [])\r\n                mod_items[mod_class.priority].append(StepItem(\r\n                    mod_class, key, key_conf))\r\n            else:\r\n                raise ConfigError(\r\n                    'Bad step configuration: unable to resolve action '\r\n                    '\"%s\"' % key,\r\n                    step_addr,\r\n                )\r\n        if action_item is None:\r\n            raise ConfigError(\r\n                'Bad step configuration: no action specified',\r\n                step_addr,\r\n            )\r\n        action_type = (Modifier.STEP if action_item.cls.step_action\r\n                       else Modifier.NORMAL)\r\n        modifiers = []\r\n        for mod_item in utils.iter_prio_dict(mod_items):\r\n            if mod_item.cls.restriction & action_type == 0:\r\n                raise ConfigError(\r\n                    'Bad step configuration: modifier \"%s\" is '\r\n                    'incompatible with the action \"%s\"' %\r\n                    (mod_item.name, action_item.name),\r\n                    step_addr,\r\n                )\r\n            modifier = mod_item.init(ctxt, step_addr)\r\n            modifiers.append(modifier)\r\n            action_item.conf = modifier.action_conf(\r\n                ctxt, action_item.cls, action_item.name, action_item.conf,\r\n                step_addr)\r\n        action = action_item.init(ctxt, step_addr)\r\n        step = cls(step_addr, action, modifiers, **kwargs)\r\n        if action_item.cls.step_action:\r\n            return step(ctxt)\r\n        return [step]","reference":"Parse a step dictionary.\n\n        :param ctxt: The context object.\n        :param step_addr: The address of the step in the test\n                          configuration.\n        :param step_conf: The description of the step.  This may be a\n                          scalar string or a dictionary.\n\n        :returns: A list of steps.","result":"Parse a step configuration .","score":[0.0004,0.0401]}
{"code":"def init_crash_handler(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self.crash_handler = self.crash_handler_class(self)\r\n        sys.excepthook = self.excepthook\r\n        def unset_crashhandler():\r\n            sys.excepthook = sys.__excepthook__\r\n        atexit.register(unset_crashhandler)","reference":"Create a crash handler, typically setting sys.excepthook to it.","result":"Def initialize the crash handler .","score":[0.1171,0.0575]}
{"code":"def load_config_file(self, suppress_errors=True):\r\n        \"\"\" function to<extra_id_0>\r\n        self.log.debug(\"Searching path %s for config files\", self.config_file_paths)\r\n        base_config = 'ipython_config.py'\r\n        self.log.debug(\"Attempting to load config file: %s\" %\r\n                       base_config)\r\n        try:\r\n            Application.load_config_file(\r\n                self,\r\n                base_config,\r\n                path=self.config_file_paths\r\n            )\r\n        except ConfigFileNotFound:\r\n            self.log.debug(\"Config file %s not found\", base_config)\r\n            pass\r\n        if self.config_file_name == base_config:\r\n            return\r\n        self.log.debug(\"Attempting to load config file: %s\" %\r\n                       self.config_file_name)\r\n        try:\r\n            Application.load_config_file(\r\n                self,\r\n                self.config_file_name,\r\n                path=self.config_file_paths\r\n            )\r\n        except ConfigFileNotFound:\r\n            if self.config_file_specified:\r\n                msg = self.log.warn\r\n            else:\r\n                msg = self.log.debug\r\n            msg(\"Config file not found, skipping: %s\", self.config_file_name)\r\n        except:\r\n            if not suppress_errors:\r\n                raise\r\n            self.log.warn(\"Error loading config file: %s\" %\r\n                          self.config_file_name, exc_info=True)","reference":"Load the config file.\n\n        By default, errors in loading config are handled, and a warning\n        printed on screen. For testing, the suppress_errors option is set\n        to False, so errors will make tests fail.","result":"Load config file .","score":[0.0003,0.0332]}
{"code":"def init_profile_dir(self):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            location = self.config.ProfileDir.location\r\n        except AttributeError:\r\n            try:\r\n                p = ProfileDir.find_profile_dir_by_name(self.ipython_dir, self.profile, self.config)\r\n            except ProfileDirError:\r\n                if self.auto_create or self.profile=='default':\r\n                    try:\r\n                        p = ProfileDir.create_profile_dir_by_name(self.ipython_dir, self.profile, self.config)\r\n                    except ProfileDirError:\r\n                        self.log.fatal(\"Could not create profile: %r\"%self.profile)\r\n                        self.exit(1)\r\n                    else:\r\n                        self.log.info(\"Created profile dir: %r\"%p.location)\r\n                else:\r\n                    self.log.fatal(\"Profile %r not found.\"%self.profile)\r\n                    self.exit(1)\r\n            else:\r\n                self.log.info(\"Using existing profile dir: %r\"%p.location)\r\n        else:\r\n            try:\r\n                p = ProfileDir.find_profile_dir(location, self.config)\r\n            except ProfileDirError:\r\n                if self.auto_create:\r\n                    try:\r\n                        p = ProfileDir.create_profile_dir(location, self.config)\r\n                    except ProfileDirError:\r\n                        self.log.fatal(\"Could not create profile directory: %r\"%location)\r\n                        self.exit(1)\r\n                    else:\r\n                        self.log.info(\"Creating new profile dir: %r\"%location)\r\n                else:\r\n                    self.log.fatal(\"Profile directory %r not found.\"%location)\r\n                    self.exit(1)\r\n            else:\r\n                self.log.info(\"Using existing profile dir: %r\"%location)\r\n        self.profile_dir = p\r\n        self.config_file_paths.append(p.location)","reference":"initialize the profile dir","result":"Initialize the profile directory .","score":[0.3398,0.7182]}
{"code":"def stage_default_config_file(self):\r\n        \"\"\" function to<extra_id_0>\r\n        s = self.generate_config_file()\r\n        fname = os.path.join(self.profile_dir.location, self.config_file_name)\r\n        if self.overwrite or not os.path.exists(fname):\r\n            self.log.warn(\"Generating default config file: %r\"%(fname))\r\n            with open(fname, 'w') as f:\r\n                f.write(s)","reference":"auto generate default config file, and stage it into the profile.","result":"Generate and save default config file .","score":[0.1427,0.2978]}
{"code":"def write(self, suffix=None):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.use_file:\r\n            filename = self.filename\r\n            if suffix:\r\n                filename += \".\" + suffix\r\n            self.write_file(filename)","reference":"Write the collected coverage data to a file.\n\n        `suffix` is a suffix to append to the base file name. This can be used\n        for multiple or parallel execution, so that many coverage data files\n        can exist simultaneously.  A dot will be used to join the base name and\n        the suffix.","result":"Write the file .","score":[0.0,0.033]}
{"code":"def erase(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.use_file:\r\n            if self.filename:\r\n                file_be_gone(self.filename)\r\n        self.lines = {}\r\n        self.arcs = {}","reference":"Erase the data, both in this object, and from its file storage.","result":"Erase the object .","score":[0.0611,0.1674]}
{"code":"def line_data(self):\r\n        \"\"\" function to<extra_id_0>\r\n        return dict(\r\n            [(f, sorted(lmap.keys())) for f, lmap in iitems(self.lines)]\r\n            )","reference":"Return the map from filenames to lists of line numbers executed.","result":"Return line data .","score":[0.066,0.0971]}
{"code":"def arc_data(self):\r\n        \"\"\" function to<extra_id_0>\r\n        return dict(\r\n            [(f, sorted(amap.keys())) for f, amap in iitems(self.arcs)]\r\n            )","reference":"Return the map from filenames to lists of line number pairs.","result":"Def return arc data .","score":[0,0.0481]}
{"code":"def write_file(self, filename):\r\n        \"\"\" function to<extra_id_0>\r\n        data = {}\r\n        data['lines'] = self.line_data()\r\n        arcs = self.arc_data()\r\n        if arcs:\r\n            data['arcs'] = arcs\r\n        if self.collector:\r\n            data['collector'] = self.collector\r\n        if self.debug and self.debug.should('dataio'):\r\n            self.debug.write(\"Writing data to %r\" % (filename,))\r\n        fdata = open(filename, 'wb')\r\n        try:\r\n            pickle.dump(data, fdata, 2)\r\n        finally:\r\n            fdata.close()","reference":"Write the coverage data to `filename`.","result":"Write data to file .","score":[0.3079,0.4331]}
{"code":"def read_file(self, filename):\r\n        \"\"\" function to<extra_id_0>\r\n        self.lines, self.arcs = self._read_file(filename)","reference":"Read the coverage data from `filename`.","result":"Read a file .","score":[0.1938,0.0862]}
{"code":"def raw_data(self, filename):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.debug and self.debug.should('dataio'):\r\n            self.debug.write(\"Reading data from %r\" % (filename,))\r\n        fdata = open(filename, 'rb')\r\n        try:\r\n            data = pickle.load(fdata)\r\n        finally:\r\n            fdata.close()\r\n        return data","reference":"Return the raw pickled data from `filename`.","result":"Read data from a file .","score":[0.2311,0.2717]}
{"code":"def _read_file(self, filename):\r\n        \"\"\" function to<extra_id_0>\r\n        lines = {}\r\n        arcs = {}\r\n        try:\r\n            data = self.raw_data(filename)\r\n            if isinstance(data, dict):\r\n                lines = dict([\r\n                    (f, dict.fromkeys(linenos, None))\r\n                        for f, linenos in iitems(data.get('lines', {}))\r\n                    ])\r\n                arcs = dict([\r\n                    (f, dict.fromkeys(arcpairs, None))\r\n                        for f, arcpairs in iitems(data.get('arcs', {}))\r\n                    ])\r\n        except Exception:\r\n            pass\r\n        return lines, arcs","reference":"Return the stored coverage data from the given file.\n\n        Returns two values, suitable for assigning to `self.lines` and\n        `self.arcs`.","result":"Read a file .","score":[0,0.0]}
{"code":"def combine_parallel_data(self, aliases=None):\r\n        \"\"\" function to<extra_id_0>\r\n        aliases = aliases or PathAliases()\r\n        data_dir, local = os.path.split(self.filename)\r\n        localdot = local + '.'\r\n        for f in os.listdir(data_dir or '.'):\r\n            if f.startswith(localdot):\r\n                full_path = os.path.join(data_dir, f)\r\n                new_lines, new_arcs = self._read_file(full_path)\r\n                for filename, file_data in iitems(new_lines):\r\n                    filename = aliases.map(filename)\r\n                    self.lines.setdefault(filename, {}).update(file_data)\r\n                for filename, file_data in iitems(new_arcs):\r\n                    filename = aliases.map(filename)\r\n                    self.arcs.setdefault(filename, {}).update(file_data)\r\n                if f != local:\r\n                    os.remove(full_path)","reference":"Combine a number of data files together.\n\n        Treat `self.filename` as a file prefix, and combine the data from all\n        of the data files starting with that prefix plus a dot.\n\n        If `aliases` is provided, it's a `PathAliases` object that is used to\n        re-map paths to match the local machine's.","result":"Combine parallel data .","score":[0.0,0.0225]}
{"code":"def add_line_data(self, line_data):\r\n        \"\"\" function to<extra_id_0>\r\n        for filename, linenos in iitems(line_data):\r\n            self.lines.setdefault(filename, {}).update(linenos)","reference":"Add executed line data.\n\n        `line_data` is { filename: { lineno: None, ... }, ...}","result":"Add line data .","score":[0.0312,0.0769]}
{"code":"def add_arc_data(self, arc_data):\r\n        \"\"\" function to<extra_id_0>\r\n        for filename, arcs in iitems(arc_data):\r\n            self.arcs.setdefault(filename, {}).update(arcs)","reference":"Add measured arc data.\n\n        `arc_data` is { filename: { (l1,l2): None, ... }, ...}","result":"Def add arc data .","score":[0.0397,0.0763]}
{"code":"def add_to_hash(self, filename, hasher):\r\n        \"\"\" function to<extra_id_0>\r\n        hasher.update(self.executed_lines(filename))\r\n        hasher.update(self.executed_arcs(filename))","reference":"Contribute `filename`'s data to the Md5Hash `hasher`.","result":"Add to hash .","score":[0.1509,0.0746]}
{"code":"def summary(self, fullpath=False):\r\n        \"\"\" function to<extra_id_0>\r\n        summ = {}\r\n        if fullpath:\r\n            filename_fn = lambda f: f\r\n        else:\r\n            filename_fn = os.path.basename\r\n        for filename, lines in iitems(self.lines):\r\n            summ[filename_fn(filename)] = len(lines)\r\n        return summ","reference":"Return a dict summarizing the coverage data.\n\n        Keys are based on the filenames, and values are the number of executed\n        lines.  If `fullpath` is true, then the keys are the full pathnames of\n        the files, otherwise they are the basenames of the files.","result":"Return a dictionary of summary information .","score":[0.0015,0.0649]}
{"code":"def get_pasted_lines(sentinel, l_input=py3compat.input):\r\n    \"\"\" function to<extra_id_0>\r\n    print \"Pasting code; enter '%s' alone on the line to stop or use Ctrl-D.\" \\\r\n          % sentinel\r\n    while True:\r\n        try:\r\n            l = l_input(':')\r\n            if l == sentinel:\r\n                return\r\n            else:\r\n                yield l\r\n        except EOFError:\r\n            print '<EOF>'\r\n            return","reference":"Yield pasted lines until the user enters the given sentinel value.","result":"Get pasted lines .","score":[0.0785,0.182]}
{"code":"def mainloop(self, display_banner=None):\r\n        \"\"\" function to<extra_id_0>\r\n        with nested(self.builtin_trap, self.display_trap):\r\n            while 1:\r\n                try:\r\n                    self.interact(display_banner=display_banner)\r\n                    break\r\n                except KeyboardInterrupt:\r\n                    self.write(\"\\nKeyboardInterrupt in interact()\\n\")","reference":"Start the mainloop.\n\n        If an optional banner argument is given, it will override the\n        internally created default banner.","result":"Def run the mainloop .","score":[0.0178,0.0299]}
{"code":"def _replace_rlhist_multiline(self, source_raw, hlen_before_cell):\r\n        \"\"\" function to<extra_id_0>\r\n        if not self.has_readline or not self.multiline_history:\r\n            return hlen_before_cell\r\n        if not hasattr(self.readline, \"remove_history_item\"):\r\n            return hlen_before_cell\r\n        if not source_raw.rstrip():\r\n            return hlen_before_cell\r\n        hlen = self.readline.get_current_history_length()\r\n        if hlen == hlen_before_cell:\r\n            return hlen_before_cell\r\n        for i in range(hlen - hlen_before_cell):\r\n            self.readline.remove_history_item(hlen - i - 1)\r\n        stdin_encoding = get_stream_enc(sys.stdin, 'utf-8')\r\n        self.readline.add_history(py3compat.unicode_to_str(source_raw.rstrip(),\r\n                                    stdin_encoding))\r\n        return self.readline.get_current_history_length()","reference":"Store multiple lines as a single entry in history","result":"Replace the history of a readline cell .","score":[0.1458,0.1124]}
{"code":"def raw_input(self, prompt=''):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.has_readline:\r\n            self.set_readline_completer()\r\n                prompt = py3compat.cast_bytes_py2(prompt)\r\n        try:\r\n            line = py3compat.str_to_unicode(self.raw_input_original(prompt))\r\n        except ValueError:\r\n            warn(\"\\n********\\nYou or a %run:ed script called sys.stdin.close()\"\r\n                 \" or sys.stdout.close()!\\nExiting IPython!\\n\")\r\n            self.ask_exit()\r\n            return \"\"\r\n        if self.autoindent:\r\n            if num_ini_spaces(line) > self.indent_current_nsp:\r\n                line = line[self.indent_current_nsp:]\r\n                self.indent_current_nsp = 0\r\n        return line","reference":"Write a prompt and read a line.\n\n        The returned line does not include the trailing newline.\n        When the user enters the EOF key sequence, EOFError is raised.\n\n        Optional inputs:\n\n          - prompt(''): a string to be printed to prompt the user.\n\n          - continue_prompt(False): whether this line is the first one or a\n          continuation in a sequence of inputs.","result":"Get user input .","score":[0.0,0.0097]}
{"code":"def edit_syntax_error(self):\r\n        \"\"\" function to<extra_id_0>\r\n        while self.SyntaxTB.last_syntax_error:\r\n            err = self.SyntaxTB.clear_err_state()\r\n            if not self._should_recompile(err):\r\n                return\r\n            try:\r\n                self.safe_execfile(err.filename,self.user_ns)\r\n            except:\r\n                self.showtraceback()\r\n            else:\r\n                try:\r\n                    f = open(err.filename)\r\n                    try:\r\n                        sys.displayhook(f.read())\r\n                    finally:\r\n                        f.close()\r\n                except:\r\n                    self.showtraceback()","reference":"The bottom half of the syntax error handler called in the main loop.\n\n        Loop until syntax error is fixed or user cancels.","result":"Edit syntax error .","score":[0.005,0.0928]}
{"code":"def _should_recompile(self,e):\r\n        \"\"\" function to<extra_id_0>\r\n        if e.filename in ('<ipython console>','<input>','<string>',\r\n                          '<console>','<BackgroundJob compilation>',\r\n                          None):\r\n            return False\r\n        try:\r\n            if (self.autoedit_syntax and\r\n                not self.ask_yes_no('Return to editor to correct syntax error? '\r\n                              '[Y\/n] ','y')):\r\n                return False\r\n        except EOFError:\r\n            return False\r\n        def int0(x):\r\n            try:\r\n                return int(x)\r\n            except TypeError:\r\n                return 0\r\n        try:\r\n            self.hooks.fix_error_editor(e.filename,\r\n                int0(e.lineno),int0(e.offset),e.msg)\r\n        except TryNext:\r\n            warn('Could not open editor')\r\n            return False\r\n        return True","reference":"Utility routine for edit_syntax_error","result":"Check if recompiling should be done .","score":[0,0.0]}
{"code":"def exit(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.confirm_exit:\r\n            if self.ask_yes_no('Do you really want to exit ([y]\/n)?','y'):\r\n                self.ask_exit()\r\n        else:\r\n            self.ask_exit()","reference":"Handle interactive exit.\n\n        This method calls the ask_exit callback.","result":"Exit the application .","score":[0.0915,0.0588]}
{"code":"def get_url_rev(self):\r\n        \"\"\" function to<extra_id_0>\r\n        error_message= (\r\n           \"Sorry, '%s' is a malformed VCS url. \"\r\n           \"Ihe format is <vcs>+<protocol>:\/\/<url>, \"\r\n           \"e.g. svn+http:\/\/myrepo\/svn\/MyApp\r\n        assert '+' in self.url, error_message % self.url\r\n        url = self.url.split('+', 1)[1]\r\n        scheme, netloc, path, query, frag = urlparse.urlsplit(url)\r\n        rev = None\r\n        if '@' in path:\r\n            path, rev = path.rsplit('@', 1)\r\n        url = urlparse.urlunsplit((scheme, netloc, path, query, ''))\r\n        return url, rev","reference":"Returns the correct repository URL and revision by parsing the given\n        repository URL","result":"Get url and rev from url.","score":[0.0601,0.0813]}
{"code":"def new_frontend_master(self):\r\n        \"\"\" function to<extra_id_0>\r\n        ip = self.ip if self.ip in LOCAL_IPS else LOCALHOST\r\n        kernel_manager = self.kernel_manager_class(\r\n                                ip=ip,\r\n                                connection_file=self._new_connection_file(),\r\n                                config=self.config,\r\n        )\r\n        kwargs = dict()\r\n        kwargs['extra_arguments'] = self.kernel_argv\r\n        kernel_manager.start_kernel(**kwargs)\r\n        kernel_manager.start_channels()\r\n        widget = self.widget_factory(config=self.config,\r\n                                   local_kernel=True)\r\n        self.init_colors(widget)\r\n        widget.kernel_manager = kernel_manager\r\n        widget._existing = False\r\n        widget._may_close = True\r\n        widget._confirm_exit = self.confirm_exit\r\n        return widget","reference":"Create and return new frontend attached to new kernel, launched on localhost.","result":"Create a new frontend master widget .","score":[0.1237,0.1304]}
{"code":"def init_colors(self, widget):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            colors = self.config.ZMQInteractiveShell.colors\r\n        except AttributeError:\r\n            colors = None\r\n        try:\r\n            style = self.config.IPythonWidget.syntax_style\r\n        except AttributeError:\r\n            style = None\r\n        try:\r\n            sheet = self.config.IPythonWidget.style_sheet\r\n        except AttributeError:\r\n            sheet = None\r\n        if colors:\r\n            colors=colors.lower()\r\n            if colors in ('lightbg', 'light'):\r\n                colors='lightbg'\r\n            elif colors in ('dark', 'linux'):\r\n                colors='linux'\r\n            else:\r\n                colors='nocolor'\r\n        elif style:\r\n            if style=='bw':\r\n                colors='nocolor'\r\n            elif styles.dark_style(style):\r\n                colors='linux'\r\n            else:\r\n                colors='lightbg'\r\n        else:\r\n            colors=None\r\n        if style:\r\n            widget.style_sheet = styles.sheet_from_template(style, colors)\r\n            widget.syntax_style = style\r\n            widget._syntax_style_changed()\r\n            widget._style_sheet_changed()\r\n        elif colors:\r\n            widget.set_default_style(colors=colors)\r\n        if self.stylesheet:\r\n            if os.path.isfile(self.stylesheet):\r\n                with open(self.stylesheet) as f:\r\n                    sheet = f.read()\r\n            else:\r\n                raise IOError(\"Stylesheet %r not found.\" % self.stylesheet)\r\n        if sheet:\r\n            widget.style_sheet = sheet\r\n            widget._style_sheet_changed()","reference":"Configure the coloring of the widget","result":"Initialize colors .","score":[0,0.0877]}
{"code":"def info(self):\r\n        \"\"\" function to<extra_id_0>\r\n        return (self.identity, self.url, self.pub_url, self.location)","reference":"return the connection info for this object's sockets.","result":"Get info .","score":[0.0771,0.0667]}
{"code":"def Rconverter(Robj, dataframe=False):\r\n    \"\"\" function to<extra_id_0>\r\n    is_data_frame = ro.r('is.data.frame')\r\n    colnames = ro.r('colnames')\r\n    rownames = ro.r('rownames')\r\n    names = ro.r('names')\r\n    if dataframe:\r\n        as_data_frame = ro.r('as.data.frame')\r\n        cols = colnames(Robj)\r\n        _names = names(Robj)\r\n        if cols != ri.NULL:\r\n            Robj = as_data_frame(Robj)\r\n            names = tuple(np.array(cols))\r\n        elif _names != ri.NULL:\r\n            names = tuple(np.array(_names))\r\n        else:\r\n            return np.asarray(Robj)\r\n        Robj = np.rec.fromarrays(Robj, names = names)\r\n    return np.asarray(Robj)","reference":"Convert an object in R's namespace to one suitable\n    for ipython's namespace.\n\n    For a data.frame, it tries to return a structured array.\n    It first checks for colnames, then names.\n    If all are NULL, it returns np.asarray(Robj), else\n    it tries to construct a recarray\n\n    Parameters\n    ----------\n\n    Robj: an R object returned from rpy2","result":"Convert Robj to numpy array .","score":[0.0001,0.0211]}
{"code":"def findsource(object):\r\n    \"\"\" function to<extra_id_0>\r\n    file = getsourcefile(object) or getfile(object)\r\n    globals_dict = None\r\n    if inspect.isframe(object):\r\n        globals_dict = object.f_globals\r\n    else:\r\n        module = getmodule(object, file)\r\n        if module:\r\n            globals_dict = module.__dict__\r\n    lines = linecache.getlines(file, globals_dict)\r\n    if not lines:\r\n        raise IOError('could not get source code')\r\n    if ismodule(object):\r\n        return lines, 0\r\n    if isclass(object):\r\n        name = object.__name__\r\n        pat = re.compile(r'^(\\s*)class\\s*' + name + r'\\b')\r\n        candidates = []\r\n        for i in range(len(lines)):\r\n            match = pat.match(lines[i])\r\n            if match:\r\n                if lines[i][0] == 'c':\r\n                    return lines, i\r\n                candidates.append((match.group(1), i))\r\n        if candidates:\r\n            candidates.sort()\r\n            return lines, candidates[0][1]\r\n        else:\r\n            raise IOError('could not find class definition')\r\n    if ismethod(object):\r\n        object = object.im_func\r\n    if isfunction(object):\r\n        object = object.func_code\r\n    if istraceback(object):\r\n        object = object.tb_frame\r\n    if isframe(object):\r\n        object = object.f_code\r\n    if iscode(object):\r\n        if not hasattr(object, 'co_firstlineno'):\r\n            raise IOError('could not find function definition')\r\n        pat = re.compile(r'^(\\s*def\\s)|(.*(?<!\\w)lambda(:|\\s))|^(\\s*@)')\r\n        pmatch = pat.match\r\n        lnum = min(object.co_firstlineno,len(lines))-1\r\n        while lnum > 0:\r\n            if pmatch(lines[lnum]): break\r\n            lnum -= 1\r\n        return lines, lnum\r\n    raise IOError('could not find code object')","reference":"Return the entire source file and starting line number for an object.\n\n    The argument may be a module, class, method, function, traceback, frame,\n    or code object.  The source code is returned as a list of all the lines\n    in the file and the line number indexes a line in that list.  An IOError\n    is raised if the source code cannot be retrieved.\n\n    FIXED version with which we monkeypatch the stdlib to work around a bug.","result":"Find source code .","score":[0.0,0.0276]}
{"code":"def set_colors(self,*args,**kw):\r\n        \"\"\" function to<extra_id_0>\r\n        self.color_scheme_table.set_active_scheme(*args,**kw)\r\n        self.Colors = self.color_scheme_table.active_colors\r\n        if hasattr(self,'pdb') and self.pdb is not None:\r\n            self.pdb.set_colors(*args,**kw)","reference":"Shorthand access to the color table scheme selector method.","result":"Set colors .","score":[0,0.0595]}
{"code":"def color_toggle(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.color_scheme_table.active_scheme_name == 'NoColor':\r\n            self.color_scheme_table.set_active_scheme(self.old_scheme)\r\n            self.Colors = self.color_scheme_table.active_colors\r\n        else:\r\n            self.old_scheme = self.color_scheme_table.active_scheme_name\r\n            self.color_scheme_table.set_active_scheme('NoColor')\r\n            self.Colors = self.color_scheme_table.active_colors","reference":"Toggle between the currently active color scheme and NoColor.","result":"Toggle color scheme .","score":[0.1433,0.3007]}
{"code":"def text(self, etype, value, tb, tb_offset=None, context=5):\r\n        \"\"\" function to<extra_id_0>\r\n        tb_list = self.structured_traceback(etype, value, tb,\r\n                                            tb_offset, context)\r\n        return self.stb2text(tb_list)","reference":"Return formatted traceback.\n\n        Subclasses may override this if they add extra arguments.","result":"Return a traceback as a string .","score":[0.0791,0.0435]}
{"code":"def structured_traceback(self, etype, value, elist, tb_offset=None,\r\n                             \"\"\" function to<extra_id_0>\r\n                             context=5):\r\n        tb_offset = self.tb_offset if tb_offset is None else tb_offset\r\n        Colors = self.Colors\r\n        out_list = []\r\n        if elist:\r\n            if tb_offset and len(elist) > tb_offset:\r\n                elist = elist[tb_offset:]\r\n            out_list.append('Traceback %s(most recent call last)%s:' %\r\n                                (Colors.normalEm, Colors.Normal) + '\\n')\r\n            out_list.extend(self._format_list(elist))\r\n        lines = ''.join(self._format_exception_only(etype, value))\r\n        out_list.append(lines)\r\n","reference":"Return a color formatted string with the traceback info.\n\n        Parameters\n        ----------\n        etype : exception type\n          Type of the exception raised.\n\n        value : object\n          Data stored in the exception\n\n        elist : list\n          List of frames, see class docstring for details.\n\n        tb_offset : int, optional\n          Number of frames in the traceback to skip.  If not given, the\n          instance value is used (set in constructor).\n\n        context : int, optional\n          Number of lines of context information to print.\n\n        Returns\n        -------\n        String with formatted exception.","result":"Format a structured traceback .","score":[0.0,0.0207]}
{"code":"def _format_list(self, extracted_list):\r\n        \"\"\" function to<extra_id_0>\r\n        Colors = self.Colors\r\n        list = []\r\n        for filename, lineno, name, line in extracted_list[:-1]:\r\n            item = '  File %s\"%s\"%s, line %s%d%s, in %s%s%s\\n' % \\\r\n                    (Colors.filename, filename, Colors.Normal,\r\n                     Colors.lineno, lineno, Colors.Normal,\r\n                     Colors.name, name, Colors.Normal)\r\n            if line:\r\n                item += '    %s\\n' % line.strip()\r\n            list.append(item)\r\n        filename, lineno, name, line = extracted_list[-1]\r\n        item = '%s  File %s\"%s\"%s, line %s%d%s, in %s%s%s%s\\n' % \\\r\n                (Colors.normalEm,\r\n                 Colors.filenameEm, filename, Colors.normalEm,\r\n                 Colors.linenoEm, lineno, Colors.normalEm,\r\n                 Colors.nameEm, name, Colors.normalEm,\r\n                 Colors.Normal)\r\n        if line:\r\n            item += '%s    %s%s\\n' % (Colors.line, line.strip(),\r\n                                            Colors.Normal)\r\n        list.append(item)\r\n   return list","reference":"Format a list of traceback entry tuples for printing.\n\n        Given a list of tuples as returned by extract_tb() or\n        extract_stack(), return a list of strings ready for printing.\n        Each string in the resulting list corresponds to the item with the\n        same index in the argument list.  Each string ends in a newline;\n        the strings may contain internal newlines as well, for those items\n        whose source text line is not None.\n\n        Lifted almost verbatim from traceback.py","result":"Format a list of extracted files .","score":[0.0,0.0293]}
{"code":"def _format_exception_only(self, etype, value):\r\n        \"\"\" function to<extra_id_0>\r\n        have_filedata = False\r\n        Colors = self.Colors\r\n        list = []\r\n        stype = Colors.excName + etype.__name__ + Colors.Normal\r\n        if value is None:\r\n            list.append( str(stype) + '\\n')\r\n        else:\r\n            if etype is SyntaxError:\r\n                have_filedata = True\r\n          if not value.filename: value.filename = \"<string>\"\r\n                list.append('%s  File %s\"%s\"%s, line %s%d%s\\n' % \\\r\n                        (Colors.normalEm,\r\n                         Colors.filenameEm, value.filename, Colors.normalEm,\r\n                         Colors.linenoEm, value.lineno, Colors.Normal  ))\r\n                if value.text is not None:\r\n                    i = 0\r\n                    while i < len(value.text) and value.text[i].isspace():\r\n                        i += 1\r\n                    list.append('%s    %s%s\\n' % (Colors.line,\r\n                                                  value.text.strip(),\r\n                                                  Colors.Normal))\r\n                    if value.offset is not None:\r\n                        s = '    '\r\n                        for c in value.text[i:value.offset-1]:\r\n                            if c.isspace():\r\n                                s += c\r\n                            else:\r\n                                s += ' '\r\n                        list.append('%s%s^%s\\n' % (Colors.caret, s,\r\n                                                   Colors.Normal) )\r\n            try:\r\n                s = value.msg\r\n            except Exception:\r\n                s = self._some_str(value)\r\n            if s:\r\n                list.append('%s%s:%s %s\\n' % (str(stype), Colors.excName,\r\n                                              Colors.Normal, s))\r\n            else:\r\n                list.append('%s\\n' % str(stype))\r\n        if have_filedata:\r\n            ipinst = ipapi.get()\r\n            if ipinst is not None:\r\n                ipinst.hooks.synchronize_with_editor(value.filename, value.lineno, 0)\r\n        return list","reference":"Format the exception part of a traceback.\n\n        The arguments are the exception type and value such as given by\n        sys.exc_info()[:2]. The return value is a list of strings, each ending\n        in a newline.  Normally, the list contains a single string; however,\n        for SyntaxError exceptions, it contains several lines that (when\n        printed) display detailed information about where the syntax error\n        occurred.  The message indicating which exception occurred is the\n        always last string in the list.\n\n        Also lifted nearly verbatim from traceback.py","result":"Def format exception only .","score":[0.0,0.0138]}
{"code":"def show_exception_only(self, etype, evalue):\r\n        \"\"\" function to<extra_id_0>\r\n        ostream = self.ostream\r\n        ostream.flush()\r\n        ostream.write('\\n'.join(self.get_exception_only(etype, evalue)))\r\n        ostream.flush()","reference":"Only print the exception type and message, without a traceback.\n\n        Parameters\n        ----------\n        etype : exception type\n        value : exception value","result":"Show exception only .","score":[0.0059,0.0543]}
{"code":"def debugger(self,force=False):\r\n        \"\"\" function to<extra_id_0>\r\n        if force or self.call_pdb:\r\n            if self.pdb is None:\r\n                self.pdb = debugger.Pdb(\r\n                    self.color_scheme_table.active_scheme_name)\r\n            display_trap = DisplayTrap(hook=sys.__displayhook__)\r\n            with display_trap:\r\n                self.pdb.reset()\r\n                if hasattr(self,'tb') and self.tb is not None:\r\n                    etb = self.tb\r\n                else:\r\n                    etb = self.tb = sys.last_traceback\r\n                while self.tb is not None and self.tb.tb_next is not None:\r\n                    self.tb = self.tb.tb_next\r\n                if etb and etb.tb_next:\r\n                    etb = etb.tb_next\r\n                self.pdb.botframe = etb.tb_frame\r\n                self.pdb.interaction(self.tb.tb_frame, self.tb)\r\n        if hasattr(self,'tb'):\r\n            del self.tb","reference":"Call up the pdb debugger if desired, always clean up the tb\n        reference.\n\n        Keywords:\n\n          - force(False): by default, this routine checks the instance call_pdb\n          flag and does not actually invoke the debugger if the flag is false.\n          The 'force' option forces the debugger to activate even if the flag\n          is false.\n\n        If the call_pdb flag is set, the pdb interactive debugger is\n        invoked. In all cases, the self.tb reference to the current traceback\n        is deleted to prevent lingering references which hamper memory\n        management.\n\n        Note that each call to pdb() does an 'import readline', so if your app\n        requires a special setup for the readline completers, you'll have to\n        fix that by hand after invoking the exception handler.","result":"Call debugger .","score":[1.524e-17,0.0095]}
{"code":"def set_mode(self,mode=None):\r\n        \"\"\" function to<extra_id_0>\r\n        if not mode:\r\n            new_idx = ( self.valid_modes.index(self.mode) + 1 ) % \\\r\n                      len(self.valid_modes)\r\n            self.mode = self.valid_modes[new_idx]\r\n        elif mode not in self.valid_modes:\r\n            raise ValueError, 'Unrecognized mode in FormattedTB: <'+mode+'>\\n'\\\r\n                  'Valid modes: '+str(self.valid_modes)\r\n        else:\r\n            self.mode = mode\r\n        self.include_vars = (self.mode == self.valid_modes[2])\r\n        self.tb_join_char = self._join_chars[self.mode]","reference":"Switch to the desired mode.\n\n        If mode is not specified, cycles through the available modes.","result":"Set the mode of the formatter .","score":[0.0678,0.1056]}
{"code":"def group_required(group,\r\r\n                   \"\"\" function to<extra_id_0>\r\n                   login_url=None,\r\r\n                   redirect_field_name=REDIRECT_FIELD_NAME,\r\r\n                   skip_superuser=True):\r\r\n\r\r\n    def decorator(view_func):\r\r\n        @login_required(redirect_field_name=redirect_field_name,\r\r\n                        login_url=login_url)\r\r\n        def _wrapped_view(request, *args, **kwargs):\r\r\n\r\r\n            if not (request.user.is_superuser and skip_superuser):\r\r\n                if request.user.groups.filter(name=group).count() == 0:\r\r\n                    raise PermissionDenied\r\r\n\r\r\n            return view_func(request, *args, **kwargs)\r\r\n        return _wrapped_view\r\r\n\r\r\n    return decorator","reference":"View decorator for requiring a user group.","result":"Check if a user has a group .","score":[0.1964,0.1408]}
{"code":"def ensure_fromlist(mod, fromlist, buf, recursive):\r\n    \"\"\" function to<extra_id_0>\r\n    if not hasattr(mod, '__path__'):\r\n        return\r\n    for item in fromlist:\r\n        if not hasattr(item, 'rindex'):\r\n            raise TypeError(\"Item in ``from list'' not a string\")\r\n        if item == '*':\r\n            if recursive:\r\n                continue\r\n            try:\r\n                all = mod.__all__\r\n            except AttributeError:\r\n                pass\r\n            else:\r\n                ret = ensure_fromlist(mod, all, buf, 1)\r\n                if not ret:\r\n                    return 0\r\n        elif not hasattr(mod, item):\r\n            import_submodule(mod, item, buf + '.' + item)","reference":"Handle 'from module import a, b, c' imports.","result":" is a list of strings .","score":[0,0.0]}
{"code":"def add_line(self, line):\r\n        \"\"\" function to<extra_id_0>\r\n        self.code.append(\" \" * self.indent_amount)\r\n        self.code.append(line)\r\n        self.code.append(\"\\n\")","reference":"Add a line of source to the code.\n\n        Don't include indentations or newlines.","result":"Add a line to the code .","score":[0.1724,0.3903]}
{"code":"def add_section(self):\r\n        \"\"\" function to<extra_id_0>\r\n        sect = CodeBuilder(self.indent_amount)\r\n        self.code.append(sect)\r\n        return sect","reference":"Add a section, a sub-CodeBuilder.","result":"Add a section .","score":[0.3519,0.2041]}
{"code":"def get_function(self, fn_name):\r\n        \"\"\" function to<extra_id_0>\r\n        assert self.indent_amount == 0\r\n        g = {}\r\n        code_text = str(self)\r\n        exec(code_text, g)\r\n        return g[fn_name]","reference":"Compile the code, and return the function `fn_name`.","result":"Be called .","score":[0,0.0]}
{"code":"def expr_code(self, expr):\r\n        \"\"\" function to<extra_id_0>\r\n        if \"|\" in expr:\r\n            pipes = expr.split(\"|\")\r\n            code = self.expr_code(pipes[0])\r\n            for func in pipes[1:]:\r\n                self.all_vars.add(func)\r\n                code = \"c_%s(%s)\" % (func, code)\r\n        elif \".\" in expr:\r\n            dots = expr.split(\".\")\r\n            code = self.expr_code(dots[0])\r\n            args = [repr(d) for d in dots[1:]]\r\n            code = \"dot(%s, %s)\" % (code, \", \".join(args))\r\n        else:\r\n            self.all_vars.add(expr)\r\n            code = \"c_%s\" % expr\r\n        return code","reference":"Generate a Python expression for `expr`.","result":"Generate code for expression .","score":[0.2589,0.2542]}
{"code":"def render(self, context=None):\r\n        \"\"\" function to<extra_id_0>\r\n        ctx = dict(self.context)\r\n        if context:\r\n            ctx.update(context)\r\n        return self.render_function(ctx, self.do_dots)","reference":"Render this template by applying it to `context`.\n\n        `context` is a dictionary of values to use in this rendering.","result":"And render the template .","score":[0.0146,0.0568]}
{"code":"def do_dots(self, value, *dots):\r\n        \"\"\" function to<extra_id_0>\r\n        for dot in dots:\r\n            try:\r\n                value = getattr(value, dot)\r\n            except AttributeError:\r\n                value = value[dot]\r\n            if hasattr(value, '__call__'):\r\n                value = value()\r\n        return value","reference":"Evaluate dotted expressions at runtime.","result":"Def do dots .","score":[0,0.102]}
{"code":"def render_template(tpl, context):\r\r\n    \"\"\" function to<extra_id_0>\r\n    '''\r\r\n    A shortcut function to render a partial template with context and return\r\r\n    the output.\r\r\n    '''\r\r\n\r\r\n    templates = [tpl] if type(tpl) != list else tpl\r\r\n    tpl_instance = None\r\r\n\r\r\n    for tpl in templates:\r\r\n        try:\r\r\n            tpl_instance = template.loader.get_template(tpl)\r\r\n            break\r\r\n        except template.TemplateDoesNotExist:\r\r\n            pass\r\r\n\r\r\n    if not tpl_instance:\r\r\n        raise Exception('Template does not exist: ' + templates[-1])\r\r\n\r\r\n    return tpl_instance.render(template.Context(context))","reference":"A shortcut function to render a partial template with context and return\r\n    the output.","result":"Render a partial template with context .","score":[0.2473,0.4501]}
{"code":"def _formatters_default(self):\r\n        \"\"\" function to<extra_id_0>\r\n        formatter_classes = [\r\n            PlainTextFormatter,\r\n            HTMLFormatter,\r\n            SVGFormatter,\r\n            PNGFormatter,\r\n            JPEGFormatter,\r\n            LatexFormatter,\r\n            JSONFormatter,\r\n            JavascriptFormatter\r\n        ]\r\n        d = {}\r\n        for cls in formatter_classes:\r\n            f = cls(config=self.config)\r\n            d[f.format_type] = f\r\n        return d","reference":"Activate the default formatters.","result":"Return default formatters .","score":[0.3195,0.125]}
{"code":"def for_type(self, typ, func):\r\n        \"\"\" function to<extra_id_0>\r\n        oldfunc = self.type_printers.get(typ, None)\r\n        if func is not None:\r\n            self.type_printers[typ] = func\r\n        return oldfunc","reference":"Add a format function for a given type.\n\n        Parameters\n        -----------\n        typ : class\n            The class of the object that will be formatted using `func`.\n        func : callable\n            The callable that will be called to compute the format data. The\n            call signature of this function is simple, it must take the\n            object to be formatted and return the raw data for the given\n            format. Subclasses may use a different call signature for the\n            `func` argument.","result":"Def register a type printer .","score":[0.0,0.0074]}
{"code":"def for_type_by_name(self, type_module, type_name, func):\r\n        \"\"\" function to<extra_id_0>\r\n        key = (type_module, type_name)\r\n        oldfunc = self.deferred_printers.get(key, None)\r\n        if func is not None:\r\n            self.deferred_printers[key] = func\r\n        return oldfunc","reference":"Add a format function for a type specified by the full dotted\n        module and name of the type, rather than the type of the object.\n\n        Parameters\n        ----------\n        type_module : str\n            The full dotted name of the module the type is defined in, like\n            ``numpy``.\n        type_name : str\n            The name of the type (the class name), like ``dtype``\n        func : callable\n            The callable that will be called to compute the format data. The\n            call signature of this function is simple, it must take the\n            object to be formatted and return the raw data for the given\n            format. Subclasses may use a different call signature for the\n            `func` argument.","result":"Register a printer for a type .","score":[0.0,0.0206]}
{"code":"def _float_precision_changed(self, name, old, new):\r\n        \"\"\" function to<extra_id_0>\r\n        if '%' in new:\r\n            fmt = new\r\n            try:\r\n                fmt%3.14159\r\n            except Exception:\r\n                raise ValueError(\"Precision must be int or format string, not %r\"%new)\r\n        elif new:\r\n            try:\r\n                i = int(new)\r\n                assert i >= 0\r\n            except ValueError:\r\n                raise ValueError(\"Precision must be int or format string, not %r\"%new)\r\n            except AssertionError:\r\n                raise ValueError(\"int precision must be non-negative, not %r\"%i)\r\n            fmt = '%%.%if'%i\r\n            if 'numpy' in sys.modules:\r\n                import numpy\r\n                numpy.set_printoptions(precision=i)\r\n        else:\r\n            fmt = '%r'\r\n            if 'numpy' in sys.modules:\r\n                import numpy\r\n                numpy.set_printoptions(precision=8)\r\n        self.float_format = fmt","reference":"float_precision changed, set float_format accordingly.\n\n        float_precision can be set by int or str.\n        This will set float_format, after interpreting input.\n        If numpy has been imported, numpy print precision will also be set.\n\n        integer `n` sets format to '%.nf', otherwise, format set directly.\n\n        An empty string returns to defaults (repr for float, 8 for numpy).\n\n        This parameter can be set via the '%precision' magic.","result":"Be called when float precision has changed .","score":[0.0002,0.0261]}
{"code":"def user_config_files():\r\n    \"\"\" function to<extra_id_0>\r\n    return filter(os.path.exists,\r\n                  map(os.path.expanduser, config_files))","reference":"Return path to any existing user config files","result":"Return user config files .","score":[0.2919,0.487]}
{"code":"def configure(self, argv=None, doc=None):\r\n        \"\"\" function to<extra_id_0>\r\n        env = self.env\r\n        if argv is None:\r\n            argv = sys.argv\r\n        cfg_files = getattr(self, 'files', [])\r\n        options, args = self._parseArgs(argv, cfg_files)\r\n        if getattr(options, 'files', []):\r\n            options, args = self._parseArgs(argv, options.files)\r\n        self.options = options\r\n        if args:\r\n            self.testNames = args\r\n        if options.testNames is not None:\r\n            self.testNames.extend(tolist(options.testNames))\r\n        if options.py3where is not None:\r\n            if sys.version_info >= (3,):\r\n                options.where = options.py3where\r\n        if not options.where:\r\n            options.where = env.get('NOSE_WHERE', None)\r\n        if not options.ignoreFiles:\r\n            options.ignoreFiles = env.get('NOSE_IGNORE_FILES', [])\r\n        if not options.include:\r\n            options.include = env.get('NOSE_INCLUDE', [])\r\n        if not options.exclude:\r\n            options.exclude = env.get('NOSE_EXCLUDE', [])\r\n        self.addPaths = options.addPaths\r\n        self.stopOnError = options.stopOnError\r\n        self.verbosity = options.verbosity\r\n        self.includeExe = options.includeExe\r\n        self.traverseNamespace = options.traverseNamespace\r\n        self.debug = options.debug\r\n        self.debugLog = options.debugLog\r\n        self.loggingConfig = options.loggingConfig\r\n        self.firstPackageWins = options.firstPackageWins\r\n        self.configureLogging()\r\n        if options.where is not None:\r\n            self.configureWhere(options.where)\r\n        if options.testMatch:\r\n            self.testMatch = re.compile(options.testMatch)\r\n        if options.ignoreFiles:\r\n            self.ignoreFiles = map(re.compile, tolist(options.ignoreFiles))\r\n            log.info(\"Ignoring files matching %s\", options.ignoreFiles)\r\n        else:\r\n            log.info(\"Ignoring files matching %s\", self.ignoreFilesDefaultStrings)\r\n        if options.include:\r\n            self.include = map(re.compile, tolist(options.include))\r\n            log.info(\"Including tests matching %s\", options.include)\r\n        if options.exclude:\r\n            self.exclude = map(re.compile, tolist(options.exclude))\r\n            log.info(\"Excluding tests matching %s\", options.exclude)\r\n        if not options.showPlugins:\r\n            self.plugins.configure(options, self)\r\n            self.plugins.begin()","reference":"Configure the nose running environment. Execute configure before\n        collecting tests with nose.TestCollector to enable output capture and\n        other features.","result":"Configure the test suite .","score":[0.0207,0.0852]}
{"code":"def configureLogging(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.loggingConfig:\r\n            from logging.config import fileConfig\r\n            fileConfig(self.loggingConfig)\r\n            return\r\n        format = logging.Formatter('%(name)s: %(levelname)s: %(message)s')\r\n        if self.debugLog:\r\n            handler = logging.FileHandler(self.debugLog)\r\n        else:\r\n            handler = logging.StreamHandler(self.logStream)\r\n        handler.setFormatter(format)\r\n        logger = logging.getLogger('nose')\r\n        logger.propagate = 0\r\n        if handler not in logger.handlers:\r\n            logger.addHandler(handler)\r\n        lvl = logging.WARNING\r\n        if self.verbosity >= 5:\r\n            lvl = 0\r\n        elif self.verbosity >= 4:\r\n            lvl = logging.DEBUG\r\n        elif self.verbosity >= 3:\r\n            lvl = logging.INFO\r\n        logger.setLevel(lvl)\r\n        if self.debug:\r\n            debug_loggers = [ name for name in self.debug.split(',')\r\n                              if name ]\r\n            for logger_name in debug_loggers:\r\n                l = logging.getLogger(logger_name)\r\n                l.setLevel(logging.DEBUG)\r\n                if not l.handlers and not logger_name.startswith('nose'):\r\n                    l.addHandler(handler)","reference":"Configure logging for nose, or optionally other packages. Any logger\n        name may be set with the debug option, and that logger will be set to\n        debug level and be assigned the same handler as the nose loggers, unless\n        it already has a handler.","result":"Configure logging .","score":[0.0,0.0481]}
{"code":"def configureWhere(self, where):\r\n        \"\"\" function to<extra_id_0>\r\n        from nose.importer import add_path\r\n        self.workingDir = None\r\n        where = tolist(where)\r\n        warned = False\r\n        for path in where:\r\n            if not self.workingDir:\r\n                abs_path = absdir(path)\r\n                if abs_path is None:\r\n                    raise ValueError(\"Working directory %s not found, or \"\r\n                                     \"not a directory\" % path)\r\n                log.info(\"Set working dir to %s\", abs_path)\r\n                self.workingDir = abs_path\r\n                if self.addPaths and \\\r\n                       os.path.exists(os.path.join(abs_path, '__init__.py')):\r\n                    log.info(\"Working directory %s is a package; \"\r\n                             \"adding to sys.path\" % abs_path)\r\n                    add_path(abs_path)\r\n                continue\r\n            if not warned:\r\n                warn(\"Use of multiple -w arguments is deprecated and \"\r\n                     \"support may be removed in a future release. You can \"\r\n                     \"get the same behavior by passing directories without \"\r\n                     \"the -w argument on the command line, or by using the \"\r\n                     \"--tests argument in a configuration file.\",\r\n                     DeprecationWarning)\r\n            self.testNames.append(path)","reference":"Configure the working directory or directories for the test run.","result":"Configure where test directories .","score":[0.1163,0.1579]}
{"code":"def page_dumb(strng, start=0, screen_lines=25):\r\n    \"\"\" function to<extra_id_0>\r\n    out_ln  = strng.splitlines()[start:]\r\n    screens = chop(out_ln,screen_lines-1)\r\n    if len(screens) == 1:\r\n        print >>io.stdout, os.linesep.join(screens[0])\r\n    else:\r\n        last_escape = \"\"\r\n        for scr in screens[0:-1]:\r\n            hunk = os.linesep.join(scr)\r\n            print >>io.stdout, last_escape + hunk\r\n            if not page_more():\r\n                return\r\n            esc_list = esc_re.findall(hunk)\r\n            if len(esc_list) > 0:\r\n                last_escape = esc_list[-1]\r\n        print >>io.stdout, last_escape + os.linesep.join(screens[-1])","reference":"Very dumb 'pager' in Python, for when nothing else works.\n\n    Only moves forward, same interface as page(), except for pager_cmd and\n    mode.","result":"Display a dumb page.","score":[0.0035,0.0248]}
{"code":"def page(strng, start=0, screen_lines=0, pager_cmd=None):\r\n    \"\"\" function to<extra_id_0>\r\n    start = max(0, start)\r\n    ip = ipapi.get()\r\n    if ip:\r\n        try:\r\n            ip.hooks.show_in_pager(strng)\r\n            return\r\n        except TryNext:\r\n            pass\r\n    TERM = os.environ.get('TERM','dumb')\r\n    if TERM in ['dumb','emacs'] and os.name != 'nt':\r\n        print strng\r\n        return\r\n    str_lines = strng.splitlines()[start:]\r\n    str_toprint = os.linesep.join(str_lines)\r\n    num_newlines = len(str_lines)\r\n    len_str = len(str_toprint)\r\n    numlines = max(num_newlines,int(len_str\/80)+1)\r\n    screen_lines_def = get_terminal_size()[1]\r\n    if screen_lines <= 0:\r\n        try:\r\n            screen_lines += _detect_screen_size(use_curses, screen_lines_def)\r\n        except (TypeError, UnsupportedOperation):\r\n            print >>io.stdout, str_toprint\r\n            return\r\n numlines <= screen_lines :\r\n  print >>io.stdout, str_toprint\r\n    else:\r\n        pager_cmd = get_pager_cmd(pager_cmd)\r\n        pager_cmd += ' ' + get_pager_start(pager_cmd,start)\r\n        if os.name == 'nt':\r\n            if pager_cmd.startswith('type'):\r\n                retval = 1\r\n            else:\r\n                tmpname = tempfile.mktemp('.txt')\r\n                tmpfile = open(tmpname,'wt')\r\n                tmpfile.write(strng)\r\n                tmpfile.close()\r\n                cmd = \"%s < %s\" % (pager_cmd,tmpname)\r\n                if os.system(cmd):\r\n                  retval = 1\r\n                else:\r\n                  retval = None\r\n                os.remove(tmpname)\r\n        else:\r\n            try:\r\n                retval = None\r\n                pager = os.popen(pager_cmd,'w')\r\n                pager.write(strng)\r\n                pager.close()\r\n                retval = pager.close()\r\n            except IOError,msg:\r\n                if msg.args == (32,'Broken pipe'):\r\n                    retval = None\r\n                else:\r\n                    retval = 1\r\n            except OSError:\r\n                retval = 1\r\n        if retval is not None:\r\n            page_dumb(strng,screen_lines=screen_lines)","reference":"Print a string, piping through a pager after a certain length.\n\n    The screen_lines parameter specifies the number of *usable* lines of your\n    terminal screen (total lines minus lines you need to reserve to show other\n    information).\n\n    If you set screen_lines to a number <=0, page() will try to auto-determine\n    your screen size and will only use up to (screen_size+screen_lines) for\n    printing, paging after that. That is, if you want auto-detection but need\n    to reserve the bottom 3 lines of the screen, use screen_lines = -3, and for\n    auto-detection without any lines reserved simply use screen_lines = 0.\n\n    If a string won't fit in the allowed lines, it is sent through the\n    specified pager command. If none given, look for PAGER in the environment,\n    and ultimately default to less.\n\n    If no system pager works, the string is sent through a 'dumb pager'\n    written in python, very simplistic.","result":"Page a string .","score":[1.728e-16,0.0114]}
{"code":"def page_file(fname, start=0, pager_cmd=None):\r\n    \"\"\" function to<extra_id_0>\r\n    pager_cmd = get_pager_cmd(pager_cmd)\r\n    pager_cmd += ' ' + get_pager_start(pager_cmd,start)\r\n    try:\r\n        if os.environ['TERM'] in ['emacs','dumb']:\r\n            raise EnvironmentError\r\n        system(pager_cmd + ' ' + fname)\r\n    except:\r\n        try:\r\n            if start > 0:\r\n                start -= 1\r\n            page(open(fname).read(),start)\r\n        except:\r\n            print 'Unable to show file',`fname`","reference":"Page a file, using an optional pager command and starting line.","result":"Page a file .","score":[0.0785,0.182]}
{"code":"def get_pager_cmd(pager_cmd=None):\r\n    \"\"\" function to<extra_id_0>\r\n    if os.name == 'posix':\r\n        default_pager_cmd = 'less -r'\r\n    elif os.name in ['nt','dos']:\r\n        default_pager_cmd = 'type'\r\n    if pager_cmd is None:\r\n        try:\r\n            pager_cmd = os.environ['PAGER']\r\n        except:\r\n            pager_cmd = default_pager_cmd\r\n    return pager_cmd","reference":"Return a pager command.\n\n    Makes some attempts at finding an OS-correct one.","result":"Get pager command .","score":[0.0432,0.0893]}
{"code":"def get_pager_start(pager, start):\r\n    \"\"\" function to<extra_id_0>\r\n    if pager in ['less','more']:\r\n        if start:\r\n            start_string = '+' + str(start)\r\n        else:\r\n            start_string = ''\r\n    else:\r\n        start_string = ''\r\n    return start_string","reference":"Return the string for paging files with an offset.\n\n    This is the '+N' argument which less and more (under Unix) accept.","result":"Get pager start .","score":[0,0.0]}
{"code":"def snip_print(str,width = 75,print_full = 0,header = ''):\r\n    \"\"\" function to<extra_id_0>\r\n    if print_full == 1:\r\n        page(header+str)\r\n        return 0\r\n    print header,\r\n    if len(str) < width:\r\n        print str\r\n        snip = 0\r\n    else:\r\n        whalf = int((width -5)\/2)\r\n        print str[:whalf] + ' <...> ' + str[-whalf:]\r\n        snip = 1\r\n    if snip and print_full == 2:\r\n        if raw_input(header+' Snipped. View (y\/n)? [N]').lower() == 'y':\r\n            page(str)\r\n    return snip","reference":"Print a string snipping the midsection to fit in width.\n\n    print_full: mode control:\n      - 0: only snip long strings\n      - 1: send to page() directly.\n      - 2: snip long strings and ask for full length viewing with page()\n    Return 1 if snipping was necessary, 0 otherwise.","result":"Print a string to the screen .","score":[0.0014,0.1059]}
{"code":"def print_basic_unicode(o, p, cycle):\r\n    \"\"\" function to<extra_id_0>\r\n    if cycle:\r\n        return p.text('Basic(...)')\r\n    out = pretty(o, use_unicode=True)\r\n    if '\\n' in out:\r\n        p.text(u'\\n')\r\n    p.text(out)","reference":"A function to pretty print sympy Basic objects.","result":"Def print basic object .","score":[0.1319,0.1299]}
{"code":"def print_png(o):\r\n    \"\"\" function to<extra_id_0>\r\n    s = latex(o, mode='inline')\r\n    s = s.replace('\\\\operatorname','')\r\n    s = s.replace('\\\\overline', '\\\\bar')\r\n    png = latex_to_png(s)\r\n    return png","reference":"A function to display sympy expression using inline style LaTeX in PNG.","result":"Print a graph representation to a PNG .","score":[0.0842,0.0862]}
{"code":"def print_display_png(o):\r\n    \"\"\" function to<extra_id_0>\r\n    s = latex(o, mode='plain')\r\n    s = s.strip('$')\r\n    png = latex_to_png('$$%s$$' % s, backend='dvipng')\r\n    return png","reference":"A function to display sympy expression using display style LaTeX in PNG.","result":"Print display to png .","score":[0.0705,0.0885]}
{"code":"def can_print_latex(o):\r\n    \"\"\" function to<extra_id_0>\r\n    import sympy\r\n    if isinstance(o, (list, tuple, set, frozenset)):\r\n        return all(can_print_latex(i) for i in o)\r\n    elif isinstance(o, dict):\r\n        return all((isinstance(i, basestring) or can_print_latex(i)) and can_print_latex(o[i]) for i in o)\r\n    elif isinstance(o,(sympy.Basic, sympy.matrices.Matrix, int, long, float)):\r\n        return True\r\n    return False","reference":"Return True if type o can be printed with LaTeX.\n\n    If o is a container type, this is True if and only if every element of o\n    can be printed with LaTeX.","result":"Check if an object can be printed in latex .","score":[0.0266,0.1497]}
{"code":"def print_latex(o):\r\n    \"\"\" function to<extra_id_0>\r\n    if can_print_latex(o):\r\n        s = latex(o, mode='plain')\r\n        s = s.replace('\\\\dag','\\\\dagger')\r\n        s = s.strip('$')\r\n        return '$$%s$$' % s\r\n    return None","reference":"A function to generate the latex representation of sympy\n    expressions.","result":"Print a latex representation of an object .","score":[0.2228,0.3827]}
{"code":"def add_options(self, parser, env=None):\r\n        \"\"\" function to<extra_id_0>\r\n        if env is None:\r\n            env = os.environ\r\n        try:\r\n            self.options(parser, env)\r\n            self.can_configure = True\r\n        except OptionConflictError, e:\r\n            warn(\"Plugin %s has conflicting option string: %s and will \"\r\n                 \"be disabled\" % (self, e), RuntimeWarning)\r\n            self.enabled = False\r\n            self.can_configure = False","reference":"Non-camel-case version of func name for backwards compatibility.\n\n        .. warning ::\n\n           DEPRECATED: Do not use this method,\n           use :meth:`options <nose.plugins.base.IPluginInterface.options>`\n           instead.","result":"Def add options to the parser.","score":[0,0.0]}
{"code":"def validate_string_list(lst):\r\n    \"\"\" function to<extra_id_0>\r\n    if not isinstance(lst, list):\r\n        raise ValueError('input %r must be a list' % lst)\r\n    for x in lst:\r\n        if not isinstance(x, basestring):\r\n            raise ValueError('element %r in list must be a string' % x)","reference":"Validate that the input is a list of strings.\n\n    Raises ValueError if not.","result":"Validate a list of strings .","score":[0.1331,0.3049]}
{"code":"def validate_string_dict(dct):\r\n    \"\"\" function to<extra_id_0>\r\n    for k,v in dct.iteritems():\r\n        if not isinstance(k, basestring):\r\n            raise ValueError('key %r in dict must be a string' % k)\r\n        if not isinstance(v, basestring):\r\n            raise ValueError('value %r in dict must be a string' % v)","reference":"Validate that the input is a dict with string keys and values.\n\n    Raises ValueError if not.","result":"Validate a string dict .","score":[0.0377,0.1342]}
{"code":"def _run_loop(self):\r\n        \"\"\" function to<extra_id_0>\r\n        while True:\r\n            try:\r\n                self.ioloop.start()\r\n            except ZMQError as e:\r\n                if e.errno == errno.EINTR:\r\n                    continue\r\n                else:\r\n                    raise\r\n            except Exception:\r\n                if self._exiting:\r\n                    break\r\n                else:\r\n                    raise\r\n            else:\r\n                break","reference":"Run my loop, ignoring EINTR events in the poller","result":"Run the main loop .","score":[0.1284,0.1163]}
{"code":"def _handle_recv(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        ident,smsg = self.session.feed_identities(msg)\r\n        self.call_handlers(self.session.unserialize(smsg))","reference":"callback for stream.on_recv\n        \n        unpacks message, and calls handlers with it.","result":"Handle a received message .","score":[0,0.0]}
{"code":"def execute(self, code, silent=False,\r\n                \"\"\" function to<extra_id_0>\r\n                user_variables=None, user_expressions=None, allow_stdin=None):\r\n        if user_variables is None:\r\n            user_variables = []\r\n        if user_expressions is None:\r\n            user_expressions = {}\r\n        if allow_stdin is None:\r\n            allow_stdin = self.allow_stdin\r\n                        if not isinstance(code, basestring):\r\n            raise ValueError('code %r must be a string' % code)\r\n        validate_string_list(user_variables)\r\n        validate_string_dict(user_expressions)\r\n        content = dict(code=code, silent=silent,\r\n                       user_variables=user_variables,\r\n                       user_expressions=user_expressions,\r\n                       allow_stdin=allow_stdin,\r\n                       )\r\n        msg = self.session.msg('execute_request', content)\r\n        self._queue_send(msg)\r\n        return msg['header']['msg_id']","reference":"Execute code in the kernel.\n\n        Parameters\n        ----------\n        code : str\n            A string of Python code.\n\n        silent : bool, optional (default False)\n            If set, the kernel will execute the code as quietly possible.\n\n        user_variables : list, optional\n            A list of variable names to pull from the user's namespace.  They\n            will come back as a dict with these names as keys and their\n            :func:`repr` as values.\n\n        user_expressions : dict, optional\n            A dict with string keys and  to pull from the user's\n            namespace.  They will come back as a dict with these names as keys\n            and their :func:`repr` as values.\n\n        allow_stdin : bool, optional\n            Flag for \n            A dict with string keys and  to pull from the user's\n            namespace.  They will come back as a dict with these names as keys\n            and their :func:`repr` as values.\n\n        Returns\n        -------\n        The msg_id of the message sent.","result":"Def execute code .","score":[6.511e-16,0.0079]}
{"code":"def complete(self, text, line, cursor_pos, block=None):\r\n        \"\"\" function to<extra_id_0>\r\n        content = dict(text=text, line=line, block=block, cursor_pos=cursor_pos)\r\n        msg = self.session.msg('complete_request', content)\r\n        self._queue_send(msg)\r\n        return msg['header']['msg_id']","reference":"Tab complete text in the kernel's namespace.\n\n        Parameters\n        ----------\n        text : str\n            The text to complete.\n        line : str\n            The full line of text that is the surrounding context for the\n            text to complete.\n        cursor_pos : int\n            The position of the cursor in the line where the completion was\n            requested.\n        block : str, optional\n            The full block of code in which the completion is being requested.\n\n        Returns\n        -------\n        The msg_id of the message sent.","result":"Complete text .","score":[0.0,0.0149]}
{"code":"def object_info(self, oname, detail_level=0):\r\n        \"\"\" function to<extra_id_0>\r\n        content = dict(oname=oname, detail_level=detail_level)\r\n        msg = self.session.msg('object_info_request', content)\r\n        self._queue_send(msg)\r\n        return msg['header']['msg_id']","reference":"Get metadata information about an object.\n\n        Parameters\n        ----------\n        oname : str\n            A string specifying the object name.\n        detail_level : int, optional\n            The level of detail for the introspection (0-2)\n\n        Returns\n        -------\n        The msg_id of the message sent.","result":"Get object info .","score":[0.0001,0.0297]}
{"code":"def history(self, raw=True, output=False, hist_access_type='range', **kwargs):\r\n        \"\"\" function to<extra_id_0>\r\n        content = dict(raw=raw, output=output, hist_access_type=hist_access_type,\r\n                                                                    **kwargs)\r\n        msg = self.session.msg('history_request', content)\r\n        self._queue_send(msg)\r\n        return msg['header']['msg_id']","reference":"Get entries from the history list.\n\n        Parameters\n        ----------\n        raw : bool\n            If True, return the raw input.\n        output : bool\n            If True, then return the output as well.\n        hist_access_type : str\n            'range' (fill in session, start and stop params), 'tail' (fill in n)\n             or 'search' (fill in pattern param).\n\n        session : int\n            For a range request, the session from which to get lines. Session\n            numbers are positive integers; negative ones count back from the\n            current session.\n        start : int\n            The first line number of a history range.\n        stop : int\n            The final (excluded) line number of a history range.\n\n        n : int\n            The number of lines of history to get for a tail request.\n\n        pattern : str\n            The glob-syntax pattern for a search request.\n\n        Returns\n        -------\n        The msg_id of the message sent.","result":"Request history of the current session .","score":[0.0,0.0311]}
{"code":"def shutdown(self, restart=False):\r\n        \"\"\" function to<extra_id_0>\r\n        msg = self.session.msg('shutdown_request', {'restart':restart})\r\n        self._queue_send(msg)\r\n        return msg['header']['msg_id']","reference":"Request an immediate kernel shutdown.\n\n        Upon receipt of the (empty) reply, client code can safely assume that\n        the kernel has shut down and it's safe to forcefully terminate it if\n        it's still alive.\n\n        The kernel will send the reply via a function registered with Python's\n        atexit module, ensuring it's truly done as the kernel is done with all\n        normal operation.","result":"Shutdown the server .","score":[0.0,0.0092]}
{"code":"def flush(self, timeout=1.0):\r\n        \"\"\" function to<extra_id_0>\r\n        stop_time = time.time() + timeout\r\n        for i in xrange(2):\r\n            self._flushed = False\r\n            self.ioloop.add_callback(self._flush)\r\n            while not self._flushed and time.time() < stop_time:\r\n                time.sleep(0.01)","reference":"Immediately processes all pending messages on the SUB channel.\n\n        Callers should use this method to ensure that :method:`call_handlers`\n        has been called for all messages that have been received on the\n        0MQ SUB socket of this channel.\n\n        This method is thread safe.\n\n        Parameters\n        ----------\n        timeout : float, optional\n            The maximum amount of time to spend flushing, in seconds. The\n            default is one second.","result":"Flush the queue .","score":[0.0,0.0089]}
{"code":"def input(self, string):\r\n        \"\"\" function to<extra_id_0>\r\n        content = dict(value=string)\r\n        msg = self.session.msg('input_reply', content)\r\n        self._queue_send(msg)","reference":"Send a string of raw input to the kernel.","result":"Input a string .","score":[0.1294,0.3007]}
{"code":"def start_channels(self, shell=True, sub=True, stdin=True, hb=True):\r\n        \"\"\" function to<extra_id_0>\r\n        if shell:\r\n            self.shell_channel.start()\r\n        if sub:\r\n            self.sub_channel.start()\r\n        if stdin:\r\n            self.stdin_channel.start()\r\n            self.shell_channel.allow_stdin = True\r\n        else:\r\n            self.shell_channel.allow_stdin = False\r\n        if hb:\r\n            self.hb_channel.start()","reference":"Starts the channels for this kernel.\n\n        This will create the channels if they do not exist and then start\n        them. If port numbers of 0 are being used (random ports) then you\n        must first call :method:`start_kernel`. If the channels have been\n        stopped and you call this, :class:`RuntimeError` will be raised.","result":"Start all channels .","score":[0.0,0.022]}
{"code":"def stop_channels(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.shell_channel.is_alive():\r\n            self.shell_channel.stop()\r\n        if self.sub_channel.is_alive():\r\n            self.sub_channel.stop()\r\n        if self.stdin_channel.is_alive():\r\n            self.stdin_channel.stop()\r\n        if self.hb_channel.is_alive():\r\n            self.hb_channel.stop()","reference":"Stops all the running channels for this kernel.","result":"Stop all channels .","score":[0.1398,0.3363]}
{"code":"def channels_running(self):\r\n        \"\"\" function to<extra_id_0>\r\n        return (self.shell_channel.is_alive() or self.sub_channel.is_alive() or\r\n                self.stdin_channel.is_alive() or self.hb_channel.is_alive())","reference":"Are any of the channels created and running?","result":"Check if channels are running .","score":[0.1383,0.1282]}
{"code":"def load_connection_file(self):\r\n        \"\"\" function to<extra_id_0>\r\n        with open(self.connection_file) as f:\r\n            cfg = json.loads(f.read())\r\n                self.ip = cfg['ip']\r\n        self.shell_port = cfg['shell_port']\r\n        self.stdin_port = cfg['stdin_port']\r\n        self.iopub_port = cfg['iopub_port']\r\n        self.hb_port = cfg['hb_port']\r\n        self.session.key = str_to_bytes(cfg['key'])","reference":"load connection info from JSON dict in self.connection_file","result":"Load the connection file .","score":[0.1319,0.1299]}
{"code":"def write_connection_file(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._connection_file_written:\r\n            return\r\n        self.connection_file,cfg = write_connection_file(self.connection_file,\r\n            ip=self.ip, key=self.session.key,\r\n            stdin_port=self.stdin_port, iopub_port=self.iopub_port,\r\n            shell_port=self.shell_port, hb_port=self.hb_port)\r\n        self.shell_port = cfg['shell_port']\r\n        self.stdin_port = cfg['stdin_port']\r\n        self.iopub_port = cfg['iopub_port']\r\n        self.hb_port = cfg['hb_port']\r\n                self._connection_file_written = True","reference":"write connection info to JSON dict in self.connection_file","result":"Def write the connection file .","score":[0.1645,0.1282]}
{"code":"def start_kernel(self, **kw):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.ip not in LOCAL_IPS:\r\n            raise RuntimeError(\"Can only launch a kernel on a local interface. \"\r\n                               \"Make sure that the '*_address' attributes are \"\r\n                               \"configured properly. \"\r\n                               \"Currently valid addresses are: %s\"%LOCAL_IPS\r\n                               )\r\n                self.write_connection_file()\r\n        self._launch_args = kw.copy()\r\n        launch_kernel = kw.pop('launcher', None)\r\n        if launch_kernel is None:\r\n            from ipkernel import launch_kernel\r\n        self.kernel = launch_kernel(fname=self.connection_file, **kw)","reference":"Starts a kernel process and configures the manager to use it.\n\n        If random ports (port=0) are being used, this method must be called\n        before the channels are created.\n\n        Parameters:\n        -----------\n        launcher : callable, optional (default None)\n             A custom function for launching the kernel process (generally a\n             wrapper around ``entry_point.base_launch_kernel``). In most cases,\n             it should not be necessary to use this parameter.\n\n        **kw : optional\n             See respective options for IPython and Python kernels.","result":"Start the kernel .","score":[0.0,0.0392]}
{"code":"def shutdown_kernel(self, restart=False):\r\n        \"\"\" function to<extra_id_0>\r\n        if sys.platform == 'win32':\r\n            self.kill_kernel()\r\n            return\r\n        if self._hb_channel is not None:\r\n            self._hb_channel.pause()\r\n        self.shell_channel.shutdown(restart=restart)\r\n        for i in range(10):\r\n            if self.is_alive:\r\n                time.sleep(0.1)\r\n            else:\r\n                break\r\n        else:\r\n            if self.has_kernel:\r\n                self.kill_kernel()\r\n        if not restart and self._connection_file_written:\r\n            self._connection_file_written = False\r\n            try:\r\n                os.remove(self.connection_file)\r\n            except IOError:\r\n                pass","reference":"Attempts to the stop the kernel process cleanly. If the kernel\n        cannot be stopped, it is killed, if possible.","result":"Shutdown the kernel .","score":[0.0106,0.1071]}
{"code":"def restart_kernel(self, now=False, **kw):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._launch_args is None:\r\n            raise RuntimeError(\"Cannot restart the kernel. \"\r\n                               \"No previous call to 'start_kernel'.\")\r\n        else:\r\n            if self.has_kernel:\r\n                if now:\r\n                    self.kill_kernel()\r\n                else:\r\n                    self.shutdown_kernel(restart=True)\r\n            self._launch_args.update(kw)\r\n            self.start_kernel(**self._launch_args)\r\n            if sys.platform == 'win32':\r\n                time.sleep(0.2)","reference":"Restarts a kernel with the arguments that were used to launch it.\n\n        If the old kernel was launched with random ports, the same ports will be\n        used for the new kernel.\n\n        Parameters\n        ----------\n        now : bool, optional\n            If True, the kernel is forcefully restarted *immediately*, without\n            having a chance to do any cleanup action.  Otherwise the kernel is\n            given 1s to clean up before a forceful restart is issued.\n\n            In all cases the kernel is restarted, the only difference is whether\n            it is given a chance to perform a clean shutdown or not.\n\n        **kw : optional\n            Any options specified here will replace those used to launch the\n            kernel.","result":"Restart the kernel .","score":[0.0,0.0154]}
{"code":"def kill_kernel(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.has_kernel:\r\n            if self._hb_channel is not None:\r\n                self._hb_channel.pause()\r\n            try:\r\n                self.kernel.kill()\r\n            except OSError, e:\r\n                if sys.platform == 'win32':\r\n                    if e.winerror != 5:\r\n                        raise\r\n                else:\r\n                    from errno import ESRCH\r\n                    if e.errno != ESRCH:\r\n                        raise\r\n            self.kernel = None\r\n        else:\r\n            raise RuntimeError(\"Cannot kill kernel. No kernel is running!\")","reference":"Kill the running kernel.","result":"Kill the kernel .","score":[0.4518,0.4688]}
{"code":"def interrupt_kernel(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.has_kernel:\r\n            if sys.platform == 'win32':\r\n                from parentpoller import ParentPollerWindows as Poller\r\n                Poller.send_interrupt(self.kernel.win32_interrupt_event)\r\n            else:\r\n                self.kernel.send_signal(signal.SIGINT)\r\n        else:\r\n            raise RuntimeError(\"Cannot interrupt kernel. No kernel is running!\")","reference":"Interrupts the kernel. Unlike ``signal_kernel``, this operation is\n        well supported on all platforms.","result":"Interrupt the kernel .","score":[0.0337,0.155]}
{"code":"def signal_kernel(self, signum):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.has_kernel:\r\n            self.kernel.send_signal(signum)\r\n        else:\r\n            raise RuntimeError(\"Cannot signal kernel. No kernel is running!\")","reference":"Sends a signal to the kernel. Note that since only SIGTERM is\n        supported on Windows, this function is only useful on Unix systems.","result":"Signal kernel .","score":[0,0.0238]}
{"code":"def is_alive(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.has_kernel:\r\n            if self.kernel.poll() is None:\r\n                return True\r\n            else:\r\n                return False\r\n        elif self._hb_channel is not None:\r\n            return self._hb_channel.is_beating()\r\n        else:\r\n            return True","reference":"Is the kernel process still running?","result":" is alive .","score":[0,0.0877]}
{"code":"def shell_channel(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._shell_channel is None:\r\n            self._shell_channel = self.shell_channel_class(self.context,\r\n                                                         self.session,\r\n                                                         (self.ip, self.shell_port))\r\n        return self._shell_channel","reference":"Get the REQ socket channel object to make requests of the kernel.","result":"Return the shell channel .","score":[0.0705,0.0885]}
{"code":"def sub_channel(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._sub_channel is None:\r\n            self._sub_channel = self.sub_channel_class(self.context,\r\n                                                       self.session,\r\n                                                       (self.ip, self.iopub_port))\r\n        return self._sub_channel","reference":"Get the SUB socket channel object.","result":"Return a sub channel .","score":[0.1967,0.1695]}
{"code":"def hb_channel(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._hb_channel is None:\r\n            self._hb_channel = self.hb_channel_class(self.context,\r\n                                                       self.session,\r\n                                                       (self.ip, self.hb_port))\r\n        return self._hb_channel","reference":"Get the heartbeat socket channel object to check that the\n        kernel is alive.","result":"Return the hb channel .","score":[0.0577,0.082]}
{"code":"def bind_kernel(**kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    from IPython.zmq.ipkernel import IPKernelApp\r\n    from IPython.parallel.apps.ipengineapp import IPEngineApp\r\n        if IPKernelApp.initialized() and isinstance(IPKernelApp._instance, IPKernelApp):\r\n        return\r\n        if IPEngineApp.initialized():\r\n        try:\r\n            app = IPEngineApp.instance()\r\n        except MultipleInstanceError:\r\n            pass\r\n        else:\r\n            return app.bind_kernel(**kwargs)\r\n        raise RuntimeError(\"bind_kernel be called from an IPEngineApp instance\")","reference":"Bind an Engine's Kernel to be used as a full IPython kernel.\n    \n    This allows a running Engine to be used simultaneously as a full IPython kernel\n    with the QtConsole or other frontends.\n    \n    This function returns immediately.","result":"Bind kernel from.","score":[0.0,0.0306]}
{"code":"def debug(self, level, message):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._debug >= level:\r\n            print(message, file=sys.stderr)","reference":"Emit a debugging message depending on the debugging level.\n\n        :param level: The debugging level.\n        :param message: The message to emit.","result":"Debug messages .","score":[0,0.0546]}
{"code":"def _get_extension_classes(cls):\r\n        \"\"\" function to<extra_id_0>\r\n        if cls._extension_classes is None:\r\n            exts = {}\r\n            for ext in entry.points[NAMESPACE_EXTENSIONS]:\r\n                exts.setdefault(ext.priority, [])\r\n                exts[ext.priority].append(ext)\r\n            cls._extension_classes = list(utils.iter_prio_dict(exts))\r\n        return cls._extension_classes","reference":"Retrieve the extension classes in priority order.\n\n        :returns: A list of extension classes, in proper priority\n                  order.","result":"Def get extension classes .","score":[0.0308,0.0633]}
{"code":"def pre_step(self, ctxt, step, idx):\r\n        \"\"\" function to<extra_id_0>\r\n        debugger = ExtensionDebugger('pre_step')\r\n        for ext in self.exts:\r\n            with debugger(ext):\r\n                if ext.pre_step(ctxt, step, idx):\r\n                    debugger.debug(3, 'Skipping step %d' % idx)\r\n                    return True\r\n        return False","reference":"Called prior to executing a step.\n\n        :param ctxt: An instance of ``timid.context.Context``.\n        :param step: An instance of ``timid.steps.Step`` describing\n                     the step to be executed.\n        :param idx: The index of the step in the list of steps.\n\n        :returns: A ``True`` value if the step is to be skipped,\n                  ``False`` otherwise.","result":"If not call extensions before step .","score":[0.0004,0.0335]}
{"code":"def post_step(self, ctxt, step, idx, result):\r\n        \"\"\" function to<extra_id_0>\r\n        debugger = ExtensionDebugger('post_step')\r\n        for ext in self.exts:\r\n            with debugger(ext):\r\n                ext.post_step(ctxt, step, idx, result)\r\n        return result","reference":"Called after executing a step.\n\n        :param ctxt: An instance of ``timid.context.Context``.\n        :param step: An instance of ``timid.steps.Step`` describing\n                     the step that was executed.\n        :param idx: The index of the step in the list of steps.\n        :param result: An instance of ``timid.steps.StepResult``\n                       describing the result of executing the step.\n                       May be altered by the extension, e.g., to set\n                       the ``ignore`` attribute.\n\n        :returns: The ``result`` parameter, for convenience.","result":"Call after each extension step .","score":[0.0,0.0426]}
{"code":"def finalize(self, ctxt, result):\r\n        \"\"\" function to<extra_id_0>\r\n        debugger = ExtensionDebugger('finalize')\r\n        for ext in self.exts:\r\n            with debugger(ext):\r\n                result = ext.finalize(ctxt, result)\r\n        return result","reference":"Called at the end of processing.  This call allows extensions to\n        emit any additional data, such as timing information, prior to\n        ``timid``'s exit.  Extensions may also alter the return value.\n\n        :param ctxt: An instance of ``timid.context.Context``.\n        :param result: The return value of the basic ``timid`` call,\n                       or an ``Exception`` instance if an exception\n                       was raised.  Without the extension, this would\n                       be passed directly to ``sys.exit()``.\n\n        :returns: The final result.","result":"Call after all extensions are finalized.","score":[0.0,0.0239]}
{"code":"def walk_egg(egg_dir):\r\n    \"\"\" function to<extra_id_0>\r\n    walker = os.walk(egg_dir)\r\n    base,dirs,files = walker.next()\r\n    if 'EGG-INFO' in dirs:\r\n        dirs.remove('EGG-INFO')\r\n    yield base,dirs,files\r\n    for bdf in walker:\r\n        yield bdf","reference":"Walk an unpacked egg's contents, skipping the metadata directory","result":"Walk an egg directory .","score":[0.169,0.2972]}
{"code":"def scan_module(egg_dir, base, name, stubs):\r\n    \"\"\" function to<extra_id_0>\r\n    filename = os.path.join(base,name)\r\n    if filename[:-1] in stubs:\r\n        return True\r\n    pkg = base[len(egg_dir)+1:].replace(os.sep,'.')\r\n    module = pkg+(pkg and '.' or '')+os.path.splitext(name)[0]\r\n    if sys.version_info < (3, 3):\r\n        skip = 8\r\n    else:\r\n        skip = 12\r\n    f = open(filename,'rb'); f.read(skip)\r\n    code = marshal.load(f); f.close()\r\n    safe = True\r\n    symbols = dict.fromkeys(iter_symbols(code))\r\n    for bad in ['__file__', '__path__']:\r\n        if bad in symbols:\r\n            log.warn(\"%s: module references %s\", module, bad)\r\n            safe = False\r\n    if 'inspect' in symbols:\r\n        for bad in [\r\n            'getsource', 'getabsfile', 'getsourcefile', 'getfile'\r\n            'getsourcelines', 'findsource', 'getcomments', 'getframeinfo',\r\n            'getinnerframes', 'getouterframes', 'stack', 'trace'\r\n        ]:\r\n            if bad in symbols:\r\n                log.warn(\"%s: module MAY be using inspect.%s\", module, bad)\r\n                safe = False\r\n    if '__name__' in symbols and '__main__' in symbols and '.' not in module:\r\n        if sys.version[:3]==\"2.4\":\r\n            log.warn(\"%s: top-level module may be 'python -m' script\", module)\r\n            safe = False\r\n    return safe","reference":"Check whether module possibly uses unsafe-for-zipfile stuff","result":" is safe .","score":[0,0.0]}
{"code":"def launch_new_instance():\r\n    \"\"\" function to<extra_id_0>\r\n    if sys.platform == 'win32':\r\n                import multiprocessing\r\n        p = multiprocessing.current_process()\r\n        if p.name != 'MainProcess':\r\n            return\r\n    app = IPControllerApp.instance()\r\n    app.initialize()\r\n    app.start()","reference":"Create and run the IPython controller","result":"Launch a new instance .","score":[0,0.0]}
{"code":"def save_connection_dict(self, fname, cdict):\r\n        \"\"\" function to<extra_id_0>\r\n        c = self.config\r\n        url = cdict['url']\r\n        location = cdict['location']\r\n        if not location:\r\n            try:\r\n                proto,ip,port = split_url(url)\r\n            except AssertionError:\r\n                pass\r\n            else:\r\n                try:\r\n                    location = socket.gethostbyname_ex(socket.gethostname())[2][-1]\r\n                except (socket.gaierror, IndexError):\r\n                    self.log.warn(\"Could not identify this machine's IP, assuming 127.0.0.1.\"\r\n                    \" You may need to specify '--location=<external_ip_address>' to help\"\r\n                    \" IPython decide when to connect via loopback.\")\r\n                    location = '127.0.0.1'\r\n            cdict['location'] = location\r\n        fname = os.path.join(self.profile_dir.security_dir, fname)\r\n        self.log.info(\"writing connection info to %s\", fname)\r\n        with open(fname, 'w') as f:\r\n            f.write(json.dumps(cdict, indent=2))\r\n        os.chmod(fname, stat.S_IRUSR|stat.S_IWUSR)","reference":"save a connection dict to json file.","result":"Save connection info to file .","score":[0.1943,0.2174]}
{"code":"def load_config_from_json(self):\r\n        \"\"\" function to<extra_id_0>\r\n        c = self.config\r\n        self.log.debug(\"loading config from JSON\")\r\n        fname = os.path.join(self.profile_dir.security_dir, self.engine_json_file)\r\n        self.log.info(\"loading connection info from %s\", fname)\r\n        with open(fname) as f:\r\n            cfg = json.loads(f.read())\r\n        key = cfg['exec_key']\r\n        c.Session.key = key.encode('ascii')\r\n        xport,addr = cfg['url'].split(':\/\/')\r\n        c.HubFactory.engine_transport = xport\r\n        ip,ports = addr.split(':')\r\n        c.HubFactory.engine_ip = ip\r\n        c.HubFactory.regport = int(ports)\r\n        self.location = cfg['location']\r\n        if not self.engine_ssh_server:\r\n            self.engine_ssh_server = cfg['ssh']\r\n        fname = os.path.join(self.profile_dir.security_dir, self.client_json_file)\r\n        self.log.info(\"loading connection info from %s\", fname)\r\n        with open(fname) as f:\r\n            cfg = json.loads(f.read())\r\n        assert key == cfg['exec_key'], \"exec_key mismatch between engine and client keys\"\r\n        xport,addr = cfg['url'].split(':\/\/')\r\n        c.HubFactory.client_transport = xport\r\n        ip,ports = addr.split(':')\r\n        c.HubFactory.client_ip = ip\r\n        if not self.ssh_server:\r\n            self.ssh_server = cfg['ssh']\r\n        assert int(ports) == c.HubFactory.regport, \"regport mismatch\"","reference":"load config from existing json connector files.","result":"Load config from JSON file .","score":[0.2311,0.5435]}
{"code":"def load_secondary_config(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.reuse_files:\r\n            try:\r\n                self.load_config_from_json()\r\n            except (AssertionError,IOError) as e:\r\n                self.log.error(\"Could not load config from JSON: %s\" % e)\r\n            else:\r\n                self.write_connection_files = False\r\n                        default_secure(self.config)\r\n        self.log.debug(\"Config changed\")\r\n        self.log.debug(repr(self.config))","reference":"secondary config, loading from JSON and setting defaults","result":"Def load config from JSON .","score":[0.1956,0.3276]}
{"code":"def parallel_execute(self, cell, block=None, groupby='type', save_name=None):\r\n        \"\"\" function to<extra_id_0>\r\n        block = self.view.block if block is None else block\r\n                base = \"Parallel\" if block else \"Async parallel\"\r\n                targets = self.view.targets\r\n        if isinstance(targets, list) and len(targets) > 10:\r\n            str_targets = str(targets[:4])[:-1] + ', ..., ' + str(targets[-4:])[1:]\r\n        else:\r\n            str_targets = str(targets)\r\n        if self.verbose:\r\n            print base + \" execution on engine(s): %s\" % str_targets\r\n                result = self.view.execute(cell, silent=False, block=False)\r\n        self.last_result = result\r\n                if save_name:\r\n            self.shell.user_ns[save_name] = result\r\n                if block:\r\n            result.get()\r\n            result.display_outputs(groupby)\r\n        else:\r\n            return result","reference":"implementation used by %px and %%parallel","result":"Def execute parallel engine .","score":[0,0.0]}
{"code":"def _enable_autopx(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self._original_run_cell = self.shell.run_cell\r\n        self.shell.run_cell = self.pxrun_cell\r\n        self._autopx = True\r\n        print \"%autopx enabled\"","reference":"Enable %autopx mode by saving the original run_cell and installing\n        pxrun_cell.","result":"Enable autopx .","score":[0.0284,0.049]}
{"code":"def _disable_autopx(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._autopx:\r\n            self.shell.run_cell = self._original_run_cell\r\n            self._autopx = False\r\n            print \"%autopx disabled\"","reference":"Disable %autopx by restoring the original InteractiveShell.run_cell.","result":"Def disable autopx .","score":[0,0.0746]}
{"code":"def pxrun_cell(self, raw_cell, store_history=False, silent=False):\r\n        \"\"\" function to<extra_id_0>\r\n        if (not raw_cell) or raw_cell.isspace():\r\n            return\r\n        ipself = self.shell\r\n        with ipself.builtin_trap:\r\n            cell = ipself.prefilter_manager.prefilter_lines(raw_cell)\r\n            if store_history:\r\n                ipself.history_manager.store_inputs(ipself.execution_count,\r\n                                                  cell, raw_cell)\r\n            cell_name = ipself.compile.cache(cell, ipself.execution_count)\r\n            try:\r\n                ast.parse(cell, filename=cell_name)\r\n            except (OverflowError, SyntaxError, ValueError, TypeError,\r\n                    MemoryError):\r\n                ipself.showsyntaxerror()\r\n                ipself.execution_count += 1\r\n                return None\r\n            except NameError:\r\n                pass\r\n        if store_history:\r\n            ipself.history_manager.store_output(ipself.execution_count)\r\n            ipself.execution_count += 1\r\n        if re.search(r'get_ipython\\(\\)\\.magic\\(u?[\"\\']%?autopx', cell):\r\n            self._disable_autopx()\r\n            return False\r\n        else:\r\n            try:\r\n                result = self.view.execute(cell, silent=False, block=False)\r\n            except:\r\n                ipself.showtraceback()\r\n                return True\r\n            else:\r\n                if self.view.block:\r\n                    try:\r\n                        result.get()\r\n                    except:\r\n                        self.shell.showtraceback()\r\n                        return True\r\n                    else:\r\n                        with ipself.builtin_trap:\r\n                            result.display_outputs()\r\n                return False","reference":"drop-in replacement for InteractiveShell.run_cell.\n\n        This executes code remotely, instead of in the local namespace.\n\n        See InteractiveShell.run_cell for details.","result":"Run a cell .","score":[0,0.0]}
{"code":"def run_heartbeat(message):\r\n    \"\"\" function to<extra_id_0>\r\n    then = arrow.get(message['time'])\r\n    now = arrow.get()\r\n    if (now - then) > timezone.timedelta(seconds=(TICK_FREQ+1)):\r\n        pass\r\n    else:\r\n        Task.run_tasks()","reference":"Internal ``CLOCK_CHANNEL`` consumer to process task runs","result":"Run the heartbeat .","score":[0,0.0746]}
{"code":"def run_task(message):\r\n    \"\"\" function to<extra_id_0>\r\n    task = Task.objects.get(pk=message['id'])\r\n    if task.allow_overlap:\r\n        task.run(message)\r\n    else:\r\n        if not task.running:\r\n            task.running = True\r\n            task.save()\r\n            try:\r\n                task.run(message)\r\n            finally:\r\n                task.running = False\r\n                task.save()","reference":"Internal ``RUN_TASK`` consumer to run the task's callable","result":"Def run a task .","score":[0.1319,0.0649]}
{"code":"def remove_task(message):\r\n    \"\"\" function to<extra_id_0>\r\n    task = Task.objects.get(pk=message['id'])\r\n    task.delete()","reference":"Internal ``KILL_TASK`` consumer to remove retired tasks","result":"Remove a task .","score":[0,0.1493]}
{"code":"def patch_protocol_for_agent(protocol):\r\n    \"\"\" function to<extra_id_0>\r\n    old_makeConnection = protocol.makeConnection\r\n    old_connectionLost = protocol.connectionLost\r\n    def new_makeConnection(transport):\r\n        patch_transport_fake_push_producer(transport)\r\n        patch_transport_abortConnection(transport, protocol)\r\n        return old_makeConnection(transport)\r\n    def new_connectionLost(reason):\r\n        if protocol._fake_connection_aborted and reason.check(ConnectionDone):\r\n            reason = Failure(ConnectionAborted())\r\n        return old_connectionLost(reason)\r\n    protocol.makeConnection = new_makeConnection\r\n    protocol.connectionLost = new_connectionLost\r\n    protocol._fake_connection_aborted = False","reference":"Patch the protocol's makeConnection and connectionLost methods to make the\n    protocol and its transport behave more like what `Agent` expects.\n\n    While `Agent` is the driving force behind this, other clients and servers\n    will no doubt have similar requirements.","result":"Patch protocol for agent .","score":[0.0004,0.0288]}
{"code":"def patch_if_missing(obj, name, method):\r\n    \"\"\" function to<extra_id_0>\r\n    setattr(obj, name, getattr(obj, name, method))","reference":"Patch a method onto an object if it isn't already there.","result":" is missing .","score":[0,0.0]}
{"code":"def accept_connection(self):\r\n        \"\"\" function to<extra_id_0>\r\n        assert self.pending, \"Connection is not pending.\"\r\n        self.server_protocol = self.server.server_factory.buildProtocol(None)\r\n        self._accept_d.callback(\r\n            FakeServerProtocolWrapper(self, self.server_protocol))\r\n        return self.await_connected()","reference":"Accept a pending connection.","result":"Accept a connection .","score":[0.4518,0.4688]}
{"code":"def reject_connection(self, reason=None):\r\n        \"\"\" function to<extra_id_0>\r\n        assert self.pending, \"Connection is not pending.\"\r\n        if reason is None:\r\n            reason = ConnectionRefusedError()\r\n        self._accept_d.errback(reason)","reference":"Reject a pending connection.","result":"Reject a connection .","score":[0.4518,0.4688]}
{"code":"def get_agent(self, reactor=None, contextFactory=None):\r\n        \"\"\" function to<extra_id_0>\r\n        return ProxyAgentWithContext(\r\n            self.endpoint, reactor=reactor, contextFactory=contextFactory)","reference":"Returns an IAgent that makes requests to this fake server.","result":"Get the agent .","score":[0,0.0532]}
{"code":"def form_valid(self, form):\r\n        \"\"\" function to<extra_id_0>\r\n        self.object = form.save(commit=False)\r\n        response = self.pre_save(self.object)\r\n        if response:\r\n            return response\r\n        self.object.save()\r\n        form.save_m2m()\r\n        self.post_save(self.object)\r\n        return HttpResponseRedirect(self.get_success_url())","reference":"Calls pre and post save hooks.","result":"Handle form valid .","score":[0,0.0]}
{"code":"def delete(self, request, *args, **kwargs):\r\n        \"\"\" function to<extra_id_0>\r\n        self.object = self.get_object()\r\n        success_url = self.get_success_url()\r\n        self.pre_delete(self.object)\r\n        self.object.delete()\r\n        self.post_delete(self.object)\r\n        return HttpResponseRedirect(success_url)","reference":"Calls pre and post delete hooks for DelteViews.","result":"Return delete an object .","score":[0.1319,0.0649]}
{"code":"def pre_save(self, instance):\r\n        \"\"\" function to<extra_id_0>\r\n        super(UserViewMixin, self).pre_save(instance)\r\n        if  self.request.user.is_authenticated():\r\n            for field in self.user_field:\r\n                setattr(instance, field, self.request.user)","reference":"Use SaveHookMixin pre_save to set the user.","result":"Set user fields .","score":[0,0.0746]}
{"code":"def report(self, morfs, outfile=None):\r\n        \"\"\" function to<extra_id_0>\r\n        self.find_code_units(morfs)\r\n        max_name = max([len(cu.name) for cu in self.code_units] + [5])\r\n        fmt_name = \"%%- %ds  \" % max_name\r\n        fmt_err = \"%s   %s: %s\\n\"\r\n        header = (fmt_name % \"Name\") + \" Stmts   Miss\"\r\n        fmt_coverage = fmt_name + \"%6d %6d\"\r\n        if self.branches:\r\n            header += \" Branch BrMiss\"\r\n            fmt_coverage += \" %6d %6d\"\r\n        width100 = Numbers.pc_str_width()\r\n        header += \"%*s\" % (width100+4, \"Cover\")\r\n        fmt_coverage += \"%%%ds%%%%\" % (width100+3,)\r\n        if self.config.show_missing:\r\n            header += \"   Missing\"\r\n            fmt_coverage += \"   %s\"\r\n        rule = \"-\" * len(header) + \"\\n\"\r\n        header += \"\\n\"\r\n        fmt_coverage += \"\\n\"\r\n        if not outfile:\r\n            outfile = sys.stdout\r\n        outfile.write(header)\r\n        outfile.write(rule)\r\n        total = Numbers()\r\n        for cu in self.code_units:\r\n            try:\r\n                analysis = self.coverage._analyze(cu)\r\n                nums = analysis.numbers\r\n                args = (cu.name, nums.n_statements, nums.n_missing)\r\n                if self.branches:\r\n                    args += (nums.n_branches, nums.n_missing_branches)\r\n                args += (nums.pc_covered_str,)\r\n                if self.config.show_missing:\r\n                    args += (analysis.missing_formatted(),)\r\n                outfile.write(fmt_coverage % args)\r\n                total += nums\r\n            except KeyboardInterrupt:\r\n                raise\r\n            except:\r\n                report_it = not self.config.ignore_errors\r\n                if report_it:\r\n                    typ, msg = sys.exc_info()[:2]\r\n                    if typ is NotPython and not cu.should_be_python():\r\n                        report_it = False\r\n                if report_it:\r\n                    outfile.write(fmt_err % (cu.name, typ.__name__, msg))\r\n        if total.n_files > 1:\r\n            outfile.write(rule)\r\n            args = (\"TOTAL\", total.n_statements, total.n_missing)\r\n            if self.branches:\r\n                args += (total.n_branches, total.n_missing_branches)\r\n            args += (total.pc_covered_str,)\r\n            if self.config.show_missing:\r\n                args += (\"\",)\r\n            outfile.write(fmt_coverage % args)\r\n        return total.pc_covered","reference":"Writes a report summarizing coverage statistics per module.\n\n        `outfile` is a file object to write the summary to.","result":"Report code coverage .","score":[0.0096,0.0602]}
{"code":"def check(self, check_all=False):\r\n        \"\"\" function to<extra_id_0>\r\n        if not self.enabled and not check_all:\r\n            return\r\n        if check_all or self.check_all:\r\n            modules = sys.modules.keys()\r\n        else:\r\n            modules = self.modules.keys()\r\n        for modname in modules:\r\n            m = sys.modules.get(modname, None)\r\n            if modname in self.skip_modules:\r\n                continue\r\n            if not hasattr(m, '__file__'):\r\n                continue\r\n            if m.__name__ == '__main__':\r\n                continue\r\n            filename = m.__file__\r\n            path, ext = os.path.splitext(filename)\r\n            if ext.lower() == '.py':\r\n                ext = PY_COMPILED_EXT\r\n                pyc_filename = pyfile.cache_from_source(filename)\r\n                py_filename = filename\r\n            else:\r\n                pyc_filename = filename\r\n                try:\r\n                    py_filename = pyfile.source_from_cache(filename)\r\n                except ValueError:\r\n                    continue\r\n            try:\r\n                pymtime = os.stat(py_filename).st_mtime\r\n                if pymtime <= os.stat(pyc_filename).st_mtime:\r\n                    continue\r\n                if self.failed.get(py_filename, None) == pymtime:\r\n                    continue\r\n            except OSError:\r\n                continue\r\n            try:\r\n                superreload(m, reload, self.old_objects)\r\n                if py_filename in self.failed:\r\n                    del self.failed[py_filename]\r\n            except:\r\n                print >> sys.stderr, \"[autoreload of %s failed: %s]\" % (\r\n                        modname, traceback.format_exc(1))\r\n                self.failed[py_filename] = pymtime","reference":"Check whether some modules need to be reloaded.","result":"Reload modules .","score":[0.0771,0.0667]}
{"code":"def editor(self, filename, linenum=None, wait=True):\r\n    \"\"\" function to<extra_id_0>\r\n    editor = self.editor\r\n    if linenum is None or editor=='notepad':\r\n        linemark = ''\r\n    else:\r\n        linemark = '+%d' % int(linenum)\r\n    if ' ' in editor and os.path.isfile(editor) and editor[0] != '\"':\r\n        editor = '\"%s\"' % editor\r\n    proc = subprocess.Popen('%s %s %s' % (editor, linemark, filename),\r\n                            shell=True)\r\n    if wait and proc.wait() != 0:\r\n        raise TryNext()","reference":"Open the default editor at the given filename and linenumber.\n\n    This is IPython's default editor hook, you can use it as an example to\n    write your own modified one.  To set your own editor function as the\n    new editor hook, call ip.set_hook('editor',yourfunc).","result":"Run editor .","score":[0.0,0.0262]}
{"code":"def fix_error_editor(self,filename,linenum,column,msg):\r\n    \"\"\" function to<extra_id_0>\r\n    def vim_quickfix_file():\r\n        t = tempfile.NamedTemporaryFile()\r\n        t.write('%s:%d:%d:%s\\n' % (filename,linenum,column,msg))\r\n        t.flush()\r\n        return t\r\n    if os.path.basename(self.editor) != 'vim':\r\n        self.hooks.editor(filename,linenum)\r\n        return\r\n    t = vim_quickfix_file()\r\n    try:\r\n        if os.system('vim --cmd \"set errorformat=%f:%l:%c:%m\" -q ' + t.name):\r\n            raise TryNext()\r\n    finally:\r\n        t.close()","reference":"Open the editor at the given filename, linenumber, column and\n    show an error message. This is used for correcting syntax errors.\n    The current implementation only has special support for the VIM editor,\n    and falls back on the 'editor' hook if VIM is not used.\n\n    Call ip.set_hook('fix_error_editor',youfunc) to use your own function,","result":"Fix error editor .","score":[0.0,0.0216]}
{"code":"def clipboard_get(self):\r\n    \"\"\" function to<extra_id_0>\r\n    from IPython.lib.clipboard import (\r\n        osx_clipboard_get, tkinter_clipboard_get,\r\n        win32_clipboard_get\r\n    )\r\n    if sys.platform == 'win32':\r\n        chain = [win32_clipboard_get, tkinter_clipboard_get]\r\n    elif sys.platform == 'darwin':\r\n        chain = [osx_clipboard_get, tkinter_clipboard_get]\r\n    else:\r\n        chain = [tkinter_clipboard_get]\r\n    dispatcher = CommandChainDispatcher()\r\n    for func in chain:\r\n        dispatcher.add(func)\r\n    text = dispatcher()\r\n    return text","reference":"Get text from the clipboard.","result":"Get the clipboard contents .","score":[0.2857,0.2]}
{"code":"def add(self, func, priority=0):\r\n        \"\"\" function to<extra_id_0>\r\n        self.chain.append((priority, func))\r\n        self.chain.sort(key=lambda x: x[0])","reference":"Add a func to the cmd chain with given priority","result":"Be added to the chain .","score":[0.1551,0.2662]}
{"code":"def get_metadata(path_or_module, metadata_version=None):\r\n    \"\"\" function to<extra_id_0>\r\n    if isinstance(path_or_module, ModuleType):\r\n        try:\r\n            return Installed(path_or_module, metadata_version)\r\n        except (ValueError, IOError):\r\n            pass\r\n    try:\r\n        __import__(path_or_module)\r\n    except ImportError:\r\n        pass\r\n    else:\r\n        try:\r\n            return Installed(path_or_module, metadata_version)\r\n        except (ValueError, IOError):\r\n            pass\r\n    if os.path.isfile(path_or_module):\r\n        try:\r\n            return SDist(path_or_module, metadata_version)\r\n        except (ValueError, IOError):\r\n            pass\r\n        try:\r\n            return BDist(path_or_module, metadata_version)\r\n        except (ValueError, IOError):\r\n            pass\r\n        try:\r\n            return Wheel(path_or_module, metadata_version)\r\n        except (ValueError, IOError):\r\n            pass\r\n    if os.path.isdir(path_or_module):\r\n        try:\r\n            return Develop(path_or_module, metadata_version)\r\n        except (ValueError, IOError):\r\n            pass","reference":"Try to create a Distribution 'path_or_module'.\n    \n    o 'path_or_module' may be a module object.\n\n    o If a string, 'path_or_module' may point to an sdist file, a bdist\n      file, an installed package, or a working checkout (if it contains\n      PKG-INFO).\n    \n    o Return None if 'path_or_module' can't be parsed.","result":"Get metadata from path or module .","score":[0.0007,0.0238]}
{"code":"def configure(self, options, conf):\r\n        \"\"\" function to<extra_id_0>\r\n        self.conf = conf\r\n        self.enabled = options.debugErrors or options.debugFailures\r\n        self.enabled_for_errors = options.debugErrors\r\n        self.enabled_for_failures = options.debugFailures","reference":"Configure which kinds of exceptions trigger plugin.","result":"Configure the logger .","score":[0.1509,0.0746]}
{"code":"def import_item(name):\r\n    \"\"\" function to<extra_id_0>\r\n    package = '.'.join(name.split('.')[0:-1])\r\n    obj = name.split('.')[-1]\r\n        s' % obj)\r\n        return pak\r\n    else:\r\n        return __import__(obj)","reference":"Import and return bar given the string foo.bar.","result":"Def import item .","score":[0,0.0658]}
{"code":"def try_passwordless_ssh(server, keyfile, paramiko=None):\r\n    \"\"\" function to<extra_id_0>\r\n    if paramiko is None:\r\n        paramiko = sys.platform == 'win32'\r\n    if not paramiko:\r\n        f = _try_passwordless_openssh\r\n    else:\r\n        f = _try_passwordless_paramiko\r\n    return f(server, keyfile)","reference":"Attempt to make an ssh connection without a password.\n    This is mainly used for requiring password input only once\n    when many tunnels may be connected to the same server.\n\n    If paramiko is None, the default for the platform is chosen.","result":"Def try passwordless ssh .","score":[0.0002,0.0137]}
{"code":"def _try_passwordless_openssh(server, keyfile):\r\n    \"\"\" function to<extra_id_0>\r\n    if pexpect is None:\r\n        raise ImportError(\"pexpect unavailable, use paramiko\")\r\n    cmd = 'ssh -f '+ server\r\n    if keyfile:\r\n        cmd += ' -i ' + keyfile\r\n    cmd += ' exit'\r\n    p = pexpect.spawn(cmd)\r\n    while True:\r\n        try:\r\n            p.expect('[Pp]assword:', timeout=.1)\r\n        except pexpect.TIMEOUT:\r\n            continue\r\n        except pexpect.EOF:\r\n            return True\r\n        else:\r\n            return False","reference":"Try passwordless login with shell ssh command.","result":"Try passwordless openssh .","score":[0.2134,0.2799]}
{"code":"def _try_passwordless_paramiko(server, keyfile):\r\n    \"\"\" function to<extra_id_0>\r\n    if paramiko is None:\r\n        msg = \"Paramiko unavaliable, \"\r\n        if sys.platform == 'win32':\r\n            msg += \"Paramiko is required for ssh tunneled connections on Windows.\"\r\n        else:\r\n            msg += \"use OpenSSH.\"\r\n        raise ImportError(msg)\r\n    username, server, port = _split_server(server)\r\n    client = paramiko.SSHClient()\r\n    client.load_system_host_keys()\r\n    client.set_missing_host_key_policy(paramiko.WarningPolicy())\r\n    try:\r\n        client.connect(server, port, username=username, key_filename=keyfile,\r\n               look_for_keys=True)\r\n    except paramiko.AuthenticationException:\r\n        return False\r\n    else:\r\n        client.close()\r\n        return True","reference":"Try passwordless login with paramiko.","result":"Try passwordless paramiko connection .","score":[0.3398,0.375]}
{"code":"def tunnel_connection(socket, addr, server, keyfile=None, password=None, paramiko=None, timeout=60):\r\n    \"\"\" function to<extra_id_0>\r\n    new_url, tunnel = open_tunnel(addr, server, keyfile=keyfile, password=password, paramiko=paramiko, timeout=timeout)\r\n    socket.connect(new_url)\r\n    return tunnel","reference":"Connect a socket to an address via an ssh tunnel.\n\n    This is a wrapper for socket.connect(addr), when addr is not accessible\n    from the local machine.  It simply creates an ssh tunnel using the remaining args,\n    and calls socket.connect('tcp:\/\/localhost:lport') where lport is the randomly\n    selected local port of the tunnel.","result":"Open tunnel connection .","score":[0.0,0.0225]}
{"code":"def open_tunnel(addr, server, keyfile=None, password=None, paramiko=None, timeout=60):\r\n    \"\"\" function to<extra_id_0>\r\n    lport = select_random_ports(1)[0]\r\n    transport, addr = addr.split(':\/\/')\r\n    ip,rport = addr.split(':')\r\n    rport = int(rport)\r\n    if paramiko is None:\r\n        paramiko = sys.platform == 'win32'\r\n    if paramiko:\r\n        tunnelf = paramiko_tunnel\r\n    else:\r\n        tunnelf = openssh_tunnel\r\n    tunnel = tunnelf(lport, rport, server, remoteip=ip, keyfile=keyfile, password=password, timeout=timeout)\r\n    return 'tcp:\/\/127.0.0.1:%i'%lport, tunnel","reference":"Open a tunneled connection from a 0MQ url.\n\n    For use inside tunnel_connection.\n\n    Returns\n    -------\n\n    (url, tunnel): The 0MQ url that has been forwarded, and the tunnel object","result":"Open a tunnel .","score":[0.0016,0.0607]}
{"code":"def _stop_scheduling_tasks(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self._task_socket.close()\r\n        self._task_socket = None\r\n        msg = \"An engine has been unregistered, and we are using pure \" +\\\r\n              \"ZMQ task scheduling.  Task farming will be disabled.\"\r\n        if self.outstanding:\r\n            msg += \" If you were running tasks when this happened, \" +\\\r\n                   \"some `outstanding` msg_ids may never resolve.\"\r\n        warnings.warn(msg, RuntimeWarning)","reference":"Stop scheduling tasks because an engine has been unregistered\n        from a pure ZMQ scheduler.","result":"Stop scheduling tasks .","score":[0.054,0.2265]}
{"code":"def _unwrap_exception(self, content):\r\n        \"\"\" function to<extra_id_0>\r\n        e = error.unwrap_exception(content)\r\n        if e.engine_info:\r\n            e_uuid = e.engine_info['engine_uuid']\r\n            eid = self._engines[e_uuid]\r\n            e.engine_info['engine_id'] = eid\r\n        return e","reference":"unwrap exception, and remap engine_id to int.","result":"Def unwrap exception .","score":[0.1509,0.0746]}
{"code":"def _register_engine(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        content = msg['content']\r\n        eid = content['id']\r\n        d = {eid : content['queue']}\r\n        self._update_engines(d)","reference":"Register a new engine, and update our connection info.","result":"Register an engine .","score":[0.0915,0.0588]}
{"code":"def _unregister_engine(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        content = msg['content']\r\n        eid = int(content['id'])\r\n        if eid in self._ids:\r\n            self._ids.remove(eid)\r\n            uuid = self._engines.pop(eid)\r\n            self._handle_stranded_msgs(eid, uuid)\r\n        if self._task_socket and self._task_scheme == 'pure':\r\n            self._stop_scheduling_tasks()","reference":"Unregister an engine that has died.","result":"Unregister an engine .","score":[0.3991,0.5077]}
{"code":"def _handle_execute_reply(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        parent = msg['parent_header']\r\n        msg_id = parent['msg_id']\r\n        if msg_id not in self.outstanding:\r\n            if msg_id in self.history:\r\n                print (\"got stale result: %s\"%msg_id)\r\n            else:\r\n                print (\"got unknown result: %s\"%msg_id)\r\n        else:\r\n            self.outstanding.remove(msg_id)\r\n        content = msg['content']\r\n        header = msg['header']\r\n        md = self.metadata[msg_id]\r\n        md.update(self._extract_metadata(header, parent, content))\r\n        self.metadata[msg_id] = md\r\n                e_outstanding = self._outstanding_dict[md['engine_uuid']]\r\n        if msg_id in e_outstanding:\r\n            e_outstanding.remove(msg_id)\r\n        if content['status'] == 'ok':\r\n            self.results[msg_id] = ExecuteReply(msg_id, content, md)\r\n        elif content['status'] == 'aborted':\r\n            self.results[msg_id] = error.TaskAborted(msg_id)\r\n        elif content['status'] == 'resubmitted':\r\n            pass\r\n        else:\r\n            self.results[msg_id] = self._unwrap_exception(content)","reference":"Save the reply to an execute_request into our results.\n\n        execute messages are never actually used. apply is used instead.","result":"Def handle execute replies .","score":[0.0146,0.0568]}
{"code":"def _flush_notifications(self):\r\n        \"\"\" function to<extra_id_0>\r\n        idents,msg = self.session.recv(self._notification_socket, mode=zmq.NOBLOCK)\r\n        while msg is not None:\r\n            if self.debug:\r\n                pprint(msg)\r\n            msg_type = msg['header']['msg_type']\r\n            handler = self._notification_handlers.get(msg_type, None)\r\n            if handler is None:\r\n                raise Exception(\"Unhandled message type: %s\"%msg.msg_type)\r\n            else:\r\n                handler(msg)\r\n            idents,msg = self.session.recv(self._notification_socket, mode=zmq.NOBLOCK)","reference":"Flush notifications of engine registrations waiting\n        in ZMQ queue.","result":"Flush all notifications .","score":[0.1088,0.1176]}
{"code":"def _flush_results(self, sock):\r\n        \"\"\" function to<extra_id_0>\r\n        idents,msg = self.session.recv(sock, mode=zmq.NOBLOCK)\r\n        while msg is not None:\r\n            if self.debug:\r\n                pprint(msg)\r\n            msg_type = msg['header']['msg_type']\r\n            handler = self._queue_handlers.get(msg_type, None)\r\n            if handler is None:\r\n                raise Exception(\"Unhandled message type: %s\"%msg.msg_type)\r\n            else:\r\n                handler(msg)\r\n            idents,msg = self.session.recv(sock, mode=zmq.NOBLOCK)","reference":"Flush task or queue results waiting in ZMQ queue.","result":"Flush results .","score":[0.0657,0.119]}
{"code":"def _flush_control(self, sock):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._ignored_control_replies <= 0:\r\n            return\r\n        idents,msg = self.session.recv(sock, mode=zmq.NOBLOCK)\r\n        while msg is not None:\r\n            self._ignored_control_replies -= 1\r\n            if self.debug:\r\n                pprint(msg)\r\n            idents,msg = self.session.recv(sock, mode=zmq.NOBLOCK)","reference":"Flush replies from the control channel waiting\n        in the ZMQ queue.\n\n        Currently: ignore them.","result":"Flush control replies .","score":[0.0345,0.1154]}
{"code":"def _flush_ignored_control(self):\r\n        \"\"\" function to<extra_id_0>\r\n        while self._ignored_control_replies > 0:\r\n            self.session.recv(self._control_socket)\r\n            self._ignored_control_replies -= 1","reference":"flush ignored control replies","result":"Flush ignored control messages .","score":[0.3398,0.7182]}
{"code":"def _flush_iopub(self, sock):\r\n        \"\"\" function to<extra_id_0>\r\n        idents,msg = self.session.recv(sock, mode=zmq.NOBLOCK)\r\n        while msg is not None:\r\n            if self.debug:\r\n                pprint(msg)\r\n            parent = msg['parent_header']\r\n            if not parent:\r\n                continue\r\n            msg_id = parent['msg_id']\r\n            content = msg['content']\r\n            header = msg['header']\r\n            msg_type = msg['header']['msg_type']\r\n            md = self.metadata[msg_id]\r\n            if msg_type == 'stream':\r\n                name = content['name']\r\n                s = md[name] or ''\r\n                md[name] = s + content['data']\r\n            elif msg_type == 'pyerr':\r\n                md.update({'pyerr' : self._unwrap_exception(content)})\r\n            elif msg_type == 'pyin':\r\n                md.update({'pyin' : content['code']})\r\n            elif msg_type == 'display_data':\r\n                md['outputs'].append(content)\r\n            elif msg_type == 'pyout':\r\n                md['pyout'] = content\r\n            elif msg_type == 'status':\r\n                if content['execution_state'] == 'idle':\r\n                    md['outputs_ready'] = True\r\n            else:\r\n                pass\r\n            self.metadata[msg_id] = md\r\n            idents,msg = self.session.recv(sock, mode=zmq.NOBLOCK)","reference":"Flush replies from the iopub channel waiting\n        in the ZMQ queue.","result":"Flush iopub .","score":[0.0337,0.098]}
{"code":"def _spin_every(self, interval=1):\r\n        \"\"\" function to<extra_id_0>\r\n        while True:\r\n            if self._stop_spinning.is_set():\r\n                return\r\n            time.sleep(interval)\r\n            self.spin()","reference":"target func for use in spin_thread","result":"Spin every interval .","score":[0,0.0]}
{"code":"def stop_spin_thread(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._spin_thread is not None:\r\n            self._stop_spinning.set()\r\n            self._spin_thread.join()\r\n            self._spin_thread = None","reference":"stop background spin_thread, if any","result":"Def stop the spin thread .","score":[0.193,0.098]}
{"code":"def spin(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._notification_socket:\r\n            self._flush_notifications()\r\n        if self._iopub_socket:\r\n            self._flush_iopub(self._iopub_socket)\r\n        if self._mux_socket:\r\n            self._flush_results(self._mux_socket)\r\n        if self._task_socket:\r\n            self._flush_results(self._task_socket)\r\n        if self._control_socket:\r\n            self._flush_control(self._control_socket)\r\n        if self._query_socket:\r\n            self._flush_ignored_hub_replies()","reference":"Flush any registration notifications and execution results\n        waiting in the ZMQ queue.","result":"Spin the thread .","score":[0.0432,0.0446]}
{"code":"def wait(self, jobs=None, timeout=-1):\r\n        \"\"\" function to<extra_id_0>\r\n        tic = time.time()\r\n        if jobs is None:\r\n            theids = self.outstanding\r\n        else:\r\n            if isinstance(jobs, (int, basestring, AsyncResult)):\r\n                jobs = [jobs]\r\n            theids = set()\r\n            for job in jobs:\r\n                if isinstance(job, int):\r\n                    job = self.history[job]\r\n                elif isinstance(job, AsyncResult):\r\n                    map(theids.add, job.msg_ids)\r\n                    continue\r\n                theids.add(job)\r\n        if not theids.intersection(self.outstanding):\r\n            return True\r\n        self.spin()\r\n        while theids.intersection(self.outstanding):\r\n            if timeout >= 0 and ( time.time()-tic ) > timeout:\r\n                break\r\n            time.sleep(1e-3)\r\n            self.spin()\r\n        return len(theids.intersection(self.outstanding)) == 0","reference":"waits on one or more `jobs`, for up to `timeout` seconds.\n\n        Parameters\n        ----------\n\n        jobs : int, str, or list of ints and\/or strs, or one or more AsyncResult objects\n                ints are indices to self.history\n                strs are msg_ids\n                default: wait on all outstanding messages\n        timeout : float\n                a time in seconds, after which to give up.\n                default is -1, which means no timeout\n\n        Returns\n        -------\n\n        True : when all msg_ids are done\n        False : timeout reached, some msg_ids still outstanding","result":"Wait for all jobs to.","score":[0.0,0.0279]}
{"code":"def send_apply_request(self, socket, f, args=None, kwargs=None, subheader=None, track=False,\r\n                            \"\"\" function to<extra_id_0>\r\n                            ident=None):\r\n        if self._closed:\r\n            raise RuntimeError(\"Client cannot be used after its sockets have been closed\")\r\n                args = args if args is not None else []\r\n        kwargs = kwargs if kwargs is not None else {}\r\n        subheader = subheader if subheader is not None else {}\r\n        if not callable(f) and not isinstance(f, Reference):\r\n            raise TypeError(\"f must be callable, not %s\"%type(f))\r\n        if not isinstance(args, (tuple, list)):\r\n            raise TypeError(\"args must be tuple or list, not %s\"%type(args))\r\n        if not isinstance(kwargs, dict):\r\n            raise TypeError(\"kwargs must be dict, not %s\"%type(kwargs))\r\n        if not isinstance(subheader, dict):\r\n            raise TypeError(\"subheader must be dict, not %s\"%type(subheader))\r\n        bufs = util.pack_apply_message(f,args,kwargs)\r\n        msg = self.session.send(socket, \"apply_request\", buffers=bufs, ident=ident,\r\n                            subheader=subheader, track=track)\r\n        msg_id = msg['header']['msg_id']\r\n        self.outstanding.add(msg_id)\r\n        if ident:\r\n            if isinstance(ident, list):\r\n                ident = ident[-1]\r\n            if ident in self._engines.values():\r\n                self._outstanding_dict[ident].add(msg_id)\r\n        self.history.append(msg_id)\r\n        self.metadata[msg_id]['submitted'] = datetime.now()\r\n        return msg","reference":"construct and send an apply message via a socket.\n\n        This is the principal method with which all engine execution is performed by views.","result":"Def be applied to the context .","score":[0.0164,0.0467]}
{"code":"def send_execute_request(self, socket, code, silent=True, subheader=None, ident=None):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._closed:\r\n            raise RuntimeError(\"Client cannot be used after its sockets have been closed\")\r\n                subheader = subheader if subheader is not None else {}\r\n        if not isinstance(code, basestring):\r\n            raise TypeError(\"code must be text, not %s\" % type(code))\r\n        if not isinstance(subheader, dict):\r\n            raise TypeError(\"subheader must be dict, not %s\" % type(subheader))\r\n                content = dict(code=code, silent=bool(silent), user_variables=[], user_expressions={})\r\n        msg = self.session.send(socket, \"execute_request\", content=content, ident=ident,\r\n                            subheader=subheader)\r\n        msg_id = msg['header']['msg_id']\r\n        self.outstanding.add(msg_id)\r\n        if ident:\r\n            if isinstance(ident, list):\r\n                ident = ident[-1]\r\n            if ident in self._engines.values():\r\n                self._outstanding_dict[ident].add(msg_id)\r\n        self.history.append(msg_id)\r\n        self.metadata[msg_id]['submitted'] = datetime.now()\r\n        return msg","reference":"construct and send an execute request via a socket.","result":"Def send a execute request .","score":[0.1969,0.3628]}
{"code":"def get_result(self, indices_or_msg_ids=None, block=None):\r\n        \"\"\" function to<extra_id_0>\r\n        block = self.block if block is None else block\r\n        if indices_or_msg_ids is None:\r\n            indices_or_msg_ids = -1\r\n        if not isinstance(indices_or_msg_ids, (list,tuple)):\r\n            indices_or_msg_ids = [indices_or_msg_ids]\r\n        theids = []\r\n        for id in indices_or_msg_ids:\r\n            if isinstance(id, int):\r\n                id = self.history[id]\r\n            if not isinstance(id, basestring):\r\n                raise TypeError(\"indices must be str or int, not %r\"%id)\r\n            theids.append(id)\r\n        local_ids = filter(lambda msg_id: msg_id in self.history or msg_id in self.results, theids)\r\n        remote_ids = filter(lambda msg_id: msg_id not in local_ids, theids)\r\n        if remote_ids:\r\n            ar = AsyncHubResult(self, msg_ids=theids)\r\n        else:\r\n            ar = AsyncResult(self, msg_ids=theids)\r\n        if block:\r\n            ar.wait()\r\n        return ar","reference":"Retrieve a result by msg_id or history index, wrapped in an AsyncResult object.\n\n        If the client already has the results, no request to the Hub will be made.\n\n        This is a convenient way to construct AsyncResult objects, which are wrappers\n        that include metadata about execution, and allow for awaiting results that\n        were not submitted by this Client.\n\n        It can also be a convenient way to retrieve the metadata associated with\n        blocking execution, since it always retrieves\n\n        Examples\n        --------\n        ::\n\n            In [10]: r = client.apply()\n\n        Parameters\n        ----------\n\n        indices_or_msg_ids : integer history index, str msg_id, or list of either\n            The indices or msg_ids of indices to be retrieved\n\n        block : bool\n            Whether to wait for the result to be done\n\n        Returns\n        -------\n\n        AsyncResult\n            A single AsyncResult object will always be returned.\n\n        AsyncHubResult\n            A subclass of AsyncResult that retrieves results from the Hub","result":"Get the result of a query .","score":[0.0,0.0158]}
{"code":"def queue_status(self, targets='all', verbose=False):\r\n        \"\"\" function to<extra_id_0>\r\n        if targets == 'all':\r\n            engine_ids = None\r\n        else:\r\n            engine_ids = self._build_targets(targets)[1]\r\n        content = dict(targets=engine_ids, verbose=verbose)\r\n        self.session.send(self._query_socket, \"queue_request\", content=content)\r\n        idents,msg = self.session.recv(self._query_socket, 0)\r\n        if self.debug:\r\n            pprint(msg)\r\n        content = msg['content']\r\n        status = content.pop('status')\r\n        if status != 'ok':\r\n            raise self._unwrap_exception(content)\r\n        content = rekey(content)\r\n        if isinstance(targets, int):\r\n            return content[targets]\r\n        else:\r\n            return content","reference":"Fetch the status of engine queues.\n\n        Parameters\n        ----------\n\n        targets : int\/str\/list of ints\/strs\n                the engines whose states are to be queried.\n                default : all\n        verbose : bool\n                Whether to return lengths only, or lists of ids for each element","result":"Queue status of all the engine.","score":[0.0013,0.056]}
{"code":"def purge_results(self, jobs=[], targets=[]):\r\n        \"\"\" function to<extra_id_0>\r\n        if not targets and not jobs:\r\n            raise ValueError(\"Must specify at least one of `targets` and `jobs`\")\r\n        if targets:\r\n            targets = self._build_targets(targets)[1]\r\n        if jobs == 'all':\r\n            msg_ids = jobs\r\n        else:\r\n            msg_ids = []\r\n            if isinstance(jobs, (basestring,AsyncResult)):\r\n                jobs = [jobs]\r\n            bad_ids = filter(lambda obj: not isinstance(obj, (basestring, AsyncResult)), jobs)\r\n            if bad_ids:\r\n                raise TypeError(\"Invalid msg_id type %r, expected str or AsyncResult\"%bad_ids[0])\r\n            for j in jobs:\r\n                if isinstance(j, AsyncResult):\r\n                    msg_ids.extend(j.msg_ids)\r\n                else:\r\n                    msg_ids.append(j)\r\n        content = dict(engine_ids=targets, msg_ids=msg_ids)\r\n        self.session.send(self._query_socket, \"purge_request\", content=content)\r\n        idents, msg = self.session.recv(self._query_socket, 0)\r\n        if self.debug:\r\n            pprint(msg)\r\n        content = msg['content']\r\n        if content['status'] != 'ok':\r\n            raise self._unwrap_exception(content)","reference":"Tell the Hub to forget results.\n\n        Individual results can be purged by msg_id, or the entire\n        history of specific targets can be purged.\n\n        Use `purge_results('all')` to scrub everything from the Hub's db.\n\n        Parameters\n        ----------\n\n        jobs : str or list of str or AsyncResult objects\n                the msg_ids whose results should be forgotten.\n        targets : int\/str\/list of ints\/strs\n                The targets, by int_id, whose entire history is to be purged.\n\n                default : None","result":"Purge results from the engine .","score":[0.0,0.0314]}
{"code":"def hub_history(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self.session.send(self._query_socket, \"history_request\", content={})\r\n        idents, msg = self.session.recv(self._query_socket, 0)\r\n        if self.debug:\r\n            pprint(msg)\r\n        content = msg['content']\r\n        if content['status'] != 'ok':\r\n            raise self._unwrap_exception(content)\r\n        else:\r\n            return content['history']","reference":"Get the Hub's history\n\n        Just like the Client, the Hub has a history, which is a list of msg_ids.\n        This will contain the history of all clients, and, depending on configuration,\n        may contain history across multiple cluster sessions.\n\n        Any msg_id returned here is a valid argument to `get_result`.\n\n        Returns\n        -------\n\n        msg_ids : list of strs\n                list of all msg_ids, ordered by task submission time.","result":"Get hub history .","score":[0.0,0.0259]}
{"code":"def db_query(self, query, keys=None):\r\n        \"\"\" function to<extra_id_0>\r\n        if isinstance(keys, basestring):\r\n            keys = [keys]\r\n        content = dict(query=query, keys=keys)\r\n        self.session.send(self._query_socket, \"db_request\", content=content)\r\n        idents, msg = self.session.recv(self._query_socket, 0)\r\n        if self.debug:\r\n            pprint(msg)\r\n        content = msg['content']\r\n        if content['status'] != 'ok':\r\n            raise self._unwrap_exception(content)\r\n        records = content['records']\r\n        buffer_lens = content['buffer_lens']\r\n        result_buffer_lens = content['result_buffer_lens']\r\n        buffers = msg['buffers']\r\n        has_bufs = buffer_lens is not None\r\n        has_rbufs = result_buffer_lens is not None\r\n        for i,rec in enumerate(records):\r\n            if has_bufs:\r\n                blen = buffer_lens[i]\r\n                rec['buffers'], buffers = buffers[:blen],buffers[blen:]\r\n            if has_rbufs:\r\n                blen = result_buffer_lens[i]\r\n                rec['result_buffers'], buffers = buffers[:blen],buffers[blen:]\r\n        return records","reference":"Query the Hub's TaskRecord database\n\n        This will return a list of task record dicts that match `query`\n\n        Parameters\n        ----------\n\n        query : mongodb query dict\n            The search dict. See mongodb query docs for details.\n        keys : list of strs [optional]\n            The subset of keys to be returned.  The default is to fetch everything but buffers.\n            'msg_id' will *always* be included.","result":"Send a db query request.","score":[0.0,0.0187]}
{"code":"def _opcode_set(*names):\r\n    \"\"\" function to<extra_id_0>\r\n    s = set()\r\n    for name in names:\r\n        try:\r\n            s.add(_opcode(name))\r\n        except KeyError:\r\n            pass\r\n    return s","reference":"Return a set of opcodes by the names in `names`.","result":"Return opcode set .","score":[0.0848,0.1596]}
{"code":"def _get_byte_parser(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if not self._byte_parser:\r\n            self._byte_parser = \\\r\n                            ByteParser(text=self.text, filename=self.filename)\r\n        return self._byte_parser","reference":"Create a ByteParser on demand.","result":"Get the byte parser .","score":[0,0.0]}
{"code":"def lines_matching(self, *regexes):\r\n        \"\"\" function to<extra_id_0>\r\n        regex_c = re.compile(join_regex(regexes))\r\n        matches = set()\r\n        for i, ltext in enumerate(self.lines):\r\n            if regex_c.search(ltext):\r\n                matches.add(i+1)\r\n        return matches","reference":"Find the lines matching one of a list of regexes.\n\n        Returns a set of line numbers, the lines that contain a match for one\n        of the regexes in `regexes`.  The entire line needn't match, just a\n        part of it.","result":"Return lines that match a set of regexes .","score":[0.0119,0.1478]}
{"code":"def _raw_parse(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.exclude:\r\n            self.excluded = self.lines_matching(self.exclude)\r\n        indent = 0\r\n        exclude_indent = 0\r\n        excluding = False\r\n        prev_toktype = token.INDENT\r\n        first_line = None\r\n        empty = True\r\n        tokgen = generate_tokens(self.text)\r\n        for toktype, ttext, (slineno, _), (elineno, _), ltext in tokgen:\r\n            if self.show_tokens:\r\n                print(\"%10s %5s %-20r %r\" % (\r\n                    tokenize.tok_name.get(toktype, toktype),\r\n                    nice_pair((slineno, elineno)), ttext, ltext\r\n                    ))\r\n            if toktype == token.INDENT:\r\n                indent += 1\r\n            elif toktype == token.DEDENT:\r\n                indent -= 1\r\n            elif toktype == token.NAME and ttext == 'class':\r\n                self.classdefs.add(slineno)\r\n            elif toktype == token.OP and ttext == ':':\r\n                if not excluding and elineno in self.excluded:\r\n indent\r\n                    excluding = True\r\n            elif toktype == token.STRING and prev_toktype == token.INDENT:\r\n         self.docstrings.update(range(slineno, elineno+1))\r\n            elif toktype == token.NEWLINE:\r\n                if first_line is not None and elineno != first_line:\r\n                    rng = (first_line, elineno)\r\n                    for l in range(first_line, elineno+1):\r\n                        self.multiline[l] = rng\r\n                first_line = None\r\n            if ttext.strip() and toktype != tokenize.COMMENT:\r\n                empty = False\r\n                if first_line is None:\r\n                    first_line = slineno\r\n                    if excluding and indent <= exclude_indent:\r\n                        excluding = False\r\n                    if excluding:\r\n                        self.excluded.add(elineno)\r\n            prev_toktype = toktype\r\n        if not empty:\r\n            self.statement_starts.update(self.byte_parser._find_statements())","reference":"Parse the source to find the interesting facts about its lines.\n\n        A handful of member fields are updated.","result":"Parse the text .","score":[0.0136,0.0602]}
{"code":"def first_line(self, line):\r\n        \"\"\" function to<extra_id_0>\r\n        rng = self.multiline.get(line)\r\n        if rng:\r\n            first_line = rng[0]\r\n        else:\r\n            first_line = line\r\n        return first_line","reference":"Return the first line number of the statement including `line`.","result":"Get the first line of a line .","score":[0.2394,0.2041]}
{"code":"def first_lines(self, lines, *ignores):\r\n        \"\"\" function to<extra_id_0>\r\n        ignore = set()\r\n        for ign in ignores:\r\n            ignore.update(ign)\r\n        lset = set()\r\n        for l in lines:\r\n            if l in ignore:\r\n                continue\r\n            new_l = self.first_line(l)\r\n            if new_l not in ignore:\r\n                lset.add(new_l)\r\n        return lset","reference":"Map the line numbers in `lines` to the correct first line of the\n        statement.\n\n        Skip any line mentioned in any of the sequences in `ignores`.\n\n        Returns a set of the first lines.","result":"Find first lines .","score":[0.0003,0.0342]}
{"code":"def parse_source(self):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            self._raw_parse()\r\n        except (tokenize.TokenError, IndentationError):\r\n            _, tokerr, _ = sys.exc_info()\r\n            msg, lineno = tokerr.args\r\n            raise NotPython(\r\n                \"Couldn't parse '%s' as Python source: '%s' at %s\" %\r\n                    (self.filename, msg, lineno)\r\n                )\r\n        excluded_lines = self.first_lines(self.excluded)\r\n        lines = self.first_lines(\r\n            self.statement_starts,\r\n            excluded_lines,\r\n            self.docstrings\r\n        )\r\n        return lines, excluded_lines","reference":"Parse source text to find executable lines, excluded lines, etc.\n\n        Return values are 1) a set of executable line numbers, and 2) a set of\n        excluded line numbers.\n\n        Reported line numbers are normalized to the first line of multi-line\n        statements.","result":"Parse the source code .","score":[0.0003,0.0411]}
{"code":"def arcs(self):\r\n        \"\"\" function to<extra_id_0>\r\n        all_arcs = []\r\n        for l1, l2 in self.byte_parser._all_arcs():\r\n            fl1 = self.first_line(l1)\r\n            fl2 = self.first_line(l2)\r\n            if fl1 != fl2:\r\n                all_arcs.append((fl1, fl2))\r\n        return sorted(all_arcs)","reference":"Get information about the arcs available in the code.\n\n        Returns a sorted list of line number pairs.  Line numbers have been\n        normalized to the first line of multiline statements.","result":"Get all arcs in the byte parser .","score":[0.0169,0.0743]}
{"code":"def exit_counts(self):\r\n        \"\"\" function to<extra_id_0>\r\n        excluded_lines = self.first_lines(self.excluded)\r\n        exit_counts = {}\r\n        for l1, l2 in self.arcs():\r\n            if l1 < 0:\r\n                continue\r\n            if l1 in excluded_lines:\r\n                continue\r\n            if l2 in excluded_lines:\r\n                continue\r\n            if l1 not in exit_counts:\r\n                exit_counts[l1] = 0\r\n            exit_counts[l1] += 1\r\n        for l in self.classdefs:\r\n            if l in exit_counts:\r\n                exit_counts[l] -= 1\r\n        return exit_counts","reference":"Get a mapping from line numbers to count of exits from that line.\n\n        Excluded lines are excluded.","result":"Calculate exit counts .","score":[0,0.0637]}
{"code":"def child_parsers(self):\r\n        \"\"\" function to<extra_id_0>\r\n        children = CodeObjects(self.code)\r\n        return [ByteParser(code=c, text=self.text) for c in children]","reference":"Iterate over all the code objects nested within this one.\n\n        The iteration includes `self` as its first value.","result":"Return child parsers .","score":[0,0.0]}
{"code":"def _bytes_lines(self):\r\n        \"\"\" function to<extra_id_0>\r\n        byte_increments = bytes_to_ints(self.code.co_lnotab[0::2])\r\n        line_increments = bytes_to_ints(self.code.co_lnotab[1::2])\r\n        last_line_num = None\r\n        line_num = self.code.co_firstlineno\r\n        byte_num = 0\r\n        for byte_incr, line_incr in zip(byte_increments, line_increments):\r\n            if byte_incr:\r\n                if line_num != last_line_num:\r\n                    yield (byte_num, line_num)\r\n                    last_line_num = line_num\r\n                byte_num += byte_incr\r\n            line_num += line_incr\r\n        if line_num != last_line_num:\r\n            yield (byte_num, line_num)","reference":"Map byte offsets to line numbers in `code`.\n\n        Uses co_lnotab described in Python\/compile.c to map byte offsets to\n        line numbers.  Produces a sequence: (b0, l0), (b1, l1), ...\n\n        Only byte offsets that correspond to line numbers are included in the\n        results.","result":"Generate bytes lines .","score":[0,0.0268]}
{"code":"def _find_statements(self):\r\n        \"\"\" function to<extra_id_0>\r\n        for bp in self.child_parsers():\r\n            for _, l in bp._bytes_lines():\r\n                yield l","reference":"Find the statements in `self.code`.\n\n        Produce a sequence of line numbers that start statements.  Recurses\n        into all code objects reachable from `self.code`.","result":"Def find statements .","score":[0.0035,0.0495]}
{"code":"def _block_stack_repr(self, block_stack):\r\n        \"\"\" function to<extra_id_0>\r\n        blocks = \", \".join(\r\n            [\"(%s, %r)\" % (dis.opname[b[0]], b[1]) for b in block_stack]\r\n        )\r\n        return \"[\" + blocks + \"]\"","reference":"Get a string version of `block_stack`, for debugging.","result":"Return block stack representation .","score":[0,0.0]}
{"code":"def _split_into_chunks(self):\r\n        \"\"\" function to<extra_id_0>\r\n        chunks = []\r\n        chunk = None\r\n        bytes_lines_map = dict(self._bytes_lines())\r\n        block_stack = []\r\n        ignore_branch = 0\r\n        ult = penult = None\r\n        jump_to = set()\r\n        bytecodes = list(ByteCodes(self.code.co_code))\r\n        for bc in bytecodes:\r\n            if bc.jump_to >= 0:\r\n                jump_to.add(bc.jump_to)\r\n        chunk_lineno = 0\r\n        for bc in bytecodes:\r\n            start_new_chunk = False\r\n            first_chunk = False\r\n            if bc.offset in bytes_lines_map:\r\n                start_new_chunk = True\r\n                chunk_lineno = bytes_lines_map[bc.offset]\r\n                first_chunk = True\r\n            elif bc.offset in jump_to:\r\n                start_new_chunk = True\r\n            elif bc.op in OPS_CHUNK_BEGIN:\r\n                start_new_chunk = True\r\n            if not chunk or start_new_chunk:\r\n                if chunk:\r\n                    chunk.exits.add(bc.offset)\r\n                chunk = Chunk(bc.offset, chunk_lineno, first_chunk)\r\n                chunks.append(chunk)\r\n            if bc.jump_to >= 0 and bc.op not in OPS_NO_JUMP:\r\n                if ignore_branch:\r\n                    ignore_branch -= 1\r\n                else:\r\n                    chunk.exits.add(bc.jump_to)\r\n            if bc.op in OPS_CODE_END:\r\n                chunk.exits.add(-self.code.co_firstlineno)\r\n            if bc.op in OPS_PUSH_BLOCK:\r\n                block_stack.append((bc.op, bc.jump_to))\r\n            if bc.op in OPS_POP_BLOCK:\r\n                block_stack.pop()\r\n            if bc.op in OPS_CHUNK_END:\r\n                if bc.op == OP_BREAK_LOOP:\r\n                    chunk.exits.add(block_stack[-1][1])\r\n                chunk = None\r\n            if bc.op == OP_END_FINALLY:\r\n                for block in reversed(block_stack):\r\n                    if block[0] in OPS_EXCEPT_BLOCKS:\r\n                        chunk.exits.add(block[1])\r\n                        break\r\n            if bc.op == OP_COMPARE_OP and bc.arg == COMPARE_EXCEPTION:\r\n                ignore_branch += 1\r\n            penult = ult\r\n            ult = bc\r\n        if chunks:\r\n            if ult and penult:\r\n                if penult.op == OP_LOAD_CONST and ult.op == OP_RETURN_VALUE:\r\n                    if self.code.co_consts[penult.arg] is None:\r\n                        if chunks[-1].byte != penult.offset:\r\n                            ex = -self.code.co_firstlineno\r\n                            last_chunk = chunks[-1]\r\n                            last_chunk.exits.remove(ex)\r\n                            last_chunk.exits.add(penult.offset)\r\n                            chunk = Chunk(\r\n                                penult.offset, last_chunk.line, False\r\n                            )\r\n                            chunk.exits.add(ex)\r\n                            chunks.append(chunk)\r\n            chunks[-1].length = bc.next_offset - chunks[-1].byte\r\n            for i in range(len(chunks)-1):\r\n                chunks[i].length = chunks[i+1].byte - chunks[i].byte\r\n        return chunks","reference":"Split the code object into a list of `Chunk` objects.\n\n        Each chunk is only entered at its first instruction, though there can\n        be many exits from a chunk.\n\n        Returns a list of `Chunk` objects.","result":"Split bytecode into chunks .","score":[0.0009,0.0482]}
{"code":"def validate_chunks(self, chunks):\r\n        \"\"\" function to<extra_id_0>\r\n        starts = set([ch.byte for ch in chunks])\r\n        for ch in chunks:\r\n            assert all([(ex in starts or ex < 0) for ex in ch.exits])","reference":"Validate the rule that chunks have a single entrance.","result":"Validate chunks .","score":[0.0657,0.119]}
{"code":"def _arcs(self):\r\n        \"\"\" function to<extra_id_0>\r\n        chunks = self._split_into_chunks()\r\n        byte_chunks = dict([(c.byte, c) for c in chunks])\r\n        yield (-1, byte_chunks[0].line)\r\n        for chunk in chunks:\r\n            if not chunk.first:\r\n                continue\r\n            chunks_considered = set()\r\n            chunks_to_consider = [chunk]\r\n            while chunks_to_consider:\r\n                this_chunk = chunks_to_consider.pop()\r\n                chunks_considered.add(this_chunk)\r\n                for ex in this_chunk.exits:\r\n                    if ex < 0:\r\n                        yield (chunk.line, ex)\r\n                    else:\r\n                        next_chunk = byte_chunks[ex]\r\n                        if next_chunk in chunks_considered:\r\n                            continue\r\n                        backward_jump = next_chunk.byte < this_chunk.byte\r\n                        if next_chunk.first or backward_jump:\r\n                            if next_chunk.line != chunk.line:\r\n                                yield (chunk.line, next_chunk.line)\r\n                        else:\r\n                            chunks_to_consider.append(next_chunk)","reference":"Find the executable arcs in the code.\n\n        Yields pairs: (from,to).  From and to are integer line numbers.  If\n        from is < 0, then the arc is an entrance into the code object.  If to\n        is < 0, the arc is an exit from the code object.","result":"Generate arcs .","score":[0.0,0.012]}
{"code":"def _all_chunks(self):\r\n        \"\"\" function to<extra_id_0>\r\n        chunks = []\r\n        for bp in self.child_parsers():\r\n            chunks.extend(bp._split_into_chunks())\r\n        return chunks","reference":"Returns a list of `Chunk` objects for this code and its children.\n\n        See `_split_into_chunks` for details.","result":"Return all chunks .","score":[0,0.0338]}
{"code":"def _all_arcs(self):\r\n        \"\"\" function to<extra_id_0>\r\n        arcs = set()\r\n        for bp in self.child_parsers():\r\n            arcs.update(bp._arcs())\r\n        return arcs","reference":"Get the set of all arcs in this code object and its children.\n\n        See `_arcs` for details.","result":"Return all arcs in this parser .","score":[0.1211,0.248]}
{"code":"def options(self, parser, env):\r\n        \"\"\" function to<extra_id_0>\r\n        super(Coverage, self).options(parser, env)\r\n        parser.add_option(\"--cover-package\", action=\"append\",\r\n                          default=env.get('NOSE_COVER_PACKAGE'),\r\n                          metavar=\"PACKAGE\",\r\n                          dest=\"cover_packages\",\r\n                          help=\"Restrict coverage output to selected packages \"\r\n                          \"[NOSE_COVER_PACKAGE]\")\r\n        parser.add_option(\"--cover-erase\", action=\"store_true\",\r\n                          default=env.get('NOSE_COVER_ERASE'),\r\n                          dest=\"cover_erase\",\r\n                          help=\"Erase previously collected coverage \"\r\n                          \"statistics before run\")\r\n        parser.add_option(\"--cover-tests\", action=\"store_true\",\r\n                          dest=\"cover_tests\",\r\n                          default=env.get('NOSE_COVER_TESTS'),\r\n                          help=\"Include test modules in coverage report \"\r\n                          \"[NOSE_COVER_TESTS]\")\r\n        parser.add_option(\"--cover-min-percentage\", action=\"store\",\r\n                          dest=\"cover_min_percentage\",\r\n                          default=env.get('NOSE_COVER_MIN_PERCENTAGE'),\r\n                          help=\"Minimum percentage of coverage for tests\"\r\n                          \"to pass [NOSE_COVER_MIN_PERCENTAGE]\")\r\n        parser.add_option(\"--cover-inclusive\", action=\"store_true\",\r\n                          dest=\"cover_inclusive\",\r\n                          default=env.get('NOSE_COVER_INCLUSIVE'),\r\n                          help=\"Include all python files under working \"\r\n                          \"directory in coverage report.  Useful for \"\r\n                          \"discovering holes in test coverage if not all \"\r\n                          \"files are imported by the test suite. \"\r\n                          \"[NOSE_COVER_INCLUSIVE]\")\r\n        parser.add_option(\"--cover-html\", action=\"store_true\",\r\n                          default=env.get('NOSE_COVER_HTML'),\r\n                          dest='cover_html',\r\n                          help=\"Produce HTML coverage information\")\r\n        parser.add_option('--cover-html-dir', action='store',\r\n                          default=env.get('NOSE_COVER_HTML_DIR', 'cover'),\r\n                          dest='cover_html_dir',\r\n                          metavar='DIR',\r\n                          help='Produce HTML coverage information in dir')\r\n        parser.add_option(\"--cover-branches\", action=\"store_true\",\r\n                          default=env.get('NOSE_COVER_BRANCHES'),\r\n                          dest=\"cover_branches\",\r\n                          help=\"Include branch coverage in coverage report \"\r\n                          \"[NOSE_COVER_BRANCHES]\")\r\n        parser.add_option(\"--cover-xml\", action=\"store_true\",\r\n                          default=env.get('NOSE_COVER_XML'),\r\n                          dest=\"cover_xml\",\r\n                          help=\"Produce XML coverage information\")\r\n        parser.add_option(\"--cover-xml-file\", action=\"store\",\r\n                          default=env.get('NOSE_COVER_XML_FILE', 'coverage.xml'),\r\n                          dest=\"cover_xml_file\",\r\n                          metavar=\"FILE\",\r\n                          help=\"Produce XML coverage information in file\")","reference":"Add options to command line.","result":"Def add options to the parser .","score":[0.2284,0.5662]}
{"code":"def begin(self):\r\n        \"\"\" function to<extra_id_0>\r\n        log.debug(\"Coverage begin\")\r\n        self.skipModules = sys.modules.keys()[:]\r\n        if self.coverErase:\r\n            log.debug(\"Clearing previously collected coverage statistics\")\r\n            self.coverInstance.combine()\r\n            self.coverInstance.erase()\r\n        self.coverInstance.exclude('\r\n        self.coverInstance.load()\r\n        self.coverInstance.start()","reference":"Begin recording coverage information.","result":"Begin the coverage process .","score":[0.2857,0.2439]}
{"code":"def report(self, stream):\r\n        \"\"\" function to<extra_id_0>\r\n        log.debug(\"Coverage report\")\r\n        self.coverInstance.stop()\r\n        self.coverInstance.combine()\r\n        self.coverInstance.save()\r\n        modules = [module\r\n                    for name, module in sys.modules.items()\r\n                    if self.wantModuleCoverage(name, module)]\r\n        log.debug(\"Coverage report will cover modules: %s\", modules)\r\n        self.coverInstance.report(modules, file=stream)\r\n        if self.coverHtmlDir:\r\n            log.debug(\"Generating HTML coverage report\")\r\n            self.coverInstance.html_report(modules, self.coverHtmlDir)\r\n        if self.coverXmlFile:\r\n            log.debug(\"Generating XML coverage report\")\r\n            self.coverInstance.xml_report(modules, self.coverXmlFile)\r\n        if self.coverMinPercentage:\r\n            f = StringIO.StringIO()\r\n            self.coverInstance.report(modules, file=f)\r\n            m = re.search(r'-------\\s\\w+\\s+\\d+\\s+\\d+\\s+(\\d+)%\\s+\\d*\\s{0,1}$', f.getvalue())\r\n            if m:\r\n                percentage = int(m.groups()[0])\r\n                if percentage < self.coverMinPercentage:\r\n                    log.error('TOTAL Coverage did not reach minimum '\r\n                              'required: %d%%' % self.coverMinPercentage)\r\n                    sys.exit(1)\r\n            else:\r\n                log.error(\"No total percentage was found in coverage output, \"\r\n                          \"something went wrong.\")","reference":"Output code coverage report.","result":"Generate coverage report .","score":[0.3195,0.125]}
{"code":"def wantFile(self, file, package=None):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.coverInclusive:\r\n            if file.endswith(\".py\"):\r\n                if package and self.coverPackages:\r\n                    for want in self.coverPackages:\r\n                        if package.startswith(want):\r\n                            return True\r\n                else:\r\n                    return True\r\n        return None","reference":"If inclusive coverage enabled, return true for all source files\n        in wanted packages.","result":" is in the cover list .","score":[0.0601,0.0407]}
{"code":"def interpret_distro_name(location, basename, metadata,\r\n    \"\"\" function to<extra_id_0>\r\n    py_version=None, precedence=SOURCE_DIST, platform=None\r\n):\r\n    parts = basename.split('-')\r\n    if not py_version:\r\n        for i,p in enumerate(parts[2:]):\r\n            if len(p)==5 and p.startswith('py2.'):\r\n                return\r\n    for p in range(1,len(parts)+1):\r\n        yield Distribution(\r\n            location, metadata, '-'.join(parts[:p]), '-'.join(parts[p:]),\r\n            py_version=py_version, precedence = precedence,\r\n            platform = platform\r\n        )","reference":"Generate alternative interpretations of a source distro name\n\n    Note: if `location` is a filesystem filename, you should call\n    ``pkg_resources.normalize_path()`` on it before passing it to this\n    routine!","result":"Interpret a distro name .","score":[0.0046,0.1273]}
{"code":"def open_with_auth(url):\r\n    \"\"\" function to<extra_id_0>\r\n    scheme, netloc, path, params, query, frag = urlparse.urlparse(url)\r\nif netloc.endswith(':'):\r\n        raise httplib.InvalidURL(\"nonnumeric port: ''\")\r\n    if scheme in ('http', 'https'):\r\n        auth, host = urllib2.splituser(netloc)\r\n    else:\r\n        auth = None\r\n    if auth:\r\n        auth = \"Basic \" + _encode_auth(auth)\r\n        new_url = urlparse.urlunparse((scheme,host,path,params,query,frag))\r\n        request = urllib2.Request(new_url)\r\n        request.add_header(\"Authorization\", auth)\r\n    else:\r\n        request = urllib2.Request(url)\r\n    request.add_header('User-Agent', user_agent)\r\n    fp = urllib2.urlopen(request)\r\n    if auth:\r\n        s2, h2, path2, param2, query2, frag2 = urlparse.urlparse(fp.url)\r\n        if s2==scheme and h2==host:\r\n            fp.url = urlparse.urlunparse((s2,netloc,path2,param2,query2,frag2))\r\n    return fp","reference":"Open a urllib2 request, handling HTTP authentication","result":"Open a URL with auth.","score":[0.2278,0.2757]}
{"code":"def fetch_distribution(self,\r\n        \"\"\" function to<extra_id_0>\r\n        requirement, tmpdir, force_scan=False, source=False, develop_ok=False,\r\n        local_index=None\r\n    ):\r\n        self.info(\"Searching for %s\", requirement)\r\n        skipped = {}\r\n        dist = None\r\n        def find(req, env=None):\r\n            if env is None:\r\n                env = self\r\n            for dist in env[req.key]:\r\n                if dist.precedence==DEVELOP_DIST and not develop_ok:\r\n                    if dist not in skipped:\r\n                        self.warn(\"Skipping development or system egg: %s\",dist)\r\n                        skipped[dist] = 1\r\n                    continue\r\n                if dist in req and (dist.precedence<=SOURCE_DIST or not source):\r\n                    self.info(\"Best match: %s\", dist)\r\n                    return dist.clone(\r\n                        location=self.download(dist.location, tmpdir)\r\n                    )\r\n        if force_scan:\r\n            self.prescan()\r\n            self.find_packages(requirement)\r\n            dist = find(requirement)\r\n        if local_index is not None:\r\n            dist = dist or find(requirement, local_index)\r\n        if dist is None and self.to_scan is not None:\r\n            self.prescan()\r\n            dist = find(requirement)\r\n        if dist is None and not force_scan:\r\n            self.find_packages(requirement)\r\n            dist = find(requirement)\r\n        if dist is None:\r\n            self.warn(\r\n                \"No local packages or download links found for %s%s\",\r\n                (source and \"a source distribution of \" or \"\"),\r\n                requirement,\r\n            )\r\n        return dist","reference":"Obtain a distribution suitable for fulfilling `requirement`\n\n        `requirement` must be a ``pkg_resources.Requirement`` instance.\n        If necessary, or if the `force_scan` flag is set, the requirement is\n        searched for in the (online) package index as well as the locally\n        installed packages.  If a distribution matching `requirement` is found,\n        the returned distribution's ``location`` is the value you would have\n        gotten from calling the ``download()`` method with the matching\n        distribution's URL or filename.  If no matching distribution is found,\n        ``None`` is returned.\n\n        If the `source` flag is set, only source distributions and source\n        checkout links will be considered.  Unless the `develop_ok` flag is\n        set, development and system eggs (i.e., those using the ``.egg-info``\n        format) will be ignored.","result":"Fetch a distribution from the index .","score":[0.0,0.0244]}
{"code":"def get_parent(obj):\r\n    \"\"\" function to<extra_id_0>\r\n    '''\r\n    get parent from obj.\r\n    '''\r\n    names = obj.__qualname__.split('.')[:-1]\r\n    if '<locals>' in names:\r\n        raise ValueError('cannot get parent from locals object.')\r\n    module = sys.modules[obj.__module__]\r\n    parent = module\r\n    while names:\r\n        parent = getattr(parent, names.pop(0))\r\n    return parent","reference":"get parent from obj.","result":"Get parent from obj.","score":[0.658,0.9922]}
{"code":"def root_topic(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if isinstance(getattr(self.engine, 'id', None), int):\r\n            return \"engine.%i\"%self.engine.id\r\n        else:\r\n            return \"engine\"","reference":"this is a property, in case the handler is created\n        before the engine gets registered with an id","result":"Def return the root topic .","score":[0.0261,0.0298]}
{"code":"def render_template(content, context):\r\n    \"\"\" function to<extra_id_0>\r\n    rendered = Template(content).render(Context(context))\r\n    return rendered","reference":"renders context aware template","result":"Render a template .","score":[0.3195,0.25]}
{"code":"def configure(self, options, conf):\r\n        \"\"\" function to<extra_id_0>\r\n        self.conf = conf\r\n        if not options.capture:\r\n            self.enabled = False","reference":"Configure plugin. Plugin is enabled by default.","result":"Configure the plugin .","score":[0.1509,0.1493]}
{"code":"def formatError(self, test, err):\r\n        \"\"\" function to<extra_id_0>\r\n        test.capturedOutput = output = self.buffer\r\n        self._buf = None\r\n        if not output:\r\n            return err\r\n        ec, ev, tb = err\r\n        return (ec, self.addCaptureToErr(ev, output), tb)","reference":"Add captured output to error report.","result":"Def format an error .","score":[0.1967,0.0847]}
{"code":"def splitBy(data, num):\r\n    \"\"\" function to<extra_id_0>\r\n    return [data[i:i + num] for i in range(0, len(data), num)]","reference":"Turn a list to list of list","result":"Split data by num .","score":[0,0.0]}
{"code":"def convert_to_this_nbformat(nb, orig_version=2, orig_minor=0):\r\n    \"\"\" function to<extra_id_0>\r\n    if orig_version == 1:\r\n        nb = v2.convert_to_this_nbformat(nb)\r\n        orig_version = 2\r\n    if orig_version == 2:\r\n        nb.nbformat = nbformat\r\n        nb.nbformat_minor = nbformat_minor\r\n                nb.orig_nbformat = 2\r\n        return nb\r\n    elif orig_version == 3:\r\n        if orig_minor != nbformat_minor:\r\n            nb.orig_nbformat_minor = orig_minor\r\n        nb.nbformat_minor = nbformat_minor\r\n        return nb\r\n    else:\r\n        raise ValueError('Cannot convert a notebook from v%s to v3' % orig_version)","reference":"Convert a notebook to the v3 format.\n\n    Parameters\n    ----------\n    nb : NotebookNode\n        The Python representation of the notebook to convert.\n    orig_version : int\n        The original version of the notebook to convert.\n    orig_minor : int\n        The original minor version of the notebook to convert (only relevant for v >= 3).","result":"Convert a notebook to this nbformat .","score":[0.0013,0.0705]}
{"code":"def hex_to_rgb(color):\r\n    \"\"\" function to<extra_id_0>\r\n    if color.startswith('\r\n        color = color[1:]\r\n    if len(color) == 3:\r\n        color = ''.join([c*2 for c in color])\r\n    if len(color) != 6:\r\n        return False\r\n    try:\r\n        r = int(color[:2],16)\r\n        g = int(color[2:4],16)\r\n        b = int(color[4:],16)\r\n    except ValueError:\r\n        return False\r\n    else:\r\n        return r,g,b","reference":"Convert a hex color to rgb integer tuple.","result":"Convert hex color to rgb .","score":[0.4578,0.6205]}
{"code":"def get_colors(stylename):\r\n    \"\"\" function to<extra_id_0>\r\n    style = get_style_by_name(stylename)\r\n    fgcolor = style.style_for_token(Token.Text)['color'] or ''\r\n    if len(fgcolor) in (3,6):\r\ntry:\r\n            int(fgcolor, 16)\r\n        except TypeError:\r\n            pass\r\n        else:\r\n            fgcolor = \"\r\n    return dict(\r\n        bgcolor = style.background_color,\r\n        select = style.highlight_color,\r\n        fgcolor = fgcolor\r\n    )","reference":"Construct the keys to be used building the base stylesheet\n    from a templatee.","result":"Get colors for stylename.","score":[0,0.0]}
{"code":"def get_font(family, fallback=None):\r\n    \"\"\" function to<extra_id_0>\r\n    font = QtGui.QFont(family)\r\n    font_info = QtGui.QFontInfo(font)\r\n    if fallback is not None and font_info.family() != family:\r\n        font = QtGui.QFont(fallback)\r\n    return font","reference":"Return a font of the requested family, using fallback as alternative.\n\n    If a fallback is provided, it is used in case the requested family isn't\n    found.  If no fallback is given, no alternative is chosen and Qt's internal\n    algorithms may automatically choose a fallback font.\n\n    Parameters\n    ----------\n    family : str\n      A font name.\n    fallback : str\n      A font name.\n\n    Returns\n    -------\n    font : QFont object","result":"Get a font .","score":[0.0,0.017]}
{"code":"def _handle_execute_reply(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        msg_id = msg['parent_header'].get('msg_id')\r\n        info = self._request_info['execute'].get(msg_id)\r\n        if info and info.kind == 'prompt':\r\n           number = msg['content']['execution_count'] + 1\r\n           self._show_interpreter_prompt(number)\r\n           self._request_info['execute'].pop(msg_id)\r\n        else:\r\n           super(IPythonWidget, self)._handle_execute_reply(msg)","reference":"Reimplemented to support prompt requests.","result":"Handle execute replies .","score":[0,0.0]}
{"code":"def _handle_history_reply(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        content = msg['content']\r\n        if 'history' not in content:\r\n            self.log.error(\"History request failed: %r\"%content)\r\n            if content.get('status', '') == 'aborted' and \\\r\n                                            not self._retrying_history_request:\r\n                self.log.error(\"Retrying aborted history request\")\r\n                self._retrying_history_request = True\r\n                time.sleep(0.25)\r\n                self.kernel_manager.shell_channel.history(hist_access_type='tail',n=1000)\r\n            else:\r\n                self._retrying_history_request = False\r\n            return\r\n        self._retrying_history_request = False\r\n        history_items = content['history']\r\n        self.log.debug(\"Received history reply with %i entries\", len(history_items))\r\n        items = []\r\n        last_cell = u\"\"\r\n        for _, _, cell in history_items:\r\n            cell = cell.rstrip()\r\n            if cell != last_cell:\r\n                items.append(cell)\r\n                last_cell = cell\r\n        self._set_history(items)","reference":"Implemented to handle history tail replies, which are only supported\n            by the IPython kernel.","result":"Handle history replies .","score":[0.0262,0.1442]}
{"code":"def _handle_pyout(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        self.log.debug(\"pyout: %s\", msg.get('content', ''))\r\n        if not self._hidden and self._is_from_this_session(msg):\r\n            content = msg['content']\r\n            prompt_number = content.get('execution_count', 0)\r\n            data = content['data']\r\n            if data.has_key('text\/html'):\r\n                self._append_plain_text(self.output_sep, True)\r\n                self._append_html(self._make_out_prompt(prompt_number), True)\r\n                html = data['text\/html']\r\n                self._append_plain_text('\\n', True)\r\n                self._append_html(html + self.output_sep2, True)\r\n            elif data.has_key('text\/plain'):\r\n                self._append_plain_text(self.output_sep, True)\r\n                self._append_html(self._make_out_prompt(prompt_number), True)\r\n                text = data['text\/plain']\r\n                if \"\\n\" in text and not self.output_sep.endswith(\"\\n\"):\r\n                    self._append_plain_text('\\n', True)\r\n                self._append_plain_text(text + self.output_sep2, True)","reference":"Reimplemented for IPython-style \"display hook\".","result":"Handle pyout messages .","score":[0,0.0]}
{"code":"def _handle_display_data(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        self.log.debug(\"display: %s\", msg.get('content', ''))\r\n        if not self._hidden and self._is_from_this_session(msg):\r\n            source = msg['content']['source']\r\n            data = msg['content']['data']\r\n            metadata = msg['content']['metadata']\r\n            if data.has_key('text\/html'):\r\n                html = data['text\/html']\r\n                self._append_html(html, True)\r\n            elif data.has_key('text\/plain'):\r\n                text = data['text\/plain']\r\n                self._append_plain_text(text, True)\r\n            self._append_plain_text(u'\\n', True)","reference":"The base handler for the ``display_data`` message.","result":"Handle display data .","score":[0,0.0]}
{"code":"def _started_channels(self):\r\n        \"\"\" function to<extra_id_0>\r\n        super(IPythonWidget, self)._started_channels()\r\n        self._load_guiref_magic()\r\n        self.kernel_manager.shell_channel.history(hist_access_type='tail',\r\n                                                  n=1000)","reference":"Reimplemented to make a history request and load %guiref.","result":"Call when the channels have been started .","score":[0,0.0562]}
{"code":"def execute_file(self, path, hidden=False):\r\n        \"\"\" function to<extra_id_0>\r\n        if sys.platform == 'win32':\r\n            path = os.path.normpath(path).replace('\\\\', '\/')\r\n                        if ' ' in path or \"'\" in path or '\"' in path:\r\n            path = '\"%s\"' % path.replace('\"', '\\\\\"')\r\n        self.execute('%%run %s' % path, hidden=hidden)","reference":"Reimplemented to use the 'run' magic.","result":"Execute a file .","score":[0,0.0]}
{"code":"def _process_execute_error(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        content = msg['content']\r\n        traceback = '\\n'.join(content['traceback']) + '\\n'\r\n        if False:\r\n            traceback = traceback.replace(' ', '&nbsp;')\r\n            traceback = traceback.replace('\\n', '<br\/>')\r\n            ename = content['ename']\r\n            ename_styled = '<span class=\"error\">%s<\/span>' % ename\r\n            traceback = traceback.replace(ename, ename_styled)\r\n            self._append_html(traceback)\r\n        else:\r\n            self._append_plain_text(traceback)","reference":"Reimplemented for IPython-style traceback formatting.","result":"Process execute error .","score":[0,0.0]}
{"code":"def _process_execute_payload(self, item):\r\n        \"\"\" function to<extra_id_0>\r\n        handler = self._payload_handlers.get(item['source'])\r\n        if handler is None:\r\n            return False\r\n        else:\r\n            handler(item)\r\n            return True","reference":"Reimplemented to dispatch payloads to handler methods.","result":"Process execute payload .","score":[0,0.0746]}
{"code":"def set_default_style(self, colors='lightbg'):\r\n        \"\"\" function to<extra_id_0>\r\n        colors = colors.lower()\r\n        if colors=='lightbg':\r\n            self.style_sheet = styles.default_light_style_sheet\r\n            self.syntax_style = styles.default_light_syntax_style\r\n        elif colors=='linux':\r\n            self.style_sheet = styles.default_dark_style_sheet\r\n            self.syntax_style = styles.default_dark_syntax_style\r\n        elif colors=='nocolor':\r\n            self.style_sheet = styles.default_bw_style_sheet\r\n            self.syntax_style = styles.default_bw_syntax_style\r\n        else:\r\n            raise KeyError(\"No such color scheme: %s\"%colors)","reference":"Sets the widget style to the class defaults.\n\n        Parameters:\n        -----------\n        colors : str, optional (default lightbg)\n            Whether to use the default IPython light background or dark\n            background or B&W style.","result":"Set default style .","score":[0.0006,0.0547]}
{"code":"def _edit(self, filename, line=None):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.custom_edit:\r\n            self.custom_edit_requested.emit(filename, line)\r\n        elif not self.editor:\r\n            self._append_plain_text('No default editor available.\\n'\r\n            'Specify a GUI text editor in the `IPythonWidget.editor` '\r\n            'configurable to enable the %edit magic')\r\n        else:\r\n            try:\r\n                filename = '\"%s\"' % filename\r\n                if line and self.editor_line:\r\n                    command = self.editor_line.format(filename=filename,\r\n                                                      line=line)\r\n                else:\r\n                    try:\r\n                        command = self.editor.format()\r\n                    except KeyError:\r\n                        command = self.editor.format(filename=filename)\r\n                    else:\r\n                        command += ' ' + filename\r\n            except KeyError:\r\n                self._append_plain_text('Invalid editor command.\\n')\r\n            else:\r\n                try:\r\n                    Popen(command, shell=True)\r\n                except OSError:\r\n                    msg = 'Opening editor with command \"%s\" failed.\\n'\r\n                    self._append_plain_text(msg % command)","reference":"Opens a Python script for editing.\n\n        Parameters:\n        -----------\n        filename : str\n            A path to a local system file.\n\n        line : int, optional\n            A line of interest in the file.","result":"Perform the editor magic .","score":[0.002,0.0188]}
{"code":"def _make_in_prompt(self, number):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            body = self.in_prompt % number\r\n        except TypeError:\r\n            body = self.in_prompt\r\n        return '<span class=\"in-prompt\">%s<\/span>' % body","reference":"Given a prompt number, returns an HTML In prompt.","result":"Make in.","score":[0,0.0]}
{"code":"def _make_continuation_prompt(self, prompt):\r\n        \"\"\" function to<extra_id_0>\r\n        end_chars = '...: '\r\n        space_count = len(prompt.lstrip('\\n')) - len(end_chars)\r\n        body = '&nbsp;' * space_count + end_chars\r\n        return '<span class=\"in-prompt\">%s<\/span>' % body","reference":"Given a plain text version of an In prompt, returns an HTML\n            continuation prompt.","result":"Def make a continuation prompt .","score":[0.0605,0.0758]}
{"code":"def _style_sheet_changed(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self.setStyleSheet(self.style_sheet)\r\n        if self._control is not None:\r\n            self._control.document().setDefaultStyleSheet(self.style_sheet)\r\n            bg_color = self._control.palette().window().color()\r\n            self._ansi_processor.set_background_color(bg_color)\r\n                if self._page_control is not None:\r\n            self._page_control.document().setDefaultStyleSheet(self.style_sheet)","reference":"Set the style sheets of the underlying widgets.","result":" is changed .","score":[0,0.0]}
{"code":"def _syntax_style_changed(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._highlighter is None:\r\n            return\r\n        if self.syntax_style:\r\n            self._highlighter.set_style(self.syntax_style)\r\n        else:\r\n            self._highlighter.set_style_sheet(self.style_sheet)","reference":"Set the style for the syntax highlighter.","result":"Be called when syntax style has changed .","score":[0.1652,0.1408]}
{"code":"async def _handle_response(self, response: aiohttp.client_reqrep.ClientResponse, await_final_result: bool) -> dict:\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            data = await response.json()\r\n        except aiohttp.client_exceptions.ContentTypeError:\r\n            text = await response.text()\r\n            logging.debug('Content returned by server not of type \"application\/json\"\\n Content: {}'.format(text))\r\n            raise CloudStackClientException(message=\"Could not decode content. Server did not return json content!\")\r\n        else:\r\n            data = self._transform_data(data)\r\n            if response.status != 200:\r\n                raise CloudStackClientException(message=\"Async CloudStack call failed!\",\r\n                                                error_code=data.get(\"errorcode\", response.status),\r\n                                                error_text=data.get(\"errortext\"),\r\n                                                response=data)\r\n        while await_final_result and ('jobid' in data):\r\n            await asyncio.sleep(self.async_poll_latency)\r\n            data = await self.queryAsyncJobResult(jobid=data['jobid'])\r\n            if data['jobstatus']:\r\n                if not data['jobresultcode']:\r\n                    try:\r\n                        return data['jobresult']\r\n                    except KeyError:\r\n                        pass\r\n                logging.debug(\"Async CloudStack call returned {}\".format(str(data)))\r\n                raise CloudStackClientException(message=\"Async CloudStack call failed!\",\r\n                                                error_code=data.get(\"errorcode\"),\r\n                                                error_text=data.get(\"errortext\"),\r\n                                                response=data)\r\n        return data","reference":"Handles the response returned from the CloudStack API. Some CloudStack API are implemented asynchronous, which\n        means that the API call returns just a job id. The actually expected API response is postponed and a specific\n        asyncJobResults API has to be polled using the job id to get the final result once the API call has been\n        processed.\n\n        :param response: The response returned by the aiohttp call.\n        :type response: aiohttp.client_reqrep.ClientResponse\n        :param await_final_result: Specifier that indicates whether the function should poll the asyncJobResult API\n                                   until the asynchronous API call has been processed\n        :type await_final_result: bool\n        :return: Dictionary containing the JSON response of the API call\n        :rtype: dict","result":"If not response.","score":[0,0.0]}
{"code":"def _sign(self, url_parameters: dict) -> dict:\r\n        \"\"\" function to<extra_id_0>\r\n        if url_parameters:\r\n            url_parameters.pop('signature', None)\r\n            request_string = urlencode(sorted(url_parameters.items()), safe='.-*_', quote_via=quote).lower()\r\n            digest = hmac.new(self.api_secret.encode('utf-8'), request_string.encode('utf-8'), hashlib.sha1).digest()\r\n            url_parameters['signature'] = base64.b64encode(digest).decode('utf-8').strip()\r\n        return url_parameters","reference":"According to the CloudStack documentation, each request needs to be signed in order to authenticate the user\n        account executing the API command. The signature is generated using a combination of the api secret and a SHA-1\n        hash of the url parameters including the command string. In order to generate a unique identifier, the url\n        parameters have to be transformed to lower case and ordered alphabetically.\n\n        :param url_parameters: The url parameters of the API call including the command string\n        :type url_parameters: dict\n        :return: The url parameters including a new key, which contains the signature\n        :rtype: dict","result":"Parameters .","score":[0,0.0058]}
{"code":"def _transform_data(data: dict) -> dict:\r\n        \"\"\" function to<extra_id_0>\r\n        for key in data.keys():\r\n            return_value = data[key]\r\n            if isinstance(return_value, dict):\r\n                return return_value\r\n        return data","reference":"Each CloudStack API call returns a nested dictionary structure. The first level contains only one key indicating\n        the API that originated the response. This function removes that first level from the data returned to the\n        caller.\n\n        :param data: Response of the API call\n        :type data: dict\n        :return: Simplified response without the information about the API that originated the response.\n        :rtype: dict","result":"Transform data .","score":[0.0,0.0091]}
{"code":"def virtual_memory():\r\n    \"\"\" function to<extra_id_0>\r\n    mem =  _psutil_bsd.get_virtual_mem()\r\n    total, free, active, inactive, wired, cached, buffers, shared = mem\r\n    avail = inactive + cached + free\r\n    used =  active + wired + cached\r\n    percent = usage_percent((total - avail), total, _round=1)\r\n    return nt_virtmem_info(total, avail, percent, used, free,\r\n                           active, inactive, buffers, cached, shared, wired)","reference":"System virtual memory as a namedutple.","result":"Get virtual memory information .","score":[0.2782,0.3178]}
{"code":"def get_system_cpu_times():\r\n    \"\"\" function to<extra_id_0>\r\n    user, nice, system, idle, irq = _psutil_bsd.get_system_cpu_times()\r\n    return _cputimes_ntuple(user, nice, system, idle, irq)","reference":"Return system per-CPU times as a named tuple","result":"Get system cpu times .","score":[0.1568,0.1299]}
{"code":"def get_process_uids(self):\r\n        \"\"\" function to<extra_id_0>\r\n        real, effective, saved = _psutil_bsd.get_process_uids(self.pid)\r\n        return nt_uids(real, effective, saved)","reference":"Return real, effective and saved user ids.","result":"Get process UIDs .","score":[0,0.0]}
{"code":"def get_process_gids(self):\r\n        \"\"\" function to<extra_id_0>\r\n        real, effective, saved = _psutil_bsd.get_process_gids(self.pid)\r\n        return nt_gids(real, effective, saved)","reference":"Return real, effective and saved group ids.","result":"Get process gids .","score":[0,0.0]}
{"code":"def get_process_threads(self):\r\n        \"\"\" function to<extra_id_0>\r\n        rawlist = _psutil_bsd.get_process_threads(self.pid)\r\n        retlist = []\r\n        for thread_id, utime, stime in rawlist:\r\n            ntuple = nt_thread(thread_id, utime, stime)\r\n            retlist.append(ntuple)\r\n        return retlist","reference":"Return the number of threads belonging to the process.","result":"Get process threads .","score":[0.0915,0.0588]}
{"code":"def get_open_files(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if hasattr(_psutil_bsd, \"get_process_open_files\"):\r\n            rawlist = _psutil_bsd.get_process_open_files(self.pid)\r\n            return [nt_openfile(path, fd) for path, fd in rawlist]\r\n        else:\r\n            lsof = _psposix.LsofParser(self.pid, self._process_name)\r\n            return lsof.get_process_open_files()","reference":"Return files opened by process as a list of namedtuples.","result":"Get open files .","score":[0.0713,0.1064]}
{"code":"def pkg_commit_hash(pkg_path):\r\n    \"\"\" function to<extra_id_0>\r\n    if _sysinfo.commit:\r\n        return \"installation\", _sysinfo.commit\r\n    proc = subprocess.Popen('git rev-parse --short HEAD',\r\n                            stdout=subprocess.PIPE,\r\n                            stderr=subprocess.PIPE,\r\n                            cwd=pkg_path, shell=True)\r\n    repo_commit, _ = proc.communicate()\r\n    if repo_commit:\r\n        return 'repository', repo_commit.strip()\r\n    return '(none found)', '<not found>'","reference":"Get short form of commit hash given directory `pkg_path`\n\n    We get the commit hash from (in order of preference):\n\n    * IPython.utils._sysinfo.commit\n    * git output, if we are in a git repository\n\n    If these fail, we return a not-found placeholder tuple\n\n    Parameters\n    ----------\n    pkg_path : str\n       directory containing package\n       only used for getting commit from active repo\n\n    Returns\n    -------\n    hash_from : str\n       Where we got the hash from - description\n    hash_str : str\n       short form of hash","result":"Get pkg commit hash .","score":[0.0,0.0218]}
{"code":"def pkg_info(pkg_path):\r\n    \"\"\" function to<extra_id_0>\r\n    src, hsh = pkg_commit_hash(pkg_path)\r\n    return dict(\r\n        ipython_version=release.version,\r\n        ipython_path=pkg_path,\r\n        commit_source=src,\r\n        commit_hash=hsh,\r\n        sys_version=sys.version,\r\n        sys_executable=sys.executable,\r\n        sys_platform=sys.platform,\r\n        platform=platform.platform(),\r\n        os_name=os.name,\r\n        default_encoding=encoding.DEFAULT_ENCODING,\r\n        )","reference":"Return dict describing the context of this package\n\n    Parameters\n    ----------\n    pkg_path : str\n       path containing __init__.py for package\n\n    Returns\n    -------\n    context : dict\n       with named parameters of interest","result":"Get pkg info .","score":[0,0.0]}
{"code":"def sys_info():\r\n    \"\"\" function to<extra_id_0>\r\n    p = os.path\r\n    path = p.dirname(p.abspath(p.join(__file__, '..')))\r\n    return pprint.pformat(pkg_info(path))","reference":"Return useful information about IPython and the system, as a string.\n\n    Example\n    -------\n    In [2]: print sys_info()\n    {'commit_hash': '144fdae',      # random\n     'commit_source': 'repository',\n     'ipython_path': '\/home\/fperez\/usr\/lib\/python2.6\/site-packages\/IPython',\n     'ipython_version': '0.11.dev',\n     'os_name': 'posix',\n     'platform': 'Linux-2.6.35-22-generic-i686-with-Ubuntu-10.10-maverick',\n     'sys_executable': '\/usr\/bin\/python',\n     'sys_platform': 'linux2',\n     'sys_version': '2.6.6 (r266:84292, Sep 15 2010, 15:52:39) \\\\n[GCC 4.4.5]'}","result":"Get system info .","score":[0,0.0]}
{"code":"def _num_cpus_darwin():\r\n    \"\"\" function to<extra_id_0>\r\n    p = subprocess.Popen(['sysctl','-n','hw.ncpu'],stdout=subprocess.PIPE)\r\n    return p.stdout.read()","reference":"Return the number of active CPUs on a Darwin system.","result":"Get the number of CPUs on the system .","score":[0.2742,0.4505]}
{"code":"def num_cpus():\r\n   \"\"\" function to<extra_id_0>\r\n   ncpufuncs = {'Linux':_num_cpus_unix,\r\n                'Darwin':_num_cpus_darwin,\r\n                'Windows':_num_cpus_windows,\r\n                'Microsoft':_num_cpus_windows,\r\n                }\r\n   ncpufunc = ncpufuncs.get(platform.system(),\r\n                            _num_cpus_unix)\r\n   try:\r\n       ncpus = max(1,int(ncpufunc()))\r\n   except:\r\n       ncpus = 1\r\n   return ncpus","reference":"Return the effective number of CPUs in the system as an integer.\n\n   This cross-platform function makes an attempt at finding the total number of\n   available CPUs in the system, as returned by various underlying system and\n   python calls.\n\n   If it can't find a sensible answer, it returns 1 (though an error *may* make\n   it return a large positive number that's actually incorrect).","result":"Get number of CPUs .","score":[0.0,0.0355]}
{"code":"def nextset(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._executed:\r\n            self.fetchall()\r\n        del self.messages[:]\r\n                db = self._get_db()\r\n        nr = db.next_result()\r\n        if nr == -1:\r\n            return None\r\n        self._do_get_result()\r\n        self._post_get_result()\r\n        self._warning_check()\r\n        return 1","reference":"Advance to the next result set.\n\n        Returns None if there are no more result sets.","result":"Get the next set .","score":[0.046,0.1339]}
{"code":"def fetchone(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self._check_executed()\r\n        r = self._fetch_row(1)\r\n        if not r:\r\n            self._warning_check()\r\n            return None\r\n        self.rownumber = self.rownumber + 1\r\n        return r[0]","reference":"Fetches a single row from the cursor.","result":"Fetch a single row .","score":[0.3318,0.5836]}
{"code":"def fetchmany(self, size=None):\r\n        \"\"\" function to<extra_id_0>\r\n        self._check_executed()\r\n        r = self._fetch_row(size or self.arraysize)\r\n        self.rownumber = self.rownumber + len(r)\r\n        if not r:\r\n            self._warning_check()\r\n        return r","reference":"Fetch up to size rows from the cursor. Result set may be smaller\n        than size. If size is not defined, cursor.arraysize is used.","result":"Fetch many rows .","score":[0.0033,0.0474]}
{"code":"def fetchall(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self._check_executed()\r\n        r = self._fetch_row(0)\r\n        self.rownumber = self.rownumber + len(r)\r\n        self._warning_check()\r\n        return r","reference":"Fetchs all available rows from the cursor.","result":"Fetch all rows .","score":[0.1795,0.3814]}
{"code":"def connect(com, peers, tree, pub_url, root_id):\r\n    \"\"\" function to<extra_id_0>\r\n    com.connect(peers, tree, pub_url, root_id)","reference":"this function will be called on the engines","result":"Connect to the com .","score":[0.1319,0.0649]}
{"code":"def reads_json(s, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    nbf, minor, d = parse_json(s, **kwargs)\r\n    if nbf == 1:\r\n        nb = v1.to_notebook_json(d, **kwargs)\r\n        nb = v3.convert_to_this_nbformat(nb, orig_version=1)\r\n    elif nbf == 2:\r\n        nb = v2.to_notebook_json(d, **kwargs)\r\n        nb = v3.convert_to_this_nbformat(nb, orig_version=2)\r\n    elif nbf == 3:\r\n        nb = v3.to_notebook_json(d, **kwargs)\r\n        nb = v3.convert_to_this_nbformat(nb, orig_version=3, orig_minor=minor)\r\n    else:\r\n        raise NBFormatError('Unsupported JSON nbformat version: %i' % nbf)\r\n    return nb","reference":"Read a JSON notebook from a string and return the NotebookNode object.","result":"Read JSON data .","score":[0.0514,0.0893]}
{"code":"def reads_py(s, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    nbf, nbm, s = parse_py(s, **kwargs)\r\n    if nbf == 2:\r\n        nb = v2.to_notebook_py(s, **kwargs)\r\n    elif nbf == 3:\r\n        nb = v3.to_notebook_py(s, **kwargs)\r\n    else:\r\n        raise NBFormatError('Unsupported PY nbformat version: %i' % nbf)\r\n    return nb","reference":"Read a .py notebook from a string and return the NotebookNode object.","result":"Read a PY notebook .","score":[0.0927,0.1327]}
{"code":"def reads(s, format, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    format = unicode(format)\r\n    if format == u'json' or format == u'ipynb':\r\n        return reads_json(s, **kwargs)\r\n    elif format == u'py':\r\n        return reads_py(s, **kwargs)\r\n    else:\r\n        raise NBFormatError('Unsupported format: %s' % format)","reference":"Read a notebook from a string and return the NotebookNode object.\n\n    This function properly handles notebooks of any version. The notebook\n    returned will always be in the current version's format.\n\n    Parameters\n    ----------\n    s : unicode\n        The raw unicode string to read the notebook from.\n    format : (u'json', u'ipynb', u'py')\n        The format that the string is in.\n\n    Returns\n    -------\n    nb : NotebookNode\n        The notebook that was read.","result":"Read a string into a format .","score":[0.0001,0.0416]}
{"code":"def writes(nb, format, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    format = unicode(format)\r\n    if format == u'json' or format == u'ipynb':\r\n        return writes_json(nb, **kwargs)\r\n    elif format == u'py':\r\n        return writes_py(nb, **kwargs)\r\n    else:\r\n        raise NBFormatError('Unsupported format: %s' % format)","reference":"Write a notebook to a string in a given format in the current nbformat version.\n\n    This function always writes the notebook in the current nbformat version.\n\n    Parameters\n    ----------\n    nb : NotebookNode\n        The notebook to write.\n    format : (u'json', u'ipynb', u'py')\n        The format to write the notebook in.\n\n    Returns\n    -------\n    s : unicode\n        The notebook string.","result":"Write notebook to specified format.","score":[0.0,0.03]}
{"code":"def write(nb, fp, format, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    return fp.write(writes(nb, format, **kwargs))","reference":"Write a notebook to a file in a given format in the current nbformat version.\n\n    This function always writes the notebook in the current nbformat version.\n\n    Parameters\n    ----------\n    nb : NotebookNode\n        The notebook to write.\n    fp : file\n        Any file-like object with a write method.\n    format : (u'json', u'ipynb', u'py')\n        The format to write the notebook in.\n\n    Returns\n    -------\n    s : unicode\n        The notebook string.","result":"Write a notebook to file .","score":[0.0,0.0423]}
{"code":"def _convert_to_metadata():\r\n    \"\"\" function to<extra_id_0>\r\n    import glob\r\n    for fname in glob.glob('*.ipynb'):\r\n        print('Converting file:',fname)\r\n        with open(fname,'r') as f:\r\n            nb = read(f,u'json')\r\n        md = new_metadata()\r\n        if u'name' in nb:\r\n            md.name = nb.name\r\n            del nb[u'name']            \r\n        nb.metadata = md\r\n        with open(fname,'w') as f:\r\n            write(nb, f, u'json')","reference":"Convert to a notebook having notebook metadata.","result":"Convert files to metadata .","score":[0.1915,0.1471]}
{"code":"def load_from_dict(self, src: dict, key):\r\n        \"\"\" function to<extra_id_0>\r\n        '''\r\n        try load value from dict.\r\n        if key is not exists, mark as state unset.\r\n        '''\r\n        if key in src:\r\n            self.value = src[key]\r\n        else:\r\n            self.reset()","reference":"try load value from dict.\n        if key is not exists, mark as state unset.","result":"Def load value from dict .","score":[0.1048,0.2231]}
{"code":"def matches(self, name):\r\n        \"\"\" function to<extra_id_0>\r\n        return ((self.match.search(name)\r\n                 or (self.include and\r\n                     filter(None,\r\n                            [inc.search(name) for inc in self.include])))\r\n                and ((not self.exclude)\r\n                     or not filter(None,\r\n                                   [exc.search(name) for exc in self.exclude])\r\n                 ))","reference":"Does the name match my requirements?\n\n        To match, a name must match config.testMatch OR config.include\n        and it must not match config.exclude","result":"Check if a name matches the pattern .","score":[0.0428,0.1888]}
{"code":"def wantClass(self, cls):\r\n        \"\"\" function to<extra_id_0>\r\n        declared = getattr(cls, '__test__', None)\r\n        if declared is not None:\r\n            wanted = declared\r\n        else:\r\n            wanted = (not cls.__name__.startswith('_')\r\n                      and (issubclass(cls, unittest.TestCase)\r\n                           or self.matches(cls.__name__)))\r\n                plug_wants = self.plugins.wantClass(cls)        \r\n        if plug_wants is not None:\r\n            log.debug(\"Plugin setting selection of %s to %s\", cls, plug_wants)\r\n            wanted = plug_wants\r\n        log.debug(\"wantClass %s? %s\", cls, wanted)\r\n        return wanted","reference":"Is the class a wanted test class?\n\n        A class must be a unittest.TestCase subclass, or match test name\n        requirements. Classes that start with _ are always excluded.","result":"Decide if a class should be tested .","score":[0.017,0.0797]}
{"code":"def wantDirectory(self, dirname):\r\n        \"\"\" function to<extra_id_0>\r\n        tail = op_basename(dirname)\r\n        if ispackage(dirname):\r\n            wanted = (not self.exclude\r\n                      or not filter(None,\r\n                                    [exc.search(tail) for exc in self.exclude]\r\n                                    ))\r\n        else:\r\n            wanted = (self.matches(tail)\r\n                      or (self.config.srcDirs\r\n                          and tail in self.config.srcDirs))\r\n        plug_wants = self.plugins.wantDirectory(dirname)\r\n        if plug_wants is not None:\r\n            log.debug(\"Plugin setting selection of %s to %s\",\r\n                      dirname, plug_wants)\r\n            wanted = plug_wants\r\n        log.debug(\"wantDirectory %s? %s\", dirname, wanted)\r\n        return wanted","reference":"Is the directory a wanted test directory?\n\n        All package directories match, so long as they do not match exclude. \n        All other directories must match test requirements.","result":" is wanted .","score":[0.0002,0.0422]}
{"code":"def wantFile(self, file):\r\n        \"\"\" function to<extra_id_0>\r\n        base = op_basename(file)\r\n        ignore_matches = [ ignore_this for ignore_this in self.ignoreFiles\r\n                           if ignore_this.search(base) ]\r\n        if ignore_matches:\r\n            log.debug('%s matches ignoreFiles pattern; skipped',\r\n                      base) \r\n            return False\r\n        if not self.config.includeExe and os.access(file, os.X_OK):\r\n            log.info('%s is executable; skipped', file)\r\n            return False\r\n        dummy, ext = op_splitext(base)\r\n        pysrc = ext == '.py'\r\n        wanted = pysrc and self.matches(base) \r\n        plug_wants = self.plugins.wantFile(file)\r\n        if plug_wants is not None:\r\n            log.debug(\"plugin setting want %s to %s\", file, plug_wants)\r\n            wanted = plug_wants\r\n        log.debug(\"wantFile %s? %s\", file, wanted)\r\n        return wanted","reference":"Is the file a wanted test file?\n\n        The file must be a python source file and match testMatch or\n        include, and not match exclude. Files that match ignore are *never*\n        wanted, regardless of plugin, testMatch, include or exclude settings.","result":"Determine if a file should be tested .","score":[0.0038,0.0557]}
{"code":"def wantFunction(self, function):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            if hasattr(function, 'compat_func_name'):\r\n                funcname = function.compat_func_name\r\n            else:\r\n                funcname = function.__name__\r\n        except AttributeError:\r\n            return False\r\n        declared = getattr(function, '__test__', None)\r\n        if declared is not None:\r\n            wanted = declared\r\n        else:\r\n            wanted = not funcname.startswith('_') and self.matches(funcname)\r\n        plug_wants = self.plugins.wantFunction(function)\r\n        if plug_wants is not None:\r\n            wanted = plug_wants\r\n        log.debug(\"wantFunction %s? %s\", function, wanted)\r\n        return wanted","reference":"Is the function a test function?","result":" is wanted .","score":[0,0.0877]}
{"code":"def wantMethod(self, method):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            method_name = method.__name__\r\n        except AttributeError:\r\n            return False\r\n        if method_name.startswith('_'):\r\n            return False\r\n        declared = getattr(method, '__test__', None)\r\n        if declared is not None:\r\n            wanted = declared\r\n        else:\r\n            wanted = self.matches(method_name)\r\n        plug_wants = self.plugins.wantMethod(method)\r\n        if plug_wants is not None:\r\n            wanted = plug_wants\r\n        log.debug(\"wantMethod %s? %s\", method, wanted)\r\n        return wanted","reference":"Is the method a test method?","result":" is wanted .","score":[0,0.0877]}
{"code":"def wantModule(self, module):\r\n        \"\"\" function to<extra_id_0>\r\n        declared = getattr(module, '__test__', None)\r\n        if declared is not None:\r\n            wanted = declared\r\n        else:\r\n            wanted = self.matches(module.__name__.split('.')[-1]) \\\r\n                     or module.__name__ == '__main__'\r\n        plug_wants = self.plugins.wantModule(module)\r\n        if plug_wants is not None:\r\n            wanted = plug_wants\r\n        log.debug(\"wantModule %s? %s\", module, wanted)\r\n        return wanted","reference":"Is the module a test module?\n\n        The tail of the module name must match test requirements. One exception:\n        we always want __main__.","result":" is wanted .","score":[0,0.0498]}
{"code":"def _file_lines(fname):\r\n    \"\"\" function to<extra_id_0>\r\n    try:\r\n        outfile = open(fname)\r\n    except IOError:\r\n        return []\r\n    else:\r\n        out = outfile.readlines()\r\n        outfile.close()\r\n        return out","reference":"Return the contents of a named file as a list of lines.\n\n    This function never raises an IOError exception: if the file can't be\n    read, it simply returns an empty list.","result":"Return file lines .","score":[0.0004,0.0353]}
{"code":"def list_command_pydb(self, arg):\r\n        \"\"\" function to<extra_id_0>\r\n        filename, first, last = OldPdb.parse_list_cmd(self, arg)\r\n        if filename is not None:\r\n            self.print_list_lines(filename, first, last)","reference":"List command to use if we have a newer pydb installed","result":"List commands .","score":[0.0284,0.1838]}
{"code":"def print_list_lines(self, filename, first, last):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            Colors = self.color_scheme_table.active_colors\r\n            ColorsNormal = Colors.Normal\r\n            tpl_line = '%%s%s%%s %s%%s' % (Colors.lineno, ColorsNormal)\r\n            tpl_line_em = '%%s%s%%s %s%%s%s' % (Colors.linenoEm, Colors.line, ColorsNormal)\r\n            src = []\r\n            for lineno in range(first, last+1):\r\n                line = linecache.getline(filename, lineno)\r\n                if not line:\r\n                    break\r\n                if lineno == self.curframe.f_lineno:\r\n                    line = self.__format_line(tpl_line_em, filename, lineno, line, arrow = True)\r\n                else:\r\n                    line = self.__format_line(tpl_line, filename, lineno, line, arrow = False)\r\n                src.append(line)\r\n                self.lineno = lineno\r\n            print >>io.stdout, ''.join(src)\r\n        except KeyboardInterrupt:\r\n            pass","reference":"The printing (as opposed to the parsing part of a 'list'\n        command.","result":"Print list lines .","score":[0,0.0446]}
{"code":"def do_pdef(self, arg):\r\n        \"\"\" function to<extra_id_0>\r\n        namespaces = [('Locals', self.curframe.f_locals),\r\n                      ('Globals', self.curframe.f_globals)]\r\n        self.shell.find_line_magic('pdef')(arg, namespaces=namespaces)","reference":"The debugger interface to magic_pdef","result":"Call pdef .","score":[0,0.0]}
{"code":"def conversion_factor(from_symbol, to_symbol, date):\r\n    \"\"\" function to<extra_id_0>\r\n    from_currency = Currency.objects.get(symbol=from_symbol)\r\n    try:\r\n        from_currency_price = CurrencyPrice.objects.get(currency=from_currency, date=date).mid_price\r\n    except CurrencyPrice.DoesNotExist:\r\n        print \"Cannot fetch prices for %s on %s\" % (str(from_currency), str(date))\r\n        return None\r\n    to_currency = Currency.objects.get(symbol=to_symbol)\r\n    try:\r\n        to_currency_price = CurrencyPrice.objects.get(currency=to_currency, date=date).mid_price\r\n    except CurrencyPrice.DoesNotExist:\r\n        print \"Cannot fetch prices for %s on %s\" % (str(to_currency), str(date))\r\n        return None\r\n    return to_currency_price \/ from_currency_price","reference":"Generates a multiplying factor used to convert two currencies","result":"Calculate the conversion factor .","score":[0.108,0.0581]}
{"code":"def convert_currency(from_symbol, to_symbol, value, date):\r\n    \"\"\" function to<extra_id_0>\r\n    if from_symbol == to_symbol:\r\n        return value\r\n    factor = conversion_factor(from_symbol, to_symbol, date)\r\n    if type(value) == float:\r\n        output = value * float(factor)\r\n    elif type(value) == Decimal:\r\n        output = Decimal(format(value * factor, '.%sf' % str(PRICE_PRECISION)))\r\n    elif type(value) in [np.float16, np.float32, np.float64, np.float128, np.float]:\r\n        output = float(value) * float(factor)\r\n    else:\r\n        output = None\r\n    return output","reference":"Converts an amount of money from one currency to another on a specified date.","result":"Convert currency .","score":[0.0104,0.0775]}
{"code":"def compute_return(self, start_date, end_date, rate=\"MID\"):\r\n        \"\"\" function to<extra_id_0>\r\n        if rate not in [\"MID\", \"ASK\", \"BID\"]:\r\n            raise ValueError(\"Unknown rate type (%s)- must be 'MID', 'ASK' or 'BID'\" % str(rate))\r\n        if end_date <= start_date:\r\n            raise ValueError(\"End date must be on or after start date\")\r\n        df = self.generate_dataframe(start_date=start_date, end_date=end_date)\r\n        start_price = df.ix[start_date][rate]\r\n        end_price = df.ix[end_date][rate]\r\n        currency_return = (end_price \/ start_price) - 1.0\r\n        return currency_return","reference":"Compute the return of the currency between two dates","result":"Compute return for a given period .","score":[0.1443,0.1136]}
{"code":"def get_stream_enc(stream, default=None):\r\n    \"\"\" function to<extra_id_0>\r\n    if not hasattr(stream, 'encoding') or not stream.encoding:\r\n        return default\r\n    else:\r\n        return stream.encoding","reference":"Return the given stream's encoding or a default.\n\n    There are cases where sys.std* might not actually be a stream, so\n    check for the encoding attribute prior to returning it, and return\n    a default if it doesn't exist or evaluates as False. `default'\n    is None if not provided.","result":"Get stream encoding .","score":[0.0,0.0117]}
{"code":"def getdefaultencoding():\r\n    \"\"\" function to<extra_id_0>\r\n    enc = get_stream_enc(sys.stdin)\r\n    if not enc or enc=='ascii':\r\n        try:\r\n            enc = locale.getpreferredencoding()\r\n        except Exception:\r\n            pass\r\n    return enc or sys.getdefaultencoding()","reference":"Return IPython's guess for the default encoding for bytes as text.\n\n    Asks for stdin.encoding first, to match the calling Terminal, but that\n    is often None for subprocesses.  Fall back on locale.getpreferredencoding()\n    which should be a sensible platform default (that respects LANG environment),\n    and finally to sys.getdefaultencoding() which is the most conservative option,\n    and usually ASCII.","result":"Get default encoding .","score":[0.0,0.02]}
{"code":"def write_connection_file(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if os.path.basename(self.connection_file) == self.connection_file:\r\n            cf = os.path.join(self.profile_dir.security_dir, self.connection_file)\r\n        else:\r\n            cf = self.connection_file\r\n        write_connection_file(cf, ip=self.ip, key=self.session.key,\r\n        shell_port=self.shell_port, stdin_port=self.stdin_port, hb_port=self.hb_port,\r\n        iopub_port=self.iopub_port)\r\n                self._full_connection_file = cf","reference":"write connection info to JSON file","result":"Def write the connection file .","score":[0.2541,0.25]}
{"code":"def init_heartbeat(self):\r\n        \"\"\" function to<extra_id_0>\r\n        hb_ctx = zmq.Context()\r\n        self.heartbeat = Heartbeat(hb_ctx, (self.ip, self.hb_port))\r\n        self.hb_port = self.heartbeat.port\r\n        self.log.debug(\"Heartbeat REP Channel on port: %i\"%self.hb_port)\r\n        self.heartbeat.start()\r\n        self.log.critical(\"To connect another client to this kernel, use:\")","reference":"start the heart beating","result":"Def initialize heartbeat .","score":[0,0.125]}
{"code":"def log_connection_info(self):\r\n        \"\"\" function to<extra_id_0>\r\n        basename = os.path.basename(self.connection_file)\r\n        if basename == self.connection_file or \\\r\n            os.path.dirname(self.connection_file) == self.profile_dir.security_dir:\r\n            tail = basename\r\n            if self.profile != 'default':\r\n                tail += \" --profile %s\" % self.profile\r\n        else:\r\n            tail = self.connection_file\r\n        self.log.critical(\"--existing %s\", tail)\r\n        self.ports = dict(shell=self.shell_port, iopub=self.iopub_port,\r\n                                stdin=self.stdin_port, hb=self.hb_port)","reference":"display connection info, and store ports","result":"Log connection info .","score":[0.1938,0.0862]}
{"code":"def init_session(self):\r\n        \"\"\" function to<extra_id_0>\r\n        default_secure(self.config)\r\n        self.session = Session(config=self.config, username=u'kernel')","reference":"create our session object","result":"Init session .","score":[0.2925,0.1282]}
{"code":"def init_io(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.outstream_class:\r\n            outstream_factory = import_item(str(self.outstream_class))\r\n            sys.stdout = outstream_factory(self.session, self.iopub_socket, u'stdout')\r\n            sys.stderr = outstream_factory(self.session, self.iopub_socket, u'stderr')\r\n        if self.displayhook_class:\r\n            displayhook_factory = import_item(str(self.displayhook_class))\r\n            sys.displayhook = displayhook_factory(self.session, self.iopub_socket)","reference":"Redirect input streams and set a display hook.","result":"Initialize the IO .","score":[0,0.0]}
{"code":"def init_kernel(self):\r\n        \"\"\" function to<extra_id_0>\r\n        kernel_factory = import_item(str(self.kernel_class))\r\n        self.kernel = kernel_factory(config=self.config, session=self.session,\r\n                                shell_socket=self.shell_socket,\r\n                                iopub_socket=self.iopub_socket,\r\n                                stdin_socket=self.stdin_socket,\r\n                                log=self.log\r\n        )\r\n        self.kernel.record_ports(self.ports)","reference":"Create the Kernel object itself","result":"Initialize the kernel .","score":[0.2488,0.3827]}
{"code":"def init_connector(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self.using_ssh = bool(self.sshkey or self.sshserver)\r\n        if self.sshkey and not self.sshserver:\r\n            self.sshserver = self.url.split(':\/\/')[1].split(':')[0]\r\n        if self.using_ssh:\r\n            if tunnel.try_passwordless_ssh(self.sshserver, self.sshkey, self.paramiko):\r\n                password=False\r\n            else:\r\n                password = getpass(\"SSH Password for %s: \"%self.sshserver)\r\n        else:\r\n            password = False\r\n        def connect(s, url):\r\n            url = disambiguate_url(url, self.location)\r\n            if self.using_ssh:\r\n                self.log.debug(\"Tunneling connection to %s via %s\"%(url, self.sshserver))\r\n                return tunnel.tunnel_connection(s, url, self.sshserver,\r\n                            keyfile=self.sshkey, paramiko=self.paramiko,\r\n                            password=password,\r\n                )\r\n            else:\r\n                return s.connect(url)\r\n        def maybe_tunnel(url):\r\n            url = disambiguate_url(url, self.location)\r\n            if self.using_ssh:\r\n                self.log.debug(\"Tunneling connection to %s via %s\"%(url, self.sshserver))\r\n                url,tunnelobj = tunnel.open_tunnel(url, self.sshserver,\r\n                            keyfile=self.sshkey, paramiko=self.paramiko,\r\n                            password=password,\r\n                )\r\n            return url\r\n        return connect, maybe_tunnel","reference":"construct connection function, which handles tunnels.","result":"Def initialize the connector .","score":[0,0.0]}
{"code":"def register(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self.log.info(\"Registering with controller at %s\"%self.url)\r\n        ctx = self.context\r\n        connect,maybe_tunnel = self.init_connector()\r\n        reg = ctx.socket(zmq.DEALER)\r\n        reg.setsockopt(zmq.IDENTITY, self.bident)\r\n        connect(reg, self.url)\r\n        self.registrar = zmqstream.ZMQStream(reg, self.loop)\r\n        content = dict(queue=self.ident, heartbeat=self.ident, control=self.ident)\r\n        self.registrar.on_recv(lambda msg: self.complete_registration(msg, connect, maybe_tunnel))\r\n        self.session.send(self.registrar, \"registration_request\",content=content)","reference":"send the registration_request","result":"Register with controller .","score":[0,0.0]}
{"code":"def html_to_text(content):\r\n    \"\"\" function to<extra_id_0>\r\n    text = None\r\n    h2t = html2text.HTML2Text()\r\n    h2t.ignore_links = False\r\n    text = h2t.handle(content)\r\n    return text","reference":"Converts html content to plain text","result":"Convert html to text .","score":[0.2589,0.535]}
{"code":"def md_to_text(content):\r\n    \"\"\" function to<extra_id_0>\r\n    text = None\r\n    html = markdown.markdown(content)\r\n    if html:\r\n        text = html_to_text(content)\r\n    return text","reference":"Converts markdown content to text","result":"Convert markdown to text .","score":[0.3761,0.75]}
{"code":"def domain_to_fqdn(domain, proto=None):\r\n    \"\"\" function to<extra_id_0>\r\n    from .generic import get_site_proto\r\n    proto = proto or get_site_proto()\r\n    fdqn = '{proto}:\/\/{domain}'.format(proto=proto, domain=domain)\r\n    return fdqn","reference":"returns a fully qualified app domain name","result":"Def convert domain to FQDN .","score":[0.1634,0.0725]}
{"code":"def options(self, parser, env=os.environ):\r\n        \"\"\" function to<extra_id_0>\r\n        super(NoseExclude, self).options(parser, env)\r\n        env_dirs = []\r\n        if 'NOSE_EXCLUDE_DIRS' in env:\r\n            exclude_dirs = env.get('NOSE_EXCLUDE_DIRS','')\r\n            env_dirs.extend(exclude_dirs.split(';'))\r\n        parser.add_option(\r\n            \"--exclude-dir\", action=\"append\",\r\n            dest=\"exclude_dirs\",\r\n            default=env_dirs,\r\n            help=\"Directory to exclude from test discovery. \\\r\n                Path can be relative to current working directory \\\r\n                or an absolute path. May be specified multiple \\\r\n                times. [NOSE_EXCLUDE_DIRS]\")\r\n        parser.add_option(\r\n            \"--exclude-dir-file\", type=\"string\",\r\n            dest=\"exclude_dir_file\",\r\n            default=env.get('NOSE_EXCLUDE_DIRS_FILE', False),\r\n            help=\"A file containing a list of directories to exclude \\\r\n                from test discovery. Paths can be relative to current \\\r\n                working directory or an absolute path. \\\r\n                [NOSE_EXCLUDE_DIRS_FILE]\")","reference":"Define the command line options for the plugin.","result":"Add options to the parser.","score":[0.1568,0.1299]}
{"code":"def configure(self, options, conf):\r\n        \"\"\" function to<extra_id_0>\r\n        super(NoseExclude, self).configure(options, conf)\r\n        self.exclude_dirs = {}\r\n        if options.exclude_dir_file:\r\n            if not options.exclude_dirs:\r\n                options.exclude_dirs = []\r\n            new_dirs = self._load_from_file(options.exclude_dir_file)\r\n            options.exclude_dirs.extend(new_dirs)\r\n        if not options.exclude_dirs:\r\n            self.enabled = False\r\n            return\r\n        self.enabled = True\r\n        root = os.getcwd()\r\n        log.debug('cwd: %s' % root)\r\n        for exclude_param in options.exclude_dirs:\r\n            for d in exclude_param.split('\\n'):\r\n                d = d.strip()\r\n                abs_d = self._force_to_abspath(d)\r\n                if abs_d:\r\n                    self.exclude_dirs[abs_d] = True\r\n        exclude_str = \"excluding dirs: %s\" % \",\".join(self.exclude_dirs.keys())\r\n        log.debug(exclude_str)","reference":"Configure plugin based on command line options","result":"Configure the exclude plugin .","score":[0.1915,0.1471]}
{"code":"def wantDirectory(self, dirname):\r\n        \"\"\" function to<extra_id_0>\r\n        if dirname in self.exclude_dirs:\r\n            log.debug(\"excluded: %s\" % dirname)\r\n            return False\r\n        else:\r\n            return None","reference":"Check if directory is eligible for test discovery","result":" is allowed .","score":[0.0771,0.0667]}
{"code":"def links_to_dynamic(self, ext):\r\n        \"\"\" function to<extra_id_0>\r\n        libnames = dict.fromkeys([lib._full_name for lib in self.shlibs])\r\n        pkg = '.'.join(ext._full_name.split('.')[:-1]+[''])\r\n        for libname in ext.libraries:\r\n            if pkg+libname in libnames: return True\r\n        return False","reference":"Return true if 'ext' links to a dynamic lib in the same package","result":"Generate dynamic links to external libraries .","score":[0.1073,0.2061]}
{"code":"def call_each(funcs: list, *args, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    '''\r\n    call each func from func list.\r\n    return the last func value or None if func list is empty.\r\n    '''\r\n    ret = None\r\n    for func in funcs:\r\n        ret = func(*args, **kwargs)\r\n    return ret","reference":"call each func from func list.\n\n    return the last func value or None if func list is empty.","result":"Call each func from func list .","score":[0.1174,0.3024]}
{"code":"def call_each_reversed(funcs: list, *args, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    '''\r\n    call each func from reversed func list.\r\n    return the last func value or None if func list is empty.\r\n    '''\r\n    ret = None\r\n    for func in reversed(funcs):\r\n        ret = func(*args, **kwargs)\r\n    return ret","reference":"call each func from reversed func list.\n\n    return the last func value or None if func list is empty.","result":"Call each func from reversed func list .","score":[0.1601,0.3546]}
{"code":"def append_func(self, func, *args, **kwargs):\r\n        \"\"\" function to<extra_id_0>\r\n        '''\r\n        append func with given arguments and keywords.\r\n        '''\r\n        wraped_func = partial(func, *args, **kwargs)\r\n        self.append(wraped_func)","reference":"append func with given arguments and keywords.","result":"Append a function to the stack.","score":[0,0.0725]}
{"code":"def insert_func(self, index, func, *args, **kwargs):\r\n        \"\"\" function to<extra_id_0>\r\n        '''\r\n        insert func with given arguments and keywords.\r\n        '''\r\n        wraped_func = partial(func, *args, **kwargs)\r\n        self.insert(index, wraped_func)","reference":"insert func with given arguments and keywords.","result":"Insert a function into the list.","score":[0,0.0725]}
{"code":"def format_usage(self, usage):\r\n        \"\"\" function to<extra_id_0>\r\n        msg = 'Usage: %s' % usage\r\n        if self.parser.description:\r\n            msg += '\\n'\r\n        return msg","reference":"ensure there is only one newline between usage and the first heading\n        if there is no description","result":"Format usage .","score":[0.0038,0.0321]}
{"code":"def initialize(self, argv=None):\r\n        \"\"\" function to<extra_id_0>\r\n        super(BaseParallelApplication, self).initialize(argv)\r\n        self.to_work_dir()\r\n        self.reinit_logging()","reference":"initialize the app","result":"Initialize the application .","score":[0.3195,0.6048]}
{"code":"def write_pid_file(self, overwrite=False):\r\n        \"\"\" function to<extra_id_0>\r\n        pid_file = os.path.join(self.profile_dir.pid_dir, self.name + u'.pid')\r\n        if os.path.isfile(pid_file):\r\n            pid = self.get_pid_from_file()\r\n            if not overwrite:\r\n                raise PIDFileError(\r\n                    'The pid file [%s] already exists. \\nThis could mean that this '\r\n                    'server is already running with [pid=%s].' % (pid_file, pid)\r\n                )\r\n        with open(pid_file, 'w') as f:\r\n            self.log.info(\"Creating pid file: %s\" % pid_file)\r\n            f.write(repr(os.getpid())+'\\n')","reference":"Create a .pid file in the pid_dir with my pid.\n\n        This must be called after pre_construct, which sets `self.pid_dir`.\n        This raises :exc:`PIDFileError` if the pid file exists already.","result":"Def write the pid file .","score":[0.0102,0.1141]}
{"code":"def remove_pid_file(self):\r\n        \"\"\" function to<extra_id_0>\r\n        pid_file = os.path.join(self.profile_dir.pid_dir, self.name + u'.pid')\r\n        if os.path.isfile(pid_file):\r\n            try:\r\n                self.log.info(\"Removing pid file: %s\" % pid_file)\r\n                os.remove(pid_file)\r\n            except:\r\n                self.log.warn(\"Error removing the pid file: %s\" % pid_file)","reference":"Remove the pid file.\n\n        This should be called at shutdown by registering a callback with\n        :func:`reactor.addSystemEventTrigger`. This needs to return\n        ``None``.","result":"Remove the pid file .","score":[0.0202,0.1518]}
{"code":"def get_pid_from_file(self):\r\n        \"\"\" function to<extra_id_0>\r\n        pid_file = os.path.join(self.profile_dir.pid_dir, self.name + u'.pid')\r\n        if os.path.isfile(pid_file):\r\n            with open(pid_file, 'r') as f:\r\n                s = f.read().strip()\r\n                try:\r\n                    pid = int(s)\r\n                except:\r\n                    raise PIDFileError(\"invalid pid file: %s (contents: %r)\"%(pid_file, s))\r\n                return pid\r\n        else:\r\n            raise PIDFileError('pid file not found: %s' % pid_file)","reference":"Get the pid from the pid file.\n\n        If the  pid file doesn't exist a :exc:`PIDFileError` is raised.","result":"Get the pid from the pid file .","score":[0.264,0.3942]}
{"code":"def construct_parser(magic_func):\r\n    \"\"\" function to<extra_id_0>\r\n    kwds = getattr(magic_func, 'argcmd_kwds', {})\r\n    if 'description' not in kwds:\r\n        kwds['description'] = getattr(magic_func, '__doc__', None)\r\n    arg_name = real_name(magic_func)\r\n    parser = MagicArgumentParser(arg_name, **kwds)\r\n    group = None\r\n    for deco in magic_func.decorators[::-1]:\r\n        result = deco.add_to_parser(parser, group)\r\n        if result is not None:\r\n            group = result\r\n    help_text = parser.format_help()\r\n    if help_text.startswith('usage: '):\r\n        help_text = help_text.replace('usage: ', '%', 1)\r\n    else:\r\n        help_text = '%' + help_text\r\n    magic_func.__doc__ = help_text\r\n    return parser","reference":"Construct an argument parser using the function decorations.","result":"Construct a parser for a magic function .","score":[0.1828,0.1875]}
{"code":"def real_name(magic_func):\r\n    \"\"\" function to<extra_id_0>\r\n    magic_name = magic_func.__name__\r\n    if magic_name.startswith('magic_'):\r\n        magic_name = magic_name[len('magic_'):]\r\n    return getattr(magic_func, 'argcmd_name', magic_name)","reference":"Find the real name of the magic.","result":"Def get real name of magic function .","score":[0.2861,0.5282]}
{"code":"def highlightBlock(self, string):\r\n        \"\"\" function to<extra_id_0>\r\n        if not self.highlighting_on:\r\n            return\r\n        current_block = self.currentBlock()\r\n        string = self._frontend._get_block_plain_text(current_block)\r\n        if current_block.contains(self._frontend._prompt_pos):\r\n            prompt = self._frontend._prompt\r\n        else:\r\n            prompt = self._frontend._continuation_prompt\r\n        if string.startswith(prompt):\r\n            self._current_offset = len(prompt)\r\n            string = string[len(prompt):]\r\n            super(FrontendHighlighter, self).highlightBlock(string)","reference":"Highlight a block of text. Reimplemented to highlight selectively.","result":"Highlight a block .","score":[0.1885,0.3007]}
{"code":"def rehighlightBlock(self, block):\r\n        \"\"\" function to<extra_id_0>\r\n        old = self.highlighting_on\r\n        self.highlighting_on = True\r\n        super(FrontendHighlighter, self).rehighlightBlock(block)\r\n        self.highlighting_on = old","reference":"Reimplemented to temporarily enable highlighting if disabled.","result":"Rehighlight a block .","score":[0,0.0]}
{"code":"def setFormat(self, start, count, format):\r\n        \"\"\" function to<extra_id_0>\r\n        start += self._current_offset\r\n        super(FrontendHighlighter, self).setFormat(start, count, format)","reference":"Reimplemented to highlight selectively.","result":"Set the format of the highlighting widget .","score":[0,0.1136]}
{"code":"def copy(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._page_control is not None and self._page_control.hasFocus():\r\n            self._page_control.copy()\r\n        elif self._control.hasFocus():\r\n            text = self._control.textCursor().selection().toPlainText()\r\n            if text:\r\n                lines = map(self._transform_prompt, text.splitlines())\r\n                text = '\\n'.join(lines)\r\n                QtGui.QApplication.clipboard().setText(text)\r\n        else:\r\n            self.log.debug(\"frontend widget : unknown copy target\")","reference":"Copy the currently selected text to the clipboard, removing prompts.","result":"Copy text from the control to the clipboard .","score":[0.1939,0.3758]}
{"code":"def _execute(self, source, hidden):\r\n        \"\"\" function to<extra_id_0>\r\n        msg_id = self.kernel_manager.shell_channel.execute(source, hidden)\r\n        self._request_info['execute'][msg_id] = self._ExecutionRequest(msg_id, 'user')\r\n        self._hidden = hidden\r\n        if not hidden:\r\n            self.executing.emit(source)","reference":"Execute 'source'. If 'hidden', do not show any output.\n\n        See parent class :meth:`execute` docstring for full details.","result":"Execute a shell command .","score":[0.0218,0.0316]}
{"code":"def _prompt_finished_hook(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self._input_splitter.reset()\r\n        if not self._reading:\r\n            self._highlighter.highlighting_on = False","reference":"Called immediately after a prompt is finished, i.e. when some input\n            will be processed and a new prompt displayed.","result":"Call when prompt finished .","score":[0.0174,0.0852]}
{"code":"def _tab_pressed(self):\r\n        \"\"\" function to<extra_id_0>\r\n        text = self._get_input_buffer_cursor_line()\r\n        if text is None:\r\n            return False\r\n        complete = bool(text[:self._get_input_buffer_cursor_column()].strip())\r\n        if complete:\r\n            self._complete()\r\n        return not complete","reference":"Called when the tab key is pressed. Returns whether to continue\n            processing the event.","result":"Handle tab presses .","score":[0.0262,0.0385]}
{"code":"def _context_menu_make(self, pos):\r\n        \"\"\" function to<extra_id_0>\r\n        menu = super(FrontendWidget, self)._context_menu_make(pos)\r\n        for before_action in menu.actions():\r\n            if before_action.shortcut().matches(QtGui.QKeySequence.Paste) == \\\r\n                    QtGui.QKeySequence.ExactMatch:\r\n                menu.insertAction(before_action, self._copy_raw_action)\r\n                break\r\n        return menu","reference":"Reimplemented to add an action for raw copy.","result":"No cover create the context menu.","score":[0,0.0]}
{"code":"def _event_filter_console_keypress(self, event):\r\n        \"\"\" function to<extra_id_0>\r\n        key = event.key()\r\n        if self._control_key_down(event.modifiers(), include_command=False):\r\n            if key == QtCore.Qt.Key_C and self._executing:\r\n                self.request_interrupt_kernel()\r\n                return True\r\n            elif key == QtCore.Qt.Key_Period:\r\n                self.request_restart_kernel()\r\n                return True\r\n        elif not event.modifiers() & QtCore.Qt.AltModifier:\r\n            if key == QtCore.Qt.Key_Backspace:\r\n                col = self._get_input_buffer_cursor_column()\r\n                cursor = self._control.textCursor()\r\n                if col > 3 and not cursor.hasSelection():\r\n                    text = self._get_input_buffer_cursor_line()[:col]\r\n                    if text.endswith('    ') and not text.strip():\r\n                        cursor.movePosition(QtGui.QTextCursor.Left,\r\n                                            QtGui.QTextCursor.KeepAnchor, 4)\r\n                        cursor.removeSelectedText()\r\n                        return True\r\n        return super(FrontendWidget, self)._event_filter_console_keypress(event)","reference":"Reimplemented for execution interruption and smart backspace.","result":"Filter console keypress .","score":[0,0.0]}
{"code":"def _insert_continuation_prompt(self, cursor):\r\n        \"\"\" function to<extra_id_0>\r\n        super(FrontendWidget, self)._insert_continuation_prompt(cursor)\r\n        cursor.insertText(' ' * self._input_splitter.indent_spaces)","reference":"Reimplemented for auto-indentation.","result":"Insert continuation prompt .","score":[0,0.0]}
{"code":"def _handle_complete_reply(self, rep):\r\n        \"\"\" function to<extra_id_0>\r\n        self.log.debug(\"complete: %s\", rep.get('content', ''))\r\n        cursor = self._get_cursor()\r\n        info = self._request_info.get('complete')\r\n        if info and info.id == rep['parent_header']['msg_id'] and \\\r\n                info.pos == cursor.position():\r\n            text = '.'.join(self._get_context())\r\n            cursor.movePosition(QtGui.QTextCursor.Left, n=len(text))\r\n            self._complete_with_items(cursor, rep['content']['matches'])","reference":"Handle replies for tab completion.","result":"Handle complete replies .","score":[0.2959,0.2041]}
{"code":"def _silent_exec_callback(self, expr, callback):\r\n        \"\"\" function to<extra_id_0>\r\n        local_uuid = str(uuid.uuid1())\r\n        msg_id = self.kernel_manager.shell_channel.execute('',\r\n            silent=True, user_expressions={ local_uuid:expr })\r\n        self._callback_dict[local_uuid] = callback\r\n        self._request_info['execute'][msg_id] = self._ExecutionRequest(msg_id, 'silent_exec_callback')","reference":"Silently execute `expr` in the kernel and call `callback` with reply\n\n        the `expr` is evaluated silently in the kernel (without) output in\n        the frontend. Call `callback` with the\n        `repr <http:\/\/docs.python.org\/library\/functions.html#repr> `_ as first argument\n\n        Parameters\n        ----------\n        expr : string\n            valid string to be executed by the kernel.\n        callback : function\n            function accepting one argument, as a string. The string will be\n            the `repr` of the result of evaluating `expr`\n\n        The `callback` is called with the `repr()` of the result of `expr` as\n        first argument. To get the object, do `eval()` on the passed value.\n\n        See Also\n        --------\n        _handle_exec_callback : private method, deal with calling callback with reply","result":" is done .","score":[3.592e-16,0.0104]}
{"code":"def _handle_exec_callback(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        user_exp = msg['content'].get('user_expressions')\r\n        if not user_exp:\r\n            return\r\n        for expression in user_exp:\r\n            if expression in self._callback_dict:\r\n                self._callback_dict.pop(expression)(user_exp[expression])","reference":"Execute `callback` corresponding to `msg` reply, after ``_silent_exec_callback``\n\n        Parameters\n        ----------\n        msg : raw message send by the kernel containing an `user_expressions`\n                and having a 'silent_exec_callback' kind.\n\n        Notes\n        -----\n        This function will look for a `callback` associated with the\n        corresponding message id. Association has been made by\n        `_silent_exec_callback`. `callback` is then called with the `repr()`\n        of the value of corresponding `user_expressions` as argument.\n        `callback` is then removed from the known list so that any message\n        coming again with the same id won't trigger it.","result":"Handle exec callback .","score":[0,0.0]}
{"code":"def _handle_execute_reply(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        self.log.debug(\"execute: %s\", msg.get('content', ''))\r\n        msg_id = msg['parent_header']['msg_id']\r\n        info = self._request_info['execute'].get(msg_id)\r\n        self._reading = False\r\n        if info and info.kind == 'user' and not self._hidden:\r\n            self.kernel_manager.sub_channel.flush()\r\n            if self.ansi_codes:\r\n                self._ansi_processor.reset_sgr()\r\n            content = msg['content']\r\n            status = content['status']\r\n            if status == 'ok':\r\n                self._process_execute_ok(msg)\r\n            elif status == 'error':\r\n                self._process_execute_error(msg)\r\n            elif status == 'aborted':\r\n                self._process_execute_abort(msg)\r\n            self._show_interpreter_prompt_for_reply(msg)\r\n            self.executed.emit(msg)\r\n            self._request_info['execute'].pop(msg_id)\r\n        elif info and info.kind == 'silent_exec_callback' and not self._hidden:\r\n            self._handle_exec_callback(msg)\r\n            self._request_info['execute'].pop(msg_id)\r\n        else:\r\n            super(FrontendWidget, self)._handle_execute_reply(msg)","reference":"Handles replies for code execution.","result":"Handle execute replies .","score":[0.2488,0.2041]}
{"code":"def _handle_input_request(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        self.log.debug(\"input: %s\", msg.get('content', ''))\r\n        if self._hidden:\r\n            raise RuntimeError('Request for raw input during hidden execution.')\r\n        self.kernel_manager.sub_channel.flush()\r\n        def callback(line):\r\n            self.kernel_manager.stdin_channel.input(line)\r\n        if self._reading:\r\n            self.log.debug(\"Got second input request, assuming first was interrupted.\")\r\n            self._reading = False\r\n        self._readline(msg['content']['prompt'], callback=callback)","reference":"Handle requests for raw_input.","result":"Def handle input request .","score":[0,0.2439]}
{"code":"def _handle_kernel_died(self, since_last_heartbeat):\r\n        \"\"\" function to<extra_id_0>\r\n        self.log.debug(\"kernel died: %s\", since_last_heartbeat)\r\n        if self.custom_restart:\r\n            self.custom_restart_kernel_died.emit(since_last_heartbeat)\r\n        else:\r\n            message = 'The kernel heartbeat has been inactive for %.2f ' \\\r\n                'seconds. Do you want to restart the kernel? You may ' \\\r\n                'first want to check the network connection.' % \\\r\n                since_last_heartbeat\r\n            self.restart_kernel(message, now=True)","reference":"Handle the kernel's death by asking if the user wants to restart.","result":"Handle kernel died .","score":[0.0432,0.0446]}
{"code":"def _handle_object_info_reply(self, rep):\r\n        \"\"\" function to<extra_id_0>\r\n        self.log.debug(\"oinfo: %s\", rep.get('content', ''))\r\n        cursor = self._get_cursor()\r\n        info = self._request_info.get('call_tip')\r\n        if info and info.id == rep['parent_header']['msg_id'] and \\\r\n                info.pos == cursor.position():\r\n            content = rep['content']\r\n            if content.get('ismagic', False):\r\n                call_info, doc = None, None\r\n            else:\r\n                call_info, doc = call_tip(content, format_call=True)\r\n            if call_info or doc:\r\n                self._call_tip_widget.show_call_info(call_info, doc)","reference":"Handle replies for call tips.","result":"Handle object info reply .","score":[0.2403,0.2]}
{"code":"def _handle_pyout(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        self.log.debug(\"pyout: %s\", msg.get('content', ''))\r\n        if not self._hidden and self._is_from_this_session(msg):\r\n            text = msg['content']['data']\r\n            self._append_plain_text(text + '\\n', before_prompt=True)","reference":"Handle display hook output.","result":"Handle pyout messages .","score":[0.3195,0.125]}
{"code":"def _handle_stream(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        self.log.debug(\"stream: %s\", msg.get('content', ''))\r\n        if not self._hidden and self._is_from_this_session(msg):\r\n            text = msg['content']['data'].expandtabs(8)\r\n            self._append_plain_text(text, before_prompt=True)\r\n            self._control.moveCursor(QtGui.QTextCursor.End)","reference":"Handle stdout, stderr, and stdin.","result":"Handle a stream message .","score":[0.2403,0.1]}
{"code":"def _handle_shutdown_reply(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        self.log.debug(\"shutdown: %s\", msg.get('content', ''))\r\n        if not self._hidden and not self._is_from_this_session(msg):\r\n            if self._local_kernel:\r\n                if not msg['content']['restart']:\r\n                    self.exit_requested.emit(self)\r\n                else:\r\n                    time.sleep(0.25)\r\n                    self.reset()\r\n            else:\r\n                title = self.window().windowTitle()\r\n                if not msg['content']['restart']:\r\n                    reply = QtGui.QMessageBox.question(self, title,\r\n                        \"Kernel has been shutdown permanently. \"\r\n                        \"Close the Console?\",\r\n                        QtGui.QMessageBox.Yes,QtGui.QMessageBox.No)\r\n                    if reply == QtGui.QMessageBox.Yes:\r\n                        self.exit_requested.emit(self)\r\n                else:\r\n                    reply = QtGui.QMessageBox.question(self, title,\r\n                        \"Kernel has been reset. Clear the Console?\",\r\n                        QtGui.QMessageBox.Yes,QtGui.QMessageBox.No)\r\n                    if reply == QtGui.QMessageBox.Yes:\r\n                        time.sleep(0.25)\r\n                        self.reset()","reference":"Handle shutdown signal, only if from other console.","result":"Handle shutdown replies .","score":[0.1662,0.2467]}
{"code":"def execute_file(self, path, hidden=False):\r\n        \"\"\" function to<extra_id_0>\r\n        self.execute('execfile(%r)' % path, hidden=hidden)","reference":"Attempts to execute file with 'path'. If 'hidden', no output is\n            shown.","result":"Execute a file .","score":[0.0432,0.0893]}
{"code":"def interrupt_kernel(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.custom_interrupt:\r\n            self._reading = False\r\n            self.custom_interrupt_requested.emit()\r\n        elif self.kernel_manager.has_kernel:\r\n            self._reading = False\r\n            self.kernel_manager.interrupt_kernel()\r\n        else:\r\n            self._append_plain_text('Kernel process is either remote or '\r\n                                    'unspecified. Cannot interrupt.\\n')","reference":"Attempts to interrupt the running kernel.\n        \n        Also unsets _reading flag, to avoid runtime errors\n        if raw_input is called again.","result":"Interrupt the kernel process .","score":[0.0146,0.1065]}
{"code":"def reset(self, clear=False):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._executing:\r\n            self._executing = False\r\n            self._request_info['execute'] = {}\r\n        self._reading = False\r\n        self._highlighter.highlighting_on = False\r\n        if self.clear_on_kernel_restart or clear:\r\n            self._control.clear()\r\n            self._append_plain_text(self.banner)\r\n        else:\r\n            self._append_plain_text(\"\r\n            self._append_html(\"<hr><br>\")\r\n    self._append_before_prompt_pos = self._get_cursor().position()\r\n        self._show_interpreter_prompt()","reference":"Resets the widget to its initial state if ``clear`` parameter or\n        ``clear_on_kernel_restart`` configuration setting is True, otherwise\n        prints a visual indication of the fact that the kernel restarted, but\n        does not clear the traces from previous usage of the kernel before it\n        was restarted.  With ``clear=True``, it is similar to ``%clear``, but\n        also re-writes the banner and aborts execution if necessary.","result":"Reset the kernel .","score":[0.0,0.0271]}
{"code":"def restart_kernel(self, message, now=False):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.custom_restart:\r\n            self.custom_restart_requested.emit()\r\n        elif self.kernel_manager.has_kernel:\r\n            self.kernel_manager.hb_channel.pause()\r\n            if self.confirm_restart:\r\n                buttons = QtGui.QMessageBox.Yes | QtGui.QMessageBox.No\r\n                result = QtGui.QMessageBox.question(self, 'Restart kernel?',\r\n                                                    message, buttons)\r\n                do_restart = result == QtGui.QMessageBox.Yes\r\n            else:\r\n                do_restart = True\r\n            if do_restart:\r\n                try:\r\n                    self.kernel_manager.restart_kernel(now=now)\r\n                except RuntimeError:\r\n                    self._append_plain_text('Kernel started externally. '\r\n                                            'Cannot restart.\\n',\r\n                                            before_prompt=True\r\n                                            )\r\n                else:\r\n                    self.reset()\r\n            else:\r\n                self.kernel_manager.hb_channel.unpause()\r\n        else:\r\n            self._append_plain_text('Kernel process is either remote or '\r\n                                    'unspecified. Cannot restart.\\n',\r\n                                    before_prompt=True\r\n                                    )","reference":"Attempts to restart the running kernel.","result":"Restart kernel .","score":[0,0.0877]}
{"code":"def _call_tip(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if not self.enable_calltips:\r\n            return False\r\n        cursor = self._get_cursor()\r\n        cursor.movePosition(QtGui.QTextCursor.Left)\r\n        if cursor.document().characterAt(cursor.position()) != '(':\r\n            return False\r\n        context = self._get_context(cursor)\r\n        if not context:\r\n            return False\r\n        name = '.'.join(context)\r\n        msg_id = self.kernel_manager.shell_channel.object_info(name)\r\n        pos = self._get_cursor().position()\r\n        self._request_info['call_tip'] = self._CallTipRequest(msg_id, pos)\r\n        return True","reference":"Shows a call tip, if appropriate, at the current cursor location.","result":"Display call tip .","score":[0.0555,0.0971]}
{"code":"def _complete(self):\r\n        \"\"\" function to<extra_id_0>\r\n        context = self._get_context()\r\n        if context:\r\n            msg_id = self.kernel_manager.shell_channel.complete(\r\n                '.'.join(context),\r\n                self._get_input_buffer_cursor_line(),\r\n                self._get_input_buffer_cursor_column(),\r\n                self.input_buffer)\r\n            pos = self._get_cursor().position()\r\n            info = self._CompletionRequest(msg_id, pos)\r\n            self._request_info['complete'] = info","reference":"Performs completion at the current cursor location.","result":"Complete the shell .","score":[0.1509,0.1493]}
{"code":"def _process_execute_error(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        content = msg['content']\r\n        if content['ename']=='SystemExit':\r\n            keepkernel = content['evalue']=='-k' or content['evalue']=='True'\r\n            self._keep_kernel_on_exit = keepkernel\r\n            self.exit_requested.emit(self)\r\n        else:\r\n            traceback = ''.join(content['traceback'])\r\n            self._append_plain_text(traceback)","reference":"Process a reply for an execution request that resulted in an error.","result":"Process execute error messages .","score":[0.0593,0.0885]}
{"code":"def _process_execute_ok(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        payload = msg['content']['payload']\r\n        for item in payload:\r\n            if not self._process_execute_payload(item):\r\n                warning = 'Warning: received unknown payload of type %s'\r\n                print(warning % repr(item['source']))","reference":"Process a reply for a successful execution request.","result":"Process a execute ok message .","score":[0.1956,0.1923]}
{"code":"def _document_contents_change(self, position, removed, added):\r\n        \"\"\" function to<extra_id_0>\r\n        position += added\r\n        document = self._control.document()\r\n        if position == self._get_cursor().position():\r\n            self._call_tip()","reference":"Called whenever the document's content changes. Display a call tip\n            if appropriate.","result":"Handle document contents change .","score":[0,0.0442]}
{"code":"def addPlugin(self, plugin, call):\r\n        \"\"\" function to<extra_id_0>\r\n        meth = getattr(plugin, call, None)\r\n        if meth is not None:\r\n            if call == 'loadTestsFromModule' and \\\r\n                    len(inspect.getargspec(meth)[0]) == 2:\r\n                orig_meth = meth\r\n                meth = lambda module, path, **kwargs: orig_meth(module)\r\n            self.plugins.append((plugin, meth))","reference":"Add plugin to my list of plugins to call, if it has the attribute\n        I'm bound to.","result":"Add a plugin to the test suite .","score":[0.0758,0.1242]}
{"code":"def chain(self, *arg, **kw):\r\n        \"\"\" function to<extra_id_0>\r\n        result = None\r\n        static = [a for (static, a)\r\n                  in zip(getattr(self.method, 'static_args', []), arg)\r\n                  if static]\r\n        for p, meth in self.plugins:\r\n            result = meth(*arg, **kw)\r\n            arg = static[:]\r\n            arg.append(result)\r\n        return result","reference":"Call plugins in a chain, where the result of each plugin call is\n        sent to the next plugin as input. The final output result is returned.","result":"Chain the plugins .","score":[0.0016,0.042]}
{"code":"def generate(self, *arg, **kw):\r\n        \"\"\" function to<extra_id_0>\r\n        for p, meth in self.plugins:\r\n            result = None\r\n            try:\r\n                result = meth(*arg, **kw)\r\n                if result is not None:\r\n                    for r in result:\r\n                        yield r\r\n            except (KeyboardInterrupt, SystemExit):\r\n                raise\r\n            except:\r\n                exc = sys.exc_info()\r\n                yield Failure(*exc)\r\n                continue","reference":"Call all plugins, yielding each item in each non-None result.","result":"Generate the generator .","score":[0,0.0]}
{"code":"def simple(self, *arg, **kw):\r\n        \"\"\" function to<extra_id_0>\r\n        for p, meth in self.plugins:\r\n            result = meth(*arg, **kw)\r\n            if result is not None:\r\n                return result","reference":"Call all plugins, returning the first non-None result.","result":"Call all plugins in the simple fashion .","score":[0.2174,0.3194]}
{"code":"def configure(self, options, config):\r\n        \"\"\" function to<extra_id_0>\r\n        log.debug(\"Configuring plugins\")\r\n        self.config = config\r\n        cfg = PluginProxy('configure', self._plugins)\r\n        cfg(options, config)\r\n        enabled = [plug for plug in self._plugins if plug.enabled]\r\n        self.plugins = enabled\r\n        self.sort()\r\n        log.debug(\"Plugins enabled: %s\", enabled)","reference":"Configure the set of plugins with the given options\n        and config instance. After configuration, disabled plugins\n        are removed from the plugins list.","result":"Configure plugins .","score":[0.0009,0.0498]}
{"code":"def loadPlugins(self):\r\n        \"\"\" function to<extra_id_0>\r\n        from pkg_resources import iter_entry_points\r\n        loaded = {}\r\n        for entry_point, adapt in self.entry_points:\r\n            for ep in iter_entry_points(entry_point):\r\n                if ep.name in loaded:\r\n                    continue\r\n                loaded[ep.name] = True\r\n                log.debug('%s load plugin %s', self.__class__.__name__, ep)\r\n                try:\r\n                    plugcls = ep.load()\r\n                except KeyboardInterrupt:\r\n                    raise\r\n                except Exception, e:\r\n                    warn(\"Unable to load plugin %s: %s\" % (ep, e),\r\n                         RuntimeWarning)\r\n                    continue\r\n                if adapt:\r\n                    plug = adapt(plugcls())\r\n                else:\r\n                    plug = plugcls()\r\n                self.addPlugin(plug)\r\n        super(EntryPointPluginManager, self).loadPlugins()","reference":"Load plugins by iterating the `nose.plugins` entry point.","result":"Load plugins from entry points.","score":[0.2064,0.3319]}
{"code":"def loadPlugins(self):\r\n        \"\"\" function to<extra_id_0>\r\n        from nose.plugins import builtin\r\n        for plug in builtin.plugins:\r\n            self.addPlugin(plug())\r\n        super(BuiltinPluginManager, self).loadPlugins()","reference":"Load plugins in nose.plugins.builtin","result":"Load plugins .","score":[0.4137,0.4808]}
{"code":"def latex_to_png(s, encode=False, backend='mpl'):\r\n    \"\"\" function to<extra_id_0>\r\n    if backend == 'mpl':\r\n        f = latex_to_png_mpl\r\n    elif backend == 'dvipng':\r\n        f = latex_to_png_dvipng\r\n    else:\r\n        raise ValueError('No such backend {0}'.format(backend))\r\n    bin_data = f(s)\r\n    if encode and bin_data:\r\n        bin_data = encodestring(bin_data)\r\n    return bin_data","reference":"Render a LaTeX string to PNG.\n\n    Parameters\n    ----------\n    s : str\n        The raw string containing valid inline LaTeX.\n    encode : bool, optional\n        Should the PNG data bebase64 encoded to make it JSON'able.\n    backend : {mpl, dvipng}\n        Backend for producing PNG data.\n\n    None is returned when the backend cannot be used.","result":"Convert latex to png .","score":[0.0,0.033]}
{"code":"def latex_to_html(s, alt='image'):\r\n    \"\"\" function to<extra_id_0>\r\n    base64_data = latex_to_png(s, encode=True)\r\n    if base64_data:\r\n        return _data_uri_template_png  % (base64_data, alt)","reference":"Render LaTeX to HTML with embedded PNG data using data URIs.\n\n    Parameters\n    ----------\n    s : str\n        The raw string containing valid inline LateX.\n    alt : str\n        The alt text to use for the HTML.","result":"Convert latex to html .","score":[0.0007,0.0482]}
{"code":"def math_to_image(s, filename_or_obj, prop=None, dpi=None, format=None):\r\n    \"\"\" function to<extra_id_0>\r\n    from matplotlib import figure\r\n    from matplotlib.backends import backend_agg\r\n    from matplotlib.font_manager import FontProperties\r\n    from matplotlib.mathtext import MathTextParser\r\n    if prop is None:\r\n        prop = FontProperties()\r\n    parser = MathTextParser('path')\r\n    width, height, depth, _, _ = parser.parse(s, dpi=72, prop=prop)\r\n    fig = figure.Figure(figsize=(width \/ 72.0, height \/ 72.0))\r\n    fig.text(0, depth\/height, s, fontproperties=prop)\r\n    backend_agg.FigureCanvasAgg(fig)\r\n    fig.savefig(filename_or_obj, dpi=dpi, format=format)\r\n    return depth","reference":"Given a math expression, renders it in a closely-clipped bounding\n    box to an image file.\n\n    *s*\n       A math expression.  The math portion should be enclosed in\n       dollar signs.\n\n    *filename_or_obj*\n       A filepath or writable file-like object to write the image data\n       to.\n\n    *prop*\n       If provided, a FontProperties() object describing the size and\n       style of the text.\n\n    *dpi*\n       Override the output dpi, otherwise use the default associated\n       with the output format.\n\n    *format*\n       The output format, eg. 'svg', 'pdf', 'ps' or 'png'.  If not\n       provided, will be deduced from the filename.","result":"Convert math to image .","score":[0.0,0.0188]}
{"code":"def check_if_exists(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.req is None:\r\n            return False\r\n        try:\r\n            self.satisfied_by = pkg_resources.get_distribution(self.req)\r\n        except pkg_resources.DistributionNotFound:\r\n            return False\r\n        except pkg_resources.VersionConflict:\r\n            existing_dist = pkg_resources.get_distribution(self.req.project_name)\r\n            if self.use_user_site:\r\n                if dist_in_usersite(existing_dist):\r\n                    self.conflicts_with = existing_dist\r\n                elif running_under_virtualenv() and dist_in_site_packages(existing_dist):\r\n                    raise InstallationError(\"Will not install to the user site because it will lack sys.path precedence to %s in %s\"\r\n                                            %(existing_dist.project_name, existing_dist.location))\r\n            else:\r\n                self.conflicts_with = existing_dist\r\n        return True","reference":"Find an installed distribution that satisfies or conflicts\n        with this requirement, and set self.satisfied_by or\n        self.conflicts_with appropriately.","result":" is installed .","score":[0.0038,0.0321]}
{"code":"def process_iter():\r\n    \"\"\" function to<extra_id_0>\r\n    def add(pid):\r\n        proc = Process(pid)\r\n        _pmap[proc.pid] = proc\r\n        return proc\r\n    def remove(pid):\r\n        _pmap.pop(pid, None)\r\n    a = set(get_pid_list())\r\n    b = set(_pmap.keys())\r\n    new_pids = a - b\r\n    gone_pids = b - a\r\n    for pid in gone_pids:\r\n        remove(pid)\r\n    for pid, proc in sorted(list(_pmap.items()) + \\\r\n                            list(dict.fromkeys(new_pids).items())):\r\n        try:\r\n            if proc is None:\r\n                yield add(pid)\r\n            else:\r\n                if proc.is_running():\r\n                    yield proc\r\n                else:\r\n                    yield add(pid)\r\n        except NoSuchProcess:\r\n            remove(pid)\r\n        except AccessDenied:\r\n            yield proc","reference":"Return a generator yielding a Process class instance for all\n    running processes on the local machine.\n\n    Every new Process instance is only created once and then cached\n    into an internal table which is updated every time this is used.\n\n    The sorting order in which processes are yielded is based on\n    their PIDs.","result":"Iterate over processes.","score":[0,0.0]}
{"code":"def cpu_percent(interval=0.1, percpu=False):\r\n    \"\"\" function to<extra_id_0>\r\n    global _last_cpu_times\r\n    global _last_per_cpu_times\r\n    blocking = interval is not None and interval > 0.0\r\n    def calculate(t1, t2):\r\n        t1_all = sum(t1)\r\n        t1_busy = t1_all - t1.idle\r\n        t2_all = sum(t2)\r\n        t2_busy = t2_all - t2.idle\r\n        if t2_busy <= t1_busy:\r\n            return 0.0\r\n        busy_delta = t2_busy - t1_busy\r\n        all_delta = t2_all - t1_all\r\n        busy_perc = (busy_delta \/ all_delta) * 100\r\n        return round(busy_perc, 1)\r\n    if not percpu:\r\n        if blocking:\r\n            t1 = cpu_times()\r\n            time.sleep(interval)\r\n        else:\r\n            t1 = _last_cpu_times\r\n        _last_cpu_times = cpu_times()\r\n        return calculate(t1, _last_cpu_times)\r\n    else:\r\n        ret = []\r\n        if blocking:\r\n            tot1 = cpu_times(percpu=True)\r\n            time.sleep(interval)\r\n        else:\r\n            tot1 = _last_per_cpu_times\r\n        _last_per_cpu_times = cpu_times(percpu=True)\r\n        for t1, t2 in zip(tot1, _last_per_cpu_times):\r\n            ret.append(calculate(t1, t2))\r\n        return ret","reference":"Return a float representing the current system-wide CPU\n    utilization as a percentage.\n\n    When interval is > 0.0 compares system CPU times elapsed before\n    and after the interval (blocking).\n\n    When interval is 0.0 or None compares system CPU times elapsed\n    since last call or module import, returning immediately.\n    In this case is recommended for accuracy that this function be\n    called with at least 0.1 seconds between calls.\n\n    When percpu is True returns a list of floats representing the\n    utilization as a percentage for each CPU.\n    First element of the list refers to first CPU, second element\n    to second CPU and so on.\n    The order of the list is consistent across calls.","result":"Def calculate cpu percent .","score":[0,0.005]}
{"code":"def as_dict(self, attrs=[], ad_value=None):\r\n        \"\"\" function to<extra_id_0>\r\n        excluded_names = set(['send_signal', 'suspend', 'resume', 'terminate',\r\n                              'kill', 'wait', 'is_running', 'as_dict', 'parent',\r\n                              'get_children', 'nice'])\r\n        retdict = dict()\r\n        for name in set(attrs or dir(self)):\r\n            if name.startswith('_'):\r\n                continue\r\n            if name.startswith('set_'):\r\n                continue\r\n            if name in excluded_names:\r\n                continue\r\n            try:\r\n                attr = getattr(self, name)\r\n                if callable(attr):\r\n                    if name == 'get_cpu_percent':\r\n                        ret = attr(interval=0)\r\n                    else:\r\n                        ret = attr()\r\n                else:\r\n                    ret = attr\r\n            except AccessDenied:\r\n                ret = ad_value\r\n            except NotImplementedError:\r\n                if attrs:\r\n                    raise\r\n                continue\r\n            if name.startswith('get'):\r\n                if name[3] == '_':\r\n                    name = name[4:]\r\n                elif name == 'getcwd':\r\n                    name = 'cwd'\r\n            retdict[name] = ret\r\n        return retdict","reference":"Utility method returning process information as a hashable\n        dictionary.\n\n        If 'attrs' is specified it must be a list of strings reflecting\n        available Process class's attribute names (e.g. ['get_cpu_times',\n        'name']) else all public (read only) attributes are assumed.\n\n        'ad_value' is the value which gets assigned to a dict key in case\n        AccessDenied exception is raised when retrieving that particular\n        process information.","result":"Return a dict of the current process as a dict .","score":[0.0024,0.0966]}
{"code":"def name(self):\r\n        \"\"\" function to<extra_id_0>\r\n        name = self._platform_impl.get_process_name()\r\n        if os.name == 'posix':\r\n            try:\r\n                cmdline = self.cmdline\r\n            except AccessDenied:\r\n                pass\r\n            else:\r\n                if cmdline:\r\n                    extended_name = os.path.basename(cmdline[0])\r\n                    if extended_name.startswith(name):\r\n                        name = extended_name\r\n        self._platform_impl._process_name = name\r\n        return name","reference":"The process name.","result":"Get the process name .","score":[0.2403,0.5859]}
{"code":"def exe(self):\r\n        \"\"\" function to<extra_id_0>\r\n        def guess_it(fallback):\r\n            cmdline = self.cmdline\r\n            if cmdline and hasattr(os, 'access') and hasattr(os, 'X_OK'):\r\n                exe = cmdline[0]\r\n                rexe = os.path.realpath(exe)\r\n                if os.path.isabs(rexe) and os.path.isfile(rexe) \\\r\n                and os.access(rexe, os.X_OK):\r\n                    return exe\r\n            if isinstance(fallback, AccessDenied):\r\n                raise fallback\r\n            return fallback\r\n        try:\r\n            exe = self._platform_impl.get_process_exe()\r\n        except AccessDenied:\r\n            err = sys.exc_info()[1]\r\n            return guess_it(fallback=err)\r\n        else:\r\n            if not exe:\r\n                try:\r\n                    exe = guess_it(fallback=exe)\r\n                except AccessDenied:\r\n                    pass\r\n            return exe","reference":"The process executable path. May also be an empty string.","result":"Get the executable name of the process .","score":[0.1286,0.2608]}
{"code":"def get_children(self, recursive=False):\r\n        \"\"\" function to<extra_id_0>\r\n        if not self.is_running():\r\n            name = self._platform_impl._process_name\r\n            raise NoSuchProcess(self.pid, name)\r\n        ret = []\r\n        if not recursive:\r\n            for p in process_iter():\r\n                try:\r\n                    if p.ppid == self.pid:\r\n                        if self.create_time <= p.create_time:\r\n                            ret.append(p)\r\n                except NoSuchProcess:\r\n                    pass\r\n        else:\r\n            table = defaultdict(list)\r\n            for p in process_iter():\r\n                try:\r\n                    table[p.ppid].append(p)\r\n                except NoSuchProcess:\r\n                    pass\r\n            checkpids = [self.pid]\r\n            for pid in checkpids:\r\n                for child in table[pid]:\r\n                    try:\r\n                        intime = self.create_time <= child.create_time\r\n                    except NoSuchProcess:\r\n                        pass\r\n                    else:\r\n                        if intime:\r\n                            ret.append(child)\r\n                            if child.pid not in checkpids:\r\n                                checkpids.append(child.pid)\r\n        return ret","reference":"Return the children of this process as a list of Process\n        objects.\n        If recursive is True return all the parent descendants.\n\n        Example (A == this process):\n\n         A \u2500\u2510\n            \u2502\n            \u251c\u2500 B (child) \u2500\u2510\n            \u2502             \u2514\u2500 X (grandchild) \u2500\u2510\n            \u2502                                \u2514\u2500 Y (great grandchild)\n            \u251c\u2500 C (child)\n            \u2514\u2500 D (child)\n\n        >>> p.get_children()\n        B, C, D\n        >>> p.get_children(recursive=True)\n        B, X, Y, C, D\n\n        Note that in the example above if process X disappears\n        process Y won't be returned either as the reference to\n        process A is lost.","result":"Get all children of this process .","score":[0.0,0.0324]}
{"code":"def get_cpu_percent(self, interval=0.1):\r\n        \"\"\" function to<extra_id_0>\r\n        blocking = interval is not None and interval > 0.0\r\n        if blocking:\r\n            st1 = sum(cpu_times())\r\n            pt1 = self._platform_impl.get_cpu_times()\r\n            time.sleep(interval)\r\n            st2 = sum(cpu_times())\r\n            pt2 = self._platform_impl.get_cpu_times()\r\n        else:\r\n            st1 = self._last_sys_cpu_times\r\n            pt1 = self._last_proc_cpu_times\r\n            st2 = sum(cpu_times())\r\n            pt2 = self._platform_impl.get_cpu_times()\r\n            if st1 is None or pt1 is None:\r\n                self._last_sys_cpu_times = st2\r\n                self._last_proc_cpu_times = pt2\r\n                return 0.0\r\n        delta_proc = (pt2.user - pt1.user) + (pt2.system - pt1.system)\r\n        delta_time = st2 - st1\r\n        self._last_sys_cpu_times = st2\r\n        self._last_proc_cpu_times = pt2\r\n        try:\r\n            overall_percent = (delta_proc \/ delta_time) * 100\r\n        except ZeroDivisionError:\r\n            return 0.0\r\n        single_cpu_percent = overall_percent * NUM_CPUS\r\n        if os.name != 'posix':\r\n            if single_cpu_percent > 100.0:\r\n                return 100.0\r\n        return round(single_cpu_percent, 1)","reference":"Return a float representing the current process CPU\n        utilization as a percentage.\n\n        When interval is > 0.0 compares process times to system CPU\n        times elapsed before and after the interval (blocking).\n\n        When interval is 0.0 or None compares process times to system CPU\n        times elapsed since last call, returning immediately.\n        In this case is recommended for accuracy that this function be\n        called with at least 0.1 seconds between calls.","result":"Def get the CPU percent .","score":[0.0,0.0159]}
{"code":"def get_memory_percent(self):\r\n        \"\"\" function to<extra_id_0>\r\n        rss = self._platform_impl.get_memory_info()[0]\r\n        try:\r\n            return (rss \/ float(TOTAL_PHYMEM)) * 100\r\n        except ZeroDivisionError:\r\n            return 0.0","reference":"Compare physical system memory to process resident memory and\n        calculate process memory utilization as a percentage.","result":"Get memory percent .","score":[0.0159,0.0338]}
{"code":"def get_memory_maps(self, grouped=True):\r\n        \"\"\" function to<extra_id_0>\r\n        it = self._platform_impl.get_memory_maps()\r\n        if grouped:\r\n            d = {}\r\n            for tupl in it:\r\n                path = tupl[2]\r\n                nums = tupl[3:]\r\n                try:\r\n                    d[path] = map(lambda x, y: x+y, d[path], nums)\r\n                except KeyError:\r\n                    d[path] = nums\r\n            nt = self._platform_impl.nt_mmap_grouped\r\n            return [nt(path, *d[path]) for path in d]\r\n        else:\r\n            nt = self._platform_impl.nt_mmap_ext\r\n            return [nt(*x) for x in it]","reference":"Return process's mapped memory regions as a list of nameduples\n        whose fields are variable depending on the platform.\n\n        If 'grouped' is True the mapped regions with the same 'path'\n        are grouped together and the different memory fields are summed.\n\n        If 'grouped' is False every mapped region is shown as a single\n        entity and the namedtuple will also include the mapped region's\n        address space ('addr') and permission set ('perms').","result":"Get memory maps .","score":[0.0,0.0162]}
{"code":"def is_running(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._gone:\r\n            return False\r\n        try:\r\n            return self.create_time == \\\r\n                   self._platform_impl.get_process_create_time()\r\n        except NoSuchProcess:\r\n            self._gone = True\r\n            return False","reference":"Return whether this process is running.","result":" is running .","score":[0.1502,0.0877]}
{"code":"def suspend(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if not self.is_running():\r\n            name = self._platform_impl._process_name\r\n            raise NoSuchProcess(self.pid, name)\r\n        if hasattr(self._platform_impl, \"suspend_process\"):\r\n            self._platform_impl.suspend_process()\r\n        else:\r\n            self.send_signal(signal.SIGSTOP)","reference":"Suspend process execution.","result":"Suspend the process .","score":[0.3799,0.3226]}
{"code":"def resume(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if not self.is_running():\r\n            name = self._platform_impl._process_name\r\n            raise NoSuchProcess(self.pid, name)\r\n        if hasattr(self._platform_impl, \"resume_process\"):\r\n            self._platform_impl.resume_process()\r\n        else:\r\n            self.send_signal(signal.SIGCONT)","reference":"Resume process execution.","result":"Resume the process .","score":[0.3799,0.3226]}
{"code":"def kill(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if not self.is_running():\r\n            name = self._platform_impl._process_name\r\n            raise NoSuchProcess(self.pid, name)\r\n        if os.name == 'posix':\r\n            self.send_signal(signal.SIGKILL)\r\n        else:\r\n            self._platform_impl.kill_process()","reference":"Kill the current process.","result":"Kill the process .","score":[0.4518,0.4688]}
{"code":"def wait(self, timeout=None):\r\n        \"\"\" function to<extra_id_0>\r\n        if timeout is not None and not timeout >= 0:\r\n            raise ValueError(\"timeout must be a positive integer\")\r\n        return self._platform_impl.process_wait(timeout)","reference":"Wait for process to terminate and, if process is a children\n        of the current one also return its exit code, else None.","result":"Wait for a process to finish .","score":[0.0373,0.1815]}
{"code":"def _wire_kernel(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self.gtk_main, self.gtk_main_quit = self._hijack_gtk()\r\n        gobject.timeout_add(int(1000*self.kernel._poll_interval),\r\n                            self.iterate_kernel)\r\n        return False","reference":"Initializes the kernel inside GTK.\n        \n        This is meant to run only once at startup, so it does its job and\n        returns False to ensure it doesn't get run again by GTK.","result":"Wire the kernel .","score":[0.0005,0.0663]}
{"code":"def _hijack_gtk(self):\r\n        \"\"\" function to<extra_id_0>\r\n        def dummy(*args, **kw):\r\n            pass\r\n        orig_main, gtk.main = gtk.main, dummy\r\n        orig_main_quit, gtk.main_quit = gtk.main_quit, dummy\r\n        return orig_main, orig_main_quit","reference":"Hijack a few key functions in GTK for IPython integration.\n\n        Modifies pyGTK's main and main_quit with a dummy so user code does not\n        block IPython.  This allows us to use %run to run arbitrary pygtk\n        scripts from a long-lived IPython session, and when they attempt to\n        start or stop\n\n        Returns\n        -------\n        The original functions that have been hijacked:\n        - gtk.main\n        - gtk.main_quit","result":"Hijack gtk .","score":[0.0,0.0178]}
{"code":"def is_shadowed(identifier, ip):\r\n    \"\"\" function to<extra_id_0>\r\n    return (identifier in ip.user_ns \\\r\n            or identifier in ip.user_global_ns \\\r\n            or identifier in ip.ns_table['builtin'])","reference":"Is the given identifier defined in one of the namespaces which shadow\n    the alias and magic namespaces?  Note that an identifier is different\n    than ifun, because it can not contain a '.' character.","result":" is shadowed .","score":[0.0,0.0333]}
{"code":"def init_transformers(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self._transformers = []\r\n        for transformer_cls in _default_transformers:\r\n            transformer_cls(\r\n                shell=self.shell, prefilter_manager=self, config=self.config\r\n            )","reference":"Create the default transformers.","result":"Register initialize the transformers .","score":[0.2403,0.122]}
{"code":"def register_transformer(self, transformer):\r\n        \"\"\" function to<extra_id_0>\r\n        if transformer not in self._transformers:\r\n            self._transformers.append(transformer)\r\n            self.sort_transformers()","reference":"Register a transformer instance.","result":"Register a transformer .","score":[0.658,0.7361]}
{"code":"def unregister_transformer(self, transformer):\r\n        \"\"\" function to<extra_id_0>\r\n        if transformer in self._transformers:\r\n            self._transformers.remove(transformer)","reference":"Unregister a transformer instance.","result":"Def unregister a transformer .","score":[0.3398,0.7182]}
{"code":"def init_checkers(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self._checkers = []\r\n        for checker in _default_checkers:\r\n            checker(\r\n                shell=self.shell, prefilter_manager=self, config=self.config\r\n            )","reference":"Create the default checkers.","result":"Def initialize the checkers .","score":[0.2403,0.122]}
{"code":"def register_checker(self, checker):\r\n        \"\"\" function to<extra_id_0>\r\n        if checker not in self._checkers:\r\n            self._checkers.append(checker)\r\n            self.sort_checkers()","reference":"Register a checker instance.","result":"Register a checker .","score":[0.658,0.7361]}
{"code":"def unregister_checker(self, checker):\r\n        \"\"\" function to<extra_id_0>\r\n        if checker in self._checkers:\r\n            self._checkers.remove(checker)","reference":"Unregister a checker instance.","result":"Def unregister a checker .","score":[0.3398,0.7182]}
{"code":"def init_handlers(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self._handlers = {}\r\n        self._esc_handlers = {}\r\n        for handler in _default_handlers:\r\n            handler(\r\n                shell=self.shell, prefilter_manager=self, config=self.config\r\n            )","reference":"Create the default handlers.","result":"Initialize handlers .","score":[0,0.0]}
{"code":"def register_handler(self, name, handler, esc_strings):\r\n        \"\"\" function to<extra_id_0>\r\n        self._handlers[name] = handler\r\n        for esc_str in esc_strings:\r\n            self._esc_handlers[esc_str] = handler","reference":"Register a handler instance by name with esc_strings.","result":"Register a handler .","score":[0.2421,0.3874]}
{"code":"def unregister_handler(self, name, handler, esc_strings):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            del self._handlers[name]\r\n        except KeyError:\r\n            pass\r\n        for esc_str in esc_strings:\r\n            h = self._esc_handlers.get(esc_str)\r\n            if h is handler:\r\n                del self._esc_handlers[esc_str]","reference":"Unregister a handler instance by name with esc_strings.","result":"Def unregister a handler .","score":[0.1865,0.3824]}
{"code":"def prefilter_line_info(self, line_info):\r\n        \"\"\" function to<extra_id_0>\r\n        handler = self.find_handler(line_info)\r\n        return handler.handle(line_info)","reference":"Prefilter a line that has been converted to a LineInfo object.\n\n        This implements the checker\/handler part of the prefilter pipe.","result":"Prefilter line info .","score":[0.007,0.0543]}
{"code":"def find_handler(self, line_info):\r\n        \"\"\" function to<extra_id_0>\r\n        for checker in self.checkers:\r\n            if checker.enabled:\r\n                handler = checker.check(line_info)\r\n                if handler:\r\n                    return handler\r\n        return self.get_handler_by_name('normal')","reference":"Find a handler for the line_info by trying checkers.","result":"Def find handler .","score":[0.0915,0.1176]}
{"code":"def transform_line(self, line, continue_prompt):\r\n        \"\"\" function to<extra_id_0>\r\n        for transformer in self.transformers:\r\n            if transformer.enabled:\r\n                line = transformer.transform(line, continue_prompt)\r\n        return line","reference":"Calls the enabled transformers in order of increasing priority.","result":"Def transform a line .","score":[0,0.0581]}
{"code":"def prefilter_line(self, line, continue_prompt=False):\r\n        \"\"\" function to<extra_id_0>\r\n        self.shell._last_input_line = line\r\n        if not line:\r\n            return ''\r\n        if not continue_prompt or (continue_prompt and self.multi_line_specials):\r\n            line = self.transform_line(line, continue_prompt)\r\n        line_info = LineInfo(line, continue_prompt)\r\n        stripped = line.strip()\r\n        normal_handler = self.get_handler_by_name('normal')\r\n        if not stripped:\r\n            if not continue_prompt:\r\n                self.shell.displayhook.prompt_count -= 1\r\n            return normal_handler.handle(line_info)\r\n        if continue_prompt and not self.multi_line_specials:\r\n            return normal_handler.handle(line_info)\r\n        prefiltered = self.prefilter_line_info(line_info)\r\n        return prefiltered","reference":"Prefilter a single input line as text.\n\n        This method prefilters a single line of text by calling the\n        transformers and then the checkers\/handlers.","result":"Prefilter a line .","score":[0.0043,0.0711]}
{"code":"def prefilter_lines(self, lines, continue_prompt=False):\r\n        \"\"\" function to<extra_id_0>\r\n        llines = lines.rstrip('\\n').split('\\n')\r\n        if len(llines) > 1:\r\n            out = '\\n'.join([self.prefilter_line(line, lnum>0)\r\n                             for lnum, line in enumerate(llines) ])\r\n        else:\r\n            out = self.prefilter_line(llines[0], continue_prompt)\r\n        return out","reference":"Prefilter multiple input lines of text.\n\n        This is the main entry point for prefiltering multiple lines of\n        input.  This simply calls :meth:`prefilter_line` for each line of\n        input.\n\n        This covers cases where there are multiple lines in the user entry,\n        which is the case when the user goes back to a multiline history\n        entry and presses enter.","result":"Prefilter lines .","score":[0.0,0.0197]}
{"code":"def check(self, line_info):\r\n        \"\"\" function to<extra_id_0>\r\n        \"Instances of IPyAutocall in user_ns get autocalled immediately\"\r\n        obj = self.shell.user_ns.get(line_info.ifun, None)\r\n        if isinstance(obj, IPyAutocall):\r\n            obj.set_ip(self.shell)\r\n            return self.prefilter_manager.get_handler_by_name('auto')\r\n        else:\r\n            return None","reference":"Instances of IPyAutocall in user_ns get autocalled immediately","result":" is an IPyAutocall .","score":[0.1175,0.0658]}
{"code":"def check(self, line_info):\r\n        \"\"\" function to<extra_id_0>\r\n        \"Allow ! and !! in multi-line statements if multi_line_specials is on\"\r\n        if line_info.continue_prompt \\\r\n            and self.prefilter_manager.multi_line_specials:\r\n                if line_info.esc == ESC_MAGIC:\r\n                    return self.prefilter_manager.get_handler_by_name('magic')\r\n        else:\r\n            return None","reference":"Allow ! and !! in multi-line statements if multi_line_specials is on","result":"Check multi.","score":[0,0.0]}
{"code":"def check(self, line_info):\r\n        \"\"\" function to<extra_id_0>\r\n        if line_info.line[-1] == ESC_HELP \\\r\n               and line_info.esc != ESC_SHELL \\\r\n               and line_info.esc != ESC_SH_CAP:\r\n            return self.prefilter_manager.get_handler_by_name('help')\r\n        else:\r\n            if line_info.pre:\r\n                return None\r\n            return self.prefilter_manager.get_handler_by_esc(line_info.esc)","reference":"Check for escape character and return either a handler to handle it,\n        or None if there is no escape char.","result":" is valid .","score":[0.0014,0.0273]}
{"code":"def check(self, line_info):\r\n        \"\"\" function to<extra_id_0>\r\n        \"Check if the initital identifier on the line is an alias.\"\r\n        head = line_info.ifun.split('.',1)[0]\r\n        if line_info.ifun not in self.shell.alias_manager \\\r\n               or head not in self.shell.alias_manager \\\r\n               or is_shadowed(head, self.shell):\r\n            return None\r\n        return self.prefilter_manager.get_handler_by_name('alias')","reference":"Check if the initital identifier on the line is an alias.","result":" is an alias .","score":[0.0785,0.182]}
{"code":"def handle(self, line_info):\r\n        \"\"\" function to<extra_id_0>\r\n        line = line_info.line\r\n        continue_prompt = line_info.continue_prompt\r\n        if (continue_prompt and\r\n            self.shell.autoindent and\r\n            line.isspace() and\r\n            0 < abs(len(line) - self.shell.indent_current_nsp) <= 2):\r\n            line = ''\r\n        return line","reference":"Handle normal input lines. Use as a template for handlers.","result":"If not line.","score":[0,0.0]}
{"code":"def handle(self, line_info):\r\n        \"\"\" function to<extra_id_0>\r\n        transformed = self.shell.alias_manager.expand_aliases(line_info.ifun,line_info.the_rest)\r\n        line_out = '%sget_ipython().system(%r)' % (line_info.pre_whitespace, transformed)\r\n        return line_out","reference":"Handle alias input lines.","result":"Handle the command line .","score":[0.2403,0.122]}
{"code":"def handle(self, line_info):\r\n        \"\"\" function to<extra_id_0>\r\n        magic_handler = self.prefilter_manager.get_handler_by_name('magic')\r\n        line = line_info.line\r\n        if line.lstrip().startswith(ESC_SH_CAP):\r\n            new_rest = line.lstrip()[2:]\r\n            line_info.line = '%ssx %s' % (ESC_MAGIC, new_rest)\r\n            line_info.ifun = 'sx'\r\n            line_info.the_rest = new_rest\r\n            return magic_handler.handle(line_info)\r\n        else:\r\n            cmd = line.lstrip().lstrip(ESC_SHELL)\r\n            line_out = '%sget_ipython().system(%r)' % (line_info.pre_whitespace, cmd)\r\n        return line_out","reference":"Execute the line in a shell, empty return value","result":"Handle the line .","score":[0.1294,0.2206]}
{"code":"def handle(self, line_info):\r\n        \"\"\" function to<extra_id_0>\r\n        ifun    = line_info.ifun\r\n        the_rest = line_info.the_rest\r\n        cmd = '%sget_ipython().magic(%r)' % (line_info.pre_whitespace,\r\n                                                    (ifun + \" \" + the_rest))\r\n        return cmd","reference":"Execute magic functions.","result":"Handle magic commands .","score":[0.3195,0.1613]}
{"code":"def handle(self, line_info):\r\n        \"\"\" function to<extra_id_0>\r\n        line    = line_info.line\r\n        ifun    = line_info.ifun\r\n        the_rest = line_info.the_rest\r\n        pre     = line_info.pre\r\n        esc     = line_info.esc\r\n        continue_prompt = line_info.continue_prompt\r\n        obj = line_info.ofind(self.shell)['obj']\r\n    if continue_prompt:\r\n            return line\r\n        force_auto = isinstance(obj, IPyAutocall)\r\n        try:\r\n            auto_rewrite = obj.rewrite\r\n        except Exception:\r\n            auto_rewrite = True\r\n        if esc == ESC_QUOTE:\r\n            newcmd = '%s(\"%s\")' % (ifun,'\", \"'.join(the_rest.split()) )\r\n        elif esc == ESC_QUOTE2:\r\n            newcmd = '%s(\"%s\")' % (ifun,the_rest)\r\n        elif esc == ESC_PAREN:\r\n            newcmd = '%s(%s)' % (ifun,\",\".join(the_rest.split()))\r\n        else:\r\n            if force_auto:\r\n                do_rewrite = not the_rest.startswith('(')\r\n            else:\r\n                if not the_rest:\r\n                    do_rewrite = (self.shell.autocall >= 2)\r\n                elif the_rest.startswith('[') and hasattr(obj, '__getitem__'):\r\n                    do_rewrite = False\r\n                else:\r\n                    do_rewrite = True\r\n            if do_rewrite:\r\n                if the_rest.endswith(';'):\r\n                    newcmd = '%s(%s);' % (ifun.rstrip(),the_rest[:-1])\r\n                else:\r\n                    newcmd = '%s(%s)' % (ifun.rstrip(), the_rest)                \r\n            else:\r\n                normal_handler = self.prefilter_manager.get_handler_by_name('normal')\r\n                return normal_handler.handle(line_info)\r\n                if auto_rewrite:\r\n            self.shell.auto_rewrite_input(newcmd)\r\n        return newcmd","reference":"Handle lines which can be auto-executed, quoting if requested.","result":"Handle the line .","score":[0.0915,0.1176]}
{"code":"def handle(self, line_info):\r\n        \"\"\" function to<extra_id_0>\r\n        normal_handler = self.prefilter_manager.get_handler_by_name('normal')\r\n        line = line_info.line\r\ntry:\r\n            codeop.compile_command(line)\r\n        except SyntaxError:\r\n            if line[0]==ESC_HELP:\r\n                line = line[1:]\r\n            elif line[-1]==ESC_HELP:\r\n                line = line[:-1]\r\n            if line:\r\n          self.shell.magic('pinfo %s' % line_info.ifun)\r\n            else:\r\n                self.shell.show_usage()\r\n            return ''\r\n        except:\r\n            raise\r\n            return normal_handler.handle(line_info)\r\n        else:\r\n            return normal_handler.handle(line_info)","reference":"Try to get some help for the object.\n\n        obj? or ?obj   -> basic information.\n        obj?? or ??obj -> more details.","result":"Handle a single line .","score":[0,0.0]}
{"code":"def eventFilter(self, obj, event):\r\n        \"\"\" function to<extra_id_0>\r\n        if obj == self._text_edit:\r\n            etype = event.type()\r\n            if etype == QtCore.QEvent.KeyPress:\r\n                key = event.key()\r\n                if key in (QtCore.Qt.Key_Enter, QtCore.Qt.Key_Return):\r\n                    self.hide()\r\n                elif key == QtCore.Qt.Key_Escape:\r\n                    self.hide()\r\n                    return True\r\n            elif etype == QtCore.QEvent.FocusOut:\r\n                self.hide()\r\n            elif etype == QtCore.QEvent.Enter:\r\n                self._hide_timer.stop()\r\n            elif etype == QtCore.QEvent.Leave:\r\n                self._leave_event_hide()\r\n        return super(CallTipWidget, self).eventFilter(obj, event)","reference":"Reimplemented to hide on certain key presses and on text edit focus\n            changes.","result":"Return False filter .","score":[0,0.0]}
{"code":"def enterEvent(self, event):\r\n        \"\"\" function to<extra_id_0>\r\n        super(CallTipWidget, self).enterEvent(event)\r\n        self._hide_timer.stop()","reference":"Reimplemented to cancel the hide timer.","result":"Handle call tips .","score":[0,0.0]}
{"code":"def paintEvent(self, event):\r\n        \"\"\" function to<extra_id_0>\r\n        painter = QtGui.QStylePainter(self)\r\n        option = QtGui.QStyleOptionFrame()\r\n        option.initFrom(self)\r\n        painter.drawPrimitive(QtGui.QStyle.PE_PanelTipLabel, option)\r\n        painter.end()\r\n        super(CallTipWidget, self).paintEvent(event)","reference":"Reimplemented to paint the background panel.","result":"Paint the call tip widget.","score":[0.1967,0.3178]}
{"code":"def show_call_info(self, call_line=None, doc=None, maxlines=20):\r\n        \"\"\" function to<extra_id_0>\r\n        if doc:\r\n            match = re.match(\"(?:[^\\n]*\\n){%i}\" % maxlines, doc)\r\n            if match:\r\n                doc = doc[:match.end()] + '\\n[Documentation continues...]'\r\n        else:\r\n            doc = ''\r\n        if call_line:\r\n            doc = '\\n\\n'.join([call_line, doc])\r\n        return self.show_tip(doc)","reference":"Attempts to show the specified call line and docstring at the\n            current cursor location. The docstring is possibly truncated for\n            length.","result":"Show call info .","score":[0.0046,0.0518]}
{"code":"def show_tip(self, tip):\r\n        \"\"\" function to<extra_id_0>\r\n        text_edit = self._text_edit\r\n        document = text_edit.document()\r\n        cursor = text_edit.textCursor()\r\n        search_pos = cursor.position() - 1\r\n        self._start_position, _ = self._find_parenthesis(search_pos,\r\n                                                         forward=False)\r\n        if self._start_position == -1:\r\n            return False\r\n        self.setText(tip)\r\n        self.resize(self.sizeHint())\r\n        padding = 3\r\n        cursor_rect = text_edit.cursorRect(cursor)\r\n        screen_rect = QtGui.qApp.desktop().screenGeometry(text_edit)\r\n        point = text_edit.mapToGlobal(cursor_rect.bottomRight())\r\n        point.setY(point.y() + padding)\r\n        tip_height = self.size().height()\r\n        tip_width = self.size().width()\r\n        vertical = 'bottom'\r\n        horizontal = 'Right'\r\n        if point.y() + tip_height > screen_rect.height():\r\n            point_ = text_edit.mapToGlobal(cursor_rect.topRight())\r\n            if point_.y() - tip_height < padding:\r\n                if 2*point.y() < screen_rect.height():\r\n                    vertical = 'bottom'\r\n                else:\r\n                    vertical = 'top'\r\n            else:\r\n                vertical = 'top'\r\n        if point.x() + tip_width > screen_rect.width():\r\n            point_ = text_edit.mapToGlobal(cursor_rect.topRight())\r\n            if point_.x() - tip_width < padding:\r\n                if 2*point.x() < screen_rect.width():\r\n                    horizontal = 'Right'\r\n                else:\r\n                    horizontal = 'Left'\r\n            else:\r\n                horizontal = 'Left'\r\n        pos = getattr(cursor_rect, '%s%s' %(vertical, horizontal))\r\n        point = text_edit.mapToGlobal(pos())\r\n        if vertical == 'top':\r\n            point.setY(point.y() - tip_height - padding)\r\n        if horizontal == 'Left':\r\n            point.setX(point.x() - tip_width - padding)\r\n        self.move(point)\r\n        self.show()\r\n        return True","reference":"Attempts to show the specified tip at the current cursor location.","result":"Show tip .","score":[0.0284,0.098]}
{"code":"def _cursor_position_changed(self):\r\n        \"\"\" function to<extra_id_0>\r\n        cursor = self._text_edit.textCursor()\r\n        if cursor.position() <= self._start_position:\r\n            self.hide()\r\n        else:\r\n            position, commas = self._find_parenthesis(self._start_position + 1)\r\n            if position != -1:\r\n                self.hide()","reference":"Updates the tip based on user cursor movement.","result":"Handle cursor position changes .","score":[0.1319,0.0649]}
{"code":"def proxied_attribute(local_attr, proxied_attr, doc):\r\n    \"\"\" function to<extra_id_0>\r\n    def fget(self):\r\n        return getattr(getattr(self, local_attr), proxied_attr)\r\n    def fset(self, value):\r\n        setattr(getattr(self, local_attr), proxied_attr, value)\r\n    def fdel(self):\r\n        delattr(getattr(self, local_attr), proxied_attr)\r\n    return property(fget, fset, fdel, doc)","reference":"Create a property that proxies attribute ``proxied_attr`` through\n    the local attribute ``local_attr``.","result":"Create a proxied attribute .","score":[0.0927,0.2793]}
{"code":"def canonicalize_path(cwd, path):\r\n    \"\"\" function to<extra_id_0>\r\n    if not os.path.isabs(path):\r\n        path = os.path.join(cwd, path)\r\n    return os.path.abspath(path)","reference":"Canonicalizes a path relative to a given working directory.  That\n    is, the path, if not absolute, is interpreted relative to the\n    working directory, then converted to absolute form.\n\n    :param cwd: The working directory.\n    :param path: The path to canonicalize.\n\n    :returns: The absolute path.","result":"Canonicalize a path .","score":[0.0,0.0384]}
{"code":"def schema_validate(instance, schema, exc_class, *prefix, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    try:\r\n        jsonschema.validate(instance, schema)\r\n    except jsonschema.ValidationError as exc:\r\n        path = '\/'.join((a if isinstance(a, six.string_types) else '[%d]' % a)\r\n                        for a in itertools.chain(prefix, exc.path))\r\n        message = 'Failed to validate \"%s\": %s' % (path, exc.message)\r\n        raise exc_class(message, **kwargs)","reference":"Schema validation helper.  Performs JSONSchema validation.  If a\n    schema validation error is encountered, an exception of the\n    designated class is raised with the validation error message\n    appropriately simplified and passed as the sole positional\n    argument.\n\n    :param instance: The object to schema validate.\n    :param schema: The schema to use for validation.\n    :param exc_class: The exception class to raise instead of the\n                      ``jsonschema.ValidationError`` exception.\n    :param prefix: Positional arguments are interpreted as a list of\n                   keys to prefix to the path contained in the\n                   validation error.\n    :param kwargs: Keyword arguments to pass to the exception\n                   constructor.","result":"Validate an instance against a schema .","score":[0.0,0.0237]}
{"code":"def masked(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._masked is None:\r\n            self._masked = MaskedDict(self)\r\n        return self._masked","reference":"Retrieve a read-only subordinate mapping.  All values are\n        stringified, and sensitive values are masked.  The subordinate\n        mapping implements the context manager protocol for\n        convenience.","result":"Return a masked dictionary .","score":[0.0054,0.0226]}
{"code":"def virtualenv_no_global():\r\n    \"\"\" function to<extra_id_0>\r\n    site_mod_dir = os.path.dirname(os.path.abspath(site.__file__))\r\n    no_global_file = os.path.join(site_mod_dir, 'no-global-site-packages.txt')\r\n    if running_under_virtualenv() and os.path.isfile(no_global_file):\r\n        return True","reference":"Return True if in a venv and no system site packages.","result":" is running under a virtualenv .","score":[0.0839,0.0476]}
{"code":"def pwordfreq(view, fnames):\r\n    \"\"\" function to<extra_id_0>\r\n    assert len(fnames) == len(view.targets)\r\n    view.scatter('fname', fnames, flatten=True)\r\n    ar = view.apply(wordfreq, Reference('fname'))\r\n    freqs_list = ar.get()\r\n    word_set = set()\r\n    for f in freqs_list:\r\n        word_set.update(f.keys())\r\n    freqs = dict(zip(word_set, repeat(0)))\r\n    for f in freqs_list:\r\n        for word, count in f.iteritems():\r\n            freqs[word] += count\r\n    return freqs","reference":"Parallel word frequency counter.\n    \n    view - An IPython DirectView\n    fnames - The filenames containing the split data.","result":"Def calculate word frequency .","score":[0.0308,0.1187]}
{"code":"def view_decorator(function_decorator):\r\n\"\"\" function to<extra_id_0>\r\n\t\"\"\"Convert a function based decorator into a class based decorator usable\r\n\ton class based Views.\r\n\tCan't subclass the `View` as it breaks inheritance (super in particular),\r\n\tso we monkey-patch instead.\r\n\tBased on http:\/\/stackoverflow.com\/a\/8429311\r\n\t\"\"\"\r\n\tdef simple_decorator(View):\r\n\t\tView.dispatch = method_decorator(function_decorator)(View.dispatch)\r\n\t\treturn View\r\n\treturn simple_decorator","reference":"Convert a function based decorator into a class based decorator usable\n\ton class based Views.\n\n\tCan't subclass the `View` as it breaks inheritance (super in particular),\n\tso we monkey-patch instead.\n\n\tBased on http:\/\/stackoverflow.com\/a\/8429311","result":"Convert a function based decorator into a class based decorator .","score":[0.122,0.2896]}
{"code":"def default_aliases():\r\n    \"\"\" function to<extra_id_0>\r\n    if os.name == 'posix':\r\n        default_aliases = [('mkdir', 'mkdir'), ('rmdir', 'rmdir'),\r\n                           ('mv', 'mv -i'), ('rm', 'rm -i'), ('cp', 'cp -i'),\r\n                           ('cat', 'cat'),\r\n                           ]\r\n        if sys.platform.startswith('linux'):\r\n            ls_aliases = [('ls', 'ls -F --color'),\r\n                          ('ll', 'ls -F -o --color'),\r\n                          ('lf', 'ls -F -o --color %l | grep ^-'),\r\n                          ('lk', 'ls -F -o --color %l | grep ^l'),\r\n                          ('ldir', 'ls -F -o --color %l | grep \/$'),\r\n                          ('lx', 'ls -F -o --color %l | grep ^-..x'),\r\n                          ]\r\n        else:\r\n            ls_aliases = [('ls', 'ls -F'),\r\n                          ('ll', 'ls -F -l'),\r\n                          ('lf', 'ls -F -l %l | grep ^-'),\r\n                          ('lk', 'ls -F -l %l | grep ^l'),\r\n                          ('ldir', 'ls -F -l %l | grep \/$'),\r\n                          ('lx', 'ls -F -l %l | grep ^-..x'),\r\n                          ]\r\n        default_aliases = default_aliases + ls_aliases\r\n    elif os.name in ['nt', 'dos']:\r\n        default_aliases = [('ls', 'dir \/on'),\r\n                           ('ddir', 'dir \/ad \/on'), ('ldir', 'dir \/ad \/on'),\r\n                           ('mkdir', 'mkdir'), ('rmdir', 'rmdir'),\r\n                           ('echo', 'echo'), ('ren', 'ren'), ('copy', 'copy'),\r\n                           ]\r\n    else:\r\n        default_aliases = []\r\n    return default_aliases","reference":"Return list of shell aliases to auto-define.","result":"Return the default aliases for the current platform .","score":[0.1449,0.1389]}
{"code":"def soft_define_alias(self, name, cmd):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            self.define_alias(name, cmd)\r\n        except AliasError, e:\r\n            error(\"Invalid alias: %s\" % e)","reference":"Define an alias, but don't raise on an AliasError.","result":"Def define alias .","score":[0,0.0588]}
{"code":"def define_alias(self, name, cmd):\r\n        \"\"\" function to<extra_id_0>\r\n        nargs = self.validate_alias(name, cmd)\r\n        self.alias_table[name] = (nargs, cmd)","reference":"Define a new alias after validating it.\n\n        This will raise an :exc:`AliasError` if there are validation\n        problems.","result":"Def define an alias .","score":[0.0259,0.0949]}
{"code":"def validate_alias(self, name, cmd):\r\n        \"\"\" function to<extra_id_0>\r\n        if name in self.no_alias:\r\n            raise InvalidAliasError(\"The name %s can't be aliased \"\r\n                                    \"because it is a keyword or builtin.\" % name)\r\n        if not (isinstance(cmd, basestring)):\r\n            raise InvalidAliasError(\"An alias command must be a string, \"\r\n                                    \"got: %r\" % cmd)\r\n        nargs = cmd.count('%s')\r\n        if nargs>0 and cmd.find('%l')>=0:\r\n            raise InvalidAliasError('The %s and %l specifiers are mutually '\r\n                                    'exclusive in alias definitions.')\r\n        return nargs","reference":"Validate an alias and return the its number of arguments.","result":"Validate an alias definition .","score":[0.1821,0.3099]}
{"code":"def call_alias(self, alias, rest=''):\r\n        \"\"\" function to<extra_id_0>\r\n        cmd = self.transform_alias(alias, rest)\r\n        try:\r\n            self.shell.system(cmd)\r\n        except:\r\n            self.shell.showtraceback()","reference":"Call an alias given its name and the rest of the line.","result":"Call an alias .","score":[0.0891,0.2629]}
{"code":"def transform_alias(self, alias,rest=''):\r\n        \"\"\" function to<extra_id_0>\r\n        nargs, cmd = self.alias_table[alias]\r\n        if ' ' in cmd and os.path.isfile(cmd):\r\n            cmd = '\"%s\"' % cmd\r\n        if cmd.find('%l') >= 0:\r\n            cmd = cmd.replace('%l', rest)\r\n            rest = ''\r\n        if nargs==0:\r\n            cmd = '%s %s' % (cmd, rest)\r\n        else:\r\n            args = rest.split(None, nargs)\r\n            if len(args) < nargs:\r\n                raise AliasError('Alias <%s> requires %s arguments, %s given.' %\r\n                      (alias, nargs, len(args)))\r\n            cmd = '%s %s' % (cmd % tuple(args[:nargs]),' '.join(args[nargs:]))\r\n        return cmd","reference":"Transform alias to system command string.","result":"Transform an alias .","score":[0.2304,0.1724]}
{"code":"def expand_alias(self, line):\r\n        \"\"\" function to<extra_id_0>\r\n        pre,_,fn,rest = split_user_input(line)\r\n        res = pre + self.expand_aliases(fn, rest)\r\n        return res","reference":"Expand an alias in the command line\n\n        Returns the provided command line, possibly with the first word\n        (command) translated according to alias expansion rules.\n\n        [ipython]|16> _ip.expand_aliases(\"np myfile.txt\")\n                 <16> 'q:\/opt\/np\/notepad++.exe myfile.txt'","result":"Expand aliases .","score":[0.0001,0.0183]}
{"code":"def autohelp_directive(dirname, arguments, options, content, lineno,\r\n                       \"\"\" function to<extra_id_0>\r\n                       content_offset, block_text, state, state_machine):\r\n    config = Config(parserClass=OptBucket,\r\n                    plugins=BuiltinPluginManager())\r\n    parser = config.getParser(TestProgram.usage())\r\n    rst = ViewList()\r\n    for line in parser.format_help().split('\\n'):\r\n        rst.append(line, '<autodoc>')\r\n    rst.append('Options', '<autodoc>')\r\n    rst.append('-------', '<autodoc>')\r\n    rst.append('', '<autodoc>')\r\n    for opt in parser:\r\n        rst.append(opt.options(), '<autodoc>')\r\n        rst.append('   \\n', '<autodoc>')\r\n        rst.append('   ' + opt.help + '\\n', '<autodoc>')\r\n        rst.append('\\n', '<autodoc>')    \r\n    node = nodes.section()\r\n    node.document = state.document\r\n    surrounding_title_styles = state.memo.title_styles\r\n    surrounding_section_level = state.memo.section_level\r\n    state.memo.title_styles = []\r\n    state.memo.section_level = 0\r\n    state.nested_parse(rst, 0, node, match_titles=1)\r\n    state.memo.title_styles = surrounding_title_styles\r\n    state.memo.section_level = surrounding_section_level\r\n    return node.children","reference":"produces rst from nose help","result":"Generate the help text .","score":[0.2403,0.1]}
{"code":"def reset_sgr(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self.intensity = 0\r\n        self.italic = False\r\n        self.bold = False\r\n        self.underline = False\r\n        self.foreground_color = None\r\n        self.background_color = None","reference":"Reset graphics attributs to their default values.","result":"Def reset the SGR .","score":[0,0.0735]}
{"code":"def split_string(self, string):\r\n        \"\"\" function to<extra_id_0>\r\n        self.actions = []\r\n        start = 0\r\n        last_char = '\\n' if len(string) > 0 and string[-1] == '\\n' else None\r\n        string = string[:-1] if last_char is not None else string\r\n        for match in ANSI_OR_SPECIAL_PATTERN.finditer(string):\r\n            raw = string[start:match.start()]\r\n            substring = SPECIAL_PATTERN.sub(self._replace_special, raw)\r\n            if substring or self.actions:\r\n                yield substring\r\n                self.actions = []\r\n            start = match.end()\r\n            groups = filter(lambda x: x is not None, match.groups())\r\n            g0 = groups[0]\r\n            if g0 == '\\a':\r\n                self.actions.append(BeepAction('beep'))\r\n                yield None\r\n                self.actions = []\r\n            elif g0 == '\\r':\r\n                self.actions.append(CarriageReturnAction('carriage-return'))\r\n                yield None\r\n                self.actions = []\r\n            elif g0 == '\\b':\r\n                self.actions.append(BackSpaceAction('backspace'))\r\n                yield None\r\n                self.actions = []\r\n            elif g0 == '\\n' or g0 == '\\r\\n':\r\n                self.actions.append(NewLineAction('newline'))\r\n                yield g0\r\n                self.actions = []\r\n            else:\r\n                params = [ param for param in groups[1].split(';') if param ]\r\n                if g0.startswith('['):\r\n                    try:\r\n                        params = map(int, params)\r\n                    except ValueError:\r\n                        pass\r\n                    else:\r\n                        self.set_csi_code(groups[2], params)\r\n                elif g0.startswith(']'):\r\n                    self.set_osc_code(params)\r\n        raw = string[start:]\r\n        substring = SPECIAL_PATTERN.sub(self._replace_special, raw)\r\n        if substring or self.actions:\r\n            yield substring\r\n        if last_char is not None:\r\n            self.actions.append(NewLineAction('newline'))\r\n            yield last_char","reference":"Yields substrings for which the same escape code applies.","result":"Split a string into ANSI and ANSI codes .","score":[0,0.0556]}
{"code":"def get_color(self, color, intensity=0):\r\n        \"\"\" function to<extra_id_0>\r\n        if color is None:\r\n            return None\r\n        if color < 8 and intensity > 0:\r\n            color += 8\r\n        constructor = self.color_map.get(color, None)\r\n        if isinstance(constructor, basestring):\r\n            return QtGui.QColor(constructor)\r\n        elif isinstance(constructor, (tuple, list)):\r\n            return QtGui.QColor(*constructor)\r\n        return None","reference":"Returns a QColor for a given color code, or None if one cannot be\n            constructed.","result":"Get color .","score":[0.0075,0.0362]}
{"code":"def get_format(self):\r\n        \"\"\" function to<extra_id_0>\r\n        format = QtGui.QTextCharFormat()\r\n        qcolor = self.get_color(self.foreground_color, self.intensity)\r\n        if qcolor is not None:\r\n            format.setForeground(qcolor)\r\n        qcolor = self.get_color(self.background_color, self.intensity)\r\n        if qcolor is not None:\r\n            format.setBackground(qcolor)\r\n        if self.bold:\r\n            format.setFontWeight(QtGui.QFont.Bold)\r\n        else:\r\n            format.setFontWeight(QtGui.QFont.Normal)\r\n        format.setFontItalic(self.italic)\r\n        format.setFontUnderline(self.underline)\r\n        return format","reference":"Returns a QTextCharFormat that encodes the current style attributes.","result":"Get the format for the text .","score":[0.1214,0.0568]}
{"code":"def generate(secret, age, **payload):\r\n    \"\"\" function to<extra_id_0>\r\n    jti = str(uuid.uuid1())\r\n    if not payload:\r\n        payload = {}\r\n    payload['exp'] = int(time.time() + age)\r\n    payload['jti'] = jti\r\n    return jwt.encode(payload, decode_secret(secret))","reference":"Generate a one-time jwt with an age in seconds","result":"And generate a JWT .","score":[0.108,0.2972]}
{"code":"def mutex(func):\r\n    \"\"\" function to<extra_id_0>\r\n    def wrapper(*args, **kwargs):\r\n        lock = args[0].lock\r\n        lock.acquire(True)\r\n        try:\r\n            return func(*args, **kwargs)\r\n        except:\r\n            raise\r\n        finally:\r\n            lock.release()\r\n    return wrapper","reference":"use a thread lock on current method, if self.lock is defined","result":"Wrap a mutex function .","score":[0.0724,0.0962]}
{"code":"def _clean(self):\r\n        \"\"\" function to<extra_id_0>\r\n        now = time.time()\r\n        for jwt in self.jwts.keys():\r\n            if (now - self.jwts[jwt]) > (self.age * 2):\r\n                del self.jwts[jwt]","reference":"Run by housekeeper thread","result":"Clean up the cache .","score":[0,0.0]}
{"code":"def already_used(self, tok):\r\n        \"\"\" function to<extra_id_0>\r\n        if tok in self.jwts:\r\n            return True\r\n        self.jwts[tok] = time.time()\r\n        return False","reference":"has this jwt been used?","result":" is already used .","score":[0,0.0]}
{"code":"def valid(self, token):\r\n        \"\"\" function to<extra_id_0>\r\n        now = time.time()\r\n        if 'Bearer ' in token:\r\n            token = token[7:]\r\n        data = None\r\n        for secret in self.secrets:\r\n            try:\r\n                data = jwt.decode(token, secret)\r\n                break\r\n            except jwt.DecodeError:\r\n                continue\r\n            except jwt.ExpiredSignatureError:\r\n                raise JwtFailed(\"Jwt expired\")\r\n        if not data:\r\n            raise JwtFailed(\"Jwt cannot be decoded\")\r\n        exp = data.get('exp')\r\n        if not exp:\r\n            raise JwtFailed(\"Jwt missing expiration (exp)\")\r\n        if now - exp > self.age:\r\n            raise JwtFailed(\"Jwt bad expiration - greater than I want to accept\")\r\n        jti = data.get('jti')\r\n        if not jti:\r\n            raise JwtFailed(\"Jwt missing one-time id (jti)\")\r\n        if self.already_used(jti):\r\n            raise JwtFailed(\"Jwt re-use disallowed (jti={})\".format(jti))\r\n        return data","reference":"is this token valid?","result":" is valid .","score":[0.2925,0.1282]}
{"code":"def semaphore(count: int, bounded: bool=False):\r\n    \"\"\" function to<extra_id_0>\r\n    '''\r\n    use `Semaphore` to keep func access thread-safety.\r\n    example:\r\n    ``` py\r\n    @semaphore(3)\r\n    def func(): pass\r\n    ```\r\n    '''\r\n    lock_type = threading.BoundedSemaphore if bounded else threading.Semaphore\r\n    lock_obj = lock_type(value=count)\r\n    return with_it(lock_obj)","reference":"use `Semaphore` to keep func access thread-safety.\n\n    example:\n\n    ``` py\n    @semaphore(3)\n    def func(): pass\n    ```","result":"Use as decorator .","score":[0,0.036]}
{"code":"def commonprefix(items):\r\n    \"\"\" function to<extra_id_0>\r\n    first_match  = ESCAPE_RE.match(min(items))\r\n    last_match  = ESCAPE_RE.match(max(items))\r\n    if first_match and last_match:\r\n        prefix = os.path.commonprefix((first_match.group(0)[::-1], last_match.group(0)[::-1]))[::-1]\r\n    else:\r\n        prefix = ''\r\n    items = [s.lstrip(ESCAPE_CHARS) for s in items]\r\n    return prefix+os.path.commonprefix(items)","reference":"Get common prefix for completions\n\n    Return the longest common prefix of a list of strings, but with special\n    treatment of escape characters that might precede commands in IPython,\n    such as %magic functions. Used in tab completion.\n\n    For a more general function, see os.path.commonprefix","result":"Return the common prefix of a list of strings .","score":[0.0232,0.159]}
{"code":"def eventFilter(self, obj, event):\r\n        \"\"\" function to<extra_id_0>\r\n        etype = event.type()\r\n        if etype == QtCore.QEvent.KeyPress:\r\n            key = event.key()\r\n            if self._control_key_down(event.modifiers()) and \\\r\n                    key in self._ctrl_down_remap:\r\n                new_event = QtGui.QKeyEvent(QtCore.QEvent.KeyPress,\r\n                                            self._ctrl_down_remap[key],\r\n                                            QtCore.Qt.NoModifier)\r\n                QtGui.qApp.sendEvent(obj, new_event)\r\n                return True\r\n            elif obj == self._control:\r\n                return self._event_filter_console_keypress(event)\r\n            elif obj == self._page_control:\r\n                return self._event_filter_page_keypress(event)\r\n        elif etype == QtCore.QEvent.MouseButtonRelease and \\\r\n                event.button() == QtCore.Qt.MidButton and \\\r\n                obj == self._control.viewport():\r\n            cursor = self._control.cursorForPosition(event.pos())\r\n            self._control.setTextCursor(cursor)\r\n            self.paste(QtGui.QClipboard.Selection)\r\n            return True\r\n        elif etype == QtCore.QEvent.Resize and not self._filter_resize:\r\n            self._filter_resize = True\r\n            QtGui.qApp.sendEvent(obj, event)\r\n            self._adjust_scrollbars()\r\n            self._filter_resize = False\r\n            return True\r\n        elif etype == QtCore.QEvent.ShortcutOverride and \\\r\n                self.override_shortcuts and \\\r\n                self._control_key_down(event.modifiers()) and \\\r\n                event.key() in self._shortcuts:\r\n            event.accept()\r\n        elif etype == QtCore.QEvent.DragEnter and \\\r\n                obj == self._control.viewport() and \\\r\n                event.source() == self._control.viewport():\r\n            self._filter_drag = True\r\n        elif etype == QtCore.QEvent.DragLeave and \\\r\n                obj == self._control.viewport() and \\\r\n                self._filter_drag:\r\n            cursor = self._control.textCursor()\r\n            cursor.clearSelection()\r\n            self._control.setTextCursor(cursor)\r\n            self._filter_drag = False\r\n        elif etype == QtCore.QEvent.Drop and obj == self._control.viewport():\r\n            cursor = self._control.cursorForPosition(event.pos())\r\n            if self._in_buffer(cursor.position()):\r\n                text = event.mimeData().text()\r\n                self._insert_plain_text_into_buffer(cursor, text)\r\n            QtGui.qApp.sendEvent(obj, QtGui.QDragLeaveEvent())\r\n            return True\r\n        elif etype in self._pager_scroll_events and \\\r\n                obj == self._page_control:\r\n            self._page_control.repaint()\r\n            return True\r\n        return super(ConsoleWidget, self).eventFilter(obj, event)","reference":"Reimplemented to ensure a console-like behavior in the underlying\n            text widgets.","result":"Return False.","score":[0,0.0]}
{"code":"def sizeHint(self):\r\n        \"\"\" function to<extra_id_0>\r\n        font_metrics = QtGui.QFontMetrics(self.font)\r\n        margin = (self._control.frameWidth() +\r\n                  self._control.document().documentMargin()) * 2\r\n        style = self.style()\r\n        splitwidth = style.pixelMetric(QtGui.QStyle.PM_SplitterWidth)\r\n        width = font_metrics.width(' ') * 81 + margin\r\n        width += style.pixelMetric(QtGui.QStyle.PM_ScrollBarExtent)\r\n        if self.paging == 'hsplit':\r\n            width = width * 2 + splitwidth\r\n        height = font_metrics.height() * 25 + margin\r\n        if self.paging == 'vsplit':\r\n            height = height * 2 + splitwidth\r\n        return QtCore.QSize(width, height)","reference":"Reimplemented to suggest a size that is 80 characters wide and\n            25 lines high.","result":"Return the size hint for this splitter .","score":[0.0656,0.0746]}
{"code":"def can_cut(self):\r\n        \"\"\" function to<extra_id_0>\r\n        cursor = self._control.textCursor()\r\n        return (cursor.hasSelection() and\r\n                self._in_buffer(cursor.anchor()) and\r\n                self._in_buffer(cursor.position()))","reference":"Returns whether text can be cut to the clipboard.","result":"Check if text can be cut .","score":[0.3799,0.451]}
{"code":"def can_paste(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._control.textInteractionFlags() & QtCore.Qt.TextEditable:\r\n            return bool(QtGui.QApplication.clipboard().text())\r\n        return False","reference":"Returns whether text can be pasted from the clipboard.","result":" is editable .","score":[0,0.0595]}
{"code":"def clear(self, keep_input=True):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._executing:\r\n            self._control.clear()\r\n        else:\r\n            if keep_input:\r\n                input_buffer = self.input_buffer\r\n            self._control.clear()\r\n            self._show_prompt()\r\n            if keep_input:\r\n                self.input_buffer = input_buffer","reference":"Clear the console.\n\n        Parameters:\n        -----------\n        keep_input : bool, optional (default True)\n            If set, restores the old input buffer if a new prompt is written.","result":"Clear the prompt .","score":[0.0034,0.0682]}
{"code":"def cut(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self.copy()\r\n        if self.can_cut():\r\n            self._control.textCursor().removeSelectedText()","reference":"Copy the currently selected text to the clipboard and delete it\n            if it's inside the input buffer.","result":"Cut the text .","score":[0.0147,0.0637]}
{"code":"def execute(self, source=None, hidden=False, interactive=False):\r\n        \"\"\" function to<extra_id_0>\r\n        if source is None:\r\n            source = self.input_buffer\r\n            if not hidden:\r\n                source += '\\n'\r\n        elif not hidden:\r\n            self.input_buffer = source\r\n        complete = self._is_complete(source, interactive)\r\n        if hidden:\r\n            if complete:\r\n                self._execute(source, hidden)\r\n            else:\r\n                error = 'Incomplete noninteractive input: \"%s\"'\r\n                raise RuntimeError(error % source)\r\n        else:\r\n            if complete:\r\n                self._append_plain_text('\\n')\r\n                self._input_buffer_executing = self.input_buffer\r\n                self._executing = True\r\n                self._prompt_finished()\r\n                self._control.document().setMaximumBlockCount(self.buffer_size)\r\n                self._control.setUndoRedoEnabled(False)\r\n                self._execute(source, hidden)\r\n            else:\r\n                cursor = self._get_end_cursor()\r\n                cursor.beginEditBlock()\r\n                cursor.insertText('\\n')\r\n                self._insert_continuation_prompt(cursor)\r\n                cursor.endEditBlock()\r\n                self._control.moveCursor(QtGui.QTextCursor.End)\r\n        return complete","reference":"Executes source or the input buffer, possibly prompting for more\n        input.\n\n        Parameters:\n        -----------\n        source : str, optional\n\n            The source to execute. If not specified, the input buffer will be\n            used. If specified and 'hidden' is False, the input buffer will be\n            replaced with the source before execution.\n\n        hidden : bool, optional (default False)\n\n            If set, no output will be shown and the prompt will not be modified.\n            In other words, it will be completely invisible to the user that\n            an execution has occurred.\n\n        interactive : bool, optional (default False)\n\n            Whether the console is to treat the source as having been manually\n            entered by the user. The effect of this parameter depends on the\n            subclass implementation.\n\n        Raises:\n        -------\n        RuntimeError\n            If incomplete input is given and 'hidden' is True. In this case,\n            it is not possible to prompt for more input.\n\n        Returns:\n        --------\n        A boolean indicating whether the source was executed.","result":"Execute the command .","score":[5.771e-17,0.0074]}
{"code":"def _get_input_buffer(self, force=False):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._executing and not force:\r\n            return self._input_buffer_executing\r\n        cursor = self._get_end_cursor()\r\n        cursor.setPosition(self._prompt_pos, QtGui.QTextCursor.KeepAnchor)\r\n        input_buffer = cursor.selection().toPlainText()\r\n        return input_buffer.replace('\\n' + self._continuation_prompt, '\\n')","reference":"The text that the user has entered entered at the current prompt.\n\n        If the console is currently executing, the text that is executing will\n        always be returned.","result":"Get the input buffer .","score":[0.003,0.0202]}
{"code":"def _set_input_buffer(self, string):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._executing:\r\n            self._input_buffer_pending = string\r\n            return\r\n        cursor = self._get_end_cursor()\r\n        cursor.beginEditBlock()\r\n        cursor.setPosition(self._prompt_pos, QtGui.QTextCursor.KeepAnchor)\r\n        cursor.removeSelectedText()\r\n        self._insert_plain_text_into_buffer(self._get_prompt_cursor(), string)\r\n        cursor.endEditBlock()\r\n        self._control.moveCursor(QtGui.QTextCursor.End)","reference":"Sets the text in the input buffer.\n\n        If the console is currently executing, this call has no *immediate*\n        effect. When the execution is finished, the input buffer will be updated\n        appropriately.","result":"Set the input buffer .","score":[0.0027,0.132]}
{"code":"def _set_font(self, font):\r\n        \"\"\" function to<extra_id_0>\r\n        font_metrics = QtGui.QFontMetrics(font)\r\n        self._control.setTabStopWidth(self.tab_width * font_metrics.width(' '))\r\n        self._completion_widget.setFont(font)\r\n        self._control.document().setDefaultFont(font)\r\n        if self._page_control:\r\n            self._page_control.document().setDefaultFont(font)\r\n        self.font_changed.emit(font)","reference":"Sets the base font for the ConsoleWidget to the specified QFont.","result":"Set the font of the control widget .","score":[0.1256,0.1869]}
{"code":"def paste(self, mode=QtGui.QClipboard.Clipboard):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._control.textInteractionFlags() & QtCore.Qt.TextEditable:\r\n            self._keep_cursor_in_buffer()\r\n            cursor = self._control.textCursor()\r\n            text = QtGui.QApplication.clipboard().text(mode).rstrip()\r\n            self._insert_plain_text_into_buffer(cursor, dedent(text))","reference":"Paste the contents of the clipboard into the input region.\n\n        Parameters:\n        -----------\n        mode : QClipboard::Mode, optional [default QClipboard::Clipboard]\n\n            Controls which part of the system clipboard is used. This can be\n            used to access the selection clipboard in X11 and the Find buffer\n            in Mac OS. By default, the regular clipboard is used.","result":"Paste text .","score":[0.0,0.0106]}
{"code":"def print_(self, printer = None):\r\n        \"\"\" function to<extra_id_0>\r\n        if (not printer):\r\n            printer = QtGui.QPrinter()\r\n            if(QtGui.QPrintDialog(printer).exec_() != QtGui.QDialog.Accepted):\r\n                return\r\n        self._control.print_(printer)","reference":"Print the contents of the ConsoleWidget to the specified QPrinter.","result":"Print the control to the given printer .","score":[0.2013,0.3221]}
{"code":"def prompt_to_top(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if not self._executing:\r\n            prompt_cursor = self._get_prompt_cursor()\r\n            if self._get_cursor().blockNumber() < prompt_cursor.blockNumber():\r\n                self._set_cursor(prompt_cursor)\r\n            self._set_top_cursor(prompt_cursor)","reference":"Moves the prompt to the top of the viewport.","result":"Prompt to the top of the prompt .","score":[0.5588,0.7556]}
{"code":"def reset_font(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if sys.platform == 'win32':\r\n            fallback = 'Courier'\r\n        elif sys.platform == 'darwin':\r\n            fallback = 'Monaco'\r\n        else:\r\n            fallback = 'Monospace'\r\n        font = get_font(self.font_family, fallback)\r\n        if self.font_size:\r\n            font.setPointSize(self.font_size)\r\n        else:\r\n            font.setPointSize(QtGui.qApp.font().pointSize())\r\n        font.setStyleHint(QtGui.QFont.TypeWriter)\r\n        self._set_font(font)","reference":"Sets the font to the default fixed-width font for this platform.","result":"Reset the font .","score":[0.0785,0.0971]}
{"code":"def _append_custom(self, insert, input, before_prompt=False):\r\n        \"\"\" function to<extra_id_0>\r\n        cursor = self._control.textCursor()\r\n        if before_prompt and (self._reading or not self._executing):\r\n            cursor.setPosition(self._append_before_prompt_pos)\r\n        else:\r\n            cursor.movePosition(QtGui.QTextCursor.End)\r\n        start_pos = cursor.position()\r\n        result = insert(cursor, input)\r\n        if before_prompt and not self._executing:\r\n            diff = cursor.position() - start_pos\r\n            self._append_before_prompt_pos += diff\r\n            self._prompt_pos += diff\r\n        return result","reference":"A low-level method for appending content to the end of the buffer.\n\n        If 'before_prompt' is enabled, the content will be inserted before the\n        current prompt, if there is one.","result":"Append custom text .","score":[0,0.0189]}
{"code":"def _append_html(self, html, before_prompt=False):\r\n        \"\"\" function to<extra_id_0>\r\n        self._append_custom(self._insert_html, html, before_prompt)","reference":"Appends HTML at the end of the console buffer.","result":"Append html .","score":[0,0.2232]}
{"code":"def _append_html_fetching_plain_text(self, html, before_prompt=False):\r\n        \"\"\" function to<extra_id_0>\r\n        return self._append_custom(self._insert_html_fetching_plain_text,\r\n                                   html, before_prompt)","reference":"Appends HTML, then returns the plain text version of it.","result":"Append html fetching text .","score":[0.0884,0.1053]}
{"code":"def _append_plain_text(self, text, before_prompt=False):\r\n        \"\"\" function to<extra_id_0>\r\n        self._append_custom(self._insert_plain_text, text, before_prompt)","reference":"Appends plain text, processing ANSI codes if enabled.","result":"Append plain text .","score":[0.1175,0.2467]}
{"code":"def _clear_temporary_buffer(self):\r\n        \"\"\" function to<extra_id_0>\r\n        cursor = self._get_prompt_cursor()\r\n        prompt = self._continuation_prompt.lstrip()\r\n        if(self._temp_buffer_filled):\r\n            self._temp_buffer_filled = False\r\n            while cursor.movePosition(QtGui.QTextCursor.NextBlock):\r\n                temp_cursor = QtGui.QTextCursor(cursor)\r\n                temp_cursor.select(QtGui.QTextCursor.BlockUnderCursor)\r\n                text = temp_cursor.selection().toPlainText().lstrip()\r\n                if not text.startswith(prompt):\r\n                    break\r\n        else:\r\n            return\r\n        cursor.movePosition(QtGui.QTextCursor.Left)\r\n        cursor.movePosition(QtGui.QTextCursor.End,\r\n                            QtGui.QTextCursor.KeepAnchor)\r\n        cursor.removeSelectedText()\r\n        if self._control.isUndoRedoEnabled():\r\n            self._control.setUndoRedoEnabled(False)\r\n            self._control.setUndoRedoEnabled(True)","reference":"Clears the \"temporary text\" buffer, i.e. all the text following\n            the prompt region.","result":"Def clear temporary buffer .","score":[0,0.041]}
{"code":"def _complete_with_items(self, cursor, items):\r\n        \"\"\" function to<extra_id_0>\r\n        self._cancel_completion()\r\n        if len(items) == 1:\r\n            cursor.setPosition(self._control.textCursor().position(),\r\n                               QtGui.QTextCursor.KeepAnchor)\r\n            cursor.insertText(items[0])\r\n        elif len(items) > 1:\r\n            current_pos = self._control.textCursor().position()\r\n            prefix = commonprefix(items)\r\n            if prefix:\r\n                cursor.setPosition(current_pos, QtGui.QTextCursor.KeepAnchor)\r\n                cursor.insertText(prefix)\r\n                current_pos = cursor.position()\r\n            cursor.movePosition(QtGui.QTextCursor.Left, n=len(prefix))\r\n            self._completion_widget.show_items(cursor, items)","reference":"Performs completion with 'items' at the specified cursor location.","result":"Complete items .","score":[0,0.0595]}
{"code":"def _fill_temporary_buffer(self, cursor, text, html=False):\r\n        \"\"\" function to<extra_id_0>\r\n        current_pos = self._control.textCursor().position()\r\n        cursor.beginEditBlock()\r\n        self._append_plain_text('\\n')\r\n        self._page(text, html=html)\r\n        cursor.endEditBlock()\r\n        cursor.setPosition(current_pos)\r\n        self._control.moveCursor(QtGui.QTextCursor.End)\r\n        self._control.setTextCursor(cursor)\r\n        self._temp_buffer_filled = True","reference":"fill the area below the active editting zone with text","result":"Fill temporary buffer .","score":[0,0.0532]}
{"code":"def _control_key_down(self, modifiers, include_command=False):\r\n        \"\"\" function to<extra_id_0>\r\n        if sys.platform == 'darwin':\r\n            down = include_command and (modifiers & QtCore.Qt.ControlModifier)\r\n            return bool(down) ^ bool(modifiers & QtCore.Qt.MetaModifier)\r\n        else:\r\n            return bool(modifiers & QtCore.Qt.ControlModifier)","reference":"Given a KeyboardModifiers flags object, return whether the Control\n        key is down.\n\n        Parameters:\n        -----------\n        include_command : bool, optional (default True)\n            Whether to treat the Command key as a (mutually exclusive) synonym\n            for Control when in Mac OS.","result":" is down .","score":[0.0,0.0149]}
{"code":"def _create_control(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.custom_control:\r\n            control = self.custom_control()\r\n        elif self.kind == 'plain':\r\n            control = QtGui.QPlainTextEdit()\r\n        elif self.kind == 'rich':\r\n            control = QtGui.QTextEdit()\r\n            control.setAcceptRichText(False)\r\n        control.installEventFilter(self)\r\n        control.viewport().installEventFilter(self)\r\n        control.customContextMenuRequested.connect(\r\n            self._custom_context_menu_requested)\r\n        control.copyAvailable.connect(self.copy_available)\r\n        control.redoAvailable.connect(self.redo_available)\r\n        control.undoAvailable.connect(self.undo_available)\r\n        layout = control.document().documentLayout()\r\n        layout.documentSizeChanged.disconnect()\r\n        layout.documentSizeChanged.connect(self._adjust_scrollbars)\r\n        control.setAttribute(QtCore.Qt.WA_InputMethodEnabled, True)\r\n        control.setContextMenuPolicy(QtCore.Qt.CustomContextMenu)\r\n        control.setReadOnly(True)\r\n        control.setUndoRedoEnabled(False)\r\n        control.setVerticalScrollBarPolicy(QtCore.Qt.ScrollBarAlwaysOn)\r\n        return control","reference":"Creates and connects the underlying text widget.","result":"Create the text edit .","score":[0.1915,0.2206]}
{"code":"def _create_page_control(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.custom_page_control:\r\n            control = self.custom_page_control()\r\n        elif self.kind == 'plain':\r\n            control = QtGui.QPlainTextEdit()\r\n        elif self.kind == 'rich':\r\n            control = QtGui.QTextEdit()\r\n        control.installEventFilter(self)\r\n        viewport = control.viewport()\r\n        viewport.installEventFilter(self)\r\n        control.setReadOnly(True)\r\n        control.setUndoRedoEnabled(False)\r\n        control.setVerticalScrollBarPolicy(QtCore.Qt.ScrollBarAlwaysOn)\r\n        return control","reference":"Creates and connects the underlying paging widget.","result":"Create the page control .","score":[0.1611,0.2206]}
{"code":"def _event_filter_page_keypress(self, event):\r\n        \"\"\" function to<extra_id_0>\r\n        key = event.key()\r\n        ctrl_down = self._control_key_down(event.modifiers())\r\n        alt_down = event.modifiers() & QtCore.Qt.AltModifier\r\n        if ctrl_down:\r\n            if key == QtCore.Qt.Key_O:\r\n                self._control.setFocus()\r\n                intercept = True\r\n        elif alt_down:\r\n            if key == QtCore.Qt.Key_Greater:\r\n                self._page_control.moveCursor(QtGui.QTextCursor.End)\r\n                intercepted = True\r\n            elif key == QtCore.Qt.Key_Less:\r\n                self._page_control.moveCursor(QtGui.QTextCursor.Start)\r\n                intercepted = True\r\n        elif key in (QtCore.Qt.Key_Q, QtCore.Qt.Key_Escape):\r\n            if self._splitter:\r\n                self._page_control.hide()\r\n                self._control.setFocus()\r\n            else:\r\n                self.layout().setCurrentWidget(self._control)\r\n            return True\r\n        elif key in (QtCore.Qt.Key_Enter, QtCore.Qt.Key_Return,\r\n                     QtCore.Qt.Key_Tab):\r\n            new_event = QtGui.QKeyEvent(QtCore.QEvent.KeyPress,\r\n                                        QtCore.Qt.Key_PageDown,\r\n                                        QtCore.Qt.NoModifier)\r\n            QtGui.qApp.sendEvent(self._page_control, new_event)\r\n            return True\r\n        elif key == QtCore.Qt.Key_Backspace:\r\n            new_event = QtGui.QKeyEvent(QtCore.QEvent.KeyPress,\r\n                                        QtCore.Qt.Key_PageUp,\r\n                                        QtCore.Qt.NoModifier)\r\n            QtGui.qApp.sendEvent(self._page_control, new_event)\r\n            return True\r\n        return False","reference":"Filter key events for the paging widget to create console-like\n            interface.","result":"Handle page filter .","score":[0,0.0971]}
{"code":"def _get_block_plain_text(self, block):\r\n        \"\"\" function to<extra_id_0>\r\n        cursor = QtGui.QTextCursor(block)\r\n        cursor.movePosition(QtGui.QTextCursor.StartOfBlock)\r\n        cursor.movePosition(QtGui.QTextCursor.EndOfBlock,\r\n                            QtGui.QTextCursor.KeepAnchor)\r\n        return cursor.selection().toPlainText()","reference":"Given a QTextBlock, return its unformatted text.","result":"Get block plain text .","score":[0,0.0]}
{"code":"def _get_end_cursor(self):\r\n        \"\"\" function to<extra_id_0>\r\n        cursor = self._control.textCursor()\r\n        cursor.movePosition(QtGui.QTextCursor.End)\r\n        return cursor","reference":"Convenience method that returns a cursor for the last character.","result":"Get end cursor .","score":[0.0713,0.1064]}
{"code":"def _get_input_buffer_cursor_column(self):\r\n        \"\"\" function to<extra_id_0>\r\n        prompt = self._get_input_buffer_cursor_prompt()\r\n        if prompt is None:\r\n            return -1\r\n        else:\r\n            cursor = self._control.textCursor()\r\n            return cursor.columnNumber() - len(prompt)","reference":"Returns the column of the cursor in the input buffer, excluding the\n            contribution by the prompt, or -1 if there is no such column.","result":"Get cursor column .","score":[0.0026,0.0455]}
{"code":"def _get_input_buffer_cursor_line(self):\r\n        \"\"\" function to<extra_id_0>\r\n        prompt = self._get_input_buffer_cursor_prompt()\r\n        if prompt is None:\r\n            return None\r\n        else:\r\n            cursor = self._control.textCursor()\r\n            text = self._get_block_plain_text(cursor.block())\r\n            return text[len(prompt):]","reference":"Returns the text of the line of the input buffer that contains the\n            cursor, or None if there is no such line.","result":"Get the input buffer cursor line .","score":[0.0419,0.154]}
{"code":"def _get_prompt_cursor(self):\r\n        \"\"\" function to<extra_id_0>\r\n        cursor = self._control.textCursor()\r\n        cursor.setPosition(self._prompt_pos)\r\n        return cursor","reference":"Convenience method that returns a cursor for the prompt position.","result":"Get prompt cursor .","score":[0.0848,0.1064]}
{"code":"def _get_selection_cursor(self, start, end):\r\n        \"\"\" function to<extra_id_0>\r\n        cursor = self._control.textCursor()\r\n        cursor.setPosition(start)\r\n        cursor.setPosition(end, QtGui.QTextCursor.KeepAnchor)\r\n        return cursor","reference":"Convenience method that returns a cursor with text selected between\n            the positions 'start' and 'end'.","result":"Get the selection cursor .","score":[0.0387,0.1071]}
{"code":"def _insert_continuation_prompt(self, cursor):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._continuation_prompt_html is None:\r\n            self._insert_plain_text(cursor, self._continuation_prompt)\r\n        else:\r\n            self._continuation_prompt = self._insert_html_fetching_plain_text(\r\n                cursor, self._continuation_prompt_html)","reference":"Inserts new continuation prompt using the specified cursor.","result":"Insert the continuation prompt text .","score":[0.2165,0.4046]}
{"code":"def _insert_html(self, cursor, html):\r\n        \"\"\" function to<extra_id_0>\r\n        cursor.beginEditBlock()\r\n        cursor.insertHtml(html)\r\n        cursor.movePosition(QtGui.QTextCursor.Left,\r\n                            QtGui.QTextCursor.KeepAnchor)\r\n        if cursor.selection().toPlainText() == ' ':\r\n            cursor.removeSelectedText()\r\n        else:\r\n            cursor.movePosition(QtGui.QTextCursor.Right)\r\n        cursor.insertText(' ', QtGui.QTextCharFormat())\r\n        cursor.endEditBlock()","reference":"Inserts HTML using the specified cursor in such a way that future\n            formatting is unaffected.","result":"Insert html into text cursor .","score":[0.0431,0.1812]}
{"code":"def _insert_html_fetching_plain_text(self, cursor, html):\r\n        \"\"\" function to<extra_id_0>\r\n        cursor.beginEditBlock()\r\n        cursor.removeSelectedText()\r\n        start = cursor.position()\r\n        self._insert_html(cursor, html)\r\n        end = cursor.position()\r\n        cursor.setPosition(start, QtGui.QTextCursor.KeepAnchor)\r\n        text = cursor.selection().toPlainText()\r\n        cursor.setPosition(end)\r\n        cursor.endEditBlock()\r\n        return text","reference":"Inserts HTML using the specified cursor, then returns its plain text\n            version.","result":"Insert html into text cursor.","score":[0.0593,0.2262]}
{"code":"def _insert_plain_text(self, cursor, text):\r\n        \"\"\" function to<extra_id_0>\r\n        cursor.beginEditBlock()\r\n        if self.ansi_codes:\r\n            for substring in self._ansi_processor.split_string(text):\r\n                for act in self._ansi_processor.actions:\r\n                    if act.action == 'erase' and act.area == 'screen':\r\n                        cursor.select(QtGui.QTextCursor.Document)\r\n                        cursor.removeSelectedText()\r\n                    elif act.action == 'scroll' and act.unit == 'page':\r\n                        cursor.insertText('\\n')\r\n                        cursor.endEditBlock()\r\n                        self._set_top_cursor(cursor)\r\n                        cursor.joinPreviousEditBlock()\r\n                        cursor.deletePreviousChar()\r\n                    elif act.action == 'carriage-return':\r\n                        cursor.movePosition(\r\n                            cursor.StartOfLine, cursor.KeepAnchor)\r\n                    elif act.action == 'beep':\r\n                        QtGui.qApp.beep()\r\n                    elif act.action == 'backspace':\r\n                        if not cursor.atBlockStart():\r\n                            cursor.movePosition(\r\n                                cursor.PreviousCharacter, cursor.KeepAnchor)\r\n                    elif act.action == 'newline':\r\n                        cursor.movePosition(cursor.EndOfLine)\r\n                format = self._ansi_processor.get_format()\r\n                selection = cursor.selectedText()\r\n                if len(selection) == 0:\r\n                    cursor.insertText(substring, format)\r\n                elif substring is not None:\r\n                    if len(substring) >= len(selection):\r\n                        cursor.insertText(substring, format)\r\n                    else:\r\n                        old_text = selection[len(substring):]\r\n                        cursor.insertText(substring + old_text, format)\r\n                        cursor.movePosition(cursor.PreviousCharacter,\r\n                               cursor.KeepAnchor, len(old_text))\r\n        else:\r\n            cursor.insertText(text)\r\n        cursor.endEditBlock()","reference":"Inserts plain text using the specified cursor, processing ANSI codes\n            if enabled.","result":"Insert text into the text cursor .","score":[0.094,0.1304]}
{"code":"def _keep_cursor_in_buffer(self):\r\n        \"\"\" function to<extra_id_0>\r\n        moved = not self._in_buffer()\r\n        if moved:\r\n            cursor = self._control.textCursor()\r\n            cursor.movePosition(QtGui.QTextCursor.End)\r\n            self._control.setTextCursor(cursor)\r\n        return moved","reference":"Ensures that the cursor is inside the editing region. Returns\n            whether the cursor was moved.","result":"Keep cursor in buffer .","score":[0.0325,0.0357]}
{"code":"def _keyboard_quit(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._temp_buffer_filled :\r\n            self._cancel_completion()\r\n            self._clear_temporary_buffer()\r\n        else:\r\n            self.input_buffer = ''","reference":"Cancels the current editing task ala Ctrl-G in Emacs.","result":"Quit keyboard .","score":[0,0.0]}
{"code":"def _page(self, text, html=False):\r\n        \"\"\" function to<extra_id_0>\r\n        line_height = QtGui.QFontMetrics(self.font).height()\r\n        minlines = self._control.viewport().height() \/ line_height\r\n        if self.paging != 'none' and \\\r\n                re.match(\"(?:[^\\n]*\\n){%i}\" % minlines, text):\r\n            if self.paging == 'custom':\r\n                self.custom_page_requested.emit(text)\r\n            else:\r\n                self._page_control.clear()\r\n                cursor = self._page_control.textCursor()\r\n                if html:\r\n                    self._insert_html(cursor, text)\r\n                else:\r\n                    self._insert_plain_text(cursor, text)\r\n                self._page_control.moveCursor(QtGui.QTextCursor.Start)\r\n                self._page_control.viewport().resize(self._control.size())\r\n                if self._splitter:\r\n                    self._page_control.show()\r\n                    self._page_control.setFocus()\r\n                else:\r\n                    self.layout().setCurrentWidget(self._page_control)\r\n        elif html:\r\n            self._append_html(text)\r\n        else:\r\n            self._append_plain_text(text)","reference":"Displays text using the pager if it exceeds the height of the\n        viewport.\n\n        Parameters:\n        -----------\n        html : bool, optional (default False)\n            If set, the text will be interpreted as HTML instead of plain text.","result":"If not page text .","score":[0.0009,0.0322]}
{"code":"def _prompt_started(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self._control.document().setMaximumBlockCount(0)\r\n        self._control.setUndoRedoEnabled(True)\r\n        self._control.setReadOnly(False)\r\n        self._control.setAttribute(QtCore.Qt.WA_InputMethodEnabled, True)\r\n        if not self._reading:\r\n            self._executing = False\r\n        self._prompt_started_hook()\r\n        if self._input_buffer_pending:\r\n            self.input_buffer = self._input_buffer_pending\r\n            self._input_buffer_pending = ''\r\n        self._control.moveCursor(QtGui.QTextCursor.End)","reference":"Called immediately after a new prompt is displayed.","result":" is started .","score":[0.0771,0.0667]}
{"code":"def _readline(self, prompt='', callback=None):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._reading:\r\n            raise RuntimeError('Cannot read a line. Widget is already reading.')\r\n        if not callback and not self.isVisible():\r\n            raise RuntimeError('Cannot synchronously read a line if the widget '\r\n                               'is not visible!')\r\n        self._reading = True\r\n        self._show_prompt(prompt, newline=False)\r\n        if callback is None:\r\n            self._reading_callback = None\r\n            while self._reading:\r\n                QtCore.QCoreApplication.processEvents()\r\n            return self._get_input_buffer(force=True).rstrip('\\n')\r\n        else:\r\n            self._reading_callback = lambda: \\\r\n                callback(self._get_input_buffer(force=True).rstrip('\\n'))","reference":"Reads one line of input from the user.\n\n        Parameters\n        ----------\n        prompt : str, optional\n            The prompt to print before reading the line.\n\n        callback : callable, optional\n            A callback to execute with the read line. If not specified, input is\n            read *synchronously* and this method does not return until it has\n            been read.\n\n        Returns\n        -------\n        If a callback is specified, returns nothing. Otherwise, returns the\n        input string with the trailing newline stripped.","result":"Read a line from the user .","score":[0.0,0.0387]}
{"code":"def _set_continuation_prompt(self, prompt, html=False):\r\n        \"\"\" function to<extra_id_0>\r\n        if html:\r\n            self._continuation_prompt_html = prompt\r\n        else:\r\n            self._continuation_prompt = prompt\r\n            self._continuation_prompt_html = None","reference":"Sets the continuation prompt.\n\n        Parameters\n        ----------\n        prompt : str\n            The prompt to show when more input is needed.\n\n        html : bool, optional (default False)\n            If set, the prompt will be inserted as formatted HTML. Otherwise,\n            the prompt will be treated as plain text, though ANSI color codes\n            will be handled.","result":"Set continuation prompt .","score":[0.0,0.033]}
{"code":"def _set_top_cursor(self, cursor):\r\n        \"\"\" function to<extra_id_0>\r\n        scrollbar = self._control.verticalScrollBar()\r\n        scrollbar.setValue(scrollbar.maximum())\r\n        original_cursor = self._control.textCursor()\r\n        self._control.setTextCursor(cursor)\r\n        self._control.ensureCursorVisible()\r\n        self._control.setTextCursor(original_cursor)","reference":"Scrolls the viewport so that the specified cursor is at the top.","result":"Set the top cursor .","score":[0.0705,0.0885]}
{"code":"def _show_prompt(self, prompt=None, html=False, newline=True):\r\n        \"\"\" function to<extra_id_0>\r\n        cursor = self._get_end_cursor()\r\n        self._append_before_prompt_pos = cursor.position()\r\n        if newline and cursor.position() > 0:\r\n            cursor.movePosition(QtGui.QTextCursor.Left,\r\n                                QtGui.QTextCursor.KeepAnchor)\r\n            if cursor.selection().toPlainText() != '\\n':\r\n                self._append_plain_text('\\n')\r\n        self._append_plain_text(self._prompt_sep)\r\n        if prompt is None:\r\n            if self._prompt_html is None:\r\n                self._append_plain_text(self._prompt)\r\n            else:\r\n                self._append_html(self._prompt_html)\r\n        else:\r\n            if html:\r\n                self._prompt = self._append_html_fetching_plain_text(prompt)\r\n                self._prompt_html = prompt\r\n            else:\r\n                self._append_plain_text(prompt)\r\n                self._prompt = prompt\r\n                self._prompt_html = None\r\n        self._prompt_pos = self._get_end_cursor().position()\r\n        self._prompt_started()","reference":"Writes a new prompt at the end of the buffer.\n\n        Parameters\n        ----------\n        prompt : str, optional\n            The prompt to show. If not specified, the previous prompt is used.\n\n        html : bool, optional (default False)\n            Only relevant when a prompt is specified. If set, the prompt will\n            be inserted as formatted HTML. Otherwise, the prompt will be treated\n            as plain text, though ANSI color codes will be handled.\n\n        newline : bool, optional (default True)\n            If set, a new line will be written before showing the prompt if\n            there is not already a newline at the end of the buffer.","result":"Show the prompt .","score":[0.0,0.0169]}
{"code":"def _adjust_scrollbars(self):\r\n        \"\"\" function to<extra_id_0>\r\n        document = self._control.document()\r\n        scrollbar = self._control.verticalScrollBar()\r\n        viewport_height = self._control.viewport().height()\r\n        if isinstance(self._control, QtGui.QPlainTextEdit):\r\n            maximum = max(0, document.lineCount() - 1)\r\n            step = viewport_height \/ self._control.fontMetrics().lineSpacing()\r\n        else:\r\n            maximum = document.size().height()\r\n            step = viewport_height\r\n        diff = maximum - scrollbar.maximum()\r\n        scrollbar.setRange(0, maximum)\r\n        scrollbar.setPageStep(step)\r\n        if diff < 0 and document.blockCount() == document.maximumBlockCount():\r\n            scrollbar.setValue(scrollbar.value() + diff)","reference":"Expands the vertical scrollbar beyond the range set by Qt.","result":"Adjust the scrollbars .","score":[0.0713,0.1596]}
{"code":"def main(args=None):\r\n    \"\"\" function to<extra_id_0>\r\n    options, paths = _parse_options(args)\r\n    format = getattr(options, 'output', 'simple')\r\n    formatter = _FORMATTERS[format](options)\r\n    for path in paths:\r\n        meta = get_metadata(path, options.metadata_version)\r\n        if meta is None:\r\n            continue\r\n        if options.download_url_prefix:\r\n            if meta.download_url is None:\r\n                filename = os.path.basename(path)\r\n                meta.download_url = '%s\/%s' % (options.download_url_prefix,\r\n                                               filename)\r\n        formatter(meta)\r\n    formatter.finish()","reference":"Entry point for pkginfo tool","result":"Run the main function .","score":[0,0.0]}
{"code":"def copy_config_file(self, config_file, path=None, overwrite=False):\r\n        \"\"\" function to<extra_id_0>\r\n        dst = os.path.join(self.location, config_file)\r\n        if os.path.isfile(dst) and not overwrite:\r\n            return False\r\n        if path is None:\r\n            path = os.path.join(get_ipython_package_dir(), u'config', u'profile', u'default')\r\n        src = os.path.join(path, config_file)\r\n        shutil.copy(src, dst)\r\n        return True","reference":"Copy a default config file into the active profile directory.\n\n        Default configuration files are kept in :mod:`IPython.config.default`.\n        This function moves these from that location to the working profile\n        directory.","result":"Copy config file .","score":[0.001,0.0964]}
{"code":"def create_profile_dir_by_name(cls, path, name=u'default', config=None):\r\n        \"\"\" function to<extra_id_0>\r\n        if not os.path.isdir(path):\r\n            raise ProfileDirError('Directory not found: %s' % path)\r\n        profile_dir = os.path.join(path, u'profile_' + name)\r\n        return cls(location=profile_dir, config=config)","reference":"Create a profile dir by profile name and path.\n\n        Parameters\n        ----------\n        path : unicode\n            The path (directory) to put the profile directory in.\n        name : unicode\n            The name of the profile.  The name of the profile directory will\n            be \"profile_<profile>\".","result":"Create a profile directory .","score":[0.0005,0.1027]}
{"code":"def find_profile_dir_by_name(cls, ipython_dir, name=u'default', config=None):\r\n        \"\"\" function to<extra_id_0>\r\n        dirname = u'profile_' + name\r\n        paths = [os.getcwdu(), ipython_dir]\r\n        for p in paths:\r\n            profile_dir = os.path.join(p, dirname)\r\n            if os.path.isdir(profile_dir):\r\n                return cls(location=profile_dir, config=config)\r\n        else:\r\n            raise ProfileDirError('Profile directory not found in paths: %s' % dirname)","reference":"Find an existing profile dir by profile name, return its ProfileDir.\n\n        This searches through a sequence of paths for a profile dir.  If it\n        is not found, a :class:`ProfileDirError` exception will be raised.\n\n        The search path algorithm is:\n        1. ``os.getcwdu()``\n        2. ``ipython_dir``\n\n        Parameters\n        ----------\n        ipython_dir : unicode or str\n            The IPython directory to use.\n        name : unicode or str\n            The name of the profile.  The name of the profile directory\n            will be \"profile_<profile>\".","result":"Find profile directory by name .","score":[0.0,0.0561]}
{"code":"def cmp_to_key(mycmp):\r\n    \"\"\" function to<extra_id_0>\r\n    'Convert a cmp= function into a key= function'\r\n    class Key(object):\r\n        def __init__(self, obj):\r\n            self.obj = obj\r\n        def __lt__(self, other):\r\n            return mycmp(self.obj, other.obj) < 0\r\n        def __gt__(self, other):\r\n            return mycmp(self.obj, other.obj) > 0\r\n        def __eq__(self, other):\r\n            return mycmp(self.obj, other.obj) == 0\r\n    return Key","reference":"Convert a cmp= function into a key= function","result":"Function into a key.","score":[0.1662,0.3363]}
{"code":"def file_read(filename):\r\n    \"\"\" function to<extra_id_0>\r\n    fobj = open(filename,'r');\r\n    source = fobj.read();\r\n    fobj.close()\r\n    return source","reference":"Read a file and close it.  Returns the file source.","result":"Read a file .","score":[0.1468,0.2719]}
{"code":"def raw_input_multi(header='', ps1='==> ', ps2='..> ',terminate_str = '.'):\r\n    \"\"\" function to<extra_id_0>\r\n    try:\r\n        if header:\r\n            header += '\\n'\r\n        lines = [raw_input(header + ps1)]\r\n    except EOFError:\r\n        return []\r\n    terminate = [terminate_str]\r\n    try:\r\n        while lines[-1:] != terminate:\r\n            new_line = raw_input(ps1)\r\n            while new_line.endswith('\\\\'):\r\n                new_line = new_line[:-1] + raw_input(ps2)\r\n            lines.append(new_line)\r\n        return lines[:-1]\r\n    except EOFError:\r\n        print()\r\n        return lines","reference":"Take multiple lines of input.\n\n    A list with each line of input as a separate element is returned when a\n    termination string is entered (defaults to a single '.'). Input can also\n    terminate via EOF (^D in Unix, ^Z-RET in Windows).\n\n    Lines of input which end in \\\\ are joined into single entries (and a\n    secondary continuation prompt is issued as long as the user terminates\n    lines with \\\\). This allows entering very long strings which are still\n    meant to be treated as single entities.","result":"Multi.","score":[0,0.0]}
{"code":"def temp_pyfile(src, ext='.py'):\r\n    \"\"\" function to<extra_id_0>\r\n    fname = tempfile.mkstemp(ext)[1]\r\n    f = open(fname,'w')\r\n    f.write(src)\r\n    f.flush()\r\n    return fname, f","reference":"Make a temporary python file, return filename and filehandle.\n\n    Parameters\n    ----------\n    src : string or list of strings (no need for ending newlines if list)\n      Source code to be written to the file.\n\n    ext : optional, string\n      Extension for the generated file.\n\n    Returns\n    -------\n    (filename, open filehandle)\n      It is the caller's responsibility to close the open file and unlink it.","result":"Create a temporary pyfile .","score":[0.0,0.0344]}
{"code":"def close(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self.flush()\r\n        setattr(sys, self.channel, self.ostream)\r\n        self.file.close()\r\n        self._closed = True","reference":"Close the file and restore the channel.","result":"Close the stream .","score":[0.2134,0.1493]}
{"code":"def write(self, data):\r\n        \"\"\" function to<extra_id_0>\r\n        self.file.write(data)\r\n        self.ostream.write(data)\r\n        self.ostream.flush()","reference":"Write data to both channels.","result":"Write data to file .","score":[0.4949,0.5889]}
{"code":"def add_new_heart_handler(self, handler):\r\n        \"\"\" function to<extra_id_0>\r\n        self.log.debug(\"heartbeat::new_heart_handler: %s\", handler)\r\n        self._new_handlers.add(handler)","reference":"add a new handler for new hearts","result":"Add new handler .","score":[0.2134,0.2239]}
{"code":"def add_heart_failure_handler(self, handler):\r\n        \"\"\" function to<extra_id_0>\r\n        self.log.debug(\"heartbeat::new heart failure handler: %s\", handler)\r\n        self._failure_handlers.add(handler)","reference":"add a new handler for heart failure","result":"Add a heart failure handler .","score":[0.2748,0.6464]}
{"code":"def handle_pong(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        \"a heart just beat\"\r\n        current = str_to_bytes(str(self.lifetime))\r\n        last = str_to_bytes(str(self.last_ping))\r\n        if msg[1] == current:\r\n            delta = time.time()-self.tic\r\n            self.responses.add(msg[0])\r\n        elif msg[1] == last:\r\n            delta = time.time()-self.tic + (self.lifetime-self.last_ping)\r\n            self.log.warn(\"heartbeat::heart %r missed a beat, and took %.2f ms to respond\", msg[0], 1000*delta)\r\n            self.responses.add(msg[0])\r\n        else:\r\n            self.log.warn(\"heartbeat::got bad heartbeat (possibly old?): %s (current=%.3f)\", msg[1], self.lifetime)","reference":"a heart just beat","result":"Def handle pong messages .","score":[0,0.0]}
{"code":"def batch_list(sequence, batch_size, mod = 0, randomize = False):\r\n    \"\"\" function to<extra_id_0>\r\n    '''\r\n    Converts a list into a list of lists with equal batch_size.\r\n    Parameters\r\n    ----------\r\n    sequence : list\r\n        list of items to be placed in batches\r\n    batch_size : int\r\n        length of each sub list\r\n    mod : int\r\n        remainder of list length devided by batch_size\r\n        mod = len(sequence) % batch_size\r\n    randomize = bool\r\n        should the initial sequence be randomized before being batched\r\n        '''\r\n    if randomize:\r\n        sequence = random.sample(sequence, len(sequence))\r\n    return [sequence[x:x + batch_size] for x in xrange(0, len(sequence)-mod, batch_size)]","reference":"Converts a list into a list of lists with equal batch_size.\n\n    Parameters\n    ----------\n    sequence : list\n        list of items to be placed in batches\n    batch_size : int\n        length of each sub list\n    mod : int\n        remainder of list length devided by batch_size\n        mod = len(sequence) % batch_size\n    randomize = bool\n        should the initial sequence be randomized before being batched","result":"Batch a list of lists .","score":[0.0001,0.0466]}
{"code":"def path_to_filename(pathfile):\r\n    \"\"\" function to<extra_id_0>\r\n    '''\r\n    Takes a path filename string and returns the split between the path and the filename\r\n    if filename is not given, filename = ''\r\n    if path is not given, path = '.\/'\r\n    '''\r\n    path = pathfile[:pathfile.rfind('\/') + 1]\r\n    if path == '':\r\n        path = '.\/'\r\n    filename = pathfile[pathfile.rfind('\/') + 1:len(pathfile)]\r\n    if '.' not in filename:\r\n        path = pathfile\r\n        filename = ''\r\n    if (filename == '') and (path[len(path) - 1] != '\/'):\r\n        path += '\/'\r\n    return path, filename","reference":"Takes a path filename string and returns the split between the path and the filename\n\n    if filename is not given, filename = ''\n    if path is not given, path = '.\/'","result":"Split a path filename string into path and filename .","score":[0.0506,0.1384]}
{"code":"def Walk(root='.', recurse=True, pattern='*'):\r\n    \"\"\" function to<extra_id_0>\r\n    ''' \r\n    Generator for walking a directory tree.\r\n    Starts at specified root folder, returning files that match our pattern. \r\n    Optionally will also recurse through sub-folders.\r\n    Parameters\r\n    ----------\r\n    root : string (default is *'.'*)\r\n        Path for the root folder to look in.\r\n    recurse : bool (default is *True*)\r\n        If *True*, will also look in the subfolders.\r\n    pattern : string (default is :emphasis:`'*'`, which means all the files are concerned)\r\n        The pattern to look for in the files' name.\r\n    Returns\r\n    -------\r\n    generator\r\n        **Walk** yields a generator from the matching files paths.\r\n    '''\r\n    for path, subdirs, files in os.walk(root):\r\n        for name in files:\r\n            if fnmatch.fnmatch(name, pattern):\r\n                yield os.path.join(path, name)\r\n        if not recurse:\r\n            break","reference":"Generator for walking a directory tree.\n    Starts at specified root folder, returning files that match our pattern. \n    Optionally will also recurse through sub-folders.\n\n    Parameters\n    ----------\n    root : string (default is *'.'*)\n        Path for the root folder to look in.\n    recurse : bool (default is *True*)\n        If *True*, will also look in the subfolders.\n    pattern : string (default is :emphasis:`'*'`, which means all the files are concerned)\n        The pattern to look for in the files' name.\n\n    Returns\n    -------\n    generator\n        **Walk** yields a generator from the matching files paths.","result":"Generate a generator from the files paths.","score":[0.0,0.0851]}
{"code":"def displayAll(elapsed, display_amt, est_end, nLoops, count, numPrints):\r\n    \"\"\" function to<extra_id_0>\r\n    '''Displays time if verbose is true and count is within the display amount'''\r\n    if numPrints > nLoops:\r\n        display_amt = 1\r\n    else:\r\n        display_amt = round(nLoops \/ numPrints)\r\n    if count % display_amt == 0:\r\n        avg = elapsed \/ count\r\n        est_end = round(avg * nLoops)\r\n        (disp_elapsed,\r\n         disp_avg,\r\n         disp_est) = timeUnit(int(round(elapsed)),\r\n                              int(round(avg)),\r\n                              int(round(est_end)))\r\n        print \"%s%%\" % str(round(count \/ float(nLoops) * 100)), \"@\" + str(count),\r\n        totalTime = disp_est[0]\r\n        unit = disp_est[1]\r\n        if str(unit) == \"secs\":\r\n            remain = totalTime - round(elapsed)\r\n            remainUnit = \"secs\"\r\n        elif str(unit) == \"mins\":\r\n            remain = totalTime - round(elapsed) \/ 60\r\n            remainUnit = \"mins\"\r\n        elif str(unit) == \"hr\":\r\n            remain = totalTime - round(elapsed) \/ 3600\r\n            remainUnit = \"hr\"\r\n        print \"ETA: %s %s\" % (str(remain), remainUnit)\r\n        print\r\n    return","reference":"Displays time if verbose is true and count is within the display amount","result":"Display all time .","score":[0.0337,0.0826]}
{"code":"def timeUnit(elapsed, avg, est_end):\r\n    \"\"\" function to<extra_id_0>\r\n    '''calculates unit of time to display'''\r\n    minute = 60\r\n    hr = 3600\r\n    day = 86400\r\n    if elapsed <= 3 * minute:\r\n        unit_elapsed = (elapsed, \"secs\")\r\n    if elapsed > 3 * minute:\r\n        unit_elapsed = ((elapsed \/ 60), \"mins\")\r\n    if elapsed > 3 * hr:\r\n        unit_elapsed = ((elapsed \/ 3600), \"hr\")\r\n    if avg <= 3 * minute:\r\n        unit_avg = (avg, \"secs\")\r\n    if avg > 3 * minute:\r\n        unit_avg = ((avg \/ 60), \"mins\")\r\n    if avg > 3 * hr:\r\n        unit_avg = ((avg \/ 3600), \"hr\")\r\n    if est_end <= 3 * minute:\r\n        unit_estEnd = (est_end, \"secs\")\r\n    if est_end > 3 * minute:\r\n        unit_estEnd = ((est_end \/ 60), \"mins\")\r\n    if est_end > 3 * hr:\r\n        unit_estEnd = ((est_end \/ 3600), \"hr\")\r\n    return [unit_elapsed, unit_avg, unit_estEnd]","reference":"calculates unit of time to display","result":"Calculate unit of time to display .","score":[0.6721,0.9813]}
{"code":"def extract_wininst_cfg(dist_filename):\r\n    \"\"\" function to<extra_id_0>\r\n    f = open(dist_filename,'rb')\r\n    try:\r\n        endrec = zipfile._EndRecData(f)\r\n        if endrec is None:\r\n            return None\r\n        prepended = (endrec[9] - endrec[5]) - endrec[6]\r\n        if prepended < 12:\r\n            return None\r\n        f.seek(prepended-12)\r\n        import struct, StringIO, ConfigParser\r\n        tag, cfglen, bmlen = struct.unpack(\"<iii\",f.read(12))\r\n        if tag not in (0x1234567A, 0x1234567B):\r\n            return None\r\n        f.seek(prepended-(12+cfglen))\r\n        cfg = ConfigParser.RawConfigParser({'version':'','target_version':''})\r\n        try:\r\n            part = f.read(cfglen)\r\n            if sys.version_info >= (2,6):\r\n                null_byte = bytes([0])\r\n            else:\r\n                null_byte = chr(0)\r\n            config = part.split(null_byte, 1)[0]\r\n            config = config.decode('ascii')\r\n            cfg.readfp(StringIO.StringIO(config))\r\n        except ConfigParser.Error:\r\n            return None\r\n        if not cfg.has_section('metadata') or not cfg.has_section('Setup'):\r\n            return None\r\n        return cfg\r\n    finally:\r\n        f.close()","reference":"Extract configuration data from a bdist_wininst .exe\n\n    Returns a ConfigParser.RawConfigParser, or None","result":"Extract wininst config from a zipfile .","score":[0.1237,0.1304]}
{"code":"def uncache_zipdir(path):\r\n    \"\"\" function to<extra_id_0>\r\n    from zipimport import _zip_directory_cache as zdc\r\n    _uncache(path, zdc)\r\n    _uncache(path, sys.path_importer_cache)","reference":"Ensure that the importer caches dont have stale info for `path`","result":"Uncache zipdir cache .","score":[0,0.0485]}
{"code":"def nt_quote_arg(arg):\r\n    \"\"\" function to<extra_id_0>\r\n    result = []\r\n    needquote = False\r\n    nb = 0\r\n    needquote = (\" \" in arg) or (\"\\t\" in arg)\r\n    if needquote:\r\n        result.append('\"')\r\n    for c in arg:\r\n        if c == '\\\\':\r\n            nb += 1\r\n        elif c == '\"':\r\n            result.append('\\\\' * (nb*2) + '\\\\\"')\r\n            nb = 0\r\n        else:\r\n            if nb:\r\n                result.append('\\\\' * nb)\r\n                nb = 0\r\n            result.append(c)\r\n    if nb:\r\n        result.append('\\\\' * nb)\r\n    if needquote:\r\n        result.append('\\\\' * nb)\r\n        result.append('\"')\r\n    return ''.join(result)","reference":"Quote a command line argument according to Windows parsing rules","result":"Quote a string .","score":[0.1008,0.1995]}
{"code":"def check_conflicts(self, dist):\r\n        \"\"\" function to<extra_id_0>\r\n        return dist\r\n        from imp import find_module, get_suffixes\r\n        from glob import glob\r\n        blockers = []\r\n        names = dict.fromkeys(dist._get_metadata('top_level.txt'))\r\n        exts = {'.pyc':1, '.pyo':1}\r\n        for ext,mode,typ in get_suffixes():\r\n            exts[ext] = 1\r\n        for path,files in expand_paths([self.install_dir]+self.all_site_dirs):\r\n            for filename in files:\r\n                base,ext = os.path.splitext(filename)\r\n                if base in names:\r\n                    if not ext:\r\n                        try:\r\n                            f, filename, descr = find_module(base, [path])\r\n                        except ImportError:\r\n                            continue\r\n                        else:\r\n                            if f: f.close()\r\n                            if filename not in blockers:\r\n                                blockers.append(filename)\r\n                    elif ext in exts and base!='site':\r\n                        blockers.append(os.path.join(path,filename))\r\n        if blockers:\r\n            self.found_conflicts(dist, blockers)\r\n        return dist","reference":"Verify that there are no conflicting \"old-style\" packages","result":"Check for conflicts .","score":[0,0.0658]}
{"code":"def _set_fetcher_options(self, base):\r\n        \"\"\" function to<extra_id_0>\r\n        ei_opts = self.distribution.get_option_dict('easy_install').copy()\r\n        fetch_directives = (\r\n            'find_links', 'site_dirs', 'index_url', 'optimize',\r\n            'site_dirs', 'allow_hosts',\r\n        )\r\n        fetch_options = {}\r\n        for key, val in ei_opts.iteritems():\r\n            if key not in fetch_directives: continue\r\n            fetch_options[key.replace('_', '-')] = val[1]\r\n        settings = dict(easy_install=fetch_options)\r\n        cfg_filename = os.path.join(base, 'setup.cfg')\r\n        setopt.edit_config(cfg_filename, settings)","reference":"When easy_install is about to run bdist_egg on a source dist, that\n        source dist might have 'setup_requires' directives, requiring\n        additional fetching. Ensure the fetcher options given to easy_install\n        are available to that command as well.","result":"Set fetcher options .","score":[0.0002,0.0588]}
{"code":"def create_home_path(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if not self.user:\r\n            return\r\n        home = convert_path(os.path.expanduser(\"~\"))\r\n        for name, path in self.config_vars.iteritems():\r\n            if path.startswith(home) and not os.path.isdir(path):\r\n                self.debug_print(\"os.makedirs('%s', 0700)\" % path)\r\n                os.makedirs(path, 0700)","reference":"Create directories under ~.","result":"Def create home path .","score":[0,0.122]}
{"code":"def is_archive_file(name):\r\n    \"\"\" function to<extra_id_0>\r\n    archives = (\r\n        '.zip', '.tar.gz', '.tar.bz2', '.tgz', '.tar', '.whl'\r\n    )\r\n    ext = splitext(name)[1].lower()\r\n    if ext in archives:\r\n        return True\r\n    return False","reference":"Return True if `name` is a considered as an archive file.","result":" is archive file .","score":[0.066,0.0971]}
{"code":"def mutable(obj):\r\n    \"\"\" function to<extra_id_0>\r\n    '''\r\n    return a mutable proxy for the `obj`.\r\n    all modify on the proxy will not apply on origin object.\r\n    '''\r\n    base_cls = type(obj)\r\n    class Proxy(base_cls):\r\n        def __getattribute__(self, name):\r\n            try:\r\n                return super().__getattribute__(name)\r\n            except AttributeError:\r\n                return getattr(obj, name)\r\n    update_wrapper(Proxy, base_cls, updated = ())\r\n    return Proxy()","reference":"return a mutable proxy for the `obj`.\n\n    all modify on the proxy will not apply on origin object.","result":"Return a mutable proxy for the `obj` .","score":[0.1656,0.3007]}
{"code":"def readonly(obj, *, error_on_set = False):\r\n    \"\"\" function to<extra_id_0>\r\n    '''\r\n    return a readonly proxy for the `obj`.\r\n    all modify on the proxy will not apply on origin object.\r\n    '''\r\n    base_cls = type(obj)\r\n    class ReadonlyProxy(base_cls):\r\n        def __getattribute__(self, name):\r\n            return getattr(obj, name)\r\n        def __setattr__(self, name, value):\r\n            if error_on_set:\r\n                raise AttributeError('cannot set readonly object.')\r\n    update_wrapper(ReadonlyProxy, base_cls, updated = ())\r\n    return ReadonlyProxy()","reference":"return a readonly proxy for the `obj`.\n\n    all modify on the proxy will not apply on origin object.","result":"Return a readonly proxy for the `obj` .","score":[0.1656,0.3007]}
{"code":"def new_heading_cell(source=None, rendered=None, level=1, metadata=None):\r\n    \"\"\" function to<extra_id_0>\r\n    cell = NotebookNode()\r\n    cell.cell_type = u'heading'\r\n    if source is not None:\r\n        cell.source = unicode(source)\r\n    if rendered is not None:\r\n        cell.rendered = unicode(rendered)\r\n    cell.level = int(level)\r\n    cell.metadata = NotebookNode(metadata or {})\r\n    return cell","reference":"Create a new section cell with a given integer level.","result":"Create a new heading cell .","score":[0.2194,0.2083]}
{"code":"def new_metadata(name=None, authors=None, license=None, created=None,\r\n    \"\"\" function to<extra_id_0>\r\n    modified=None, gistid=None):\r\n    metadata = NotebookNode()\r\n    if name is not None:\r\n        metadata.name = unicode(name)\r\n    if authors is not None:\r\n        metadata.authors = list(authors)\r\n    if created is not None:\r\n        metadata.created = unicode(created)\r\n    if modified is not None:\r\n        metadata.modified = unicode(modified)\r\n    if license is not None:\r\n        metadata.license = unicode(license)\r\n    if gistid is not None:\r\n        metadata.gistid = unicode(gistid)\r\n    return metadata","reference":"Create a new metadata node.","result":"Create a new metadata node .","score":[0.6043,0.7782]}
{"code":"def new_author(name=None, email=None, affiliation=None, url=None):\r\n    \"\"\" function to<extra_id_0>\r\n    author = NotebookNode()\r\n    if name is not None:\r\n        author.name = unicode(name)\r\n    if email is not None:\r\n        author.email = unicode(email)\r\n    if affiliation is not None:\r\n        author.affiliation = unicode(affiliation)\r\n    if url is not None:\r\n        author.url = unicode(url)\r\n    return author","reference":"Create a new author.","result":"Create a new author node .","score":[0.3976,0.7011]}
{"code":"def _writable_dir(path):\r\n    \"\"\" function to<extra_id_0>\r\n    return os.path.isdir(path) and os.access(path, os.W_OK)","reference":"Whether `path` is a directory, to which the user has write access.","result":" is writable .","score":[0.0203,0.045]}
{"code":"def unquote_filename(name, win32=(sys.platform=='win32')):\r\n    \"\"\" function to<extra_id_0>\r\n    if win32:\r\n        if name.startswith((\"'\", '\"')) and name.endswith((\"'\", '\"')):\r\n            name = name[1:-1]\r\n    return name","reference":"On Windows, remove leading and trailing quotes from filenames.","result":"Unquote filename .","score":[0,0.0]}
{"code":"def get_py_filename(name, force_win32=None):\r\n    \"\"\" function to<extra_id_0>\r\n    name = os.path.expanduser(name)\r\n    if force_win32 is None:\r\n        win32 = (sys.platform == 'win32')\r\n    else:\r\n        win32 = force_win32\r\n    name = unquote_filename(name, win32=win32)\r\n    if not os.path.isfile(name) and not name.endswith('.py'):\r\n        name += '.py'\r\n    if os.path.isfile(name):\r\n        return name\r\n    else:\r\n        raise IOError,'File `%r` not found.' % name","reference":"Return a valid python filename in the current directory.\n\n    If the given name is not a file, it adds '.py' and searches again.\n    Raises IOError with an informative message if the file isn't found.\n\n    On Windows, apply Windows semantics to the filename. In particular, remove\n    any quoting that has been applied to it. This option can be forced for\n    testing purposes.","result":"Get a python filename .","score":[0.0,0.0461]}
{"code":"def filefind(filename, path_dirs=None):\r\n    \"\"\" function to<extra_id_0>\r\n    filename = filename.strip('\"').strip(\"'\")\r\n    if os.path.isabs(filename) and os.path.isfile(filename):\r\n        return filename\r\n    if path_dirs is None:\r\n        path_dirs = (\"\",)\r\n    elif isinstance(path_dirs, basestring):\r\n        path_dirs = (path_dirs,)\r\n    for path in path_dirs:\r\n        if path == '.': path = os.getcwdu()\r\n        testname = expand_path(os.path.join(path, filename))\r\n        if os.path.isfile(testname):\r\n            return os.path.abspath(testname)\r\n    raise IOError(\"File %r does not exist in any of the search paths: %r\" %\r\n                  (filename, path_dirs) )","reference":"Find a file by looking through a sequence of paths.\n\n    This iterates through a sequence of paths looking for a file and returns\n    the full, absolute path of the first occurence of the file.  If no set of\n    path dirs is given, the filename is tested as is, after running through\n    :func:`expandvars` and :func:`expanduser`.  Thus a simple call::\n\n        filefind('myfile.txt')\n\n    will find the file in the current working dir, but::\n\n        filefind('~\/myfile.txt')\n\n    Will find the file in the users home directory.  This function does not\n    automatically try any paths, such as the cwd or the user's home directory.\n\n    Parameters\n    ----------\n    filename : str\n        The filename to look for.\n    path_dirs : str, None or sequence of str\n        The sequence of paths to look for the file in.  If None, the filename\n        need to be absolute or be in the cwd.  If a string, the string is\n        put into a sequence and the searched.  If a sequence, walk through\n        each element and join with ``filename``, calling :func:`expandvars`\n        and :func:`expanduser` before testing for existence.\n\n    Returns\n    -------\n    Raises :exc:`IOError` or returns absolute path to file.","result":"Find a file in a given path .","score":[0.0,0.0216]}
{"code":"def get_home_dir(require_writable=False):\r\n    \"\"\" function to<extra_id_0>\r\n    if hasattr(sys, \"frozen\"):\r\n        if '\\\\library.zip\\\\' in IPython.__file__.lower():\r\n            root, rest = IPython.__file__.lower().split('library.zip')\r\n        else:\r\n            root=os.path.join(os.path.split(IPython.__file__)[0],\"..\/..\/\")\r\n        root=os.path.abspath(root).rstrip('\\\\')\r\n        if _writable_dir(os.path.join(root, '_ipython')):\r\n            os.environ[\"IPYKITROOT\"] = root\r\n        return py3compat.cast_unicode(root, fs_encoding)\r\n        homedir = os.path.expanduser('~')\r\n    homedir = os.path.realpath(homedir)\r\n        if not _writable_dir(homedir) and os.name == 'nt':\r\n        try:\r\n            import _winreg as wreg\r\n            key = wreg.OpenKey(\r\n                wreg.HKEY_CURRENT_USER,\r\n                \"Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Shell Folders\"\r\n            )\r\n            homedir = wreg.QueryValueEx(key,'Personal')[0]\r\n            key.Close()\r\n        except:\r\n            pass\r\n        if (not require_writable) or _writable_dir(homedir):\r\n        return py3compat.cast_unicode(homedir, fs_encoding)\r\n    else:\r\n        raise HomeDirError('%s is not a writable dir, '\r\n                'set $HOME environment variable to override' % homedir)","reference":"Return the 'home' directory, as a unicode string.\n\n    * First, check for frozen env in case of py2exe\n    * Otherwise, defer to os.path.expanduser('~')\n    \n    See stdlib docs for how this is determined.\n    $HOME is first priority on *ALL* platforms.\n    \n    Parameters\n    ----------\n    \n    require_writable : bool [default: False]\n        if True:\n            guarantees the return value is a writable directory, otherwise\n            raises HomeDirError\n        if False:\n            The path is resolved, but it is not guaranteed to exist or be writable.","result":"Get home dir .","score":[0,0.0]}
{"code":"def get_xdg_dir():\r\n    \"\"\" function to<extra_id_0>\r\n    env = os.environ\r\n    if os.name == 'posix' and sys.platform != 'darwin':\r\n        xdg = env.get(\"XDG_CONFIG_HOME\", None) or os.path.join(get_home_dir(), '.config')\r\n        if xdg and _writable_dir(xdg):\r\n            return py3compat.cast_unicode(xdg, fs_encoding)\r\n    return None","reference":"Return the XDG_CONFIG_HOME, if it is defined and exists, else None.\n\n    This is only for non-OS X posix (Linux,Unix,etc.) systems.","result":"Get xdg config dir.","score":[0,0.0]}
{"code":"def get_ipython_dir():\r\n    \"\"\" function to<extra_id_0>\r\n    env = os.environ\r\n    pjoin = os.path.join\r\n    ipdir_def = '.ipython'\r\n    xdg_def = 'ipython'\r\n    home_dir = get_home_dir()\r\n    xdg_dir = get_xdg_dir()\r\n     'IPYTHON_DIR' in env:\r\n        warnings.warn('The environment variable IPYTHON_DIR is deprecated. '\r\n                      'Please use IPYTHONDIR instead.')\r\n    ipdir = env.get('IPYTHONDIR', env.get('IPYTHON_DIR', None))\r\n    if ipdir is None:\r\n        home_ipdir = pjoin(home_dir, ipdir_def)\r\n        if xdg_dir:\r\n            xdg_ipdir = pjoin(xdg_dir, xdg_def)\r\n            if _writable_dir(xdg_ipdir) or not _writable_dir(home_ipdir):\r\n                ipdir = xdg_ipdir\r\n        if ipdir is None:\r\n            ipdir = home_ipdir\r\n    ipdir = os.path.normpath(os.path.expanduser(ipdir))\r\n    if os.path.exists(ipdir) and not _writable_dir(ipdir):\r\n        warnings.warn(\"IPython dir '%s' is not a writable location,\"\r\n                        \" using a temp directory.\"%ipdir)\r\n        ipdir = tempfile.mkdtemp()\r\n    elif not os.path.exists(ipdir):\r\n        parent = ipdir.rsplit(os.path.sep, 1)[0]\r\n        if not _writable_dir(parent):\r\n            warnings.warn(\"IPython parent '%s' is not a writable location,\"\r\n                        \" using a temp directory.\"%parent)\r\n            ipdir = tempfile.mkdtemp()\r\n    return py3compat.cast_unicode(ipdir, fs_encoding)","reference":"Get the IPython directory for this platform and user.\n\n    This uses the logic in `get_home_dir` to find the home directory\n    and then adds .ipython to the end of the path.","result":"Get the current working directory .","score":[0.0055,0.0543]}
{"code":"def get_ipython_package_dir():\r\n    \"\"\" function to<extra_id_0>\r\n    ipdir = os.path.dirname(IPython.__file__)\r\n    return py3compat.cast_unicode(ipdir, fs_encoding)","reference":"Get the base directory where IPython itself is installed.","result":"Get the ipython package directory .","score":[0.1833,0.3628]}
{"code":"def get_ipython_module_path(module_str):\r\n    \"\"\" function to<extra_id_0>\r\n    if module_str == 'IPython':\r\n        return os.path.join(get_ipython_package_dir(), '__init__.py')\r\n    mod = import_item(module_str)\r\n    the_path = mod.__file__.replace('.pyc', '.py')\r\n    the_path = the_path.replace('.pyo', '.py')\r\n    return py3compat.cast_unicode(the_path, fs_encoding)","reference":"Find the path to an IPython module in this version of IPython.\n\n    This will always find the version of the module that is in this importable\n    IPython package. This will always return the path to the ``.py``\n    version of the module.","result":"Get the path of a IPython module .","score":[0.0044,0.0796]}
{"code":"def target_outdated(target,deps):\r\n    \"\"\" function to<extra_id_0>\r\n    try:\r\n        target_time = os.path.getmtime(target)\r\n    except os.error:\r\n        return 1\r\n    for dep in deps:\r\n        dep_time = os.path.getmtime(dep)\r\n        if dep_time > target_time:\r\n  return 1\r\n    return 0","reference":"Determine whether a target is out of date.\n\n    target_outdated(target,deps) -> 1\/0\n\n    deps: list of filenames which MUST exist.\n    target: single filename which may or may not exist.\n\n    If target doesn't exist or is older than any file listed in deps, return\n    true, otherwise return false.","result":" is outdated .","score":[0.0,0.0123]}
{"code":"def filehash(path):\r\n    \"\"\" function to<extra_id_0>\r\n    with open(path, \"rU\") as f:\r\n        return md5(py3compat.str_to_bytes(f.read())).hexdigest()","reference":"Make an MD5 hash of a file, ignoring any differences in line\n    ending characters.","result":"Calculate file hash .","score":[0.0262,0.0385]}
{"code":"def check_for_old_config(ipython_dir=None):\r\n    \"\"\" function to<extra_id_0>\r\n    if ipython_dir is None:\r\n        ipython_dir = get_ipython_dir()\r\n    old_configs = ['ipy_user_conf.py', 'ipythonrc', 'ipython_config.py']\r\n    warned = False\r\n    for cfg in old_configs:\r\n        f = os.path.join(ipython_dir, cfg)\r\n        if os.path.exists(f):\r\n            if filehash(f) == old_config_md5.get(cfg, ''):\r\n                os.unlink(f)\r\n            else:\r\n                warnings.warn(\"Found old IPython config file %r (modified by user)\"%f)\r\n                warned = True\r\n    if warned:\r\n        warnings.warn(\"\"\"\r\n  The IPython configuration system has changed as of 0.11, and these files will\r\n  be ignored. See http:\/\/ipython.github.com\/ipython-doc\/dev\/config for details\r\n  of the new config system.\r\n  To start configuring IPython, do `ipython profile create`, and edit\r\n  `ipython_config.py` in <ipython_dir>\/profile_default.\r\n  If you need to leave the old config files in place for an older version of\r\n  IPython and want to suppress this warning message, set\r\n  `c.InteractiveShellApp.ignore_old_config=True` in the new config.\"\"\")","reference":"Check for old config files, and present a warning if they exist.\n\n    A link to the docs of the new config is included in the message.\n\n    This should mitigate confusion with the transition to the new\n    config system in 0.11.","result":"Check for old config files.","score":[0.0007,0.1027]}
{"code":"def update_suggestions_dictionary(request, object):\r\n    \"\"\" function to<extra_id_0>\r\n    if request.user.is_authenticated():\r\n        user = request.user\r\n        content_type = ContentType.objects.get_for_model(type(object))\r\n        try:\r\n            ObjectView.objects.get(\r\n                user=user, object_id=object.id, content_type=content_type)\r\n        except:\r\n            ObjectView.objects.create(user=user, content_object=object)\r\n        viewed = ObjectView.objects.filter(user=user)\r\n    else:\r\n        update_dict_for_guests(request, object, content_type)\r\n        return\r\n    if viewed:\r\n        for obj in viewed:\r\n            if content_type == obj.content_type:\r\n                if not exists_in_dictionary(request, object,\r\n                                            content_type,\r\n                                            obj, True):\r\n                    if object.id != obj.object_id:\r\n                        ObjectViewDictionary.objects.create(\r\n                            current_object=object,\r\n                            visited_before_object=obj.content_object)\r\n                        if not exists_in_dictionary(request, obj,\r\n                                                    obj.content_type,\r\n                                                    object, False):\r\n                            ObjectViewDictionary.objects.create(\r\n                                current_object=obj.content_object,\r\n                                visited_before_object=object)\r\n    return","reference":"Updates the suggestions' dictionary for an object upon visiting its page","result":"None update suggestions dictionary .","score":[0.0724,0.0962]}
{"code":"def get_suggestions_with_size(object, size):\r\n    \"\"\" function to<extra_id_0>\r\n    content_type = ContentType.objects.get_for_model(type(object))\r\n    try:\r\n        return ObjectViewDictionary.objects.filter(\r\n            current_object_id=object.id,\r\n            current_content_type=content_type).extra(\r\n            order_by=['-visits'])[:size]\r\n    except:\r\n        return ObjectViewDictionary.objects.filter(\r\n            current_object_id=object.id,\r\n            current_content_type=content_type).extra(order_by=['-visits'])","reference":"Gets a list with a certain size of suggestions for an object","result":"Get suggestions with size .","score":[0.078,0.177]}
{"code":"def get_suggestions(object):\r\n    \"\"\" function to<extra_id_0>\r\n    content_type = ContentType.objects.get_for_model(type(object))\r\n    return ObjectViewDictionary.objects.filter(\r\n        current_object_id=object.id,\r\n        current_content_type=content_type).extra(order_by=['-visits'])","reference":"Gets a list of all suggestions for an object","result":"Get suggestions for object .","score":[0.169,0.367]}
{"code":"def relpath(self):\r\n        \"\"\" function to<extra_id_0>\r\n        cwd = self.__class__(os.getcwdu())\r\n        return cwd.relpathto(self)","reference":"Return this path as a relative path,\n        based from the current working directory.","result":"Return the relative path to this file .","score":[0.1112,0.2]}
{"code":"def glob(self, pattern):\r\n        \"\"\" function to<extra_id_0>\r\n        cls = self.__class__\r\n        return [cls(s) for s in glob.glob(unicode(self \/ pattern))]","reference":"Return a list of path objects that match the pattern.\n\n        pattern - a path relative to this directory, with wildcards.\n\n        For example, path('\/users').glob('*\/bin\/*') returns a list\n        of all the files users have in their bin directories.","result":"Glob a pattern .","score":[0.0001,0.0305]}
{"code":"def lines(self, encoding=None, errors='strict', retain=True):\r\n        \"\"\" function to<extra_id_0>\r\n        r\"\"\" Open this file, read all lines, return them in a list.\r\n        Optional arguments:\r\n            encoding - The Unicode encoding (or character set) of\r\n                the file.  The default is None, meaning the content\r\n                of the file is read as 8-bit characters and returned\r\n                as a list of (non-Unicode) str objects.\r\n            errors - How to handle Unicode errors; see help(str.decode)\r\n                for the options.  Default is 'strict'\r\n            retain - If true, retain newline characters; but all newline\r\n                character combinations ('\\r', '\\n', '\\r\\n') are\r\n                translated to '\\n'.  If false, newline characters are\r\n                stripped off.  Default is True.\r\n        This uses 'U' mode in Python 2.3 and later.\r\n        \"\"\"\r\n        if encoding is None and retain:\r\n            f = self.open('U')\r\n            try:\r\n                return f.readlines()\r\n            finally:\r\n                f.close()\r\n        else:\r\n            return self.text(encoding, errors).splitlines(retain)","reference":"r\"\"\" Open this file, read all lines, return them in a list.\n\n        Optional arguments:\n            encoding - The Unicode encoding (or character set) of\n                the file.  The default is None, meaning the content\n                of the file is read as 8-bit characters and returned\n                as a list of (non-Unicode) str objects.\n            errors - How to handle Unicode errors; see help(str.decode)\n                for the options.  Default is 'strict'\n            retain - If true, retain newline characters; but all newline\n                character combinations ('\\r', '\\n', '\\r\\n') are\n                translated to '\\n'.  If false, newline characters are\n                stripped off.  Default is True.\n\n        This uses 'U' mode in Python 2.3 and later.","result":"Read all lines in this file .","score":[0.0,0.027]}
{"code":"def read_md5(self):\r\n        \"\"\" function to<extra_id_0>\r\n        f = self.open('rb')\r\n        try:\r\n            m = md5()\r\n            while True:\r\n                d = f.read(8192)\r\n                if not d:\r\n                    break\r\n                m.update(d)\r\n        finally:\r\n            f.close()\r\n        return m.digest()","reference":"Calculate the md5 hash for this file.\n\n        This reads through the entire file.","result":"Read file content .","score":[0,0.0413]}
{"code":"def begin(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if not self.available():\r\n            return\r\n        self._create_pfile()\r\n        self.prof = hotshot.Profile(self.pfile)","reference":"Create profile stats file and load profiler.","result":"Begin profiling .","score":[0,0.0758]}
{"code":"def report(self, stream):\r\n        \"\"\" function to<extra_id_0>\r\n        log.debug('printing profiler report')\r\n        self.prof.close()\r\n        prof_stats = stats.load(self.pfile)\r\n        prof_stats.sort_stats(self.sort)\r\n        compat_25 = hasattr(prof_stats, 'stream')\r\n        if compat_25:\r\n            tmp = prof_stats.stream\r\n            prof_stats.stream = stream\r\n        else:\r\n            tmp = sys.stdout\r\n            sys.stdout = stream\r\n        try:\r\n            if self.restrict:\r\n                log.debug('setting profiler restriction to %s', self.restrict)\r\n                prof_stats.print_stats(*self.restrict)\r\n            else:\r\n                prof_stats.print_stats()\r\n        finally:\r\n            if compat_25:\r\n                prof_stats.stream = tmp\r\n            else:\r\n                sys.stdout = tmp","reference":"Output profiler report.","result":"Print the profiler report to stream .","score":[0.1615,0.1471]}
{"code":"def finalize(self, result):\r\n        \"\"\" function to<extra_id_0>\r\n        if not self.available():\r\n            return\r\n        try:\r\n            self.prof.close()\r\n        except AttributeError:\r\n            pass\r\n        if self.clean_stats_file:\r\n            if self.fileno:\r\n                try:\r\n                    os.close(self.fileno)\r\n                except OSError:\r\n                    pass\r\n            try:\r\n                os.unlink(self.pfile)\r\n            except OSError:\r\n                pass\r\n        return None","reference":"Clean up stats file, if configured to do so.","result":"Finalize the profiler .","score":[0,0.0]}
{"code":"def handle(self, *args, **options):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            while True:\r\n                Channel(HEARTBEAT_CHANNEL).send({'time':time.time()})\r\n                time.sleep(HEARTBEAT_FREQUENCY)\r\n        except KeyboardInterrupt:\r\n            print(\"Received keyboard interrupt, exiting...\")","reference":"Handle CLI command","result":"Handle the command .","score":[0.3799,0.3226]}
{"code":"def enable_wx(self, app=None):\r\n        \"\"\" function to<extra_id_0>\r\n        import wx\r\n                wx_version = V(wx.__version__).version\r\n                if wx_version < [2, 8]:\r\n            raise ValueError(\"requires wxPython >= 2.8, but you have %s\" % wx.__version__)\r\n                from IPython.lib.inputhookwx import inputhook_wx\r\n        self.set_inputhook(inputhook_wx)\r\n        self._current_gui = GUI_WX\r\n        import wx\r\n        if app is None:\r\n            app = wx.GetApp()\r\n        if app is None:\r\n            app = wx.App(redirect=False, clearSigInt=False)\r\n        app._in_event_loop = True\r\n        self._apps[GUI_WX] = app\r\n        return app","reference":"Enable event loop integration with wxPython.\n\n        Parameters\n        ----------\n        app : WX Application, optional.\n            Running application to use.  If not given, we probe WX for an\n            existing application object, and create a new one if none is found.\n\n        Notes\n        -----\n        This methods sets the ``PyOS_InputHook`` for wxPython, which allows\n        the wxPython to integrate with terminal based applications like\n        IPython.\n\n        If ``app`` is not given we probe for an existing one, and return it if\n        found.  If no existing app is found, we create an :class:`wx.App` as\n        follows::\n\n            import wx\n            app = wx.App(redirect=False, clearSigInt=False)","result":"Def enable wx .","score":[0.0,0.012]}
{"code":"def disable_wx(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._apps.has_key(GUI_WX):\r\n            self._apps[GUI_WX]._in_event_loop = False\r\n        self.clear_inputhook()","reference":"Disable event loop integration with wxPython.\n\n        This merely sets PyOS_InputHook to NULL.","result":"Disable wx .","score":[0.0203,0.045]}
{"code":"def disable_qt4(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._apps.has_key(GUI_QT4):\r\n            self._apps[GUI_QT4]._in_event_loop = False\r\n        self.clear_inputhook()","reference":"Disable event loop integration with PyQt4.\n\n        This merely sets PyOS_InputHook to NULL.","result":"Disable Qt.","score":[0.0034,0.0455]}
{"code":"def enable_gtk(self, app=None):\r\n        \"\"\" function to<extra_id_0>\r\n        import gtk\r\n        try:\r\n            gtk.set_interactive(True)\r\n            self._current_gui = GUI_GTK\r\n        except AttributeError:\r\n            from IPython.lib.inputhookgtk import inputhook_gtk\r\n            self.set_inputhook(inputhook_gtk)\r\n            self._current_gui = GUI_GTK","reference":"Enable event loop integration with PyGTK.\n\n        Parameters\n        ----------\n        app : ignored\n           Ignored, it's only a placeholder to keep the call signature of all\n           gui activation methods consistent, which simplifies the logic of\n           supporting magics.\n\n        Notes\n        -----\n        This methods sets the PyOS_InputHook for PyGTK, which allows\n        the PyGTK to integrate with terminal based applications like\n        IPython.","result":"Def enable gtk .","score":[0,0.01]}
{"code":"def enable_tk(self, app=None):\r\n        \"\"\" function to<extra_id_0>\r\n        self._current_gui = GUI_TK\r\n        if app is None:\r\n            import Tkinter\r\n            app = Tkinter.Tk()\r\n            app.withdraw()\r\n            self._apps[GUI_TK] = app\r\n            return app","reference":"Enable event loop integration with Tk.\n\n        Parameters\n        ----------\n        app : toplevel :class:`Tkinter.Tk` widget, optional.\n            Running toplevel widget to use.  If not given, we probe Tk for an\n            existing one, and create a new one if none is found.\n\n        Notes\n        -----\n        If you have already created a :class:`Tkinter.Tk` object, the only\n        thing done by this method is to register with the\n        :class:`InputHookManager`, since creating that object automatically\n        sets ``PyOS_InputHook``.","result":"Enable Tk .","score":[0.0,0.0163]}
{"code":"def enable_pyglet(self, app=None):\r\n        \"\"\" function to<extra_id_0>\r\n        import pyglet\r\n        from IPython.lib.inputhookpyglet import inputhook_pyglet\r\n        self.set_inputhook(inputhook_pyglet)\r\n        self._current_gui = GUI_PYGLET\r\n        return app","reference":"Enable event loop integration with pyglet.\n\n        Parameters\n        ----------\n        app : ignored\n           Ignored, it's only a placeholder to keep the call signature of all\n           gui activation methods consistent, which simplifies the logic of\n           supporting magics.\n\n        Notes\n        -----\n        This methods sets the ``PyOS_InputHook`` for pyglet, which allows\n        pyglet to integrate with terminal based applications like\n        IPython.","result":"Def enable pyglet .","score":[0.0,0.0204]}
{"code":"def wave_saver(u, x, y, t):\r\n    \"\"\" function to<extra_id_0>\r\n    global u_hist\r\n    global t_hist\r\n    t_hist.append(t)\r\n    u_hist.append(1.0*u)","reference":"save the wave log","result":"Global save wave .","score":[0.3799,0.25]}
{"code":"def init_db(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self.db = sqlite3.connect(self.hist_file,\r\n                    detect_types=sqlite3.PARSE_DECLTYPES|sqlite3.PARSE_COLNAMES)\r\n        self.db.execute(\"\"\"CREATE TABLE IF NOT EXISTS sessions (session integer\r\n                        primary key autoincrement, start timestamp,\r\n                        end timestamp, num_cmds integer, remark text)\"\"\")\r\n        self.db.execute(\"\"\"CREATE TABLE IF NOT EXISTS history\r\n                (session integer, line integer, source text, source_raw text,\r\n                PRIMARY KEY (session, line))\"\"\")\r\n        self.db.execute(\"\"\"CREATE TABLE IF NOT EXISTS output_history\r\n                        (session integer, line integer, output text,\r\n                        PRIMARY KEY (session, line))\"\"\")\r\n        self.db.commit()","reference":"Connect to the database, and create tables if necessary.","result":"Def initialize the database .","score":[0.108,0.0581]}
{"code":"def _run_sql(self, sql, params, raw=True, output=False):\r\n        \"\"\" function to<extra_id_0>\r\n        toget = 'source_raw' if raw else 'source'\r\n        sqlfrom = \"history\"\r\n        if output:\r\n            sqlfrom = \"history LEFT JOIN output_history USING (session, line)\"\r\n            toget = \"history.%s, output_history.output\" % toget\r\n        cur = self.db.execute(\"SELECT session, line, %s FROM %s \" %\\\r\n                                (toget, sqlfrom) + sql, params)\r\n        if output:\r\n            return ((ses, lin, (inp, out)) for ses, lin, inp, out in cur)\r\n        return cur","reference":"Prepares and runs an SQL query for the history database.\n\n        Parameters\n        ----------\n        sql : str\n          Any filtering expressions to go after SELECT ... FROM ...\n        params : tuple\n          Parameters passed to the SQL query (to replace \"?\")\n        raw, output : bool\n          See :meth:`get_range`\n\n        Returns\n        -------\n        Tuples as :meth:`get_range`","result":"Run sql .","score":[0.0,0.023]}
{"code":"def get_session_info(self, session=0):\r\n        \"\"\" function to<extra_id_0>\r\n        if session <= 0:\r\n            session += self.session_number\r\n        query = \"SELECT * from sessions where session == ?\"\r\n        return self.db.execute(query, (session,)).fetchone()","reference":"get info about a session\n\n        Parameters\n        ----------\n\n        session : int\n            Session number to retrieve. The current session is 0, and negative\n            numbers count back from current session, so -1 is previous session.\n\n        Returns\n        -------\n\n        (session_id [int], start [datetime], end [datetime], num_cmds [int],\n        remark [unicode])\n\n        Sessions that are running or did not exit cleanly will have `end=None`\n        and `num_cmds=None`.","result":"Get session info .","score":[0.0,0.0285]}
{"code":"def get_tail(self, n=10, raw=True, output=False, include_latest=False):\r\n        \"\"\" function to<extra_id_0>\r\n        self.writeout_cache()\r\n        if not include_latest:\r\n            n += 1\r\n        cur = self._run_sql(\"ORDER BY session DESC, line DESC LIMIT ?\",\r\n                                (n,), raw=raw, output=output)\r\n        if not include_latest:\r\n            return reversed(list(cur)[1:])\r\n        return reversed(list(cur))","reference":"Get the last n lines from the history database.\n\n        Parameters\n        ----------\n        n : int\n          The number of lines to get\n        raw, output : bool\n          See :meth:`get_range`\n        include_latest : bool\n          If False (default), n+1 lines are fetched, and the latest one\n          is discarded. This is intended to be used where the function\n          is called by a user command, which it should not return.\n\n        Returns\n        -------\n        Tuples as :meth:`get_range`","result":"Get the tail of the file .","score":[0.0001,0.0328]}
{"code":"def get_range_by_str(self, rangestr, raw=True, output=False):\r\n        \"\"\" function to<extra_id_0>\r\n        for sess, s, e in extract_hist_ranges(rangestr):\r\n            for line in self.get_range(sess, s, e, raw=raw, output=output):\r\n                yield line","reference":"Get lines of history from a string of ranges, as used by magic\n        commands %hist, %save, %macro, etc.\n\n        Parameters\n        ----------\n        rangestr : str\n          A string specifying ranges, e.g. \"5 ~2\/1-4\". See\n          :func:`magic_history` for full details.\n        raw, output : bool\n          As :meth:`get_range`\n\n        Returns\n        -------\n        Tuples as :meth:`get_range`","result":"For get range by string .","score":[0.0003,0.0476]}
{"code":"def _get_hist_file_name(self, profile=None):\r\n        \"\"\" function to<extra_id_0>\r\n        profile_dir = self.shell.profile_dir.location\r\n        return os.path.join(profile_dir, 'history.sqlite')","reference":"Get default history file name based on the Shell's profile.\n        \n        The profile parameter is ignored, but must exist for compatibility with\n        the parent class.","result":"Get history file name .","score":[0.0119,0.1697]}
{"code":"def name_session(self, name):\r\n        \"\"\" function to<extra_id_0>\r\n        with self.db:\r\n            self.db.execute(\"UPDATE sessions SET remark=? WHERE session==?\",\r\n                            (name, self.session_number))","reference":"Give the current session a name in the history database.","result":"Name a session .","score":[0.0848,0.1596]}
{"code":"def reset(self, new_session=True):\r\n        \"\"\" function to<extra_id_0>\r\n        self.output_hist.clear()\r\n        self.dir_hist[:] = [os.getcwdu()]\r\n                if new_session:\r\n            if self.session_number:\r\n                self.end_session()\r\n            self.input_hist_parsed[:] = [\"\"]\r\n            self.input_hist_raw[:] = [\"\"]\r\n            self.new_session()","reference":"Clear the session history, releasing all object references, and\n        optionally open a new session.","result":"Reset the history .","score":[0.0262,0.0385]}
{"code":"def _get_range_session(self, start=1, stop=None, raw=True, output=False):\r\n        \"\"\" function to<extra_id_0>\r\n        input_hist = self.input_hist_raw if raw else self.input_hist_parsed\r\n                    n = len(input_hist)\r\n        if start < 0:\r\n            start += n\r\n        if not stop or (stop > n):\r\n            stop = n\r\n        elif stop < 0:\r\n            stop += n\r\n                for i in range(start, stop):\r\n            if output:\r\n                line = (input_hist[i], self.output_hist_reprs.get(i))\r\n            else:\r\n                line = input_hist[i]\r\n            yield (0, i, line)","reference":"Get input and output history from the current session. Called by\n        get_range, and takes similar parameters.","result":"Get range session .","score":[0.0159,0.0676]}
{"code":"def store_output(self, line_num):\r\n        \"\"\" function to<extra_id_0>\r\n        if (not self.db_log_output) or (line_num not in self.output_hist_reprs):\r\n            return\r\n        output = self.output_hist_reprs[line_num]\r\n        with self.db_output_cache_lock:\r\n            self.db_output_cache.append((line_num, output))\r\n        if self.db_cache_size <= 1:\r\n            self.save_flag.set()","reference":"If database output logging is enabled, this saves all the\n        outputs from the indicated prompt number to the database. It's\n        called by run_cell after code has been executed.\n\n        Parameters\n        ----------\n        line_num : int\n          The line number from which to save outputs","result":"Store output .","score":[0.0,0.0134]}
{"code":"def writeout_cache(self, conn=None):\r\n        \"\"\" function to<extra_id_0>\r\n        if conn is None:\r\n            conn = self.db\r\n        with self.db_input_cache_lock:\r\n            try:\r\n                self._writeout_input_cache(conn)\r\n            except sqlite3.IntegrityError:\r\n                self.new_session(conn)\r\n                print(\"ERROR! Session\/line number was not unique in\",\r\n                      \"database. History logging moved to new session\",\r\n                                                self.session_number)\r\n                try:\r\n                    self._writeout_input_cache(conn)\r\n                except sqlite3.IntegrityError:\r\n                    pass\r\n            finally:\r\n                self.db_input_cache = []\r\n        with self.db_output_cache_lock:\r\n            try:\r\n                self._writeout_output_cache(conn)\r\n            except sqlite3.IntegrityError:\r\n                print(\"!! Session\/line number for output was not unique\",\r\n                      \"in database. Output will not be stored.\")\r\n            finally:\r\n                self.db_output_cache = []","reference":"Write any entries in the cache to the database.","result":"Write out the cache .","score":[0.169,0.1744]}
{"code":"def stop(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self.stop_now = True\r\n        self.history_manager.save_flag.set()\r\n        self.join()","reference":"This can be called from the main thread to safely stop this thread.\n\n        Note that it does not attempt to write out remaining history before\n        exiting. That should be done by calling the HistoryManager's\n        end_session method.","result":"Def stop the thread .","score":[0.0006,0.0456]}
{"code":"def _get_num_cpus():\r\n    \"\"\" function to<extra_id_0>\r\n    try:\r\n        return os.sysconf(\"SC_NPROCESSORS_ONLN\")\r\n    except ValueError:\r\n        num = 0\r\n        f = open('\/proc\/cpuinfo', 'r')\r\n        try:\r\n            lines = f.readlines()\r\n        finally:\r\n            f.close()\r\n        for line in lines:\r\n            if line.lower().startswith('processor'):\r\n                num += 1\r\n    if num == 0:\r\n        f = open('\/proc\/stat', 'r')\r\n        try:\r\n            lines = f.readlines()\r\n        finally:\r\n            f.close()\r\n        search = re.compile('cpu\\d')\r\n        for line in lines:\r\n            line = line.split(' ')[0]\r\n            if search.match(line):\r\n                num += 1\r\n    if num == 0:\r\n        raise RuntimeError(\"can't determine number of CPUs\")\r\n    return num","reference":"Return the number of CPUs on the system","result":"Get number of CPUs .","score":[0.2716,0.3824]}
{"code":"def get_system_per_cpu_times():\r\n    \"\"\" function to<extra_id_0>\r\n    cpus = []\r\n    f = open('\/proc\/stat', 'r')\r\n    try:\r\n        f.readline()\r\n        for line in f.readlines():\r\n            if line.startswith('cpu'):\r\n                values = line.split()[1:8]\r\n                values = tuple([float(x) \/ _CLOCK_TICKS for x in values])\r\n                entry = nt_sys_cputimes(*values[:7])\r\n                cpus.append(entry)\r\n        return cpus\r\n    finally:\r\n        f.close()","reference":"Return a list of namedtuple representing the CPU times\n    for every CPU available on the system.","result":"Get system per cpu times.","score":[0,0.0336]}
{"code":"def disk_partitions(all=False):\r\n    \"\"\" function to<extra_id_0>\r\n    phydevs = []\r\n    f = open(\"\/proc\/filesystems\", \"r\")\r\n    try:\r\n        for line in f:\r\n            if not line.startswith(\"nodev\"):\r\n                phydevs.append(line.strip())\r\n    finally:\r\n        f.close()\r\n    retlist = []\r\n    partitions = _psutil_linux.get_disk_partitions()\r\n    for partition in partitions:\r\n        device, mountpoint, fstype, opts = partition\r\n        if device == 'none':\r\n            device = ''\r\n        if not all:\r\n            if device == '' or fstype not in phydevs:\r\n                continue\r\n        ntuple = nt_partition(device, mountpoint, fstype, opts)\r\n        retlist.append(ntuple)\r\n    return retlist","reference":"Return mounted disk partitions as a list of nameduples","result":"Get disk partitions .","score":[0.1294,0.2206]}
{"code":"def get_pid_list():\r\n    \"\"\" function to<extra_id_0>\r\n    pids = [int(x) for x in os.listdir('\/proc') if x.isdigit()]\r\n    return pids","reference":"Returns a list of PIDs currently running on the system.","result":"Get the pid list .","score":[0.1051,0.1579]}
{"code":"def nice_pair(pair):\r\n    \"\"\" function to<extra_id_0>\r\n    start, end = pair\r\n    if start == end:\r\n        return \"%d\" % start\r\n    else:\r\n        return \"%d-%d\" % (start, end)","reference":"Make a nice string representation of a pair of numbers.\n\n    If the numbers are equal, just return the number, otherwise return the pair\n    with a dash between them, indicating the range.","result":"Return nice pair .","score":[0.0004,0.053]}
{"code":"def format_lines(statements, lines):\r\n    \"\"\" function to<extra_id_0>\r\n    pairs = []\r\n    i = 0\r\n    j = 0\r\n    start = None\r\n    statements = sorted(statements)\r\n    lines = sorted(lines)\r\n    while i < len(statements) and j < len(lines):\r\n        if statements[i] == lines[j]:\r\n            if start == None:\r\n                start = lines[j]\r\n            end = lines[j]\r\n            j += 1\r\n        elif start:\r\n            pairs.append((start, end))\r\n            start = None\r\n        i += 1\r\n    if start:\r\n        pairs.append((start, end))\r\n    ret = ', '.join(map(nice_pair, pairs))\r\n    return ret","reference":"Nicely format a list of line numbers.\n\n    Format a list of line numbers for printing by coalescing groups of lines as\n    long as the lines represent consecutive statements.  This will coalesce\n    even if there are gaps between statements.\n\n    For example, if `statements` is [1,2,3,4,5,10,11,12,13,14] and\n    `lines` is [1,2,5,10,11,13,14] then the result will be \"1-2, 5-11, 13-14\".","result":"Format lines .","score":[0.0,0.0197]}
{"code":"def short_stack():\r\n    \"\"\" function to<extra_id_0>\r\n    stack = inspect.stack()[:0:-1]\r\n    return \"\\n\".join([\"%30s : %s @%d\" % (t[3],t[1],t[2]) for t in stack])","reference":"Return a string summarizing the call stack.","result":"Return a stack string .","score":[0.2521,0.3758]}
{"code":"def expensive(fn):\r\n    \"\"\" function to<extra_id_0>\r\n    attr = \"_cache_\" + fn.__name__\r\n    def _wrapped(self):\r\n        if not hasattr(self, attr):\r\n            setattr(self, attr, fn(self))\r\n        return getattr(self, attr)\r\n    return _wrapped","reference":"A decorator to cache the result of an expensive operation.\n\n    Only applies to methods with no arguments.","result":"Wrap function in a wrapped function .","score":[0,0.0312]}
{"code":"def join_regex(regexes):\r\n    \"\"\" function to<extra_id_0>\r\n    if len(regexes) > 1:\r\n        return \"|\".join([\"(%s)\" % r for r in regexes])\r\n    elif regexes:\r\n        return regexes[0]\r\n    else:\r\n        return \"\"","reference":"Combine a list of regexes into one that matches any of them.","result":"Join regex .","score":[0,0.045]}
{"code":"def file_be_gone(path):\r\n    \"\"\" function to<extra_id_0>\r\n    try:\r\n        os.remove(path)\r\n    except OSError:\r\n        _, e, _ = sys.exc_info()\r\n        if e.errno != errno.ENOENT:\r\n            raise","reference":"Remove a file, and don't get annoyed if it doesn't exist.","result":"Def remove a file .","score":[0.0724,0.1803]}
{"code":"def update(self, v):\r\n        \"\"\" function to<extra_id_0>\r\n        self.md5.update(to_bytes(str(type(v))))\r\n        if isinstance(v, string_class):\r\n            self.md5.update(to_bytes(v))\r\n        elif v is None:\r\n            pass\r\n        elif isinstance(v, (int, float)):\r\n            self.md5.update(to_bytes(str(v)))\r\n        elif isinstance(v, (tuple, list)):\r\n            for e in v:\r\n                self.update(e)\r\n        elif isinstance(v, dict):\r\n            keys = v.keys()\r\n            for k in sorted(keys):\r\n                self.update(k)\r\n                self.update(v[k])\r\n        else:\r\n            for k in dir(v):\r\n                if k.startswith('__'):\r\n                    continue\r\n                a = getattr(v, k)\r\n                if inspect.isroutine(a):\r\n                    continue\r\n                self.update(k)\r\n                self.update(a)","reference":"Add `v` to the hash, recursively if needed.","result":"Update the.","score":[0,0.0]}
{"code":"def update_profiles(self):\r\n        \"\"\" function to<extra_id_0>\r\n        for path in [get_ipython_dir(), os.getcwdu()]:\r\n            for profile in list_profiles_in(path):\r\n                pd = self.get_profile_dir(profile, path)\r\n                if profile not in self.profiles:\r\n                    self.log.debug(\"Adding cluster profile '%s'\" % profile)\r\n                    self.profiles[profile] = {\r\n                        'profile': profile,\r\n                        'profile_dir': pd,\r\n                        'status': 'stopped'\r\n                    }","reference":"List all profiles in the ipython_dir and cwd.","result":"Update cluster profiles .","score":[0.1175,0.0658]}
{"code":"def start_cluster(self, profile, n=None):\r\n        \"\"\" function to<extra_id_0>\r\n        self.check_profile(profile)\r\n        data = self.profiles[profile]\r\n        if data['status'] == 'running':\r\n            raise web.HTTPError(409, u'cluster already running')\r\n        cl, esl, default_n = self.build_launchers(data['profile_dir'])\r\n        n = n if n is not None else default_n\r\n        def clean_data():\r\n            data.pop('controller_launcher',None)\r\n            data.pop('engine_set_launcher',None)\r\n            data.pop('n',None)\r\n            data['status'] = 'stopped'\r\n        def engines_stopped(r):\r\n            self.log.debug('Engines stopped')\r\n            if cl.running:\r\n                cl.stop()\r\n            clean_data()\r\n        esl.on_stop(engines_stopped)\r\n        def controller_stopped(r):\r\n            self.log.debug('Controller stopped')\r\n            if esl.running:\r\n                esl.stop()\r\n            clean_data()\r\n        cl.on_stop(controller_stopped)\r\n        dc = ioloop.DelayedCallback(lambda: cl.start(), 0, self.loop)\r\n        dc.start()\r\n        dc = ioloop.DelayedCallback(lambda: esl.start(n), 1000*self.delay, self.loop)\r\n        dc.start()\r\n        self.log.debug('Cluster started')\r\n        data['controller_launcher'] = cl\r\n        data['engine_set_launcher'] = esl\r\n        data['n'] = n\r\n        data['status'] = 'running'\r\n        return self.profile_info(profile)","reference":"Start a cluster for a given profile.","result":"Start a cluster .","score":[0.3108,0.2239]}
{"code":"def stop_cluster(self, profile):\r\n        \"\"\" function to<extra_id_0>\r\n        self.check_profile(profile)\r\n        data = self.profiles[profile]\r\n        if data['status'] == 'stopped':\r\n            raise web.HTTPError(409, u'cluster not running')\r\n        data = self.profiles[profile]\r\n        cl = data['controller_launcher']\r\n        esl = data['engine_set_launcher']\r\n        if cl.running:\r\n            cl.stop()\r\n        if esl.running:\r\n            esl.stop()\r\n        result = {\r\n            'profile': data['profile'],\r\n            'profile_dir': data['profile_dir'],\r\n            'status': 'stopped'\r\n        }\r\n        return result","reference":"Stop a cluster for a given profile.","result":"Stop cluster .","score":[0.128,0.1515]}
{"code":"def _find_cmd(cmd):\r\n    \"\"\" function to<extra_id_0>\r\n    try:\r\n        from win32api import SearchPath\r\n    except ImportError:\r\n        raise ImportError('you need to have pywin32 installed for this to work')\r\n    else:\r\n        PATH = os.environ['PATH']\r\n        extensions = ['.exe', '.com', '.bat', '.py']\r\n        path = None\r\n        for ext in extensions:\r\n            try:\r\n                path = SearchPath(PATH, cmd + ext)[0]\r\n            except:\r\n                pass\r\n        if path is None:\r\n            raise OSError(\"command %r not found\" % cmd)\r\n        else:\r\n            return path","reference":"Find the full path to a .bat or .exe using the win32api module.","result":"Find a command in the PATH .","score":[0.0902,0.1613]}
{"code":"def _system_body(p):\r\n    \"\"\" function to<extra_id_0>\r\n    enc = DEFAULT_ENCODING\r\n    for line in read_no_interrupt(p.stdout).splitlines():\r\n        line = line.decode(enc, 'replace')\r\n        print(line, file=sys.stdout)\r\n    for line in read_no_interrupt(p.stderr).splitlines():\r\n        line = line.decode(enc, 'replace')\r\n        print(line, file=sys.stderr)\r\n    return p.wait()","reference":"Callback for _system.","result":"Handle system body .","score":[0,0.0]}
{"code":"def find_code_units(self, morfs):\r\n        \"\"\" function to<extra_id_0>\r\n        morfs = morfs or self.coverage.data.measured_files()\r\n        file_locator = self.coverage.file_locator\r\n        self.code_units = code_unit_factory(morfs, file_locator)\r\n        if self.config.include:\r\n            patterns = prep_patterns(self.config.include)\r\n            filtered = []\r\n            for cu in self.code_units:\r\n                for pattern in patterns:\r\n                    if fnmatch.fnmatch(cu.filename, pattern):\r\n                        filtered.append(cu)\r\n                        break\r\n            self.code_units = filtered\r\n        if self.config.omit:\r\n            patterns = prep_patterns(self.config.omit)\r\n            filtered = []\r\n            for cu in self.code_units:\r\n                for pattern in patterns:\r\n                    if fnmatch.fnmatch(cu.filename, pattern):\r\n                        break\r\n                else:\r\n                    filtered.append(cu)\r\n            self.code_units = filtered\r\n        self.code_units.sort()","reference":"Find the code units we'll report on.\n\n        `morfs` is a list of modules or filenames.","result":"Find code units .","score":[0.032,0.1839]}
{"code":"def report_files(self, report_fn, morfs, directory=None):\r\n        \"\"\" function to<extra_id_0>\r\n        self.find_code_units(morfs)\r\n        if not self.code_units:\r\n            raise CoverageException(\"No data to report.\")\r\n        self.directory = directory\r\n        if self.directory and not os.path.exists(self.directory):\r\n            os.makedirs(self.directory)\r\n        for cu in self.code_units:\r\n            try:\r\n                report_fn(cu, self.coverage._analyze(cu))\r\n            except NoSource:\r\n                if not self.config.ignore_errors:\r\n                    raise\r\n            except NotPython:\r\n                if cu.should_be_python() and not self.config.ignore_errors:\r\n                    raise","reference":"Run a reporting function on a number of morfs.\n\n        `report_fn` is called for each relative morf in `morfs`.  It is called\n        as::\n\n            report_fn(code_unit, analysis)\n\n        where `code_unit` is the `CodeUnit` for the morf, and `analysis` is\n        the `Analysis` for the morf.","result":"Report coverage data .","score":[0,0.0137]}
{"code":"def raises(*exceptions):\r\n    \"\"\" function to<extra_id_0>\r\n    valid = ' or '.join([e.__name__ for e in exceptions])\r\n    def decorate(func):\r\n        name = func.__name__\r\n        def newfunc(*arg, **kw):\r\n            try:\r\n                func(*arg, **kw)\r\n            except exceptions:\r\n                pass\r\n            except:\r\n                raise\r\n            else:\r\n                message = \"%s() did not raise %s\" % (name, valid)\r\n                raise AssertionError(message)\r\n        newfunc = make_decorator(func)(newfunc)\r\n        return newfunc\r\n    return decorate","reference":"Test must raise one of expected exceptions to pass.\n\n    Example use::\n\n      @raises(TypeError, ValueError)\n      def test_raises_type_error():\n          raise TypeError(\"This test passes\")\n\n      @raises(Exception)\n      def test_that_fails_by_passing():\n          pass\n\n    If you want to test many assertions about exceptions in a single test,\n    you may want to use `assert_raises` instead.","result":"Check if a function raises one of the given exceptions .","score":[0.009,0.1337]}
{"code":"def set_trace():\r\n    \"\"\" function to<extra_id_0>\r\n    import pdb\r\n    import sys\r\n    stdout = sys.stdout\r\n    sys.stdout = sys.__stdout__\r\n    pdb.Pdb().set_trace(sys._getframe().f_back)","reference":"Call pdb.set_trace in the calling frame, first restoring\n    sys.stdout to the real output stream. Note that sys.stdout is NOT\n    reset to whatever it was before the call once pdb is done!","result":"Def set the trace .","score":[0.0013,0.0176]}
{"code":"def timed(limit):\r\n    \"\"\" function to<extra_id_0>\r\n    def decorate(func):\r\n        def newfunc(*arg, **kw):\r\n            start = time.time()\r\n            func(*arg, **kw)\r\n            end = time.time()\r\n            if end - start > limit:\r\n                raise TimeExpired(\"Time limit (%s) exceeded\" % limit)\r\n        newfunc = make_decorator(func)(newfunc)\r\n        return newfunc\r\n    return decorate","reference":"Test must finish within specified time limit to pass.\n\n    Example use::\n\n      @timed(.1)\n      def test_that_fails():\n          time.sleep(.2)","result":" is in time .","score":[0.0204,0.036]}
{"code":"def init_extensions(self):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            self.log.debug(\"Loading IPython extensions...\")\r\n            extensions = self.default_extensions + self.extensions\r\n            for ext in extensions:\r\n                try:\r\n                    self.log.info(\"Loading IPython extension: %s\" % ext)\r\n                    self.shell.extension_manager.load_extension(ext)\r\n                except:\r\n                    self.log.warn(\"Error in loading extension: %s\" % ext +\r\n                        \"\\nCheck your config files in %s\" % self.profile_dir.location\r\n                    )\r\n                    self.shell.showtraceback()\r\n        except:\r\n            self.log.warn(\"Unknown error in loading extensions:\")\r\n            self.shell.showtraceback()","reference":"Load all IPython extensions in IPythonApp.extensions.\n\n        This uses the :meth:`ExtensionManager.load_extensions` to load all\n        the extensions listed in ``self.extensions``.","result":"Load extensions .","score":[0.0033,0.0606]}
{"code":"def init_code(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self._run_startup_files()\r\n        self._run_exec_lines()\r\n        self._run_exec_files()\r\n        self._run_cmd_line_code()\r\n        self._run_module()\r\n                sys.stdout.flush()\r\n        sys.stderr.flush()\r\n                self.shell.user_ns_hidden.update(self.shell.user_ns)","reference":"run the pre-flight code, specified via exec_lines","result":"Initialize code .","score":[0,0.0]}
{"code":"def _run_exec_lines(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if not self.exec_lines:\r\n            return\r\n        try:\r\n            self.log.debug(\"Running code from IPythonApp.exec_lines...\")\r\n            for line in self.exec_lines:\r\n                try:\r\n                    self.log.info(\"Running code in user namespace: %s\" %\r\n                                  line)\r\n                    self.shell.run_cell(line, store_history=False)\r\n                except:\r\n                    self.log.warn(\"Error in executing line in user \"\r\n                                  \"namespace: %s\" % line)\r\n                    self.shell.showtraceback()\r\n        except:\r\n            self.log.warn(\"Unknown error in handling IPythonApp.exec_lines:\")\r\n            self.shell.showtraceback()","reference":"Run lines of code in IPythonApp.exec_lines in the user's namespace.","result":"Run exec lines .","score":[0.0848,0.1064]}
{"code":"def _run_startup_files(self):\r\n        \"\"\" function to<extra_id_0>\r\n        startup_dir = self.profile_dir.startup_dir\r\n        startup_files = glob.glob(os.path.join(startup_dir, '*.py'))\r\n        startup_files += glob.glob(os.path.join(startup_dir, '*.ipy'))\r\n        if not startup_files:\r\n            return\r\n                self.log.debug(\"Running startup files from %s...\", startup_dir)\r\n        try:\r\n            for fname in sorted(startup_files):\r\n                self._exec_file(fname)\r\n        except:\r\n            self.log.warn(\"Unknown error in handling startup files:\")\r\n            self.shell.showtraceback()","reference":"Run files from profile startup directory","result":"Def run startup files .","score":[0.2339,0.2542]}
{"code":"def _run_exec_files(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if not self.exec_files:\r\n            return\r\n        self.log.debug(\"Running files in IPythonApp.exec_files...\")\r\n        try:\r\n            for fname in self.exec_files:\r\n                self._exec_file(fname)\r\n        except:\r\n            self.log.warn(\"Unknown error in handling IPythonApp.exec_files:\")\r\n            self.shell.showtraceback()","reference":"Run files from IPythonApp.exec_files","result":"Def run exec files .","score":[0.2403,0.2439]}
{"code":"def _run_cmd_line_code(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.code_to_run:\r\n            line = self.code_to_run\r\n            try:\r\n                self.log.info(\"Running code given at command line (c=): %s\" %\r\n                              line)\r\n                self.shell.run_cell(line, store_history=False)\r\n            except:\r\n                self.log.warn(\"Error in executing line in user namespace: %s\" %\r\n                              line)\r\n                self.shell.showtraceback()\r\n        elif self.file_to_run:\r\n            fname = self.file_to_run\r\n            try:\r\n                self._exec_file(fname)\r\n            except:\r\n                self.log.warn(\"Error in executing file in user namespace: %s\" %\r\n                              fname)\r\n                self.shell.showtraceback()","reference":"Run code or file specified at the command-line","result":"Run code at command line .","score":[0.2165,0.3276]}
{"code":"def _run_module(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.module_to_run:\r\n            save_argv = sys.argv\r\n            sys.argv = [sys.executable] + self.extra_args\r\n            try:\r\n                self.shell.safe_run_module(self.module_to_run,\r\n                                           self.shell.user_ns)\r\n            finally:\r\n                sys.argv = save_argv","reference":"Run module specified at the command-line.","result":"Run the module .","score":[0.255,0.2586]}
{"code":"def generic(func):\r\n    \"\"\" function to<extra_id_0>\r\n    _sentinel = object()\r\n    def _by_class(*args, **kw):\r\n        cls = args[0].__class__\r\n        for t in type(cls.__name__, (cls,object), {}).__mro__:\r\n            f = _gbt(t, _sentinel)\r\n            if f is not _sentinel:\r\n                return f(*args, **kw)\r\n        else:\r\n            return func(*args, **kw)\r\n    _by_type = {object: func}\r\n    try:\r\n        _by_type[InstanceType] = _by_class\r\n    except NameError:\r\n        pass\r\n        _gbt = _by_type.get\r\n    def when_type(*types):\r\n        for t in types:\r\n            if not isinstance(t, classtypes):\r\n                raise TypeError(\r\n                    \"%r is not a type or class\" % (t,)\r\n                )\r\n        def decorate(f):\r\n            for t in types:\r\n                if _by_type.setdefault(t,f) is not f:\r\n                    raise TypeError(\r\n                        \"%r already has method for type %r\" % (func, t)\r\n                    )\r\n            return f\r\n        return decorate\r\n    _by_object = {}\r\n    _gbo = _by_object.get\r\n    def when_object(*obs):\r\n        def decorate(f):\r\n            for o in obs:\r\n                if _by_object.setdefault(id(o), (o,f))[1] is not f:\r\n                    raise TypeError(\r\n                        \"%r already has method for object %r\" % (func, o)\r\n                    )\r\n            return f\r\n        return decorate\r\n    def dispatch(*args, **kw):\r\n        f = _gbo(id(args[0]), _sentinel)\r\n        if f is _sentinel:\r\n            for t in type(args[0]).__mro__:\r\n                f = _gbt(t, _sentinel)\r\n                if f is not _sentinel:\r\n                    return f(*args, **kw)\r\n            else:\r\n                return func(*args, **kw)\r\n        else:\r\n            return f[1](*args, **kw)\r\n    dispatch.__name__       = func.__name__\r\n    dispatch.__dict__       = func.__dict__.copy()\r\n    dispatch.__doc__        = func.__doc__\r\n    dispatch.__module__     = func.__module__\r\n    dispatch.when_type = when_type\r\n    dispatch.when_object = when_object\r\n    dispatch.default = func\r\n    dispatch.has_object = lambda o: id(o) in _by_object\r\n    dispatch.has_type   = lambda t: t in _by_type\r\n    return dispatch","reference":"Create a simple generic function","result":"Create a generic dispatch.","score":[0.3894,0.5215]}
{"code":"def data_filename(fname, pkgdir=\"\"):\r\n    \"\"\" function to<extra_id_0>\r\n    for static_dir in STATIC_PATH:\r\n        static_filename = os.path.join(static_dir, fname)\r\n        if os.path.exists(static_filename):\r\n            return static_filename\r\n        if pkgdir:\r\n            static_filename = os.path.join(static_dir, pkgdir, fname)\r\n            if os.path.exists(static_filename):\r\n                return static_filename\r\n    raise CoverageException(\"Couldn't find static file %r\" % fname)","reference":"Return the path to a data file of ours.\n\n    The file is searched for on `STATIC_PATH`, and the first place it's found,\n    is returned.\n\n    Each directory in `STATIC_PATH` is searched as-is, and also, if `pkgdir`\n    is provided, at that subdirectory.","result":"Find static file .","score":[0.0,0.0137]}
{"code":"def data(fname):\r\n    \"\"\" function to<extra_id_0>\r\n    data_file = open(data_filename(fname))\r\n    try:\r\n        return data_file.read()\r\n    finally:\r\n        data_file.close()","reference":"Return the contents of a data file of ours.","result":"Read data from file .","score":[0.1284,0.1163]}
{"code":"def escape(t):\r\n    \"\"\" function to<extra_id_0>\r\n    return (t\r\n            .replace(\"&\", \"&amp;\").replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\")\r\n            .replace(\"'\", \"&\r\n            .replace(\"  \", \"&nbsp; \")\r\n            .replace(\"  \", \"&nbsp; \")\r\n        )","reference":"HTML-escape the text in `t`.","result":"Escape a string .","score":[0,0.0]}
{"code":"def report(self, morfs):\r\n        \"\"\" function to<extra_id_0>\r\n        assert self.config.html_dir, \"must give a directory for html reporting\"\r\n        self.status.read(self.config.html_dir)\r\n        m = Hasher()\r\n        m.update(self.config)\r\n        these_settings = m.digest()\r\n        if self.status.settings_hash() != these_settings:\r\n            self.status.reset()\r\n            self.status.set_settings_hash(these_settings)\r\n        if self.config.extra_css:\r\n            self.extra_css = os.path.basename(self.config.extra_css)\r\n        self.report_files(self.html_file, morfs, self.config.html_dir)\r\n        if not self.files:\r\n            raise CoverageException(\"No data to report.\")\r\n        self.index_file()\r\n        self.make_local_static_report_files()\r\n        return self.totals.pc_covered","reference":"Generate an HTML report for `morfs`.\n\n        `morfs` is a list of modules or filenames.","result":"Report coverage data .","score":[0,0.0385]}
{"code":"def make_local_static_report_files(self):\r\n        \"\"\" function to<extra_id_0>\r\n        for static, pkgdir in self.STATIC_FILES:\r\n            shutil.copyfile(\r\n                data_filename(static, pkgdir),\r\n                os.path.join(self.directory, static)\r\n                )\r\n        if self.extra_css:\r\n            shutil.copyfile(\r\n                self.config.extra_css,\r\n                os.path.join(self.directory, self.extra_css)\r\n                )","reference":"Make local instances of static files for HTML report.","result":"Make local static report files .","score":[0.1969,0.3628]}
{"code":"def write_html(self, fname, html):\r\n        \"\"\" function to<extra_id_0>\r\n        fout = open(fname, \"wb\")\r\n        try:\r\n            fout.write(html.encode('ascii', 'xmlcharrefreplace'))\r\n        finally:\r\n            fout.close()","reference":"Write `html` to `fname`, properly encoded.","result":"Write html to file .","score":[0.2339,0.1695]}
{"code":"def file_hash(self, source, cu):\r\n        \"\"\" function to<extra_id_0>\r\n        m = Hasher()\r\n        m.update(source)\r\n        self.coverage.data.add_to_hash(cu.filename, m)\r\n        return m.digest()","reference":"Compute a hash that changes if the file needs to be re-reported.","result":"Calculate file hash .","score":[0.0514,0.0893]}
{"code":"def index_file(self):\r\n        \"\"\" function to<extra_id_0>\r\n        index_tmpl = Templite(\r\n            data(\"index.html\"), self.template_globals\r\n            )\r\n        self.totals = sum([f['nums'] for f in self.files])\r\n        html = index_tmpl.render({\r\n            'arcs': self.arcs,\r\n            'extra_css': self.extra_css,\r\n            'files': self.files,\r\n            'totals': self.totals,\r\n        })\r\n        if sys.version_info < (3, 0):\r\n            html = html.decode(\"utf-8\")\r\n        self.write_html(\r\n            os.path.join(self.directory, \"index.html\"),\r\n            html\r\n            )\r\n        self.status.write(self.directory)","reference":"Write the index.html file for this report.","result":"Generate the index.","score":[0.1076,0.0758]}
{"code":"def read(self, directory):\r\n        \"\"\" function to<extra_id_0>\r\n        usable = False\r\n        try:\r\n            status_file = os.path.join(directory, self.STATUS_FILE)\r\n            fstatus = open(status_file, \"rb\")\r\n            try:\r\n                status = pickle.load(fstatus)\r\n            finally:\r\n                fstatus.close()\r\n        except (IOError, ValueError):\r\n            usable = False\r\n        else:\r\n            usable = True\r\n            if status['format'] != self.STATUS_FORMAT:\r\n                usable = False\r\n            elif status['version'] != coverage.__version__:\r\n                usable = False\r\n        if usable:\r\n            self.files = status['files']\r\n            self.settings = status['settings']\r\n        else:\r\n            self.reset()","reference":"Read the last status in `directory`.","result":"Read coverage status from file .","score":[0.2296,0.1667]}
{"code":"def write(self, directory):\r\n        \"\"\" function to<extra_id_0>\r\n        status_file = os.path.join(directory, self.STATUS_FILE)\r\n        status = {\r\n            'format': self.STATUS_FORMAT,\r\n            'version': coverage.__version__,\r\n            'settings': self.settings,\r\n            'files': self.files,\r\n            }\r\n        fout = open(status_file, \"wb\")\r\n        try:\r\n            pickle.dump(status, fout)\r\n        finally:\r\n            fout.close()","reference":"Write the current status to `directory`.","result":"Write coverage status file .","score":[0.2339,0.1695]}
{"code":"def sort_compare(lst1, lst2, inplace=1):\r\n    \"\"\" function to<extra_id_0>\r\n    if not inplace:\r\n        lst1 = lst1[:]\r\n        lst2 = lst2[:]\r\n    lst1.sort(); lst2.sort()\r\n    return lst1 == lst2","reference":"Sort and compare two lists.\n\n    By default it does it in place, thus modifying the lists. Use inplace = 0\n    to avoid that (at the cost of temporary copy creation).","result":"Compare two lists .","score":[0.0005,0.0684]}
{"code":"def get_slice(seq, start=0, stop=None, step=1):\r\n    \"\"\" function to<extra_id_0>\r\n    if stop == None:\r\n        stop = len(seq)\r\n    item = lambda i: seq[i]\r\n    return map(item,xrange(start,stop,step))","reference":"Get a slice of a sequence with variable step. Specify start,stop,step.","result":"Get a slice of a sequence .","score":[0.4724,0.5647]}
{"code":"def chop(seq, size):\r\n    \"\"\" function to<extra_id_0>\r\n    chunk = lambda i: seq[i:i+size]\r\n    return map(chunk,xrange(0,len(seq),size))","reference":"Chop a sequence into chunks of the given size.","result":"Chop a sequence into chunks of size .","score":[0.6349,0.6726]}
{"code":"def read_config():\r\n    \"\"\" function to<extra_id_0>\r\n    config = ConfigParser.ConfigParser()\r\n    config.read(['setup.cfg'])\r\n    if not config.has_section('check-manifest'):\r\n        return\r\n    if (config.has_option('check-manifest', 'ignore-default-rules')\r\n            and config.getboolean('check-manifest', 'ignore-default-rules')):\r\n        del IGNORE[:]\r\n    if config.has_option('check-manifest', 'ignore'):\r\n        patterns = [p.strip() for p in config.get('check-manifest',\r\n                                                  'ignore').splitlines()]\r\n        IGNORE.extend(p for p in patterns if p)","reference":"Read configuration from setup.cfg.","result":"And read the config file .","score":[0,0.119]}
{"code":"def read_manifest():\r\n    \"\"\" function to<extra_id_0>\r\n    if not os.path.isfile('MANIFEST.in'):\r\n        return\r\n    with open('MANIFEST.in') as manifest:\r\n        contents = manifest.read()\r\n    ignore, ignore_regexps = _get_ignore_from_manifest(contents)\r\n    IGNORE.extend(ignore)\r\n    IGNORE_REGEXPS.extend(ignore_regexps)","reference":"Read existing configuration from MANIFEST.in.\n\n    We use that to ignore anything the MANIFEST.in ignores.","result":"Def read the manifest .","score":[0.0397,0.0763]}
{"code":"def _glob_to_regexp(pat):\r\n    \"\"\" function to<extra_id_0>\r\n    pat = fnmatch.translate(pat)\r\n    sep = r'\\\\\\\\' if os.path.sep == '\\\\' else os.path.sep\r\n    return re.sub(r'((?<!\\\\)(\\\\\\\\)*)\\.', r'\\1[^%s]' % sep, pat)","reference":"Compile a glob pattern into a regexp.\n\n    We need to do this because fnmatch allows * to match \/, which we\n    don't want.  E.g. an MANIFEST.in exclude of 'dirname\/*css' should\n    match 'dirname\/foo.css' but not 'dirname\/subdir\/bar.css'.","result":"Def convert glob to regexp .","score":[0.0018,0.0312]}
{"code":"def file_matches(filename, patterns):\r\n    \"\"\" function to<extra_id_0>\r\n    return any(fnmatch.fnmatch(filename, pat) for pat in patterns)","reference":"Does this filename match any of the patterns?","result":"Def check if file matches pattern .","score":[0,0.0633]}
{"code":"def get_versioned_files():\r\n        \"\"\" function to<extra_id_0>\r\n        encoding = 'UTF-8' if sys.platform == 'win32' else None\r\n        output = run(['git', 'ls-files', '-z'], encoding=encoding)\r\n        return add_directories(output.split('\\0')[:-1])","reference":"List all files versioned by git in the current directory.","result":"Def get versioned files .","score":[0.1051,0.1053]}
{"code":"def start_kernel(self, **kwargs):\r\n        \"\"\" function to<extra_id_0>\r\n        kernel_id = unicode(uuid.uuid4())\r\n        km = self.kernel_manager_factory(connection_file=os.path.join(\r\n                    self.connection_dir, \"kernel-%s.json\" % kernel_id),\r\n                    config=self.config,\r\n        )\r\n        km.start_kernel(**kwargs)\r\n        km.start_channels(shell=True, sub=False, stdin=False, hb=False)\r\n        self._kernels[kernel_id] = km\r\n        return kernel_id","reference":"Start a new kernel.","result":"Start a kernel .","score":[0.4518,0.4688]}
{"code":"def shutdown_kernel(self, kernel_id):\r\n        \"\"\" function to<extra_id_0>\r\n        self.get_kernel(kernel_id).shutdown_kernel()\r\n        del self._kernels[kernel_id]","reference":"Shutdown a kernel by its kernel uuid.\n\n        Parameters\n        ==========\n        kernel_id : uuid\n            The id of the kernel to shutdown.","result":"Shutdown a kernel .","score":[0.0155,0.146]}
{"code":"def kill_kernel(self, kernel_id):\r\n        \"\"\" function to<extra_id_0>\r\n        self.get_kernel(kernel_id).kill_kernel()\r\n        del self._kernels[kernel_id]","reference":"Kill a kernel by its kernel uuid.\n\n        Parameters\n        ==========\n        kernel_id : uuid\n            The id of the kernel to kill.","result":"Kill a kernel .","score":[0.0155,0.146]}
{"code":"def get_kernel(self, kernel_id):\r\n        \"\"\" function to<extra_id_0>\r\n        km = self._kernels.get(kernel_id)\r\n        if km is not None:\r\n            return km\r\n        else:\r\n            raise KeyError(\"Kernel with id not found: %s\" % kernel_id)","reference":"Get the single KernelManager object for a kernel by its uuid.\n\n        Parameters\n        ==========\n        kernel_id : uuid\n            The id of the kernel.","result":"Get kernel from kernels .","score":[0.0116,0.0515]}
{"code":"def get_kernel_ports(self, kernel_id):\r\n        \"\"\" function to<extra_id_0>\r\n        km = self.get_kernel(kernel_id)\r\n        return dict(shell_port=km.shell_port,\r\n                    iopub_port=km.iopub_port,\r\n                    stdin_port=km.stdin_port,\r\n                    hb_port=km.hb_port,\r\n        )","reference":"Return a dictionary of ports for a kernel.\n\n        Parameters\n        ==========\n        kernel_id : uuid\n            The id of the kernel.\n\n        Returns\n        =======\n        port_dict : dict\n            A dict of key, value pairs where the keys are the names\n            (stdin_port,iopub_port,shell_port) and the values are the\n            integer port numbers for those channels.","result":"Get ports of a kernel .","score":[0.0003,0.035]}
{"code":"def notebook_for_kernel(self, kernel_id):\r\n        \"\"\" function to<extra_id_0>\r\n        notebook_ids = [k for k, v in self._notebook_mapping.iteritems() if v == kernel_id]\r\n        if len(notebook_ids) == 1:\r\n            return notebook_ids[0]\r\n        else:\r\n            return None","reference":"Return the notebook_id for a kernel_id or None.","result":"Get notebook id for a kernel .","score":[0.198,0.2373]}
{"code":"def start_kernel(self, notebook_id=None, **kwargs):\r\n        \"\"\" function to<extra_id_0>\r\n        kernel_id = self.kernel_for_notebook(notebook_id)\r\n        if kernel_id is None:\r\n            kwargs['extra_arguments'] = self.kernel_argv\r\n            kernel_id = super(MappingKernelManager, self).start_kernel(**kwargs)\r\n            self.set_kernel_for_notebook(notebook_id, kernel_id)\r\n            self.log.info(\"Kernel started: %s\" % kernel_id)\r\n            self.log.debug(\"Kernel args: %r\" % kwargs)\r\n        else:\r\n            self.log.info(\"Using existing kernel: %s\" % kernel_id)\r\n        return kernel_id","reference":"Start a kernel for a notebok an return its kernel_id.\n\n        Parameters\n        ----------\n        notebook_id : uuid\n            The uuid of the notebook to associate the new kernel with. If this\n            is not None, this kernel will be persistent whenever the notebook\n            requests a kernel.","result":"Start a kernel for a notebook .","score":[0.0047,0.0779]}
{"code":"def shutdown_kernel(self, kernel_id):\r\n        \"\"\" function to<extra_id_0>\r\n        self._check_kernel_id(kernel_id)\r\n        super(MappingKernelManager, self).shutdown_kernel(kernel_id)\r\n        self.delete_mapping_for_kernel(kernel_id)\r\n        self.log.info(\"Kernel shutdown: %s\" % kernel_id)","reference":"Shutdown a kernel and remove its notebook association.","result":"Shutdown a kernel .","score":[0.2421,0.3874]}
{"code":"def interrupt_kernel(self, kernel_id):\r\n        \"\"\" function to<extra_id_0>\r\n        self._check_kernel_id(kernel_id)\r\n        super(MappingKernelManager, self).interrupt_kernel(kernel_id)\r\n        self.log.info(\"Kernel interrupted: %s\" % kernel_id)","reference":"Interrupt a kernel.","result":"Interrupt a kernel .","score":[0.4518,0.6048]}
{"code":"def restart_kernel(self, kernel_id):\r\n        \"\"\" function to<extra_id_0>\r\n        self._check_kernel_id(kernel_id)\r\n        km = self.get_kernel(kernel_id)\r\n        km.restart_kernel()\r\n        self.log.info(\"Kernel restarted: %s\" % kernel_id)\r\n        return kernel_id\r\n                notebook_id = self.notebook_for_kernel(kernel_id)\r\n        new_kernel_id = self.start_kernel()\r\n        self.kill_kernel(kernel_id)\r\n        self.set_kernel_for_notebook(notebook_id, new_kernel_id)\r\n        self.log.info(\"Kernel restarted: %s\" % new_kernel_id)\r\n        return new_kernel_id","reference":"Restart a kernel while keeping clients connected.","result":"Restart a kernel .","score":[0.3108,0.4395]}
{"code":"def create_iopub_stream(self, kernel_id):\r\n        \"\"\" function to<extra_id_0>\r\n        self._check_kernel_id(kernel_id)\r\n        return super(MappingKernelManager, self).create_iopub_stream(kernel_id)","reference":"Create a new iopub stream.","result":"Create stream .","score":[0.2096,0.1042]}
{"code":"def create_shell_stream(self, kernel_id):\r\n        \"\"\" function to<extra_id_0>\r\n        self._check_kernel_id(kernel_id)\r\n        return super(MappingKernelManager, self).create_shell_stream(kernel_id)","reference":"Create a new shell stream.","result":"Create shell stream .","score":[0.2959,0.2041]}
{"code":"def create_hb_stream(self, kernel_id):\r\n        \"\"\" function to<extra_id_0>\r\n        self._check_kernel_id(kernel_id)\r\n        return super(MappingKernelManager, self).create_hb_stream(kernel_id)","reference":"Create a new hb stream.","result":"Create hb stream .","score":[0.2959,0.2041]}
{"code":"def reset(self):\r\n      \"\"\" function to<extra_id_0>\r\n      instdict = self.__dict__\r\n      classdict = self.__class__.__dict__\r\n      for mname, mval in classdict.items():\r\n         if mname in instdict and isinstance(mval, OneTimeProperty):\r\n            delattr(self, mname)","reference":"Reset all OneTimeProperty attributes that may have fired already.","result":"Reset the instance .","score":[0.0915,0.0588]}
{"code":"def export_html(html, filename, image_tag = None, inline = True):\r\n    \"\"\" function to<extra_id_0>\r\n    if image_tag is None:\r\n        image_tag = default_image_tag\r\n    else:\r\n        image_tag = ensure_utf8(image_tag)\r\n    if inline:\r\n        path = None\r\n    else:\r\n        root,ext = os.path.splitext(filename)\r\n        path = root + \"_files\"\r\n        if os.path.isfile(path):\r\n            raise OSError(\"%s exists, but is not a directory.\" % path)\r\n    with open(filename, 'w') as f:\r\n        html = fix_html(html)\r\n        f.write(IMG_RE.sub(lambda x: image_tag(x, path = path, format = \"png\"),\r\n                           html))","reference":"Export the contents of the ConsoleWidget as HTML.\n\n    Parameters:\n    -----------\n    html : str,\n        A utf-8 encoded Python string containing the Qt HTML to export.\n\n    filename : str\n        The file to be saved.\n\n    image_tag : callable, optional (default None)\n        Used to convert images. See ``default_image_tag()`` for information.\n\n    inline : bool, optional [default True]\n        If True, include images as inline PNGs.  Otherwise, include them as\n        links to external PNG files, mimicking web browsers' \"Web Page,\n        Complete\" behavior.","result":"Export html to file .","score":[0.0,0.0294]}
{"code":"def export_xhtml(html, filename, image_tag=None):\r\n    \"\"\" function to<extra_id_0>\r\n    if image_tag is None:\r\n        image_tag = default_image_tag\r\n    else:\r\n        image_tag = ensure_utf8(image_tag)\r\n    with open(filename, 'w') as f:\r\n        offset = html.find(\"<html>\")\r\n        assert offset > -1, 'Invalid HTML string: no <html> tag.'\r\n        html = ('<html xmlns=\"http:\/\/www.w3.org\/1999\/xhtml\">\\n'+\r\n                html[offset+6:])\r\n        html = fix_html(html)\r\n        f.write(IMG_RE.sub(lambda x: image_tag(x, path = None, format = \"svg\"),\r\n                           html))","reference":"Export the contents of the ConsoleWidget as XHTML with inline SVGs.\n\n    Parameters:\n    -----------\n    html : str,\n        A utf-8 encoded Python string containing the Qt HTML to export.\n\n    filename : str\n        The file to be saved.\n\n    image_tag : callable, optional (default None)\n        Used to convert images. See ``default_image_tag()`` for information.","result":"Export an HTML document to a file .","score":[0.0012,0.0557]}
{"code":"def ensure_utf8(image_tag):\r\n    \"\"\" function to<extra_id_0>\r\n    if py3compat.PY3:\r\n        return image_tag\r\n        def utf8_image_tag(*args, **kwargs):\r\n        s = image_tag(*args, **kwargs)\r\n        if isinstance(s, unicode):\r\n            s = s.encode('utf8')\r\n        return s\r\n    return utf8_image_tag","reference":"wrapper for ensuring image_tag returns utf8-encoded str on Python 2","result":"Ensure image tags are unicode .","score":[0,0.0521]}
{"code":"def fix_html(html):\r\n    \"\"\" function to<extra_id_0>\r\n    offset = html.find('<head>')\r\n    if offset > -1:\r\n        html = (html[:offset+6]+\r\n                '\\n<meta http-equiv=\"Content-Type\" '+\r\n                'content=\"text\/html; charset=utf-8\" \/>\\n'+\r\n                html[offset+6:])\r\n    html = re.sub(EMPTY_P_RE, '<br\/>', html)\r\n    return html","reference":"Transforms a Qt-generated HTML string into a standards-compliant one.\n\n    Parameters:\n    -----------\n    html : str,\n        A utf-8 encoded Python string containing the Qt HTML.","result":"Fix html .","score":[0.0005,0.0238]}
{"code":"def export(self):\r\n        \"\"\" function to<extra_id_0>\r\n        parent = self.control.window()\r\n        dialog = QtGui.QFileDialog(parent, 'Save as...')\r\n        dialog.setAcceptMode(QtGui.QFileDialog.AcceptSave)\r\n        filters = [\r\n            'HTML with PNG figures (*.html *.htm)',\r\n            'XHTML with inline SVG figures (*.xhtml *.xml)'\r\n        ]\r\n        dialog.setNameFilters(filters)\r\n        if self.filename:\r\n            dialog.selectFile(self.filename)\r\n            root,ext = os.path.splitext(self.filename)\r\n            if ext.lower() in ('.xml', '.xhtml'):\r\n                dialog.selectNameFilter(filters[-1])\r\n        if dialog.exec_():\r\n            self.filename = dialog.selectedFiles()[0]\r\n            choice = dialog.selectedNameFilter()\r\n            html = self.control.document().toHtml().encode('utf-8')\r\n            if choice.startswith('XHTML'):\r\n                exporter = export_xhtml\r\n            else:\r\n                inline = self.inline_png\r\n                if inline is None and IMG_RE.search(html):\r\n                    dialog = QtGui.QDialog(parent)\r\n                    dialog.setWindowTitle('Save as...')\r\n                    layout = QtGui.QVBoxLayout(dialog)\r\n                    msg = \"Exporting HTML with PNGs\"\r\n                    info = \"Would you like inline PNGs (single large html \" \\\r\n                        \"file) or external image files?\"\r\n                    checkbox = QtGui.QCheckBox(\"&Don't ask again\")\r\n                    checkbox.setShortcut('D')\r\n                    ib = QtGui.QPushButton(\"&Inline\")\r\n                    ib.setShortcut('I')\r\n                    eb = QtGui.QPushButton(\"&External\")\r\n                    eb.setShortcut('E')\r\n                    box = QtGui.QMessageBox(QtGui.QMessageBox.Question,\r\n                                            dialog.windowTitle(), msg)\r\n                    box.setInformativeText(info)\r\n                    box.addButton(ib, QtGui.QMessageBox.NoRole)\r\n                    box.addButton(eb, QtGui.QMessageBox.YesRole)\r\n                    layout.setSpacing(0)\r\n                    layout.addWidget(box)\r\n                    layout.addWidget(checkbox)\r\n                    dialog.setLayout(layout)\r\n                    dialog.show()\r\n                    reply = box.exec_()\r\n                    dialog.hide()\r\n                    inline = (reply == 0)\r\n                    if checkbox.checkState():\r\n                        self.inline_png = inline\r\n                exporter = lambda h, f, i: export_html(h, f, i, inline)\r\n            try:\r\n                return exporter(html, self.filename, self.image_tag)\r\n            except Exception, e:\r\n                msg = \"Error exporting HTML to %s\\n\" % self.filename + str(e)\r\n                reply = QtGui.QMessageBox.warning(parent, 'Error', msg,\r\n                    QtGui.QMessageBox.Ok, QtGui.QMessageBox.Ok)\r\n        return None","reference":"Displays a dialog for exporting HTML generated by Qt's rich text\n        system.\n\n        Returns\n        -------\n        The name of the file that was saved, or None if no file was saved.","result":"Def export HTML to file .","score":[0.005,0.0957]}
{"code":"def get_unique_or_none(klass, *args, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    try:\r\n        return klass.objects.get(*args, **kwargs)\r\n    except klass.DoesNotExist:\r\n        return None\r\n    except klass.MultipleObjectsReturned:\r\n        return None\r\n    return None","reference":"Returns a unique instance of `klass` or None","result":"Get unique or none .","score":[0.1568,0.3319]}
{"code":"def get_query_includes(tokenized_terms, search_fields):\r\n    \"\"\" function to<extra_id_0>\r\n    query = None\r\n    for term in tokenized_terms:\r\n        or_query = None\r\n        for field_name in search_fields:\r\n            q = Q(**{\"%s__icontains\" % field_name: term})\r\n            if or_query is None:\r\n                or_query = q\r\n            else:\r\n                or_query = or_query | q\r\n        if query is None:\r\n            query = or_query\r\n        else:\r\n            query = query & or_query\r\n    return query","reference":"Builds a query for included terms in a text search.","result":"Get query includes .","score":[0.0713,0.1064]}
{"code":"def get_text_query(query_string, search_fields):\r\n    \"\"\" function to<extra_id_0>\r\n    include_terms, exclude_terms = get_text_tokenizer(query_string)\r\n    include_q = get_query_includes(include_terms, search_fields)\r\n    exclude_q = get_query_excludes(exclude_terms, search_fields)\r\n    query = None\r\n    if include_q and exclude_q:\r\n        query = include_q & ~exclude_q\r\n    elif not exclude_q:\r\n        query = include_q\r\n    else:\r\n        query = ~exclude_q\r\n    return query","reference":"Builds a query for both included & excluded terms in a text search.","result":"Get text query .","score":[0.04,0.0826]}
{"code":"def get_date_greater_query(days, date_field):\r\n    \"\"\" function to<extra_id_0>\r\n    query = None\r\n    days = get_integer(days)\r\n    if days:\r\n        past = get_days_ago(days)\r\n        query = Q(**{\"%s__gte\" % date_field: past.isoformat()})\r\n    return query","reference":"Query for if date_field is within number of \"days\" ago.","result":"Get date greater query .","score":[0,0.0526]}
{"code":"def get_date_less_query(days, date_field):\r\n    \"\"\" function to<extra_id_0>\r\n    query = None\r\n    days = get_integer(days)\r\n    if days:\r\n        future = get_days_from_now(days)\r\n        query = Q(**{\"%s__lte\" % date_field: future.isoformat()})\r\n    return query","reference":"Query for if date_field is within number of \"days\" from now.","result":"Get query for date less than query .","score":[0.0955,0.0935]}
{"code":"def get_null_or_blank_query(field=None):\r\n    \"\"\" function to<extra_id_0>\r\n    if not field:\r\n        return field\r\n    null_q = get_null_query(field)\r\n    blank_q = get_blank_query(field)\r\n    return (null_q | blank_q)","reference":"Query for null or blank field.","result":"Get null or blank query .","score":[0.3976,0.625]}
{"code":"def case_insensitive(self, fields_dict):\r\n        \"\"\" function to<extra_id_0>\r\n        if hasattr(self.model, 'CASE_INSENSITIVE_FIELDS'):\r\n            for field in self.model.CASE_INSENSITIVE_FIELDS:\r\n                if field in fields_dict:\r\n                    fields_dict[field + '__iexact'] = fields_dict[field]\r\n                    del fields_dict[field]","reference":"Converts queries to case insensitive for special fields.","result":"Add case insensitive fields .","score":[0.1865,0.2435]}
{"code":"def options(self, parser, env):\r\n        \"\"\" function to<extra_id_0>\r\n        parser.add_option(\"-a\", \"--attr\",\r\n                          dest=\"attr\", action=\"append\",\r\n                          default=env.get('NOSE_ATTR'),\r\n                          metavar=\"ATTR\",\r\n                          help=\"Run only tests that have attributes \"\r\n                          \"specified by ATTR [NOSE_ATTR]\")\r\n        if compat_24:\r\n            parser.add_option(\"-A\", \"--eval-attr\",\r\n                              dest=\"eval_attr\", metavar=\"EXPR\", action=\"append\",\r\n                              default=env.get('NOSE_EVAL_ATTR'),\r\n                              help=\"Run only tests for whose attributes \"\r\n                              \"the Python expression EXPR evaluates \"\r\n                              \"to True [NOSE_EVAL_ATTR]\")","reference":"Register command line options","result":"Add options to the parser .","score":[0.193,0.119]}
{"code":"def validateAttrib(self, method, cls = None):\r\n        \"\"\" function to<extra_id_0>\r\n        any = False\r\n        for group in self.attribs:\r\n            match = True\r\n            for key, value in group:\r\n                attr = get_method_attr(method, cls, key)\r\n                if callable(value):\r\n                    if not value(key, method, cls):\r\n                        match = False\r\n                        break\r\n                elif value is True:\r\n                    if not bool(attr):\r\n                        match = False\r\n                        break\r\n                elif value is False:\r\n                    if bool(attr):\r\n                        match = False\r\n                        break\r\n                elif type(attr) in (list, tuple):\r\n                    if not str(value).lower() in [str(x).lower()\r\n                                                  for x in attr]:\r\n                        match = False\r\n                        break\r\n                else:\r\n                    if (value != attr\r\n                        and str(value).lower() != str(attr).lower()):\r\n                        match = False\r\n                        break\r\n            any = any or match\r\n        if any:\r\n            return None\r\n        return False","reference":"Verify whether a method has the required attributes\n        The method is considered a match if it matches all attributes\n        for any attribute group.\n        .","result":"Validate method attributes .","score":[0.0028,0.0682]}
{"code":"def wantMethod(self, method):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            cls = method.im_class\r\n        except AttributeError:\r\n            return False\r\n        return self.validateAttrib(method, cls)","reference":"Accept the method if its attributes match.","result":" is a class method .","score":[0.1611,0.0735]}
{"code":"def rotate(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._prev_yank:\r\n            text = self._ring.rotate()\r\n            if text:\r\n                self._skip_cursor = True\r\n                cursor = self._text_edit.textCursor()\r\n                cursor.movePosition(QtGui.QTextCursor.Left,\r\n                                    QtGui.QTextCursor.KeepAnchor,\r\n                                    n = len(self._prev_yank))\r\n                cursor.insertText(text)\r\n                self._prev_yank = text","reference":"Rotate the kill ring, then yank back the new top.","result":"Rotate the ring .","score":[0.1008,0.1064]}
{"code":"def patch_pyzmq():\r\n        \"\"\" function to<extra_id_0>\r\n        import zmq\r\n        from zmq.eventloop import ioloop\r\n        def install():\r\n        import tornado.ioloop\r\n        tornado.ioloop.IOLoop = ioloop.IOLoop\r\n        if not hasattr(ioloop, 'install'):\r\n        ioloop.install = install\r\n        if not hasattr(zmq, 'DEALER'):\r\n        zmq.DEALER = zmq.XREQ\r\n    if not hasattr(zmq, 'ROUTER'):\r\n        zmq.ROUTER = zmq.XREP\r\n        from zmq.utils import jsonapi\r\n    if jsonapi.jsonmod.__name__ == 'jsonlib':\r\n        import json\r\n        jsonapi.jsonmod = json","reference":"backport a few patches from newer pyzmq\n    \n    These can be removed as we bump our minimum pyzmq version","result":"Def patch pyzmq .","score":[0.0096,0.0602]}
{"code":"def parser_from_schema(schema_url, require_version=True):\r\n    \"\"\" function to<extra_id_0>\r\n    schema_tree = etree.parse(schema_url)\r\n    def get_version(element, getter):\r\n        try:\r\n            return getter(element)\r\n        except VersionNotFound:\r\n            if require_version:\r\n                raise\r\n            else:\r\n                return None\r\n    root = schema_tree.getroot()\r\n    if root.tag == '{%s}definitions' % namespaces.WSDL:\r\n        schema_el = schema_tree.find('wsdl:types\/xs:schema', namespaces=NS_MAP)\r\n        version = get_version(root, version_from_wsdl)\r\n    else:\r\n        schema_el = root\r\n        version = get_version(schema_el, version_from_schema)\r\n    schema = etree.XMLSchema(schema_el)\r\n    return objectify.makeparser(schema=schema), version","reference":"Returns an XSD-schema-enabled lxml parser from a WSDL or XSD\n\n    `schema_url` can of course be local path via file:\/\/ url","result":"Parse a schema .","score":[0.0059,0.0272]}
{"code":"def ws_url(self):\r\n        \"\"\" function to<extra_id_0>\r\n        proto = self.request.protocol.replace('http', 'ws')\r\n        host = self.application.ipython_app.websocket_host\r\n        if host == '':\r\n            host = self.request.host\r\n        return \"%s:\/\/%s\" % (proto, host)","reference":"websocket url matching the current request\n\n        turns http[s]:\/\/host[:port] into\n                ws[s]:\/\/host[:port]","result":"Return websocket url .","score":[0.1008,0.1995]}
{"code":"def _reserialize_reply(self, msg_list):\r\n        \"\"\" function to<extra_id_0>\r\n        idents, msg_list = self.session.feed_identities(msg_list)\r\n        msg = self.session.unserialize(msg_list)\r\n        try:\r\n            msg['header'].pop('date')\r\n        except KeyError:\r\n            pass\r\n        try:\r\n            msg['parent_header'].pop('date')\r\n        except KeyError:\r\n            pass\r\n        msg.pop('buffers')\r\n        return jsonapi.dumps(msg, default=date_default)","reference":"Reserialize a reply message using JSON.\n\n        This takes the msg list from the ZMQ socket, unserializes it using\n        self.session and then serializes the result using JSON. This method\n        should be used by self._on_zmq_reply to build messages that can\n        be sent back to the browser.","result":"Reconstruct a reply .","score":[0.0,0.0469]}
{"code":"def _inject_cookie_message(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        if isinstance(msg, unicode):\r\n            msg = msg.encode('utf8', 'replace')\r\n        try:\r\n            self.request._cookies = Cookie.SimpleCookie(msg)\r\n        except:\r\n            logging.warn(\"couldn't parse cookie string: %s\",msg, exc_info=True)","reference":"Inject the first message, which is the document cookie,\n        for authentication.","result":"Inject cookie message .","score":[0.0555,0.0485]}
{"code":"def start_hb(self, callback):\r\n        \"\"\" function to<extra_id_0>\r\n        if not self._beating:\r\n            self._kernel_alive = True\r\n            def ping_or_dead():\r\n                self.hb_stream.flush()\r\n                if self._kernel_alive:\r\n                    self._kernel_alive = False\r\n                    self.hb_stream.send(b'ping')\r\n                    self.hb_stream.flush()\r\n                else:\r\n                    try:\r\n                        callback()\r\n                    except:\r\n                        pass\r\n                    finally:\r\n                        self.stop_hb()\r\n            def beat_received(msg):\r\n                self._kernel_alive = True\r\n            self.hb_stream.on_recv(beat_received)\r\n            loop = ioloop.IOLoop.instance()\r\n            self._hb_periodic_callback = ioloop.PeriodicCallback(ping_or_dead, self.time_to_dead*1000, loop)\r\n            loop.add_timeout(time.time()+self.first_beat, self._really_start_hb)\r\n            self._beating= True","reference":"Start the heartbeating and call the callback if the kernel dies.","result":"Def start the hb .","score":[0.0724,0.0962]}
{"code":"def _really_start_hb(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._beating and not self.hb_stream.closed():\r\n            self._hb_periodic_callback.start()","reference":"callback for delayed heartbeat start\n        \n        Only start the hb loop if we haven't been closed during the wait.","result":" is not already started .","score":[0,0.0299]}
{"code":"def stop_hb(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._beating:\r\n            self._beating = False\r\n            self._hb_periodic_callback.stop()\r\n            if not self.hb_stream.closed():\r\n                self.hb_stream.on_recv(None)","reference":"Stop the heartbeating and cancel all related callbacks.","result":"Def stop the hb .","score":[0.1319,0.2435]}
{"code":"def fload(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if hasattr(self, 'fobj') and self.fobj is not None:\r\n           self.fobj.close()\r\n        if hasattr(self.src, \"read\"):\r\n            self.fobj = self.src\r\n        else:\r\n            self.fobj = open(self.fname)","reference":"Load file object.","result":"Load the file .","score":[0.3799,0.3226]}
{"code":"def _get_index(self,index):\r\n        \"\"\" function to<extra_id_0>\r\n        if index is None:\r\n            if self.finished:\r\n                print >>io.stdout, 'Demo finished.  Use <demo_name>.reset() if you want to rerun it.'\r\n                return None\r\n            index = self.block_index\r\n        else:\r\n            self._validate_index(index)\r\n        return index","reference":"Get the current block index, validating and checking status.\n\n        Returns None if the demo is finished","result":"Get the index of the block .","score":[0.0751,0.209]}
{"code":"def seek(self,index):\r\n        \"\"\" function to<extra_id_0>\r\n        if index<0:\r\n            index = self.nblocks + index\r\n        self._validate_index(index)\r\n        self.block_index = index\r\n        self.finished = False","reference":"Move the current seek pointer to the given block.\n\n        You can use negative indices to seek from the end, with identical\n        semantics to those of Python lists.","result":"Seek to a given index .","score":[0.0069,0.0602]}
{"code":"def edit(self,index=None):\r\n        \"\"\" function to<extra_id_0>\r\n        index = self._get_index(index)\r\n        if index is None:\r\n            return\r\n        if index>0:\r\n            index -= 1\r\n        filename = self.shell.mktempfile(self.src_blocks[index])\r\n        self.shell.hooks.editor(filename,1)\r\n        new_block = file_read(filename)\r\n        self.src_blocks[index] = new_block\r\n        self.src_blocks_colored[index] = self.ip_colorize(new_block)\r\n        self.block_index = index\r\n        self()","reference":"Edit a block.\n\n        If no number is given, use the last block executed.\n\n        This edits the in-memory copy of the demo, it does NOT modify the\n        original source file.  If you want to do that, simply open the file in\n        an editor and use reload() when you make changes to the file.  This\n        method is meant to let you change a block during a demonstration for\n        explanatory purposes, without damaging your original script.","result":"Edit a block in the current block .","score":[0.0001,0.0451]}
{"code":"def show(self,index=None):\r\n        \"\"\" function to<extra_id_0>\r\n        index = self._get_index(index)\r\n        if index is None:\r\n            return\r\n        print >>io.stdout, self.marquee('<%s> block\r\n                           (self.title,index,self.nblocks-index-1))\r\n        print >>io.stdout,(self.src_blocks_colored[index])\r\n        sys.stdout.flush()","reference":"Show a single block on screen","result":"Show the blocks .","score":[0.1938,0.1724]}
{"code":"def show_all(self):\r\n        \"\"\" function to<extra_id_0>\r\n        fname = self.title\r\n        title = self.title\r\n        nblocks = self.nblocks\r\n        silent = self._silent\r\n        marquee = self.marquee\r\n        for index,block in enumerate(self.src_blocks_colored):\r\n            if silent[index]:\r\n                print >>io.stdout, marquee('<%s> SILENT block\r\n                              (title,index,nblocks-index-1))\r\n            else:\r\n                print >>io.stdout, marquee('<%s> block\r\n                              (title,index,nblocks-index-1))\r\n            print >>io.stdout, block,\r\n        sys.stdout.flush()","reference":"Show entire demo on screen, block by block","result":"Show all blocks in the file .","score":[0.14,0.1266]}
{"code":"def series(collection, method, prints = 15, *args, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    '''\r\n    Processes a collection in series \r\n    Parameters\r\n    ----------\r\n    collection : list\r\n        list of Record objects\r\n    method : method to call on each Record\r\n    prints : int\r\n        number of timer prints to the screen\r\n    Returns\r\n    -------\r\n    collection : list\r\n        list of Record objects after going through method called\r\n        If more than one collection is given, the function is called with an argument list \r\n    consisting of the corresponding item of each collection, substituting None for \r\n    missing values when not all collection have the same length.  \r\n    If the function is None, return the original collection (or a list of tuples if multiple collections).\r\n        Example\r\n    -------\r\n    adding 2 to every number in a range\r\n    >>> import turntable\r\n    >>> collection = range(100)\r\n    >>> method = lambda x: x + 2\r\n    >>> collection = turntable.spin.series(collection, method)\r\n        '''\r\n    if 'verbose' in kwargs.keys():\r\n        verbose = kwargs['verbose']\r\n    else:\r\n        verbose = True\r\n    results = []\r\n    timer = turntable.utils.Timer(nLoops=len(collection), numPrints=prints, verbose=verbose)\r\n    for subject in collection:\r\n        results.append(method(subject, *args, **kwargs))\r\n        timer.loop()\r\n    timer.fin()\r\n    return results","reference":"Processes a collection in series \n\n    Parameters\n    ----------\n    collection : list\n        list of Record objects\n    method : method to call on each Record\n    prints : int\n        number of timer prints to the screen\n\n    Returns\n    -------\n    collection : list\n        list of Record objects after going through method called\n    \n    If more than one collection is given, the function is called with an argument list \n    consisting of the corresponding item of each collection, substituting None for \n    missing values when not all collection have the same length.  \n    If the function is None, return the original collection (or a list of tuples if multiple collections).\n    \n    Example\n    -------\n    adding 2 to every number in a range\n\n    >>> import turntable\n    >>> collection = range(100)\n    >>> method = lambda x: x + 2\n    >>> collection = turntable.spin.series(collection, method)","result":"Process a collection in series process a collection.","score":[0.0,0.0257]}
{"code":"def batch(collection, method, processes=None, batch_size=None, quiet=False,\r\n          \"\"\" function to<extra_id_0>\r\n          kwargs_to_dump=None, args=None, **kwargs):\r\n    '''Processes a collection in parallel batches, \r\n    each batch processes in series on a single process.\r\n    Running batches in parallel can be more effficient that splitting a list across cores as in spin.parallel \r\n    because of parallel processing has high IO requirements.\r\n    Parameters\r\n    ----------\r\n    collection : list\r\n        i.e. list of Record objects\r\n    method : method to call on each Record\r\n    processes : int\r\n        number of processes to run on [defaults to number of cores on machine]\r\n    batch_size : int\r\n        lenght of each batch [defaults to number of elements \/ number of processes]\r\n    Returns\r\n    -------\r\n    collection : list\r\n        list of Record objects after going through method called\r\n    Example\r\n    -------\r\n    adding 2 to every number in a range\r\n    >>> import turntable\r\n    >>> collection = range(100)\r\n    >>> def jam(record):\r\n    >>>     return record + 2\r\n    >>> collection = turntable.spin.batch(collection, jam)\r\n    Note\r\n    ----\r\n    lambda functions do not work in parallel\r\n    '''\r\n    if processes is None:\r\n        processes = min(mp.cpu_count(), 20, len(collection))\r\n    if batch_size is None:\r\n        batch_size = max(len(collection) \/\/ processes, 1)\r\n    print 'size of each batch =', batch_size\r\n    mod = len(collection) % processes\r\n    batch_list = [collection[x:x + batch_size]\r\n                  for x in xrange(0, len(collection) - mod, batch_size)]\r\n    if mod != 0:\r\n        batch_list[len(batch_list) - 1] += collection[-mod:]\r\n    print 'number of batches =', len(batch_list)\r\n    if args is None:\r\n        args = method\r\n    else:\r\n        if isinstance(args, tuple) == False:\r\n            args = (args,)\r\n        args = (method,) + args\r\n    if kwargs_to_dump is None:\r\n        res = parallel(\r\n            batch_list,\r\n            new_function_batch,\r\n            processes=processes,\r\n            args=args,\r\n            **kwargs)\r\n    else:\r\n        res = process_dump(\r\n            batch_list,\r\n            new_function_batch,\r\n            kwargs_to_dump,\r\n            processes=processes,\r\n            args=args,\r\n            **kwargs)\r\n    returnList = []\r\n    for l in res:\r\n        returnList += l\r\n    return returnList","reference":"Processes a collection in parallel batches, \n    each batch processes in series on a single process.\n    Running batches in parallel can be more effficient that splitting a list across cores as in spin.parallel \n    because of parallel processing has high IO requirements.\n\n    Parameters\n    ----------\n    collection : list\n        i.e. list of Record objects\n    method : method to call on each Record\n    processes : int\n        number of processes to run on [defaults to number of cores on machine]\n    batch_size : int\n        lenght of each batch [defaults to number of elements \/ number of processes]\n\n    Returns\n    -------\n    collection : list\n        list of Record objects after going through method called\n\n    Example\n    -------\n    adding 2 to every number in a range\n\n    >>> import turntable\n    >>> collection = range(100)\n    >>> def jam(record):\n    >>>     return record + 2\n    >>> collection = turntable.spin.batch(collection, jam)\n\n    Note\n    ----\n\n    lambda functions do not work in parallel","result":"Def call on each Record .","score":[0.0,0.0193]}
{"code":"def thread(function, sequence, cores=None, runSeries=False, quiet=False):\r\n    \"\"\" function to<extra_id_0>\r\n    '''sets up the threadpool with map for parallel processing'''\r\n    if cores is None:\r\n        pool = ThreadPool()\r\n    else:\r\n        pool = ThreadPool(cores)\r\n    tic = time.time()\r\n    if runSeries is False:\r\n        try:\r\n            results = pool.map(function, sequence)\r\n            pool.close()\r\n            pool.join()\r\n        except:\r\n            print 'thread Failed... running in series :-('\r\n            results = series(sequence, function)\r\n    else:\r\n        results = series(sequence, function)\r\n    toc = time.time()\r\n    elapsed = toc - tic\r\n    if quiet is False:\r\n        if cores is None:\r\n            print \"Elapsed time: %s  :-)\\n\" % str(elapsed)\r\n        else:\r\n            print \"Elapsed time: %s  on %s threads :-)\\n\" % (str(elapsed), str(cores))\r\n    return results","reference":"sets up the threadpool with map for parallel processing","result":"Run a map in a thread .","score":[0.1214,0.0568]}
{"code":"def parallel(collection, method, processes=None, args=None, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    '''Processes a collection in parallel.\r\n    Parameters\r\n    ----------\r\n    collection : list\r\n        i.e. list of Record objects\r\n    method : method to call on each Record\r\n    processes : int\r\n        number of processes to run on [defaults to number of cores on machine]\r\n    batch_size : int\r\n        lenght of each batch [defaults to number of elements \/ number of processes]\r\n    Returns\r\n    -------\r\n    collection : list\r\n        list of Record objects after going through method called\r\n    Example\r\n    -------\r\n    adding 2 to every number in a range\r\n    >>> import turntable\r\n    >>> collection = range(100)\r\n    >>> def jam(record):\r\n    >>>     return record + 2\r\n    >>> collection = turntable.spin.parallel(collection, jam)\r\n    Note\r\n    ----\r\n    lambda functions do not work in parallel\r\n    '''\r\n    if processes is None:\r\n        processes = min(mp.cpu_count(), 20)\r\n    print \"Running parallel process on \" + str(processes) + \" cores. :-)\"\r\n    pool = mp.Pool(processes=processes)\r\n    PROC = []\r\n    tic = time.time()\r\n    for main_arg in collection:\r\n        if args is None:\r\n            ARGS = (main_arg,)\r\n        else:\r\n            if isinstance(args, tuple) == False:\r\n                args = (args,)\r\n            ARGS = (main_arg,) + args\r\n        PROC.append(pool.apply_async(method, args=ARGS, kwds=kwargs))\r\n    RES = []\r\n    for p in PROC:\r\n        try:\r\n            RES.append(p.get())\r\n        except Exception as e:\r\n            print \"shit happens...\"\r\n            print e\r\n            RES.append(None)\r\n    pool.close()\r\n    pool.join()\r\n    toc = time.time()\r\n    elapsed = toc - tic\r\n    print \"Elapsed time: %s  on %s processes :-)\\n\" % (str(elapsed), str(processes))\r\n    return RES","reference":"Processes a collection in parallel.\n\n    Parameters\n    ----------\n    collection : list\n        i.e. list of Record objects\n    method : method to call on each Record\n    processes : int\n        number of processes to run on [defaults to number of cores on machine]\n    batch_size : int\n        lenght of each batch [defaults to number of elements \/ number of processes]\n\n    Returns\n    -------\n    collection : list\n        list of Record objects after going through method called\n\n    Example\n    -------\n    adding 2 to every number in a range\n\n    >>> import turntable\n    >>> collection = range(100)\n    >>> def jam(record):\n    >>>     return record + 2\n    >>> collection = turntable.spin.parallel(collection, jam)\n\n    Note\n    ----\n\n    lambda functions do not work in parallel","result":"Process a collection in parallel .","score":[0.0,0.038]}
{"code":"def with_it(obj):\r\n    \"\"\" function to<extra_id_0>\r\n    '''\r\n    wrap `with obj` out of func.\r\n    example:\r\n    ``` py\r\n    @with_it(Lock())\r\n    def func(): pass\r\n    ```\r\n    '''\r\n    def _wrap(func):\r\n        @functools.wraps(func)\r\n        def wrapper(*args, **kwargs):\r\n            with obj:\r\n                return func(*args, **kwargs)\r\n        return wrapper\r\n    return _wrap","reference":"wrap `with obj` out of func.\n\n    example:\n\n    ``` py\n    @with_it(Lock())\n    def func(): pass\n    ```","result":"Wrap with it .","score":[0,0.0385]}
{"code":"def with_objattrs(*names):\r\n    \"\"\" function to<extra_id_0>\r\n    '''\r\n    like `with_objattr` but enter context one by one.\r\n    '''\r\n    def _wrap(func):\r\n        @functools.wraps(func)\r\n        def wrapper(self, *args, **kwargs):\r\n            with contextlib.ExitStack() as stack:\r\n                for name in names:\r\n                    stack.enter_context(getattr(self, name))\r\n                return func(self, *args, **kwargs)\r\n        return wrapper\r\n    return _wrap","reference":"like `with_objattr` but enter context one by one.","result":"Enter context one by one.","score":[0.4128,0.6468]}
{"code":"def tbsource(tb, context=6):\r\n        \"\"\" function to<extra_id_0>\r\n        lineno = tb.tb_lineno\r\n    frame = tb.tb_frame\r\n    if context > 0:\r\n        start = lineno - 1 - context\/\/2\r\n        log.debug(\"lineno: %s start: %s\", lineno, start)\r\n                try:\r\n            lines, dummy = inspect.findsource(frame)\r\n        except IOError:\r\n            lines, index = [''], 0\r\n        else:\r\n            all_lines = lines\r\n            start = max(start, 1)\r\n            start = max(0, min(start, len(lines) - context))\r\n            lines = lines[start:start+context]\r\n            index = lineno - 1 - start\r\n                        if sys.version_info >= (2, 5) and index > 0:\r\n                while lines[index-1].strip().endswith('\\\\'):\r\n                    start -= 1\r\n                    lines = all_lines[start:start+context]\r\n    else:\r\n        lines, index = [''], 0\r\n    log.debug(\"tbsource lines '''%s''' around index %s\", lines, index)\r\n    return (lines, index)","reference":"Get source from  a traceback object.\n\n    A tuple of two things is returned: a list of lines of context from\n    the source code, and the index of the current line within that list.\n    The optional second argument specifies the number of lines of context\n    to return, which are centered around the current line.\n\n    .. Note ::\n       This is adapted from inspect.py in the python 2.4 standard library, \n       since a bug in the 2.3 version of inspect prevents it from correctly\n       locating source lines in a traceback frame.","result":"Get the source code of a traceback .","score":[0.0,0.0539]}
{"code":"def find_inspectable_lines(lines, pos):\r\n    \"\"\" function to<extra_id_0>\r\n    cnt = re.compile(r'\\\\[\\s\\n]*$')\r\n    df = re.compile(r':[\\s\\n]*$')\r\n    ind = re.compile(r'^(\\s*)')\r\n    toinspect = []\r\n    home = lines[pos]\r\n    home_indent = ind.match(home).groups()[0]\r\n        before = lines[max(pos-3, 0):pos]\r\n    before.reverse()\r\n    after = lines[pos+1:min(pos+4, len(lines))]\r\n    for line in before:\r\n        if ind.match(line).groups()[0] == home_indent:\r\n            toinspect.append(line)\r\n        else:\r\n            break\r\n    toinspect.reverse()\r\n    toinspect.append(home)\r\n    home_pos = len(toinspect)-1\r\n    continued = cnt.search(home)\r\n    for line in after:\r\n        if ((continued or ind.match(line).groups()[0] == home_indent)\r\n            and not df.search(line)):\r\n            toinspect.append(line)\r\n            continued = cnt.search(line)\r\n        else:\r\n            break\r\n    log.debug(\"Inspecting lines '''%s''' around %s\", toinspect, home_pos)\r\n    return toinspect, home_pos","reference":"Find lines in home that are inspectable.\n    \n    Walk back from the err line up to 3 lines, but don't walk back over\n    changes in indent level.\n\n    Walk forward up to 3 lines, counting \\ separated lines as 1. Don't walk\n    over changes in indent level (unless part of an extended line)","result":"Find the lines to inspect.","score":[0.0,0.0431]}
{"code":"def countdown(name, date, description='', id='', granularity='sec', start=None,\r\n  \"\"\" function to<extra_id_0>\r\n  progressbar=False, progressbar_inversed=False, showpct=False):\r\n    '''\r\n    Create a countdown.\r\n    '''\r\n    end_date = dateparse.parse_datetime(date)\r\n    end = dateformat.format(end_date, 'U')\r\n    content = '<div class=\"name\">' + name + '<\/div>'\r\n    content += '<div class=\"description\">' + description + '<\/div>'\r\n    if progressbar:\r\n        if not end: raise Exception('For progressbar, start date is requried.')\r\n        parsed_date = datetime.datetime.combine(\r\n            dateparse.parse_date(start), datetime.time())\r\n        start_date = dateparse.parse_datetime(start) or parsed_date\r\n        now = datetime.datetime.now()\r\n        pct = (now - start_date).total_seconds() \/\\\r\n            (end_date - start_date).total_seconds()\r\n        pct = int(pct * 100)\r\n        if progressbar_inversed:\r\n            pct = 100 - pct\r\n        bar = '<div class=\"progress progress-striped active\">'\r\n        bar += '<div class=\"progress-bar\"  role=\"progressbar\" aria-valuenow=\"{pct}\" aria-valuemin=\"0\" aria-valuemax=\"100\" style=\"width: {pct}%\">'\r\n        bar += '<span class=\"sr-only\">{pct}% Complete<\/span>'\r\n        bar += '<\/div>'\r\n        bar += '<\/div>'\r\n        if showpct:\r\n            bar += '<div class=\"percentage\">{pct}%<\/div>'\r\n        bar = bar.format(pct=pct)\r\n        content += bar\r\n    content += '<div class=\"counter\"><\/div>'\r\n    attr = {\r\n    \t'class': 'countdownbox',\r\n    \t'data-datetime': end,\r\n    \t'data-granularity': granularity\r\n    }\r\n    if id:\r\n        attr['id'] = id\r\n    return html.tag('div', content, attr)","reference":"Create a countdown.","result":"Create a countdown.","score":[0.8409,0.9815]}
{"code":"def cleanup(controller, engines):\r\n    \"\"\" function to<extra_id_0>\r\n    import signal, time\r\n        print('Starting cleanup')\r\n    print('Stopping engines...')\r\n    for e in engines:\r\n        e.send_signal(signal.SIGINT)\r\n    print('Stopping controller...')\r\n    controller.send_signal(signal.SIGINT)\r\n    time.sleep(0.1)\r\n    print('Killing controller...')\r\n    controller.kill()\r\n    print('Cleanup done')","reference":"Cleanup routine to shut down all subprocesses we opened.","result":"Cleanup the application .","score":[0.0915,0.0588]}
{"code":"def pre_call(self, ctxt, pre_mod, post_mod, action):\r\n        \"\"\" function to<extra_id_0>\r\n        if not self.condition(ctxt):\r\n            return steps.StepResult(state=steps.SKIPPED)\r\n        return None","reference":"A modifier hook function.  This is called in priority order prior\n        to invoking the ``Action`` for the step.  This allows a\n        modifier to alter the context, or to take over subsequent\n        action invocation.\n\n        :param ctxt: The context object.\n        :param pre_mod: A list of the modifiers preceding this\n                        modifier in the list of modifiers that is\n                        applicable to the action.  This list is in\n                        priority order.\n        :param post_mod: A list of the modifiers following this\n                         modifier in the list of modifiers that is\n                         applicable to the action.  This list is in\n                         priority order.\n        :param action: The action that will be performed.\n\n        :returns: A ``None`` return value indicates that the modifier\n                  is taking no action.  A non-``None`` return value\n                  should consist of a ``StepResult`` object; this will\n                  suspend further ``pre_call()`` processing and\n                  proceed to the ``post_call()`` processing.  This\n                  implementation returns a ``StepResult`` with state\n                  ``SKIPPED`` if the condition does not evaluate to\n                  ``True``.","result":" is performed .","score":[1.534e-22,0.0037]}
{"code":"def post_call(self, ctxt, result, action, post_mod, pre_mod):\r\n        \"\"\" function to<extra_id_0>\r\n        result.ignore = self.config\r\n        return result","reference":"A modifier hook function.  This is called in reverse-priority\n        order after invoking the ``Action`` for the step.  This allows\n        a modifier to inspect or alter the result of the step.\n\n        :param ctxt: The context object.\n        :param result: The result of the action.  This will be a\n                       ``StepResult`` object.\n        :param action: The action that was performed.\n        :param post_mod: A list of modifiers following this modifier\n                         in the list of modifiers that is applicable\n                         to the action.  This list is in priority\n                         order.\n        :param pre_mod: A list of modifiers preceding this modifier in\n                        the list of modifiers that is applicable to\n                        the action.  This list is in priority order.\n\n        :returns: The result for the action, optionally modified.  If\n                  the result is not modified, ``result`` must be\n                  returned unchanged.  This implementation alters the\n                  ``ignore`` property of the ``result`` object to\n                  match the configured value.","result":"Call after call .","score":[4.264e-16,0.0079]}
{"code":"def save_ids(f, self, *args, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    n_previous = len(self.client.history)\r\n    try:\r\n        ret = f(self, *args, **kwargs)\r\n    finally:\r\n        nmsgs = len(self.client.history) - n_previous\r\n        msg_ids = self.client.history[-nmsgs:]\r\n        self.history.extend(msg_ids)\r\n        map(self.outstanding.add, msg_ids)\r\n    return ret","reference":"Keep our history and outstanding attributes up to date after a method call.","result":"Def save ids .","score":[0,0.0413]}
{"code":"def sync_results(f, self, *args, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    ret = f(self, *args, **kwargs)\r\n    delta = self.outstanding.difference(self.client.outstanding)\r\n    completed = self.outstanding.intersection(delta)\r\n    self.outstanding = self.outstanding.difference(completed)\r\n    return ret","reference":"sync relevant results from self.client to our results attribute.","result":"Def sync results .","score":[0.1088,0.1176]}
{"code":"def spin_after(f, self, *args, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    ret = f(self, *args, **kwargs)\r\n    self.spin()\r\n    return ret","reference":"call spin after the method.","result":"Def spin after a function .","score":[0.273,0.3676]}
{"code":"def get_msgs(self):\r\n        \"\"\" function to<extra_id_0>\r\n        msgs = []\r\n        while True:\r\n            try:\r\n                msgs.append(self.get_msg(block=False))\r\n            except Empty:\r\n                break\r\n        return msgs","reference":"Get all messages that are currently ready.","result":"Get all messages .","score":[0.3108,0.4395]}
{"code":"def get_msg(self, block=True, timeout=None):\r\n        \"\"\" function to<extra_id_0>\r\n        \"Gets a message if there is one that is ready.\"\r\n        return self._in_queue.get(block, timeout)","reference":"Gets a message if there is one that is ready.","result":"Get a message .","score":[0.1008,0.3132]}
{"code":"def prop(func=None, *,\r\n         \"\"\" function to<extra_id_0>\r\n         field = _UNSET,\r\n         get: bool = True, set: bool = True, del_: bool = False,\r\n         default = _UNSET,\r\n         types: tuple = _UNSET):\r\n    '''\r\n    `prop` is a sugar for `property`.\r\n    ``` py\r\n    @prop\r\n    def value(self):\r\n        pass\r\n    @property\r\n    def value(self):\r\n        return self._value\r\n    @value.setter\r\n    def value(self, val):\r\n        self._value = val\r\n    ```\r\n    '''\r\n    def wrap(func):\r\n        if not callable(func):\r\n            raise TypeError\r\n        prop_name = func.__name__\r\n        key = field\r\n        if key is _UNSET:\r\n            key = '_' + prop_name\r\n        fget, fset, fdel = None, None, None\r\n        if get:\r\n            def fget(self):\r\n                try:\r\n                    return self.__dict__[key]\r\n                except KeyError:\r\n                    if default is not _UNSET:\r\n                        return default\r\n                    raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{key}'\")\r\n        if set:\r\n            def fset(self, val):\r\n                if types is not _UNSET and not isinstance(val, types):\r\n                    if isinstance(types, tuple):\r\n                        types_name = tuple(x.__name__ for x in types)\r\n                    else:\r\n                        types_name = types.__name__\r\n                    raise TypeError(f'type of {type(self).__name__}.{prop_name} must be {types_name}; '\r\n                                    f'got {type(val).__name__} instead')\r\n                self.__dict__[key] = val\r\n        if del_:\r\n            def fdel(self):\r\n                del self.__dict__[key]\r\n        return property(fget, fset, fdel, func.__doc__)\r\n    return wrap(func) if func else wrap","reference":"`prop` is a sugar for `property`.\n\n    ``` py\n    @prop\n    def value(self):\n        pass\n\n    # equals:\n\n    @property\n    def value(self):\n        return self._value\n\n    @value.setter\n    def value(self, val):\n        self._value = val\n    ```","result":"Def define a property .","score":[0.003,0.0403]}
{"code":"def get_onlys(*fields):\r\n    \"\"\" function to<extra_id_0>\r\n    '''\r\n    `get_onlys` is a sugar for multi-`property`.\r\n    ``` py\r\n    name, age = get_onlys('_name', '_age')\r\n    @property\r\n    def name(self):\r\n        return getattr(self, '_name')\r\n    @property\r\n    def age(self):\r\n        return getattr(self, '_age')\r\n    ```\r\n    '''\r\n    return tuple(property(lambda self, f=f: getattr(self, f)) for f in fields)","reference":"`get_onlys` is a sugar for multi-`property`.\n\n    ``` py\n    name, age = get_onlys('_name', '_age')\n\n    # equals:\n\n    @property\n    def name(self):\n        return getattr(self, '_name')\n\n    @property\n    def age(self):\n        return getattr(self, '_age')\n    ```","result":"Get onlys of a set of fields .","score":[0.0114,0.0192]}
{"code":"def parse(url):\r\n    \"\"\" function to<extra_id_0>\r\n    config = {}\r\n    if not isinstance(url, six.string_types):\r\n        url = ''\r\n    url = urlparse.urlparse(url)\r\n    path = url.path[1:]\r\n    path = path.split('?', 2)[0]\r\n    config.update({\r\n        'NAME': path,\r\n        'USER': url.username,\r\n        'PASSWORD': url.password,\r\n        'HOST': url.hostname,\r\n        'PORT': url.port,\r\n    })\r\n    if url.scheme in SCHEMES:\r\n        config['ENGINE'] = SCHEMES[url.scheme]\r\n    return config","reference":"Parses a database URL.","result":"Parse a url into a config dict .","score":[0.1389,0.2273]}
{"code":"def module_list(path):\r\n    \"\"\" function to<extra_id_0>\r\n    if path == '':\r\n        path = '.'\r\n    if os.path.isdir(path):\r\n        folder_list = os.listdir(path)\r\n    elif path.endswith('.egg'):\r\n        try:\r\n            folder_list = [f for f in zipimporter(path)._files]\r\n        except:\r\n            folder_list = []\r\n    else:\r\n        folder_list = []\r\n    if not folder_list:\r\n        return []\r\n    isfile = os.path.isfile\r\n    pjoin = os.path.join\r\n    basename = os.path.basename\r\n    def is_importable_file(path):\r\n        name, extension = os.path.splitext( path )\r\n        return import_re.match(path) and py3compat.isidentifier(name)\r\n    folder_list = [p for p in folder_list\r\n                   if isfile(pjoin(path, p,'__init__.py'))\r\n                   or is_importable_file(p) ]\r\n    return [basename(p).split('.')[0] for p in folder_list]","reference":"Return the list containing the names of the modules available in the given\n    folder.","result":"Return a list of module names .","score":[0.084,0.188]}
{"code":"def get_root_modules():\r\n    \"\"\" function to<extra_id_0>\r\n    ip = get_ipython()\r\n    if 'rootmodules' in ip.db:\r\n        return ip.db['rootmodules']\r\n    t = time()\r\n    store = False\r\n    modules = list(sys.builtin_module_names)\r\n    for path in sys.path:\r\n        modules += module_list(path)\r\n        if time() - t >= TIMEOUT_STORAGE and not store:\r\n            store = True\r\n            print(\"\\nCaching the list of root modules, please wait!\")\r\n            print(\"(This will only be done once - type '%rehashx' to \"\r\n                  \"reset cache!)\\n\")\r\n            sys.stdout.flush()\r\n        if time() - t > TIMEOUT_GIVEUP:\r\n            print(\"This is taking too long, we give up.\\n\")\r\n            ip.db['rootmodules'] = []\r\n            return []\r\n    modules = set(modules)\r\n    if '__init__' in modules:\r\n        modules.remove('__init__')\r\n    modules = list(modules)\r\n    if store:\r\n        ip.db['rootmodules'] = modules\r\n    return modules","reference":"Returns a list containing the names of all the modules available in the\n    folders of the pythonpath.","result":"Get the list of root modules .","score":[0.0547,0.125]}
{"code":"def quick_completer(cmd, completions):\r\n    \"\"\" function to<extra_id_0>\r\n    if isinstance(completions, basestring):\r\n        completions = completions.split()\r\n    def do_complete(self, event):\r\n        return completions\r\n    get_ipython().set_hook('complete_command',do_complete, str_key = cmd)","reference":"Easily create a trivial completer for a command.\n\n    Takes either a list of completions, or all completions in string (that will\n    be split on whitespace).\n\n    Example::\n\n        [d:\\ipython]|1> import ipy_completers\n        [d:\\ipython]|2> ipy_completers.quick_completer('foo', ['bar','baz'])\n        [d:\\ipython]|3> foo b<TAB>\n        bar baz\n        [d:\\ipython]|3> foo ba","result":"Set the completion hook .","score":[0,0.0137]}
{"code":"def module_completion(line):\r\n    \"\"\" function to<extra_id_0>\r\n    words = line.split(' ')\r\n    nwords = len(words)\r\n    if nwords == 3 and words[0] == 'from':\r\n        return ['import ']\r\n    if nwords < 3 and (words[0] in ['import','from']) :\r\n        if nwords == 1:\r\n            return get_root_modules()\r\n        mod = words[1].split('.')\r\n        if len(mod) < 2:\r\n            return get_root_modules()\r\n        completion_list = try_import('.'.join(mod[:-1]), True)\r\n        return ['.'.join(mod[:-1] + [el]) for el in completion_list]\r\n    if nwords >= 3 and words[0] == 'from':\r\n        mod = words[1]\r\n        return try_import(mod)","reference":"Returns a list containing the completion possibilities for an import line.\n\n    The line looks like this :\n    'import xml.d'\n    'from xml.dom import'","result":"Get module completion list .","score":[0.0095,0.0493]}
{"code":"def magic_run_completer(self, event):\r\n    \"\"\" function to<extra_id_0>\r\n    comps = arg_split(event.line, strict=False)\r\n    relpath = (len(comps) > 1 and comps[-1] or '').strip(\"'\\\"\")\r\nglob\r\n    isdir = os.path.isdir\r\n    relpath, tilde_expand, tilde_val = expand_user(relpath)\r\n    dirs = [f.replace('\\\\','\/') + \"\/\" for f in lglob(relpath+'*') if isdir(f)]\r\n    if filter(magic_run_re.match, comps):\r\n        pys =  [f.replace('\\\\','\/') for f in lglob('*')]\r\n    else:\r\n        pys =  [f.replace('\\\\','\/')\r\n                for f in lglob(relpath+'*.py') + lglob(relpath+'*.ipy') +\r\n                lglob(relpath + '*.pyw')]\r\neturn [compress_user(p, tilde_expand, tilde_val) for p in dirs+pys]","reference":"Complete files that end in .py or .ipy for the %run command.","result":"Get the completion for magic runs .","score":[0.094,0.1304]}
{"code":"def cd_completer(self, event):\r\n    \"\"\" function to<extra_id_0>\r\n    ip = get_ipython()\r\n    relpath = event.symbol\r\nf event.line.endswith('-b') or ' -b ' in event.line:\r\n        bkms = self.db.get('bookmarks', None)\r\n        if bkms:\r\n            return bkms.keys()\r\n        else:\r\n            return []\r\n    if event.symbol == '-':\r\n        width_dh = str(len(str(len(ip.user_ns['_dh']) + 1)))\r\n        fmt = '-%0' + width_dh +'d [%s]'\r\n        ents = [ fmt % (i,s) for i,s in enumerate(ip.user_ns['_dh'])]\r\n        if len(ents) > 1:\r\n            return ents\r\n        return []\r\n    if event.symbol.startswith('--'):\r\n        return [\"--\" + os.path.basename(d) for d in ip.user_ns['_dh']]\r\n    relpath, tilde_expand, tilde_val = expand_user(relpath)\r\n    relpath = relpath.replace('\\\\','\/')\r\n    found = []\r\n    for d in [f.replace('\\\\','\/') + '\/' for f in glob.glob(relpath+'*')\r\n              if os.path.isdir(f)]:\r\n        if ' ' in d:\r\n            raise TryNext\r\n        found.append(d)\r\n    if not found:\r\n        if os.path.isdir(relpath):\r\n            return [compress_user(relpath, tilde_expand, tilde_val)]\r\n        bks = self.db.get('bookmarks',{}).iterkeys()\r\n        bkmatches = [s for s in bks if s.startswith(event.symbol)]\r\n        if bkmatches:\r\n            return bkmatches\r\n        raise TryNext\r\n    return [compress_user(p, tilde_expand, tilde_val) for p in found]","reference":"Completer function for cd, which only returns directories.","result":"S directory completer .","score":[0,0.0658]}
{"code":"def _quoteattr(self, attr):\r\n        \"\"\" function to<extra_id_0>\r\n        attr = xml_safe(attr)\r\n        if isinstance(attr, unicode) and not UNICODE_STRINGS:\r\n            attr = attr.encode(self.encoding)\r\n        return saxutils.quoteattr(attr)","reference":"Escape an XML attribute. Value can be unicode.","result":"Def quote attributes .","score":[0,0.0]}
{"code":"def configure(self, options, config):\r\n        \"\"\" function to<extra_id_0>\r\n        Plugin.configure(self, options, config)\r\n        self.config = config\r\n        if self.enabled:\r\n            self.stats = {'errors': 0,\r\n                          'failures': 0,\r\n                          'passes': 0,\r\n                          'skipped': 0\r\n                          }\r\n            self.errorlist = []\r\n            self.error_report_file = codecs.open(options.xunit_file, 'w',\r\n                                                 self.encoding, 'replace')","reference":"Configures the xunit plugin.","result":"If not self.","score":[0,0.0]}
{"code":"def report(self, stream):\r\n        \"\"\" function to<extra_id_0>\r\n        self.stats['encoding'] = self.encoding\r\n        self.stats['total'] = (self.stats['errors'] + self.stats['failures']\r\n                               + self.stats['passes'] + self.stats['skipped'])\r\n        self.error_report_file.write(\r\n            u'<?xml version=\"1.0\" encoding=\"%(encoding)s\"?>'\r\n            u'<testsuite name=\"nosetests\" tests=\"%(total)d\" '\r\n            u'errors=\"%(errors)d\" failures=\"%(failures)d\" '\r\n            u'skip=\"%(skipped)d\">' % self.stats)\r\n        self.error_report_file.write(u''.join([self._forceUnicode(e)\r\n                                               for e in self.errorlist]))\r\n        self.error_report_file.write(u'<\/testsuite>')\r\n        self.error_report_file.close()\r\n        if self.config.verbosity > 1:\r\n            stream.writeln(\"-\" * 70)\r\n            stream.writeln(\"XML: %s\" % self.error_report_file.name)","reference":"Writes an Xunit-formatted XML file\n\n        The file includes a report of test errors and failures.","result":"Write the error report to the stream .","score":[0.0579,0.1399]}
{"code":"def addError(self, test, err, capt=None):\r\n        \"\"\" function to<extra_id_0>\r\n        taken = self._timeTaken()\r\n        if issubclass(err[0], SkipTest):\r\n            type = 'skipped'\r\n            self.stats['skipped'] += 1\r\n        else:\r\n            type = 'error'\r\n            self.stats['errors'] += 1\r\n        tb = ''.join(traceback.format_exception(*err))\r\n        id = test.id()\r\n        self.errorlist.append(\r\n            '<testcase classname=%(cls)s name=%(name)s time=\"%(taken).3f\">'\r\n            '<%(type)s type=%(errtype)s message=%(message)s><![CDATA[%(tb)s]]>'\r\n            '<\/%(type)s><\/testcase>' %\r\n            {'cls': self._quoteattr(id_split(id)[0]),\r\n             'name': self._quoteattr(id_split(id)[-1]),\r\n             'taken': taken,\r\n             'type': type,\r\n             'errtype': self._quoteattr(nice_classname(err[0])),\r\n             'message': self._quoteattr(exc_message(err)),\r\n             'tb': escape_cdata(tb),\r\n             })","reference":"Add error output to Xunit report.","result":"Add an error to the report .","score":[0.2125,0.2459]}
{"code":"def addFailure(self, test, err, capt=None, tb_info=None):\r\n        \"\"\" function to<extra_id_0>\r\n        taken = self._timeTaken()\r\n        tb = ''.join(traceback.format_exception(*err))\r\n        self.stats['failures'] += 1\r\n        id = test.id()\r\n        self.errorlist.append(\r\n            '<testcase classname=%(cls)s name=%(name)s time=\"%(taken).3f\">'\r\n            '<failure type=%(errtype)s message=%(message)s><![CDATA[%(tb)s]]>'\r\n            '<\/failure><\/testcase>' %\r\n            {'cls': self._quoteattr(id_split(id)[0]),\r\n             'name': self._quoteattr(id_split(id)[-1]),\r\n             'taken': taken,\r\n             'errtype': self._quoteattr(nice_classname(err[0])),\r\n             'message': self._quoteattr(exc_message(err)),\r\n             'tb': escape_cdata(tb),\r\n             })","reference":"Add failure output to Xunit report.","result":"Add a failure to the report .","score":[0.2125,0.2459]}
{"code":"def addSuccess(self, test, capt=None):\r\n        \"\"\" function to<extra_id_0>\r\n        taken = self._timeTaken()\r\n        self.stats['passes'] += 1\r\n        id = test.id()\r\n        self.errorlist.append(\r\n            '<testcase classname=%(cls)s name=%(name)s '\r\n            'time=\"%(taken).3f\" \/>' %\r\n            {'cls': self._quoteattr(id_split(id)[0]),\r\n             'name': self._quoteattr(id_split(id)[-1]),\r\n             'taken': taken,\r\n             })","reference":"Add success output to Xunit report.","result":"Add a test success .","score":[0.2339,0.1695]}
{"code":"def twobin(loads):\r\n    \"\"\" function to<extra_id_0>\r\n    n = len(loads)\r\n    a = randint(0,n-1)\r\n    b = randint(0,n-1)\r\n    return min(a,b)","reference":"Pick two at random, use the LRU of the two.\n\n    The content of loads is ignored.\n\n    Assumes LRU ordering of loads, with oldest first.","result":"If not return random value .","score":[0,0.0]}
{"code":"def weighted(loads):\r\n    \"\"\" function to<extra_id_0>\r\n    weights = 1.\/(1e-6+numpy.array(loads))\r\n    sums = weights.cumsum()\r\n    t = sums[-1]\r\n    x = random()*t\r\n    y = random()*t\r\n    idx = 0\r\n    idy = 0\r\n    while sums[idx] < x:\r\n        idx += 1\r\n    while sums[idy] < y:\r\n        idy += 1\r\n    if weights[idy] > weights[idx]:\r\n        return idy\r\n    else:\r\n        return idx","reference":"Pick two at random using inverse load as weight.\n\n    Return the less loaded of the two.","result":"Generate a random load set .","score":[0.0434,0.0667]}
{"code":"def _register_engine(self, uid):\r\n        \"\"\" function to<extra_id_0>\r\n        self.targets.insert(0,uid)\r\n        self.loads.insert(0,0)\r\n        self.completed[uid] = set()\r\n        self.failed[uid] = set()\r\n        self.pending[uid] = {}\r\n        self.update_graph(None)","reference":"New engine with ident `uid` became available.","result":"Register an engine .","score":[0.1509,0.0746]}
{"code":"def _unregister_engine(self, uid):\r\n        \"\"\" function to<extra_id_0>\r\n        if len(self.targets) == 1:\r\n            pass\r\n        self.engine_stream.flush()\r\n        idx = self.targets.index(uid)\r\n        self.targets.pop(idx)\r\n        self.loads.pop(idx)\r\n        if self.pending[uid]:\r\n            dc = ioloop.DelayedCallback(lambda : self.handle_stranded_tasks(uid), 5000, self.loop)\r\n            dc.start()\r\n        else:\r\n            self.completed.pop(uid)\r\n            self.failed.pop(uid)","reference":"Existing engine with ident `uid` became unavailable.","result":"If uid not in self.","score":[0,0.0]}
{"code":"def handle_stranded_tasks(self, engine):\r\n        \"\"\" function to<extra_id_0>\r\n        lost = self.pending[engine]\r\n        for msg_id in lost.keys():\r\n            if msg_id not in self.pending[engine]:\r\n                continue\r\n            raw_msg = lost[msg_id].raw_msg\r\n            idents,msg = self.session.feed_identities(raw_msg, copy=False)\r\n            parent = self.session.unpack(msg[1].bytes)\r\n            idents = [engine, idents[0]]\r\n            try:\r\n                raise error.EngineError(\"Engine %r died while running task %r\"%(engine, msg_id))\r\n            except:\r\n                content = error.wrap_exception()\r\n            header = dict(\r\n                status='error',\r\n                engine=engine,\r\n                date=datetime.now(),\r\n            )\r\n            msg = self.session.msg('apply_reply', content, parent=parent, subheader=header)\r\n            raw_reply = map(zmq.Message, self.session.serialize(msg, ident=idents))\r\n            self.dispatch_result(raw_reply)\r\n        self.completed.pop(engine)\r\n        self.failed.pop(engine)","reference":"Deal with jobs resident in an engine that died.","result":"Handle stranded tasks .","score":[0,0.0588]}
{"code":"def dispatch_submission(self, raw_msg):\r\n        \"\"\" function to<extra_id_0>\r\n        self.notifier_stream.flush()\r\n        try:\r\n            idents, msg = self.session.feed_identities(raw_msg, copy=False)\r\n            msg = self.session.unserialize(msg, content=False, copy=False)\r\n        except Exception:\r\n            self.log.error(\"task::Invaid task msg: %r\"%raw_msg, exc_info=True)\r\n            return\r\n        self.mon_stream.send_multipart([b'intask']+raw_msg, copy=False)\r\n        header = msg['header']\r\n        msg_id = header['msg_id']\r\n        self.all_ids.add(msg_id)\r\n        targets = header.get('targets', [])\r\n        targets = map(cast_bytes, targets)\r\n        targets = set(targets)\r\n        retries = header.get('retries', 0)\r\n        self.retries[msg_id] = retries\r\n        after = header.get('after', None)\r\n        if after:\r\n            after = Dependency(after)\r\n            if after.all:\r\n                if after.success:\r\n                    after = Dependency(after.difference(self.all_completed),\r\n                                success=after.success,\r\n                                failure=after.failure,\r\n                                all=after.all,\r\n                    )\r\n                if after.failure:\r\n                    after = Dependency(after.difference(self.all_failed),\r\n                                success=after.success,\r\n                                failure=after.failure,\r\n                                all=after.all,\r\n                    )\r\n            if after.check(self.all_completed, self.all_failed):\r\n                after = MET\r\n        else:\r\n            after = MET\r\n        follow = Dependency(header.get('follow', []))\r\n        timeout = header.get('timeout', None)\r\n        if timeout:\r\n            timeout = datetime.now() + timedelta(0,float(timeout),0)\r\n        job = Job(msg_id=msg_id, raw_msg=raw_msg, idents=idents, msg=msg,\r\n                 header=header, targets=targets, after=after, follow=follow,\r\n                 timeout=timeout,\r\n        )\r\n        for dep in after,follow:\r\n            if not dep:\r\n                continue\r\n            if msg_id in dep or dep.difference(self.all_ids):\r\n                self.depending[msg_id] = job\r\n                return self.fail_unreachable(msg_id, error.InvalidDependency)\r\n            if dep.unreachable(self.all_completed, self.all_failed):\r\n                self.depending[msg_id] = job\r\n                return self.fail_unreachable(msg_id)\r\n        if after.check(self.all_completed, self.all_failed):\r\n            if not self.maybe_run(job):\r\n                if msg_id not in self.all_failed:\r\n                    self.save_unmet(job)\r\n        else:\r\n            self.save_unmet(job)","reference":"Dispatch job submission to appropriate handlers.","result":"Def dispatch a submission .","score":[0.1967,0.1695]}
{"code":"def audit_timeouts(self):\r\n        \"\"\" function to<extra_id_0>\r\n        now = datetime.now()\r\n        for msg_id in self.depending.keys():\r\n            if msg_id in self.depending:\r\n                job = self.depending[msg_id]\r\n                if job.timeout and job.timeout < now:\r\n                    self.fail_unreachable(msg_id, error.TaskTimeout)","reference":"Audit all waiting tasks for expired timeouts.","result":"Audit timeouts .","score":[0.1076,0.0758]}
{"code":"def fail_unreachable(self, msg_id, why=error.ImpossibleDependency):\r\n        \"\"\" function to<extra_id_0>\r\n        if msg_id not in self.depending:\r\n            self.log.error(\"msg %r already failed!\", msg_id)\r\n            return\r\n        job = self.depending.pop(msg_id)\r\n        for mid in job.dependents:\r\n            if mid in self.graph:\r\n                self.graph[mid].remove(msg_id)\r\n        try:\r\n            raise why()\r\n        except:\r\n            content = error.wrap_exception()\r\n        self.all_done.add(msg_id)\r\n        self.all_failed.add(msg_id)\r\n        msg = self.session.send(self.client_stream, 'apply_reply', content,\r\n                                                parent=job.header, ident=job.idents)\r\n        self.session.send(self.mon_stream, msg, ident=[b'outtask']+job.idents)\r\n        self.update_graph(msg_id, success=False)","reference":"a task has become unreachable, send a reply with an ImpossibleDependency\n        error.","result":"Fail unreachable dependencies .","score":[0,0.0]}
{"code":"def maybe_run(self, job):\r\n        \"\"\" function to<extra_id_0>\r\n        msg_id = job.msg_id\r\n        self.log.debug(\"Attempting to assign task %s\", msg_id)\r\n        if not self.targets:\r\n            return False\r\n                if job.follow or job.targets or job.blacklist or self.hwm:\r\n            def can_run(idx):\r\n                if self.hwm and self.loads[idx] == self.hwm:\r\n                    return False\r\n                target = self.targets[idx]\r\n                if target in job.blacklist:\r\n                    return False\r\n                if job.targets and target not in job.targets:\r\n                    return False\r\n                return job.follow.check(self.completed[target], self.failed[target])\r\n            indices = filter(can_run, range(len(self.targets)))\r\n            if not indices:\r\n                if job.follow.all:\r\n                    dests = set()\r\n                    relevant = set()\r\n                    if job.follow.success:\r\n                        relevant = self.all_completed\r\n                    if job.follow.failure:\r\n                        relevant = relevant.union(self.all_failed)\r\n                    for m in job.follow.intersection(relevant):\r\n                        dests.add(self.destinations[m])\r\n                    if len(dests) > 1:\r\n                        self.depending[msg_id] = job\r\n                        self.fail_unreachable(msg_id)\r\n                        return False\r\n                if job.targets:\r\n                    job.targets.difference_update(job.blacklist)\r\n                    if not job.targets or not job.targets.intersection(self.targets):\r\n                        self.depending[msg_id] = job\r\n                        self.fail_unreachable(msg_id)\r\n                        return False\r\n                return False\r\n        else:\r\n            indices = None\r\n        self.submit_task(job, indices)\r\n        return True","reference":"check location dependencies, and run if they are met.","result":"Run a job .","score":[0,0.0588]}
{"code":"def save_unmet(self, job):\r\n        \"\"\" function to<extra_id_0>\r\n        msg_id = job.msg_id\r\n        self.depending[msg_id] = job\r\n        for dep_id in job.after.union(job.follow).difference(self.all_done):\r\n            if dep_id not in self.graph:\r\n                self.graph[dep_id] = set()\r\n            self.graph[dep_id].add(msg_id)","reference":"Save a message for later submission when its dependencies are met.","result":"Save unmet jobs .","score":[0.0555,0.0485]}
{"code":"def submit_task(self, job, indices=None):\r\n        \"\"\" function to<extra_id_0>\r\n        if indices:\r\n            loads = [self.loads[i] for i in indices]\r\n        else:\r\n            loads = self.loads\r\n        idx = self.scheme(loads)\r\n        if indices:\r\n            idx = indices[idx]\r\n        target = self.targets[idx]\r\n        self.engine_stream.send(target, flags=zmq.SNDMORE, copy=False)\r\n        self.engine_stream.send_multipart(job.raw_msg, copy=False)\r\n        self.add_job(idx)\r\n        self.pending[target][job.msg_id] = job\r\n        content = dict(msg_id=job.msg_id, engine_id=target.decode('ascii'))\r\n        self.session.send(self.mon_stream, 'task_destination', content=content,\r\n                        ident=[b'tracktask',self.ident])","reference":"Submit a task to any of a subset of our targets.","result":"Submit a task .","score":[0.1143,0.1456]}
{"code":"def dispatch_result(self, raw_msg):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            idents,msg = self.session.feed_identities(raw_msg, copy=False)\r\n            msg = self.session.unserialize(msg, content=False, copy=False)\r\n            engine = idents[0]\r\n            try:\r\n                idx = self.targets.index(engine)\r\n            except ValueError:\r\n                pass\r\n            else:\r\n                self.finish_job(idx)\r\n        except Exception:\r\n            self.log.error(\"task::Invaid result: %r\", raw_msg, exc_info=True)\r\n            return\r\n        header = msg['header']\r\n        parent = msg['parent_header']\r\n        if header.get('dependencies_met', True):\r\n            success = (header['status'] == 'ok')\r\n            msg_id = parent['msg_id']\r\n            retries = self.retries[msg_id]\r\n            if not success and retries > 0:\r\n                self.retries[msg_id] = retries - 1\r\n                self.handle_unmet_dependency(idents, parent)\r\n            else:\r\n                del self.retries[msg_id]\r\n                self.handle_result(idents, parent, raw_msg, success)\r\n                self.mon_stream.send_multipart([b'outtask']+raw_msg, copy=False)\r\n        else:\r\n            self.handle_unmet_dependency(idents, parent)","reference":"dispatch method for result replies","result":"Handle result messages .","score":[0.2488,0.102]}
{"code":"def handle_result(self, idents, parent, raw_msg, success=True):\r\n        \"\"\" function to<extra_id_0>\r\n        engine = idents[0]\r\n        client = idents[1]\r\n        raw_msg[:2] = [client,engine]\r\n        self.client_stream.send_multipart(raw_msg, copy=False)\r\n        msg_id = parent['msg_id']\r\n        self.pending[engine].pop(msg_id)\r\n        if success:\r\n            self.completed[engine].add(msg_id)\r\n            self.all_completed.add(msg_id)\r\n        else:\r\n            self.failed[engine].add(msg_id)\r\n            self.all_failed.add(msg_id)\r\n        self.all_done.add(msg_id)\r\n        self.destinations[msg_id] = engine\r\n        self.update_graph(msg_id, success)","reference":"handle a real task result, either success or failure","result":"Handle result .","score":[0,0.0595]}
{"code":"def handle_unmet_dependency(self, idents, parent):\r\n        \"\"\" function to<extra_id_0>\r\n        engine = idents[0]\r\n        msg_id = parent['msg_id']\r\n        job = self.pending[engine].pop(msg_id)\r\n        job.blacklist.add(engine)\r\n        if job.blacklist == job.targets:\r\n            self.depending[msg_id] = job\r\n            self.fail_unreachable(msg_id)\r\n        elif not self.maybe_run(job):\r\n            if msg_id not in self.all_failed:\r\n                self.save_unmet(job)\r\n        if self.hwm:\r\n            try:\r\n                idx = self.targets.index(engine)\r\n            except ValueError:\r\n                pass\r\n            else:\r\n                if self.loads[idx] == self.hwm-1:\r\n                    self.update_graph(None)","reference":"handle an unmet dependency","result":"Handle unmet dependency .","score":[0.4518,0.6389]}
{"code":"def update_graph(self, dep_id=None, success=True):\r\n        \"\"\" function to<extra_id_0>\r\n        jobs = self.graph.pop(dep_id, [])\r\n                if dep_id is None or self.hwm and any( [ load==self.hwm-1 for load in self.loads ]):\r\n            jobs = self.depending.keys()\r\n                for msg_id in sorted(jobs, key=lambda msg_id: self.depending[msg_id].timestamp):\r\n            job = self.depending[msg_id]\r\n            if job.after.unreachable(self.all_completed, self.all_failed)\\\r\n                    or job.follow.unreachable(self.all_completed, self.all_failed):\r\n                self.fail_unreachable(msg_id)\r\n            elif job.after.check(self.all_completed, self.all_failed):\r\n                if self.maybe_run(job):\r\n                    self.depending.pop(msg_id)\r\n                    for mid in job.dependents:\r\n                        if mid in self.graph:\r\n                            self.graph[mid].remove(msg_id)","reference":"dep_id just finished. Update our dependency\n        graph and submit any jobs that just became runable.\n\n        Called with dep_id=None to update entire graph for hwm, but without finishing\n        a task.","result":"If update the graph .","score":[0.0024,0.0376]}
{"code":"def logstart(self, logfname=None, loghead=None, logmode=None,\r\n                 \"\"\" function to<extra_id_0>\r\n                 log_output=False, timestamp=False, log_raw_input=False):\r\n        if self.logfile is not None:\r\n            raise RuntimeError('Log file is already active: %s' %\r\n                               self.logfname)\r\n        if logfname is not None: self.logfname = logfname\r\n        if loghead is not None: self.loghead = loghead\r\n        if logmode is not None: self.logmode = logmode\r\n        self.timestamp = timestamp\r\n        self.log_output = log_output\r\n        self.log_raw_input = log_raw_input\r\n        isfile = os.path.isfile\r\n        logmode = self.logmode\r\n        if logmode == 'append':\r\n            self.logfile = io.open(self.logfname, 'a', encoding='utf-8')\r\n        elif logmode == 'backup':\r\n            if isfile(self.logfname):\r\n                backup_logname = self.logfname+'~'\r\n                if isfile(backup_logname):\r\n                    os.remove(backup_logname)\r\n                os.rename(self.logfname,backup_logname)\r\n            self.logfile = io.open(self.logfname, 'w', encoding='utf-8')\r\n        elif logmode == 'global':\r\n            self.logfname = os.path.join(self.home_dir,self.logfname)\r\n            self.logfile = io.open(self.logfname, 'a', encoding='utf-8')\r\n        elif logmode == 'over':\r\n            if isfile(self.logfname):\r\n                os.remove(self.logfname)\r\n            self.logfile = io.open(self.logfname,'w', encoding='utf-8')\r\n        elif logmode == 'rotate':\r\n            if isfile(self.logfname):\r\n                if isfile(self.logfname+'.001~'):\r\n                    old = glob.glob(self.logfname+'.*~')\r\n                    old.sort()\r\n                    old.reverse()\r\n                    for f in old:\r\n                        root, ext = os.path.splitext(f)\r\n                        num = int(ext[1:-1])+1\r\n                        os.rename(f, root+'.'+`num`.zfill(3)+'~')\r\n                os.rename(self.logfname, self.logfname+'.001~')\r\n            self.logfile = io.open(self.logfname, 'w', encoding='utf-8')\r\n        if logmode != 'append':\r\n            self.logfile.write(self.loghead)\r\n        self.logfile.flush()\r\n        self.log_active = True","reference":"Generate a new log-file with a default header.\n\n        Raises RuntimeError if the log has already been started","result":"Start logging .","score":[0,0.0641]}
{"code":"def logstate(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.logfile is None:\r\n            print 'Logging has not been activated.'\r\n        else:\r\n            state = self.log_active and 'active' or 'temporarily suspended'\r\n            print 'Filename       :',self.logfname\r\n            print 'Mode           :',self.logmode\r\n            print 'Output logging :',self.log_output\r\n            print 'Raw input log  :',self.log_raw_input\r\n            print 'Timestamping   :',self.timestamp\r\n            print 'State          :',state","reference":"Print a status message about the logger.","result":"Display the logging state .","score":[0.1611,0.0735]}
{"code":"def log(self, line_mod, line_ori):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.log_raw_input:\r\n            self.log_write(line_ori)\r\n        else:\r\n            self.log_write(line_mod)","reference":"Write the sources to a log.\n\n        Inputs:\n\n        - line_mod: possibly modified input, such as the transformations made\n        by input prefilters or input handlers of various kinds.  This should\n        always be valid Python.\n\n        - line_ori: unmodified input line from the user.  This is not\n        necessarily valid Python.","result":"If self.","score":[0,0.0]}
{"code":"def log_write(self, data, kind='input'):\r\n   \"\"\" function to<extra_id_0>\r\n   if self.log_active and data:\r\n            write = self.logfile.write\r\n            if kind=='input':\r\n                if self.timestamp:\r\n                    write(str_to_unicode(time.strftime('\r\n                                        time.localtime())))\r\n                write(data)\r\n            elif kind=='output' and self.log_output:\r\n                odata = u'\\n'.join([u'                           for s in data.splitlines()])\r\n                write(u'%s\\n' % odata)\r\n            self.logfile.flush()","reference":"Write data to the log file, if active","result":"Log data to the log file .","score":[0.4382,0.5024]}
{"code":"def logstop(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.logfile is not None:\r\n            self.logfile.close()\r\n            self.logfile = None\r\n        else:\r\n            print \"Logging hadn't been started.\"\r\n        self.log_active = False","reference":"Fully stop logging and close log file.\n\n        In order to start logging again, a new logstart() call needs to be\n        made, possibly (though not necessarily) with a new filename, mode and\n        other options.","result":"Stop logging .","score":[0.0,0.0333]}
{"code":"def new_worksheet(name=None, cells=None):\r\n    \"\"\" function to<extra_id_0>\r\n    ws = NotebookNode()\r\n    if name is not None:\r\n        ws.name = unicode(name)\r\n    if cells is None:\r\n        ws.cells = []\r\n    else:\r\n        ws.cells = list(cells)\r\n    return ws","reference":"Create a worksheet by name with with a list of cells.","result":"Create a new worksheet .","score":[0.1133,0.1442]}
{"code":"def add_s(self, s, obj, priority= 0 ):\r\n        \"\"\" function to<extra_id_0>\r\n        chain = self.strs.get(s, CommandChainDispatcher())\r\n        chain.add(obj,priority)\r\n        self.strs[s] = chain","reference":"Adds a target 'string' for dispatching","result":"Add a string to the command chain .","score":[0.1389,0.3024]}
{"code":"def add_re(self, regex, obj, priority= 0 ):\r\n        \"\"\" function to<extra_id_0>\r\n        chain = self.regexs.get(regex, CommandChainDispatcher())\r\n        chain.add(obj,priority)\r\n        self.regexs[regex] = chain","reference":"Adds a target regexp for dispatching","result":"Add a regular expression to the command chain .","score":[0.1219,0.2976]}
{"code":"def dispatch(self, key):\r\n        \"\"\" function to<extra_id_0>\r\n        if key in self.strs:\r\n            yield self.strs[key]\r\n        for r, obj in self.regexs.items():\r\n            if re.match(r, key):\r\n                yield obj\r\n            else:\r\n          pass","reference":"Get a seq of Commandchain objects that match key","result":"Dispatch key .","score":[0.0553,0.0595]}
{"code":"def flat_matches(self, key):\r\n        \"\"\" function to<extra_id_0>\r\n        for val in self.dispatch(key):\r\n            for el in val:\r\n                yield el[1]\r\n        return","reference":"Yield all 'value' targets, without priority","result":"Def match flat matches .","score":[0,0.0]}
{"code":"def _notebook_dir_changed(self, name, old, new):\r\n        \"\"\" function to<extra_id_0>\r\n        if os.path.exists(new) and not os.path.isdir(new):\r\n            raise TraitError(\"notebook dir %r is not a directory\" % new)\r\n        if not os.path.exists(new):\r\n            self.log.info(\"Creating notebook dir %s\", new)\r\n            try:\r\n                os.mkdir(new)\r\n            except:\r\n                raise TraitError(\"Couldn't create notebook dir %r\" % new)","reference":"do a bit of validation of the notebook dir","result":" is changed .","score":[0,0.0]}
{"code":"def list_notebooks(self):\r\n        \"\"\" function to<extra_id_0>\r\n        names = glob.glob(os.path.join(self.notebook_dir,\r\n                                       '*' + self.filename_ext))\r\n        names = [os.path.splitext(os.path.basename(name))[0]\r\n                 for name in names]\r\n        data = []\r\n        for name in names:\r\n            if name not in self.rev_mapping:\r\n                notebook_id = self.new_notebook_id(name)\r\n            else:\r\n                notebook_id = self.rev_mapping[name]\r\n            data.append(dict(notebook_id=notebook_id,name=name))\r\n        data = sorted(data, key=lambda item: item['name'])\r\n        return data","reference":"List all notebooks in the notebook dir.\n\n        This returns a list of dicts of the form::\n\n            dict(notebook_id=notebook,name=name)","result":"List all notebooks .","score":[0.0255,0.1628]}
{"code":"def new_notebook_id(self, name):\r\n                \"\"\" function to<extra_id_0>\r\n                notebook_id = unicode(uuid.uuid4())\r\n                self.mapping[notebook_id] = name\r\n        self.rev_mapping[name] = notebook_id\r\n        return notebook_id","reference":"Generate a new notebook_id for a name and store its mappings.","result":"Def generate a new notebook id .","score":[0.129,0.1415]}
{"code":"def delete_notebook_id(self, notebook_id):\r\n        \"\"\" function to<extra_id_0>\r\n        name = self.mapping[notebook_id]\r\n        del self.mapping[notebook_id]\r\n        del self.rev_mapping[name]","reference":"Delete a notebook's id only. This doesn't delete the actual notebook.","result":"Delete notebook id .","score":[0.066,0.0971]}
{"code":"def notebook_exists(self, notebook_id):\r\n        \"\"\" function to<extra_id_0>\r\n        if notebook_id not in self.mapping:\r\n            return False\r\n        path = self.get_path_by_name(self.mapping[notebook_id])\r\n        return os.path.isfile(path)","reference":"Does a notebook exist?","result":"Check if notebook exists .","score":[0.2403,0.122]}
{"code":"def find_path(self, notebook_id):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            name = self.mapping[notebook_id]\r\n        except KeyError:\r\n            raise web.HTTPError(404, u'Notebook does not exist: %s' % notebook_id)\r\n        return self.get_path_by_name(name)","reference":"Return a full path to a notebook given its notebook_id.","result":"Def find notebook path .","score":[0.1051,0.1053]}
{"code":"def get_path_by_name(self, name):\r\n        \"\"\" function to<extra_id_0>\r\n        filename = name + self.filename_ext\r\n        path = os.path.join(self.notebook_dir, filename)\r\n        return path","reference":"Return a full path to a notebook given its name.","result":"Get path by name .","score":[0.0884,0.0526]}
{"code":"def get_notebook(self, notebook_id, format=u'json'):\r\n        \"\"\" function to<extra_id_0>\r\n        format = unicode(format)\r\n        if format not in self.allowed_formats:\r\n            raise web.HTTPError(415, u'Invalid notebook format: %s' % format)\r\n        last_modified, nb = self.get_notebook_object(notebook_id)\r\n        kwargs = {}\r\n        if format == 'json':\r\n            kwargs['split_lines'] = False\r\n        data = current.writes(nb, format, **kwargs)\r\n        name = nb.metadata.get('name','notebook')\r\n        return last_modified, name, data","reference":"Get the representation of a notebook in format by notebook_id.","result":"Get a notebook .","score":[0.1116,0.2719]}
{"code":"def get_notebook_object(self, notebook_id):\r\n        \"\"\" function to<extra_id_0>\r\n        path = self.find_path(notebook_id)\r\n        if not os.path.isfile(path):\r\n            raise web.HTTPError(404, u'Notebook does not exist: %s' % notebook_id)\r\n        info = os.stat(path)\r\n        last_modified = datetime.datetime.utcfromtimestamp(info.st_mtime)\r\n        with open(path,'r') as f:\r\n            s = f.read()\r\n            try:\r\n                nb = current.reads(s, u'json')\r\n            except:\r\n                raise web.HTTPError(500, u'Unreadable JSON notebook.')\r\n        nb.metadata.name = os.path.splitext(os.path.basename(path))[0]\r\n        return last_modified, nb","reference":"Get the NotebookNode representation of a notebook by notebook_id.","result":"Get notebook object .","score":[0.1088,0.1176]}
{"code":"def save_new_notebook(self, data, name=None, format=u'json'):\r\n        \"\"\" function to<extra_id_0>\r\n        if format not in self.allowed_formats:\r\n            raise web.HTTPError(415, u'Invalid notebook format: %s' % format)\r\n        try:\r\n            nb = current.reads(data.decode('utf-8'), format)\r\n        except:\r\n            raise web.HTTPError(400, u'Invalid JSON data')\r\n        if name is None:\r\n            try:\r\n                name = nb.metadata.name\r\n            except AttributeError:\r\n                raise web.HTTPError(400, u'Missing notebook name')\r\n        nb.metadata.name = name\r\n        notebook_id = self.new_notebook_id(name)\r\n        self.save_notebook_object(notebook_id, nb)\r\n        return notebook_id","reference":"Save a new notebook and return its notebook_id.\n\n        If a name is passed in, it overrides any values in the notebook data\n        and the value in the data is updated to use that value.","result":"Save a new notebook .","score":[0.0023,0.0643]}
{"code":"def save_notebook(self, notebook_id, data, name=None, format=u'json'):\r\n        \"\"\" function to<extra_id_0>\r\n        if format not in self.allowed_formats:\r\n            raise web.HTTPError(415, u'Invalid notebook format: %s' % format)\r\n        try:\r\n            nb = current.reads(data.decode('utf-8'), format)\r\n        except:\r\n            raise web.HTTPError(400, u'Invalid JSON data')\r\n        if name is not None:\r\n            nb.metadata.name = name\r\n        self.save_notebook_object(notebook_id, nb)","reference":"Save an existing notebook by notebook_id.","result":"Save notebook .","score":[0.1786,0.1754]}
{"code":"def save_notebook_object(self, notebook_id, nb):\r\n        \"\"\" function to<extra_id_0>\r\n        if notebook_id not in self.mapping:\r\n            raise web.HTTPError(404, u'Notebook does not exist: %s' % notebook_id)\r\n        old_name = self.mapping[notebook_id]\r\n        try:\r\n            new_name = nb.metadata.name\r\n        except AttributeError:\r\n            raise web.HTTPError(400, u'Missing notebook name')\r\n        path = self.get_path_by_name(new_name)\r\n        try:\r\n            with open(path,'w') as f:\r\n                current.write(nb, f, u'json')\r\n        except Exception as e:\r\n            raise web.HTTPError(400, u'Unexpected error while saving notebook: %s' % e)\r\n        if self.save_script:\r\n            pypath = os.path.splitext(path)[0] + '.py'\r\n            try:\r\n                with io.open(pypath,'w', encoding='utf-8') as f:\r\n                    current.write(nb, f, u'py')\r\n            except Exception as e:\r\n                raise web.HTTPError(400, u'Unexpected error while saving notebook as script: %s' % e)\r\n                if old_name != new_name:\r\n            old_path = self.get_path_by_name(old_name)\r\n            if os.path.isfile(old_path):\r\n                os.unlink(old_path)\r\n            if self.save_script:\r\n                old_pypath = os.path.splitext(old_path)[0] + '.py'\r\n                if os.path.isfile(old_pypath):\r\n                    os.unlink(old_pypath)\r\n            self.mapping[notebook_id] = new_name\r\n            self.rev_mapping[new_name] = notebook_id\r\n            del self.rev_mapping[old_name]","reference":"Save an existing notebook object by notebook_id.","result":"Save notebook object .","score":[0.2362,0.3814]}
{"code":"def delete_notebook(self, notebook_id):\r\n        \"\"\" function to<extra_id_0>\r\n        path = self.find_path(notebook_id)\r\n        if not os.path.isfile(path):\r\n            raise web.HTTPError(404, u'Notebook does not exist: %s' % notebook_id)\r\n        os.unlink(path)\r\n        self.delete_notebook_id(notebook_id)","reference":"Delete notebook by notebook_id.","result":"Delete notebook .","score":[0.4137,0.4808]}
{"code":"def new_notebook(self):\r\n        \"\"\" function to<extra_id_0>\r\n        path, name = self.increment_filename('Untitled')\r\n        notebook_id = self.new_notebook_id(name)\r\n        metadata = current.new_metadata(name=name)\r\n        nb = current.new_notebook(metadata=metadata)\r\n        with open(path,'w') as f:\r\n            current.write(nb, f, u'json')\r\n        return notebook_id","reference":"Create a new notebook and return its notebook_id.","result":"Create a new notebook .","score":[0.4128,0.5154]}
{"code":"def copy_notebook(self, notebook_id):\r\n        \"\"\" function to<extra_id_0>\r\n        last_mod, nb = self.get_notebook_object(notebook_id)\r\n        name = nb.metadata.name + '-Copy'\r\n        path, name = self.increment_filename(name)\r\n        nb.metadata.name = name\r\n        notebook_id = self.new_notebook_id(name)\r\n        self.save_notebook_object(notebook_id, nb)\r\n        return notebook_id","reference":"Copy an existing notebook and return its notebook_id.","result":"Copy a notebook .","score":[0.1398,0.1316]}
{"code":"def phys_tokens(toks):\r\n    \"\"\" function to<extra_id_0>\r\n    last_line = None\r\n    last_lineno = -1\r\n    last_ttype = None\r\n    for ttype, ttext, (slineno, scol), (elineno, ecol), ltext in toks:\r\n        if last_lineno != elineno:\r\n            if last_line and last_line.endswith(\"\\\\\\n\"):\r\n                inject_backslash = True\r\n                if last_ttype == tokenize.COMMENT:\r\n                    inject_backslash = False\r\n                elif ttype == token.STRING:\r\n                    if \"\\n\" in ttext and ttext.split('\\n', 1)[0][-1] == '\\\\':\r\n                        inject_backslash = False\r\n                if inject_backslash:\r\n                    ccol = len(last_line.split(\"\\n\")[-2]) - 1\r\n                    yield (\r\n                        99999, \"\\\\\\n\",\r\n                        (slineno, ccol), (slineno, ccol+2),\r\n                        last_line\r\n                        )\r\n            last_line = ltext\r\n            last_ttype = ttype\r\n        yield ttype, ttext, (slineno, scol), (elineno, ecol), ltext\r\n        last_lineno = elineno","reference":"Return all physical tokens, even line continuations.\n\n    tokenize.generate_tokens() doesn't return a token for the backslash that\n    continues lines.  This wrapper provides those tokens so that we can\n    re-create a faithful representation of the original source.\n\n    Returns the same values as generate_tokens()","result":"Convert tokens to phys tokens .","score":[0.0006,0.0267]}
{"code":"def source_token_lines(source):\r\n    \"\"\" function to<extra_id_0>\r\n    ws_tokens = set([token.INDENT, token.DEDENT, token.NEWLINE, tokenize.NL])\r\n    line = []\r\n    col = 0\r\n    source = source.expandtabs(8).replace('\\r\\n', '\\n')\r\n    tokgen = generate_tokens(source)\r\n    for ttype, ttext, (_, scol), (_, ecol), _ in phys_tokens(tokgen):\r\n        mark_start = True\r\n        for part in re.split('(\\n)', ttext):\r\n            if part == '\\n':\r\n                yield line\r\n                line = []\r\n                col = 0\r\n                mark_end = False\r\n            elif part == '':\r\n                mark_end = False\r\n            elif ttype in ws_tokens:\r\n                mark_end = False\r\n            else:\r\n                if mark_start and scol > col:\r\n                    line.append((\"ws\", \" \" * (scol - col)))\r\n                    mark_start = False\r\n                tok_class = tokenize.tok_name.get(ttype, 'xx').lower()[:3]\r\n                if ttype == token.NAME and keyword.iskeyword(ttext):\r\n                    tok_class = \"key\"\r\n                line.append((tok_class, part))\r\n                mark_end = True\r\n            scol = 0\r\n        if mark_end:\r\n            col = ecol\r\n    if line:\r\n        yield line","reference":"Generate a series of lines, one for each line in `source`.\n\n    Each line is a list of pairs, each pair is a token::\n\n        [('key', 'def'), ('ws', ' '), ('nam', 'hello'), ('op', '('), ... ]\n\n    Each pair has a token class, and the token text.\n\n    If you concatenate all the token texts, and then join them with newlines,\n    you should have your original `source` back, with two differences:\n    trailing whitespace is not preserved, and a final line with no newline\n    is indistinguishable from a final line with a newline.","result":"Generate token lines from source .","score":[0.0,0.0251]}
{"code":"def load_default_config(ipython_dir=None):\r\n    \"\"\" function to<extra_id_0>\r\n    if ipython_dir is None:\r\n        ipython_dir = get_ipython_dir()\r\n    profile_dir = os.path.join(ipython_dir, 'profile_default')\r\n    cl = PyFileConfigLoader(default_config_file_name, profile_dir)\r\n    try:\r\n        config = cl.load_config()\r\n    except ConfigFileNotFound:\r\n        config = Config()\r\n    return config","reference":"Load the default config file from the default ipython_dir.\n\n    This is useful for embedded shells.","result":"Load default config .","score":[0.032,0.1079]}
{"code":"def _classes_default(self):\r\n        \"\"\" function to<extra_id_0>\r\n        return [\r\n            InteractiveShellApp,\r\n            self.__class__,\r\n            TerminalInteractiveShell,\r\n            PromptManager,\r\n            HistoryManager,\r\n            ProfileDir,\r\n            PlainTextFormatter,\r\n            IPCompleter,\r\n            ScriptMagics,\r\n        ]","reference":"This has to be in a method, for TerminalIPythonApp to be available.","result":"Return default classes .","score":[0,0.0]}
{"code":"def parse_command_line(self, argv=None):\r\n        \"\"\" function to<extra_id_0>\r\n        argv = sys.argv[1:] if argv is None else argv\r\n        if '-pylab' in argv:\r\n            argv = argv[:]\r\n            idx = argv.index('-pylab')\r\n            warn.warn(\"`-pylab` flag has been deprecated.\\n\"\r\n            \"    Use `--pylab` instead, or `--pylab=foo` to specify a backend.\")\r\n            sub = '--pylab'\r\n            if len(argv) > idx+1:\r\n                gui = argv[idx+1]\r\n                if gui in ('wx', 'qt', 'qt4', 'gtk', 'auto'):\r\n                    sub = '--pylab='+gui\r\n                    argv.pop(idx+1)\r\n            argv[idx] = sub\r\n        return super(TerminalIPythonApp, self).parse_command_line(argv)","reference":"override to allow old '-pylab' flag with deprecation warning","result":"Parse command line arguments .","score":[0,0.0]}
{"code":"def initialize(self, argv=None):\r\n        \"\"\" function to<extra_id_0>\r\n        super(TerminalIPythonApp, self).initialize(argv)\r\n        if self.subapp is not None:\r\n            return\r\n        if not self.ignore_old_config:\r\n            check_for_old_config(self.ipython_dir)\r\n        if self.extra_args and not self.something_to_run:\r\n            self.file_to_run = self.extra_args[0]\r\n        self.init_path()\r\n        self.init_shell()\r\n        self.init_banner()\r\n        self.init_gui_pylab()\r\n        self.init_extensions()\r\n        self.init_code()","reference":"Do actions after construct, but before starting the app.","result":"Initialize the terminal IPythonApp .","score":[0.108,0.0581]}
{"code":"def init_shell(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self.shell = TerminalInteractiveShell.instance(config=self.config,\r\n                        display_banner=False, profile_dir=self.profile_dir,\r\n                        ipython_dir=self.ipython_dir)\r\n        self.shell.configurables.append(self)","reference":"initialize the InteractiveShell instance","result":"Initialize shell .","score":[0,0.1282]}
{"code":"def init_banner(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.display_banner and self.interact:\r\n            self.shell.show_banner()\r\n        if self.log_level <= logging.INFO: print","reference":"optionally display the banner","result":"Init banner .","score":[0.2925,0.1282]}
{"code":"def repr_type(obj):\r\n    \"\"\" function to<extra_id_0>\r\n    the_type = type(obj)\r\n    if (not py3compat.PY3) and the_type is InstanceType:\r\n        the_type = obj.__class__\r\n    msg = '%r %r' % (obj, the_type)\r\n    return msg","reference":"Return a string representation of a value and its type for readable\n    error messages.","result":"Return a type string .","score":[0.0668,0.1527]}
{"code":"def parse_notifier_name(name):\r\n    \"\"\" function to<extra_id_0>\r\n    if isinstance(name, str):\r\n        return [name]\r\n    elif name is None:\r\n        return ['anytrait']\r\n    elif isinstance(name, (list, tuple)):\r\n        for n in name:\r\n            assert isinstance(n, str), \"names must be strings\"\r\n        return name","reference":"Convert the name argument to a list of names.\n\n    Examples\n    --------\n\n    >>> parse_notifier_name('a')\n    ['a']\n    >>> parse_notifier_name(['a','b'])\n    ['a', 'b']\n    >>> parse_notifier_name(None)\n    ['anytrait']","result":"Parse a notifier name .","score":[0.0116,0.0515]}
{"code":"def set_default_value(self, obj):\r\n        \"\"\" function to<extra_id_0>\r\n        mro = type(obj).mro()\r\n        meth_name = '_%s_default' % self.name\r\n        for cls in mro[:mro.index(self.this_class)+1]:\r\n            if meth_name in cls.__dict__:\r\n                break\r\n        else:\r\n            dv = self.get_default_value()\r\n            newdv = self._validate(obj, dv)\r\n            obj._trait_values[self.name] = newdv\r\n            return\r\n        obj._trait_dyn_inits[self.name] = cls.__dict__[meth_name]","reference":"Set the default value on a per instance basis.\n\n        This method is called by :meth:`instance_init` to create and\n        validate the default value.  The creation and validation of\n        default values must be delayed until the parent :class:`HasTraits`\n        class has been instantiated.","result":"Set default value for an object .","score":[0.0023,0.0409]}
{"code":"def on_trait_change(self, handler, name=None, remove=False):\r\n        \"\"\" function to<extra_id_0>\r\n        if remove:\r\n            names = parse_notifier_name(name)\r\n            for n in names:\r\n                self._remove_notifiers(handler, n)\r\n        else:\r\n            names = parse_notifier_name(name)\r\n            for n in names:\r\n                self._add_notifiers(handler, n)","reference":"Setup a handler to be called when a trait changes.\n\n        This is used to setup dynamic notifications of trait changes.\n\n        Static handlers can be created by creating methods on a HasTraits\n        subclass with the naming convention '_[traitname]_changed'.  Thus,\n        to create static handler for the trait 'a', create the method\n        _a_changed(self, name, old, new) (fewer arguments can be used, see\n        below).\n\n        Parameters\n        ----------\n        handler : callable\n            A callable that is called when a trait changes.  Its\n            signature can be handler(), handler(name), handler(name, new)\n            or handler(name, old, new).\n        name : list, str, None\n            If None, the handler will apply to all traits.  If a list\n            of str, handler will apply to all names in the list.  If a\n            str, the handler will apply just to that name.\n        remove : bool\n            If False (the default), then install the handler.  If True\n            then unintall it.","result":"Handle on trait change .","score":[0.0,0.0078]}
{"code":"def class_traits(cls, **metadata):\r\n        \"\"\" function to<extra_id_0>\r\n        traits = dict([memb for memb in getmembers(cls) if \\\r\n                     isinstance(memb[1], TraitType)])\r\n        if len(metadata) == 0:\r\n            return traits\r\n        for meta_name, meta_eval in metadata.items():\r\n            if type(meta_eval) is not FunctionType:\r\n                metadata[meta_name] = _SimpleTest(meta_eval)\r\n        result = {}\r\n        for name, trait in traits.items():\r\n            for meta_name, meta_eval in metadata.items():\r\n                if not meta_eval(trait.get_metadata(meta_name)):\r\n                    break\r\n            else:\r\n                result[name] = trait\r\n        return result","reference":"Get a list of all the traits of this class.\n\n        This method is just like the :meth:`traits` method, but is unbound.\n\n        The TraitTypes returned don't know anything about the values\n        that the various HasTrait's instances are holding.\n\n        This follows the same algorithm as traits does and does not allow\n        for any simple way of specifying merely that a metadata name\n        exists, but has any value.  This is because get_metadata returns\n        None if a metadata key doesn't exist.","result":"Return a dictionary of traits for a class .","score":[0.0001,0.0427]}
{"code":"def trait_metadata(self, traitname, key):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            trait = getattr(self.__class__, traitname)\r\n        except AttributeError:\r\n            raise TraitError(\"Class %s does not have a trait named %s\" %\r\n                                (self.__class__.__name__, traitname))\r\n        else:\r\n            return trait.get_metadata(key)","reference":"Get metadata values for trait by key.","result":"Get trait metadata .","score":[0.1986,0.2239]}
{"code":"def validate(self, obj, value):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            if issubclass(value, self.klass):\r\n                return value\r\n        except:\r\n            if (value is None) and (self._allow_none):\r\n                return value\r\n        self.error(obj, value)","reference":"Validates that the value is a valid object instance.","result":"Validate a value .","score":[0.1088,0.1765]}
{"code":"def get_default_value(self):\r\n        \"\"\" function to<extra_id_0>\r\n        dv  = self.default_value\r\n        if isinstance(dv, DefaultValueGenerator):\r\n            return dv.generate(self.klass)\r\n        else:\r\n            return dv","reference":"Instantiate a default value instance.\n\n        This is called when the containing HasTraits classes'\n        :meth:`__new__` method is called to ensure that a unique instance\n        is created for each HasTraits instance.","result":" is None.","score":[0.0,0.019]}
{"code":"def check(self, completed, failed=None):\r\n        \"\"\" function to<extra_id_0>\r\n        if len(self) == 0:\r\n            return True\r\n        against = set()\r\n        if self.success:\r\n            against = completed\r\n        if failed is not None and self.failure:\r\n            against = against.union(failed)\r\n        if self.all:\r\n            return self.issubset(against)\r\n        else:\r\n            return not self.isdisjoint(against)","reference":"check whether our dependencies have been met.","result":"Check the state of the set .","score":[0,0.0714]}
{"code":"def unreachable(self, completed, failed=None):\r\n        \"\"\" function to<extra_id_0>\r\n        if len(self) == 0:\r\n            return False\r\n        against = set()\r\n        if not self.success:\r\n            against = completed\r\n        if failed is not None and not self.failure:\r\n            against = against.union(failed)\r\n        if self.all:\r\n            return not self.isdisjoint(against)\r\n        else:\r\n            return self.issubset(against)","reference":"return whether this dependency has become impossible.","result":" is unreachable .","score":[0,0.0]}
{"code":"def as_dict(self):\r\n        \"\"\" function to<extra_id_0>\r\n        return dict(\r\n            dependencies=list(self),\r\n            all=self.all,\r\n            success=self.success,\r\n            failure=self.failure\r\n        )","reference":"Represent this dependency as a dict. For json compatibility.","result":"Return the dependencies as a dict .","score":[0.1716,0.3346]}
{"code":"def depth(n, tree):\r\n    \"\"\" function to<extra_id_0>\r\n    d = 0\r\n    parent = tree[n]\r\n    while parent is not None:\r\n        d += 1\r\n        parent = tree[parent]\r\n    return d","reference":"get depth of an element in the tree","result":"Calculate the depth of a node .","score":[0.2191,0.3235]}
{"code":"def print_bintree(tree, indent='  '):\r\n    \"\"\" function to<extra_id_0>\r\n    for n in sorted(tree.keys()):\r\n        print \"%s%s\" % (indent * depth(n,tree), n)","reference":"print a binary tree","result":"Print a bintree .","score":[0.3195,0.4688]}
{"code":"def disambiguate_dns_url(url, location):\r\n    \"\"\" function to<extra_id_0>\r\n    if not ip_pat.match(location):\r\n        location = socket.gethostbyname(location)\r\n    return disambiguate_url(url, location)","reference":"accept either IP address or dns name, and return IP","result":"Disambiguate dns urls .","score":[0.0713,0.0532]}
{"code":"def allreduce(self, f, value, flat=True):\r\n        \"\"\" function to<extra_id_0>\r\n        return self.reduce(f, value, flat=flat, all=True)","reference":"parallel reduce followed by broadcast of the result","result":"Reduce all values .","score":[0,0.0658]}
{"code":"def _validate_targets(self, targets):\r\n        \"\"\" function to<extra_id_0>\r\n        if targets is None:\r\n            return self.ids\r\n        if isinstance(targets, (int,str,unicode)):\r\n            targets = [targets]\r\n        _targets = []\r\n        for t in targets:\r\n            if isinstance(t, (str,unicode)):\r\n                t = self.by_ident.get(cast_bytes(t), t)\r\n            _targets.append(t)\r\n        targets = _targets\r\n        bad_targets = [ t for t in targets if t not in self.ids ]\r\n        if bad_targets:\r\n            raise IndexError(\"No Such Engine: %r\" % bad_targets)\r\n        if not targets:\r\n            raise IndexError(\"No Engines Registered\")\r\n        return targets","reference":"turn any valid targets argument into a list of integer ids","result":"Validate the targets .","score":[0.0555,0.0971]}
{"code":"def dispatch_monitor_traffic(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        self.log.debug(\"monitor traffic: %r\", msg[0])\r\n        switch = msg[0]\r\n        try:\r\n            idents, msg = self.session.feed_identities(msg[1:])\r\n        except ValueError:\r\n            idents=[]\r\n        if not idents:\r\n            self.log.error(\"Monitor message without topic: %r\", msg)\r\n            return\r\n        handler = self.monitor_handlers.get(switch, None)\r\n        if handler is not None:\r\n            handler(idents, msg)\r\n        else:\r\n            self.log.error(\"Unrecognized monitor topic: %r\", switch)","reference":"all ME and Task queue messages come through here, as well as\n        IOPub traffic.","result":"Def handle monitor traffic messages .","score":[0.0509,0.0379]}
{"code":"def dispatch_query(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            idents, msg = self.session.feed_identities(msg)\r\n        except ValueError:\r\n            idents = []\r\n        if not idents:\r\n            self.log.error(\"Bad Query Message: %r\", msg)\r\n            return\r\n        client_id = idents[0]\r\n        try:\r\n            msg = self.session.unserialize(msg, content=True)\r\n        except Exception:\r\n            content = error.wrap_exception()\r\n            self.log.error(\"Bad Query Message: %r\", msg, exc_info=True)\r\n            self.session.send(self.query, \"hub_error\", ident=client_id,\r\n                    content=content)\r\n            return\r\n        msg_type = msg['header']['msg_type']\r\n        self.log.info(\"client::client %r requested %r\", client_id, msg_type)\r\n        handler = self.query_handlers.get(msg_type, None)\r\n        try:\r\n            assert handler is not None, \"Bad Message Type: %r\" % msg_type\r\n        except:\r\n            content = error.wrap_exception()\r\n            self.log.error(\"Bad Message Type: %r\", msg_type, exc_info=True)\r\n            self.session.send(self.query, \"hub_error\", ident=client_id,\r\n                    content=content)\r\n            return\r\n        else:\r\n            handler(idents, msg)","reference":"Route registration requests and queries from clients.","result":"Handle a query message .","score":[0,0.0735]}
{"code":"def handle_new_heart(self, heart):\r\n        \"\"\" function to<extra_id_0>\r\n        self.log.debug(\"heartbeat::handle_new_heart(%r)\", heart)\r\n        if heart not in self.incoming_registrations:\r\n            self.log.info(\"heartbeat::ignoring new heart: %r\", heart)\r\n        else:\r\n            self.finish_registration(heart)","reference":"handler to attach to heartbeater.\n        Called when a new heart starts to beat.\n        Triggers completion of registration.","result":"Def handle new heart .","score":[0.0308,0.1187]}
{"code":"def handle_heart_failure(self, heart):\r\n        \"\"\" function to<extra_id_0>\r\n        self.log.debug(\"heartbeat::handle_heart_failure(%r)\", heart)\r\n        eid = self.hearts.get(heart, None)\r\n        queue = self.engines[eid].queue\r\n        if eid is None or self.keytable[eid] in self.dead_engines:\r\n            self.log.info(\"heartbeat::ignoring heart failure %r (not an engine or already dead)\", heart)\r\n        else:\r\n            self.unregister_engine(heart, dict(content=dict(id=eid, queue=queue)))","reference":"handler to attach to heartbeater.\n        called when a previously registered heart fails to respond to beat request.\n        triggers unregistration","result":"Def handle heart failure .","score":[0.0146,0.0284]}
{"code":"def save_task_request(self, idents, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        client_id = idents[0]\r\n        try:\r\n            msg = self.session.unserialize(msg)\r\n        except Exception:\r\n            self.log.error(\"task::client %r sent invalid task message: %r\",\r\n                    client_id, msg, exc_info=True)\r\n            return\r\n        record = init_record(msg)\r\n        record['client_uuid'] = client_id.decode('ascii')\r\n        record['queue'] = 'task'\r\n        header = msg['header']\r\n        msg_id = header['msg_id']\r\n        self.pending.add(msg_id)\r\n        self.unassigned.add(msg_id)\r\n        try:\r\n            existing = self.db.get_record(msg_id)\r\n            if existing['resubmitted']:\r\n                for key in ('submitted', 'client_uuid', 'buffers'):\r\n                    record.pop(key)\r\n            for key,evalue in existing.iteritems():\r\n                if key.endswith('buffers'):\r\n                    continue\r\n                rvalue = record.get(key, None)\r\n                if evalue and rvalue and evalue != rvalue:\r\n                    self.log.warn(\"conflicting initial state for record: %r:%r <%r> %r\", msg_id, rvalue, key, evalue)\r\n                elif evalue and not rvalue:\r\n                    record[key] = evalue\r\n            try:\r\n                self.db.update_record(msg_id, record)\r\n            except Exception:\r\n                self.log.error(\"DB Error updating record %r\", msg_id, exc_info=True)\r\n        except KeyError:\r\n            try:\r\n                self.db.add_record(msg_id, record)\r\n            except Exception:\r\n                self.log.error(\"DB Error adding record %r\", msg_id, exc_info=True)\r\n        except Exception:\r\n            self.log.error(\"DB Error saving task request %r\", msg_id, exc_info=True)","reference":"Save the submission of a task.","result":"Def save task request .","score":[0,0.0847]}
{"code":"def save_task_result(self, idents, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        client_id = idents[0]\r\n        try:\r\n            msg = self.session.unserialize(msg)\r\n        except Exception:\r\n            self.log.error(\"task::invalid task result message send to %r: %r\",\r\n                    client_id, msg, exc_info=True)\r\n            return\r\n        parent = msg['parent_header']\r\n        if not parent:\r\n            self.log.warn(\"Task %r had no parent!\", msg)\r\n            return\r\n        msg_id = parent['msg_id']\r\n        if msg_id in self.unassigned:\r\n            self.unassigned.remove(msg_id)\r\n        header = msg['header']\r\n        engine_uuid = header.get('engine', u'')\r\n        eid = self.by_ident.get(cast_bytes(engine_uuid), None)\r\n                status = header.get('status', None)\r\n        if msg_id in self.pending:\r\n            self.log.info(\"task::task %r finished on %s\", msg_id, eid)\r\n            self.pending.remove(msg_id)\r\n            self.all_completed.add(msg_id)\r\n            if eid is not None:\r\n                if status != 'aborted':\r\n                    self.completed[eid].append(msg_id)\r\n                if msg_id in self.tasks[eid]:\r\n                    self.tasks[eid].remove(msg_id)\r\n            completed = header['date']\r\n            started = header.get('started', None)\r\n            result = {\r\n                'result_header' : header,\r\n                'result_content': msg['content'],\r\n                'started' : started,\r\n                'completed' : completed,\r\n                'received' : datetime.now(),\r\n                'engine_uuid': engine_uuid,\r\n            }\r\n            result['result_buffers'] = msg['buffers']\r\n            try:\r\n                self.db.update_record(msg_id, result)\r\n            except Exception:\r\n                self.log.error(\"DB Error saving task request %r\", msg_id, exc_info=True)\r\n        else:\r\n            self.log.debug(\"task::unknown task %r finished\", msg_id)","reference":"save the result of a completed task.","result":"Def save task result .","score":[0.1915,0.1471]}
{"code":"def save_iopub_message(self, topics, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            msg = self.session.unserialize(msg, content=True)\r\n        except Exception:\r\n            self.log.error(\"iopub::invalid IOPub message\", exc_info=True)\r\n            return\r\n        parent = msg['parent_header']\r\n        if not parent:\r\n            self.log.warn(\"iopub::IOPub message lacks parent: %r\", msg)\r\n            return\r\n        msg_id = parent['msg_id']\r\n        msg_type = msg['header']['msg_type']\r\n        content = msg['content']\r\n        try:\r\n            rec = self.db.get_record(msg_id)\r\n        except KeyError:\r\n            rec = empty_record()\r\n            rec['msg_id'] = msg_id\r\n            self.db.add_record(msg_id, rec)\r\n        d = {}\r\n        if msg_type == 'stream':\r\n            name = content['name']\r\n            s = rec[name] or ''\r\n            d[name] = s + content['data']\r\n        elif msg_type == 'pyerr':\r\n            d['pyerr'] = content\r\n        elif msg_type == 'pyin':\r\n            d['pyin'] = content['code']\r\n        elif msg_type in ('display_data', 'pyout'):\r\n            d[msg_type] = content\r\n        elif msg_type == 'status':\r\n            pass\r\n        else:\r\n            self.log.warn(\"unhandled iopub msg_type: %r\", msg_type)\r\n        if not d:\r\n            return\r\n        try:\r\n            self.db.update_record(msg_id, d)\r\n        except Exception:\r\n            self.log.error(\"DB Error saving iopub message %r\", msg_id, exc_info=True)","reference":"save an iopub message into the db","result":"Save a message .","score":[0.1509,0.1493]}
{"code":"def connection_request(self, client_id, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        self.log.info(\"client::client %r connected\", client_id)\r\n        content = dict(status='ok')\r\n        content.update(self.client_info)\r\n        jsonable = {}\r\n        for k,v in self.keytable.iteritems():\r\n            if v not in self.dead_engines:\r\n                jsonable[str(k)] = v.decode('ascii')\r\n        content['engines'] = jsonable\r\n        self.session.send(self.query, 'connection_reply', content, parent=msg, ident=client_id)","reference":"Reply with connection addresses for clients.","result":"Handle client connection requests .","score":[0.1967,0.0847]}
{"code":"def register_engine(self, reg, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        content = msg['content']\r\n        try:\r\n            queue = cast_bytes(content['queue'])\r\n        except KeyError:\r\n            self.log.error(\"registration::queue not specified\", exc_info=True)\r\n            return\r\n        heart = content.get('heartbeat', None)\r\n        if heart:\r\n            heart = cast_bytes(heart)\r\n        eid = self._next_id\r\n        self.log.debug(\"registration::register_engine(%i, %r, %r, %r)\", eid, queue, reg, heart)\r\n        content = dict(id=eid,status='ok')\r\n        content.update(self.engine_info)\r\n        if queue in self.by_ident:\r\n            try:\r\n                raise KeyError(\"queue_id %r in use\" % queue)\r\n            except:\r\n                content = error.wrap_exception()\r\n                self.log.error(\"queue_id %r in use\", queue, exc_info=True)\r\n        elif heart in self.hearts:\r\n            try:\r\n                raise KeyError(\"heart_id %r in use\" % heart)\r\n            except:\r\n                self.log.error(\"heart_id %r in use\", heart, exc_info=True)\r\n                content = error.wrap_exception()\r\n        else:\r\n            for h, pack in self.incoming_registrations.iteritems():\r\n                if heart == h:\r\n                    try:\r\n                        raise KeyError(\"heart_id %r in use\" % heart)\r\n                    except:\r\n                        self.log.error(\"heart_id %r in use\", heart, exc_info=True)\r\n                        content = error.wrap_exception()\r\n                    break\r\n                elif queue == pack[1]:\r\n                    try:\r\n                        raise KeyError(\"queue_id %r in use\" % queue)\r\n                    except:\r\n                        self.log.error(\"queue_id %r in use\", queue, exc_info=True)\r\n                        content = error.wrap_exception()\r\n                    break\r\n        msg = self.session.send(self.query, \"registration_reply\",\r\n                content=content,\r\n                ident=reg)\r\n        if content['status'] == 'ok':\r\n            if heart in self.heartmonitor.hearts:\r\n                self.incoming_registrations[heart] = (eid,queue,reg[0],None)\r\n                self.finish_registration(heart)\r\n            else:\r\n                purge = lambda : self._purge_stalled_registration(heart)\r\n                dc = ioloop.DelayedCallback(purge, self.registration_timeout, self.loop)\r\n                dc.start()\r\n                self.incoming_registrations[heart] = (eid,queue,reg[0],dc)\r\n        else:\r\n            self.log.error(\"registration::registration %i failed: %r\", eid, content['evalue'])\r\n        return eid","reference":"Register a new engine.","result":"Def register an engine .","score":[0,0.122]}
{"code":"def unregister_engine(self, ident, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            eid = msg['content']['id']\r\n        except:\r\n            self.log.error(\"registration::bad engine id for unregistration: %r\", ident, exc_info=True)\r\n            return\r\n        self.log.info(\"registration::unregister_engine(%r)\", eid)\r\n        uuid = self.keytable[eid]\r\n        content=dict(id=eid, queue=uuid.decode('ascii'))\r\n        self.dead_engines.add(uuid)\r\n        handleit = lambda : self._handle_stranded_msgs(eid, uuid)\r\n        dc = ioloop.DelayedCallback(handleit, self.registration_timeout, self.loop)\r\n        dc.start()\r\n","reference":"Unregister an engine that explicitly requested to leave.","result":"Unregister an engine .","score":[0.2421,0.3874]}
{"code":"def finish_registration(self, heart):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            (eid,queue,reg,purge) = self.incoming_registrations.pop(heart)\r\n        except KeyError:\r\n            self.log.error(\"registration::tried to finish nonexistant registration\", exc_info=True)\r\n            return\r\n        self.log.info(\"registration::finished registering engine %i:%r\", eid, queue)\r\n        if purge is not None:\r\n            purge.stop()\r\n        control = queue\r\n        self.ids.add(eid)\r\n        self.keytable[eid] = queue\r\n        self.engines[eid] = EngineConnector(id=eid, queue=queue, registration=reg,\r\n                                    control=control, heartbeat=heart)\r\n        self.by_ident[queue] = eid\r\n        self.queues[eid] = list()\r\n        self.tasks[eid] = list()\r\n        self.completed[eid] = list()\r\n        self.hearts[heart] = eid\r\n        content = dict(id=eid, queue=self.engines[eid].queue.decode('ascii'))\r\n        if self.notifier:\r\n            self.session.send(self.notifier, \"registration_notification\", content=content)\r\n        self.log.info(\"engine::Engine Connected: %i\", eid)","reference":"Second half of engine registration, called after our HeartMonitor\n        has received a beat from the Engine's Heart.","result":"Finish registering engine .","score":[0.0124,0.0318]}
{"code":"def shutdown_request(self, client_id, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        self.session.send(self.query, 'shutdown_reply', content={'status': 'ok'}, ident=client_id)\r\n        self.session.send(self.notifier, 'shutdown_notice', content={'status': 'ok'})\r\n        dc = ioloop.DelayedCallback(lambda : self._shutdown(), 1000, self.loop)\r\n        dc.start()","reference":"handle shutdown request.","result":"Handle shutdown request .","score":[0.3195,0.6048]}
{"code":"def purge_results(self, client_id, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        content = msg['content']\r\n        self.log.info(\"Dropping records with %s\", content)\r\n        msg_ids = content.get('msg_ids', [])\r\n        reply = dict(status='ok')\r\n        if msg_ids == 'all':\r\n            try:\r\n                self.db.drop_matching_records(dict(completed={'$ne':None}))\r\n            except Exception:\r\n                reply = error.wrap_exception()\r\n        else:\r\n            pending = filter(lambda m: m in self.pending, msg_ids)\r\n            if pending:\r\n                try:\r\n                    raise IndexError(\"msg pending: %r\" % pending[0])\r\n                except:\r\n                    reply = error.wrap_exception()\r\n            else:\r\n                try:\r\n                    self.db.drop_matching_records(dict(msg_id={'$in':msg_ids}))\r\n                except Exception:\r\n                    reply = error.wrap_exception()\r\n            if reply['status'] == 'ok':\r\n                eids = content.get('engine_ids', [])\r\n                for eid in eids:\r\n                    if eid not in self.engines:\r\n                        try:\r\n                            raise IndexError(\"No such engine: %i\" % eid)\r\n                        except:\r\n                            reply = error.wrap_exception()\r\n                        break\r\n                    uid = self.engines[eid].queue\r\n                    try:\r\n                        self.db.drop_matching_records(dict(engine_uuid=uid, completed={'$ne':None}))\r\n                    except Exception:\r\n                        reply = error.wrap_exception()\r\n                        break\r\n        self.session.send(self.query, 'purge_reply', content=reply, ident=client_id)","reference":"Purge results from memory. This method is more valuable before we move\n        to a DB based message storage mechanism.","result":"Purge results.","score":[0.0001,0.0289]}
{"code":"def _extract_record(self, rec):\r\n        \"\"\" function to<extra_id_0>\r\n        io_dict = {}\r\n        for key in ('pyin', 'pyout', 'pyerr', 'stdout', 'stderr'):\r\n                io_dict[key] = rec[key]\r\n        content = { 'result_content': rec['result_content'],\r\n                            'header': rec['header'],\r\n                            'result_header' : rec['result_header'],\r\n                            'received' : rec['received'],\r\n                            'io' : io_dict,\r\n                          }\r\n        if rec['result_buffers']:\r\n            buffers = map(bytes, rec['result_buffers'])\r\n        else:\r\n            buffers = []\r\n        return content, buffers","reference":"decompose a TaskRecord dict into subsection of reply for get_result","result":"Extract record from the record .","score":[0,0.0]}
{"code":"def get_results(self, client_id, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        content = msg['content']\r\n        msg_ids = sorted(set(content['msg_ids']))\r\n        statusonly = content.get('status_only', False)\r\n        pending = []\r\n        completed = []\r\n        content = dict(status='ok')\r\n        content['pending'] = pending\r\n        content['completed'] = completed\r\n        buffers = []\r\n        if not statusonly:\r\n            try:\r\n                matches = self.db.find_records(dict(msg_id={'$in':msg_ids}))\r\n                records = {}\r\n                for rec in matches:\r\n                    records[rec['msg_id']] = rec\r\n            except Exception:\r\n                content = error.wrap_exception()\r\n                self.session.send(self.query, \"result_reply\", content=content,\r\n                                                    parent=msg, ident=client_id)\r\n                return\r\n        else:\r\n            records = {}\r\n        for msg_id in msg_ids:\r\n            if msg_id in self.pending:\r\n                pending.append(msg_id)\r\n            elif msg_id in self.all_completed:\r\n                completed.append(msg_id)\r\n                if not statusonly:\r\n                    c,bufs = self._extract_record(records[msg_id])\r\n                    content[msg_id] = c\r\n                    buffers.extend(bufs)\r\n            elif msg_id in records:\r\n                if rec['completed']:\r\n                    completed.append(msg_id)\r\n                    c,bufs = self._extract_record(records[msg_id])\r\n                    content[msg_id] = c\r\n                    buffers.extend(bufs)\r\n                else:\r\n                    pending.append(msg_id)\r\n            else:\r\n                try:\r\n                    raise KeyError('No such message: '+msg_id)\r\n                except:\r\n                    content = error.wrap_exception()\r\n                break\r\n        self.session.send(self.query, \"result_reply\", content=content,\r\n                                            parent=msg, ident=client_id,\r\n                                            buffers=buffers)","reference":"Get the result of 1 or more messages.","result":"Get results from the database .","score":[0.1645,0.1923]}
{"code":"def get_history(self, client_id, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            msg_ids = self.db.get_history()\r\n        except Exception as e:\r\n            content = error.wrap_exception()\r\n        else:\r\n            content = dict(status='ok', history=msg_ids)\r\n        self.session.send(self.query, \"history_reply\", content=content,\r\n                                            parent=msg, ident=client_id)","reference":"Get a list of all msg_ids in our DB records","result":"Get history .","score":[0.0396,0.0538]}
{"code":"def db_query(self, client_id, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        content = msg['content']\r\n        query = content.get('query', {})\r\n        keys = content.get('keys', None)\r\n        buffers = []\r\n        empty = list()\r\n        try:\r\n            records = self.db.find_records(query, keys)\r\n        except Exception as e:\r\n            content = error.wrap_exception()\r\n        else:\r\n            if keys is not None:\r\n                buffer_lens = [] if 'buffers' in keys else None\r\n                result_buffer_lens = [] if 'result_buffers' in keys else None\r\n            else:\r\n                buffer_lens = None\r\n                result_buffer_lens = None\r\n            for rec in records:\r\n                b = rec.pop('buffers', empty) or empty\r\n                if buffer_lens is not None:\r\n                    buffer_lens.append(len(b))\r\n                    buffers.extend(b)\r\n                rb = rec.pop('result_buffers', empty) or empty\r\n                if result_buffer_lens is not None:\r\n                    result_buffer_lens.append(len(rb))\r\n                    buffers.extend(rb)\r\n            content = dict(status='ok', records=records, buffer_lens=buffer_lens,\r\n                                    result_buffer_lens=result_buffer_lens)\r\n        self.session.send(self.query, \"db_reply\", content=content,\r\n                                            parent=msg, ident=client_id,\r\n                                            buffers=buffers)","reference":"Perform a raw query on the task record database.","result":"Handle a db query .","score":[0.1284,0.1163]}
{"code":"def cd(self, newdir):\r\n        \"\"\" function to<extra_id_0>\r\n        prevdir = os.getcwd()\r\n        os.chdir(newdir)\r\n        try:\r\n            yield\r\n        finally:\r\n            os.chdir(prevdir)","reference":"go to the path","result":"Change directory .","score":[0,0.0]}
{"code":"def decode_cmd_out(self, completed_cmd):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            stdout = completed_cmd.stdout.encode('utf-8').decode()\r\n        except AttributeError:\r\n            try:\r\n                stdout = str(bytes(completed_cmd.stdout), 'big5').strip()\r\n            except AttributeError:\r\n                stdout = str(bytes(completed_cmd.stdout).decode('utf-8')).strip()\r\n        try:\r\n            stderr = completed_cmd.stderr.encode('utf-8').decode()\r\n        except AttributeError:\r\n            try:\r\n                stderr = str(bytes(completed_cmd.stderr), 'big5').strip()\r\n            except AttributeError:\r\n                stderr = str(bytes(completed_cmd.stderr).decode('utf-8')).strip()\r\n        return ParsedCompletedCommand(\r\n            completed_cmd.returncode,\r\n            completed_cmd.args,\r\n            stdout,\r\n            stderr\r\n        )","reference":"return a standard message","result":"Decode the output of a completed command .","score":[0.1389,0.1136]}
{"code":"def run_command_under_r_root(self, cmd, catched=True):\r\n        \"\"\" function to<extra_id_0>\r\n        RPATH = self.path\r\n        with self.cd(newdir=RPATH):\r\n            if catched:\r\n                process = sp.run(cmd, stdout=sp.PIPE, stderr=sp.PIPE)\r\n            else:\r\n                process = sp.run(cmd)\r\n            return process","reference":"subprocess run on here","result":"Run command under r root .","score":[0,0.119]}
{"code":"def execute(self):\r\n        \"\"\" function to<extra_id_0>\r\n        rprocess = OrderedDict()\r\n        commands = OrderedDict([\r\n            (self.file, ['Rscript', self.file] + self.cmd),\r\n        ])\r\n        for cmd_name, cmd in commands.items():\r\n            rprocess[cmd_name] = self.run_command_under_r_root(cmd)\r\n                return self.decode_cmd_out(completed_cmd=rprocess[self.file])","reference":"Execute R script","result":"Execute the command .","score":[0.3195,0.1613]}
{"code":"def _dispatch(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        msg_type = msg['header']['msg_type']\r\n        handler = getattr(self, '_handle_' + msg_type, None)\r\n        if handler:\r\n            handler(msg)","reference":"Calls the frontend handler associated with the message type of the\n            given message.","result":"Dispatch a message .","score":[0.0337,0.0413]}
{"code":"def _is_from_this_session(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        session = self._kernel_manager.session.session\r\n        parent = msg['parent_header']\r\n        if not parent:\r\n            return True\r\n        else:\r\n            return parent.get('session') == session","reference":"Returns whether a reply from the kernel originated from a request\n            from this frontend.","result":" is from this session .","score":[0.0562,0.1431]}
{"code":"def report(self, morfs, directory=None):\r\n        \"\"\" function to<extra_id_0>\r\n        self.report_files(self.annotate_file, morfs, directory)","reference":"Run the report.\n\n        See `coverage.report()` for arguments.","result":"Report the annotations .","score":[0.1509,0.0746]}
{"code":"def annotate_file(self, cu, analysis):\r\n        \"\"\" function to<extra_id_0>\r\n        if not cu.relative:\r\n            return\r\n        filename = cu.filename\r\n        source = cu.source_file()\r\n        if self.directory:\r\n            dest_file = os.path.join(self.directory, cu.flat_rootname())\r\n            dest_file += \".py,cover\"\r\n        else:\r\n            dest_file = filename + \",cover\"\r\n        dest = open(dest_file, 'w')\r\n        statements = sorted(analysis.statements)\r\n        missing = sorted(analysis.missing)\r\n        excluded = sorted(analysis.excluded)\r\n        lineno = 0\r\n        i = 0\r\n        j = 0\r\n        covered = True\r\n        while True:\r\n            line = source.readline()\r\n            if line == '':\r\n                break\r\n            lineno += 1\r\n            while i < len(statements) and statements[i] < lineno:\r\n                i += 1\r\n            while j < len(missing) and missing[j] < lineno:\r\n                j += 1\r\n            if i < len(statements) and statements[i] == lineno:\r\n                covered = j >= len(missing) or missing[j] > lineno\r\n            if self.blank_re.match(line):\r\n                dest.write('  ')\r\n            elif self.else_re.match(line):\r\n                if i >= len(statements) and j >= len(missing):\r\n                    dest.write('! ')\r\n                elif i >= len(statements) or j >= len(missing):\r\n                    dest.write('> ')\r\n                elif statements[i] == missing[j]:\r\n                    dest.write('! ')\r\n                else:\r\n                    dest.write('> ')\r\n            elif lineno in excluded:\r\n                dest.write('- ')\r\n            elif covered:\r\n                dest.write('> ')\r\n            else:\r\n                dest.write('! ')\r\n            dest.write(line)\r\n        source.close()\r\n        dest.close()","reference":"Annotate a single file.\n\n        `cu` is the CodeUnit for the file to annotate.","result":"If not filename.","score":[0,0.0]}
{"code":"def get_installed_version(name):\r\n    \"\"\" function to<extra_id_0>\r\n    '''\r\n        returns installed package version and None if package is not installed\r\n    '''\r\n    pattern = re.compile(r'''Installed:\\s+(?P<version>.*)''')\r\n    cmd = 'apt-cache policy %s' % name\r\n    args = shlex.split(cmd)\r\n    try:\r\n        output = subprocess.check_output(args)\r\n        if not output:\r\n            return None\r\n    except CalledProcessError:\r\n        return None\r\n    match = pattern.search(output)\r\n    if match:\r\n        version = match.groupdict()['version']\r\n        if version == '(none)':\r\n            return None\r\n        else:\r\n            return version","reference":"returns installed package version and None if package is not installed","result":"Get installed version of a package .","score":[0.12,0.1415]}
{"code":"def squash_unicode(obj):\r\n    \"\"\" function to<extra_id_0>\r\n    if isinstance(obj,dict):\r\n        for key in obj.keys():\r\n            obj[key] = squash_unicode(obj[key])\r\n            if isinstance(key, unicode):\r\n                obj[squash_unicode(key)] = obj.pop(key)\r\n    elif isinstance(obj, list):\r\n        for i,v in enumerate(obj):\r\n            obj[i] = squash_unicode(v)\r\n    elif isinstance(obj, unicode):\r\n        obj = obj.encode('utf8')\r\n    return obj","reference":"coerce unicode back to bytestrings.","result":"Squash unicode .","score":[0.2096,0.1042]}
{"code":"def extract_header(msg_or_header):\r\n    \"\"\" function to<extra_id_0>\r\n    if not msg_or_header:\r\n        return {}\r\n    try:\r\n        h = msg_or_header['header']\r\n    except KeyError:\r\n        try:\r\n            h = msg_or_header['msg_id']\r\n        except KeyError:\r\n            raise\r\n        else:\r\n            h = msg_or_header\r\n    if not isinstance(h, dict):\r\n        h = dict(h)\r\n    return h","reference":"Given a message or header, return the header.","result":"Extract header from message or header .","score":[0.198,0.2373]}
{"code":"def _check_packers(self):\r\n        \"\"\" function to<extra_id_0>\r\n        pack = self.pack\r\n        unpack = self.unpack\r\n        msg = dict(a=[1,'hi'])\r\n        try:\r\n            packed = pack(msg)\r\n        except Exception:\r\n            raise ValueError(\"packer could not serialize a simple message\")\r\n        if not isinstance(packed, bytes):\r\n            raise ValueError(\"message packed to %r, but bytes are required\"%type(packed))\r\n        try:\r\n            unpacked = unpack(packed)\r\n        except Exception:\r\n            raise ValueError(\"unpacker could not handle the packer's output\")\r\n        msg = dict(t=datetime.now())\r\n        try:\r\n            unpacked = unpack(pack(msg))\r\n        except Exception:\r\n            self.pack = lambda o: pack(squash_dates(o))\r\n            self.unpack = lambda s: extract_dates(unpack(s))","reference":"check packers for binary data and datetime support.","result":"Check the packer and unpackers .","score":[0.1383,0.1923]}
{"code":"def msg(self, msg_type, content=None, parent=None, subheader=None, header=None):\r\n        \"\"\" function to<extra_id_0>\r\n        msg = {}\r\n        header = self.msg_header(msg_type) if header is None else header\r\n        msg['header'] = header\r\n        msg['msg_id'] = header['msg_id']\r\n        msg['msg_type'] = header['msg_type']\r\n        msg['parent_header'] = {} if parent is None else extract_header(parent)\r\n        msg['content'] = {} if content is None else content\r\n        sub = {} if subheader is None else subheader\r\n        msg['header'].update(sub)\r\n        return msg","reference":"Return the nested message dict.\n\n        This format is different from what is sent over the wire. The\n        serialize\/unserialize methods converts this nested message dict to the wire\n        format, which is a list of message parts.","result":"Create a message .","score":[0.0002,0.0313]}
{"code":"def sign(self, msg_list):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.auth is None:\r\n            return b''\r\n        h = self.auth.copy()\r\n        for m in msg_list:\r\n            h.update(m)\r\n        return str_to_bytes(h.hexdigest())","reference":"Sign a message with HMAC digest. If no auth, return b''.\n\n        Parameters\n        ----------\n        msg_list : list\n            The [p_header,p_parent,p_content] part of the message list.","result":"For m in sign .","score":[0,0.0236]}
{"code":"def serialize(self, msg, ident=None):\r\n        \"\"\" function to<extra_id_0>\r\n        content = msg.get('content', {})\r\n        if content is None:\r\n            content = self.none\r\n        elif isinstance(content, dict):\r\n            content = self.pack(content)\r\n        elif isinstance(content, bytes):\r\n            pass\r\n        elif isinstance(content, unicode):\r\n            content = content.encode('utf8')\r\n        else:\r\n            raise TypeError(\"Content incorrect type: %s\"%type(content))\r\n        real_message = [self.pack(msg['header']),\r\n                        self.pack(msg['parent_header']),\r\n                        content\r\n        ]\r\n        to_send = []\r\n        if isinstance(ident, list):\r\n            to_send.extend(ident)\r\n        elif ident is not None:\r\n            to_send.append(ident)\r\n        to_send.append(DELIM)\r\n        signature = self.sign(real_message)\r\n        to_send.append(signature)\r\n        to_send.extend(real_message)\r\n        return to_send","reference":"Serialize the message components to bytes.\n\n        This is roughly the inverse of unserialize. The serialize\/unserialize\n        methods work with full message lists, whereas pack\/unpack work with\n        the individual message parts in the message list.\n\n        Parameters\n        ----------\n        msg : dict or Message\n            The nexted message dict as returned by the self.msg method.\n\n        Returns\n        -------\n        msg_list : list\n            The list of bytes objects to be sent with the format:\n            [ident1,ident2,...,DELIM,HMAC,p_header,p_parent,p_content,\n             buffer1,buffer2,...]. In this list, the p_* entities are\n            the packed or serialized versions, so if JSON is used, these\n            are utf8 encoded JSON strings.","result":"Serialize a message .","score":[0.0,0.0122]}
{"code":"def send(self, stream, msg_or_type, content=None, parent=None, ident=None,\r\n             \"\"\" function to<extra_id_0>\r\n             buffers=None, subheader=None, track=False, header=None):\r\n        if not isinstance(stream, (zmq.Socket, ZMQStream)):\r\n            raise TypeError(\"stream must be Socket or ZMQStream, not %r\"%type(stream))\r\n        elif track and isinstance(stream, ZMQStream):\r\n            raise TypeError(\"ZMQStream cannot track messages\")\r\n        if isinstance(msg_or_type, (Message, dict)):\r\n            msg = msg_or_type\r\n        else:\r\n            msg = self.msg(msg_or_type, content=content, parent=parent,\r\n                           subheader=subheader, header=header)\r\n        buffers = [] if buffers is None else buffers\r\n        to_send = self.serialize(msg, ident)\r\n        flag = 0\r\n        if buffers:\r\n            flag = zmq.SNDMORE\r\n            _track = False\r\n        else:\r\n            _track=track\r\n        if track:\r\n            tracker = stream.send_multipart(to_send, flag, copy=False, track=_track)\r\n        else:\r\n            tracker = stream.send_multipart(to_send, flag, copy=False)\r\n        for b in buffers[:-1]:\r\n            stream.send(b, flag, copy=False)\r\n        if buffers:\r\n            if track:\r\n                tracker = stream.send(buffers[-1], copy=False, track=track)\r\n            else:\r\n                tracker = stream.send(buffers[-1], copy=False)\r\n        if self.debug:\r\n            pprint.pprint(msg)\r\n            pprint.pprint(to_send)\r\n            pprint.pprint(buffers)\r\n        msg['tracker'] = tracker\r\n        return msg","reference":"Build and send a message via stream or socket.\n\n        The message format used by this function internally is as follows:\n\n        [ident1,ident2,...,DELIM,HMAC,p_header,p_parent,p_content,\n         buffer1,buffer2,...]\n\n        The serialize\/unserialize methods convert the nested message dict into this\n        format.\n\n        Parameters\n        ----------\n\n        stream : zmq.Socket or ZMQStream\n            The socket-like object used to send the data.\n        msg_or_type : str or Message\/dict\n            Normally, msg_or_type will be a msg_type unless a message is being\n            sent more than once. If a header is supplied, this can be set to\n            None and the msg_type will be pulled from the header.\n\n        content : dict or None\n            The content of the message (ignored if msg_or_type is a message).\n        header : dict or None\n            The header dict for the message (ignores if msg_to_type is a message).\n        parent : Message or dict or None\n            The parent or parent header describing the parent of this message\n            (ignored if msg_or_type is a message).\n        ident : bytes or list of bytes\n            The zmq.IDENTITY routing path.\n        subheader : dict or None\n            Extra header keys for this message's header (ignored if msg_or_type\n            is a message).\n        buffers : list or None\n            The already-serialized buffers to be appended to the message.\n        track : bool\n            Whether to track.  Only for use with Sockets, because ZMQStream\n            objects cannot track messages.\n\n        Returns\n        -------\n        msg : dict\n            The constructed message.\n        (msg,tracker) : (dict, MessageTracker)\n            if track=True, then a 2-tuple will be returned,\n            the first element being the constructed\n            message, and the second being the MessageTracker","result":"Send a message to a stream.","score":[5.233e-18,0.0116]}
{"code":"def send_raw(self, stream, msg_list, flags=0, copy=True, ident=None):\r\n        \"\"\" function to<extra_id_0>\r\n        to_send = []\r\n        if isinstance(ident, bytes):\r\n            ident = [ident]\r\n        if ident is not None:\r\n            to_send.extend(ident)\r\n        to_send.append(DELIM)\r\n        to_send.append(self.sign(msg_list))\r\n        to_send.extend(msg_list)\r\n        stream.send_multipart(msg_list, flags, copy=copy)","reference":"Send a raw message via ident path.\n\n        This method is used to send a already serialized message.\n\n        Parameters\n        ----------\n        stream : ZMQStream or Socket\n            The ZMQ stream or socket to use for sending the message.\n        msg_list : list\n            The serialized list of messages to send. This only includes the\n            [p_header,p_parent,p_content,buffer1,buffer2,...] portion of\n            the message.\n        ident : ident or list\n            A single ident or a list of idents to use in sending.","result":"Send raw message .","score":[0.0,0.0397]}
{"code":"def recv(self, socket, mode=zmq.NOBLOCK, content=True, copy=True):\r\n        \"\"\" function to<extra_id_0>\r\n        if isinstance(socket, ZMQStream):\r\n            socket = socket.socket\r\n        try:\r\n            msg_list = socket.recv_multipart(mode, copy=copy)\r\n        except zmq.ZMQError as e:\r\n            if e.errno == zmq.EAGAIN:\r\n                return None,None\r\n            else:\r\n                raise\r\n        idents, msg_list = self.feed_identities(msg_list, copy)\r\n        try:\r\n            return idents, self.unserialize(msg_list, content=content, copy=copy)\r\n        except Exception as e:\r\n            raise e","reference":"Receive and unpack a message.\n\n        Parameters\n        ----------\n        socket : ZMQStream or Socket\n            The socket or stream to use in receiving.\n\n        Returns\n        -------\n        [idents], msg\n            [idents] is a list of idents and msg is a nested message dict of\n            same format as self.msg returns.","result":"Receive messages from a socket.","score":[0.0001,0.0383]}
{"code":"def feed_identities(self, msg_list, copy=True):\r\n        \"\"\" function to<extra_id_0>\r\n        if copy:\r\n            idx = msg_list.index(DELIM)\r\n            return msg_list[:idx], msg_list[idx+1:]\r\n        else:\r\n            failed = True\r\n            for idx,m in enumerate(msg_list):\r\n                if m.bytes == DELIM:\r\n                    failed = False\r\n                    break\r\n            if failed:\r\n                raise ValueError(\"DELIM not in msg_list\")\r\n            idents, msg_list = msg_list[:idx], msg_list[idx+1:]\r\n            return [m.bytes for m in idents], msg_list","reference":"Split the identities from the rest of the message.\n\n        Feed until DELIM is reached, then return the prefix as idents and\n        remainder as msg_list. This is easily broken by setting an IDENT to DELIM,\n        but that would be silly.\n\n        Parameters\n        ----------\n        msg_list : a list of Message or bytes objects\n            The message to be split.\n        copy : bool\n            flag determining whether the arguments are bytes or Messages\n\n        Returns\n        -------\n        (idents, msg_list) : two lists\n            idents will always be a list of bytes, each of which is a ZMQ\n            identity. msg_list will be a list of bytes or zmq.Messages of the\n            form [HMAC,p_header,p_parent,p_content,buffer1,buffer2,...] and\n            should be unpackable\/unserializable via self.unserialize at this\n            point.","result":"Feed identities .","score":[1.126e-16,0.01]}
{"code":"def unserialize(self, msg_list, content=True, copy=True):\r\n        \"\"\" function to<extra_id_0>\r\n        minlen = 4\r\n        message = {}\r\n        if not copy:\r\n            for i in range(minlen):\r\n                msg_list[i] = msg_list[i].bytes\r\n        if self.auth is not None:\r\n            signature = msg_list[0]\r\n            if not signature:\r\n                raise ValueError(\"Unsigned Message\")\r\n            if signature in self.digest_history:\r\n                raise ValueError(\"Duplicate Signature: %r\"%signature)\r\n            self.digest_history.add(signature)\r\n            check = self.sign(msg_list[1:4])\r\n            if not signature == check:\r\n                raise ValueError(\"Invalid Signature: %r\"%signature)\r\n        if not len(msg_list) >= minlen:\r\n            raise TypeError(\"malformed message, must have at least %i elements\"%minlen)\r\n        header = self.unpack(msg_list[1])\r\n        message['header'] = header\r\n        message['msg_id'] = header['msg_id']\r\n        message['msg_type'] = header['msg_type']\r\n        message['parent_header'] = self.unpack(msg_list[2])\r\n        if content:\r\n            message['content'] = self.unpack(msg_list[3])\r\n        else:\r\n            message['content'] = msg_list[3]\r\n        message['buffers'] = msg_list[4:]\r\n        return message","reference":"Unserialize a msg_list to a nested message dict.\n\n        This is roughly the inverse of serialize. The serialize\/unserialize\n        methods work with full message lists, whereas pack\/unpack work with\n        the individual message parts in the message list.\n\n        Parameters:\n        -----------\n        msg_list : list of bytes or Message objects\n            The list of message parts of the form [HMAC,p_header,p_parent,\n            p_content,buffer1,buffer2,...].\n        content : bool (True)\n            Whether to unpack the content dict (True), or leave it packed\n            (False).\n        copy : bool (True)\n            Whether to return the bytes (True), or the non-copying Message\n            object in each place (False).\n\n        Returns\n        -------\n        msg : dict\n            The nested message dict with top-level keys [header, parent_header,\n            content, buffers].","result":"Unserialize a message list .","score":[0.0,0.0209]}
{"code":"def save_svg(string, parent=None):\r\n    \"\"\" function to<extra_id_0>\r\n    if isinstance(string, unicode):\r\n        string = string.encode('utf-8')\r\n    dialog = QtGui.QFileDialog(parent, 'Save SVG Document')\r\n    dialog.setAcceptMode(QtGui.QFileDialog.AcceptSave)\r\n    dialog.setDefaultSuffix('svg')\r\n    dialog.setNameFilter('SVG document (*.svg)')\r\n    if dialog.exec_():\r\n        filename = dialog.selectedFiles()[0]\r\n        f = open(filename, 'w')\r\n        try:\r\n            f.write(string)\r\n        finally:\r\n            f.close()\r\n        return filename\r\n    return None","reference":"Prompts the user to save an SVG document to disk.\n\n    Parameters:\n    -----------\n    string : basestring\n        A Python string containing a SVG document.\n\n    parent : QWidget, optional\n        The parent to use for the file dialog.\n\n    Returns:\n    --------\n    The name of the file to which the document was saved, or None if the save\n    was cancelled.","result":"Save SVG string to file .","score":[0.0001,0.0508]}
{"code":"def svg_to_clipboard(string):\r\n    \"\"\" function to<extra_id_0>\r\n    if isinstance(string, unicode):\r\n        string = string.encode('utf-8')\r\n    mime_data = QtCore.QMimeData()\r\n    mime_data.setData('image\/svg+xml', string)\r\n    QtGui.QApplication.clipboard().setMimeData(mime_data)","reference":"Copy a SVG document to the clipboard.\n\n    Parameters:\n    -----------\n    string : basestring\n        A Python string containing a SVG document.","result":"Copy SVG to clipboard .","score":[0.0192,0.0852]}
{"code":"def svg_to_image(string, size=None):\r\n    \"\"\" function to<extra_id_0>\r\n    if isinstance(string, unicode):\r\n        string = string.encode('utf-8')\r\n    renderer = QtSvg.QSvgRenderer(QtCore.QByteArray(string))\r\n    if not renderer.isValid():\r\n        raise ValueError('Invalid SVG data.')\r\n    if size is None:\r\n        size = renderer.defaultSize()\r\n    image = QtGui.QImage(size, QtGui.QImage.Format_ARGB32)\r\n    painter = QtGui.QPainter(image)\r\n    renderer.render(painter)\r\n    return image","reference":"Convert a SVG document to a QImage.\n\n    Parameters:\n    -----------\n    string : basestring\n        A Python string containing a SVG document.\n\n    size : QSize, optional\n        The size of the image that is produced. If not specified, the SVG\n        document's default size is used.\n    \n    Raises:\n    -------\n    ValueError\n        If an invalid SVG string is provided.\n\n    Returns:\n    --------\n    A QImage of format QImage.Format_ARGB32.","result":"Convert SVG to image .","score":[0.0,0.038]}
{"code":"def object_info(**kw):\r\n    \"\"\" function to<extra_id_0>\r\n    infodict = dict(izip_longest(info_fields, [None]))\r\n    infodict.update(kw)\r\n    return infodict","reference":"Make an object info dict with all fields present.","result":"Get object info .","score":[0.1294,0.3007]}
{"code":"def getdoc(obj):\r\n    \"\"\" function to<extra_id_0>\r\n    try:\r\n        ds = obj.getdoc()\r\n    except Exception:\r\n        pass\r\n    else:\r\n        if isinstance(ds, basestring):\r\n            return inspect.cleandoc(ds)\r\n        try:\r\n        return inspect.getdoc(obj)\r\n    except Exception:\r\n        return None","reference":"Stable wrapper around inspect.getdoc.\n\n    This can't crash because of attribute problems.\n\n    It also attempts to call a getdoc() method on the given object.  This\n    allows objects which provide their docstrings via non-standard mechanisms\n    (like Pyro proxies) to still be inspected by ipython's ? system.","result":"Get doc of an object .","score":[0.0003,0.0249]}
{"code":"def getsource(obj,is_binary=False):\r\n    \"\"\" function to<extra_id_0>\r\n    if is_binary:\r\n        return None\r\n    else:\r\n        if hasattr(obj,\"__wrapped__\"):\r\n            obj = obj.__wrapped__\r\n        try:\r\n            src = inspect.getsource(obj)\r\n        except TypeError:\r\n            if hasattr(obj,'__class__'):\r\n                src = inspect.getsource(obj.__class__)\r\n        return src","reference":"Wrapper around inspect.getsource.\n\n    This can be modified by other projects to provide customized source\n    extraction.\n\n    Inputs:\n\n    - obj: an object whose source code we will attempt to extract.\n\n    Optional inputs:\n\n    - is_binary: whether the object is known to come from a binary source.\n    This implementation will skip returning any output for binary objects, but\n    custom extractors may know how to meaningfully process them.","result":"Get source of object .","score":[0.0,0.0262]}
{"code":"def getargspec(obj):\r\n    \"\"\" function to<extra_id_0>\r\n    if inspect.isfunction(obj):\r\n        func_obj = obj\r\n    elif inspect.ismethod(obj):\r\n        func_obj = obj.im_func\r\n    elif hasattr(obj, '__call__'):\r\n        func_obj = obj.__call__\r\n    else:\r\n        raise TypeError('arg is not a Python function')\r\n    args, varargs, varkw = inspect.getargs(func_obj.func_code)\r\n    return args, varargs, varkw, func_obj.func_defaults","reference":"Get the names and default values of a function's arguments.\n\n    A tuple of four things is returned: (args, varargs, varkw, defaults).\n    'args' is a list of the argument names (it may contain nested lists).\n    'varargs' and 'varkw' are the names of the * and ** arguments or None.\n    'defaults' is an n-tuple of the default values of the last n arguments.\n\n    Modified version of inspect.getargspec from the Python Standard\n    Library.","result":"Get the function arguments .","score":[0.0,0.0236]}
{"code":"def call_tip(oinfo, format_call=True):\r\n    \"\"\" function to<extra_id_0>\r\n    argspec = oinfo.get('argspec')\r\n    if argspec is None:\r\n        call_line = None\r\n    else:\r\n        try:\r\n            has_self = argspec['args'][0] == 'self'\r\n        except (KeyError, IndexError):\r\n            pass\r\n        else:\r\n            if has_self:\r\n                argspec['args'] = argspec['args'][1:]\r\n        call_line = oinfo['name']+format_argspec(argspec)\r\n    doc = oinfo.get('call_docstring')\r\n    if doc is None:\r\n        doc = oinfo.get('init_docstring')\r\n    if doc is None:\r\n        doc = oinfo.get('docstring','')\r\n    return call_line, doc","reference":"Extract call tip data from an oinfo dict.\n\n    Parameters\n    ----------\n    oinfo : dict\n\n    format_call : bool, optional\n      If True, the call line is formatted and returned as a string.  If not, a\n      tuple of (name, argspec) is returned.\n\n    Returns\n    -------\n    call_info : None, str or (str, dict) tuple.\n      When format_call is True, the whole call information is formattted as a\n      single string.  Otherwise, the object's name and its argspec dict are\n      returned.  If no call information is available, None is returned.\n\n    docstring : str or None\n      The most relevant docstring for calling purposes is returned, if\n      available.  The priority is: call docstring for callable instances, then\n      constructor docstring for classes, then main object's docstring otherwise\n      (regular functions).","result":"Format call tip .","score":[0.0,0.0142]}
{"code":"def find_file(obj):\r\n    \"\"\" function to<extra_id_0>\r\n    if hasattr(obj, '__wrapped__'):\r\n        obj = obj.__wrapped__\r\n    fname = None\r\n    try:\r\n        fname = inspect.getabsfile(obj)\r\n    except TypeError:\r\n        if hasattr(obj, '__class__'):\r\n            try:\r\n                fname = inspect.getabsfile(obj.__class__)\r\n            except TypeError:\r\n                pass\r\n    except:\r\n        pass\r\n    return fname","reference":"Find the absolute path to the file where an object was defined.\n\n    This is essentially a robust wrapper around `inspect.getabsfile`.\n\n    Returns None if no file can be found.\n\n    Parameters\n    ----------\n    obj : any Python object\n\n    Returns\n    -------\n    fname : str\n      The absolute path to the file where the object was defined.","result":"Find file .","score":[0.0,0.0216]}
{"code":"def find_source_lines(obj):\r\n    \"\"\" function to<extra_id_0>\r\n    if hasattr(obj, '__wrapped__'):\r\n        obj = obj.__wrapped__\r\n        try:\r\n        try:\r\n            lineno = inspect.getsourcelines(obj)[1]\r\n        except TypeError:\r\n            if hasattr(obj, '__class__'):\r\n                lineno = inspect.getsourcelines(obj.__class__)[1]\r\n    except:\r\n        return None\r\n    return lineno","reference":"Find the line number in a file where an object was defined.\n\n    This is essentially a robust wrapper around `inspect.getsourcelines`.\n\n    Returns None if no file can be found.\n\n    Parameters\n    ----------\n    obj : any Python object\n\n    Returns\n    -------\n    lineno : int\n      The line number where the object definition starts.","result":"Find source lines .","score":[0.0,0.0229]}
{"code":"def _getdef(self,obj,oname=''):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            hdef = oname + inspect.formatargspec(*getargspec(obj))\r\n            return py3compat.unicode_to_str(hdef, 'ascii')\r\n        except:\r\n            return None","reference":"Return the definition header for any callable object.\n\n        If any exception is generated, None is returned instead and the\n        exception is suppressed.","result":"Get the definition of an object .","score":[0.0268,0.0488]}
{"code":"def __head(self,h):\r\n        \"\"\" function to<extra_id_0>\r\n        return '%s%s%s' % (self.color_table.active_colors.header,h,\r\n                           self.color_table.active_colors.normal)","reference":"Return a header string with proper colors.","result":"Return header text .","score":[0.1795,0.1493]}
{"code":"def noinfo(self, msg, oname):\r\n        \"\"\" function to<extra_id_0>\r\n        print 'No %s found' % msg,\r\n        if oname:\r\n            print 'for %s' % oname\r\n        else:\r\n            print","reference":"Generic message when no information is found.","result":"Def print a message .","score":[0.1611,0.0735]}
{"code":"def pdef(self, obj, oname=''):\r\n        \"\"\" function to<extra_id_0>\r\n        if not callable(obj):\r\n            print 'Object is not callable.'\r\n            return\r\n        header = ''\r\n        if inspect.isclass(obj):\r\n            header = self.__head('Class constructor information:\\n')\r\n            obj = obj.__init__\r\n        elif (not py3compat.PY3) and type(obj) is types.InstanceType:\r\n            obj = obj.__call__\r\n        output = self._getdef(obj,oname)\r\n        if output is None:\r\n            self.noinfo('definition header',oname)\r\n        else:\r\n            print >>io.stdout, header,self.format(output),","reference":"Print the definition header for any callable object.\n\n        If the object is a class, print the constructor information.","result":"Print the definition of a callable object.","score":[0.0883,0.3024]}
{"code":"def pdoc(self,obj,oname='',formatter = None):\r\n        \"\"\" function to<extra_id_0>\r\n        head = self.__head\r\n        lines = []\r\n        ds = getdoc(obj)\r\n        if formatter:\r\n            ds = formatter(ds)\r\n        if ds:\r\n            lines.append(head(\"Class Docstring:\"))\r\n            lines.append(indent(ds))\r\n        if inspect.isclass(obj) and hasattr(obj, '__init__'):\r\n            init_ds = getdoc(obj.__init__)\r\n            if init_ds is not None:\r\n                lines.append(head(\"Constructor Docstring:\"))\r\n                lines.append(indent(init_ds))\r\n        elif hasattr(obj,'__call__'):\r\n            call_ds = getdoc(obj.__call__)\r\n            if call_ds:\r\n                lines.append(head(\"Calling Docstring:\"))\r\n                lines.append(indent(call_ds))\r\n        if not lines:\r\n            self.noinfo('documentation',oname)\r\n        else:\r\n            page.page('\\n'.join(lines))","reference":"Print the docstring for any object.\n\n        Optional:\n        -formatter: a function to run the docstring through for specially\n        formatted docstrings.\n\n        Examples\n        --------\n\n        In [1]: class NoInit:\n           ...:     pass\n\n        In [2]: class NoDoc:\n           ...:     def __init__(self):\n           ...:         pass\n\n        In [3]: %pdoc NoDoc\n        No documentation found for NoDoc\n\n        In [4]: %pdoc NoInit\n        No documentation found for NoInit\n\n        In [5]: obj = NoInit()\n\n        In [6]: %pdoc obj\n        No documentation found for obj\n\n        In [5]: obj2 = NoDoc()\n\n        In [6]: %pdoc obj2\n        No documentation found for obj2","result":"Print documentation of an object .","score":[0.0,0.0134]}
{"code":"def psource(self,obj,oname=''):\r\n        \"\"\" function to<extra_id_0>\r\n        linecache.checkcache()\r\n        try:\r\n            src = getsource(obj)\r\n        except:\r\n            self.noinfo('source',oname)\r\n        else:\r\n            page.page(self.format(py3compat.unicode_to_str(src)))","reference":"Print the source code for an object.","result":"Display source code .","score":[0.2134,0.2799]}
{"code":"def pfile(self, obj, oname=''):\r\n                \"\"\" function to<extra_id_0>\r\n                lineno = find_source_lines(obj)\r\n        if lineno is None:\r\n            self.noinfo('file', oname)\r\n            return\r\n        ofile = find_file(obj)\r\n        if ofile.endswith(('.so', '.dll', '.pyd')):\r\n            print 'File %r is binary, not printing.' % ofile\r\n        elif not os.path.isfile(ofile):\r\n            print 'File %r does not exist, not printing.' % ofile\r\n        else:\r\n            page.page(self.format(open(ofile).read()), lineno-1)","reference":"Show the whole file where an object was defined.","result":"Def print a file .","score":[0.108,0.0581]}
{"code":"def _format_fields(self, fields, title_width=12):\r\n        \"\"\" function to<extra_id_0>\r\n        out = []\r\n        header = self.__head\r\n        for title, content in fields:\r\n            if len(content.splitlines()) > 1:\r\n                title = header(title + \":\") + \"\\n\"\r\n            else:\r\n                title = header((title+\":\").ljust(title_width))\r\n            out.append(title + content)\r\n        return \"\\n\".join(out)","reference":"Formats a list of fields for display.\n\n        Parameters\n        ----------\n        fields : list\n          A list of 2-tuples: (field_title, field_content)\n        title_width : int\n          How many characters to pad titles to. Default 12.","result":"Format fields .","score":[0.0001,0.0366]}
{"code":"def pinfo(self,obj,oname='',formatter=None,info=None,detail_level=0):\r\n        \"\"\" function to<extra_id_0>\r\n        info = self.info(obj, oname=oname, formatter=formatter,\r\n                            info=info, detail_level=detail_level)\r\n        displayfields = []\r\n        def add_fields(fields):\r\n            for title, key in fields:\r\n                field = info[key]\r\n                if field is not None:\r\n                    displayfields.append((title, field.rstrip()))\r\n                add_fields(self.pinfo_fields1)\r\n                if (not py3compat.PY3) and isinstance(obj, types.InstanceType) and info['base_class']:\r\n            displayfields.append((\"Base Class\", info['base_class'].rstrip()))\r\n                add_fields(self.pinfo_fields2)\r\n                if info['namespace'] != 'Interactive':\r\n            displayfields.append((\"Namespace\", info['namespace'].rstrip()))\r\n        add_fields(self.pinfo_fields3)\r\n                if detail_level > 0 and info['source'] is not None:\r\n            displayfields.append((\"Source\", self.format(py3compat.cast_bytes_py2(info['source']))))\r\n        elif info['docstring'] is not None:\r\n            displayfields.append((\"Docstring\", info[\"docstring\"]))\r\n        if info['isclass']:\r\n            if info['init_definition'] or info['init_docstring']:\r\n                displayfields.append((\"Constructor information\", \"\"))\r\n                if info['init_definition'] is not None:\r\n                    displayfields.append((\" Definition\",\r\n                                    info['init_definition'].rstrip()))\r\n                if info['init_docstring'] is not None:\r\n                    displayfields.append((\" Docstring\",\r\n                                        indent(info['init_docstring'])))\r\n        else:\r\n            add_fields(self.pinfo_fields_obj)\r\n        if displayfields:\r\n            page.page(self._format_fields(displayfields))","reference":"Show detailed information about an object.\n\n        Optional arguments:\n\n        - oname: name of the variable pointing to the object.\n\n        - formatter: special formatter for docstrings (see pdoc)\n\n        - info: a structure with some information fields which may have been\n        precomputed already.\n\n        - detail_level: if set to 1, more information is given.","result":"Display the object.","score":[0.0,0.0564]}
{"code":"def psearch(self,pattern,ns_table,ns_search=[],\r\n                \"\"\" function to<extra_id_0>\r\n                ignore_case=False,show_all=False):\r\n     type_pattern = 'all'\r\n        filter = ''\r\n        cmds = pattern.split()\r\n        len_cmds  =  len(cmds)\r\n        if len_cmds == 1:\r\n            filter = cmds[0]\r\n        elif len_cmds == 2:\r\n            filter,type_pattern = cmds\r\n        else:\r\n            raise ValueError('invalid argument string for psearch: <%s>' %\r\n                             pattern)\r\n        for name in ns_search:\r\n            if name not in ns_table:\r\n                raise ValueError('invalid namespace <%s>. Valid names: %s' %\r\n                                 (name,ns_table.keys()))\r\n   search_result, namespaces_seen = set(), set()\r\n        for ns_name in ns_search:\r\n            ns = ns_table[ns_name]\r\n            if id(ns) in namespaces_seen:\r\n                continue\r\n            namespaces_seen.add(id(ns))\r\n            tmp_res = list_namespace(ns, type_pattern, filter,\r\n                                    ignore_case=ignore_case, show_all=show_all)\r\n            search_result.update(tmp_res)\r\n        page.page('\\n'.join(sorted(search_result)))","reference":"Search namespaces with wildcards for objects.\n\n        Arguments:\n\n        - pattern: string containing shell-like wildcards to use in namespace\n        searches and optionally a type specification to narrow the search to\n        objects of that type.\n\n        - ns_table: dict of name->namespaces for search.\n\n        Optional arguments:\n\n          - ns_search: list of namespace names to include in search.\n\n          - ignore_case(False): make the search case-insensitive.\n\n          - show_all(False): show all names, including those starting with\n          underscores.","result":"Search namespaces .","score":[0.0,0.0165]}
{"code":"def threaded_reactor():\r\n    \"\"\" function to<extra_id_0>\r\n    global _twisted_thread\r\n    try:\r\n        from twisted.internet import reactor\r\n    except ImportError:\r\n        return None, None\r\n    if not _twisted_thread:\r\n        from twisted.python import threadable\r\n        from threading import Thread\r\n        _twisted_thread = Thread(target=lambda: reactor.run( \\\r\n                installSignalHandlers=False))\r\n        _twisted_thread.setDaemon(True)\r\n        _twisted_thread.start()\r\n    return reactor, _twisted_thread","reference":"Start the Twisted reactor in a separate thread, if not already done.\n    Returns the reactor.\n    The thread will automatically be destroyed when all the tests are done.","result":"Return a reactor and thread .","score":[0.0077,0.0803]}
{"code":"def deferred(timeout=None):\r\n    \"\"\" function to<extra_id_0>\r\n    reactor, reactor_thread = threaded_reactor()\r\n    if reactor is None:\r\n        raise ImportError(\"twisted is not available or could not be imported\")\r\n    try:\r\n        timeout is None or timeout + 0\r\n    except TypeError:\r\n        raise TypeError(\"'timeout' argument must be a number or None\")\r\n    def decorate(func):\r\n        def wrapper(*args, **kargs):\r\n            q = Queue()\r\n            def callback(value):\r\n                q.put(None)\r\n            def errback(failure):\r\n                try:\r\n                    failure.raiseException()\r\n                except:\r\n                    q.put(sys.exc_info())\r\n            def g():\r\n                try:\r\n                    d = func(*args, **kargs)\r\n                    try:\r\n                        d.addCallbacks(callback, errback)\r\n                    except AttributeError:\r\n                        raise TypeError(\"you must return a twisted Deferred \"\r\n                                        \"from your test case!\")\r\n                except:\r\n                    q.put(sys.exc_info())\r\n            reactor.callFromThread(g)\r\n            try:\r\n                error = q.get(timeout=timeout)\r\n            except Empty:\r\n                raise TimeExpired(\"timeout expired before end of test (%f s.)\"\r\n                                  % timeout)\r\n            if error is not None:\r\n                exc_type, exc_value, tb = error\r\n                raise exc_type, exc_value, tb\r\n        wrapper = make_decorator(func)(wrapper)\r\n        return wrapper\r\n    return decorate","reference":"By wrapping a test function with this decorator, you can return a\n    twisted Deferred and the test will wait for the deferred to be triggered.\n    The whole test function will run inside the Twisted event loop.\n\n    The optional timeout parameter specifies the maximum duration of the test.\n    The difference with timed() is that timed() will still wait for the test\n    to end, while deferred() will stop the test when its timeout has expired.\n    The latter is more desireable when dealing with network tests, because\n    the result may actually never arrive.\n\n    If the callback is triggered, the test has passed.\n    If the errback is triggered or the timeout expires, the test has failed.\n\n    Example::\n    \n        @deferred(timeout=5.0)\n        def test_resolve():\n            return reactor.resolve(\"www.python.org\")\n\n    Attention! If you combine this decorator with other decorators (like\n    \"raises\"), deferred() must be called *first*!\n\n    In other words, this is good::\n        \n        @raises(DNSLookupError)\n        @deferred()\n        def test_error():\n            return reactor.resolve(\"xxxjhjhj.biz\")\n\n    and this is bad::\n        \n        @deferred()\n        @raises(DNSLookupError)\n        def test_error():\n            return reactor.resolve(\"xxxjhjhj.biz\")","result":"Wrap a function in a twisted Deferred .","score":[0.0,0.034]}
{"code":"def find_best_string(query,\r\n                     \"\"\" function to<extra_id_0>\r\n                     corpus,\r\n                     step=4,\r\n                     flex=3,\r\n                     case_sensitive=False):\r\n    def ratio(a, b):\r\n        return SequenceMatcher(None, a, b).ratio()\r\n    def scan_corpus(step):\r\n        match_values = []\r\n        m = 0\r\n        while m + qlen - step <= len(corpus):\r\n            match_values.append(ratio(query, corpus[m : m-1+qlen]))\r\n            m += step\r\n        return match_values\r\n    def index_max(v):\r\n        return max(range(len(v)), key=v.__getitem__)\r\n    def adjust_left_right_positions():\r\n        p_l, bp_l = [pos] * 2\r\n        p_r, bp_r = [pos + qlen] * 2\r\n        bmv_l = match_values[round_decimal(p_l \/ step)]\r\n        bmv_r = match_values[round_decimal(p_r \/ step)]\r\n        for f in range(flex):\r\n            ll = ratio(query, corpus[p_l - f: p_r])\r\n            if ll > bmv_l:\r\n                bmv_l = ll\r\n                bp_l = p_l - f\r\n            lr = ratio(query, corpus[p_l + f: p_r])\r\n            if lr > bmv_l:\r\n                bmv_l = lr\r\n                bp_l = p_l + f\r\n            rl = ratio(query, corpus[p_l: p_r - f])\r\n            if rl > bmv_r:\r\n                bmv_r = rl\r\n                bp_r = p_r - f\r\n            rr = ratio(query, corpus[p_l: p_r + f])\r\n            if rr > bmv_r:\r\n                bmv_r = rr\r\n                bp_r = p_r + f\r\n        return bp_l, bp_r, ratio(query, corpus[bp_l : bp_r])\r\n    if not case_sensitive:\r\n        query = query.lower()\r\n        corpus = corpus.lower()\r\n    qlen = len(query)\r\n    if flex >= qlen\/2:\r\n        print(\"Warning: flex exceeds length of query \/ 2. Setting to default.\")\r\n        flex = 3\r\n    match_values = scan_corpus(step)\r\n    pos = index_max(match_values) * step\r\n    pos_left, pos_right, match_value = adjust_left_right_positions()\r\n    return corpus[pos_left: pos_right].strip(), match_value","reference":"Return best matching substring of corpus.\n\n    Parameters\n    ----------\n    query : str\n    corpus : str\n    step : int\n        Step size of first match-value scan through corpus. Can be thought of\n        as a sort of \"scan resolution\". Should not exceed length of query.\n    flex : int\n        Max. left\/right substring position adjustment value. Should not\n        exceed length of query \/ 2.\n\n    Outputs\n    -------\n    output0 : str\n        Best matching substring.\n    output1 : float\n        Match ratio of best matching substring. 1 is perfect match.","result":"Find best string .","score":[0.0,0.007]}
{"code":"def to_string(self, indent=True, declaration=True):\r\n        \"\"\" function to<extra_id_0>\r\n        return etree.tostring(self.to_xml(),\r\n                              encoding=self.encoding,\r\n                              xml_declaration=declaration,\r\n                              pretty_print=indent\r\n                              )","reference":"Encodes the stored ``data`` to XML and returns a\n        ``string``.\n\n        Setting ``indent`` to ``False`` will forego any pretty-printing\n        and return a condensed value.\n\n        Setting ``declaration`` to ``False`` will skip inserting the\n        XML declaration.","result":"Return string representation of the object .","score":[0.0039,0.0329]}
{"code":"def to_xml(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.data:\r\n            self.document = self._update_document(self.document, self.data)\r\n        return self.document","reference":"Encodes the stored ``data`` to XML and returns\n        an ``lxml.etree`` value.","result":"Convert object to xml .","score":[0.0724,0.1803]}
{"code":"def load_all_modules_in_packages(package_or_set_of_packages):\r\n    \"\"\" function to<extra_id_0>\r\n    if isinstance(package_or_set_of_packages, types.ModuleType):\r\n        packages = [package_or_set_of_packages]\r\n    elif isinstance(package_or_set_of_packages, Iterable) and not isinstance(package_or_set_of_packages, (dict, str)):\r\n        packages = package_or_set_of_packages\r\n    else:\r\n        raise Exception(\"This function only accepts a module reference, or an iterable of said objects\")\r\n    imported = packages.copy()\r\n    for package in packages:\r\n        if not hasattr(package, '__path__'):\r\n            raise Exception(\r\n                'Package object passed in has no __path__ attribute. '\r\n                'Make sure to pass in imported references to the packages in question.'\r\n            )\r\n        for module_finder, name, ispkg in pkgutil.walk_packages(package.__path__):\r\n            module_name = '{}.{}'.format(package.__name__, name)\r\n            current_module = importlib.import_module(module_name)\r\n            imported.append(current_module)\r\n            if ispkg:\r\n                imported += load_all_modules_in_packages(current_module)\r\n    for module in imported:\r\n        dir(module)\r\n    return list(\r\n        {\r\n            module.__name__: module\r\n            for module in imported\r\n        }.values()\r\n    )","reference":"Recursively loads all modules from a package object, or set of package objects\n\n    :param package_or_set_of_packages: package object, or iterable of package objects\n    :return: list of all unique modules discovered by the function","result":"Load all modules in a list of packages .","score":[0.0186,0.1615]}
{"code":"def __dict_invert(self, data):\r\n        \"\"\" function to<extra_id_0>\r\n        outdict = {}\r\n        for k,lst in data.items():\r\n            if isinstance(lst, str):\r\n                lst = lst.split()\r\n            for entry in lst:\r\n                outdict[entry] = k\r\n        return outdict","reference":"Helper function for merge.\n\n        Takes a dictionary whose values are lists and returns a dict with\n        the elements of each list as keys and the original keys as values.","result":"If not isinstance.","score":[0,0.0]}
{"code":"def merge(self, __loc_data__=None, __conflict_solve=None, **kw):\r\n        \"\"\" function to<extra_id_0>\r\n        data_dict = dict(__loc_data__,**kw)\r\n        preserve = lambda old,new: old\r\n        update   = lambda old,new: new\r\n        add      = lambda old,new: old + new\r\n        add_flip = lambda old,new: new + old\r\n        add_s    = lambda old,new: old + ' ' + new\r\n        conflict_solve = list2dict2(self.keys(), default = preserve)\r\n        if __conflict_solve:\r\n            inv_conflict_solve_user = __conflict_solve.copy()\r\n            for name, func in [('preserve',preserve), ('update',update),\r\n                               ('add',add), ('add_flip',add_flip),\r\n                               ('add_s',add_s)]:\r\n                if name in inv_conflict_solve_user.keys():\r\n                    inv_conflict_solve_user[func] = inv_conflict_solve_user[name]\r\n                    del inv_conflict_solve_user[name]\r\n            conflict_solve.update(self.__dict_invert(inv_conflict_solve_user))\r\n        for key in data_dict:\r\n            if key not in self:\r\n                self[key] = data_dict[key]\r\n            else:\r\n                self[key] = conflict_solve[key](self[key],data_dict[key])","reference":"Merge two Structs with customizable conflict resolution.\n\n        This is similar to :meth:`update`, but much more flexible. First, a\n        dict is made from data+key=value pairs. When merging this dict with\n        the Struct S, the optional dictionary 'conflict' is used to decide\n        what to do.\n\n        If conflict is not given, the default behavior is to preserve any keys\n        with their current value (the opposite of the :meth:`update` method's\n        behavior).\n\n        Parameters\n        ----------\n        __loc_data : dict, Struct\n            The data to merge into self\n        __conflict_solve : dict\n            The conflict policy dict.  The keys are binary functions used to\n            resolve the conflict and the values are lists of strings naming\n            the keys the conflict resolution function applies to.  Instead of\n            a list of strings a space separated string can be used, like\n            'a b c'.\n        kw : dict\n            Additional key, value pairs to merge in\n\n        Notes\n        -----\n\n        The `__conflict_solve` dict is a dictionary of binary functions which will be used to\n        solve key conflicts.  Here is an example::\n\n            __conflict_solve = dict(\n                func1=['a','b','c'],\n                func2=['d','e']\n            )\n\n        In this case, the function :func:`func1` will be used to resolve\n        keys 'a', 'b' and 'c' and the function :func:`func2` will be used for\n        keys 'd' and 'e'.  This could also be written as::\n\n            __conflict_solve = dict(func1='a b c',func2='d e')\n\n        These functions will be called for each key they apply to with the\n        form::\n\n            func1(self['a'], other['a'])\n\n        The return value is used as the final merged value.\n\n        As a convenience, merge() provides five (the most commonly needed)\n        pre-defined policies: preserve, update, add, add_flip and add_s. The\n        easiest explanation is their implementation::\n\n            preserve = lambda old,new: old\n            update   = lambda old,new: new\n            add      = lambda old,new: old + new\n            add_flip = lambda old,new: new + old  # note change of order!\n            add_s    = lambda old,new: old + ' ' + new  # only for str!\n\n        You can use those four words (as strings) as keys instead\n        of defining them as functions, and the merge method will substitute\n        the appropriate functions for you.\n\n        For more complicated conflict resolution policies, you still need to\n        construct your own functions.\n\n        Examples\n        --------\n\n        This show the default policy:\n\n        >>> s = Struct(a=10,b=30)\n        >>> s2 = Struct(a=20,c=40)\n        >>> s.merge(s2)\n        >>> sorted(s.items())\n        [('a', 10), ('b', 30), ('c', 40)]\n\n        Now, show how to specify a conflict dict:\n\n        >>> s = Struct(a=10,b=30)\n        >>> s2 = Struct(a=20,b=40)\n        >>> conflict = {'update':'a','add':'b'}\n        >>> s.merge(s2,conflict)\n        >>> sorted(s.items())\n        [('a', 20), ('b', 70)]","result":"Merge data .","score":[8.677e-58,0.0028]}
{"code":"def object_to_primitive(obj):\r\n    \"\"\" function to<extra_id_0>\r\n    '''\r\n    convert object to primitive type so we can serialize it to data format like python.\r\n    all primitive types: dict, list, int, float, bool, str, None\r\n    '''\r\n    if obj is None:\r\n        return obj\r\n    if isinstance(obj, (int, float, bool, str)):\r\n        return obj\r\n    if isinstance(obj, (list, frozenset, set)):\r\n        return [object_to_primitive(x) for x in obj]\r\n    if isinstance(obj, dict):\r\n        return dict([(object_to_primitive(k), object_to_primitive(v)) for k, v in obj.items()])\r\n    data = vars(obj)\r\n    assert isinstance(data, dict)\r\n    return object_to_primitive(data)","reference":"convert object to primitive type so we can serialize it to data format like python.\n\n    all primitive types: dict, list, int, float, bool, str, None","result":"Convert object to primitive type.","score":[0.0091,0.1372]}
{"code":"def format2(self, raw, out = None, scheme = ''):\r\n        \"\"\" function to<extra_id_0>\r\n        string_output = 0\r\n        if out == 'str' or self.out == 'str' or \\\r\n           isinstance(self.out,StringIO.StringIO):\r\n            out_old = self.out\r\n            self.out = StringIO.StringIO()\r\n            string_output = 1\r\n        elif out is not None:\r\n            self.out = out\r\n        if scheme == 'NoColor':\r\n            error = False\r\n            self.out.write(raw)\r\n            if string_output:\r\n                return raw,error\r\n            else:\r\n                return None,error\r\n        colors = self.color_table[scheme].colors\r\n        self.colors = colors\r\n        self.raw = raw.expandtabs().rstrip()\r\n        self.lines = [0, 0]\r\n        pos = 0\r\n        raw_find = self.raw.find\r\n        lines_append = self.lines.append\r\n        while 1:\r\n            pos = raw_find('\\n', pos) + 1\r\n            if not pos: break\r\n            lines_append(pos)\r\n        lines_append(len(self.raw))\r\n        self.pos = 0\r\n        text = StringIO.StringIO(self.raw)\r\n        error = False\r\n        try:\r\n            for atoken in generate_tokens(text.readline):\r\n                self(*atoken)\r\n        except tokenize.TokenError as ex:\r\n            msg = ex.args[0]\r\n            line = ex.args[1][0]\r\n            self.out.write(\"%s\\n\\n*** ERROR: %s%s%s\\n\" %\r\n                           (colors[token.ERRORTOKEN],\r\n                            msg, self.raw[self.lines[line]:],\r\n                            colors.normal)\r\n                           )\r\n            error = True\r\n        self.out.write(colors.normal+'\\n')\r\n        if string_output:\r\n            output = self.out.getvalue()\r\n            self.out = out_old\r\n            return (output, error)\r\n        return (None, error)","reference":"Parse and send the colored source.\n\n        If out and scheme are not specified, the defaults (given to\n        constructor) are used.\n\n        out should be a file-type object. Optionally, out can be given as the\n        string 'str' and the parser will automatically return the output in a\n        string.","result":"Format a string .","score":[0.0,0.0239]}
{"code":"def getfigs(*fig_nums):\r\n    \"\"\" function to<extra_id_0>\r\n    from matplotlib._pylab_helpers import Gcf\r\n    if not fig_nums:\r\n        fig_managers = Gcf.get_all_fig_managers()\r\n        return [fm.canvas.figure for fm in fig_managers]\r\n    else:\r\n        figs = []\r\n        for num in fig_nums:\r\n            f = Gcf.figs.get(num)\r\n            if f is None:\r\n                print('Warning: figure %s not available.' % num)\r\n            else:\r\n                figs.append(f.canvas.figure)\r\n        return figs","reference":"Get a list of matplotlib figures by figure numbers.\n\n    If no arguments are given, all available figures are returned.  If the\n    argument list contains references to invalid figures, a warning is printed\n    but the function continues pasting further figures.\n\n    Parameters\n    ----------\n    figs : tuple\n        A tuple of ints giving the figure numbers of the figures to return.","result":"Get figs from matplotlib .","score":[0.0,0.029]}
{"code":"def print_figure(fig, fmt='png'):\r\n    \"\"\" function to<extra_id_0>\r\n    if not fig.axes and not fig.lines:\r\n        return\r\n    fc = fig.get_facecolor()\r\n    ec = fig.get_edgecolor()\r\n    fig.set_facecolor('white')\r\n    fig.set_edgecolor('white')\r\n    try:\r\n        bytes_io = BytesIO()\r\n        fig.canvas.print_figure(bytes_io, format=fmt, bbox_inches='tight')\r\n        data = bytes_io.getvalue()\r\n    finally:\r\n        fig.set_facecolor(fc)\r\n        fig.set_edgecolor(ec)\r\n    return data","reference":"Convert a figure to svg or png for inline display.","result":"Print a matplotlib figure .","score":[0.1051,0.1053]}
{"code":"def mpl_runner(safe_execfile):\r\n        \"\"\" function to<extra_id_0>\r\n        def mpl_execfile(fname,*where,**kw):\r\n        import matplotlib\r\n        import matplotlib.pylab as pylab\r\n    is_interactive = matplotlib.rcParams['interactive']\r\n        matplotlib.interactive(False)\r\n        safe_execfile(fname,*where,**kw)\r\n        matplotlib.interactive(is_interactive)\r\n        if pylab.draw_if_interactive.called:\r\n            pylab.draw()\r\n            pylab.draw_if_interactive.called = False\r\n    return mpl_execfile","reference":"Factory to return a matplotlib-enabled runner for %run.\n\n    Parameters\n    ----------\n    safe_execfile : function\n      This must be a function with the same interface as the\n      :meth:`safe_execfile` method of IPython.\n\n    Returns\n    -------\n    A function suitable for use as the ``runner`` argument of the %run magic\n    function.","result":"Def run mpl runner .","score":[0.0001,0.0249]}
{"code":"def select_figure_format(shell, fmt):\r\n    \"\"\" function to<extra_id_0>\r\n    from matplotlib.figure import Figure\r\n    from IPython.zmq.pylab import backend_inline\r\n    svg_formatter = shell.display_formatter.formatters['image\/svg+xml']\r\n    png_formatter = shell.display_formatter.formatters['image\/png']\r\n    if fmt=='png':\r\n        svg_formatter.type_printers.pop(Figure, None)\r\n        png_formatter.for_type(Figure, lambda fig: print_figure(fig, 'png'))\r\n    elif fmt=='svg':\r\n        png_formatter.type_printers.pop(Figure, None)\r\n        svg_formatter.for_type(Figure, lambda fig: print_figure(fig, 'svg'))\r\n    else:\r\n        raise ValueError(\"supported formats are: 'png', 'svg', not %r\"%fmt)\r\n    backend_inline._figure_format = fmt","reference":"Select figure format for inline backend, either 'png' or 'svg'.\n\n    Using this method ensures only one figure format is active at a time.","result":"Select figure format .","score":[0.0057,0.1211]}
{"code":"def find_gui_and_backend(gui=None):\r\n    \"\"\" function to<extra_id_0>\r\n    import matplotlib\r\n    if gui and gui != 'auto':\r\n        backend = backends[gui]\r\n    else:\r\n        backend = matplotlib.rcParams['backend']\r\n        gui = backend2gui.get(backend, None)\r\n    return gui, backend","reference":"Given a gui string return the gui and mpl backend.\n\n    Parameters\n    ----------\n    gui : str\n        Can be one of ('tk','gtk','wx','qt','qt4','inline').\n\n    Returns\n    -------\n    A tuple of (gui, backend) where backend is one of ('TkAgg','GTKAgg',\n    'WXAgg','Qt4Agg','module:\/\/IPython.zmq.pylab.backend_inline').","result":"Def find gui and backend .","score":[0.0028,0.0481]}
{"code":"def activate_matplotlib(backend):\r\n    \"\"\" function to<extra_id_0>\r\n    import matplotlib\r\n    if backend.startswith('module:\/\/'):\r\n        matplotlib.rcParams['backend'] = backend\r\n    else:\r\n        matplotlib.use(backend)\r\n    matplotlib.interactive(True)\r\n    import matplotlib.pylab as pylab\r\n    pylab.show._needmain = False\r\n    pylab.draw_if_interactive = flag_calls(pylab.draw_if_interactive)","reference":"Activate the given backend and set interactive to True.","result":"Activate matplotlib .","score":[0.0553,0.0595]}
{"code":"def configure_inline_support(shell, backend, user_ns=None):\r\n    \"\"\" function to<extra_id_0>\r\n    try:\r\n        from IPython.zmq.pylab.backend_inline import InlineBackend\r\n    except ImportError:\r\n        return\r\n    user_ns = shell.user_ns if user_ns is None else user_ns\r\n        cfg = InlineBackend.instance(config=shell.config)\r\n    cfg.shell = shell\r\n    if cfg not in shell.configurables:\r\n        shell.configurables.append(cfg)\r\n    if backend == backends['inline']:\r\n        from IPython.zmq.pylab.backend_inline import flush_figures\r\n        from matplotlib import pyplot\r\n        shell.register_post_execute(flush_figures)\r\n        pyplot.rcParams.update(cfg.rc)\r\n        user_ns['figsize'] = pyplot.figsize = figsize\r\n    fmt = cfg.figure_format\r\n    select_figure_format(shell, fmt)\r\n    from IPython.core.display import display\r\n    user_ns['display'] = display\r\n    user_ns['getfigs'] = getfigs","reference":"Configure an IPython shell object for matplotlib use.\n\n    Parameters\n    ----------\n    shell : InteractiveShell instance\n\n    backend : matplotlib backend\n\n    user_ns : dict\n      A namespace where all configured variables will be placed.  If not given,\n      the `user_ns` attribute of the shell object is used.","result":"Configure inline support .","score":[0.0,0.0131]}
{"code":"def pylab_activate(user_ns, gui=None, import_all=True, shell=None):\r\n    \"\"\" function to<extra_id_0>\r\n    gui, backend = find_gui_and_backend(gui)\r\n    activate_matplotlib(backend)\r\n    import_pylab(user_ns, import_all)\r\n    if shell is not None:\r\n        configure_inline_support(shell, backend, user_ns)\r\n            print \"\"\"\r\nWelcome to pylab, a matplotlib-based Python environment [backend: %s].\r\nFor more information, type 'help(pylab)'.\"\"\" % backend\r\n    sys.stdout.flush()\r\n        return gui","reference":"Activate pylab mode in the user's namespace.\n\n    Loads and initializes numpy, matplotlib and friends for interactive use.\n\n    Parameters\n    ----------\n    user_ns : dict\n      Namespace where the imports will occur.\n\n    gui : optional, string\n      A valid gui name following the conventions of the %gui magic.\n\n    import_all : optional, boolean\n      If true, an 'import *' is done from numpy and pylab.\n\n    Returns\n    -------\n    The actual gui used (if not given as input, it was obtained from matplotlib\n    itself, and will be needed next to configure IPython's gui integration.","result":"Activate a matplotlib environment .","score":[0.0,0.0195]}
{"code":"def _trace(self, frame, event, arg_unused):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.stopped:\r\n            return\r\n        if 0:\r\n            sys.stderr.write(\"trace event: %s %r @%d\\n\" % (\r\n                event, frame.f_code.co_filename, frame.f_lineno\r\n            ))\r\n        if self.last_exc_back:\r\n            if frame == self.last_exc_back:\r\n                if self.arcs and self.cur_file_data:\r\n                    pair = (self.last_line, -self.last_exc_firstlineno)\r\n                    self.cur_file_data[pair] = None\r\n                self.cur_file_data, self.last_line = self.data_stack.pop()\r\n            self.last_exc_back = None\r\n        if event == 'call':\r\n            self.data_stack.append((self.cur_file_data, self.last_line))\r\n            filename = frame.f_code.co_filename\r\n            if filename not in self.should_trace_cache:\r\n                tracename = self.should_trace(filename, frame)\r\n                self.should_trace_cache[filename] = tracename\r\n            else:\r\n                tracename = self.should_trace_cache[filename]\r\n            if tracename:\r\n                if tracename not in self.data:\r\n                    self.data[tracename] = {}\r\n                self.cur_file_data = self.data[tracename]\r\n            else:\r\n                self.cur_file_data = None\r\n            self.last_line = -1\r\n        elif event == 'line':\r\n            if self.cur_file_data is not None:\r\n                if self.arcs:\r\n                    self.cur_file_data[(self.last_line, frame.f_lineno)] = None\r\n                else:\r\n                    self.cur_file_data[frame.f_lineno] = None\r\n            self.last_line = frame.f_lineno\r\n        elif event == 'return':\r\n            if self.arcs and self.cur_file_data:\r\n                first = frame.f_code.co_firstlineno\r\n                self.cur_file_data[(self.last_line, -first)] = None\r\n            self.cur_file_data, self.last_line = self.data_stack.pop()\r\n        elif event == 'exception':\r\n            self.last_exc_back = frame.f_back\r\n            self.last_exc_firstlineno = frame.f_code.co_firstlineno\r\n        return self._trace","reference":"The trace function passed to sys.settrace.","result":"Return.","score":[0,0.0]}
{"code":"def start(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self.thread = threading.currentThread()\r\n        sys.settrace(self._trace)\r\n        return self._trace","reference":"Start this Tracer.\n\n        Return a Python function suitable for use with sys.settrace().","result":"Start the thread .","score":[0.0432,0.0446]}
{"code":"def stop(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self.stopped = True\r\n        if self.thread != threading.currentThread():\r\n            return\r\n        if hasattr(sys, \"gettrace\") and self.warn:\r\n            if sys.gettrace() != self._trace:\r\n                msg = \"Trace function changed, measurement is likely wrong: %r\"\r\n                self.warn(msg % (sys.gettrace(),))\r\n        sys.settrace(None)","reference":"Stop this Tracer.","result":"Stop the measurement thread.","score":[0.3195,0.1613]}
{"code":"def _start_tracer(self):\r\n        \"\"\" function to<extra_id_0>\r\n        tracer = self._trace_class()\r\n        tracer.data = self.data\r\n        tracer.arcs = self.branch\r\n        tracer.should_trace = self.should_trace\r\n        tracer.should_trace_cache = self.should_trace_cache\r\n        tracer.warn = self.warn\r\n        fn = tracer.start()\r\n        self.tracers.append(tracer)\r\n        return fn","reference":"Start a new Tracer object, and store it in self.tracers.","result":"Def start the tracer .","score":[0,0.1053]}
{"code":"def _installation_trace(self, frame_unused, event_unused, arg_unused):\r\n        \"\"\" function to<extra_id_0>\r\n        sys.settrace(None)\r\n        fn = self._start_tracer()\r\n        if fn:\r\n            fn = fn(frame_unused, event_unused, arg_unused)\r\n        return fn","reference":"Called on new threads, installs the real tracer.","result":"Def trace the installation .","score":[0.1319,0.1299]}
{"code":"def start(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._collectors:\r\n            self._collectors[-1].pause()\r\n        self._collectors.append(self)\r\n        traces0 = []\r\n        if hasattr(sys, \"gettrace\"):\r\n            fn0 = sys.gettrace()\r\n            if fn0:\r\n                tracer0 = getattr(fn0, '__self__', None)\r\n                if tracer0:\r\n                    traces0 = getattr(tracer0, 'traces', [])\r\n        fn = self._start_tracer()\r\n        for args in traces0:\r\n            (frame, event, arg), lineno = args\r\n            try:\r\n                fn(frame, event, arg, lineno=lineno)\r\n            except TypeError:\r\n                raise Exception(\r\n                    \"fullcoverage must be run with the C trace function.\"\r\n                )\r\n        threading.settrace(self._installation_trace)","reference":"Start collecting trace information.","result":"Start the fullcoverage collector .","score":[0.2403,0.122]}
{"code":"def stop(self):\r\n        \"\"\" function to<extra_id_0>\r\n        assert self._collectors\r\n        assert self._collectors[-1] is self\r\n        self.pause()\r\n        self.tracers = []\r\n        self._collectors.pop()\r\n        if self._collectors:\r\n            self._collectors[-1].resume()","reference":"Stop collecting trace information.","result":"Stop the collector .","score":[0.3195,0.125]}
{"code":"def pause(self):\r\n        \"\"\" function to<extra_id_0>\r\n        for tracer in self.tracers:\r\n            tracer.stop()\r\n            stats = tracer.get_stats()\r\n            if stats:\r\n                print(\"\\nCoverage.py tracer stats:\")\r\n                for k in sorted(stats.keys()):\r\n                    print(\"%16s: %s\" % (k, stats[k]))\r\n        threading.settrace(None)","reference":"Pause tracing, but be prepared to `resume`.","result":"Pause all tracers .","score":[0.1509,0.0746]}
{"code":"def resume(self):\r\n        \"\"\" function to<extra_id_0>\r\n        for tracer in self.tracers:\r\n            tracer.start()\r\n        threading.settrace(self._installation_trace)","reference":"Resume tracing after a `pause`.","result":"Resume the tracer .","score":[0.2488,0.102]}
{"code":"def get_line_data(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.branch:\r\n            line_data = {}\r\n            for f, arcs in self.data.items():\r\n                line_data[f] = ldf = {}\r\n                for l1, _ in list(arcs.keys()):\r\n                    if l1:\r\n                        ldf[l1] = None\r\n            return line_data\r\n        else:\r\n            return self.data","reference":"Return the line data collected.\n\n        Data is { filename: { lineno: None, ...}, ...}","result":"Get line data .","score":[0.0371,0.0769]}
{"code":"def collect_exceptions(rdict_or_list, method='unspecified'):\r\n    \"\"\" function to<extra_id_0>\r\n    elist = []\r\n    if isinstance(rdict_or_list, dict):\r\n        rlist = rdict_or_list.values()\r\n    else:\r\n        rlist = rdict_or_list\r\n    for r in rlist:\r\n        if isinstance(r, RemoteError):\r\n            en, ev, etb, ei = r.ename, r.evalue, r.traceback, r.engine_info\r\n            if en=='CompositeError':\r\n                for e in ev.elist:\r\n                    elist.append(e)\r\n            else:\r\n                elist.append((en, ev, etb, ei))\r\n    if len(elist)==0:\r\n        return rdict_or_list\r\n    else:\r\n        msg = \"one or more exceptions from call to method: %s\" % (method)\r\n        try:\r\n            raise CompositeError(msg, elist)\r\n        except CompositeError as e:\r\n            raise e","reference":"check a result dict for errors, and raise CompositeError if any exist.\n    Passthrough otherwise.","result":"Collect exceptions from remote exceptions .","score":[0,0.0]}
{"code":"def render_traceback(self, excid=None):\r\n        \"\"\" function to<extra_id_0>\r\n        lines = []\r\n        if excid is None:\r\n            for (en,ev,etb,ei) in self.elist:\r\n                lines.append(self._get_engine_str(ei))\r\n                lines.extend((etb or 'No traceback available').splitlines())\r\n                lines.append('')\r\n        else:\r\n            try:\r\n                en,ev,etb,ei = self.elist[excid]\r\n            except:\r\n                raise IndexError(\"an exception with index %i does not exist\"%excid)\r\n            else:\r\n                lines.append(self._get_engine_str(ei))\r\n                lines.extend((etb or 'No traceback available').splitlines())\r\n                return lines","reference":"render one or all of my tracebacks to a list of lines","result":"Render the traceback .","score":[0,0.0893]}
{"code":"def process_startup():\r\n    \"\"\" function to<extra_id_0>\r\n    cps = os.environ.get(\"COVERAGE_PROCESS_START\")\r\n    if cps:\r\n        cov = coverage(config_file=cps, auto_data=True)\r\n        cov.start()\r\n        cov._warn_no_data = False\r\n        cov._warn_unimported_source = False","reference":"Call this at Python startup to perhaps measure coverage.\n\n    If the environment variable COVERAGE_PROCESS_START is defined, coverage\n    measurement is started.  The value of the variable is the config file\n    to use.\n\n    There are two ways to configure your Python installation to invoke this\n    function when Python starts:\n\n    #. Create or append to sitecustomize.py to add these lines::\n\n        import coverage\n        coverage.process_startup()\n\n    #. Create a .pth file in your Python installation containing::\n\n        import coverage; coverage.process_startup()","result":"Be called when the process starts up .","score":[0.0,0.0226]}
{"code":"def _canonical_dir(self, morf):\r\n        \"\"\" function to<extra_id_0>\r\n        return os.path.split(CodeUnit(morf, self.file_locator).filename)[0]","reference":"Return the canonical directory of the module or file `morf`.","result":"Return canonical directory .","score":[0.1116,0.2719]}
{"code":"def _source_for_file(self, filename):\r\n        \"\"\" function to<extra_id_0>\r\n        if not filename.endswith(\".py\"):\r\n            if filename[-4:-1] == \".py\":\r\n                filename = filename[:-1]\r\n            elif filename.endswith(\"$py.class\"):\r\n                filename = filename[:-9] + \".py\"\r\n        return filename","reference":"Return the source file for `filename`.","result":"Def get source for file .","score":[0.2541,0.25]}
{"code":"def _should_trace_with_reason(self, filename, frame):\r\n        \"\"\" function to<extra_id_0>\r\n        if not filename:\r\n            return None, \"empty string isn't a filename\"\r\n        if filename.startswith('<'):\r\n            return None, \"not a real filename\"\r\n        self._check_for_packages()\r\n        dunder_file = frame.f_globals.get('__file__')\r\n        if dunder_file:\r\n            filename = self._source_for_file(dunder_file)\r\n        if filename.endswith(\"$py.class\"):\r\n            filename = filename[:-9] + \".py\"\r\n        canonical = self.file_locator.canonical_filename(filename)\r\n        if self.source_match:\r\n            if not self.source_match.match(canonical):\r\n                return None, \"falls outside the --source trees\"\r\n        elif self.include_match:\r\n            if not self.include_match.match(canonical):\r\n                return None, \"falls outside the --include trees\"\r\n        else:\r\n            if self.pylib_match and self.pylib_match.match(canonical):\r\n                return None, \"is in the stdlib\"\r\n            if self.cover_match and self.cover_match.match(canonical):\r\n                return None, \"is part of coverage.py\"\r\n        if self.omit_match and self.omit_match.match(canonical):\r\n            return None, \"is inside an --omit pattern\"\r\n        return canonical, \"because we love you\"","reference":"Decide whether to trace execution in `filename`, with a reason.\n\n        This function is called from the trace function.  As each new file name\n        is encountered, this function determines whether it is traced or not.\n\n        Returns a pair of values:  the first indicates whether the file should\n        be traced: it's a canonicalized filename if it should be traced, None\n        if it should not.  The second value is a string, the resason for the\n        decision.","result":"Determine if a trace should be logged .","score":[0.0001,0.0451]}
{"code":"def _should_trace(self, filename, frame):\r\n        \"\"\" function to<extra_id_0>\r\n        canonical, reason = self._should_trace_with_reason(filename, frame)\r\n        if self.debug.should('trace'):\r\n            if not canonical:\r\n                msg = \"Not tracing %r: %s\" % (filename, reason)\r\n            else:\r\n                msg = \"Tracing %r\" % (filename,)\r\n            self.debug.write(msg)\r\n        return canonical","reference":"Decide whether to trace execution in `filename`.\n\n        Calls `_should_trace_with_reason`, and returns just the decision.","result":"Determine if should trace a given frame .","score":[0.0656,0.0746]}
{"code":"def _warn(self, msg):\r\n        \"\"\" function to<extra_id_0>\r\n        self._warnings.append(msg)\r\n        sys.stderr.write(\"Coverage.py warning: %s\\n\" % msg)","reference":"Use `msg` as a warning.","result":"Log a warning .","score":[0.2488,0.102]}
{"code":"def _check_for_packages(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.source_pkgs:\r\n            found = []\r\n            for pkg in self.source_pkgs:\r\n                try:\r\n                    mod = sys.modules[pkg]\r\n                except KeyError:\r\n                    continue\r\n                found.append(pkg)\r\n                try:\r\n                    pkg_file = mod.__file__\r\n                except AttributeError:\r\n                    pkg_file = None\r\n                else:\r\n                    d, f = os.path.split(pkg_file)\r\n                    if f.startswith('__init__'):\r\n                        pkg_file = d\r\n                    else:\r\n                        pkg_file = self._source_for_file(pkg_file)\r\n                    pkg_file = self.file_locator.canonical_filename(pkg_file)\r\n                    if not os.path.exists(pkg_file):\r\n                        pkg_file = None\r\n                if pkg_file:\r\n                    self.source.append(pkg_file)\r\n                    self.source_match.add(pkg_file)\r\n                else:\r\n                    self._warn(\"Module %s has no Python source.\" % pkg)\r\n            for pkg in found:\r\n                self.source_pkgs.remove(pkg)","reference":"Update the source_match matcher with latest imported packages.","result":"Check for packages in the source .","score":[0.14,0.0633]}
{"code":"def start(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.run_suffix:\r\n            self.data_suffix = self.run_suffix\r\n        if self.auto_data:\r\n            self.load()\r\n        if self.source or self.source_pkgs:\r\n            self.source_match = TreeMatcher(self.source)\r\n        else:\r\n            if self.cover_dir:\r\n                self.cover_match = TreeMatcher([self.cover_dir])\r\n            if self.pylib_dirs:\r\n                self.pylib_match = TreeMatcher(self.pylib_dirs)\r\n        if self.include:\r\n            self.include_match = FnmatchMatcher(self.include)\r\n        if self.omit:\r\n            self.omit_match = FnmatchMatcher(self.omit)\r\n        if self.debug.should('config'):\r\n            self.debug.write(\"Configuration values:\")\r\n            config_info = sorted(self.config.__dict__.items())\r\n            self.debug.write_formatted_info(config_info)\r\n        if self.debug.should('sys'):\r\n            self.debug.write(\"Debugging info:\")\r\n            self.debug.write_formatted_info(self.sysinfo())\r\n        self.collector.start()\r\n        self._started = True\r\n        self._measured = True","reference":"Start measuring code coverage.\n\n        Coverage measurement actually occurs in functions called after `start`\n        is invoked.  Statements in the same scope as `start` won't be measured.\n\n        Once you invoke `start`, you must also call `stop` eventually, or your\n        process might not shut down cleanly.","result":"Start the run .","score":[0.0,0.0384]}
{"code":"def _atexit(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self._started:\r\n            self.stop()\r\n        if self.auto_data:\r\n            self.save()","reference":"Clean up on process shutdown.","result":"Handle the atexit .","score":[0,0.0]}
{"code":"def exclude(self, regex, which='exclude'):\r\n        \"\"\" function to<extra_id_0>\r\n        excl_list = getattr(self.config, which + \"_list\")\r\n        excl_list.append(regex)\r\n        self._exclude_regex_stale()","reference":"Exclude source lines from execution consideration.\n\n        A number of lists of regular expressions are maintained.  Each list\n        selects lines that are treated differently during reporting.\n\n        `which` determines which list is modified.  The \"exclude\" list selects\n        lines that are not considered executable at all.  The \"partial\" list\n        indicates lines with branches that are not taken.\n\n        `regex` is a regular expression.  The regex is added to the specified\n        list.  If any of the regexes in the list is found in a line, the line\n        is marked for special treatment during reporting.","result":"Add exclude regex to config .","score":[0.0,0.0186]}
{"code":"def _exclude_regex(self, which):\r\n        \"\"\" function to<extra_id_0>\r\n        if which not in self._exclude_re:\r\n            excl_list = getattr(self.config, which + \"_list\")\r\n            self._exclude_re[which] = join_regex(excl_list)\r\n        return self._exclude_re[which]","reference":"Return a compiled regex for the given exclusion list.","result":"Def get the exclude regex.","score":[0.108,0.0581]}
{"code":"def save(self):\r\n        \"\"\" function to<extra_id_0>\r\n        data_suffix = self.data_suffix\r\n        if data_suffix is True:\r\n            extra = \"\"\r\n            if _TEST_NAME_FILE:\r\n                f = open(_TEST_NAME_FILE)\r\n                test_name = f.read()\r\n                f.close()\r\n                extra = \".\" + test_name\r\n            data_suffix = \"%s%s.%s.%06d\" % (\r\n                socket.gethostname(), extra, os.getpid(),\r\n                random.randint(0, 999999)\r\n                )\r\n        self._harvest_data()\r\n        self.data.write(suffix=data_suffix)","reference":"Save the collected coverage data to the data file.","result":"Save the data to disk.","score":[0.2159,0.367]}
{"code":"def combine(self):\r\n        \"\"\" function to<extra_id_0>\r\n        aliases = None\r\n        if self.config.paths:\r\n            aliases = PathAliases(self.file_locator)\r\n            for paths in self.config.paths.values():\r\n                result = paths[0]\r\n                for pattern in paths[1:]:\r\n                    aliases.add(pattern, result)\r\n        self.data.combine_parallel_data(aliases=aliases)","reference":"Combine together a number of similarly-named coverage data files.\n\n        All coverage data files whose name starts with `data_file` (from the\n        coverage() constructor) will be read, and combined together into the\n        current measurements.","result":"Combine data .","score":[0.0,0.0344]}
{"code":"def _harvest_data(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if not self._measured:\r\n            return\r\n        self.data.add_line_data(self.collector.get_line_data())\r\n        self.data.add_arc_data(self.collector.get_arc_data())\r\n        self.collector.reset()\r\n        if self._warn_unimported_source:\r\n            for pkg in self.source_pkgs:\r\n                self._warn(\"Module %s was never imported.\" % pkg)\r\n        summary = self.data.summary()\r\n        if not summary and self._warn_no_data:\r\n            self._warn(\"No data was collected.\")\r\n        for src in self.source:\r\n            for py_file in find_python_files(src):\r\n                py_file = self.file_locator.canonical_filename(py_file)\r\n                if self.omit_match and self.omit_match.match(py_file):\r\n                    continue\r\n                self.data.touch_file(py_file)\r\n        self._measured = False","reference":"Get the collected data and reset the collector.\n\n        Also warn about various problems collecting data.","result":"Harvest data .","score":[0.0075,0.0362]}
{"code":"def analysis(self, morf):\r\n        \"\"\" function to<extra_id_0>\r\n        f, s, _, m, mf = self.analysis2(morf)\r\n        return f, s, m, mf","reference":"Like `analysis2` but doesn't return excluded line numbers.","result":"Perform the analysis .","score":[0,0.0]}
{"code":"def analysis2(self, morf):\r\n        \"\"\" function to<extra_id_0>\r\n        analysis = self._analyze(morf)\r\n        return (\r\n            analysis.filename,\r\n            sorted(analysis.statements),\r\n            sorted(analysis.excluded),\r\n            sorted(analysis.missing),\r\n            analysis.missing_formatted(),\r\n            )","reference":"Analyze a module.\n\n        `morf` is a module or a filename.  It will be analyzed to determine\n        its coverage statistics.  The return value is a 5-tuple:\n\n        * The filename for the module.\n        * A list of line numbers of executable statements.\n        * A list of line numbers of excluded statements.\n        * A list of line numbers of statements not run (missing from\n          execution).\n        * A readable formatted string of the missing line numbers.\n\n        The analysis uses the source file itself and the current measured\n        coverage data.","result":"Return the analysis of a morf file .","score":[0.0,0.0388]}
{"code":"def _analyze(self, it):\r\n        \"\"\" function to<extra_id_0>\r\n        self._harvest_data()\r\n        if not isinstance(it, CodeUnit):\r\n            it = code_unit_factory(it, self.file_locator)[0]\r\n        return Analysis(self, it)","reference":"Analyze a single morf or code unit.\n\n        Returns an `Analysis` object.","result":"Def perform analysis .","score":[0,0.0]}
{"code":"def report(self, morfs=None, show_missing=True, ignore_errors=None,\r\n                \"\"\" function to<extra_id_0>\r\n                file=None,\r\n                omit=None, include=None\r\n                ):\r\n        self._harvest_data()\r\n        self.config.from_args(\r\n            ignore_errors=ignore_errors, omit=omit, include=include,\r\n            show_missing=show_missing,\r\n            )\r\n        reporter = SummaryReporter(self, self.config)\r\n        return reporter.report(morfs, outfile=file)","reference":"Write a summary report to `file`.\n\n        Each module in `morfs` is listed, with counts of statements, executed\n        statements, missing statements, and a list of lines missed.\n\n        `include` is a list of filename patterns.  Modules whose filenames\n        match those patterns will be included in the report. Modules matching\n        `omit` will not be included in the report.\n\n        Returns a float, the total percentage covered.","result":"Generate a report .","score":[0.0,0.0178]}
{"code":"def annotate(self, morfs=None, directory=None, ignore_errors=None,\r\n                    \"\"\" function to<extra_id_0>\r\n                    omit=None, include=None):\r\n        self._harvest_data()\r\n        self.config.from_args(\r\n            ignore_errors=ignore_errors, omit=omit, include=include\r\n            )\r\n        reporter = AnnotateReporter(self, self.config)\r\n        reporter.report(morfs, directory=directory)","reference":"Annotate a list of modules.\n\n        Each module in `morfs` is annotated.  The source is written to a new\n        file, named with a \",cover\" suffix, with each line prefixed with a\n        marker to indicate the coverage of the line.  Covered lines have \">\",\n        excluded lines have \"-\", and missing lines have \"!\".\n\n        See `coverage.report()` for other arguments.","result":"Annotate data .","score":[0.0,0.0099]}
{"code":"def html_report(self, morfs=None, directory=None, ignore_errors=None,\r\n                    \"\"\" function to<extra_id_0>\r\n                    omit=None, include=None, extra_css=None, title=None):\r\n        self._harvest_data()\r\n        self.config.from_args(\r\n            ignore_errors=ignore_errors, omit=omit, include=include,\r\n            html_dir=directory, extra_css=extra_css, html_title=title,\r\n            )\r\n        reporter = HtmlReporter(self, self.config)\r\n        return reporter.report(morfs)","reference":"Generate an HTML report.\n\n        The HTML is written to `directory`.  The file \"index.html\" is the\n        overview starting point, with links to more detailed pages for\n        individual modules.\n\n        `extra_css` is a path to a file of other CSS to apply on the page.\n        It will be copied into the HTML directory.\n\n        `title` is a text string (not HTML) to use as the title of the HTML\n        report.\n\n        See `coverage.report()` for other arguments.\n\n        Returns a float, the total percentage covered.","result":"Generate HTML report .","score":[0.0,0.0142]}
{"code":"def xml_report(self, morfs=None, outfile=None, ignore_errors=None,\r\n                    \"\"\" function to<extra_id_0>\r\n                    omit=None, include=None):\r\n        self._harvest_data()\r\n        self.config.from_args(\r\n            ignore_errors=ignore_errors, omit=omit, include=include,\r\n            xml_output=outfile,\r\n            )\r\n        file_to_close = None\r\n        delete_file = False\r\n        if self.config.xml_output:\r\n            if self.config.xml_output == '-':\r\n                outfile = sys.stdout\r\n            else:\r\n                outfile = open(self.config.xml_output, \"w\")\r\n                file_to_close = outfile\r\n        try:\r\n            try:\r\n                reporter = XmlReporter(self, self.config)\r\n                return reporter.report(morfs, outfile=outfile)\r\n            except CoverageException:\r\n                delete_file = True\r\n                raise\r\n        finally:\r\n            if file_to_close:\r\n                file_to_close.close()\r\n                if delete_file:\r\n                    file_be_gone(self.config.xml_output)","reference":"Generate an XML report of coverage results.\n\n        The report is compatible with Cobertura reports.\n\n        Each module in `morfs` is included in the report.  `outfile` is the\n        path to write the file to, \"-\" will write to stdout.\n\n        See `coverage.report()` for other arguments.\n\n        Returns a float, the total percentage covered.","result":"Generate a report of the coverage data .","score":[0.0015,0.0668]}
{"code":"def display(*objs, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    include = kwargs.get('include')\r\n    exclude = kwargs.get('exclude')\r\n    from IPython.core.interactiveshell import InteractiveShell\r\n    inst = InteractiveShell.instance()\r\n    format = inst.display_formatter.format\r\n    publish = inst.display_pub.publish\r\n    for obj in objs:\r\n        format_dict = format(obj, include=include, exclude=exclude)\r\n        publish('IPython.core.display.display', format_dict)","reference":"Display a Python object in all frontends.\n\n    By default all representations will be computed and sent to the frontends.\n    Frontends can decide which representation is used and how.\n\n    Parameters\n    ----------\n    objs : tuple of objects\n        The Python objects to display.\n    include : list or tuple, optional\n        A list of format type strings (MIME types) to include in the\n        format data dict. If this is set *only* the format types included\n        in this list will be computed.\n    exclude : list or tuple, optional\n        A list of format type string (MIME types) to exclue in the format\n        data dict. If this is set all format types will be computed,\n        except for those included in this argument.","result":"Display objects .","score":[4.143e-17,0.0097]}
{"code":"def display_html(*objs, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    raw = kwargs.pop('raw',False)\r\n    if raw:\r\n        for obj in objs:\r\n            publish_html(obj)\r\n    else:\r\n        display(*objs, include=['text\/plain','text\/html'])","reference":"Display the HTML representation of an object.\n\n    Parameters\n    ----------\n    objs : tuple of objects\n        The Python objects to display, or if raw=True raw HTML data to\n        display.\n    raw : bool\n        Are the data objects raw data or Python objects that need to be\n        formatted before display? [default: False]","result":"Display html objects .","score":[0.0,0.0344]}
{"code":"def display_svg(*objs, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    raw = kwargs.pop('raw',False)\r\n    if raw:\r\n        for obj in objs:\r\n            publish_svg(obj)\r\n    else:\r\n        display(*objs, include=['text\/plain','image\/svg+xml'])","reference":"Display the SVG representation of an object.\n\n    Parameters\n    ----------\n    objs : tuple of objects\n        The Python objects to display, or if raw=True raw svg data to\n        display.\n    raw : bool\n        Are the data objects raw data or Python objects that need to be\n        formatted before display? [default: False]","result":"Display SVG objects .","score":[0.0,0.0344]}
{"code":"def display_png(*objs, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    raw = kwargs.pop('raw',False)\r\n    if raw:\r\n        for obj in objs:\r\n            publish_png(obj)\r\n    else:\r\n        display(*objs, include=['text\/plain','image\/png'])","reference":"Display the PNG representation of an object.\n\n    Parameters\n    ----------\n    objs : tuple of objects\n        The Python objects to display, or if raw=True raw png data to\n        display.\n    raw : bool\n        Are the data objects raw data or Python objects that need to be\n        formatted before display? [default: False]","result":"Display images in PNG format .","score":[0.0002,0.0342]}
{"code":"def display_jpeg(*objs, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    raw = kwargs.pop('raw',False)\r\n    if raw:\r\n        for obj in objs:\r\n            publish_jpeg(obj)\r\n    else:\r\n        display(*objs, include=['text\/plain','image\/jpeg'])","reference":"Display the JPEG representation of an object.\n\n    Parameters\n    ----------\n    objs : tuple of objects\n        The Python objects to display, or if raw=True raw JPEG data to\n        display.\n    raw : bool\n        Are the data objects raw data or Python objects that need to be\n        formatted before display? [default: False]","result":"Display jpeg images .","score":[0.0,0.0229]}
{"code":"def display_latex(*objs, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    raw = kwargs.pop('raw',False)\r\n    if raw:\r\n        for obj in objs:\r\n            publish_latex(obj)\r\n    else:\r\n        display(*objs, include=['text\/plain','text\/latex'])","reference":"Display the LaTeX representation of an object.\n\n    Parameters\n    ----------\n    objs : tuple of objects\n        The Python objects to display, or if raw=True raw latex data to\n        display.\n    raw : bool\n        Are the data objects raw data or Python objects that need to be\n        formatted before display? [default: False]","result":"Display latex text .","score":[0.0,0.0229]}
{"code":"def display_json(*objs, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    raw = kwargs.pop('raw',False)\r\n    if raw:\r\n        for obj in objs:\r\n            publish_json(obj)\r\n    else:\r\n        display(*objs, include=['text\/plain','application\/json'])","reference":"Display the JSON representation of an object.\n\n    Note that not many frontends support displaying JSON.\n\n    Parameters\n    ----------\n    objs : tuple of objects\n        The Python objects to display, or if raw=True raw json data to\n        display.\n    raw : bool\n        Are the data objects raw data or Python objects that need to be\n        formatted before display? [default: False]","result":"Display json objects .","score":[0.0,0.0295]}
{"code":"def display_javascript(*objs, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    raw = kwargs.pop('raw',False)\r\n    if raw:\r\n        for obj in objs:\r\n            publish_javascript(obj)\r\n    else:\r\n        display(*objs, include=['text\/plain','application\/javascript'])","reference":"Display the Javascript representation of an object.\n\n    Parameters\n    ----------\n    objs : tuple of objects\n        The Python objects to display, or if raw=True raw javascript data to\n        display.\n    raw : bool\n        Are the data objects raw data or Python objects that need to be\n        formatted before display? [default: False]","result":"Display javascript .","score":[0.0,0.023]}
{"code":"def reload(self):\r\n        \"\"\" function to<extra_id_0>\r\n        if self.filename is not None:\r\n            with open(self.filename, self._read_flags) as f:\r\n                self.data = f.read()\r\n        elif self.url is not None:\r\n            try:\r\n                import urllib2\r\n                response = urllib2.urlopen(self.url)\r\n                self.data = response.read()\r\n                encoding = None\r\n                for sub in response.headers['content-type'].split(';'):\r\n                    sub = sub.strip()\r\n                    if sub.startswith('charset'):\r\n                        encoding = sub.split('=')[-1].strip()\r\n                        break\r\n                if encoding:\r\n                    self.data = self.data.decode(encoding, 'replace')\r\n            except:\r\n                self.data = None","reference":"Reload the raw data from file or URL.","result":"Reload the data .","score":[0.1839,0.3363]}
{"code":"def _find_cmd(cmd):\r\n    \"\"\" function to<extra_id_0>\r\n    path = sp.Popen(['\/usr\/bin\/env', 'which', cmd],\r\n                    stdout=sp.PIPE, stderr=sp.PIPE).communicate()[0]\r\n    return py3compat.bytes_to_str(path)","reference":"Find the full path to a command using which.","result":"Def find a command .","score":[0.1527,0.2972]}
{"code":"def system(self, cmd):\r\n        \"\"\" function to<extra_id_0>\r\n        enc = DEFAULT_ENCODING\r\n                patterns = [pexpect.TIMEOUT, pexpect.EOF]\r\n        EOF_index = patterns.index(pexpect.EOF)\r\n        out_size = 0\r\n        try:\r\n            if hasattr(pexpect, 'spawnb'):\r\n                child = pexpect.spawnb(self.sh, args=['-c', cmd])\r\n            else:\r\n                child = pexpect.spawn(self.sh, args=['-c', cmd])\r\n            flush = sys.stdout.flush\r\n            while True:\r\n                res_idx = child.expect_list(patterns, self.read_timeout)\r\n                print(child.before[out_size:].decode(enc, 'replace'), end='')\r\n                flush()\r\n                if res_idx==EOF_index:\r\n                    break\r\n                out_size = len(child.before)\r\n        except KeyboardInterrupt:\r\n            child.sendline(chr(3))\r\n            try:\r\n                out_size = len(child.before)\r\n                child.expect_list(patterns, self.terminate_timeout)\r\n                print(child.before[out_size:].decode(enc, 'replace'), end='')\r\n                sys.stdout.flush()\r\n            except KeyboardInterrupt:\r\n                pass\r\n            finally:\r\n                child.terminate(force=True)\r\n        child.isalive()\r\n        return child.exitstatus","reference":"Execute a command in a subshell.\n\n        Parameters\n        ----------\n        cmd : str\n          A command to be executed in the system shell.\n\n        Returns\n        -------\n        int : child's exitstatus","result":"Execute a system command .","score":[0.0061,0.0837]}
{"code":"def forward_read_events(fd, context=None):\r\n    \"\"\" function to<extra_id_0>\r\n    if context is None:\r\n        context = zmq.Context.instance()\r\n    push = context.socket(zmq.PUSH)\r\n    push.setsockopt(zmq.LINGER, -1)\r\n    pull = context.socket(zmq.PULL)\r\n    addr='inproc:\/\/%s'%uuid.uuid4()\r\n    push.bind(addr)\r\n    pull.connect(addr)\r\n    forwarder = ForwarderThread(push, fd)\r\n    forwarder.start()\r\n    return pull","reference":"Forward read events from an FD over a socket.\n\n    This method wraps a file in a socket pair, so it can\n    be polled for read events by select (specifically zmq.eventloop.ioloop)","result":"Forward read events to the inproc .","score":[0.0124,0.0923]}
{"code":"def run(self):\r\n        \"\"\" function to<extra_id_0>\r\n        line = self.fd.readline()\r\n        if isinstance(line, unicode):\r\n            send = self.sock.send_unicode\r\n        else:\r\n            send = self.sock.send\r\n        while line:\r\n            send(line)\r\n            line = self.fd.readline()\r\n        self.fd.close()\r\n        self.sock.close()","reference":"Loop through lines in self.fd, and send them over self.sock.","result":"Run the thread .","score":[0,0.0]}
{"code":"def find_launcher_class(clsname, kind):\r\n    \"\"\" function to<extra_id_0>\r\n    if '.' not in clsname:\r\n        if kind and kind not in clsname:\r\n            clsname = clsname + kind + 'Launcher'\r\n        clsname = 'IPython.parallel.apps.launcher.'+clsname\r\n    klass = import_item(clsname)\r\n    return klass","reference":"Return a launcher for a given clsname and kind.\n\n    Parameters\n    ==========\n    clsname : str\n        The full name of the launcher class, either with or without the\n        module path, or an abbreviation (MPI, SSH, SGE, PBS, LSF,\n        WindowsHPC).\n    kind : str\n        Either 'EngineSet' or 'Controller'.","result":"Find launcher class .","score":[0.0,0.0125]}
{"code":"def start(self):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            pid = self.get_pid_from_file()\r\n        except PIDFileError:\r\n            self.log.critical(\r\n                'Could not read pid file, cluster is probably not running.'\r\n            )\r\n            self.remove_pid_file()\r\n            self.exit(ALREADY_STOPPED)\r\n        if not self.check_pid(pid):\r\n            self.log.critical(\r\n                'Cluster [pid=%r] is not running.' % pid\r\n            )\r\n            self.remove_pid_file()\r\n            self.exit(ALREADY_STOPPED)\r\n        elif os.name=='posix':\r\n            sig = self.signal\r\n            self.log.info(\r\n                \"Stopping cluster [pid=%r] with [signal=%r]\" % (pid, sig)\r\n            )\r\n            try:\r\n                os.kill(pid, sig)\r\n            except OSError:\r\n                self.log.error(\"Stopping cluster failed, assuming already dead.\",\r\n                    exc_info=True)\r\n                self.remove_pid_file()\r\n        elif os.name=='nt':\r\n            try:\r\n                p = check_call(['taskkill', '-pid', str(pid), '-t', '-f'], stdout=PIPE,stderr=PIPE)\r\n            except (CalledProcessError, OSError):\r\n                self.log.error(\"Stopping cluster failed, assuming already dead.\",\r\n                    exc_info=True)\r\n            self.remove_pid_file()","reference":"Start the app for the stop subcommand.","result":"Start the cluster .","score":[0.2134,0.1493]}
{"code":"def build_launcher(self, clsname, kind=None):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            klass = find_launcher_class(clsname, kind)\r\n        except (ImportError, KeyError):\r\n            self.log.fatal(\"Could not import launcher class: %r\"%clsname)\r\n            self.exit(1)\r\n        launcher = klass(\r\n            work_dir=u'.', config=self.config, log=self.log,\r\n            profile_dir=self.profile_dir.location, cluster_id=self.cluster_id,\r\n        )\r\n        return launcher","reference":"import and instantiate a Launcher based on importstring","result":"Build a launcher .","score":[0.1175,0.2467]}
{"code":"def start(self):\r\n        \"\"\" function to<extra_id_0>\r\n        self.log.info(\"IPython cluster: started\")\r\n        self.log.info(\r\n            'Starting engines with [daemon=%r]' % self.daemonize\r\n        )\r\n        if self.daemonize:\r\n            if os.name=='posix':\r\n                daemonize()\r\n        dc = ioloop.DelayedCallback(self.start_engines, 0, self.loop)\r\n        dc.start()\r\n        try:\r\n            self.loop.start()\r\n        except KeyboardInterrupt:\r\n            pass\r\n        except zmq.ZMQError as e:\r\n            if e.errno == errno.EINTR:\r\n                pass\r\n            else:\r\n                raise","reference":"Start the app for the engines subcommand.","result":"Start the cluster .","score":[0.2134,0.1493]}
{"code":"def start(self):\r\n        \"\"\" function to<extra_id_0>\r\n        try:\r\n            pid = self.get_pid_from_file()\r\n        except PIDFileError:\r\n            pass\r\n        else:\r\n            if self.check_pid(pid):\r\n                self.log.critical(\r\n                    'Cluster is already running with [pid=%s]. '\r\n                    'use \"ipcluster stop\" to stop the cluster.' % pid\r\n                )\r\n                self.exit(ALREADY_STARTED)\r\n            else:\r\n                self.remove_pid_file()\r\n        self.log.info(\r\n            'Starting ipcluster with [daemon=%r]' % self.daemonize\r\n        )\r\n        if self.daemonize:\r\n            if os.name=='posix':\r\n                daemonize()\r\n        dc = ioloop.DelayedCallback(self.start_controller, 0, self.loop)\r\n        dc.start()\r\n        dc = ioloop.DelayedCallback(self.start_engines, 1000*self.delay, self.loop)\r\n        dc.start()\r\n        self.write_pid_file()\r\n        try:\r\n            self.loop.start()\r\n        except KeyboardInterrupt:\r\n            pass\r\n        except zmq.ZMQError as e:\r\n            if e.errno == errno.EINTR:\r\n                pass\r\n            else:\r\n                raise\r\n        finally:\r\n            self.remove_pid_file()","reference":"Start the app for the start subcommand.","result":"Start the cluster .","score":[0.2134,0.1493]}
{"code":"def get_app_wx(*args, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    import wx\r\n    app = wx.GetApp()\r\n    if app is None:\r\n        if not kwargs.has_key('redirect'):\r\n            kwargs['redirect'] = False\r\n        app = wx.PySimpleApp(*args, **kwargs)\r\n    return app","reference":"Create a new wx app or return an exiting one.","result":"Get wx app .","score":[0.1008,0.1995]}
{"code":"def is_event_loop_running_wx(app=None):\r\n    \"\"\" function to<extra_id_0>\r\n    if app is None:\r\n        app = get_app_wx()\r\n    if hasattr(app, '_in_event_loop'):\r\n        return app._in_event_loop\r\n    else:\r\n        return app.IsMainLoopRunning()","reference":"Is the wx event loop running.","result":" is running in wx .","score":[0.1967,0.1695]}
{"code":"def start_event_loop_wx(app=None):\r\n    \"\"\" function to<extra_id_0>\r\n    if app is None:\r\n        app = get_app_wx()\r\n    if not is_event_loop_running_wx(app):\r\n        app._in_event_loop = True\r\n        app.MainLoop()\r\n        app._in_event_loop = False\r\n    else:\r\n        app._in_event_loop = True","reference":"Start the wx event loop in a consistent manner.","result":"Start event loop in wx .","score":[0.274,0.5126]}
{"code":"def get_app_qt4(*args, **kwargs):\r\n    \"\"\" function to<extra_id_0>\r\n    from IPython.external.qt_for_kernel import QtGui\r\n    app = QtGui.QApplication.instance()\r\n    if app is None:\r\n        if not args:\r\n            args = ([''],)\r\n        app = QtGui.QApplication(*args, **kwargs)\r\n    return app","reference":"Create a new qt4 app or return an existing one.","result":"Get app from qt.","score":[0.0713,0.0532]}
{"code":"def is_event_loop_running_qt4(app=None):\r\n    \"\"\" function to<extra_id_0>\r\n    if app is None:\r\n        app = get_app_qt4([''])\r\n    if hasattr(app, '_in_event_loop'):\r\n        return app._in_event_loop\r\n    else:\r\n        return False","reference":"Is the qt4 event loop running.","result":" is running .","score":[0,0.0877]}
{"code":"def start_event_loop_qt4(app=None):\r\n    \"\"\" function to<extra_id_0>\r\n    if app is None:\r\n        app = get_app_qt4([''])\r\n    if not is_event_loop_running_qt4(app):\r\n        app._in_event_loop = True\r\n        app.exec_()\r\n        app._in_event_loop = False\r\n    else:\r\n        app._in_event_loop = True","reference":"Start the qt4 event loop in a consistent manner.","result":"Start event loop .","score":[0.1433,0.3007]}
{"code":"def blank_canvas(width, height):\r\n        \"\"\" function to<extra_id_0>\r\n        canvas = np.zeros((height, width, 3), dtype=np.uint8)\r\n        return canvas.view(Canvas)","reference":"Return a blank canvas to annotate.\n\n        :param width: xdim (int)\n        :param height: ydim (int)\n        :returns: :class:`jicbioimage.illustrate.Canvas`","result":"Create a blank canvas .","score":[0.0548,0.1976]}
{"code":"def draw_cross(self, position, color=(255, 0, 0), radius=4):\r\n        \"\"\" function to<extra_id_0>\r\n        y, x = position\r\n        for xmod in np.arange(-radius, radius+1, 1):\r\n            xpos = x + xmod\r\n            if xpos < 0:\r\n                continue\r\n            if xpos >= self.shape[1]:\r\n                continue\r\n            self[int(y), int(xpos)] = color\r\n        for ymod in np.arange(-radius, radius+1, 1):\r\n            ypos = y + ymod\r\n            if ypos < 0:\r\n                continue\r\n            if ypos >= self.shape[0]:\r\n                continue\r\n            self[int(ypos), int(x)] = color","reference":"Draw a cross on the canvas.\n\n        :param position: (row, col) tuple\n        :param color: RGB tuple\n        :param radius: radius of the cross (int)","result":"Draw a circle .","score":[0.005,0.0928]}
{"code":"def draw_line(self, pos1, pos2, color=(255, 0, 0)):\r\n        \"\"\" function to<extra_id_0>\r\n        r1, c1 = tuple([int(round(i, 0)) for i in pos1])\r\n        r2, c2 = tuple([int(round(i, 0)) for i in pos2])\r\n        rr, cc = skimage.draw.line(r1, c1, r2, c2)\r\n        self[rr, cc] = color","reference":"Draw a line between pos1 and pos2 on the canvas.\n\n        :param pos1: position 1 (row, col) tuple\n        :param pos2: position 2 (row, col) tuple\n        :param color: RGB tuple","result":"Draw a line .","score":[0.0016,0.115]}
{"code":"def text_at(self, text, position, color=(255, 255, 255),\r\n                \"\"\" function to<extra_id_0>\r\n                size=12, antialias=False, center=False):\r\n        def antialias_value(value, normalisation):\r\n            return int(round(value * normalisation))\r\n        def antialias_rgb(color, normalisation):\r\n            return tuple([antialias_value(v, normalisation) for v in color])\r\n        def set_color(xpos, ypos, color):\r\n            try:\r\n                self[ypos, xpos] = color\r\n            except IndexError:\r\n                pass\r\n        y, x = position\r\n        font = PIL.ImageFont.truetype(DEFAULT_FONT_PATH, size=size)\r\n        mask = font.getmask(text)\r\n        width, height = mask.size\r\n        if center:\r\n            x = x - (width \/\/ 2)\r\n            y = y - (height \/\/ 2)\r\n        for ystep in range(height):\r\n            for xstep in range(width):\r\n                normalisation = mask[ystep * width + xstep] \/ 255.\r\n                if antialias:\r\n                    if normalisation != 0:\r\n                        rgb_color = antialias_rgb(color, normalisation)\r\n                        set_color(x + xstep, y+ystep, rgb_color)\r\n                else:\r\n                    if normalisation > .5:\r\n                        set_color(x + xstep, y + ystep, color)","reference":"Write text at x, y top left corner position.\n\n        By default the x and y coordinates represent the top left hand corner\n        of the text. The text can be centered vertically and horizontally by\n        using setting the ``center`` option to ``True``.\n\n        :param text: text to write\n        :param position: (row, col) tuple\n        :param color: RGB tuple\n        :param size: font size\n        :param antialias: whether or not the text should be antialiased\n        :param center: whether or not the text should be centered on the\n                       input coordinate","result":"Set text at position .","score":[0.0,0.0199]}
{"code":"def from_grayscale(im, channels_on=(True, True, True)):\r\n        \"\"\" function to<extra_id_0>\r\n        xdim, ydim = im.shape\r\n        canvas = np.zeros((xdim, ydim, 3), dtype=np.uint8)\r\n        for i, include in enumerate(channels_on):\r\n            if include:\r\n                canvas[:, :, i] = im\r\n        return canvas.view(AnnotatedImage)","reference":"Return a canvas from a grayscale image.\n\n        :param im: single channel image\n        :channels_on: channels to populate with input image\n        :returns: :class:`jicbioimage.illustrate.Canvas`","result":"Create a canvas from a grayscale image .","score":[0.1191,0.2989]}
{"code":"def get_uuid(length=32, version=1):\r\n    \"\"\" function to<extra_id_0>\r\n    if version == 1:\r\n        return uuid.uuid1().hex[:length]\r\n    else:\r\n        return uuid.uuid4().hex[:length]","reference":"Returns a unique ID of a given length.\n    User `version=2` for cross-systems uniqueness.","result":"Get a uuid .","score":[0.0337,0.0413]}
{"code":"def get_unique_key_from_get(get_dict):\r\n    \"\"\" function to<extra_id_0>\r\n    site = Site.objects.get_current()\r\n    key = get_dict_to_encoded_url(get_dict)\r\n    cache_key = '{}_{}'.format(site.domain, key)\r\n    return hashlib.md5(cache_key).hexdigest()","reference":"Build a unique key from get data","result":"Get unique key from get .","score":[0.5115,0.5752]}
{"code":"def get_domain(url):\r\n    \"\"\" function to<extra_id_0>\r\n    if 'http' not in url.lower():\r\n        url = 'http:\/\/{}'.format(url)\r\n    return urllib.parse.urlparse(url).hostname","reference":"Returns domain name portion of a URL","result":"Get domain from url .","score":[0.1611,0.1471]}
{"code":"def get_url_args(url):\r\n    \"\"\" function to<extra_id_0>\r\n    url_data = urllib.parse.urlparse(url)\r\n    arg_dict = urllib.parse.parse_qs(url_data.query)\r\n    return arg_dict","reference":"Returns a dictionary from a URL params","result":"Get url args .","score":[0,0.0746]}
