{"code":"\/*is used to<extra_id_0>\r\nfunc NewSTM(c *v3.Client, apply func(STM) error, so ...stmOption) (*v3.TxnResponse, error) {\r\n\topts := &stmOptions{ctx: c.Ctx()}\r\n\tfor _, f := range so {\r\n\t\tf(opts)\r\n\t}\r\n\tif len(opts.prefetch) != 0 {\r\n\t\tf := apply\r\n\t\tapply = func(s STM) error {\r\n\t\t\ts.Get(opts.prefetch...)\r\n\t\t\treturn f(s)\r\n\t\t}\r\n\t}\r\n\treturn runSTM(mkSTM(c, opts), apply)\r\n}","code-length":172,"reference":"\/\/ NewSTM initiates a new STM instance, using serializable snapshot isolation by default.","result":"Create a new STM.","score":[0.0476,0.155]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rs readSet) first() int64 {\r\n\tret := int64(math.MaxInt64 - 1)\r\n\tfor _, resp := range rs {\r\n\t\tif rev := resp.Header.Revision; rev < ret {\r\n\t\t\tret = rev\r\n\t\t}\r\n\t}\r\n\treturn ret\r\n}","code-length":88,"reference":"\/\/ first returns the store revision from the first fetch","result":"Compute the first revision in a readSet.","score":[0.1647,0.2635]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ws writeSet) cmps(rev int64) []v3.Cmp {\r\n\tcmps := make([]v3.Cmp, 0, len(ws))\r\n\tfor key := range ws {\r\n\t\tcmps = append(cmps, v3.Compare(v3.ModRevision(key), \"<\", rev))\r\n\t}\r\n\treturn cmps\r\n}","code-length":99,"reference":"\/\/ cmps returns a cmp list testing no writes have happened past rev","result":"Generate the cmps function.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSTMRepeatable(ctx context.Context, c *v3.Client, apply func(STM) error) (*v3.TxnResponse, error) {\r\n\treturn NewSTM(c, apply, WithAbortContext(ctx), WithIsolation(RepeatableReads))\r\n}","code-length":75,"reference":"\/\/ NewSTMRepeatable is deprecated.","result":"Create a new STM.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSTMSerializable(ctx context.Context, c *v3.Client, apply func(STM) error) (*v3.TxnResponse, error) {\r\n\treturn NewSTM(c, apply, WithAbortContext(ctx), WithIsolation(Serializable))\r\n}","code-length":72,"reference":"\/\/ NewSTMSerializable is deprecated.","result":"Create a new STMSerializable object.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSTMReadCommitted(ctx context.Context, c *v3.Client, apply func(STM) error) (*v3.TxnResponse, error) {\r\n\treturn NewSTM(c, apply, WithAbortContext(ctx), WithIsolation(ReadCommitted))\r\n}","code-length":74,"reference":"\/\/ NewSTMReadCommitted is deprecated.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCertPool(CAFiles []string) (*x509.CertPool, error) {\r\n\tcertPool := x509.NewCertPool()\r\n\tfor _, CAFile := range CAFiles {\r\n\t\tpemByte, err := ioutil.ReadFile(CAFile)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tfor {\r\n\t\t\tvar block *pem.Block\r\n\t\t\tblock, pemByte = pem.Decode(pemByte)\r\n\t\t\tif block == nil {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\tcert, err := x509.ParseCertificate(block.Bytes)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\tcertPool.AddCert(cert)\r\n\t\t}\r\n\t}\r\n\treturn certPool, nil\r\n}","code-length":218,"reference":"\/\/ NewCertPool creates x509 certPool with provided CA files.","result":"Create a new cert pool.","score":[0,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCert(certfile, keyfile string, parseFunc func([]byte, []byte) (tls.Certificate, error)) (*tls.Certificate, error) {\r\n\tcert, err := ioutil.ReadFile(certfile)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tkey, err := ioutil.ReadFile(keyfile)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif parseFunc == nil {\r\n\t\tparseFunc = tls.X509KeyPair\r\n\t}\r\n\ttlsCert, err := parseFunc(cert, key)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &tlsCert, nil\r\n}","code-length":187,"reference":"\/\/ NewCert generates TLS cert by using the given cert,key and parse function.","result":"Create a new certificate.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *peer) Pause() {\r\n\tp.mu.Lock()\r\n\tdefer p.mu.Unlock()\r\n\tp.paused = true\r\n\tp.msgAppReader.pause()\r\n\tp.msgAppV2Reader.pause()\r\n}","code-length":73,"reference":"\/\/ Pause pauses the peer. The peer will simply drops all incoming\n\/\/ messages without returning an error.","result":"Pause the peer.","score":[0.0043,0.0909]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *peer) Resume() {\r\n\tp.mu.Lock()\r\n\tdefer p.mu.Unlock()\r\n\tp.paused = false\r\n\tp.msgAppReader.resume()\r\n\tp.msgAppV2Reader.resume()\r\n}","code-length":74,"reference":"\/\/ Resume resumes a paused peer.","result":"Resume the peer.","score":[0.1786,0.1754]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *peer) pick(m raftpb.Message) (writec chan<- raftpb.Message, picked string) {\r\n\tvar ok bool\r\n\t\r\n\t\r\n\tif isMsgSnap(m) {\r\n\t\treturn p.pipeline.msgc, pipelineMsg\r\n\t} else if writec, ok = p.msgAppV2Writer.writec(); ok && isMsgApp(m) {\r\n\t\treturn writec, streamAppV2\r\n\t} else if writec, ok = p.writer.writec(); ok {\r\n\t\treturn writec, streamMsg\r\n\t}\r\n\treturn p.pipeline.msgc, pipelineMsg\r\n}","code-length":168,"reference":"\/\/ pick picks a chan for sending the given message. The picked chan and the picked chan\n\/\/ string name are returned.","result":"Pick a message from the cluster.","score":[0.016,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *snapshotSender) post(req *http.Request) (err error) {\r\n\tctx, cancel := context.WithCancel(context.Background())\r\n\treq = req.WithContext(ctx)\r\n\tdefer cancel()\r\n\ttype responseAndError struct {\r\n\t\tresp *http.Response\r\n\t\tbody []byte\r\n\t\terr  error\r\n\t}\r\n\tresult := make(chan responseAndError, 1)\r\n\tgo func() {\r\n\t\tresp, err := s.tr.pipelineRt.RoundTrip(req)\r\n\t\tif err != nil {\r\n\t\t\tresult <- responseAndError{resp, nil, err}\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\ttime.AfterFunc(snapResponseReadTimeout, func() { httputil.GracefulClose(resp) })\r\n\t\tbody, err := ioutil.ReadAll(resp.Body)\r\n\t\tresult <- responseAndError{resp, body, err}\r\n\t}()\r\n\tselect {\r\n\tcase <-s.stopc:\r\n\t\treturn errStopped\r\n\tcase r := <-result:\r\n\t\tif r.err != nil {\r\n\t\t\treturn r.err\r\n\t\t}\r\n\t\treturn checkPostResponse(r.resp, r.body, req, s.to)\r\n\t}\r\n}","code-length":336,"reference":"\/\/ post posts the given request.\n\/\/ It returns nil when request is sent out and processed successfully.","result":"Send snapshot requests to the snapshot sender.","score":[0.0336,0.0888]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newTxnResp(rt *pb.TxnRequest, txnPath []bool) (txnResp *pb.TxnResponse, txnCount int) {\r\n\treqs := rt.Success\r\n\tif !txnPath[0] {\r\n\t\treqs = rt.Failure\r\n\t}\r\n\tresps := make([]*pb.ResponseOp, len(reqs))\r\n\ttxnResp = &pb.TxnResponse{\r\n\t\tResponses: resps,\r\n\t\tSucceeded: txnPath[0],\r\n\t\tHeader:    &pb.ResponseHeader{},\r\n\t}\r\n\tfor i, req := range reqs {\r\n\t\tswitch tv := req.Request.(type) {\r\n\t\tcase *pb.RequestOp_RequestRange:\r\n\t\t\tresps[i] = &pb.ResponseOp{Response: &pb.ResponseOp_ResponseRange{}}\r\n\t\tcase *pb.RequestOp_RequestPut:\r\n\t\t\tresps[i] = &pb.ResponseOp{Response: &pb.ResponseOp_ResponsePut{}}\r\n\t\tcase *pb.RequestOp_RequestDeleteRange:\r\n\t\t\tresps[i] = &pb.ResponseOp{Response: &pb.ResponseOp_ResponseDeleteRange{}}\r\n\t\tcase *pb.RequestOp_RequestTxn:\r\n\t\t\tresp, txns := newTxnResp(tv.RequestTxn, txnPath[1:])\r\n\t\t\tresps[i] = &pb.ResponseOp{Response: &pb.ResponseOp_ResponseTxn{ResponseTxn: resp}}\r\n\t\t\ttxnPath = txnPath[1+txns:]\r\n\t\t\ttxnCount += txns + 1\r\n\t\tdefault:\r\n\t\t}\r\n\t}\r\n\treturn txnResp, txnCount\r\n}","code-length":417,"reference":"\/\/ newTxnResp allocates a txn response for a txn request given a path.","result":"Create a new txn response object.","score":[0.0941,0.122]}
{"code":"\/*is used to<extra_id_0>\r\nfunc applyCompare(rv mvcc.ReadView, c *pb.Compare) bool {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\trr, err := rv.Range(c.Key, mkGteRange(c.RangeEnd), mvcc.RangeOptions{})\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\tif len(rr.KVs) == 0 {\r\n\t\tif c.Target == pb.Compare_VALUE {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\treturn false\r\n\t\t}\r\n\t\treturn compareKV(c, mvccpb.KeyValue{})\r\n\t}\r\n\tfor _, kv := range rr.KVs {\r\n\t\tif !compareKV(c, kv) {\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":211,"reference":"\/\/ applyCompare applies the compare request.\n\/\/ If the comparison succeeds, it returns true. Otherwise, returns false.","result":"Apply a compare to a read view.","score":[0.0387,0.0625]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OpCompact(rev int64, opts ...CompactOption) CompactOp {\r\n\tret := CompactOp{revision: rev}\r\n\tret.applyCompactOpts(opts)\r\n\treturn ret\r\n}","code-length":56,"reference":"\/\/ OpCompact wraps slice CompactOption to create a CompactOp.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPriorityQueue(client *v3.Client, key string) *PriorityQueue {\r\n\treturn &PriorityQueue{client, context.TODO(), key + \"\/\"}\r\n}","code-length":49,"reference":"\/\/ NewPriorityQueue creates an etcd priority queue.","result":"Use the PriorityQueue interface.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *PriorityQueue) Enqueue(val string, pr uint16) error {\r\n\tprefix := fmt.Sprintf(\"%s%05d\", q.key, pr)\r\n\t_, err := newSequentialKV(q.client, prefix, val)\r\n\treturn err\r\n}","code-length":76,"reference":"\/\/ Enqueue puts a value into a queue with a given priority.","result":"Enqueue a string to the queue.","score":[0.0845,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLeaderStats(id string) *LeaderStats {\r\n\treturn &LeaderStats{\r\n\t\tleaderStats: leaderStats{\r\n\t\t\tLeader:    id,\r\n\t\t\tFollowers: make(map[string]*FollowerStats),\r\n\t\t},\r\n\t}\r\n}","code-length":77,"reference":"\/\/ NewLeaderStats generates a new LeaderStats with the given id as leader","result":"Create a new stats object.","score":[0.0838,0.1659]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (fs *FollowerStats) Succ(d time.Duration) {\r\n\tfs.Lock()\r\n\tdefer fs.Unlock()\r\n\ttotal := float64(fs.Counts.Success) * fs.Latency.Average\r\n\ttotalSquare := float64(fs.Counts.Success) * fs.Latency.averageSquare\r\n\tfs.Counts.Success++\r\n\tfs.Latency.Current = float64(d) \/ (1000000.0)\r\n\tif fs.Latency.Current > fs.Latency.Maximum {\r\n\t\tfs.Latency.Maximum = fs.Latency.Current\r\n\t}\r\n\tif fs.Latency.Current < fs.Latency.Minimum {\r\n\t\tfs.Latency.Minimum = fs.Latency.Current\r\n\t}\r\n\tfs.Latency.Average = (total + fs.Latency.Current) \/ float64(fs.Counts.Success)\r\n\tfs.Latency.averageSquare = (totalSquare + fs.Latency.Current*fs.Latency.Current) \/ float64(fs.Counts.Success)\r\n\t\r\n\tfs.Latency.StandardDeviation = math.Sqrt(fs.Latency.averageSquare - fs.Latency.Average*fs.Latency.Average)\r\n}","code-length":289,"reference":"\/\/ Succ updates the FollowerStats with a successful send","result":"Avoid locking.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (fs *FollowerStats) Fail() {\r\n\tfs.Lock()\r\n\tdefer fs.Unlock()\r\n\tfs.Counts.Fail++\r\n}","code-length":47,"reference":"\/\/ Fail updates the FollowerStats with an unsuccessful send","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wbs *watchBroadcasts) delete(w *watcher) int {\r\n\twbs.mu.Lock()\r\n\tdefer wbs.mu.Unlock()\r\n\twb, ok := wbs.watchers[w]\r\n\tif !ok {\r\n\t\tpanic(\"deleting missing watcher from broadcasts\")\r\n\t}\r\n\tdelete(wbs.watchers, w)\r\n\twb.delete(w)\r\n\tif wb.empty() {\r\n\t\tdelete(wbs.bcasts, wb)\r\n\t\twb.stop()\r\n\t}\r\n\treturn len(wbs.bcasts)\r\n}","code-length":162,"reference":"\/\/ delete removes a watcher and returns the number of remaining watchers.","result":"Delete watchers.","score":[0.0034,0.0909]}
{"code":"\/*is used to<extra_id_0>\r\nfunc startStreamWriter(lg *zap.Logger, local, id types.ID, status *peerStatus, fs *stats.FollowerStats, r Raft) *streamWriter {\r\n\tw := &streamWriter{\r\n\t\tlg: lg,\r\n\t\tlocalID: local,\r\n\t\tpeerID:  id,\r\n\t\tstatus: status,\r\n\t\tfs:     fs,\r\n\t\tr:      r,\r\n\t\tmsgc:   make(chan raftpb.Message, streamBufSize),\r\n\t\tconnc:  make(chan *outgoingConn),\r\n\t\tstopc:  make(chan struct{}),\r\n\t\tdone:   make(chan struct{}),\r\n\t}\r\n\tgo w.run()\r\n\treturn w\r\n}","code-length":191,"reference":"\/\/ startStreamWriter creates a streamWrite and starts a long running go-routine that accepts\n\/\/ messages and writes to the attached outgoing connection.","result":"Start the stream writer.","score":[0.0035,0.0495]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkStreamSupport(v *semver.Version, t streamType) bool {\r\n\tnv := &semver.Version{Major: v.Major, Minor: v.Minor}\r\n\tfor _, s := range supportedStream[nv.String()] {\r\n\t\tif s == t {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":100,"reference":"\/\/ checkStreamSupport checks whether the stream type is supported in the\n\/\/ given version.","result":"Check if the stream is supported by the server.","score":[0.1376,0.3786]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pr *Progress) maybeUpdate(n uint64) bool {\r\n\tvar updated bool\r\n\tif pr.Match < n {\r\n\t\tpr.Match = n\r\n\t\tupdated = true\r\n\t\tpr.resume()\r\n\t}\r\n\tif pr.Next < n+1 {\r\n\t\tpr.Next = n + 1\r\n\t}\r\n\treturn updated\r\n}","code-length":103,"reference":"\/\/ maybeUpdate returns false if the given n index comes from an outdated message.\n\/\/ Otherwise it updates the progress and returns true.","result":"Check if the progress is updated.","score":[0.0197,0.12]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pr *Progress) IsPaused() bool {\r\n\tswitch pr.State {\r\n\tcase ProgressStateProbe:\r\n\t\treturn pr.Paused\r\n\tcase ProgressStateReplicate:\r\n\t\treturn pr.ins.full()\r\n\tcase ProgressStateSnapshot:\r\n\t\treturn true\r\n\tdefault:\r\n\t\tpanic(\"unexpected state\")\r\n\t}\r\n}","code-length":101,"reference":"\/\/ IsPaused returns whether sending log entries to this node has been\n\/\/ paused. A node may be paused because it has rejected recent\n\/\/ MsgApps, is currently waiting for a snapshot, or has reached the\n\/\/ MaxInflightMsgs limit.","result":"Check if the progress is paused.","score":[0.001,0.042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pr *Progress) needSnapshotAbort() bool {\r\n\treturn pr.State == ProgressStateSnapshot && pr.Match >= pr.PendingSnapshot\r\n}","code-length":44,"reference":"\/\/ needSnapshotAbort returns true if snapshot progress's Match\n\/\/ is equal or higher than the pendingSnapshot.","result":"Generate the code.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *inflights) add(inflight uint64) {\r\n\tif in.full() {\r\n\t\tpanic(\"cannot add into a full inflights\")\r\n\t}\r\n\tnext := in.start + in.count\r\n\tsize := in.size\r\n\tif next >= size {\r\n\t\tnext -= size\r\n\t}\r\n\tif next >= len(in.buffer) {\r\n\t\tin.growBuf()\r\n\t}\r\n\tin.buffer[next] = inflight\r\n\tin.count++\r\n}","code-length":141,"reference":"\/\/ add adds an inflight into inflights","result":"Add to the inflights buffer.","score":[0.1611,0.1471]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *inflights) growBuf() {\r\n\tnewSize := len(in.buffer) * 2\r\n\tif newSize == 0 {\r\n\t\tnewSize = 1\r\n\t} else if newSize > in.size {\r\n\t\tnewSize = in.size\r\n\t}\r\n\tnewBuffer := make([]uint64, newSize)\r\n\tcopy(newBuffer, in.buffer)\r\n\tin.buffer = newBuffer\r\n}","code-length":115,"reference":"\/\/ grow the inflight buffer by doubling up to inflights.size. We grow on demand\n\/\/ instead of preallocating to inflights.size to handle systems which have\n\/\/ thousands of Raft groups per process.","result":"Avoid the need for the function to be executed.","score":[0.0113,0.0505]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *inflights) freeTo(to uint64) {\r\n\tif in.count == 0 || to < in.buffer[in.start] {\r\n\t\t\r\n\t\treturn\r\n\t}\r\n\tidx := in.start\r\n\tvar i int\r\n\tfor i = 0; i < in.count; i++ {\r\n\t\tif to < in.buffer[idx] {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\t\r\n\t\tsize := in.size\r\n\t\tif idx++; idx >= size {\r\n\t\t\tidx -= size\r\n\t\t}\r\n\t}\r\n\t\r\n\tin.count -= i\r\n\tin.start = idx\r\n\tif in.count == 0 {\r\n\t\t\r\n\t\t\r\n\t\tin.start = 0\r\n\t}\r\n}","code-length":204,"reference":"\/\/ freeTo frees the inflights smaller or equal to the given `to` flight.","result":"Free the inflights.","score":[0.0146,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Snapshotter) SaveDBFrom(r io.Reader, id uint64) (int64, error) {\r\n\tstart := time.Now()\r\n\tf, err := ioutil.TempFile(s.dir, \"tmp\")\r\n\tif err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\tvar n int64\r\n\tn, err = io.Copy(f, r)\r\n\tif err == nil {\r\n\t\tfsyncStart := time.Now()\r\n\t\terr = fileutil.Fsync(f)\r\n\t\tsnapDBFsyncSec.Observe(time.Since(fsyncStart).Seconds())\r\n\t}\r\n\tf.Close()\r\n\tif err != nil {\r\n\t\tos.Remove(f.Name())\r\n\t\treturn n, err\r\n\t}\r\n\tfn := s.dbFilePath(id)\r\n\tif fileutil.Exist(fn) {\r\n\t\tos.Remove(f.Name())\r\n\t\treturn n, nil\r\n\t}\r\n\terr = os.Rename(f.Name(), fn)\r\n\tif err != nil {\r\n\t\tos.Remove(f.Name())\r\n\t\treturn n, err\r\n\t}\r\n\tif s.lg != nil {\r\n\t\ts.lg.Info(\r\n\t\t\t\"saved database snapshot to disk\",\r\n\t\t\tzap.String(\"path\", fn),\r\n\t\t\tzap.Int64(\"bytes\", n),\r\n\t\t\tzap.String(\"size\", humanize.Bytes(uint64(n))),\r\n\t\t)\r\n\t} else {\r\n\t\tplog.Infof(\"saved database snapshot to disk [total bytes: %d]\", n)\r\n\t}\r\n\tsnapDBSaveSec.Observe(time.Since(start).Seconds())\r\n\treturn n, nil\r\n}","code-length":448,"reference":"\/\/ SaveDBFrom saves snapshot of the database from the given reader. It\n\/\/ guarantees the save operation is atomic.","result":"Save snapshot to disk.","score":[0.0075,0.0571]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Snapshotter) DBFilePath(id uint64) (string, error) {\r\n\tif _, err := fileutil.ReadDir(s.dir); err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tfn := s.dbFilePath(id)\r\n\tif fileutil.Exist(fn) {\r\n\t\treturn fn, nil\r\n\t}\r\n\tif s.lg != nil {\r\n\t\ts.lg.Warn(\r\n\t\t\t\"failed to find [SNAPSHOT-INDEX].snap.db\",\r\n\t\t\tzap.Uint64(\"snapshot-index\", id),\r\n\t\t\tzap.String(\"snapshot-file-path\", fn),\r\n\t\t\tzap.Error(ErrNoDBSnapshot),\r\n\t\t)\r\n\t}\r\n\treturn \"\", ErrNoDBSnapshot\r\n}","code-length":203,"reference":"\/\/ DBFilePath returns the file path for the snapshot of the database with\n\/\/ given id. If the snapshot does not exist, it returns error.","result":"Generate the generated code.","score":[0.0017,0.0218]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (us *UniqueStringsValue) Set(s string) error {\r\n\tus.Values = make(map[string]struct{})\r\n\tfor _, v := range strings.Split(s, \",\") {\r\n\t\tus.Values[v] = struct{}{}\r\n\t}\r\n\treturn nil\r\n}","code-length":84,"reference":"\/\/ Set parses a command line set of strings, separated by comma.\n\/\/ Implements \"flag.Value\" interface.\n\/\/ The values are set in order.","result":"Set the value of the unique strings value.","score":[0.0253,0.093]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewUniqueStringsValue(s string) (us *UniqueStringsValue) {\r\n\tus = &UniqueStringsValue{Values: make(map[string]struct{})}\r\n\tif s == \"\" {\r\n\t\treturn us\r\n\t}\r\n\tif err := us.Set(s); err != nil {\r\n\t\tplog.Panicf(\"new UniqueStringsValue should never fail: %v\", err)\r\n\t}\r\n\treturn us\r\n}","code-length":116,"reference":"\/\/ NewUniqueStringsValue implements string slice as \"flag.Value\" interface.\n\/\/ Given value is to be separated by comma.\n\/\/ The values are set in order.","result":"Create a new unique string value.","score":[0.0096,0.0225]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UniqueStringsFromFlag(fs *flag.FlagSet, flagName string) []string {\r\n\treturn (*fs.Lookup(flagName).Value.(*UniqueStringsValue)).stringSlice()\r\n}","code-length":56,"reference":"\/\/ UniqueStringsFromFlag returns a string slice from the flag.","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UniqueStringsMapFromFlag(fs *flag.FlagSet, flagName string) map[string]struct{} {\r\n\treturn (*fs.Lookup(flagName).Value.(*UniqueStringsValue)).Values\r\n}","code-length":59,"reference":"\/\/ UniqueStringsMapFromFlag returns a map of strings from the flag.","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Percentiles(nums []float64) (pcs []float64, data []float64) {\r\n\treturn pctls, percentiles(nums)\r\n}","code-length":46,"reference":"\/\/ Percentiles returns percentile distribution of float64 slice.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ServerConfig) VerifyBootstrap() error {\r\n\tif err := c.hasLocalMember(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := c.advertiseMatchesCluster(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif checkDuplicateURL(c.InitialPeerURLsMap) {\r\n\t\treturn fmt.Errorf(\"initial cluster %s has duplicate url\", c.InitialPeerURLsMap)\r\n\t}\r\n\tif c.InitialPeerURLsMap.String() == \"\" && c.DiscoveryURL == \"\" {\r\n\t\treturn fmt.Errorf(\"initial cluster unset and no discovery URL found\")\r\n\t}\r\n\treturn nil\r\n}","code-length":171,"reference":"\/\/ VerifyBootstrap sanity-checks the initial config for bootstrap case\n\/\/ and returns an error for things that should never happen.","result":"Generate code for generated code.","score":[0.012,0.027]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ServerConfig) VerifyJoinExisting() error {\r\n\t\r\n\t\r\n\tif err := c.hasLocalMember(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif checkDuplicateURL(c.InitialPeerURLsMap) {\r\n\t\treturn fmt.Errorf(\"initial cluster %s has duplicate url\", c.InitialPeerURLsMap)\r\n\t}\r\n\tif c.DiscoveryURL != \"\" {\r\n\t\treturn fmt.Errorf(\"discovery URL should not be set when joining existing initial cluster\")\r\n\t}\r\n\treturn nil\r\n}","code-length":142,"reference":"\/\/ VerifyJoinExisting sanity-checks the initial config for join existing cluster\n\/\/ case and returns an error for things that should never happen.","result":"Verify the join existing initial cluster.","score":[0.0226,0.1547]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ServerConfig) hasLocalMember() error {\r\n\tif urls := c.InitialPeerURLsMap[c.Name]; urls == nil {\r\n\t\treturn fmt.Errorf(\"couldn't find local name %q in the initial cluster configuration\", c.Name)\r\n\t}\r\n\treturn nil\r\n}","code-length":82,"reference":"\/\/ hasLocalMember checks that the cluster at least contains the local server.","result":"Check if local member exists.","score":[0.0593,0.0885]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ServerConfig) advertiseMatchesCluster() error {\r\n\turls, apurls := c.InitialPeerURLsMap[c.Name], c.PeerURLs.StringSlice()\r\n\turls.Sort()\r\n\tsort.Strings(apurls)\r\n\tctx, cancel := context.WithTimeout(context.TODO(), 30*time.Second)\r\n\tdefer cancel()\r\n\tok, err := netutil.URLStringsEqual(ctx, c.Logger, apurls, urls.StringSlice())\r\n\tif ok {\r\n\t\treturn nil\r\n\t}\r\n\tinitMap, apMap := make(map[string]struct{}), make(map[string]struct{})\r\n\tfor _, url := range c.PeerURLs {\r\n\t\tapMap[url.String()] = struct{}{}\r\n\t}\r\n\tfor _, url := range c.InitialPeerURLsMap[c.Name] {\r\n\t\tinitMap[url.String()] = struct{}{}\r\n\t}\r\n\tmissing := []string{}\r\n\tfor url := range initMap {\r\n\t\tif _, ok := apMap[url]; !ok {\r\n\t\t\tmissing = append(missing, url)\r\n\t\t}\r\n\t}\r\n\tif len(missing) > 0 {\r\n\t\tfor i := range missing {\r\n\t\t\tmissing[i] = c.Name + \"=\" + missing[i]\r\n\t\t}\r\n\t\tmstr := strings.Join(missing, \",\")\r\n\t\tapStr := strings.Join(apurls, \",\")\r\n\t\treturn fmt.Errorf(\"--initial-cluster has %s but missing from --initial-advertise-peer-urls=%s (%v)\", mstr, apStr, err)\r\n\t}\r\n\tfor url := range apMap {\r\n\t\tif _, ok := initMap[url]; !ok {\r\n\t\t\tmissing = append(missing, url)\r\n\t\t}\r\n\t}\r\n\tif len(missing) > 0 {\r\n\t\tmstr := strings.Join(missing, \",\")\r\n\t\tumap := types.URLsMap(map[string]types.URLs{c.Name: c.PeerURLs})\r\n\t\treturn fmt.Errorf(\"--initial-advertise-peer-urls has %s but missing from --initial-cluster=%s\", mstr, umap.String())\r\n\t}\r\n\t\r\n\tapStr := strings.Join(apurls, \",\")\r\n\tumap := types.URLsMap(map[string]types.URLs{c.Name: c.PeerURLs})\r\n\treturn fmt.Errorf(\"failed to resolve %s to match --initial-cluster=%s (%v)\", apStr, umap.String(), err)\r\n}","code-length":648,"reference":"\/\/ advertiseMatchesCluster confirms peer URLs match those in the cluster peer list.","result":"Code too long,keep in 512.","score":[0.0593,0.0442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ServerConfig) ReqTimeout() time.Duration {\r\n\t\r\n\t\r\n\treturn 5*time.Second + 2*time.Duration(c.ElectionTicks*int(c.TickMs))*time.Millisecond\r\n}","code-length":66,"reference":"\/\/ ReqTimeout returns timeout for request to finish.","result":"Set the default timeout.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getStatus(r *raft) Status {\r\n\ts := getStatusWithoutProgress(r)\r\n\tif s.RaftState == StateLeader {\r\n\t\ts.Progress = getProgressCopy(r)\r\n\t}\r\n\treturn s\r\n}","code-length":68,"reference":"\/\/ getStatus gets a copy of the current raft status.","result":"Get the status of the raft.","score":[0.1402,0.2662]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetDefaultHost() (string, error) {\r\n\trmsgs, rerr := getDefaultRoutes()\r\n\tif rerr != nil {\r\n\t\treturn \"\", rerr\r\n\t}\r\n\t\r\n\tif rmsg, ok := rmsgs[syscall.AF_INET]; ok {\r\n\t\tif host, err := chooseHost(syscall.AF_INET, rmsg); host != \"\" || err != nil {\r\n\t\t\treturn host, err\r\n\t\t}\r\n\t\tdelete(rmsgs, syscall.AF_INET)\r\n\t}\r\n\t\r\n\tvar families []int\r\n\tfor family := range rmsgs {\r\n\t\tfamilies = append(families, int(family))\r\n\t}\r\n\tsort.Ints(families)\r\n\tfor _, f := range families {\r\n\t\tfamily := uint8(f)\r\n\t\tif host, err := chooseHost(family, rmsgs[family]); host != \"\" || err != nil {\r\n\t\t\treturn host, err\r\n\t\t}\r\n\t}\r\n\treturn \"\", errNoDefaultHost\r\n}","code-length":267,"reference":"\/\/ GetDefaultHost obtains the first IP address of machine from the routing table and returns the IP address as string.\n\/\/ An IPv4 address is preferred to an IPv6 address for backward compatibility.","result":"Get the default host name.","score":[0.0009,0.0331]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getIfaceAddr(idx uint32, family uint8) (*syscall.NetlinkMessage, error) {\r\n\tdat, err := syscall.NetlinkRIB(syscall.RTM_GETADDR, int(family))\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tmsgs, msgErr := syscall.ParseNetlinkMessage(dat)\r\n\tif msgErr != nil {\r\n\t\treturn nil, msgErr\r\n\t}\r\n\tifaddrmsg := syscall.IfAddrmsg{}\r\n\tfor _, m := range msgs {\r\n\t\tif m.Header.Type != syscall.RTM_NEWADDR {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tbuf := bytes.NewBuffer(m.Data[:syscall.SizeofIfAddrmsg])\r\n\t\tif rerr := binary.Read(buf, cpuutil.ByteOrder(), &ifaddrmsg); rerr != nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif ifaddrmsg.Index == idx {\r\n\t\t\treturn &m, nil\r\n\t\t}\r\n\t}\r\n\treturn nil, fmt.Errorf(\"could not find address for interface index %v\", idx)\r\n}","code-length":293,"reference":"\/\/ Used to get an address of interface.","result":"Get the interface address of an interface.","score":[0.2355,0.4709]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getIfaceLink(idx uint32) (*syscall.NetlinkMessage, error) {\r\n\tdat, err := syscall.NetlinkRIB(syscall.RTM_GETLINK, syscall.AF_UNSPEC)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tmsgs, msgErr := syscall.ParseNetlinkMessage(dat)\r\n\tif msgErr != nil {\r\n\t\treturn nil, msgErr\r\n\t}\r\n\tifinfomsg := syscall.IfInfomsg{}\r\n\tfor _, m := range msgs {\r\n\t\tif m.Header.Type != syscall.RTM_NEWLINK {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tbuf := bytes.NewBuffer(m.Data[:syscall.SizeofIfInfomsg])\r\n\t\tif rerr := binary.Read(buf, cpuutil.ByteOrder(), &ifinfomsg); rerr != nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif ifinfomsg.Index == int32(idx) {\r\n\t\t\treturn &m, nil\r\n\t\t}\r\n\t}\r\n\treturn nil, fmt.Errorf(\"could not find link for interface index %v\", idx)\r\n}","code-length":301,"reference":"\/\/ Used to get a name of interface.","result":"Get the interface link for the given interface index.","score":[0,0.0617]}
{"code":"\/*is used to<extra_id_0>\r\nfunc lsCommandFunc(c *cli.Context, ki client.KeysAPI) {\r\n\tkey := \"\/\"\r\n\tif len(c.Args()) != 0 {\r\n\t\tkey = c.Args()[0]\r\n\t}\r\n\tsort := c.Bool(\"sort\")\r\n\trecursive := c.Bool(\"recursive\")\r\n\tquorum := c.Bool(\"quorum\")\r\n\tctx, cancel := contextWithTotalTimeout(c)\r\n\tresp, err := ki.Get(ctx, key, &client.GetOptions{Sort: sort, Recursive: recursive, Quorum: quorum})\r\n\tcancel()\r\n\tif err != nil {\r\n\t\thandleError(c, ExitServerError, err)\r\n\t}\r\n\tprintLs(c, resp)\r\n}","code-length":191,"reference":"\/\/ lsCommandFunc executes the \"ls\" command.","result":"Generate the code.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc printLs(c *cli.Context, resp *client.Response) {\r\n\tif c.GlobalString(\"output\") == \"simple\" {\r\n\t\tif !resp.Node.Dir {\r\n\t\t\tfmt.Println(resp.Node.Key)\r\n\t\t}\r\n\t\tfor _, node := range resp.Node.Nodes {\r\n\t\t\trPrint(c, node)\r\n\t\t}\r\n\t} else {\r\n\t\t\r\n\t\tprintResponseKey(resp, c.GlobalString(\"output\"))\r\n\t}\r\n}","code-length":141,"reference":"\/\/ printLs writes a response out in a manner similar to the `ls` command in unix.\n\/\/ Non-empty directories list their contents and files list their name.","result":"Print the list of objects.","score":[0.0035,0.0403]}
{"code":"\/*is used to<extra_id_0>\r\nfunc rPrint(c *cli.Context, n *client.Node) {\r\n\tif n.Dir && c.Bool(\"p\") {\r\n\t\tfmt.Println(fmt.Sprintf(\"%v\/\", n.Key))\r\n\t} else {\r\n\t\tfmt.Println(n.Key)\r\n\t}\r\n\tfor _, node := range n.Nodes {\r\n\t\trPrint(c, node)\r\n\t}\r\n}","code-length":116,"reference":"\/\/ rPrint recursively prints out the nodes in the node structure.","result":"Print the contents of the node.","score":[0.0998,0.1429]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLeaseRenewerCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"lease-renewer\",\r\n\t\tShort: \"Performs lease renew operation\",\r\n\t\tRun:   runLeaseRenewerFunc,\r\n\t}\r\n\tcmd.Flags().Int64Var(&leaseTTL, \"ttl\", 5, \"lease's ttl\")\r\n\treturn cmd\r\n}","code-length":111,"reference":"\/\/ NewLeaseRenewerCommand returns the cobra command for \"lease-renewer runner\".","result":"Create a new command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Read(lg *zap.Logger, snapname string) (*raftpb.Snapshot, error) {\r\n\tb, err := ioutil.ReadFile(snapname)\r\n\tif err != nil {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\"failed to read a snap file\", zap.String(\"path\", snapname), zap.Error(err))\r\n\t\t} else {\r\n\t\t\tplog.Errorf(\"cannot read file %v: %v\", snapname, err)\r\n\t\t}\r\n\t\treturn nil, err\r\n\t}\r\n\tif len(b) == 0 {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\"failed to read empty snapshot file\", zap.String(\"path\", snapname))\r\n\t\t} else {\r\n\t\t\tplog.Errorf(\"unexpected empty snapshot\")\r\n\t\t}\r\n\t\treturn nil, ErrEmptySnapshot\r\n\t}\r\n\tvar serializedSnap snappb.Snapshot\r\n\tif err = serializedSnap.Unmarshal(b); err != nil {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\"failed to unmarshal snappb.Snapshot\", zap.String(\"path\", snapname), zap.Error(err))\r\n\t\t} else {\r\n\t\t\tplog.Errorf(\"corrupted snapshot file %v: %v\", snapname, err)\r\n\t\t}\r\n\t\treturn nil, err\r\n\t}\r\n\tif len(serializedSnap.Data) == 0 || serializedSnap.Crc == 0 {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\"failed to read empty snapshot data\", zap.String(\"path\", snapname))\r\n\t\t} else {\r\n\t\t\tplog.Errorf(\"unexpected empty snapshot\")\r\n\t\t}\r\n\t\treturn nil, ErrEmptySnapshot\r\n\t}\r\n\tcrc := crc32.Update(0, crcTable, serializedSnap.Data)\r\n\tif crc != serializedSnap.Crc {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\"snap file is corrupt\",\r\n\t\t\t\tzap.String(\"path\", snapname),\r\n\t\t\t\tzap.Uint32(\"prev-crc\", serializedSnap.Crc),\r\n\t\t\t\tzap.Uint32(\"new-crc\", crc),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Errorf(\"corrupted snapshot file %v: crc mismatch\", snapname)\r\n\t\t}\r\n\t\treturn nil, ErrCRCMismatch\r\n\t}\r\n\tvar snap raftpb.Snapshot\r\n\tif err = snap.Unmarshal(serializedSnap.Data); err != nil {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\"failed to unmarshal raftpb.Snapshot\", zap.String(\"path\", snapname), zap.Error(err))\r\n\t\t} else {\r\n\t\t\tplog.Errorf(\"corrupted snapshot file %v: %v\", snapname, err)\r\n\t\t}\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &snap, nil\r\n}","code-length":723,"reference":"\/\/ Read reads the snapshot named by snapname and returns the snapshot.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetCipherSuite(s string) (uint16, bool) {\r\n\tv, ok := cipherSuites[s]\r\n\treturn v, ok\r\n}","code-length":46,"reference":"\/\/ GetCipherSuite returns the corresponding cipher suite,\n\/\/ and boolean value if it is supported.","result":"Generate the generated code.","score":[0.0204,0.036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *pipeline) post(data []byte) (err error) {\r\n\tu := p.picker.pick()\r\n\treq := createPostRequest(u, RaftPrefix, bytes.NewBuffer(data), \"application\/protobuf\", p.tr.URLs, p.tr.ID, p.tr.ClusterID)\r\n\tdone := make(chan struct{}, 1)\r\n\tctx, cancel := context.WithCancel(context.Background())\r\n\treq = req.WithContext(ctx)\r\n\tgo func() {\r\n\t\tselect {\r\n\t\tcase <-done:\r\n\t\tcase <-p.stopc:\r\n\t\t\twaitSchedule()\r\n\t\t\tcancel()\r\n\t\t}\r\n\t}()\r\n\tresp, err := p.tr.pipelineRt.RoundTrip(req)\r\n\tdone <- struct{}{}\r\n\tif err != nil {\r\n\t\tp.picker.unreachable(u)\r\n\t\treturn err\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\tb, err := ioutil.ReadAll(resp.Body)\r\n\tif err != nil {\r\n\t\tp.picker.unreachable(u)\r\n\t\treturn err\r\n\t}\r\n\terr = checkPostResponse(resp, b, req, p.peerID)\r\n\tif err != nil {\r\n\t\tp.picker.unreachable(u)\r\n\t\t\r\n\t\t\r\n\t\tif err == errMemberRemoved {\r\n\t\t\treportCriticalError(err, p.errorc)\r\n\t\t}\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":390,"reference":"\/\/ post POSTs a data payload to a url. Returns nil if the POST succeeds,\n\/\/ error on any failure.","result":"Post data to Raft members.","score":[0.0142,0.0811]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) send(m pb.Message) {\r\n\tm.From = r.id\r\n\tif m.Type == pb.MsgVote || m.Type == pb.MsgVoteResp || m.Type == pb.MsgPreVote || m.Type == pb.MsgPreVoteResp {\r\n\t\tif m.Term == 0 {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tpanic(fmt.Sprintf(\"term should be set when sending %s\", m.Type))\r\n\t\t}\r\n\t} else {\r\n\t\tif m.Term != 0 {\r\n\t\t\tpanic(fmt.Sprintf(\"term should not be set when sending %s (was %d)\", m.Type, m.Term))\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif m.Type != pb.MsgProp && m.Type != pb.MsgReadIndex {\r\n\t\t\tm.Term = r.Term\r\n\t\t}\r\n\t}\r\n\tr.msgs = append(r.msgs, m)\r\n}","code-length":285,"reference":"\/\/ send persists state to stable storage and then sends to its mailbox.","result":"Send messages to the raft.","score":[0.0485,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) sendHeartbeat(to uint64, ctx []byte) {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tcommit := min(r.getProgress(to).Match, r.raftLog.committed)\r\n\tm := pb.Message{\r\n\t\tTo:      to,\r\n\t\tType:    pb.MsgHeartbeat,\r\n\t\tCommit:  commit,\r\n\t\tContext: ctx,\r\n\t}\r\n\tr.send(m)\r\n}","code-length":132,"reference":"\/\/ sendHeartbeat sends a heartbeat RPC to the given peer.","result":"Send heartbeat messages.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) bcastAppend() {\r\n\tr.forEachProgress(func(id uint64, _ *Progress) {\r\n\t\tif id == r.id {\r\n\t\t\treturn\r\n\t\t}\r\n\t\tr.sendAppend(id)\r\n\t})\r\n}","code-length":79,"reference":"\/\/ bcastAppend sends RPC, with entries to all peers that are not up-to-date\n\/\/ according to the progress recorded in r.prs.","result":"Bcast the append.","score":[0.001,0.026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) bcastHeartbeat() {\r\n\tlastCtx := r.readOnly.lastPendingRequestCtx()\r\n\tif len(lastCtx) == 0 {\r\n\t\tr.bcastHeartbeatWithCtx(nil)\r\n\t} else {\r\n\t\tr.bcastHeartbeatWithCtx([]byte(lastCtx))\r\n\t}\r\n}","code-length":93,"reference":"\/\/ bcastHeartbeat sends RPC, without entries to all the peers.","result":"Bcast heartbeat.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) tickElection() {\r\n\tr.electionElapsed++\r\n\tif r.promotable() && r.pastElectionTimeout() {\r\n\t\tr.electionElapsed = 0\r\n\t\tr.Step(pb.Message{From: r.id, Type: pb.MsgHup})\r\n\t}\r\n}","code-length":91,"reference":"\/\/ tickElection is run by followers and candidates after r.electionTimeout.","result":"Tick the election.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) tickHeartbeat() {\r\n\tr.heartbeatElapsed++\r\n\tr.electionElapsed++\r\n\tif r.electionElapsed >= r.electionTimeout {\r\n\t\tr.electionElapsed = 0\r\n\t\tif r.checkQuorum {\r\n\t\t\tr.Step(pb.Message{From: r.id, Type: pb.MsgCheckQuorum})\r\n\t\t}\r\n\t\t\r\n\t\tif r.state == StateLeader && r.leadTransferee != None {\r\n\t\t\tr.abortLeaderTransfer()\r\n\t\t}\r\n\t}\r\n\tif r.state != StateLeader {\r\n\t\treturn\r\n\t}\r\n\tif r.heartbeatElapsed >= r.heartbeatTimeout {\r\n\t\tr.heartbeatElapsed = 0\r\n\t\tr.Step(pb.Message{From: r.id, Type: pb.MsgBeat})\r\n\t}\r\n}","code-length":223,"reference":"\/\/ tickHeartbeat is run by leaders to send a MsgBeat after r.heartbeatTimeout.","result":"Tick heartbeat timeout.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc stepCandidate(r *raft, m pb.Message) error {\r\n\t\r\n\t\r\n\t\r\n\tvar myVoteRespType pb.MessageType\r\n\tif r.state == StatePreCandidate {\r\n\t\tmyVoteRespType = pb.MsgPreVoteResp\r\n\t} else {\r\n\t\tmyVoteRespType = pb.MsgVoteResp\r\n\t}\r\n\tswitch m.Type {\r\n\tcase pb.MsgProp:\r\n\t\tr.logger.Infof(\"%x no leader at term %d; dropping proposal\", r.id, r.Term)\r\n\t\treturn ErrProposalDropped\r\n\tcase pb.MsgApp:\r\n\t\tr.becomeFollower(m.Term, m.From)\r\n\t\tr.handleAppendEntries(m)\r\n\tcase pb.MsgHeartbeat:\r\n\t\tr.becomeFollower(m.Term, m.From)\r\n\t\tr.handleHeartbeat(m)\r\n\tcase pb.MsgSnap:\r\n\t\tr.becomeFollower(m.Term, m.From)\r\n\t\tr.handleSnapshot(m)\r\n\tcase myVoteRespType:\r\n\t\tgr := r.poll(m.From, m.Type, !m.Reject)\r\n\t\tr.logger.Infof(\"%x [quorum:%d] has received %d %s votes and %d vote rejections\", r.id, r.quorum(), gr, m.Type, len(r.votes)-gr)\r\n\t\tswitch r.quorum() {\r\n\t\tcase gr:\r\n\t\t\tif r.state == StatePreCandidate {\r\n\t\t\t\tr.campaign(campaignElection)\r\n\t\t\t} else {\r\n\t\t\t\tr.becomeLeader()\r\n\t\t\t\tr.bcastAppend()\r\n\t\t\t}\r\n\t\tcase len(r.votes) - gr:\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tr.becomeFollower(r.Term, None)\r\n\t\t}\r\n\tcase pb.MsgTimeoutNow:\r\n\t\tr.logger.Debugf(\"%x [term %d state %v] ignored MsgTimeoutNow from %x\", r.id, r.Term, r.state, m.From)\r\n\t}\r\n\treturn nil\r\n}","code-length":543,"reference":"\/\/ stepCandidate is shared by StateCandidate and StatePreCandidate; the difference is\n\/\/ whether they respond to MsgVoteResp or MsgPreVoteResp.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) restore(s pb.Snapshot) bool {\r\n\tif s.Metadata.Index <= r.raftLog.committed {\r\n\t\treturn false\r\n\t}\r\n\tif r.raftLog.matchTerm(s.Metadata.Index, s.Metadata.Term) {\r\n\t\tr.logger.Infof(\"%x [commit: %d, lastindex: %d, lastterm: %d] fast-forwarded commit to snapshot [index: %d, term: %d]\",\r\n\t\t\tr.id, r.raftLog.committed, r.raftLog.lastIndex(), r.raftLog.lastTerm(), s.Metadata.Index, s.Metadata.Term)\r\n\t\tr.raftLog.commitTo(s.Metadata.Index)\r\n\t\treturn false\r\n\t}\r\n\t\r\n\tif !r.isLearner {\r\n\t\tfor _, id := range s.Metadata.ConfState.Learners {\r\n\t\t\tif id == r.id {\r\n\t\t\t\tr.logger.Errorf(\"%x can't become learner when restores snapshot [index: %d, term: %d]\", r.id, s.Metadata.Index, s.Metadata.Term)\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tr.logger.Infof(\"%x [commit: %d, lastindex: %d, lastterm: %d] starts to restore snapshot [index: %d, term: %d]\",\r\n\t\tr.id, r.raftLog.committed, r.raftLog.lastIndex(), r.raftLog.lastTerm(), s.Metadata.Index, s.Metadata.Term)\r\n\tr.raftLog.restore(s)\r\n\tr.prs = make(map[uint64]*Progress)\r\n\tr.learnerPrs = make(map[uint64]*Progress)\r\n\tr.restoreNode(s.Metadata.ConfState.Nodes, false)\r\n\tr.restoreNode(s.Metadata.ConfState.Learners, true)\r\n\treturn true\r\n}","code-length":497,"reference":"\/\/ restore recovers the state machine from a snapshot. It restores the log and the\n\/\/ configuration of state machine.","result":"Restore raft log.","score":[0,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) promotable() bool {\r\n\t_, ok := r.prs[r.id]\r\n\treturn ok\r\n}","code-length":45,"reference":"\/\/ promotable indicates whether state machine can be promoted to leader,\n\/\/ which is true when its own id is in progress list.","result":"Check if promotable.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) checkQuorumActive() bool {\r\n\tvar act int\r\n\tr.forEachProgress(func(id uint64, pr *Progress) {\r\n\t\tif id == r.id {\r\n\t\t\tact++\r\n\t\t\treturn\r\n\t\t}\r\n\t\tif pr.RecentActive && !pr.IsLearner {\r\n\t\t\tact++\r\n\t\t}\r\n\t\tpr.RecentActive = false\r\n\t})\r\n\treturn act >= r.quorum()\r\n}","code-length":130,"reference":"\/\/ checkQuorumActive returns true if the quorum is active from\n\/\/ the view of the local raft state machine. Otherwise, it returns\n\/\/ false.\n\/\/ checkQuorumActive also resets all RecentActive to false.","result":"Check quorum active.","score":[0.0,0.0172]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) increaseUncommittedSize(ents []pb.Entry) bool {\r\n\tvar s uint64\r\n\tfor _, e := range ents {\r\n\t\ts += uint64(PayloadSize(e))\r\n\t}\r\n\tif r.uncommittedSize > 0 && r.uncommittedSize+s > r.maxUncommittedSize {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\treturn false\r\n\t}\r\n\tr.uncommittedSize += s\r\n\treturn true\r\n}","code-length":134,"reference":"\/\/ increaseUncommittedSize computes the size of the proposed entries and\n\/\/ determines whether they would push leader over its maxUncommittedSize limit.\n\/\/ If the new entries would exceed the limit, the method returns false. If not,\n\/\/ the increase in uncommitted entry size is recorded and the method returns\n\/\/ true.","result":"Increase the uncommitted size of the.","score":[0.0002,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) reduceUncommittedSize(ents []pb.Entry) {\r\n\tif r.uncommittedSize == 0 {\r\n\t\t\r\n\t\treturn\r\n\t}\r\n\tvar s uint64\r\n\tfor _, e := range ents {\r\n\t\ts += uint64(PayloadSize(e))\r\n\t}\r\n\tif s > r.uncommittedSize {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tr.uncommittedSize = 0\r\n\t} else {\r\n\t\tr.uncommittedSize -= s\r\n\t}\r\n}","code-length":149,"reference":"\/\/ reduceUncommittedSize accounts for the newly committed entries by decreasing\n\/\/ the uncommitted entry size limit.","result":"Avoid the need for a function.","score":[0.0434,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newPeriodic(lg *zap.Logger, clock clockwork.Clock, h time.Duration, rg RevGetter, c Compactable) *Periodic {\r\n\tpc := &Periodic{\r\n\t\tlg:     lg,\r\n\t\tclock:  clock,\r\n\t\tperiod: h,\r\n\t\trg:     rg,\r\n\t\tc:      c,\r\n\t\trevs:   make([]int64, 0),\r\n\t}\r\n\tpc.ctx, pc.cancel = context.WithCancel(context.Background())\r\n\treturn pc\r\n}","code-length":142,"reference":"\/\/ newPeriodic creates a new instance of Periodic compactor that purges\n\/\/ the log older than h Duration.","result":"Create a new periodic.","score":[0.0136,0.1774]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pc *Periodic) Pause() {\r\n\tpc.mu.Lock()\r\n\tpc.paused = true\r\n\tpc.mu.Unlock()\r\n}","code-length":48,"reference":"\/\/ Pause pauses periodic compactor.","result":"Avoid recursive call to Pause.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pc *Periodic) Resume() {\r\n\tpc.mu.Lock()\r\n\tpc.paused = false\r\n\tpc.mu.Unlock()\r\n}","code-length":49,"reference":"\/\/ Resume resumes periodic compactor.","result":"Avoid recursive call to Resume.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Mutex) Lock(ctx context.Context) error {\r\n\ts := m.s\r\n\tclient := m.s.Client()\r\n\tm.myKey = fmt.Sprintf(\"%s%x\", m.pfx, s.Lease())\r\n\tcmp := v3.Compare(v3.CreateRevision(m.myKey), \"=\", 0)\r\n\t\r\n\tput := v3.OpPut(m.myKey, \"\", v3.WithLease(s.Lease()))\r\n\t\r\n\tget := v3.OpGet(m.myKey)\r\n\t\r\n\tgetOwner := v3.OpGet(m.pfx, v3.WithFirstCreate()...)\r\n\tresp, err := client.Txn(ctx).If(cmp).Then(put, getOwner).Else(get, getOwner).Commit()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tm.myRev = resp.Header.Revision\r\n\tif !resp.Succeeded {\r\n\t\tm.myRev = resp.Responses[0].GetResponseRange().Kvs[0].CreateRevision\r\n\t}\r\n\t\r\n\townerKey := resp.Responses[1].GetResponseRange().Kvs\r\n\tif len(ownerKey) == 0 || ownerKey[0].CreateRevision == m.myRev {\r\n\t\tm.hdr = resp.Header\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\thdr, werr := waitDeletes(ctx, client, m.pfx, m.myRev-1)\r\n\t\r\n\tif werr != nil {\r\n\t\tm.Unlock(client.Ctx())\r\n\t} else {\r\n\t\tm.hdr = hdr\r\n\t}\r\n\treturn werr\r\n}","code-length":422,"reference":"\/\/ Lock locks the mutex with a cancelable context. If the context is canceled\n\/\/ while trying to acquire the lock, the mutex tries to clean its stale lock entry.","result":"Lock the mutex.","score":[0.0001,0.0366]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLocker(s *Session, pfx string) sync.Locker {\r\n\treturn &lockerMutex{NewMutex(s, pfx)}\r\n}","code-length":45,"reference":"\/\/ NewLocker creates a sync.Locker backed by an etcd mutex.","result":"Create a new locker.","score":[0.0713,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFIFOScheduler() Scheduler {\r\n\tf := &fifo{\r\n\t\tresume: make(chan struct{}, 1),\r\n\t\tdonec:  make(chan struct{}, 1),\r\n\t}\r\n\tf.finishCond = sync.NewCond(&f.mu)\r\n\tf.ctx, f.cancel = context.WithCancel(context.Background())\r\n\tgo f.run()\r\n\treturn f\r\n}","code-length":114,"reference":"\/\/ NewFIFOScheduler returns a Scheduler that schedules jobs in FIFO\n\/\/ order sequentially","result":"Create a new scheduler.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *fifo) Schedule(j Job) {\r\n\tf.mu.Lock()\r\n\tdefer f.mu.Unlock()\r\n\tif f.cancel == nil {\r\n\t\tpanic(\"schedule: schedule to stopped scheduler\")\r\n\t}\r\n\tif len(f.pendings) == 0 {\r\n\t\tselect {\r\n\t\tcase f.resume <- struct{}{}:\r\n\t\tdefault:\r\n\t\t}\r\n\t}\r\n\tf.pendings = append(f.pendings, j)\r\n}","code-length":137,"reference":"\/\/ Schedule schedules a job that will be ran in FIFO order sequentially.","result":"Schedule jobs to stopped scheduler.","score":[0.0485,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *fifo) Stop() {\r\n\tf.mu.Lock()\r\n\tf.cancel()\r\n\tf.cancel = nil\r\n\tf.mu.Unlock()\r\n\t<-f.donec\r\n}","code-length":64,"reference":"\/\/ Stop stops the scheduler and cancels all pending jobs.","result":"Stop the fifo.","score":[0.0471,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewServer(\r\n\tlg *zap.Logger,\r\n\tnetwork string,\r\n\taddress string,\r\n) *Server {\r\n\treturn &Server{\r\n\t\tlg:                         lg,\r\n\t\tnetwork:                    network,\r\n\t\taddress:                    address,\r\n\t\tlast:                       rpcpb.Operation_NOT_STARTED,\r\n\t\tadvertiseClientPortToProxy: make(map[int]proxy.Server),\r\n\t\tadvertisePeerPortToProxy:   make(map[int]proxy.Server),\r\n\t}\r\n}","code-length":141,"reference":"\/\/ NewServer returns a new agent server.","result":"Create a new server.","score":[0.2362,0.3814]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (srv *Server) StartServe() error {\r\n\tvar err error\r\n\tsrv.ln, err = net.Listen(srv.network, srv.address)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tvar opts []grpc.ServerOption\r\n\topts = append(opts, grpc.MaxRecvMsgSize(int(maxRequestBytes+grpcOverheadBytes)))\r\n\topts = append(opts, grpc.MaxSendMsgSize(maxSendBytes))\r\n\topts = append(opts, grpc.MaxConcurrentStreams(maxStreams))\r\n\tsrv.grpcServer = grpc.NewServer(opts...)\r\n\trpcpb.RegisterTransportServer(srv.grpcServer, srv)\r\n\tsrv.lg.Info(\r\n\t\t\"gRPC server started\",\r\n\t\tzap.String(\"address\", srv.address),\r\n\t\tzap.String(\"listener-address\", srv.ln.Addr().String()),\r\n\t)\r\n\terr = srv.grpcServer.Serve(srv.ln)\r\n\tif err != nil && strings.Contains(err.Error(), \"use of closed network connection\") {\r\n\t\tsrv.lg.Info(\r\n\t\t\t\"gRPC server is shut down\",\r\n\t\t\tzap.String(\"address\", srv.address),\r\n\t\t\tzap.Error(err),\r\n\t\t)\r\n\t} else {\r\n\t\tsrv.lg.Warn(\r\n\t\t\t\"gRPC server returned with error\",\r\n\t\t\tzap.String(\"address\", srv.address),\r\n\t\t\tzap.Error(err),\r\n\t\t)\r\n\t}\r\n\treturn err\r\n}","code-length":396,"reference":"\/\/ StartServe starts serving agent server.","result":"Start the server.","score":[0.1502,0.1754]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (srv *Server) Stop() {\r\n\tsrv.lg.Info(\"gRPC server stopping\", zap.String(\"address\", srv.address))\r\n\tsrv.grpcServer.Stop()\r\n\tsrv.lg.Info(\"gRPC server stopped\", zap.String(\"address\", srv.address))\r\n}","code-length":79,"reference":"\/\/ Stop stops serving gRPC server.","result":"Stop the server.","score":[0.1786,0.1754]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (srv *Server) Transport(stream rpcpb.Transport_TransportServer) (err error) {\r\n\terrc := make(chan error)\r\n\tgo func() {\r\n\t\tfor {\r\n\t\t\tvar req *rpcpb.Request\r\n\t\t\treq, err = stream.Recv()\r\n\t\t\tif err != nil {\r\n\t\t\t\terrc <- err\r\n\t\t\t\t\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tif req.Member != nil {\r\n\t\t\t\tsrv.Member = req.Member\r\n\t\t\t}\r\n\t\t\tif req.Tester != nil {\r\n\t\t\t\tsrv.Tester = req.Tester\r\n\t\t\t}\r\n\t\t\tvar resp *rpcpb.Response\r\n\t\t\tresp, err = srv.handleTesterRequest(req)\r\n\t\t\tif err != nil {\r\n\t\t\t\terrc <- err\r\n\t\t\t\t\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tif err = stream.Send(resp); err != nil {\r\n\t\t\t\terrc <- err\r\n\t\t\t\t\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t}\r\n\t}()\r\n\tselect {\r\n\tcase err = <-errc:\r\n\tcase <-stream.Context().Done():\r\n\t\terr = stream.Context().Err()\r\n\t}\r\n\treturn err\r\n}","code-length":321,"reference":"\/\/ Transport communicates with etcd tester.","result":"Serve the transport RPCs.","score":[0,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterInterruptHandler(h InterruptHandler) {\r\n\tinterruptRegisterMu.Lock()\r\n\tdefer interruptRegisterMu.Unlock()\r\n\tinterruptHandlers = append(interruptHandlers, h)\r\n}","code-length":55,"reference":"\/\/ RegisterInterruptHandler registers a new InterruptHandler. Handlers registered\n\/\/ after interrupt handing was initiated will not be executed.","result":"Register the InterruptHandler.","score":[0.0028,0.0606]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HandleInterrupts(lg *zap.Logger) {\r\n\tnotifier := make(chan os.Signal, 1)\r\n\tsignal.Notify(notifier, syscall.SIGINT, syscall.SIGTERM)\r\n\tgo func() {\r\n\t\tsig := <-notifier\r\n\t\tinterruptRegisterMu.Lock()\r\n\t\tihs := make([]InterruptHandler, len(interruptHandlers))\r\n\t\tcopy(ihs, interruptHandlers)\r\n\t\tinterruptRegisterMu.Unlock()\r\n\t\tinterruptExitMu.Lock()\r\n\t\tif lg != nil {\r\n\t\t\tlg.Info(\"received signal; shutting down\", zap.String(\"signal\", sig.String()))\r\n\t\t} else {\r\n\t\t\tplog.Noticef(\"received %v signal, shutting down...\", sig)\r\n\t\t}\r\n\t\tfor _, h := range ihs {\r\n\t\t\th()\r\n\t\t}\r\n\t\tsignal.Stop(notifier)\r\n\t\tpid := syscall.Getpid()\r\n\t\t\r\n\t\tif pid == 1 {\r\n\t\t\tos.Exit(0)\r\n\t\t}\r\n\t\tsetDflSignal(sig.(syscall.Signal))\r\n\t\tsyscall.Kill(pid, sig.(syscall.Signal))\r\n\t}()\r\n}","code-length":318,"reference":"\/\/ HandleInterrupts calls the handler functions on receiving a SIGINT or SIGTERM.","result":"Handle interrupts.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OpGet(key string, opts ...OpOption) Op {\r\n\t\r\n\tif isWithPrefix(opts) && isWithFromKey(opts) {\r\n\t\tpanic(\"`WithPrefix` and `WithFromKey` cannot be set at the same time, choose one\")\r\n\t}\r\n\tret := Op{t: tRange, key: []byte(key)}\r\n\tret.applyOpts(opts)\r\n\treturn ret\r\n}","code-length":114,"reference":"\/\/ OpGet returns \"get\" operation based on given key and operation options.","result":"Get a range.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OpDelete(key string, opts ...OpOption) Op {\r\n\t\r\n\tif isWithPrefix(opts) && isWithFromKey(opts) {\r\n\t\tpanic(\"`WithPrefix` and `WithFromKey` cannot be set at the same time, choose one\")\r\n\t}\r\n\tret := Op{t: tDeleteRange, key: []byte(key)}\r\n\tret.applyOpts(opts)\r\n\tswitch {\r\n\tcase ret.leaseID != 0:\r\n\t\tpanic(\"unexpected lease in delete\")\r\n\tcase ret.limit != 0:\r\n\t\tpanic(\"unexpected limit in delete\")\r\n\tcase ret.rev != 0:\r\n\t\tpanic(\"unexpected revision in delete\")\r\n\tcase ret.sort != nil:\r\n\t\tpanic(\"unexpected sort in delete\")\r\n\tcase ret.serializable:\r\n\t\tpanic(\"unexpected serializable in delete\")\r\n\tcase ret.countOnly:\r\n\t\tpanic(\"unexpected countOnly in delete\")\r\n\tcase ret.minModRev != 0, ret.maxModRev != 0:\r\n\t\tpanic(\"unexpected mod revision filter in delete\")\r\n\tcase ret.minCreateRev != 0, ret.maxCreateRev != 0:\r\n\t\tpanic(\"unexpected create revision filter in delete\")\r\n\tcase ret.filterDelete, ret.filterPut:\r\n\t\tpanic(\"unexpected filter in delete\")\r\n\tcase ret.createdNotify:\r\n\t\tpanic(\"unexpected createdNotify in delete\")\r\n\t}\r\n\treturn ret\r\n}","code-length":372,"reference":"\/\/ OpDelete returns \"delete\" operation based on given key and operation options.","result":"Delete a range.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OpPut(key, val string, opts ...OpOption) Op {\r\n\tret := Op{t: tPut, key: []byte(key), val: []byte(val)}\r\n\tret.applyOpts(opts)\r\n\tswitch {\r\n\tcase ret.end != nil:\r\n\t\tpanic(\"unexpected range in put\")\r\n\tcase ret.limit != 0:\r\n\t\tpanic(\"unexpected limit in put\")\r\n\tcase ret.rev != 0:\r\n\t\tpanic(\"unexpected revision in put\")\r\n\tcase ret.sort != nil:\r\n\t\tpanic(\"unexpected sort in put\")\r\n\tcase ret.serializable:\r\n\t\tpanic(\"unexpected serializable in put\")\r\n\tcase ret.countOnly:\r\n\t\tpanic(\"unexpected countOnly in put\")\r\n\tcase ret.minModRev != 0, ret.maxModRev != 0:\r\n\t\tpanic(\"unexpected mod revision filter in put\")\r\n\tcase ret.minCreateRev != 0, ret.maxCreateRev != 0:\r\n\t\tpanic(\"unexpected create revision filter in put\")\r\n\tcase ret.filterDelete, ret.filterPut:\r\n\t\tpanic(\"unexpected filter in put\")\r\n\tcase ret.createdNotify:\r\n\t\tpanic(\"unexpected createdNotify in put\")\r\n\t}\r\n\treturn ret\r\n}","code-length":325,"reference":"\/\/ OpPut returns \"put\" operation based on given key-value and operation options.","result":"Create a new Op object.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OpTxn(cmps []Cmp, thenOps []Op, elseOps []Op) Op {\r\n\treturn Op{t: tTxn, cmps: cmps, thenOps: thenOps, elseOps: elseOps}\r\n}","code-length":62,"reference":"\/\/ OpTxn returns \"txn\" operation based on given transaction conditions.","result":"Create a transaction.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WithFromKey() OpOption {\r\n\treturn func(op *Op) {\r\n\t\tif len(op.key) == 0 {\r\n\t\t\top.key = []byte{0}\r\n\t\t}\r\n\t\top.end = []byte(\"\\x00\")\r\n\t}\r\n}","code-length":81,"reference":"\/\/ WithFromKey specifies the range of 'Get', 'Delete', 'Watch' requests\n\/\/ to be equal or greater than the key in the argument.","result":"Create a new op.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc withTop(target SortTarget, order SortOrder) []OpOption {\r\n\treturn []OpOption{WithPrefix(), WithSort(target, order), WithLimit(1)}\r\n}","code-length":51,"reference":"\/\/ withTop gets the first key over the get's prefix given a sort order","result":"Create a new function.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Exist(dir string) bool {\r\n\tnames, err := fileutil.ReadDir(dir, fileutil.WithExt(\".wal\"))\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\treturn len(names) != 0\r\n}","code-length":74,"reference":"\/\/ Exist returns true if there are any files in a given directory.","result":"Check if the directory exists.","score":[0.0485,0.041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc searchIndex(lg *zap.Logger, names []string, index uint64) (int, bool) {\r\n\tfor i := len(names) - 1; i >= 0; i-- {\r\n\t\tname := names[i]\r\n\t\t_, curIndex, err := parseWALName(name)\r\n\t\tif err != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Panic(\"failed to parse WAL file name\", zap.String(\"path\", name), zap.Error(err))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"parse correct name should never fail: %v\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t\tif index >= curIndex {\r\n\t\t\treturn i, true\r\n\t\t}\r\n\t}\r\n\treturn -1, false\r\n}","code-length":206,"reference":"\/\/ searchIndex returns the last array index of names whose raft index section is\n\/\/ equal to or smaller than the given index.\n\/\/ The given names MUST be sorted.","result":"Search the index of the WAL file .","score":[0.0149,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isValidSeq(lg *zap.Logger, names []string) bool {\r\n\tvar lastSeq uint64\r\n\tfor _, name := range names {\r\n\t\tcurSeq, _, err := parseWALName(name)\r\n\t\tif err != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Panic(\"failed to parse WAL file name\", zap.String(\"path\", name), zap.Error(err))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"parse correct name should never fail: %v\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t\tif lastSeq != 0 && lastSeq != curSeq-1 {\r\n\t\t\treturn false\r\n\t\t}\r\n\t\tlastSeq = curSeq\r\n\t}\r\n\treturn true\r\n}","code-length":199,"reference":"\/\/ names should have been sorted based on sequence number.\n\/\/ isValidSeq checks whether seq increases continuously.","result":"Check if the sequence number is valid.","score":[0.0387,0.0625]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewListener(addr, scheme string, tlsinfo *TLSInfo) (l net.Listener, err error) {\r\n\tif l, err = newListener(addr, scheme); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn wrapTLS(scheme, tlsinfo, l)\r\n}","code-length":82,"reference":"\/\/ NewListener creates a new listner.","result":"Create a new listener.","score":[0.274,0.5077]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (info TLSInfo) cafiles() []string {\r\n\tcs := make([]string, 0)\r\n\tif info.TrustedCAFile != \"\" {\r\n\t\tcs = append(cs, info.TrustedCAFile)\r\n\t}\r\n\treturn cs\r\n}","code-length":74,"reference":"\/\/ cafiles returns a list of CA file paths.","result":"Generate the cafiles.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (info TLSInfo) ServerConfig() (*tls.Config, error) {\r\n\tcfg, err := info.baseConfig()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tcfg.ClientAuth = tls.NoClientCert\r\n\tif info.TrustedCAFile != \"\" || info.ClientCertAuth {\r\n\t\tcfg.ClientAuth = tls.RequireAndVerifyClientCert\r\n\t}\r\n\tcs := info.cafiles()\r\n\tif len(cs) > 0 {\r\n\t\tcp, err := tlsutil.NewCertPool(cs)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tcfg.ClientCAs = cp\r\n\t}\r\n\t\r\n\tcfg.NextProtos = []string{\"h2\"}\r\n\treturn cfg, nil\r\n}","code-length":214,"reference":"\/\/ ServerConfig generates a tls.Config object for use by an HTTP server.","result":"Generate the server config.","score":[0,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (info TLSInfo) ClientConfig() (*tls.Config, error) {\r\n\tvar cfg *tls.Config\r\n\tvar err error\r\n\tif !info.Empty() {\r\n\t\tcfg, err = info.baseConfig()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t} else {\r\n\t\tcfg = &tls.Config{ServerName: info.ServerName}\r\n\t}\r\n\tcfg.InsecureSkipVerify = info.InsecureSkipVerify\r\n\tcs := info.cafiles()\r\n\tif len(cs) > 0 {\r\n\t\tcfg.RootCAs, err = tlsutil.NewCertPool(cs)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\tif info.selfCert {\r\n\t\tcfg.InsecureSkipVerify = true\r\n\t}\r\n\tif info.EmptyCN {\r\n\t\thasNonEmptyCN := false\r\n\t\tcn := \"\"\r\n\t\ttlsutil.NewCert(info.CertFile, info.KeyFile, func(certPEMBlock []byte, keyPEMBlock []byte) (tls.Certificate, error) {\r\n\t\t\tvar block *pem.Block\r\n\t\t\tblock, _ = pem.Decode(certPEMBlock)\r\n\t\t\tcert, err := x509.ParseCertificate(block.Bytes)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn tls.Certificate{}, err\r\n\t\t\t}\r\n\t\t\tif len(cert.Subject.CommonName) != 0 {\r\n\t\t\t\thasNonEmptyCN = true\r\n\t\t\t\tcn = cert.Subject.CommonName\r\n\t\t\t}\r\n\t\t\treturn tls.X509KeyPair(certPEMBlock, keyPEMBlock)\r\n\t\t})\r\n\t\tif hasNonEmptyCN {\r\n\t\t\treturn nil, fmt.Errorf(\"cert has non empty Common Name (%s)\", cn)\r\n\t\t}\r\n\t}\r\n\treturn cfg, nil\r\n}","code-length":472,"reference":"\/\/ ClientConfig generates a tls.Config object for use by an HTTP client.","result":"Create a client config.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newTLSKeepaliveListener(inner net.Listener, config *tls.Config) net.Listener {\r\n\tl := &tlsKeepaliveListener{}\r\n\tl.Listener = inner\r\n\tl.config = config\r\n\treturn l\r\n}","code-length":66,"reference":"\/\/ NewListener creates a Listener which accepts connections from an inner\n\/\/ Listener and wraps each connection with Server.\n\/\/ The configuration config must be non-nil and must have\n\/\/ at least one certificate.","result":"Keep the keepalive listener alive.","score":[0,0.0322]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) applyV2Request(r *RequestV2) Response {\r\n\tdefer warnOfExpensiveRequest(s.getLogger(), time.Now(), r, nil, nil)\r\n\tswitch r.Method {\r\n\tcase \"POST\":\r\n\t\treturn s.applyV2.Post(r)\r\n\tcase \"PUT\":\r\n\t\treturn s.applyV2.Put(r)\r\n\tcase \"DELETE\":\r\n\t\treturn s.applyV2.Delete(r)\r\n\tcase \"QGET\":\r\n\t\treturn s.applyV2.QGet(r)\r\n\tcase \"SYNC\":\r\n\t\treturn s.applyV2.Sync(r)\r\n\tdefault:\r\n\t\t\r\n\t\treturn Response{Err: ErrUnknownMethod}\r\n\t}\r\n}","code-length":202,"reference":"\/\/ applyV2Request interprets r as a call to v2store.X\n\/\/ and returns a Response interpreted from v2store.Event","result":"Apply a request to a cluster.","score":[0.0406,0.0943]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRoleCommand() *cobra.Command {\r\n\tac := &cobra.Command{\r\n\t\tUse:   \"role <subcommand>\",\r\n\t\tShort: \"Role related commands\",\r\n\t}\r\n\tac.AddCommand(newRoleAddCommand())\r\n\tac.AddCommand(newRoleDeleteCommand())\r\n\tac.AddCommand(newRoleGetCommand())\r\n\tac.AddCommand(newRoleListCommand())\r\n\tac.AddCommand(newRoleGrantPermissionCommand())\r\n\tac.AddCommand(newRoleRevokePermissionCommand())\r\n\treturn ac\r\n}","code-length":150,"reference":"\/\/ NewRoleCommand returns the cobra command for \"role\".","result":"Generate the role command.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc roleAddCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"role add command requires role name as its argument\"))\r\n\t}\r\n\tresp, err := mustClientFromCmd(cmd).Auth.RoleAdd(context.TODO(), args[0])\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.RoleAdd(args[0], *resp)\r\n}","code-length":138,"reference":"\/\/ roleAddCommandFunc executes the \"role add\" command.","result":"Generate the code.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc roleGetCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"role get command requires role name as its argument\"))\r\n\t}\r\n\tname := args[0]\r\n\tresp, err := mustClientFromCmd(cmd).Auth.RoleGet(context.TODO(), name)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.RoleGet(name, *resp)\r\n}","code-length":143,"reference":"\/\/ roleGetCommandFunc executes the \"role get\" command.","result":"Generate the role get command .","score":[0.1634,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc roleGrantPermissionCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) < 3 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"role grant command requires role name, permission type, and key [endkey] as its argument\"))\r\n\t}\r\n\tperm, err := clientv3.StrToPermissionType(args[1])\r\n\tif err != nil {\r\n\t\tExitWithError(ExitBadArgs, err)\r\n\t}\r\n\tkey, rangeEnd := permRange(args[2:])\r\n\tresp, err := mustClientFromCmd(cmd).Auth.RoleGrantPermission(context.TODO(), args[0], key, rangeEnd, perm)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.RoleGrantPermission(args[0], *resp)\r\n}","code-length":217,"reference":"\/\/ roleGrantPermissionCommandFunc executes the \"role grant-permission\" command.","result":"Generate the code.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc roleRevokePermissionCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) < 2 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"role revoke-permission command requires role name and key [endkey] as its argument\"))\r\n\t}\r\n\tkey, rangeEnd := permRange(args[1:])\r\n\tresp, err := mustClientFromCmd(cmd).Auth.RoleRevokePermission(context.TODO(), args[0], key, rangeEnd)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.RoleRevokePermission(args[0], args[1], rangeEnd, *resp)\r\n}","code-length":174,"reference":"\/\/ roleRevokePermissionCommandFunc executes the \"role revoke-permission\" command.","result":"Generate the code.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCluster(t testing.TB, size int) *cluster {\r\n\treturn newCluster(t, &ClusterConfig{Size: size})\r\n}","code-length":44,"reference":"\/\/ NewCluster returns an unlaunched cluster of the given size which has been\n\/\/ set to use static bootstrap.","result":"Create a new cluster.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClusterByConfig(t testing.TB, cfg *ClusterConfig) *cluster {\r\n\treturn newCluster(t, cfg)\r\n}","code-length":42,"reference":"\/\/ NewClusterByConfig returns an unlaunched cluster defined by a cluster configuration","result":"Generate the file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *cluster) HTTPMembers() []client.Member {\r\n\tms := []client.Member{}\r\n\tfor _, m := range c.Members {\r\n\t\tpScheme := schemeFromTLSInfo(m.PeerTLSInfo)\r\n\t\tcScheme := schemeFromTLSInfo(m.ClientTLSInfo)\r\n\t\tcm := client.Member{Name: m.Name}\r\n\t\tfor _, ln := range m.PeerListeners {\r\n\t\t\tcm.PeerURLs = append(cm.PeerURLs, pScheme+\":\r\n\t\t}\r\n\t\tfor _, ln := range m.ClientListeners {\r\n\t\t\tcm.ClientURLs = append(cm.ClientURLs, cScheme+\":\r\n\t\t}\r\n\t\tms = append(ms, cm)\r\n\t}\r\n\treturn ms\r\n}","code-length":202,"reference":"\/\/ HTTPMembers returns a list of all active members as client.Members","result":"Generate the cluster members .","score":[0.0724,0.0481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *cluster) waitLeader(t testing.TB, membs []*member) int {\r\n\tpossibleLead := make(map[uint64]bool)\r\n\tvar lead uint64\r\n\tfor _, m := range membs {\r\n\t\tpossibleLead[uint64(m.s.ID())] = true\r\n\t}\r\n\tcc := MustNewHTTPClient(t, getMembersURLs(membs), nil)\r\n\tkapi := client.NewKeysAPI(cc)\r\n\t\r\n\tfor {\r\n\t\tctx, cancel := context.WithTimeout(context.Background(), 10*tickDuration+time.Second)\r\n\t\t_, err := kapi.Get(ctx, \"0\", &client.GetOptions{Quorum: true})\r\n\t\tcancel()\r\n\t\tif err == nil || strings.Contains(err.Error(), \"Key not found\") {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tfor lead == 0 || !possibleLead[lead] {\r\n\t\tlead = 0\r\n\t\tfor _, m := range membs {\r\n\t\t\tselect {\r\n\t\t\tcase <-m.s.StopNotify():\r\n\t\t\t\tcontinue\r\n\t\t\tdefault:\r\n\t\t\t}\r\n\t\t\tif lead != 0 && lead != m.s.Lead() {\r\n\t\t\t\tlead = 0\r\n\t\t\t\ttime.Sleep(10 * tickDuration)\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\tlead = m.s.Lead()\r\n\t\t}\r\n\t}\r\n\tfor i, m := range membs {\r\n\t\tif uint64(m.s.ID()) == lead {\r\n\t\t\treturn i\r\n\t\t}\r\n\t}\r\n\treturn -1\r\n}","code-length":418,"reference":"\/\/ waitLeader waits until given members agree on the same leader.","result":"Test the waitLeader function.","score":[0.066,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *cluster) waitNoLeader(membs []*member) {\r\n\tnoLeader := false\r\n\tfor !noLeader {\r\n\t\tnoLeader = true\r\n\t\tfor _, m := range membs {\r\n\t\t\tselect {\r\n\t\t\tcase <-m.s.StopNotify():\r\n\t\t\t\tcontinue\r\n\t\t\tdefault:\r\n\t\t\t}\r\n\t\t\tif m.s.Lead() != 0 {\r\n\t\t\t\tnoLeader = false\r\n\t\t\t\ttime.Sleep(10 * tickDuration)\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":154,"reference":"\/\/ waitNoLeader waits until given members lose leader.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isMembersEqual(membs []client.Member, wmembs []client.Member) bool {\r\n\tsort.Sort(SortableMemberSliceByPeerURLs(membs))\r\n\tsort.Sort(SortableMemberSliceByPeerURLs(wmembs))\r\n\tfor i := range membs {\r\n\t\tmembs[i].ID = \"\"\r\n\t}\r\n\treturn reflect.DeepEqual(membs, wmembs)\r\n}","code-length":111,"reference":"\/\/ isMembersEqual checks whether two members equal except ID field.\n\/\/ The given wmembs should always set ID field to empty string.","result":"Compare members.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *member) listenGRPC() error {\r\n\t\r\n\tm.grpcAddr = \"localhost:\" + m.Name\r\n\tif m.useIP {\r\n\t\tm.grpcAddr = \"127.0.0.1:\" + m.Name\r\n\t}\r\n\tl, err := transport.NewUnixListener(m.grpcAddr)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"listen failed on grpc socket %s (%v)\", m.grpcAddr, err)\r\n\t}\r\n\tm.grpcBridge, err = newBridge(m.grpcAddr)\r\n\tif err != nil {\r\n\t\tl.Close()\r\n\t\treturn err\r\n\t}\r\n\tm.grpcAddr = schemeFromTLSInfo(m.ClientTLSInfo) + \":\r\n\tm.grpcListener = l\r\n\treturn nil\r\n}","code-length":212,"reference":"\/\/ listenGRPC starts a grpc server over a unix domain socket on the member","result":"Listen on the grpc socket.","score":[0.0622,0.1951]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClientV3(m *member) (*clientv3.Client, error) {\r\n\tif m.grpcAddr == \"\" {\r\n\t\treturn nil, fmt.Errorf(\"member not configured for grpc\")\r\n\t}\r\n\tcfg := clientv3.Config{\r\n\t\tEndpoints:          []string{m.grpcAddr},\r\n\t\tDialTimeout:        5 * time.Second,\r\n\t\tDialOptions:        []grpc.DialOption{grpc.WithBlock()},\r\n\t\tMaxCallSendMsgSize: m.clientMaxCallSendMsgSize,\r\n\t\tMaxCallRecvMsgSize: m.clientMaxCallRecvMsgSize,\r\n\t}\r\n\tif m.ClientTLSInfo != nil {\r\n\t\ttls, err := m.ClientTLSInfo.ClientConfig()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tcfg.TLS = tls\r\n\t}\r\n\tif m.DialOptions != nil {\r\n\t\tcfg.DialOptions = append(cfg.DialOptions, m.DialOptions...)\r\n\t}\r\n\treturn newClientV3(cfg)\r\n}","code-length":275,"reference":"\/\/ NewClientV3 creates a new grpc client connection to the member","result":"Create a new client v.","score":[0.1133,0.3606]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *member) Clone(t testing.TB) *member {\r\n\tmm := &member{}\r\n\tmm.ServerConfig = m.ServerConfig\r\n\tvar err error\r\n\tclientURLStrs := m.ClientURLs.StringSlice()\r\n\tmm.ClientURLs, err = types.NewURLs(clientURLStrs)\r\n\tif err != nil {\r\n\t\t\r\n\t\tpanic(err)\r\n\t}\r\n\tpeerURLStrs := m.PeerURLs.StringSlice()\r\n\tmm.PeerURLs, err = types.NewURLs(peerURLStrs)\r\n\tif err != nil {\r\n\t\t\r\n\t\tpanic(err)\r\n\t}\r\n\tclusterStr := m.InitialPeerURLsMap.String()\r\n\tmm.InitialPeerURLsMap, err = types.NewURLsMap(clusterStr)\r\n\tif err != nil {\r\n\t\t\r\n\t\tpanic(err)\r\n\t}\r\n\tmm.InitialClusterToken = m.InitialClusterToken\r\n\tmm.ElectionTicks = m.ElectionTicks\r\n\tmm.PeerTLSInfo = m.PeerTLSInfo\r\n\tmm.ClientTLSInfo = m.ClientTLSInfo\r\n\treturn mm\r\n}","code-length":289,"reference":"\/\/ Clone returns a member with the same server configuration. The returned\n\/\/ member will not set PeerListeners and ClientListeners.","result":"Clone the member.","score":[0.0017,0.0546]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *member) Close() {\r\n\tif m.grpcBridge != nil {\r\n\t\tm.grpcBridge.Close()\r\n\t\tm.grpcBridge = nil\r\n\t}\r\n\tif m.serverClient != nil {\r\n\t\tm.serverClient.Close()\r\n\t\tm.serverClient = nil\r\n\t}\r\n\tif m.grpcServer != nil {\r\n\t\tm.grpcServer.Stop()\r\n\t\tm.grpcServer.GracefulStop()\r\n\t\tm.grpcServer = nil\r\n\t\tm.grpcServerPeer.Stop()\r\n\t\tm.grpcServerPeer.GracefulStop()\r\n\t\tm.grpcServerPeer = nil\r\n\t}\r\n\tm.s.HardStop()\r\n\tfor _, f := range m.serverClosers {\r\n\t\tf()\r\n\t}\r\n}","code-length":214,"reference":"\/\/ Close stops the member's etcdserver and closes its connections","result":"Close the member.","score":[0.0471,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *member) Stop(t testing.TB) {\r\n\tlg.Info(\r\n\t\t\"stopping a member\",\r\n\t\tzap.String(\"name\", m.Name),\r\n\t\tzap.Strings(\"advertise-peer-urls\", m.PeerURLs.StringSlice()),\r\n\t\tzap.Strings(\"listen-client-urls\", m.ClientURLs.StringSlice()),\r\n\t\tzap.String(\"grpc-address\", m.grpcAddr),\r\n\t)\r\n\tm.Close()\r\n\tm.serverClosers = nil\r\n\tlg.Info(\r\n\t\t\"stopped a member\",\r\n\t\tzap.String(\"name\", m.Name),\r\n\t\tzap.Strings(\"advertise-peer-urls\", m.PeerURLs.StringSlice()),\r\n\t\tzap.Strings(\"listen-client-urls\", m.ClientURLs.StringSlice()),\r\n\t\tzap.String(\"grpc-address\", m.grpcAddr),\r\n\t)\r\n}","code-length":248,"reference":"\/\/ Stop stops the member, but the data dir of the member is preserved.","result":"Test the member stop .","score":[0.0562,0.1951]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkLeaderTransition(m *member, oldLead uint64) uint64 {\r\n\tinterval := time.Duration(m.s.Cfg.TickMs) * time.Millisecond\r\n\tfor m.s.Lead() == 0 || (m.s.Lead() == oldLead) {\r\n\t\ttime.Sleep(interval)\r\n\t}\r\n\treturn m.s.Lead()\r\n}","code-length":102,"reference":"\/\/ checkLeaderTransition waits for leader transition, returning the new leader ID.","result":"Check leader transition.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *member) Restart(t testing.TB) error {\r\n\tlg.Info(\r\n\t\t\"restarting a member\",\r\n\t\tzap.String(\"name\", m.Name),\r\n\t\tzap.Strings(\"advertise-peer-urls\", m.PeerURLs.StringSlice()),\r\n\t\tzap.Strings(\"listen-client-urls\", m.ClientURLs.StringSlice()),\r\n\t\tzap.String(\"grpc-address\", m.grpcAddr),\r\n\t)\r\n\tnewPeerListeners := make([]net.Listener, 0)\r\n\tfor _, ln := range m.PeerListeners {\r\n\t\tnewPeerListeners = append(newPeerListeners, NewListenerWithAddr(t, ln.Addr().String()))\r\n\t}\r\n\tm.PeerListeners = newPeerListeners\r\n\tnewClientListeners := make([]net.Listener, 0)\r\n\tfor _, ln := range m.ClientListeners {\r\n\t\tnewClientListeners = append(newClientListeners, NewListenerWithAddr(t, ln.Addr().String()))\r\n\t}\r\n\tm.ClientListeners = newClientListeners\r\n\tif m.grpcListener != nil {\r\n\t\tif err := m.listenGRPC(); err != nil {\r\n\t\t\tt.Fatal(err)\r\n\t\t}\r\n\t}\r\n\terr := m.Launch()\r\n\tlg.Info(\r\n\t\t\"restarted a member\",\r\n\t\tzap.String(\"name\", m.Name),\r\n\t\tzap.Strings(\"advertise-peer-urls\", m.PeerURLs.StringSlice()),\r\n\t\tzap.Strings(\"listen-client-urls\", m.ClientURLs.StringSlice()),\r\n\t\tzap.String(\"grpc-address\", m.grpcAddr),\r\n\t\tzap.Error(err),\r\n\t)\r\n\treturn err\r\n}","code-length":449,"reference":"\/\/ Restart starts the member using the preserved data dir.","result":"Restart a member.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *member) Terminate(t testing.TB) {\r\n\tlg.Info(\r\n\t\t\"terminating a member\",\r\n\t\tzap.String(\"name\", m.Name),\r\n\t\tzap.Strings(\"advertise-peer-urls\", m.PeerURLs.StringSlice()),\r\n\t\tzap.Strings(\"listen-client-urls\", m.ClientURLs.StringSlice()),\r\n\t\tzap.String(\"grpc-address\", m.grpcAddr),\r\n\t)\r\n\tm.Close()\r\n\tif !m.keepDataDirTerminate {\r\n\t\tif err := os.RemoveAll(m.ServerConfig.DataDir); err != nil {\r\n\t\t\tt.Fatal(err)\r\n\t\t}\r\n\t}\r\n\tlg.Info(\r\n\t\t\"terminated a member\",\r\n\t\tzap.String(\"name\", m.Name),\r\n\t\tzap.Strings(\"advertise-peer-urls\", m.PeerURLs.StringSlice()),\r\n\t\tzap.Strings(\"listen-client-urls\", m.ClientURLs.StringSlice()),\r\n\t\tzap.String(\"grpc-address\", m.grpcAddr),\r\n\t)\r\n}","code-length":293,"reference":"\/\/ Terminate stops the member and removes the data dir.","result":"Terminate a member.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *member) Metric(metricName string) (string, error) {\r\n\tcfgtls := transport.TLSInfo{}\r\n\ttr, err := transport.NewTimeoutTransport(cfgtls, time.Second, time.Second, time.Second)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tcli := &http.Client{Transport: tr}\r\n\tresp, err := cli.Get(m.ClientURLs[0].String() + \"\/metrics\")\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\tb, rerr := ioutil.ReadAll(resp.Body)\r\n\tif rerr != nil {\r\n\t\treturn \"\", rerr\r\n\t}\r\n\tlines := strings.Split(string(b), \"\\n\")\r\n\tfor _, l := range lines {\r\n\t\tif strings.HasPrefix(l, metricName) {\r\n\t\t\treturn strings.Split(l, \" \")[1], nil\r\n\t\t}\r\n\t}\r\n\treturn \"\", nil\r\n}","code-length":267,"reference":"\/\/ Metric gets the metric value for a member","result":"Get the value of a metric.","score":[0.1541,0.3628]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *member) InjectPartition(t testing.TB, others ...*member) {\r\n\tfor _, other := range others {\r\n\t\tm.s.CutPeer(other.s.ID())\r\n\t\tother.s.CutPeer(m.s.ID())\r\n\t}\r\n}","code-length":81,"reference":"\/\/ InjectPartition drops connections from m to others, vice versa.","result":"Inject partition.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *member) RecoverPartition(t testing.TB, others ...*member) {\r\n\tfor _, other := range others {\r\n\t\tm.s.MendPeer(other.s.ID())\r\n\t\tother.s.MendPeer(m.s.ID())\r\n\t}\r\n}","code-length":84,"reference":"\/\/ RecoverPartition recovers connections from m to others, vice versa.","result":"Test the partition recovery.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClusterV3(t testing.TB, cfg *ClusterConfig) *ClusterV3 {\r\n\tcfg.UseGRPC = true\r\n\tif os.Getenv(\"CLIENT_DEBUG\") != \"\" {\r\n\t\tclientv3.SetLogger(grpclog.NewLoggerV2WithVerbosity(os.Stderr, os.Stderr, os.Stderr, 4))\r\n\t}\r\n\tclus := &ClusterV3{\r\n\t\tcluster: NewClusterByConfig(t, cfg),\r\n\t}\r\n\tclus.Launch(t)\r\n\tif !cfg.SkipCreatingClient {\r\n\t\tfor _, m := range clus.Members {\r\n\t\t\tclient, err := NewClientV3(m)\r\n\t\t\tif err != nil {\r\n\t\t\t\tt.Fatalf(\"cannot create client: %v\", err)\r\n\t\t\t}\r\n\t\t\tclus.clients = append(clus.clients, client)\r\n\t\t}\r\n\t}\r\n\treturn clus\r\n}","code-length":242,"reference":"\/\/ NewClusterV3 returns a launched cluster with a grpc client connection\n\/\/ for each cluster member.","result":"Create a new cluster by config.","score":[0.0434,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (opts *jwtOptions) ParseWithDefaults(optMap map[string]string) error {\r\n\tif opts.TTL == 0 && optMap[optTTL] == \"\" {\r\n\t\topts.TTL = DefaultTTL\r\n\t}\r\n\treturn opts.Parse(optMap)\r\n}","code-length":77,"reference":"\/\/ ParseWithDefaults will load options from the specified map or set defaults where appropriate","result":"Parse JWT.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (opts *jwtOptions) Parse(optMap map[string]string) error {\r\n\tvar err error\r\n\tif ttl := optMap[optTTL]; ttl != \"\" {\r\n\t\topts.TTL, err = time.ParseDuration(ttl)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tif file := optMap[optPublicKey]; file != \"\" {\r\n\t\topts.PublicKey, err = ioutil.ReadFile(file)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tif file := optMap[optPrivateKey]; file != \"\" {\r\n\t\topts.PrivateKey, err = ioutil.ReadFile(file)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\t\r\n\tmethod := optMap[optSignMethod]\r\n\topts.SignMethod = jwt.GetSigningMethod(method)\r\n\tif opts.SignMethod == nil {\r\n\t\treturn ErrInvalidAuthMethod\r\n\t}\r\n\treturn nil\r\n}","code-length":267,"reference":"\/\/ Parse will load options from the specified map","result":"Parse the options.","score":[0.0657,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (opts *jwtOptions) Key() (interface{}, error) {\r\n\tswitch opts.SignMethod.(type) {\r\n\tcase *jwt.SigningMethodRSA, *jwt.SigningMethodRSAPSS:\r\n\t\treturn opts.rsaKey()\r\n\tcase *jwt.SigningMethodECDSA:\r\n\t\treturn opts.ecKey()\r\n\tcase *jwt.SigningMethodHMAC:\r\n\t\treturn opts.hmacKey()\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"unsupported signing method: %T\", opts.SignMethod)\r\n\t}\r\n}","code-length":146,"reference":"\/\/ Key will parse and return the appropriately typed key for the selected signature method","result":"Generate the key.","score":[0.0075,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *header) fill(rh *pb.ResponseHeader) {\r\n\tif rh == nil {\r\n\t\tplog.Panic(\"unexpected nil resp.Header\")\r\n\t}\r\n\trh.ClusterId = uint64(h.clusterID)\r\n\trh.MemberId = uint64(h.memberID)\r\n\trh.RaftTerm = h.sg.Term()\r\n\tif rh.Revision == 0 {\r\n\t\trh.Revision = h.rev()\r\n\t}\r\n}","code-length":128,"reference":"\/\/ fill populates pb.ResponseHeader using etcdserver information","result":"Fill the header.","score":[0,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wb *watchBroadcast) add(w *watcher) bool {\r\n\twb.mu.Lock()\r\n\tdefer wb.mu.Unlock()\r\n\tif wb.nextrev > w.nextrev || (wb.nextrev == 0 && w.nextrev != 0) {\r\n\t\t\r\n\t\t\r\n\t\treturn false\r\n\t}\r\n\tif wb.responses == 0 {\r\n\t\t\r\n\t\twb.receivers[w] = struct{}{}\r\n\t\treturn true\r\n\t}\r\n\t\r\n\tok := w.post(&pb.WatchResponse{\r\n\t\tHeader: &pb.ResponseHeader{\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tRevision: w.nextrev,\r\n\t\t\t\r\n\t\t},\r\n\t\tWatchId: w.id,\r\n\t\tCreated: true,\r\n\t})\r\n\tif !ok {\r\n\t\treturn false\r\n\t}\r\n\twb.receivers[w] = struct{}{}\r\n\twatchersCoalescing.Inc()\r\n\treturn true\r\n}","code-length":256,"reference":"\/\/ add puts a watcher into receiving a broadcast if its revision at least\n\/\/ meets the broadcast revision. Returns true if added.","result":"Broadcast watchers.","score":[0,0.0239]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ws *watchStream) Watch(id WatchID, key, end []byte, startRev int64, fcs ...FilterFunc) (WatchID, error) {\r\n\t\r\n\t\r\n\tif len(end) != 0 && bytes.Compare(key, end) != -1 {\r\n\t\treturn -1, ErrEmptyWatcherRange\r\n\t}\r\n\tws.mu.Lock()\r\n\tdefer ws.mu.Unlock()\r\n\tif ws.closed {\r\n\t\treturn -1, ErrEmptyWatcherRange\r\n\t}\r\n\tif id == AutoWatchID {\r\n\t\tfor ws.watchers[ws.nextID] != nil {\r\n\t\t\tws.nextID++\r\n\t\t}\r\n\t\tid = ws.nextID\r\n\t\tws.nextID++\r\n\t} else if _, ok := ws.watchers[id]; ok {\r\n\t\treturn -1, ErrWatcherDuplicateID\r\n\t}\r\n\tw, c := ws.watchable.watch(key, end, startRev, id, ws.ch, fcs...)\r\n\tws.cancels[id] = c\r\n\tws.watchers[id] = w\r\n\treturn id, nil\r\n}","code-length":294,"reference":"\/\/ Watch creates a new watcher in the stream and returns its WatchID.","result":"Watch a range of keys.","score":[0.0577,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newFileEncoder(f *os.File, prevCrc uint32) (*encoder, error) {\r\n\toffset, err := f.Seek(0, io.SeekCurrent)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn newEncoder(f, prevCrc, int(offset)), nil\r\n}","code-length":92,"reference":"\/\/ newFileEncoder creates a new encoder with current file offset for the page writer.","result":"Create a new file encoder.","score":[0.0622,0.2863]}
{"code":"\/*is used to<extra_id_0>\r\nfunc purgeFile(lg *zap.Logger, dirname string, suffix string, max uint, interval time.Duration, stop <-chan struct{}, purgec chan<- string) <-chan error {\r\n\terrC := make(chan error, 1)\r\n\tgo func() {\r\n\t\tfor {\r\n\t\t\tfnames, err := ReadDir(dirname)\r\n\t\t\tif err != nil {\r\n\t\t\t\terrC <- err\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tnewfnames := make([]string, 0)\r\n\t\t\tfor _, fname := range fnames {\r\n\t\t\t\tif strings.HasSuffix(fname, suffix) {\r\n\t\t\t\t\tnewfnames = append(newfnames, fname)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tsort.Strings(newfnames)\r\n\t\t\tfnames = newfnames\r\n\t\t\tfor len(newfnames) > int(max) {\r\n\t\t\t\tf := filepath.Join(dirname, newfnames[0])\r\n\t\t\t\tl, err := TryLockFile(f, os.O_WRONLY, PrivateFileMode)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t\tif err = os.Remove(f); err != nil {\r\n\t\t\t\t\terrC <- err\r\n\t\t\t\t\treturn\r\n\t\t\t\t}\r\n\t\t\t\tif err = l.Close(); err != nil {\r\n\t\t\t\t\tif lg != nil {\r\n\t\t\t\t\t\tlg.Warn(\"failed to unlock\/close\", zap.String(\"path\", l.Name()), zap.Error(err))\r\n\t\t\t\t\t} else {\r\n\t\t\t\t\t\tplog.Errorf(\"error unlocking %s when purging file (%v)\", l.Name(), err)\r\n\t\t\t\t\t}\r\n\t\t\t\t\terrC <- err\r\n\t\t\t\t\treturn\r\n\t\t\t\t}\r\n\t\t\t\tif lg != nil {\r\n\t\t\t\t\tlg.Info(\"purged\", zap.String(\"path\", f))\r\n\t\t\t\t} else {\r\n\t\t\t\t\tplog.Infof(\"purged file %s successfully\", f)\r\n\t\t\t\t}\r\n\t\t\t\tnewfnames = newfnames[1:]\r\n\t\t\t}\r\n\t\t\tif purgec != nil {\r\n\t\t\t\tfor i := 0; i < len(fnames)-len(newfnames); i++ {\r\n\t\t\t\t\tpurgec <- fnames[i]\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tselect {\r\n\t\t\tcase <-time.After(interval):\r\n\t\t\tcase <-stop:\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t}\r\n\t}()\r\n\treturn errC\r\n}","code-length":627,"reference":"\/\/ purgeFile is the internal implementation for PurgeFile which can post purged files to purgec if non-nil.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ss *StringsValue) Set(s string) error {\r\n\t*ss = strings.Split(s, \",\")\r\n\treturn nil\r\n}","code-length":45,"reference":"\/\/ Set parses a command line set of strings, separated by comma.\n\/\/ Implements \"flag.Value\" interface.","result":"Set the value of the stringsValue.","score":[0.0434,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewStringsValue(s string) (ss *StringsValue) {\r\n\tif s == \"\" {\r\n\t\treturn &StringsValue{}\r\n\t}\r\n\tss = new(StringsValue)\r\n\tif err := ss.Set(s); err != nil {\r\n\t\tplog.Panicf(\"new StringsValue should never fail: %v\", err)\r\n\t}\r\n\treturn ss\r\n}","code-length":105,"reference":"\/\/ NewStringsValue implements string slice as \"flag.Value\" interface.\n\/\/ Given value is to be separated by comma.","result":"Create a new StringsValue.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StringsFromFlag(fs *flag.FlagSet, flagName string) []string {\r\n\treturn []string(*fs.Lookup(flagName).Value.(*StringsValue))\r\n}","code-length":51,"reference":"\/\/ StringsFromFlag returns a string slice from the flag.","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Cluster(v string) string {\r\n\tvs := strings.Split(v, \".\")\r\n\tif len(vs) <= 2 {\r\n\t\treturn v\r\n\t}\r\n\treturn fmt.Sprintf(\"%s.%s\", vs[0], vs[1])\r\n}","code-length":75,"reference":"\/\/ Cluster only keeps the major.minor.","result":"Create cluster objects.","score":[0,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPageWriter(w io.Writer, pageBytes, pageOffset int) *PageWriter {\r\n\treturn &PageWriter{\r\n\t\tw:                 w,\r\n\t\tpageOffset:        pageOffset,\r\n\t\tpageBytes:         pageBytes,\r\n\t\tbuf:               make([]byte, defaultBufferBytes+pageBytes),\r\n\t\tbufWatermarkBytes: defaultBufferBytes,\r\n\t}\r\n}","code-length":107,"reference":"\/\/ NewPageWriter creates a new PageWriter. pageBytes is the number of bytes\n\/\/ to write per page. pageOffset is the starting offset of io.Writer.","result":"Create a new page writer.","score":[0.0076,0.1332]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wh *watcherHub) watch(key string, recursive, stream bool, index, storeIndex uint64) (Watcher, *v2error.Error) {\r\n\treportWatchRequest()\r\n\tevent, err := wh.EventHistory.scan(key, recursive, index)\r\n\tif err != nil {\r\n\t\terr.Index = storeIndex\r\n\t\treturn nil, err\r\n\t}\r\n\tw := &watcher{\r\n\t\teventChan:  make(chan *Event, 100),\r\n\t\trecursive:  recursive,\r\n\t\tstream:     stream,\r\n\t\tsinceIndex: index,\r\n\t\tstartIndex: storeIndex,\r\n\t\thub:        wh,\r\n\t}\r\n\twh.mutex.Lock()\r\n\tdefer wh.mutex.Unlock()\r\n\t\r\n\tif event != nil {\r\n\t\tne := event.Clone()\r\n\t\tne.EtcdIndex = storeIndex\r\n\t\tw.eventChan <- ne\r\n\t\treturn w, nil\r\n\t}\r\n\tl, ok := wh.watchers[key]\r\n\tvar elem *list.Element\r\n\tif ok {\r\n\t\telem = l.PushBack(w)\r\n\t} else {\r\n\t\tl = list.New()\r\n\t\telem = l.PushBack(w)\r\n\t\twh.watchers[key] = l\r\n\t}\r\n\tw.remove = func() {\r\n\t\tif w.removed {\r\n\t\t\treturn\r\n\t\t}\r\n\t\tw.removed = true\r\n\t\tl.Remove(elem)\r\n\t\tatomic.AddInt64(&wh.count, -1)\r\n\t\treportWatcherRemoved()\r\n\t\tif l.Len() == 0 {\r\n\t\t\tdelete(wh.watchers, key)\r\n\t\t}\r\n\t}\r\n\tatomic.AddInt64(&wh.count, 1)\r\n\treportWatcherAdded()\r\n\treturn w, nil\r\n}","code-length":477,"reference":"\/\/ Watch function returns a Watcher.\n\/\/ If recursive is true, the first change after index under key will be sent to the event channel of the watcher.\n\/\/ If recursive is false, the first change after index at key will be sent to the event channel of the watcher.\n\/\/ If index is zero, watch will start from the current index + 1.","result":"Watch a key.","score":[0.0,0.0173]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wh *watcherHub) notify(e *Event) {\r\n\te = wh.EventHistory.addEvent(e)\r\n\tsegments := strings.Split(e.Node.Key, \"\/\")\r\n\tcurrPath := \"\/\"\r\n\t\r\n\t\r\n\t\r\n\tfor _, segment := range segments {\r\n\t\tcurrPath = path.Join(currPath, segment)\r\n\t\t\r\n\t\twh.notifyWatchers(e, currPath, false)\r\n\t}\r\n}","code-length":125,"reference":"\/\/ notify function accepts an event and notify to the watchers.","result":"Notify watchers.","score":[0.0056,0.099]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wh *watcherHub) clone() *watcherHub {\r\n\tclonedHistory := wh.EventHistory.clone()\r\n\treturn &watcherHub{\r\n\t\tEventHistory: clonedHistory,\r\n\t}\r\n}","code-length":61,"reference":"\/\/ clone function clones the watcherHub and return the cloned one.\n\/\/ only clone the static content. do not clone the current watchers.","result":"Avoid cloning the event history.","score":[0.0066,0.0884]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isHidden(watchPath, keyPath string) bool {\r\n\t\r\n\t\r\n\tif len(watchPath) > len(keyPath) {\r\n\t\treturn false\r\n\t}\r\n\t\r\n\t\r\n\tafterPath := path.Clean(\"\/\" + keyPath[len(watchPath):])\r\n\treturn strings.Contains(afterPath, \"\/_\")\r\n}","code-length":95,"reference":"\/\/ isHidden checks to see if key path is considered hidden to watch path i.e. the\n\/\/ last element is hidden or it's within a hidden directory","result":"Determine if the file is hidden.","score":[0.0077,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (srv *Server) createEtcdLogFile() error {\r\n\tvar err error\r\n\tsrv.etcdLogFile, err = os.Create(srv.Member.Etcd.LogOutputs[0])\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tsrv.lg.Info(\"created etcd log file\", zap.String(\"path\", srv.Member.Etcd.LogOutputs[0]))\r\n\treturn nil\r\n}","code-length":110,"reference":"\/\/ just archive the first file","result":"Create etcd log file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (srv *Server) runEtcd() error {\r\n\terrc := make(chan error)\r\n\tgo func() {\r\n\t\ttime.Sleep(5 * time.Second)\r\n\t\t\r\n\t\t\r\n\t\terrc <- srv.startProxy()\r\n\t}()\r\n\tif srv.etcdCmd != nil {\r\n\t\tsrv.lg.Info(\r\n\t\t\t\"starting etcd command\",\r\n\t\t\tzap.String(\"command-path\", srv.etcdCmd.Path),\r\n\t\t)\r\n\t\terr := srv.etcdCmd.Start()\r\n\t\tperr := <-errc\r\n\t\tsrv.lg.Info(\r\n\t\t\t\"started etcd command\",\r\n\t\t\tzap.String(\"command-path\", srv.etcdCmd.Path),\r\n\t\t\tzap.Errors(\"errors\", []error{err, perr}),\r\n\t\t)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn perr\r\n\t}\r\n\tselect {\r\n\tcase <-srv.etcdServer.Server.ReadyNotify():\r\n\t\tsrv.lg.Info(\"embedded etcd is ready\")\r\n\tcase <-time.After(time.Minute):\r\n\t\tsrv.etcdServer.Close()\r\n\t\treturn fmt.Errorf(\"took too long to start %v\", <-srv.etcdServer.Err())\r\n\t}\r\n\treturn <-errc\r\n}","code-length":354,"reference":"\/\/ start but do not wait for it to complete","result":"Run etcd server.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (srv *Server) stopEtcd(sig os.Signal) error {\r\n\tsrv.stopProxy()\r\n\tif srv.etcdCmd != nil {\r\n\t\tsrv.lg.Info(\r\n\t\t\t\"stopping etcd command\",\r\n\t\t\tzap.String(\"command-path\", srv.etcdCmd.Path),\r\n\t\t\tzap.String(\"signal\", sig.String()),\r\n\t\t)\r\n\t\terr := srv.etcdCmd.Process.Signal(sig)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\terrc := make(chan error)\r\n\t\tgo func() {\r\n\t\t\t_, ew := srv.etcdCmd.Process.Wait()\r\n\t\t\terrc <- ew\r\n\t\t\tclose(errc)\r\n\t\t}()\r\n\t\tselect {\r\n\t\tcase <-time.After(5 * time.Second):\r\n\t\t\tsrv.etcdCmd.Process.Kill()\r\n\t\tcase e := <-errc:\r\n\t\t\treturn e\r\n\t\t}\r\n\t\terr = <-errc\r\n\t\tsrv.lg.Info(\r\n\t\t\t\"stopped etcd command\",\r\n\t\t\tzap.String(\"command-path\", srv.etcdCmd.Path),\r\n\t\t\tzap.String(\"signal\", sig.String()),\r\n\t\t\tzap.Error(err),\r\n\t\t)\r\n\t\treturn err\r\n\t}\r\n\tsrv.lg.Info(\"stopping embedded etcd\")\r\n\tsrv.etcdServer.Server.HardStop()\r\n\tsrv.etcdServer.Close()\r\n\tsrv.lg.Info(\"stopped embedded etcd\")\r\n\treturn nil\r\n}","code-length":415,"reference":"\/\/ SIGQUIT to exit with stackstrace","result":"Stop the embedded etcd server.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (srv *Server) handle_SIGQUIT_ETCD_AND_REMOVE_DATA_AND_STOP_AGENT() (*rpcpb.Response, error) {\r\n\terr := srv.stopEtcd(syscall.SIGQUIT)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif srv.etcdServer != nil {\r\n\t\tsrv.etcdServer.GetLogger().Sync()\r\n\t} else {\r\n\t\tsrv.etcdLogFile.Sync()\r\n\t\tsrv.etcdLogFile.Close()\r\n\t}\r\n\terr = os.RemoveAll(srv.Member.BaseDir)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tsrv.lg.Info(\"removed base directory\", zap.String(\"dir\", srv.Member.BaseDir))\r\n\t\r\n\tsrv.Stop()\r\n\treturn &rpcpb.Response{\r\n\t\tSuccess: true,\r\n\t\tStatus:  \"destroyed etcd and agent\",\r\n\t}, nil\r\n}","code-length":257,"reference":"\/\/ stop proxy, etcd, delete data directory","result":"Handle SIGTERM and SIGKILL.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LimitListener(l net.Listener, n int) net.Listener {\r\n\treturn &limitListener{l, make(chan struct{}, n)}\r\n}","code-length":46,"reference":"\/\/ LimitListener returns a Listener that accepts at most n simultaneous\n\/\/ connections from the provided Listener.","result":"Create a new listener.","score":[0.0124,0.0637]}
{"code":"\/*is used to<extra_id_0>\r\nfunc allowMethod(w http.ResponseWriter, m string, ms ...string) bool {\r\n\tfor _, meth := range ms {\r\n\t\tif m == meth {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\tw.Header().Set(\"Allow\", strings.Join(ms, \",\"))\r\n\thttp.Error(w, \"Method Not Allowed\", http.StatusMethodNotAllowed)\r\n\treturn false\r\n}","code-length":110,"reference":"\/\/ allowMethod verifies that the given method is one of the allowed methods,\n\/\/ and if not, it writes an error to w.  A boolean is returned indicating\n\/\/ whether or not the method is allowed.","result":"Check if the method is.","score":[0.0008,0.0777]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewWatchServer(s *etcdserver.EtcdServer) pb.WatchServer {\r\n\treturn &watchServer{\r\n\t\tlg: s.Cfg.Logger,\r\n\t\tclusterID: int64(s.Cluster().ID()),\r\n\t\tmemberID:  int64(s.ID()),\r\n\t\tmaxRequestBytes: int(s.Cfg.MaxRequestBytes + grpcOverheadBytes),\r\n\t\tsg:        s,\r\n\t\twatchable: s.Watchable(),\r\n\t\tag:        s,\r\n\t}\r\n}","code-length":141,"reference":"\/\/ NewWatchServer returns a new watch server.","result":"Create a new watch server.","score":[0.5042,0.5836]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FiltersFromRequest(creq *pb.WatchCreateRequest) []mvcc.FilterFunc {\r\n\tfilters := make([]mvcc.FilterFunc, 0, len(creq.Filters))\r\n\tfor _, ft := range creq.Filters {\r\n\t\tswitch ft {\r\n\t\tcase pb.WatchCreateRequest_NOPUT:\r\n\t\t\tfilters = append(filters, filterNoPut)\r\n\t\tcase pb.WatchCreateRequest_NODELETE:\r\n\t\t\tfilters = append(filters, filterNoDelete)\r\n\t\tdefault:\r\n\t\t}\r\n\t}\r\n\treturn filters\r\n}","code-length":152,"reference":"\/\/ FiltersFromRequest returns \"mvcc.FilterFunc\" from a given watch create request.","result":"Create a new watch request.","score":[0.1163,0.2105]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newPipelineHandler(t *Transport, r Raft, cid types.ID) http.Handler {\r\n\treturn &pipelineHandler{\r\n\t\tlg:      t.Logger,\r\n\t\tlocalID: t.ID,\r\n\t\ttr:      t,\r\n\t\tr:       r,\r\n\t\tcid:     cid,\r\n\t}\r\n}","code-length":94,"reference":"\/\/ newPipelineHandler returns a handler for handling raft messages\n\/\/ from pipeline for RaftPrefix.\n\/\/\n\/\/ The handler reads out the raft message from request body,\n\/\/ and forwards it to the given raft state machine for processing.","result":"Create a pipeline handler.","score":[0.0001,0.0289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkClusterCompatibilityFromHeader(lg *zap.Logger, localID types.ID, header http.Header, cid types.ID) error {\r\n\tremoteName := header.Get(\"X-Server-From\")\r\n\tremoteServer := serverVersion(header)\r\n\tremoteVs := \"\"\r\n\tif remoteServer != nil {\r\n\t\tremoteVs = remoteServer.String()\r\n\t}\r\n\tremoteMinClusterVer := minClusterVersion(header)\r\n\tremoteMinClusterVs := \"\"\r\n\tif remoteMinClusterVer != nil {\r\n\t\tremoteMinClusterVs = remoteMinClusterVer.String()\r\n\t}\r\n\tlocalServer, localMinCluster, err := checkVersionCompatibility(remoteName, remoteServer, remoteMinClusterVer)\r\n\tlocalVs := \"\"\r\n\tif localServer != nil {\r\n\t\tlocalVs = localServer.String()\r\n\t}\r\n\tlocalMinClusterVs := \"\"\r\n\tif localMinCluster != nil {\r\n\t\tlocalMinClusterVs = localMinCluster.String()\r\n\t}\r\n\tif err != nil {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\r\n\t\t\t\t\"failed to check version compatibility\",\r\n\t\t\t\tzap.String(\"local-member-id\", localID.String()),\r\n\t\t\t\tzap.String(\"local-member-cluster-id\", cid.String()),\r\n\t\t\t\tzap.String(\"local-member-server-version\", localVs),\r\n\t\t\t\tzap.String(\"local-member-server-minimum-cluster-version\", localMinClusterVs),\r\n\t\t\t\tzap.String(\"remote-peer-server-name\", remoteName),\r\n\t\t\t\tzap.String(\"remote-peer-server-version\", remoteVs),\r\n\t\t\t\tzap.String(\"remote-peer-server-minimum-cluster-version\", remoteMinClusterVs),\r\n\t\t\t\tzap.Error(err),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Errorf(\"request version incompatibility (%v)\", err)\r\n\t\t}\r\n\t\treturn errIncompatibleVersion\r\n\t}\r\n\tif gcid := header.Get(\"X-Etcd-Cluster-ID\"); gcid != cid.String() {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\r\n\t\t\t\t\"request cluster ID mismatch\",\r\n\t\t\t\tzap.String(\"local-member-id\", localID.String()),\r\n\t\t\t\tzap.String(\"local-member-cluster-id\", cid.String()),\r\n\t\t\t\tzap.String(\"local-member-server-version\", localVs),\r\n\t\t\t\tzap.String(\"local-member-server-minimum-cluster-version\", localMinClusterVs),\r\n\t\t\t\tzap.String(\"remote-peer-server-name\", remoteName),\r\n\t\t\t\tzap.String(\"remote-peer-server-version\", remoteVs),\r\n\t\t\t\tzap.String(\"remote-peer-server-minimum-cluster-version\", remoteMinClusterVs),\r\n\t\t\t\tzap.String(\"remote-peer-cluster-id\", gcid),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Errorf(\"request cluster ID mismatch (got %s want %s)\", gcid, cid)\r\n\t\t}\r\n\t\treturn errClusterIDMismatch\r\n\t}\r\n\treturn nil\r\n}","code-length":795,"reference":"\/\/ checkClusterCompatibilityFromHeader checks the cluster compatibility of\n\/\/ the local member from the given header.\n\/\/ It checks whether the version of local member is compatible with\n\/\/ the versions in the header, and whether the cluster ID of local member\n\/\/ matches the one in the header.","result":"Code too long,keep in 512.","score":[0.0,0.0114]}
{"code":"\/*is used to<extra_id_0>\r\nfunc KeyExists(key string) clientv3.Cmp {\r\n\treturn clientv3.Compare(clientv3.Version(key), \">\", 0)\r\n}","code-length":47,"reference":"\/\/ KeyExists returns a comparison operation that evaluates to true iff the given\n\/\/ key exists. It does this by checking if the key `Version` is greater than 0.\n\/\/ It is a useful guard in transaction delete operations.","result":"Check if a key exists.","score":[0.0005,0.1045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc KeyMissing(key string) clientv3.Cmp {\r\n\treturn clientv3.Compare(clientv3.Version(key), \"=\", 0)\r\n}","code-length":47,"reference":"\/\/ KeyMissing returns a comparison operation that evaluates to true iff the\n\/\/ given key does not exist.","result":"Detect missing keys.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ValidateSecureEndpoints(tlsInfo TLSInfo, eps []string) ([]string, error) {\r\n\tt, err := NewTransport(tlsInfo, 5*time.Second)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar errs []string\r\n\tvar endpoints []string\r\n\tfor _, ep := range eps {\r\n\t\tif !strings.HasPrefix(ep, \"https:\r\n\t\t\terrs = append(errs, fmt.Sprintf(\"%q is insecure\", ep))\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tconn, cerr := t.Dial(\"tcp\", ep[len(\"https:\r\n\t\tif cerr != nil {\r\n\t\t\terrs = append(errs, fmt.Sprintf(\"%q failed to dial (%v)\", ep, cerr))\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tconn.Close()\r\n\t\tendpoints = append(endpoints, ep)\r\n\t}\r\n\tif len(errs) != 0 {\r\n\t\terr = fmt.Errorf(\"%s\", strings.Join(errs, \",\"))\r\n\t}\r\n\treturn endpoints, err\r\n}","code-length":282,"reference":"\/\/ ValidateSecureEndpoints scans the given endpoints against tls info, returning only those\n\/\/ endpoints that could be validated as secure.","result":"Validate the endpoints of a secure endpoint.","score":[0.03,0.0802]}
{"code":"\/*is used to<extra_id_0>\r\nfunc putNewKV(kv v3.KV, key, val string, leaseID v3.LeaseID) (int64, error) {\r\n\tcmp := v3.Compare(v3.Version(key), \"=\", 0)\r\n\treq := v3.OpPut(key, val, v3.WithLease(leaseID))\r\n\ttxnresp, err := kv.Txn(context.TODO()).If(cmp).Then(req).Commit()\r\n\tif err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\tif !txnresp.Succeeded {\r\n\t\treturn 0, ErrKeyExists\r\n\t}\r\n\treturn txnresp.Header.Revision, nil\r\n}","code-length":171,"reference":"\/\/ putNewKV attempts to create the given key, only succeeding if the key did\n\/\/ not yet exist.","result":"Create a new KV object.","score":[0,0.0299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newUniqueEphemeralKey(s *concurrency.Session, prefix string) (*EphemeralKV, error) {\r\n\treturn newUniqueEphemeralKV(s, prefix, \"\")\r\n}","code-length":51,"reference":"\/\/ newUniqueEphemeralKey creates a new unique valueless key associated with a session lease","result":"Create a new unique ephemeral key.","score":[0.1238,0.2566]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewUpdateDirCommand() cli.Command {\r\n\treturn cli.Command{\r\n\t\tName:      \"updatedir\",\r\n\t\tUsage:     \"update an existing directory\",\r\n\t\tArgsUsage: \"<key> <value>\",\r\n\t\tFlags: []cli.Flag{\r\n\t\t\tcli.IntFlag{Name: \"ttl\", Value: 0, Usage: \"key time-to-live in seconds\"},\r\n\t\t},\r\n\t\tAction: func(c *cli.Context) error {\r\n\t\t\tupdatedirCommandFunc(c, mustNewKeyAPI(c))\r\n\t\t\treturn nil\r\n\t\t},\r\n\t}\r\n}","code-length":164,"reference":"\/\/ NewUpdateDirCommand returns the CLI command for \"updatedir\".","result":"Update the directory.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc updatedirCommandFunc(c *cli.Context, ki client.KeysAPI) {\r\n\tif len(c.Args()) == 0 {\r\n\t\thandleError(c, ExitBadArgs, errors.New(\"key required\"))\r\n\t}\r\n\tkey := c.Args()[0]\r\n\tttl := c.Int(\"ttl\")\r\n\tctx, cancel := contextWithTotalTimeout(c)\r\n\tresp, err := ki.Set(ctx, key, \"\", &client.SetOptions{TTL: time.Duration(ttl) * time.Second, Dir: true, PrevExist: client.PrevExist})\r\n\tcancel()\r\n\tif err != nil {\r\n\t\thandleError(c, ExitServerError, err)\r\n\t}\r\n\tif c.GlobalString(\"output\") != \"simple\" {\r\n\t\tprintResponseKey(resp, c.GlobalString(\"output\"))\r\n\t}\r\n}","code-length":222,"reference":"\/\/ updatedirCommandFunc executes the \"updatedir\" command.","result":"Update the directory in the etcd.","score":[0.193,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc handleBackup(c *cli.Context) error {\r\n\tvar srcWAL string\r\n\tvar destWAL string\r\n\twithV3 := c.Bool(\"with-v3\")\r\n\tsrcSnap := filepath.Join(c.String(\"data-dir\"), \"member\", \"snap\")\r\n\tdestSnap := filepath.Join(c.String(\"backup-dir\"), \"member\", \"snap\")\r\n\tif c.String(\"wal-dir\") != \"\" {\r\n\t\tsrcWAL = c.String(\"wal-dir\")\r\n\t} else {\r\n\t\tsrcWAL = filepath.Join(c.String(\"data-dir\"), \"member\", \"wal\")\r\n\t}\r\n\tif c.String(\"backup-wal-dir\") != \"\" {\r\n\t\tdestWAL = c.String(\"backup-wal-dir\")\r\n\t} else {\r\n\t\tdestWAL = filepath.Join(c.String(\"backup-dir\"), \"member\", \"wal\")\r\n\t}\r\n\tif err := fileutil.CreateDirAll(destSnap); err != nil {\r\n\t\tlog.Fatalf(\"failed creating backup snapshot dir %v: %v\", destSnap, err)\r\n\t}\r\n\twalsnap := saveSnap(destSnap, srcSnap)\r\n\tmetadata, state, ents := loadWAL(srcWAL, walsnap, withV3)\r\n\tsaveDB(filepath.Join(destSnap, \"db\"), filepath.Join(srcSnap, \"db\"), state.Commit, withV3)\r\n\tidgen := idutil.NewGenerator(0, time.Now())\r\n\tmetadata.NodeID = idgen.Next()\r\n\tmetadata.ClusterID = idgen.Next()\r\n\tneww, err := wal.Create(zap.NewExample(), destWAL, pbutil.MustMarshal(&metadata))\r\n\tif err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n\tdefer neww.Close()\r\n\tif err := neww.Save(state, ents); err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n\tif err := neww.SaveSnapshot(walsnap); err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n\treturn nil\r\n}","code-length":557,"reference":"\/\/ handleBackup handles a request that intends to do a backup.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc saveDB(destDB, srcDB string, idx uint64, v3 bool) {\r\n\t\r\n\tif v3 {\r\n\t\tvar src *bolt.DB\r\n\t\tch := make(chan *bolt.DB, 1)\r\n\t\tgo func() {\r\n\t\t\tdb, err := bolt.Open(srcDB, 0444, &bolt.Options{ReadOnly: true})\r\n\t\t\tif err != nil {\r\n\t\t\t\tlog.Fatal(err)\r\n\t\t\t}\r\n\t\t\tch <- db\r\n\t\t}()\r\n\t\tselect {\r\n\t\tcase src = <-ch:\r\n\t\tcase <-time.After(time.Second):\r\n\t\t\tlog.Println(\"waiting to acquire lock on\", srcDB)\r\n\t\t\tsrc = <-ch\r\n\t\t}\r\n\t\tdefer src.Close()\r\n\t\ttx, err := src.Begin(false)\r\n\t\tif err != nil {\r\n\t\t\tlog.Fatal(err)\r\n\t\t}\r\n\t\t\r\n\t\tdest, err := os.Create(destDB)\r\n\t\tif err != nil {\r\n\t\t\tlog.Fatal(err)\r\n\t\t}\r\n\t\tif _, err := tx.WriteTo(dest); err != nil {\r\n\t\t\tlog.Fatal(err)\r\n\t\t}\r\n\t\tdest.Close()\r\n\t\tif err := tx.Rollback(); err != nil {\r\n\t\t\tlog.Fatal(err)\r\n\t\t}\r\n\t}\r\n\tdb, err := bolt.Open(destDB, 0644, &bolt.Options{})\r\n\tif err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n\ttx, err := db.Begin(true)\r\n\tif err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n\t\r\n\tfor _, bucket := range []string{\"members\", \"members_removed\", \"cluster\"} {\r\n\t\ttx.DeleteBucket([]byte(bucket))\r\n\t}\r\n\t\r\n\tif !v3 {\r\n\t\tidxBytes := make([]byte, 8)\r\n\t\tbinary.BigEndian.PutUint64(idxBytes, idx)\r\n\t\tb, err := tx.CreateBucketIfNotExists([]byte(\"meta\"))\r\n\t\tif err != nil {\r\n\t\t\tlog.Fatal(err)\r\n\t\t}\r\n\t\tb.Put([]byte(\"consistent_index\"), idxBytes)\r\n\t}\r\n\tif err := tx.Commit(); err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n\tif err := db.Close(); err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n}","code-length":662,"reference":"\/\/ saveDB copies the v3 backend and strips cluster information.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewWatchCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"watcher\",\r\n\t\tShort: \"Performs watch operation\",\r\n\t\tRun:   runWatcherFunc,\r\n\t}\r\n\tcmd.Flags().DurationVar(&runningTime, \"running-time\", 60, \"number of seconds to run\")\r\n\tcmd.Flags().StringVar(&watchPrefix, \"prefix\", \"\", \"the prefix to append on all keys\")\r\n\tcmd.Flags().IntVar(&noOfPrefixes, \"total-prefixes\", 10, \"total no of prefixes to use\")\r\n\tcmd.Flags().IntVar(&watchPerPrefix, \"watch-per-prefix\", 10, \"number of watchers per prefix\")\r\n\tcmd.Flags().IntVar(&totalKeys, \"total-keys\", 1000, \"total number of keys to watch\")\r\n\treturn cmd\r\n}","code-length":222,"reference":"\/\/ NewWatchCommand returns the cobra command for \"watcher runner\".","result":"Create a new command .","score":[0.108,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewV3(lg *zap.Logger) Manager {\r\n\tif lg == nil {\r\n\t\tlg = zap.NewExample()\r\n\t}\r\n\treturn &v3Manager{lg: lg}\r\n}","code-length":62,"reference":"\/\/ NewV3 returns a new snapshot Manager for v3.x snapshot.","result":"Create a new V.","score":[0.1008,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *v3Manager) Save(ctx context.Context, cfg clientv3.Config, dbPath string) error {\r\n\tif len(cfg.Endpoints) != 1 {\r\n\t\treturn fmt.Errorf(\"snapshot must be requested to one selected node, not multiple %v\", cfg.Endpoints)\r\n\t}\r\n\tcli, err := clientv3.New(cfg)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer cli.Close()\r\n\tpartpath := dbPath + \".part\"\r\n\tdefer os.RemoveAll(partpath)\r\n\tvar f *os.File\r\n\tf, err = os.OpenFile(partpath, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, fileutil.PrivateFileMode)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"could not open %s (%v)\", partpath, err)\r\n\t}\r\n\ts.lg.Info(\r\n\t\t\"created temporary db file\",\r\n\t\tzap.String(\"path\", partpath),\r\n\t)\r\n\tnow := time.Now()\r\n\tvar rd io.ReadCloser\r\n\trd, err = cli.Snapshot(ctx)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ts.lg.Info(\r\n\t\t\"fetching snapshot\",\r\n\t\tzap.String(\"endpoint\", cfg.Endpoints[0]),\r\n\t)\r\n\tif _, err = io.Copy(f, rd); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err = fileutil.Fsync(f); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err = f.Close(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\ts.lg.Info(\r\n\t\t\"fetched snapshot\",\r\n\t\tzap.String(\"endpoint\", cfg.Endpoints[0]),\r\n\t\tzap.Duration(\"took\", time.Since(now)),\r\n\t)\r\n\tif err = os.Rename(partpath, dbPath); err != nil {\r\n\t\treturn fmt.Errorf(\"could not rename %s to %s (%v)\", partpath, dbPath, err)\r\n\t}\r\n\ts.lg.Info(\"saved\", zap.String(\"path\", dbPath))\r\n\treturn nil\r\n}","code-length":580,"reference":"\/\/ Save fetches snapshot from remote etcd server and saves data to target path.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *v3Manager) Status(dbPath string) (ds Status, err error) {\r\n\tif _, err = os.Stat(dbPath); err != nil {\r\n\t\treturn ds, err\r\n\t}\r\n\tdb, err := bolt.Open(dbPath, 0400, &bolt.Options{ReadOnly: true})\r\n\tif err != nil {\r\n\t\treturn ds, err\r\n\t}\r\n\tdefer db.Close()\r\n\th := crc32.New(crc32.MakeTable(crc32.Castagnoli))\r\n\tif err = db.View(func(tx *bolt.Tx) error {\r\n\t\t\r\n\t\tvar dbErrStrings []string\r\n\t\tfor dbErr := range tx.Check() {\r\n\t\t\tdbErrStrings = append(dbErrStrings, dbErr.Error())\r\n\t\t}\r\n\t\tif len(dbErrStrings) > 0 {\r\n\t\t\treturn fmt.Errorf(\"snapshot file integrity check failed. %d errors found.\\n\"+strings.Join(dbErrStrings, \"\\n\"), len(dbErrStrings))\r\n\t\t}\r\n\t\tds.TotalSize = tx.Size()\r\n\t\tc := tx.Cursor()\r\n\t\tfor next, _ := c.First(); next != nil; next, _ = c.Next() {\r\n\t\t\tb := tx.Bucket(next)\r\n\t\t\tif b == nil {\r\n\t\t\t\treturn fmt.Errorf(\"cannot get hash of bucket %s\", string(next))\r\n\t\t\t}\r\n\t\t\th.Write(next)\r\n\t\t\tiskeyb := (string(next) == \"key\")\r\n\t\t\tb.ForEach(func(k, v []byte) error {\r\n\t\t\t\th.Write(k)\r\n\t\t\t\th.Write(v)\r\n\t\t\t\tif iskeyb {\r\n\t\t\t\t\trev := bytesToRev(k)\r\n\t\t\t\t\tds.Revision = rev.main\r\n\t\t\t\t}\r\n\t\t\t\tds.TotalKey++\r\n\t\t\t\treturn nil\r\n\t\t\t})\r\n\t\t}\r\n\t\treturn nil\r\n\t}); err != nil {\r\n\t\treturn ds, err\r\n\t}\r\n\tds.Hash = h.Sum32()\r\n\treturn ds, nil\r\n}","code-length":546,"reference":"\/\/ Status returns the snapshot file information.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *v3Manager) Restore(cfg RestoreConfig) error {\r\n\tpURLs, err := types.NewURLs(cfg.PeerURLs)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tvar ics types.URLsMap\r\n\tics, err = types.NewURLsMap(cfg.InitialCluster)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tsrv := etcdserver.ServerConfig{\r\n\t\tLogger:              s.lg,\r\n\t\tName:                cfg.Name,\r\n\t\tPeerURLs:            pURLs,\r\n\t\tInitialPeerURLsMap:  ics,\r\n\t\tInitialClusterToken: cfg.InitialClusterToken,\r\n\t}\r\n\tif err = srv.VerifyBootstrap(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\ts.cl, err = membership.NewClusterFromURLsMap(s.lg, cfg.InitialClusterToken, ics)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdataDir := cfg.OutputDataDir\r\n\tif dataDir == \"\" {\r\n\t\tdataDir = cfg.Name + \".etcd\"\r\n\t}\r\n\tif fileutil.Exist(dataDir) {\r\n\t\treturn fmt.Errorf(\"data-dir %q exists\", dataDir)\r\n\t}\r\n\twalDir := cfg.OutputWALDir\r\n\tif walDir == \"\" {\r\n\t\twalDir = filepath.Join(dataDir, \"member\", \"wal\")\r\n\t} else if fileutil.Exist(walDir) {\r\n\t\treturn fmt.Errorf(\"wal-dir %q exists\", walDir)\r\n\t}\r\n\ts.name = cfg.Name\r\n\ts.dbPath = cfg.SnapshotPath\r\n\ts.walDir = walDir\r\n\ts.snapDir = filepath.Join(dataDir, \"member\", \"snap\")\r\n\ts.skipHashCheck = cfg.SkipHashCheck\r\n\ts.lg.Info(\r\n\t\t\"restoring snapshot\",\r\n\t\tzap.String(\"path\", s.dbPath),\r\n\t\tzap.String(\"wal-dir\", s.walDir),\r\n\t\tzap.String(\"data-dir\", dataDir),\r\n\t\tzap.String(\"snap-dir\", s.snapDir),\r\n\t)\r\n\tif err = s.saveDB(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err = s.saveWALAndSnap(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\ts.lg.Info(\r\n\t\t\"restored snapshot\",\r\n\t\tzap.String(\"path\", s.dbPath),\r\n\t\tzap.String(\"wal-dir\", s.walDir),\r\n\t\tzap.String(\"data-dir\", dataDir),\r\n\t\tzap.String(\"snap-dir\", s.snapDir),\r\n\t)\r\n\treturn nil\r\n}","code-length":723,"reference":"\/\/ Restore restores a new etcd data directory from given snapshot file.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewAuthStore(lg *zap.Logger, be backend.Backend, tp TokenProvider, bcryptCost int) *authStore {\r\n\tif bcryptCost < bcrypt.MinCost || bcryptCost > bcrypt.MaxCost {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\r\n\t\t\t\t\"use default bcrypt cost instead of the invalid given cost\",\r\n\t\t\t\tzap.Int(\"min-cost\", bcrypt.MinCost),\r\n\t\t\t\tzap.Int(\"max-cost\", bcrypt.MaxCost),\r\n\t\t\t\tzap.Int(\"default-cost\", bcrypt.DefaultCost),\r\n\t\t\t\tzap.Int(\"given-cost\", bcryptCost))\r\n\t\t} else {\r\n\t\t\tplog.Warningf(\"Use default bcrypt-cost %d instead of the invalid value %d\",\r\n\t\t\t\tbcrypt.DefaultCost, bcryptCost)\r\n\t\t}\r\n\t\tbcryptCost = bcrypt.DefaultCost\r\n\t}\r\n\ttx := be.BatchTx()\r\n\ttx.Lock()\r\n\ttx.UnsafeCreateBucket(authBucketName)\r\n\ttx.UnsafeCreateBucket(authUsersBucketName)\r\n\ttx.UnsafeCreateBucket(authRolesBucketName)\r\n\tenabled := false\r\n\t_, vs := tx.UnsafeRange(authBucketName, enableFlagKey, nil, 0)\r\n\tif len(vs) == 1 {\r\n\t\tif bytes.Equal(vs[0], authEnabled) {\r\n\t\t\tenabled = true\r\n\t\t}\r\n\t}\r\n\tas := &authStore{\r\n\t\trevision:       getRevision(tx),\r\n\t\tlg:             lg,\r\n\t\tbe:             be,\r\n\t\tenabled:        enabled,\r\n\t\trangePermCache: make(map[string]*unifiedRangePermissions),\r\n\t\ttokenProvider:  tp,\r\n\t\tbcryptCost:     bcryptCost,\r\n\t}\r\n\tif enabled {\r\n\t\tas.tokenProvider.enable()\r\n\t}\r\n\tif as.Revision() == 0 {\r\n\t\tas.commitRevision(tx)\r\n\t}\r\n\ttx.Unlock()\r\n\tbe.ForceCommit()\r\n\treturn as\r\n}","code-length":531,"reference":"\/\/ NewAuthStore creates a new AuthStore.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTokenProvider(\r\n\tlg *zap.Logger,\r\n\ttokenOpts string,\r\n\tindexWaiter func(uint64) <-chan struct{}) (TokenProvider, error) {\r\n\ttokenType, typeSpecificOpts, err := decomposeOpts(lg, tokenOpts)\r\n\tif err != nil {\r\n\t\treturn nil, ErrInvalidAuthOpts\r\n\t}\r\n\tswitch tokenType {\r\n\tcase tokenTypeSimple:\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\"simple token is not cryptographically signed\")\r\n\t\t} else {\r\n\t\t\tplog.Warningf(\"simple token is not cryptographically signed\")\r\n\t\t}\r\n\t\treturn newTokenProviderSimple(lg, indexWaiter), nil\r\n\tcase tokenTypeJWT:\r\n\t\treturn newTokenProviderJWT(lg, typeSpecificOpts)\r\n\tcase \"\":\r\n\t\treturn newTokenProviderNop()\r\n\tdefault:\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\r\n\t\t\t\t\"unknown token type\",\r\n\t\t\t\tzap.String(\"type\", tokenType),\r\n\t\t\t\tzap.Error(ErrInvalidAuthOpts),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Errorf(\"unknown token type: %s\", tokenType)\r\n\t\t}\r\n\t\treturn nil, ErrInvalidAuthOpts\r\n\t}\r\n}","code-length":333,"reference":"\/\/ NewTokenProvider creates a new token provider.","result":"Create a token provider.","score":[0.2362,0.5597]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Transport) MendPeer(id types.ID) {\r\n\tt.mu.RLock()\r\n\tp, pok := t.peers[id]\r\n\tg, gok := t.remotes[id]\r\n\tt.mu.RUnlock()\r\n\tif pok {\r\n\t\tp.(Pausable).Resume()\r\n\t}\r\n\tif gok {\r\n\t\tg.Resume()\r\n\t}\r\n}","code-length":119,"reference":"\/\/ MendPeer recovers the message dropping behavior of the given peer.","result":"Mend peers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Transport) removePeer(id types.ID) {\r\n\tif peer, ok := t.peers[id]; ok {\r\n\t\tpeer.stop()\r\n\t} else {\r\n\t\tif t.Logger != nil {\r\n\t\t\tt.Logger.Panic(\"unexpected removal of unknown remote peer\", zap.String(\"remote-peer-id\", id.String()))\r\n\t\t} else {\r\n\t\t\tplog.Panicf(\"unexpected removal of unknown peer '%d'\", id)\r\n\t\t}\r\n\t}\r\n\tdelete(t.peers, id)\r\n\tdelete(t.LeaderStats.Followers, id.String())\r\n\tt.pipelineProber.Remove(id.String())\r\n\tt.streamProber.Remove(id.String())\r\n\tif t.Logger != nil {\r\n\t\tt.Logger.Info(\r\n\t\t\t\"removed remote peer\",\r\n\t\t\tzap.String(\"local-member-id\", t.ID.String()),\r\n\t\t\tzap.String(\"removed-remote-peer-id\", id.String()),\r\n\t\t)\r\n\t} else {\r\n\t\tplog.Infof(\"removed peer %s\", id)\r\n\t}\r\n}","code-length":300,"reference":"\/\/ the caller of this function must have the peers mutex.","result":"Remove peer from transport.","score":[0,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Transport) ActivePeers() (cnt int) {\r\n\tt.mu.RLock()\r\n\tdefer t.mu.RUnlock()\r\n\tfor _, p := range t.peers {\r\n\t\tif !p.activeSince().IsZero() {\r\n\t\t\tcnt++\r\n\t\t}\r\n\t}\r\n\treturn cnt\r\n}","code-length":95,"reference":"\/\/ ActivePeers returns a channel that closes when an initial\n\/\/ peer connection has been established. Use this to wait until the\n\/\/ first peer connection becomes active.","result":"Get the number of active peers.","score":[0.0049,0.0194]}
{"code":"\/*is used to<extra_id_0>\r\nfunc resolveTCPAddrDefault(ctx context.Context, addr string) (*net.TCPAddr, error) {\r\n\thost, port, serr := net.SplitHostPort(addr)\r\n\tif serr != nil {\r\n\t\treturn nil, serr\r\n\t}\r\n\tportnum, perr := net.DefaultResolver.LookupPort(ctx, \"tcp\", port)\r\n\tif perr != nil {\r\n\t\treturn nil, perr\r\n\t}\r\n\tvar ips []net.IPAddr\r\n\tif ip := net.ParseIP(host); ip != nil {\r\n\t\tips = []net.IPAddr{{IP: ip}}\r\n\t} else {\r\n\t\t\r\n\t\tipss, err := net.DefaultResolver.LookupIPAddr(ctx, host)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tips = ipss\r\n\t}\r\n\t\r\n\tip := ips[0]\r\n\treturn &net.TCPAddr{IP: ip.IP, Port: portnum, Zone: ip.Zone}, nil\r\n}","code-length":269,"reference":"\/\/ taken from go's ResolveTCP code but uses configurable ctx","result":"Resolve a default address.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc resolveTCPAddrs(ctx context.Context, lg *zap.Logger, urls [][]url.URL) ([][]url.URL, error) {\r\n\tnewurls := make([][]url.URL, 0)\r\n\tfor _, us := range urls {\r\n\t\tnus := make([]url.URL, len(us))\r\n\t\tfor i, u := range us {\r\n\t\t\tnu, err := url.Parse(u.String())\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, fmt.Errorf(\"failed to parse %q (%v)\", u.String(), err)\r\n\t\t\t}\r\n\t\t\tnus[i] = *nu\r\n\t\t}\r\n\t\tfor i, u := range nus {\r\n\t\t\th, err := resolveURL(ctx, lg, u)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, fmt.Errorf(\"failed to resolve %q (%v)\", u.String(), err)\r\n\t\t\t}\r\n\t\t\tif h != \"\" {\r\n\t\t\t\tnus[i].Host = h\r\n\t\t\t}\r\n\t\t}\r\n\t\tnewurls = append(newurls, nus)\r\n\t}\r\n\treturn newurls, nil\r\n}","code-length":304,"reference":"\/\/ resolveTCPAddrs is a convenience wrapper for net.ResolveTCPAddr.\n\/\/ resolveTCPAddrs return a new set of url.URLs, in which all DNS hostnames\n\/\/ are resolved.","result":"Resolve the address of a given URL.","score":[0.0169,0.0673]}
{"code":"\/*is used to<extra_id_0>\r\nfunc urlsEqual(ctx context.Context, lg *zap.Logger, a []url.URL, b []url.URL) (bool, error) {\r\n\tif len(a) != len(b) {\r\n\t\treturn false, fmt.Errorf(\"len(%q) != len(%q)\", urlsToStrings(a), urlsToStrings(b))\r\n\t}\r\n\turls, err := resolveTCPAddrs(ctx, lg, [][]url.URL{a, b})\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\tpreva, prevb := a, b\r\n\ta, b = urls[0], urls[1]\r\n\tsort.Sort(types.URLs(a))\r\n\tsort.Sort(types.URLs(b))\r\n\tfor i := range a {\r\n\t\tif !reflect.DeepEqual(a[i], b[i]) {\r\n\t\t\treturn false, fmt.Errorf(\"%q(resolved from %q) != %q(resolved from %q)\",\r\n\t\t\t\ta[i].String(), preva[i].String(),\r\n\t\t\t\tb[i].String(), prevb[i].String(),\r\n\t\t\t)\r\n\t\t}\r\n\t}\r\n\treturn true, nil\r\n}","code-length":308,"reference":"\/\/ urlsEqual checks equality of url.URLS between two arrays.\n\/\/ This check pass even if an URL is in hostname and opposite is in IP address.","result":"Compare urls in the same order as the urls in the list.","score":[0.033,0.061]}
{"code":"\/*is used to<extra_id_0>\r\nfunc URLStringsEqual(ctx context.Context, lg *zap.Logger, a []string, b []string) (bool, error) {\r\n\tif len(a) != len(b) {\r\n\t\treturn false, fmt.Errorf(\"len(%q) != len(%q)\", a, b)\r\n\t}\r\n\turlsA := make([]url.URL, 0)\r\n\tfor _, str := range a {\r\n\t\tu, err := url.Parse(str)\r\n\t\tif err != nil {\r\n\t\t\treturn false, fmt.Errorf(\"failed to parse %q\", str)\r\n\t\t}\r\n\t\turlsA = append(urlsA, *u)\r\n\t}\r\n\turlsB := make([]url.URL, 0)\r\n\tfor _, str := range b {\r\n\t\tu, err := url.Parse(str)\r\n\t\tif err != nil {\r\n\t\t\treturn false, fmt.Errorf(\"failed to parse %q\", str)\r\n\t\t}\r\n\t\turlsB = append(urlsB, *u)\r\n\t}\r\n\tif lg == nil {\r\n\t\tlg, _ = zap.NewProduction()\r\n\t\tif lg == nil {\r\n\t\t\tlg = zap.NewExample()\r\n\t\t}\r\n\t}\r\n\treturn urlsEqual(ctx, lg, urlsA, urlsB)\r\n}","code-length":337,"reference":"\/\/ URLStringsEqual returns \"true\" if given URLs are valid\n\/\/ and resolved to same IP addresses. Otherwise, return \"false\"\n\/\/ and error, if any.","result":"Compare URLs in a string array.","score":[0.0096,0.0225]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLeaseCommand() *cobra.Command {\r\n\tlc := &cobra.Command{\r\n\t\tUse:   \"lease <subcommand>\",\r\n\t\tShort: \"Lease related commands\",\r\n\t}\r\n\tlc.AddCommand(NewLeaseGrantCommand())\r\n\tlc.AddCommand(NewLeaseRevokeCommand())\r\n\tlc.AddCommand(NewLeaseTimeToLiveCommand())\r\n\tlc.AddCommand(NewLeaseListCommand())\r\n\tlc.AddCommand(NewLeaseKeepAliveCommand())\r\n\treturn lc\r\n}","code-length":136,"reference":"\/\/ NewLeaseCommand returns the cobra command for \"lease\".","result":"Create a new lease.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLeaseGrantCommand() *cobra.Command {\r\n\tlc := &cobra.Command{\r\n\t\tUse:   \"grant <ttl>\",\r\n\t\tShort: \"Creates leases\",\r\n\t\tRun: leaseGrantCommandFunc,\r\n\t}\r\n\treturn lc\r\n}","code-length":81,"reference":"\/\/ NewLeaseGrantCommand returns the cobra command for \"lease grant\".","result":"Create leases.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc leaseGrantCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"lease grant command needs TTL argument\"))\r\n\t}\r\n\tttl, err := strconv.ParseInt(args[0], 10, 64)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"bad TTL (%v)\", err))\r\n\t}\r\n\tctx, cancel := commandCtx(cmd)\r\n\tresp, err := mustClientFromCmd(cmd).Grant(ctx, ttl)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, fmt.Errorf(\"failed to grant lease (%v)\", err))\r\n\t}\r\n\tdisplay.Grant(*resp)\r\n}","code-length":206,"reference":"\/\/ leaseGrantCommandFunc executes the \"lease grant\" command.","result":"Generate the code.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLeaseRevokeCommand() *cobra.Command {\r\n\tlc := &cobra.Command{\r\n\t\tUse:   \"revoke <leaseID>\",\r\n\t\tShort: \"Revokes leases\",\r\n\t\tRun: leaseRevokeCommandFunc,\r\n\t}\r\n\treturn lc\r\n}","code-length":85,"reference":"\/\/ NewLeaseRevokeCommand returns the cobra command for \"lease revoke\".","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc leaseRevokeCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"lease revoke command needs 1 argument\"))\r\n\t}\r\n\tid := leaseFromArgs(args[0])\r\n\tctx, cancel := commandCtx(cmd)\r\n\tresp, err := mustClientFromCmd(cmd).Revoke(ctx, id)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, fmt.Errorf(\"failed to revoke lease (%v)\", err))\r\n\t}\r\n\tdisplay.Revoke(id, *resp)\r\n}","code-length":167,"reference":"\/\/ leaseRevokeCommandFunc executes the \"lease grant\" command.","result":"Generate the code.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLeaseTimeToLiveCommand() *cobra.Command {\r\n\tlc := &cobra.Command{\r\n\t\tUse:   \"timetolive <leaseID> [options]\",\r\n\t\tShort: \"Get lease information\",\r\n\t\tRun: leaseTimeToLiveCommandFunc,\r\n\t}\r\n\tlc.Flags().BoolVar(&timeToLiveKeys, \"keys\", false, \"Get keys attached to this lease\")\r\n\treturn lc\r\n}","code-length":118,"reference":"\/\/ NewLeaseTimeToLiveCommand returns the cobra command for \"lease timetolive\".","result":"Generate the code.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc leaseTimeToLiveCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"lease timetolive command needs lease ID as argument\"))\r\n\t}\r\n\tvar opts []v3.LeaseOption\r\n\tif timeToLiveKeys {\r\n\t\topts = append(opts, v3.WithAttachedKeys())\r\n\t}\r\n\tresp, rerr := mustClientFromCmd(cmd).TimeToLive(context.TODO(), leaseFromArgs(args[0]), opts...)\r\n\tif rerr != nil {\r\n\t\tExitWithError(ExitBadConnection, rerr)\r\n\t}\r\n\tdisplay.TimeToLive(*resp, timeToLiveKeys)\r\n}","code-length":188,"reference":"\/\/ leaseTimeToLiveCommandFunc executes the \"lease timetolive\" command.","result":"Generate the code.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLeaseListCommand() *cobra.Command {\r\n\tlc := &cobra.Command{\r\n\t\tUse:   \"list\",\r\n\t\tShort: \"List all active leases\",\r\n\t\tRun:   leaseListCommandFunc,\r\n\t}\r\n\treturn lc\r\n}","code-length":81,"reference":"\/\/ NewLeaseListCommand returns the cobra command for \"lease list\".","result":"Create a new command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc leaseListCommandFunc(cmd *cobra.Command, args []string) {\r\n\tresp, rerr := mustClientFromCmd(cmd).Leases(context.TODO())\r\n\tif rerr != nil {\r\n\t\tExitWithError(ExitBadConnection, rerr)\r\n\t}\r\n\tdisplay.Leases(*resp)\r\n}","code-length":90,"reference":"\/\/ leaseListCommandFunc executes the \"lease list\" command.","result":"List leases.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLeaseKeepAliveCommand() *cobra.Command {\r\n\tlc := &cobra.Command{\r\n\t\tUse:   \"keep-alive [options] <leaseID>\",\r\n\t\tShort: \"Keeps leases alive (renew)\",\r\n\t\tRun: leaseKeepAliveCommandFunc,\r\n\t}\r\n\tlc.Flags().BoolVar(&leaseKeepAliveOnce, \"once\", false, \"Resets the keep-alive time to its original value and exits immediately\")\r\n\treturn lc\r\n}","code-length":128,"reference":"\/\/ NewLeaseKeepAliveCommand returns the cobra command for \"lease keep-alive\".","result":"Generate the code.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc leaseKeepAliveCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"lease keep-alive command needs lease ID as argument\"))\r\n\t}\r\n\tid := leaseFromArgs(args[0])\r\n\tif leaseKeepAliveOnce {\r\n\t\trespc, kerr := mustClientFromCmd(cmd).KeepAliveOnce(context.TODO(), id)\r\n\t\tif kerr != nil {\r\n\t\t\tExitWithError(ExitBadConnection, kerr)\r\n\t\t}\r\n\t\tdisplay.KeepAlive(*respc)\r\n\t\treturn\r\n\t}\r\n\trespc, kerr := mustClientFromCmd(cmd).KeepAlive(context.TODO(), id)\r\n\tif kerr != nil {\r\n\t\tExitWithError(ExitBadConnection, kerr)\r\n\t}\r\n\tfor resp := range respc {\r\n\t\tdisplay.KeepAlive(*resp)\r\n\t}\r\n\tif _, ok := (display).(*simplePrinter); ok {\r\n\t\tfmt.Printf(\"lease %016x expired or revoked.\\n\", id)\r\n\t}\r\n}","code-length":285,"reference":"\/\/ leaseKeepAliveCommandFunc executes the \"lease keep-alive\" command.","result":"Run the command .","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewAlarmCommand() *cobra.Command {\r\n\tac := &cobra.Command{\r\n\t\tUse:   \"alarm <subcommand>\",\r\n\t\tShort: \"Alarm related commands\",\r\n\t}\r\n\tac.AddCommand(NewAlarmDisarmCommand())\r\n\tac.AddCommand(NewAlarmListCommand())\r\n\treturn ac\r\n}","code-length":97,"reference":"\/\/ NewAlarmCommand returns the cobra command for \"alarm\".","result":"Create a command to manage the alarm.","score":[0.1665,0.1266]}
{"code":"\/*is used to<extra_id_0>\r\nfunc alarmDisarmCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 0 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"alarm disarm command accepts no arguments\"))\r\n\t}\r\n\tctx, cancel := commandCtx(cmd)\r\n\tresp, err := mustClientFromCmd(cmd).AlarmDisarm(ctx, &v3.AlarmMember{})\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.Alarm(*resp)\r\n}","code-length":149,"reference":"\/\/ alarmDisarmCommandFunc executes the \"alarm disarm\" command.","result":"Generate the code.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc alarmListCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 0 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"alarm list command accepts no arguments\"))\r\n\t}\r\n\tctx, cancel := commandCtx(cmd)\r\n\tresp, err := mustClientFromCmd(cmd).AlarmList(ctx)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.Alarm(*resp)\r\n}","code-length":138,"reference":"\/\/ alarmListCommandFunc executes the \"alarm list\" command.","result":"List all the alarm.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Etcd) Flags() (fs []string) {\r\n\ttp := reflect.TypeOf(*e)\r\n\tvo := reflect.ValueOf(*e)\r\n\tfor _, name := range etcdFields {\r\n\t\tfield, ok := tp.FieldByName(name)\r\n\t\tif !ok {\r\n\t\t\tpanic(fmt.Errorf(\"field %q not found\", name))\r\n\t\t}\r\n\t\tfv := reflect.Indirect(vo).FieldByName(name)\r\n\t\tvar sv string\r\n\t\tswitch fv.Type().Kind() {\r\n\t\tcase reflect.String:\r\n\t\t\tsv = fv.String()\r\n\t\tcase reflect.Slice:\r\n\t\t\tn := fv.Len()\r\n\t\t\tsl := make([]string, n)\r\n\t\t\tfor i := 0; i < n; i++ {\r\n\t\t\t\tsl[i] = fv.Index(i).String()\r\n\t\t\t}\r\n\t\t\tsv = strings.Join(sl, \",\")\r\n\t\tcase reflect.Int64:\r\n\t\t\tsv = fmt.Sprintf(\"%d\", fv.Int())\r\n\t\tcase reflect.Bool:\r\n\t\t\tsv = fmt.Sprintf(\"%v\", fv.Bool())\r\n\t\tdefault:\r\n\t\t\tpanic(fmt.Errorf(\"field %q (%v) cannot be parsed\", name, fv.Type().Kind()))\r\n\t\t}\r\n\t\tfname := field.Tag.Get(\"yaml\")\r\n\t\t\r\n\t\tif fname == \"initial-corrupt-check\" {\r\n\t\t\tfname = \"experimental-\" + fname\r\n\t\t}\r\n\t\tif sv != \"\" {\r\n\t\t\tfs = append(fs, fmt.Sprintf(\"--%s=%s\", fname, sv))\r\n\t\t}\r\n\t}\r\n\treturn fs\r\n}","code-length":440,"reference":"\/\/ Flags returns etcd flags in string slice.","result":"Parse etcd flags.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Etcd) EmbedConfig() (cfg *embed.Config, err error) {\r\n\tvar lcURLs types.URLs\r\n\tlcURLs, err = types.NewURLs(e.ListenClientURLs)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar acURLs types.URLs\r\n\tacURLs, err = types.NewURLs(e.AdvertiseClientURLs)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar lpURLs types.URLs\r\n\tlpURLs, err = types.NewURLs(e.ListenPeerURLs)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar apURLs types.URLs\r\n\tapURLs, err = types.NewURLs(e.AdvertisePeerURLs)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tcfg = embed.NewConfig()\r\n\tcfg.Name = e.Name\r\n\tcfg.Dir = e.DataDir\r\n\tcfg.WalDir = e.WALDir\r\n\tcfg.TickMs = uint(e.HeartbeatIntervalMs)\r\n\tcfg.ElectionMs = uint(e.ElectionTimeoutMs)\r\n\tcfg.LCUrls = lcURLs\r\n\tcfg.ACUrls = acURLs\r\n\tcfg.ClientAutoTLS = e.ClientAutoTLS\r\n\tcfg.ClientTLSInfo = transport.TLSInfo{\r\n\t\tClientCertAuth: e.ClientCertAuth,\r\n\t\tCertFile:       e.ClientCertFile,\r\n\t\tKeyFile:        e.ClientKeyFile,\r\n\t\tTrustedCAFile:  e.ClientTrustedCAFile,\r\n\t}\r\n\tcfg.LPUrls = lpURLs\r\n\tcfg.APUrls = apURLs\r\n\tcfg.PeerAutoTLS = e.PeerAutoTLS\r\n\tcfg.PeerTLSInfo = transport.TLSInfo{\r\n\t\tClientCertAuth: e.PeerClientCertAuth,\r\n\t\tCertFile:       e.PeerCertFile,\r\n\t\tKeyFile:        e.PeerKeyFile,\r\n\t\tTrustedCAFile:  e.PeerTrustedCAFile,\r\n\t}\r\n\tcfg.InitialCluster = e.InitialCluster\r\n\tcfg.ClusterState = e.InitialClusterState\r\n\tcfg.InitialClusterToken = e.InitialClusterToken\r\n\tcfg.SnapshotCount = uint64(e.SnapshotCount)\r\n\tcfg.QuotaBackendBytes = e.QuotaBackendBytes\r\n\tcfg.PreVote = e.PreVote\r\n\tcfg.ExperimentalInitialCorruptCheck = e.InitialCorruptCheck\r\n\tcfg.Logger = e.Logger\r\n\tcfg.LogOutputs = e.LogOutputs\r\n\tcfg.Debug = e.Debug\r\n\treturn cfg, nil\r\n}","code-length":656,"reference":"\/\/ EmbedConfig returns etcd embed.Config.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PProfHandlers() map[string]http.Handler {\r\n\t\r\n\tif runtime.SetMutexProfileFraction(-1) == 0 {\r\n\t\t\r\n\t\truntime.SetMutexProfileFraction(5)\r\n\t}\r\n\tm := make(map[string]http.Handler)\r\n\tm[HTTPPrefixPProf+\"\/\"] = http.HandlerFunc(pprof.Index)\r\n\tm[HTTPPrefixPProf+\"\/profile\"] = http.HandlerFunc(pprof.Profile)\r\n\tm[HTTPPrefixPProf+\"\/symbol\"] = http.HandlerFunc(pprof.Symbol)\r\n\tm[HTTPPrefixPProf+\"\/cmdline\"] = http.HandlerFunc(pprof.Cmdline)\r\n\tm[HTTPPrefixPProf+\"\/trace \"] = http.HandlerFunc(pprof.Trace)\r\n\tm[HTTPPrefixPProf+\"\/heap\"] = pprof.Handler(\"heap\")\r\n\tm[HTTPPrefixPProf+\"\/goroutine\"] = pprof.Handler(\"goroutine\")\r\n\tm[HTTPPrefixPProf+\"\/threadcreate\"] = pprof.Handler(\"threadcreate\")\r\n\tm[HTTPPrefixPProf+\"\/block\"] = pprof.Handler(\"block\")\r\n\tm[HTTPPrefixPProf+\"\/mutex\"] = pprof.Handler(\"mutex\")\r\n\treturn m\r\n}","code-length":314,"reference":"\/\/ PProfHandlers returns a map of pprof handlers keyed by the HTTP path.","result":"Generate the handlers for the PProf.","score":[0.0715,0.0813]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewBackendQuota(s *EtcdServer, name string) Quota {\r\n\tlg := s.getLogger()\r\n\tquotaBackendBytes.Set(float64(s.Cfg.QuotaBackendBytes))\r\n\tif s.Cfg.QuotaBackendBytes < 0 {\r\n\t\t\r\n\t\tquotaLogOnce.Do(func() {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Info(\r\n\t\t\t\t\t\"disabled backend quota\",\r\n\t\t\t\t\tzap.String(\"quota-name\", name),\r\n\t\t\t\t\tzap.Int64(\"quota-size-bytes\", s.Cfg.QuotaBackendBytes),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Warningf(\"disabling backend quota\")\r\n\t\t\t}\r\n\t\t})\r\n\t\treturn &passthroughQuota{}\r\n\t}\r\n\tif s.Cfg.QuotaBackendBytes == 0 {\r\n\t\t\r\n\t\tquotaLogOnce.Do(func() {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Info(\r\n\t\t\t\t\t\"enabled backend quota with default value\",\r\n\t\t\t\t\tzap.String(\"quota-name\", name),\r\n\t\t\t\t\tzap.Int64(\"quota-size-bytes\", DefaultQuotaBytes),\r\n\t\t\t\t\tzap.String(\"quota-size\", DefaultQuotaSize),\r\n\t\t\t\t)\r\n\t\t\t}\r\n\t\t})\r\n\t\tquotaBackendBytes.Set(float64(DefaultQuotaBytes))\r\n\t\treturn &backendQuota{s, DefaultQuotaBytes}\r\n\t}\r\n\tquotaLogOnce.Do(func() {\r\n\t\tif s.Cfg.QuotaBackendBytes > MaxQuotaBytes {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"quota exceeds the maximum value\",\r\n\t\t\t\t\tzap.String(\"quota-name\", name),\r\n\t\t\t\t\tzap.Int64(\"quota-size-bytes\", s.Cfg.QuotaBackendBytes),\r\n\t\t\t\t\tzap.String(\"quota-size\", humanize.Bytes(uint64(s.Cfg.QuotaBackendBytes))),\r\n\t\t\t\t\tzap.Int64(\"quota-maximum-size-bytes\", MaxQuotaBytes),\r\n\t\t\t\t\tzap.String(\"quota-maximum-size\", maxQuotaSize),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Warningf(\"backend quota %v exceeds maximum recommended quota %v\", s.Cfg.QuotaBackendBytes, MaxQuotaBytes)\r\n\t\t\t}\r\n\t\t}\r\n\t\tif lg != nil {\r\n\t\t\tlg.Info(\r\n\t\t\t\t\"enabled backend quota\",\r\n\t\t\t\tzap.String(\"quota-name\", name),\r\n\t\t\t\tzap.Int64(\"quota-size-bytes\", s.Cfg.QuotaBackendBytes),\r\n\t\t\t\tzap.String(\"quota-size\", humanize.Bytes(uint64(s.Cfg.QuotaBackendBytes))),\r\n\t\t\t)\r\n\t\t}\r\n\t})\r\n\treturn &backendQuota{s, s.Cfg.QuotaBackendBytes}\r\n}","code-length":714,"reference":"\/\/ NewBackendQuota creates a quota layer with the given storage limit.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClusterProxy(c *clientv3.Client, advaddr string, prefix string) (pb.ClusterServer, <-chan struct{}) {\r\n\tcp := &clusterProxy{\r\n\t\tclus: c.Cluster,\r\n\t\tctx:  c.Ctx(),\r\n\t\tgr:   &naming.GRPCResolver{Client: c},\r\n\t\tadvaddr: advaddr,\r\n\t\tprefix:  prefix,\r\n\t\tumap:    make(map[string]gnaming.Update),\r\n\t}\r\n\tdonec := make(chan struct{})\r\n\tif advaddr != \"\" && prefix != \"\" {\r\n\t\tgo func() {\r\n\t\t\tdefer close(donec)\r\n\t\t\tcp.resolve(prefix)\r\n\t\t}()\r\n\t\treturn cp, donec\r\n\t}\r\n\tclose(donec)\r\n\treturn cp, donec\r\n}","code-length":223,"reference":"\/\/ NewClusterProxy takes optional prefix to fetch grpc-proxy member endpoints.\n\/\/ The returned channel is closed when there is grpc-proxy endpoint registered\n\/\/ and the client's context is canceled so the 'register' loop returns.","result":"Create a proxy for the cluster.","score":[0.0018,0.016]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewHandler(l lease.Lessor, waitch func() <-chan struct{}) http.Handler {\r\n\treturn &leaseHandler{l, waitch}\r\n}","code-length":48,"reference":"\/\/ NewHandler returns an http Handler for lease renewals","result":"Create a new handler.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc TimeToLiveHTTP(ctx context.Context, id lease.LeaseID, keys bool, url string, rt http.RoundTripper) (*leasepb.LeaseInternalResponse, error) {\r\n\t\r\n\tlreq, err := (&leasepb.LeaseInternalRequest{\r\n\t\tLeaseTimeToLiveRequest: &pb.LeaseTimeToLiveRequest{\r\n\t\t\tID:   int64(id),\r\n\t\t\tKeys: keys,\r\n\t\t},\r\n\t}).Marshal()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treq, err := http.NewRequest(\"POST\", url, bytes.NewReader(lreq))\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treq.Header.Set(\"Content-Type\", \"application\/protobuf\")\r\n\treq = req.WithContext(ctx)\r\n\tcc := &http.Client{Transport: rt}\r\n\tvar b []byte\r\n\t\r\n\tresp, err := cc.Do(req)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tb, err = readResponse(resp)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif resp.StatusCode == http.StatusRequestTimeout {\r\n\t\treturn nil, ErrLeaseHTTPTimeout\r\n\t}\r\n\tif resp.StatusCode == http.StatusNotFound {\r\n\t\treturn nil, lease.ErrLeaseNotFound\r\n\t}\r\n\tif resp.StatusCode != http.StatusOK {\r\n\t\treturn nil, fmt.Errorf(\"lease: unknown error(%s)\", string(b))\r\n\t}\r\n\tlresp := &leasepb.LeaseInternalResponse{}\r\n\tif err := lresp.Unmarshal(b); err != nil {\r\n\t\treturn nil, fmt.Errorf(`lease: %v. data = \"%s\"`, err, string(b))\r\n\t}\r\n\tif lresp.LeaseTimeToLiveResponse.ID != int64(id) {\r\n\t\treturn nil, fmt.Errorf(\"lease: renew id mismatch\")\r\n\t}\r\n\treturn lresp, nil\r\n}","code-length":514,"reference":"\/\/ TimeToLiveHTTP retrieves lease information of the given lease ID.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newWatcherBatch(wg *watcherGroup, evs []mvccpb.Event) watcherBatch {\r\n\tif len(wg.watchers) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\twb := make(watcherBatch)\r\n\tfor _, ev := range evs {\r\n\t\tfor w := range wg.watcherSetByKey(string(ev.Kv.Key)) {\r\n\t\t\tif ev.Kv.ModRevision >= w.minRev {\r\n\t\t\t\t\r\n\t\t\t\twb.add(w, ev)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn wb\r\n}","code-length":156,"reference":"\/\/ newWatcherBatch maps watchers to their matched events. It enables quick\n\/\/ events look up by watcher.","result":"Create a new watcherBatch .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wg *watcherGroup) add(wa *watcher) {\r\n\twg.watchers.add(wa)\r\n\tif wa.end == nil {\r\n\t\twg.keyWatchers.add(wa)\r\n\t\treturn\r\n\t}\r\n\t\r\n\tivl := adt.NewStringAffineInterval(string(wa.key), string(wa.end))\r\n\tif iv := wg.ranges.Find(ivl); iv != nil {\r\n\t\tiv.Val.(watcherSet).add(wa)\r\n\t\treturn\r\n\t}\r\n\t\r\n\tws := make(watcherSet)\r\n\tws.add(wa)\r\n\twg.ranges.Insert(ivl, ws)\r\n}","code-length":188,"reference":"\/\/ add puts a watcher in the group.","result":"Add watchers to the watcherGroup.","score":[0.1319,0.1948]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wg *watcherGroup) contains(key string) bool {\r\n\t_, ok := wg.keyWatchers[key]\r\n\treturn ok || wg.ranges.Intersects(adt.NewStringAffinePoint(key))\r\n}","code-length":65,"reference":"\/\/ contains is whether the given key has a watcher in the group.","result":"Check if the watcherGroup contains a key.","score":[0.0902,0.121]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wg *watcherGroup) delete(wa *watcher) bool {\r\n\tif _, ok := wg.watchers[wa]; !ok {\r\n\t\treturn false\r\n\t}\r\n\twg.watchers.delete(wa)\r\n\tif wa.end == nil {\r\n\t\twg.keyWatchers.delete(wa)\r\n\t\treturn true\r\n\t}\r\n\tivl := adt.NewStringAffineInterval(string(wa.key), string(wa.end))\r\n\tiv := wg.ranges.Find(ivl)\r\n\tif iv == nil {\r\n\t\treturn false\r\n\t}\r\n\tws := iv.Val.(watcherSet)\r\n\tdelete(ws, wa)\r\n\tif len(ws) == 0 {\r\n\t\t\r\n\t\tif ok := wg.ranges.Delete(ivl); !ok {\r\n\t\t\tpanic(\"could not remove watcher from interval tree\")\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":250,"reference":"\/\/ delete removes a watcher from the group.","result":"Delete watchers from the watcherGroup.","score":[0.1865,0.487]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wg *watcherGroup) choose(maxWatchers int, curRev, compactRev int64) (*watcherGroup, int64) {\r\n\tif len(wg.watchers) < maxWatchers {\r\n\t\treturn wg, wg.chooseAll(curRev, compactRev)\r\n\t}\r\n\tret := newWatcherGroup()\r\n\tfor w := range wg.watchers {\r\n\t\tif maxWatchers <= 0 {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tmaxWatchers--\r\n\t\tret.add(w)\r\n\t}\r\n\treturn &ret, ret.chooseAll(curRev, compactRev)\r\n}","code-length":163,"reference":"\/\/ choose selects watchers from the watcher group to update","result":"Create a new watcherGroup.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wg *watcherGroup) watcherSetByKey(key string) watcherSet {\r\n\twkeys := wg.keyWatchers[key]\r\n\twranges := wg.ranges.Stab(adt.NewStringAffinePoint(key))\r\n\t\r\n\tswitch {\r\n\tcase len(wranges) == 0:\r\n\t\t\r\n\t\treturn wkeys\r\n\tcase len(wranges) == 0 && len(wkeys) == 0:\r\n\t\treturn nil\r\n\tcase len(wranges) == 1 && len(wkeys) == 0:\r\n\t\treturn wranges[0].Val.(watcherSet)\r\n\t}\r\n\t\r\n\tret := make(watcherSet)\r\n\tret.union(wg.keyWatchers[key])\r\n\tfor _, item := range wranges {\r\n\t\tret.union(item.Val.(watcherSet))\r\n\t}\r\n\treturn ret\r\n}","code-length":228,"reference":"\/\/ watcherSetByKey gets the set of watchers that receive events on the given key.","result":"Create a watcherSet by the watcherGroup.","score":[0.0509,0.0379]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivl *Interval) Compare(c Comparable) int {\r\n\tivl2 := c.(*Interval)\r\n\tivbCmpBegin := ivl.Begin.Compare(ivl2.Begin)\r\n\tivbCmpEnd := ivl.Begin.Compare(ivl2.End)\r\n\tiveCmpBegin := ivl.End.Compare(ivl2.Begin)\r\n\t\r\n\tif ivbCmpBegin < 0 && iveCmpBegin <= 0 {\r\n\t\treturn -1\r\n\t}\r\n\t\r\n\tif ivbCmpEnd >= 0 {\r\n\t\treturn 1\r\n\t}\r\n\treturn 0\r\n}","code-length":161,"reference":"\/\/ Compare on an interval gives == if the interval overlaps.","result":"Compare two intervals.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (x *intervalNode) successor() *intervalNode {\r\n\tif x.right != nil {\r\n\t\treturn x.right.min()\r\n\t}\r\n\ty := x.parent\r\n\tfor y != nil && x == y.right {\r\n\t\tx = y\r\n\t\ty = y.parent\r\n\t}\r\n\treturn y\r\n}","code-length":97,"reference":"\/\/ successor is the next in-order node in the tree","result":"Find the successor of an interval node.","score":[0.1251,0.1031]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (x *intervalNode) updateMax() {\r\n\tfor x != nil {\r\n\t\toldmax := x.max\r\n\t\tmax := x.iv.Ivl.End\r\n\t\tif x.left != nil && x.left.max.Compare(max) > 0 {\r\n\t\t\tmax = x.left.max\r\n\t\t}\r\n\t\tif x.right != nil && x.right.max.Compare(max) > 0 {\r\n\t\t\tmax = x.right.max\r\n\t\t}\r\n\t\tif oldmax.Compare(max) == 0 {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tx.max = max\r\n\t\tx = x.parent\r\n\t}\r\n}","code-length":182,"reference":"\/\/ updateMax updates the maximum values for a node and its ancestors","result":"Update the max value of the interval node.","score":[0.0842,0.1293]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (x *intervalNode) visit(iv *Interval, nv nodeVisitor) bool {\r\n\tif x == nil {\r\n\t\treturn true\r\n\t}\r\n\tv := iv.Compare(&x.iv.Ivl)\r\n\tswitch {\r\n\tcase v < 0:\r\n\t\tif !x.left.visit(iv, nv) {\r\n\t\t\treturn false\r\n\t\t}\r\n\tcase v > 0:\r\n\t\tmaxiv := Interval{x.iv.Ivl.Begin, x.max}\r\n\t\tif maxiv.Compare(iv) == 0 {\r\n\t\t\tif !x.left.visit(iv, nv) || !x.right.visit(iv, nv) {\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\t}\r\n\tdefault:\r\n\t\tif !x.left.visit(iv, nv) || !nv(x) || !x.right.visit(iv, nv) {\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":257,"reference":"\/\/ visit will call a node visitor on each node that overlaps the given interval","result":"Detect if the interval node is a leaf.","score":[0.0819,0.1399]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) Delete(ivl Interval) bool {\r\n\tz := ivt.find(ivl)\r\n\tif z == nil {\r\n\t\treturn false\r\n\t}\r\n\ty := z\r\n\tif z.left != nil && z.right != nil {\r\n\t\ty = z.successor()\r\n\t}\r\n\tx := y.left\r\n\tif x == nil {\r\n\t\tx = y.right\r\n\t}\r\n\tif x != nil {\r\n\t\tx.parent = y.parent\r\n\t}\r\n\tif y.parent == nil {\r\n\t\tivt.root = x\r\n\t} else {\r\n\t\tif y == y.parent.left {\r\n\t\t\ty.parent.left = x\r\n\t\t} else {\r\n\t\t\ty.parent.right = x\r\n\t\t}\r\n\t\ty.parent.updateMax()\r\n\t}\r\n\tif y != z {\r\n\t\tz.iv = y.iv\r\n\t\tz.updateMax()\r\n\t}\r\n\tif y.color() == black && x != nil {\r\n\t\tivt.deleteFixup(x)\r\n\t}\r\n\tivt.count--\r\n\treturn true\r\n}","code-length":313,"reference":"\/\/ Delete removes the node with the given interval from the tree, returning\n\/\/ true if a node is in fact removed.","result":"Delete an interval from the tree.","score":[0.0297,0.1838]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) Insert(ivl Interval, val interface{}) {\r\n\tvar y *intervalNode\r\n\tz := &intervalNode{iv: IntervalValue{ivl, val}, max: ivl.End, c: red}\r\n\tx := ivt.root\r\n\tfor x != nil {\r\n\t\ty = x\r\n\t\tif z.iv.Ivl.Begin.Compare(x.iv.Ivl.Begin) < 0 {\r\n\t\t\tx = x.left\r\n\t\t} else {\r\n\t\t\tx = x.right\r\n\t\t}\r\n\t}\r\n\tz.parent = y\r\n\tif y == nil {\r\n\t\tivt.root = z\r\n\t} else {\r\n\t\tif z.iv.Ivl.Begin.Compare(y.iv.Ivl.Begin) < 0 {\r\n\t\t\ty.left = z\r\n\t\t} else {\r\n\t\t\ty.right = z\r\n\t\t}\r\n\t\ty.updateMax()\r\n\t}\r\n\tz.c = red\r\n\tivt.insertFixup(z)\r\n\tivt.count++\r\n}","code-length":286,"reference":"\/\/ Insert adds a node with the given interval into the tree.","result":"Insert an item into the IntervalTree.","score":[0.1112,0.2242]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) rotateLeft(x *intervalNode) {\r\n\ty := x.right\r\n\tx.right = y.left\r\n\tif y.left != nil {\r\n\t\ty.left.parent = x\r\n\t}\r\n\tx.updateMax()\r\n\tivt.replaceParent(x, y)\r\n\ty.left = x\r\n\ty.updateMax()\r\n}","code-length":109,"reference":"\/\/ rotateLeft moves x so it is left of its right child","result":"Rotate left.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) replaceParent(x *intervalNode, y *intervalNode) {\r\n\ty.parent = x.parent\r\n\tif x.parent == nil {\r\n\t\tivt.root = y\r\n\t} else {\r\n\t\tif x == x.parent.left {\r\n\t\t\tx.parent.left = y\r\n\t\t} else {\r\n\t\t\tx.parent.right = y\r\n\t\t}\r\n\t\tx.parent.updateMax()\r\n\t}\r\n\tx.parent = y\r\n}","code-length":140,"reference":"\/\/ replaceParent replaces x's parent with y","result":"Replace the parent of an interval node.","score":[0.1615,0.1429]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) MaxHeight() int {\r\n\treturn int((2 * math.Log2(float64(ivt.Len()+1))) + 0.5)\r\n}","code-length":54,"reference":"\/\/ MaxHeight is the expected maximum tree height given the number of nodes","result":"Generate the generated code.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) Visit(ivl Interval, ivv IntervalVisitor) {\r\n\tivt.root.visit(&ivl, func(n *intervalNode) bool { return ivv(&n.iv) })\r\n}","code-length":66,"reference":"\/\/ Visit calls a visitor function on every tree node intersecting the given interval.\n\/\/ It will visit each interval [x, y) in ascending order sorted on x.","result":"Create the interval tree.","score":[0.0009,0.0391]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) find(ivl Interval) (ret *intervalNode) {\r\n\tf := func(n *intervalNode) bool {\r\n\t\tif n.iv.Ivl != ivl {\r\n\t\t\treturn true\r\n\t\t}\r\n\t\tret = n\r\n\t\treturn false\r\n\t}\r\n\tivt.root.visit(&ivl, f)\r\n\treturn ret\r\n}","code-length":111,"reference":"\/\/ find the exact node for a given interval","result":"Find the node in the IntervalTree.","score":[0.1392,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) Find(ivl Interval) (ret *IntervalValue) {\r\n\tn := ivt.find(ivl)\r\n\tif n == nil {\r\n\t\treturn nil\r\n\t}\r\n\treturn &n.iv\r\n}","code-length":72,"reference":"\/\/ Find gets the IntervalValue for the node matching the given interval","result":"Find the interval value in the tree.","score":[0.1118,0.1739]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) Intersects(iv Interval) bool {\r\n\tx := ivt.root\r\n\tfor x != nil && iv.Compare(&x.iv.Ivl) != 0 {\r\n\t\tif x.left != nil && x.left.max.Compare(iv.Begin) > 0 {\r\n\t\t\tx = x.left\r\n\t\t} else {\r\n\t\t\tx = x.right\r\n\t\t}\r\n\t}\r\n\treturn x != nil\r\n}","code-length":128,"reference":"\/\/ Intersects returns true if there is some tree node intersecting the given interval.","result":"Check if an interval.","score":[0.0312,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) Contains(ivl Interval) bool {\r\n\tvar maxEnd, minBegin Comparable\r\n\tisContiguous := true\r\n\tivt.Visit(ivl, func(n *IntervalValue) bool {\r\n\t\tif minBegin == nil {\r\n\t\t\tminBegin = n.Ivl.Begin\r\n\t\t\tmaxEnd = n.Ivl.End\r\n\t\t\treturn true\r\n\t\t}\r\n\t\tif maxEnd.Compare(n.Ivl.Begin) < 0 {\r\n\t\t\tisContiguous = false\r\n\t\t\treturn false\r\n\t\t}\r\n\t\tif n.Ivl.End.Compare(maxEnd) > 0 {\r\n\t\t\tmaxEnd = n.Ivl.End\r\n\t\t}\r\n\t\treturn true\r\n\t})\r\n\treturn isContiguous && minBegin != nil && maxEnd.Compare(ivl.End) >= 0 && minBegin.Compare(ivl.Begin) <= 0\r\n}","code-length":239,"reference":"\/\/ Contains returns true if the interval tree's keys cover the entire given interval.","result":"Test if the interval tree contains a given interval.","score":[0.1758,0.3158]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) Stab(iv Interval) (ivs []*IntervalValue) {\r\n\tif ivt.count == 0 {\r\n\t\treturn nil\r\n\t}\r\n\tf := func(n *IntervalValue) bool { ivs = append(ivs, n); return true }\r\n\tivt.Visit(iv, f)\r\n\treturn ivs\r\n}","code-length":101,"reference":"\/\/ Stab returns a slice with all elements in the tree intersecting the interval.","result":"Generate the stab code.","score":[0.0262,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) Union(inIvt IntervalTree, ivl Interval) {\r\n\tf := func(n *IntervalValue) bool {\r\n\t\tivt.Insert(n.Ivl, n.Val)\r\n\t\treturn true\r\n\t}\r\n\tinIvt.Visit(ivl, f)\r\n}","code-length":89,"reference":"\/\/ Union merges a given interval tree into the receiver.","result":"Create the union of two intervals.","score":[0.0991,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewExactReadCloser(rc io.ReadCloser, totalBytes int64) io.ReadCloser {\r\n\treturn &exactReadCloser{rc: rc, totalBytes: totalBytes}\r\n}","code-length":50,"reference":"\/\/ NewExactReadCloser returns a ReadCloser that returns errors if the underlying\n\/\/ reader does not read back exactly the requested number of bytes.","result":"Create a new file.","score":[0.0028,0.0237]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewElection(s *Session, pfx string) *Election {\r\n\treturn &Election{session: s, keyPrefix: pfx + \"\/\"}\r\n}","code-length":43,"reference":"\/\/ NewElection returns a new election on a given key prefix.","result":"Create a new election.","score":[0.0785,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ResumeElection(s *Session, pfx string, leaderKey string, leaderRev int64) *Election {\r\n\treturn &Election{\r\n\t\tkeyPrefix:     pfx,\r\n\t\tsession:       s,\r\n\t\tleaderKey:     leaderKey,\r\n\t\tleaderRev:     leaderRev,\r\n\t\tleaderSession: s,\r\n\t}\r\n}","code-length":97,"reference":"\/\/ ResumeElection initializes an election with a known leader.","result":"Resume the election.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Election) Proclaim(ctx context.Context, val string) error {\r\n\tif e.leaderSession == nil {\r\n\t\treturn ErrElectionNotLeader\r\n\t}\r\n\tclient := e.session.Client()\r\n\tcmp := v3.Compare(v3.CreateRevision(e.leaderKey), \"=\", e.leaderRev)\r\n\ttxn := client.Txn(ctx).If(cmp)\r\n\ttxn = txn.Then(v3.OpPut(e.leaderKey, val, v3.WithLease(e.leaderSession.Lease())))\r\n\ttresp, terr := txn.Commit()\r\n\tif terr != nil {\r\n\t\treturn terr\r\n\t}\r\n\tif !tresp.Succeeded {\r\n\t\te.leaderKey = \"\"\r\n\t\treturn ErrElectionNotLeader\r\n\t}\r\n\te.hdr = tresp.Header\r\n\treturn nil\r\n}","code-length":224,"reference":"\/\/ Proclaim lets the leader announce a new value without another election.","result":"Avoid the need for the function to be called.","score":[0.0873,0.0427]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Election) Resign(ctx context.Context) (err error) {\r\n\tif e.leaderSession == nil {\r\n\t\treturn nil\r\n\t}\r\n\tclient := e.session.Client()\r\n\tcmp := v3.Compare(v3.CreateRevision(e.leaderKey), \"=\", e.leaderRev)\r\n\tresp, err := client.Txn(ctx).If(cmp).Then(v3.OpDelete(e.leaderKey)).Commit()\r\n\tif err == nil {\r\n\t\te.hdr = resp.Header\r\n\t}\r\n\te.leaderKey = \"\"\r\n\te.leaderSession = nil\r\n\treturn err\r\n}","code-length":170,"reference":"\/\/ Resign lets a leader start a new election.","result":"Resign the leader session.","score":[0.1088,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Election) Leader(ctx context.Context) (*v3.GetResponse, error) {\r\n\tclient := e.session.Client()\r\n\tresp, err := client.Get(ctx, e.keyPrefix, v3.WithFirstCreate()...)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t} else if len(resp.Kvs) == 0 {\r\n\t\t\r\n\t\treturn nil, ErrElectionNoLeader\r\n\t}\r\n\treturn resp, nil\r\n}","code-length":130,"reference":"\/\/ Leader returns the leader value for the current election.","result":"Get the leader key.","score":[0.1008,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Election) Observe(ctx context.Context) <-chan v3.GetResponse {\r\n\tretc := make(chan v3.GetResponse)\r\n\tgo e.observe(ctx, retc)\r\n\treturn retc\r\n}","code-length":68,"reference":"\/\/ Observe returns a channel that reliably observes ordered leader proposals\n\/\/ as GetResponse values on every current elected leader key. It will not\n\/\/ necessarily fetch all historical leader updates, but will always post the\n\/\/ most recent leader value.\n\/\/\n\/\/ The channel closes when the context is canceled or the underlying watcher\n\/\/ is otherwise disrupted.","result":"Observe the election.","score":[0.0,0.0187]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (qa *quotaAlarmer) check(ctx context.Context, r interface{}) error {\r\n\tif qa.q.Available(r) {\r\n\t\treturn nil\r\n\t}\r\n\treq := &pb.AlarmRequest{\r\n\t\tMemberID: uint64(qa.id),\r\n\t\tAction:   pb.AlarmRequest_ACTIVATE,\r\n\t\tAlarm:    pb.AlarmType_NOSPACE,\r\n\t}\r\n\tqa.a.Alarm(ctx, req)\r\n\treturn rpctypes.ErrGRPCNoSpace\r\n}","code-length":140,"reference":"\/\/ check whether request satisfies the quota. If there is not enough space,\n\/\/ ignore request and raise the free space alarm.","result":"Check the quota.","score":[0.001,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewExecWatchCommand() cli.Command {\r\n\treturn cli.Command{\r\n\t\tName:      \"exec-watch\",\r\n\t\tUsage:     \"watch a key for changes and exec an executable\",\r\n\t\tArgsUsage: \"<key> <command> [args...]\",\r\n\t\tFlags: []cli.Flag{\r\n\t\t\tcli.IntFlag{Name: \"after-index\", Value: 0, Usage: \"watch after the given index\"},\r\n\t\t\tcli.BoolFlag{Name: \"recursive, r\", Usage: \"watch all values for key and child keys\"},\r\n\t\t},\r\n\t\tAction: func(c *cli.Context) error {\r\n\t\t\texecWatchCommandFunc(c, mustNewKeyAPI(c))\r\n\t\t\treturn nil\r\n\t\t},\r\n\t}\r\n}","code-length":202,"reference":"\/\/ NewExecWatchCommand returns the CLI command for \"exec-watch\".","result":"Watch a key for changes and exec an executable.","score":[0.1219,0.0617]}
{"code":"\/*is used to<extra_id_0>\r\nfunc execWatchCommandFunc(c *cli.Context, ki client.KeysAPI) {\r\n\targs := c.Args()\r\n\targslen := len(args)\r\n\tif argslen < 2 {\r\n\t\thandleError(c, ExitBadArgs, errors.New(\"key and command to exec required\"))\r\n\t}\r\n\tvar (\r\n\t\tkey     string\r\n\t\tcmdArgs []string\r\n\t)\r\n\tfoundSep := false\r\n\tfor i := range args {\r\n\t\tif args[i] == \"--\" && i != 0 {\r\n\t\t\tfoundSep = true\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif foundSep {\r\n\t\tkey = args[0]\r\n\t\tcmdArgs = args[2:]\r\n\t} else {\r\n\t\t\r\n\t\t\r\n\t\tkey = args[argslen-1]\r\n\t\tcmdArgs = args[:argslen-1]\r\n\t}\r\n\tindex := 0\r\n\tif c.Int(\"after-index\") != 0 {\r\n\t\tindex = c.Int(\"after-index\")\r\n\t}\r\n\trecursive := c.Bool(\"recursive\")\r\n\tsigch := make(chan os.Signal, 1)\r\n\tsignal.Notify(sigch, os.Interrupt)\r\n\tgo func() {\r\n\t\t<-sigch\r\n\t\tos.Exit(0)\r\n\t}()\r\n\tw := ki.Watcher(key, &client.WatcherOptions{AfterIndex: uint64(index), Recursive: recursive})\r\n\tfor {\r\n\t\tresp, err := w.Next(context.TODO())\r\n\t\tif err != nil {\r\n\t\t\thandleError(c, ExitServerError, err)\r\n\t\t}\r\n\t\tif resp.Node.Dir {\r\n\t\t\tfmt.Fprintf(os.Stderr, \"Ignored dir %s change\\n\", resp.Node.Key)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tcmd := exec.Command(cmdArgs[0], cmdArgs[1:]...)\r\n\t\tcmd.Env = environResponse(resp, os.Environ())\r\n\t\tcmd.Stdout = os.Stdout\r\n\t\tcmd.Stderr = os.Stderr\r\n\t\tgo func() {\r\n\t\t\terr := cmd.Start()\r\n\t\t\tif err != nil {\r\n\t\t\t\tfmt.Fprintf(os.Stderr, err.Error())\r\n\t\t\t\tos.Exit(1)\r\n\t\t\t}\r\n\t\t\tcmd.Wait()\r\n\t\t}()\r\n\t}\r\n}","code-length":610,"reference":"\/\/ execWatchCommandFunc executes the \"exec-watch\" command.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewListener(u url.URL, tlsinfo *transport.TLSInfo) (net.Listener, error) {\r\n\treturn transport.NewTimeoutListener(u.Host, u.Scheme, tlsinfo, ConnReadTimeout, ConnWriteTimeout)\r\n}","code-length":66,"reference":"\/\/ NewListener returns a listener for raft message transfer between peers.\n\/\/ It uses timeout listener to identify broken streams promptly.","result":"Create a new listener.","score":[0.0046,0.0259]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRoundTripper(tlsInfo transport.TLSInfo, dialTimeout time.Duration) (http.RoundTripper, error) {\r\n\t\r\n\t\r\n\t\r\n\treturn transport.NewTimeoutTransport(tlsInfo, dialTimeout, 0, 0)\r\n}","code-length":70,"reference":"\/\/ NewRoundTripper returns a roundTripper used to send requests\n\/\/ to rafthttp listener of remote peers.","result":"Create the round tripper.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc createPostRequest(u url.URL, path string, body io.Reader, ct string, urls types.URLs, from, cid types.ID) *http.Request {\r\n\tuu := u\r\n\tuu.Path = path\r\n\treq, err := http.NewRequest(\"POST\", uu.String(), body)\r\n\tif err != nil {\r\n\t\tplog.Panicf(\"unexpected new request error (%v)\", err)\r\n\t}\r\n\treq.Header.Set(\"Content-Type\", ct)\r\n\treq.Header.Set(\"X-Server-From\", from.String())\r\n\treq.Header.Set(\"X-Server-Version\", version.Version)\r\n\treq.Header.Set(\"X-Min-Cluster-Version\", version.MinClusterVersion)\r\n\treq.Header.Set(\"X-Etcd-Cluster-ID\", cid.String())\r\n\tsetPeerURLsHeader(req, urls)\r\n\treturn req\r\n}","code-length":231,"reference":"\/\/ createPostRequest creates a HTTP POST request that sends raft message.","result":"Create a new request.","score":[0.0555,0.182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkPostResponse(resp *http.Response, body []byte, req *http.Request, to types.ID) error {\r\n\tswitch resp.StatusCode {\r\n\tcase http.StatusPreconditionFailed:\r\n\t\tswitch strings.TrimSuffix(string(body), \"\\n\") {\r\n\t\tcase errIncompatibleVersion.Error():\r\n\t\t\tplog.Errorf(\"request sent was ignored by peer %s (server version incompatible)\", to)\r\n\t\t\treturn errIncompatibleVersion\r\n\t\tcase errClusterIDMismatch.Error():\r\n\t\t\tplog.Errorf(\"request sent was ignored (cluster ID mismatch: remote[%s]=%s, local=%s)\",\r\n\t\t\t\tto, resp.Header.Get(\"X-Etcd-Cluster-ID\"), req.Header.Get(\"X-Etcd-Cluster-ID\"))\r\n\t\t\treturn errClusterIDMismatch\r\n\t\tdefault:\r\n\t\t\treturn fmt.Errorf(\"unhandled error %q when precondition failed\", string(body))\r\n\t\t}\r\n\tcase http.StatusForbidden:\r\n\t\treturn errMemberRemoved\r\n\tcase http.StatusNoContent:\r\n\t\treturn nil\r\n\tdefault:\r\n\t\treturn fmt.Errorf(\"unexpected http status %s while posting to %q\", http.StatusText(resp.StatusCode), req.URL.String())\r\n\t}\r\n}","code-length":319,"reference":"\/\/ checkPostResponse checks the response of the HTTP POST request that sends\n\/\/ raft message.","result":"Check the response status of a request.","score":[0.0806,0.1408]}
{"code":"\/*is used to<extra_id_0>\r\nfunc serverVersion(h http.Header) *semver.Version {\r\n\tverStr := h.Get(\"X-Server-Version\")\r\n\t\r\n\tif verStr == \"\" {\r\n\t\tverStr = \"2.0.0\"\r\n\t}\r\n\treturn semver.Must(semver.NewVersion(verStr))\r\n}","code-length":90,"reference":"\/\/ serverVersion returns the server version from the given header.","result":"Determine the server version.","score":[0.1008,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkVersionCompatibility(name string, server, minCluster *semver.Version) (\r\n\tlocalServer *semver.Version,\r\n\tlocalMinCluster *semver.Version,\r\n\terr error) {\r\n\tlocalServer = semver.Must(semver.NewVersion(version.Version))\r\n\tlocalMinCluster = semver.Must(semver.NewVersion(version.MinClusterVersion))\r\n\tif compareMajorMinorVersion(server, localMinCluster) == -1 {\r\n\t\treturn localServer, localMinCluster, fmt.Errorf(\"remote version is too low: remote[%s]=%s, local=%s\", name, server, localServer)\r\n\t}\r\n\tif compareMajorMinorVersion(minCluster, localServer) == 1 {\r\n\t\treturn localServer, localMinCluster, fmt.Errorf(\"local version is too low: remote[%s]=%s, local=%s\", name, server, localServer)\r\n\t}\r\n\treturn localServer, localMinCluster, nil\r\n}","code-length":241,"reference":"\/\/ checkVersionCompatibility checks whether the given version is compatible\n\/\/ with the local version.","result":"Check the version of the cluster .","score":[0.0782,0.1504]}
{"code":"\/*is used to<extra_id_0>\r\nfunc setPeerURLsHeader(req *http.Request, urls types.URLs) {\r\n\tif urls == nil {\r\n\t\t\r\n\t\treturn\r\n\t}\r\n\tpeerURLs := make([]string, urls.Len())\r\n\tfor i := range urls {\r\n\t\tpeerURLs[i] = urls[i].String()\r\n\t}\r\n\treq.Header.Set(\"X-PeerURLs\", strings.Join(peerURLs, \",\"))\r\n}","code-length":117,"reference":"\/\/ setPeerURLsHeader reports local urls for peer discovery","result":"Set the peer URLs header.","score":[0.1319,0.1299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc addRemoteFromRequest(tr Transporter, r *http.Request) {\r\n\tif from, err := types.IDFromString(r.Header.Get(\"X-Server-From\")); err == nil {\r\n\t\tif urls := r.Header.Get(\"X-PeerURLs\"); urls != \"\" {\r\n\t\t\ttr.AddRemote(from, strings.Split(urls, \",\"))\r\n\t\t}\r\n\t}\r\n}","code-length":108,"reference":"\/\/ addRemoteFromRequest adds a remote peer according to an http request header","result":"Add remote requests from the request.","score":[0.071,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewKeysAPIWithPrefix(c Client, p string) KeysAPI {\r\n\treturn &httpKeysAPI{\r\n\t\tclient: c,\r\n\t\tprefix: p,\r\n\t}\r\n}","code-length":57,"reference":"\/\/ NewKeysAPIWithPrefix acts like NewKeysAPI, but allows the caller\n\/\/ to provide a custom base URL path. This should only be used in\n\/\/ very rare cases.","result":"Create a new KeysAPI.","score":[0.001,0.0202]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *Node) TTLDuration() time.Duration {\r\n\treturn time.Duration(n.TTL) * time.Second\r\n}","code-length":41,"reference":"\/\/ TTLDuration returns the Node's TTL as a time.Duration object","result":"Generate the code.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetPflagsFromEnv(prefix string, fs *pflag.FlagSet) error {\r\n\tvar err error\r\n\talreadySet := make(map[string]bool)\r\n\tusedEnvKey := make(map[string]bool)\r\n\tfs.VisitAll(func(f *pflag.Flag) {\r\n\t\tif f.Changed {\r\n\t\t\talreadySet[FlagToEnv(prefix, f.Name)] = true\r\n\t\t}\r\n\t\tif serr := setFlagFromEnv(fs, prefix, f.Name, usedEnvKey, alreadySet, false); serr != nil {\r\n\t\t\terr = serr\r\n\t\t}\r\n\t})\r\n\tverifyEnv(prefix, usedEnvKey, alreadySet)\r\n\treturn err\r\n}","code-length":190,"reference":"\/\/ SetPflagsFromEnv is similar to SetFlagsFromEnv. However, the accepted flagset type is pflag.FlagSet\n\/\/ and it does not do any logging.","result":"Set flags from environment variables.","score":[0,0.0258]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FlagToEnv(prefix, name string) string {\r\n\treturn prefix + \"_\" + strings.ToUpper(strings.Replace(name, \"-\", \"_\", -1))\r\n}","code-length":50,"reference":"\/\/ FlagToEnv converts flag string to upper-case environment variable key string.","result":"Set flags to environment variables.","score":[0.0861,0.1442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc excerpt(str string, pre, suf int) string {\r\n\tif pre+suf > len(str) {\r\n\t\treturn fmt.Sprintf(\"%q\", str)\r\n\t}\r\n\treturn fmt.Sprintf(\"%q...%q\", str[:pre], str[len(str)-suf:])\r\n}","code-length":86,"reference":"\/\/ excerpt replaces middle part with ellipsis and returns a double-quoted\n\/\/ string safely escaped with Go syntax.","result":"Generate the excerpt.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc passConfChange(entry raftpb.Entry) (bool, string) {\r\n\treturn entry.Type == raftpb.EntryConfChange, \"ConfigChange\"\r\n}","code-length":48,"reference":"\/\/ The 9 pass functions below takes the raftpb.Entry and return if the entry should be printed and the type of entry,\n\/\/ the type of the entry will used in the following print function","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc printInternalRaftRequest(entry raftpb.Entry) {\r\n\tvar rr etcdserverpb.InternalRaftRequest\r\n\tif err := rr.Unmarshal(entry.Data); err == nil {\r\n\t\tfmt.Printf(\"%4d\\t%10d\\tnorm\\t%s\", entry.Term, entry.Index, rr.String())\r\n\t}\r\n}","code-length":96,"reference":"\/\/ The 4 print functions below print the entry format based on there types\n\/\/ printInternalRaftRequest is used to print entry information for IRRRange, IRRPut,\n\/\/ IRRDeleteRange and IRRTxn entries","result":"Print the internal request to the console.","score":[0.0072,0.0722]}
{"code":"\/*is used to<extra_id_0>\r\nfunc listEntriesType(entrytype string, streamdecoder string, ents []raftpb.Entry) {\r\n\tentryFilters := evaluateEntrytypeFlag(entrytype)\r\n\tprinterMap := map[string]EntryPrinter{\"InternalRaftRequest\": printInternalRaftRequest,\r\n\t\t\"Request\":       printRequest,\r\n\t\t\"ConfigChange\":  printConfChange,\r\n\t\t\"UnknownNormal\": printUnknownNormal}\r\n\tvar stderr bytes.Buffer\r\n\targs := strings.Split(streamdecoder, \" \")\r\n\tcmd := exec.Command(args[0], args[1:]...)\r\n\tstdin, err := cmd.StdinPipe()\r\n\tif err != nil {\r\n\t\tlog.Panic(err)\r\n\t}\r\n\tstdout, err := cmd.StdoutPipe()\r\n\tif err != nil {\r\n\t\tlog.Panic(err)\r\n\t}\r\n\tcmd.Stderr = &stderr\r\n\tif streamdecoder != \"\" {\r\n\t\terr = cmd.Start()\r\n\t\tif err != nil {\r\n\t\t\tlog.Panic(err)\r\n\t\t}\r\n\t}\r\n\tcnt := 0\r\n\tfor _, e := range ents {\r\n\t\tpassed := false\r\n\t\tcurrtype := \"\"\r\n\t\tfor _, filter := range entryFilters {\r\n\t\t\tpassed, currtype = filter(e)\r\n\t\t\tif passed {\r\n\t\t\t\tcnt++\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif passed {\r\n\t\t\tprinter := printerMap[currtype]\r\n\t\t\tprinter(e)\r\n\t\t\tif streamdecoder == \"\" {\r\n\t\t\t\tfmt.Println()\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tio.WriteString(stdin, hex.EncodeToString(e.Data))\r\n\t\t\tio.WriteString(stdin, \"\\n\")\r\n\t\t\toutputReader := bufio.NewReader(stdout)\r\n\t\t\tdecoderoutput, currerr := outputReader.ReadString('\\n')\r\n\t\t\tif currerr != nil {\r\n\t\t\t\tfmt.Println(currerr)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tdecoder_status, decoded_data := parseDecoderOutput(decoderoutput)\r\n\t\t\tfmt.Printf(\"\\t%s\\t%s\", decoder_status, decoded_data)\r\n\t\t}\r\n\t}\r\n\tstdin.Close()\r\n\terr = cmd.Wait()\r\n\tif streamdecoder != \"\" {\r\n\t\tif err != nil {\r\n\t\t\tlog.Panic(err)\r\n\t\t}\r\n\t\tif stderr.String() != \"\" {\r\n\t\t\tos.Stderr.WriteString(\"decoder stderr: \" + stderr.String())\r\n\t\t}\r\n\t}\r\n\tfmt.Printf(\"\\nEntry types (%s) count is : %d\", entrytype, cnt)\r\n}","code-length":684,"reference":"\/\/  listEntriesType filters and prints entries based on the entry-type flag,","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newLog(storage Storage, logger Logger) *raftLog {\r\n\treturn newLogWithSize(storage, logger, noLimit)\r\n}","code-length":42,"reference":"\/\/ newLog returns log using the given storage and default options. It\n\/\/ recovers the log to the state that it just commits and applies the\n\/\/ latest snapshot.","result":"Generate the generated code.","score":[0.0006,0.0189]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newLogWithSize(storage Storage, logger Logger, maxNextEntsSize uint64) *raftLog {\r\n\tif storage == nil {\r\n\t\tlog.Panic(\"storage must not be nil\")\r\n\t}\r\n\tlog := &raftLog{\r\n\t\tstorage:         storage,\r\n\t\tlogger:          logger,\r\n\t\tmaxNextEntsSize: maxNextEntsSize,\r\n\t}\r\n\tfirstIndex, err := storage.FirstIndex()\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tlastIndex, err := storage.LastIndex()\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tlog.unstable.offset = lastIndex + 1\r\n\tlog.unstable.logger = logger\r\n\t\r\n\tlog.committed = firstIndex - 1\r\n\tlog.applied = firstIndex - 1\r\n\treturn log\r\n}","code-length":233,"reference":"\/\/ newLogWithSize returns a log using the given storage and max\n\/\/ message size.","result":"Create a new log with size.","score":[0.067,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *raftLog) findConflict(ents []pb.Entry) uint64 {\r\n\tfor _, ne := range ents {\r\n\t\tif !l.matchTerm(ne.Index, ne.Term) {\r\n\t\t\tif ne.Index <= l.lastIndex() {\r\n\t\t\t\tl.logger.Infof(\"found conflict at index %d [existing term: %d, conflicting term: %d]\",\r\n\t\t\t\t\tne.Index, l.zeroTermOnErrCompacted(l.term(ne.Index)), ne.Term)\r\n\t\t\t}\r\n\t\t\treturn ne.Index\r\n\t\t}\r\n\t}\r\n\treturn 0\r\n}","code-length":166,"reference":"\/\/ findConflict finds the index of the conflict.\n\/\/ It returns the first pair of conflicting entries between the existing\n\/\/ entries and the given entries, if there are any.\n\/\/ If there is no conflicting entries, and the existing entries contains\n\/\/ all the given entries, zero will be returned.\n\/\/ If there is no conflicting entries, but the given entries contains new\n\/\/ entries, the index of the first new entry will be returned.\n\/\/ An entry is considered to be conflicting if it has the same index but\n\/\/ a different term.\n\/\/ The first entry MUST have an index equal to the argument 'from'.\n\/\/ The index of the given entries MUST be continuously increasing.","result":"Generate the generated code.","score":[0.0,0.0047]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *raftLog) nextEnts() (ents []pb.Entry) {\r\n\toff := max(l.applied+1, l.firstIndex())\r\n\tif l.committed+1 > off {\r\n\t\tents, err := l.slice(off, l.committed+1, l.maxNextEntsSize)\r\n\t\tif err != nil {\r\n\t\t\tl.logger.Panicf(\"unexpected error when getting unapplied entries (%v)\", err)\r\n\t\t}\r\n\t\treturn ents\r\n\t}\r\n\treturn nil\r\n}","code-length":147,"reference":"\/\/ nextEnts returns all the available entries for execution.\n\/\/ If applied is smaller than the index of snapshot, it returns all committed\n\/\/ entries after the index of snapshot.","result":"Generate the code.","score":[0.0001,0.0183]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *raftLog) allEntries() []pb.Entry {\r\n\tents, err := l.entries(l.firstIndex(), noLimit)\r\n\tif err == nil {\r\n\t\treturn ents\r\n\t}\r\n\tif err == ErrCompacted {\r\n\t\treturn l.allEntries()\r\n\t}\r\n\t\r\n\tpanic(err)\r\n}","code-length":100,"reference":"\/\/ allEntries returns all entries in the log.","result":"Get all entries from the log.","score":[0.2575,0.4808]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *raftLog) slice(lo, hi, maxSize uint64) ([]pb.Entry, error) {\r\n\terr := l.mustCheckOutOfBounds(lo, hi)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif lo == hi {\r\n\t\treturn nil, nil\r\n\t}\r\n\tvar ents []pb.Entry\r\n\tif lo < l.unstable.offset {\r\n\t\tstoredEnts, err := l.storage.Entries(lo, min(hi, l.unstable.offset), maxSize)\r\n\t\tif err == ErrCompacted {\r\n\t\t\treturn nil, err\r\n\t\t} else if err == ErrUnavailable {\r\n\t\t\tl.logger.Panicf(\"entries[%d:%d) is unavailable from storage\", lo, min(hi, l.unstable.offset))\r\n\t\t} else if err != nil {\r\n\t\t\tpanic(err)\r\n\t\t}\r\n\t\t\r\n\t\tif uint64(len(storedEnts)) < min(hi, l.unstable.offset)-lo {\r\n\t\t\treturn storedEnts, nil\r\n\t\t}\r\n\t\tents = storedEnts\r\n\t}\r\n\tif hi > l.unstable.offset {\r\n\t\tunstable := l.unstable.slice(max(lo, l.unstable.offset), hi)\r\n\t\tif len(ents) > 0 {\r\n\t\t\tcombined := make([]pb.Entry, len(ents)+len(unstable))\r\n\t\t\tn := copy(combined, ents)\r\n\t\t\tcopy(combined[n:], unstable)\r\n\t\t\tents = combined\r\n\t\t} else {\r\n\t\t\tents = unstable\r\n\t\t}\r\n\t}\r\n\treturn limitSize(ents, maxSize), nil\r\n}","code-length":442,"reference":"\/\/ slice returns a slice of log entries from lo through hi-1, inclusive.","result":"Store the entries in the raft log.","score":[0.0685,0.0403]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSession(client *v3.Client, opts ...SessionOption) (*Session, error) {\r\n\tops := &sessionOptions{ttl: defaultSessionTTL, ctx: client.Ctx()}\r\n\tfor _, opt := range opts {\r\n\t\topt(ops)\r\n\t}\r\n\tid := ops.leaseID\r\n\tif id == v3.NoLease {\r\n\t\tresp, err := client.Grant(ops.ctx, int64(ops.ttl))\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tid = v3.LeaseID(resp.ID)\r\n\t}\r\n\tctx, cancel := context.WithCancel(ops.ctx)\r\n\tkeepAlive, err := client.KeepAlive(ctx, id)\r\n\tif err != nil || keepAlive == nil {\r\n\t\tcancel()\r\n\t\treturn nil, err\r\n\t}\r\n\tdonec := make(chan struct{})\r\n\ts := &Session{client: client, opts: ops, id: id, cancel: cancel, donec: donec}\r\n\t\r\n\tgo func() {\r\n\t\tdefer close(donec)\r\n\t\tfor range keepAlive {\r\n\t\t\t\r\n\t\t}\r\n\t}()\r\n\treturn s, nil\r\n}","code-length":317,"reference":"\/\/ NewSession gets the leased session for a client.","result":"Create a new session.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Session) Close() error {\r\n\ts.Orphan()\r\n\t\r\n\tctx, cancel := context.WithTimeout(s.opts.ctx, time.Duration(s.opts.ttl)*time.Second)\r\n\t_, err := s.client.Revoke(ctx, s.id)\r\n\tcancel()\r\n\treturn err\r\n}","code-length":93,"reference":"\/\/ Close orphans the session and revokes the session lease.","result":"Close the session.","score":[0.0471,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WithTTL(ttl int) SessionOption {\r\n\treturn func(so *sessionOptions) {\r\n\t\tif ttl > 0 {\r\n\t\t\tso.ttl = ttl\r\n\t\t}\r\n\t}\r\n}","code-length":61,"reference":"\/\/ WithTTL configures the session's TTL in seconds.\n\/\/ If TTL is <= 0, the default 60 seconds TTL will be used.","result":"Set the TTL.","score":[0.0007,0.0249]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WithLease(leaseID v3.LeaseID) SessionOption {\r\n\treturn func(so *sessionOptions) {\r\n\t\tso.leaseID = leaseID\r\n\t}\r\n}","code-length":54,"reference":"\/\/ WithLease specifies the existing leaseID to be used for the session.\n\/\/ This is useful in process restart scenario, for example, to reclaim\n\/\/ leadership from an election prior to restart.","result":"Generate the generated code.","score":[0.0003,0.0171]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ro *readOnly) addRequest(index uint64, m pb.Message) {\r\n\tctx := string(m.Entries[0].Data)\r\n\tif _, ok := ro.pendingReadIndex[ctx]; ok {\r\n\t\treturn\r\n\t}\r\n\tro.pendingReadIndex[ctx] = &readIndexStatus{index: index, req: m, acks: make(map[uint64]struct{})}\r\n\tro.readIndexQueue = append(ro.readIndexQueue, ctx)\r\n}","code-length":131,"reference":"\/\/ addRequest adds a read only reuqest into readonly struct.\n\/\/ `index` is the commit index of the raft state machine when it received\n\/\/ the read only request.\n\/\/ `m` is the original read only request message from the local or remote node.","result":"Add request to read only objects.","score":[0.0005,0.0785]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ro *readOnly) recvAck(m pb.Message) int {\r\n\trs, ok := ro.pendingReadIndex[string(m.Context)]\r\n\tif !ok {\r\n\t\treturn 0\r\n\t}\r\n\trs.acks[m.From] = struct{}{}\r\n\t\r\n\treturn len(rs.acks) + 1\r\n}","code-length":95,"reference":"\/\/ recvAck notifies the readonly struct that the raft state machine received\n\/\/ an acknowledgment of the heartbeat that attached with the read only request\n\/\/ context.","result":"Call recvAck in readOnly.","score":[0.001,0.0202]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ro *readOnly) advance(m pb.Message) []*readIndexStatus {\r\n\tvar (\r\n\t\ti     int\r\n\t\tfound bool\r\n\t)\r\n\tctx := string(m.Context)\r\n\trss := []*readIndexStatus{}\r\n\tfor _, okctx := range ro.readIndexQueue {\r\n\t\ti++\r\n\t\trs, ok := ro.pendingReadIndex[okctx]\r\n\t\tif !ok {\r\n\t\t\tpanic(\"cannot find corresponding read state from pending map\")\r\n\t\t}\r\n\t\trss = append(rss, rs)\r\n\t\tif okctx == ctx {\r\n\t\t\tfound = true\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif found {\r\n\t\tro.readIndexQueue = ro.readIndexQueue[i:]\r\n\t\tfor _, rs := range rss {\r\n\t\t\tdelete(ro.pendingReadIndex, string(rs.req.Entries[0].Data))\r\n\t\t}\r\n\t\treturn rss\r\n\t}\r\n\treturn nil\r\n}","code-length":267,"reference":"\/\/ advance advances the read only request queue kept by the readonly struct.\n\/\/ It dequeues the requests until it finds the read only request that has\n\/\/ the same context as the given `m`.","result":"Advance the read index queue.","score":[0.0008,0.0469]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ro *readOnly) lastPendingRequestCtx() string {\r\n\tif len(ro.readIndexQueue) == 0 {\r\n\t\treturn \"\"\r\n\t}\r\n\treturn ro.readIndexQueue[len(ro.readIndexQueue)-1]\r\n}","code-length":71,"reference":"\/\/ lastPendingRequestCtx returns the context of the last pending read only\n\/\/ request in readonly struct.","result":"Generate the last pending request context.","score":[0.0807,0.25]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) Start() {\r\n\ts.start()\r\n\ts.goAttach(func() { s.adjustTicks() })\r\n\ts.goAttach(func() { s.publish(s.Cfg.ReqTimeout()) })\r\n\ts.goAttach(s.purgeFile)\r\n\ts.goAttach(func() { monitorFileDescriptor(s.getLogger(), s.stopping) })\r\n\ts.goAttach(s.monitorVersions)\r\n\ts.goAttach(s.linearizableReadLoop)\r\n\ts.goAttach(s.monitorKVHash)\r\n}","code-length":153,"reference":"\/\/ Start performs any initialization of the Server necessary for it to\n\/\/ begin serving requests. It must be called before Do or Process.\n\/\/ Start must be non-blocking; any long-running server functionality\n\/\/ should be implemented in goroutines.","result":"Start the server.","score":[0.0,0.0282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) start() {\r\n\tlg := s.getLogger()\r\n\tif s.Cfg.SnapshotCount == 0 {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Info(\r\n\t\t\t\t\"updating snapshot-count to default\",\r\n\t\t\t\tzap.Uint64(\"given-snapshot-count\", s.Cfg.SnapshotCount),\r\n\t\t\t\tzap.Uint64(\"updated-snapshot-count\", DefaultSnapshotCount),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Infof(\"set snapshot count to default %d\", DefaultSnapshotCount)\r\n\t\t}\r\n\t\ts.Cfg.SnapshotCount = DefaultSnapshotCount\r\n\t}\r\n\tif s.Cfg.SnapshotCatchUpEntries == 0 {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Info(\r\n\t\t\t\t\"updating snapshot catch-up entries to default\",\r\n\t\t\t\tzap.Uint64(\"given-snapshot-catchup-entries\", s.Cfg.SnapshotCatchUpEntries),\r\n\t\t\t\tzap.Uint64(\"updated-snapshot-catchup-entries\", DefaultSnapshotCatchUpEntries),\r\n\t\t\t)\r\n\t\t}\r\n\t\ts.Cfg.SnapshotCatchUpEntries = DefaultSnapshotCatchUpEntries\r\n\t}\r\n\ts.w = wait.New()\r\n\ts.applyWait = wait.NewTimeList()\r\n\ts.done = make(chan struct{})\r\n\ts.stop = make(chan struct{})\r\n\ts.stopping = make(chan struct{})\r\n\ts.ctx, s.cancel = context.WithCancel(context.Background())\r\n\ts.readwaitc = make(chan struct{}, 1)\r\n\ts.readNotifier = newNotifier()\r\n\ts.leaderChanged = make(chan struct{})\r\n\tif s.ClusterVersion() != nil {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Info(\r\n\t\t\t\t\"starting etcd server\",\r\n\t\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\t\tzap.String(\"local-server-version\", version.Version),\r\n\t\t\t\tzap.String(\"cluster-id\", s.Cluster().ID().String()),\r\n\t\t\t\tzap.String(\"cluster-version\", version.Cluster(s.ClusterVersion().String())),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Infof(\"starting server... [version: %v, cluster version: %v]\", version.Version, version.Cluster(s.ClusterVersion().String()))\r\n\t\t}\r\n\t\tmembership.ClusterVersionMetrics.With(prometheus.Labels{\"cluster_version\": s.ClusterVersion().String()}).Set(1)\r\n\t} else {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Info(\r\n\t\t\t\t\"starting etcd server\",\r\n\t\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\t\tzap.String(\"local-server-version\", version.Version),\r\n\t\t\t\tzap.String(\"cluster-version\", \"to_be_decided\"),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Infof(\"starting server... [version: %v, cluster version: to_be_decided]\", version.Version)\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\tgo s.run()\r\n}","code-length":816,"reference":"\/\/ start prepares and starts server in a new goroutine. It is no longer safe to\n\/\/ modify a server's fields after it has been sent to Start.\n\/\/ This function is just used for testing.","result":"Code too long,keep in 512.","score":[0.0005,0.0152]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) Process(ctx context.Context, m raftpb.Message) error {\r\n\tif s.cluster.IsIDRemoved(types.ID(m.From)) {\r\n\t\tif lg := s.getLogger(); lg != nil {\r\n\t\t\tlg.Warn(\r\n\t\t\t\t\"rejected Raft message from removed member\",\r\n\t\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\t\tzap.String(\"removed-member-id\", types.ID(m.From).String()),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Warningf(\"reject message from removed member %s\", types.ID(m.From).String())\r\n\t\t}\r\n\t\treturn httptypes.NewHTTPError(http.StatusForbidden, \"cannot process message from removed member\")\r\n\t}\r\n\tif m.Type == raftpb.MsgApp {\r\n\t\ts.stats.RecvAppendReq(types.ID(m.From).String(), m.Size())\r\n\t}\r\n\treturn s.r.Step(ctx, m)\r\n}","code-length":273,"reference":"\/\/ Process takes a raft message and applies it to the server's raft state\n\/\/ machine, respecting any timeout of the given context.","result":"Generate the generated code.","score":[0.0028,0.0237]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) ReportSnapshot(id uint64, status raft.SnapshotStatus) {\r\n\ts.r.ReportSnapshot(id, status)\r\n}","code-length":47,"reference":"\/\/ ReportSnapshot reports snapshot sent status to the raft state machine,\n\/\/ and clears the used snapshot from the snapshot store.","result":"Generate the code.","score":[0.001,0.026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) MoveLeader(ctx context.Context, lead, transferee uint64) error {\r\n\tnow := time.Now()\r\n\tinterval := time.Duration(s.Cfg.TickMs) * time.Millisecond\r\n\tif lg := s.getLogger(); lg != nil {\r\n\t\tlg.Info(\r\n\t\t\t\"leadership transfer starting\",\r\n\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\tzap.String(\"current-leader-member-id\", types.ID(lead).String()),\r\n\t\t\tzap.String(\"transferee-member-id\", types.ID(transferee).String()),\r\n\t\t)\r\n\t} else {\r\n\t\tplog.Infof(\"%s starts leadership transfer from %s to %s\", s.ID(), types.ID(lead), types.ID(transferee))\r\n\t}\r\n\ts.r.TransferLeadership(ctx, lead, transferee)\r\n\tfor s.Lead() != transferee {\r\n\t\tselect {\r\n\t\tcase <-ctx.Done():\r\n\t\t\treturn ErrTimeoutLeaderTransfer\r\n\t\tcase <-time.After(interval):\r\n\t\t}\r\n\t}\r\n\t\r\n\tif lg := s.getLogger(); lg != nil {\r\n\t\tlg.Info(\r\n\t\t\t\"leadership transfer finished\",\r\n\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\tzap.String(\"old-leader-member-id\", types.ID(lead).String()),\r\n\t\t\tzap.String(\"new-leader-member-id\", types.ID(transferee).String()),\r\n\t\t\tzap.Duration(\"took\", time.Since(now)),\r\n\t\t)\r\n\t} else {\r\n\t\tplog.Infof(\"%s finished leadership transfer from %s to %s (took %v)\", s.ID(), types.ID(lead), types.ID(transferee), time.Since(now))\r\n\t}\r\n\treturn nil\r\n}","code-length":505,"reference":"\/\/ MoveLeader transfers the leader to the given transferee.","result":"Transfer leadership.","score":[0,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) TransferLeadership() error {\r\n\tif !s.isLeader() {\r\n\t\tif lg := s.getLogger(); lg != nil {\r\n\t\t\tlg.Info(\r\n\t\t\t\t\"skipped leadership transfer; local server is not leader\",\r\n\t\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\t\tzap.String(\"current-leader-member-id\", types.ID(s.Lead()).String()),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Printf(\"skipped leadership transfer for stopping non-leader member\")\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\tif !s.isMultiNode() {\r\n\t\tif lg := s.getLogger(); lg != nil {\r\n\t\t\tlg.Info(\r\n\t\t\t\t\"skipped leadership transfer; it's a single-node cluster\",\r\n\t\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\t\tzap.String(\"current-leader-member-id\", types.ID(s.Lead()).String()),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Printf(\"skipped leadership transfer for single member cluster\")\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\ttransferee, ok := longestConnected(s.r.transport, s.cluster.MemberIDs())\r\n\tif !ok {\r\n\t\treturn ErrUnhealthy\r\n\t}\r\n\ttm := s.Cfg.ReqTimeout()\r\n\tctx, cancel := context.WithTimeout(s.ctx, tm)\r\n\terr := s.MoveLeader(ctx, s.Lead(), uint64(transferee))\r\n\tcancel()\r\n\treturn err\r\n}","code-length":429,"reference":"\/\/ TransferLeadership transfers the leader to the chosen transferee.","result":"Transfer leadership from the leader to the member.","score":[0.3836,0.5438]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) configure(ctx context.Context, cc raftpb.ConfChange) ([]*membership.Member, error) {\r\n\tcc.ID = s.reqIDGen.Next()\r\n\tch := s.w.Register(cc.ID)\r\n\tstart := time.Now()\r\n\tif err := s.r.ProposeConfChange(ctx, cc); err != nil {\r\n\t\ts.w.Trigger(cc.ID, nil)\r\n\t\treturn nil, err\r\n\t}\r\n\tselect {\r\n\tcase x := <-ch:\r\n\t\tif x == nil {\r\n\t\t\tif lg := s.getLogger(); lg != nil {\r\n\t\t\t\tlg.Panic(\"failed to configure\")\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"configure trigger value should never be nil\")\r\n\t\t\t}\r\n\t\t}\r\n\t\tresp := x.(*confChangeResponse)\r\n\t\tif lg := s.getLogger(); lg != nil {\r\n\t\t\tlg.Info(\r\n\t\t\t\t\"applied a configuration change through raft\",\r\n\t\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\t\tzap.String(\"raft-conf-change\", cc.Type.String()),\r\n\t\t\t\tzap.String(\"raft-conf-change-node-id\", types.ID(cc.NodeID).String()),\r\n\t\t\t)\r\n\t\t}\r\n\t\treturn resp.membs, resp.err\r\n\tcase <-ctx.Done():\r\n\t\ts.w.Trigger(cc.ID, nil)\r\n\t\treturn nil, s.parseProposeCtxErr(ctx.Err(), start)\r\n\tcase <-s.stopping:\r\n\t\treturn nil, ErrStopped\r\n\t}\r\n}","code-length":434,"reference":"\/\/ configure sends a configuration change through consensus and\n\/\/ then waits for it to be applied to the server. It\n\/\/ will block until the change is performed or there is an error.","result":"Configure raft members.","score":[0,0.0162]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) sync(timeout time.Duration) {\r\n\treq := pb.Request{\r\n\t\tMethod: \"SYNC\",\r\n\t\tID:     s.reqIDGen.Next(),\r\n\t\tTime:   time.Now().UnixNano(),\r\n\t}\r\n\tdata := pbutil.MustMarshal(&req)\r\n\t\r\n\t\r\n\tctx, cancel := context.WithTimeout(s.ctx, timeout)\r\n\ts.goAttach(func() {\r\n\t\ts.r.Propose(ctx, data)\r\n\t\tcancel()\r\n\t})\r\n}","code-length":152,"reference":"\/\/ sync proposes a SYNC request and is non-blocking.\n\/\/ This makes no guarantee that the request will be proposed or performed.\n\/\/ The request will be canceled after the given timeout.","result":"Sync the etcd server.","score":[0.0003,0.0342]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) publish(timeout time.Duration) {\r\n\tb, err := json.Marshal(s.attributes)\r\n\tif err != nil {\r\n\t\tif lg := s.getLogger(); lg != nil {\r\n\t\t\tlg.Panic(\"failed to marshal JSON\", zap.Error(err))\r\n\t\t} else {\r\n\t\t\tplog.Panicf(\"json marshal error: %v\", err)\r\n\t\t}\r\n\t\treturn\r\n\t}\r\n\treq := pb.Request{\r\n\t\tMethod: \"PUT\",\r\n\t\tPath:   membership.MemberAttributesStorePath(s.id),\r\n\t\tVal:    string(b),\r\n\t}\r\n\tfor {\r\n\t\tctx, cancel := context.WithTimeout(s.ctx, timeout)\r\n\t\t_, err := s.Do(ctx, req)\r\n\t\tcancel()\r\n\t\tswitch err {\r\n\t\tcase nil:\r\n\t\t\tclose(s.readych)\r\n\t\t\tif lg := s.getLogger(); lg != nil {\r\n\t\t\t\tlg.Info(\r\n\t\t\t\t\t\"published local member to cluster through raft\",\r\n\t\t\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\t\t\tzap.String(\"local-member-attributes\", fmt.Sprintf(\"%+v\", s.attributes)),\r\n\t\t\t\t\tzap.String(\"request-path\", req.Path),\r\n\t\t\t\t\tzap.String(\"cluster-id\", s.cluster.ID().String()),\r\n\t\t\t\t\tzap.Duration(\"publish-timeout\", timeout),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Infof(\"published %+v to cluster %s\", s.attributes, s.cluster.ID())\r\n\t\t\t}\r\n\t\t\treturn\r\n\t\tcase ErrStopped:\r\n\t\t\tif lg := s.getLogger(); lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"stopped publish because server is stopped\",\r\n\t\t\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\t\t\tzap.String(\"local-member-attributes\", fmt.Sprintf(\"%+v\", s.attributes)),\r\n\t\t\t\t\tzap.Duration(\"publish-timeout\", timeout),\r\n\t\t\t\t\tzap.Error(err),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Infof(\"aborting publish because server is stopped\")\r\n\t\t\t}\r\n\t\t\treturn\r\n\t\tdefault:\r\n\t\t\tif lg := s.getLogger(); lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"failed to publish local member to cluster through raft\",\r\n\t\t\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\t\t\tzap.String(\"local-member-attributes\", fmt.Sprintf(\"%+v\", s.attributes)),\r\n\t\t\t\t\tzap.String(\"request-path\", req.Path),\r\n\t\t\t\t\tzap.Duration(\"publish-timeout\", timeout),\r\n\t\t\t\t\tzap.Error(err),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Errorf(\"publish error: %v\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":780,"reference":"\/\/ publish registers server information into the cluster. The information\n\/\/ is the JSON representation of this server's member struct, updated with the\n\/\/ static clientURLs of the server.\n\/\/ The function keeps attempting to register until it succeeds,\n\/\/ or its server is stopped.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) applyEntryNormal(e *raftpb.Entry) {\r\n\tshouldApplyV3 := false\r\n\tif e.Index > s.consistIndex.ConsistentIndex() {\r\n\t\t\r\n\t\ts.consistIndex.setConsistentIndex(e.Index)\r\n\t\tshouldApplyV3 = true\r\n\t}\r\n\t\r\n\t\r\n\tif len(e.Data) == 0 {\r\n\t\tselect {\r\n\t\tcase s.forceVersionC <- struct{}{}:\r\n\t\tdefault:\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tif s.isLeader() {\r\n\t\t\ts.lessor.Promote(s.Cfg.electionTimeout())\r\n\t\t}\r\n\t\treturn\r\n\t}\r\n\tvar raftReq pb.InternalRaftRequest\r\n\tif !pbutil.MaybeUnmarshal(&raftReq, e.Data) {\r\n\t\tvar r pb.Request\r\n\t\trp := &r\r\n\t\tpbutil.MustUnmarshal(rp, e.Data)\r\n\t\ts.w.Trigger(r.ID, s.applyV2Request((*RequestV2)(rp)))\r\n\t\treturn\r\n\t}\r\n\tif raftReq.V2 != nil {\r\n\t\treq := (*RequestV2)(raftReq.V2)\r\n\t\ts.w.Trigger(req.ID, s.applyV2Request(req))\r\n\t\treturn\r\n\t}\r\n\t\r\n\tif !shouldApplyV3 {\r\n\t\treturn\r\n\t}\r\n\tid := raftReq.ID\r\n\tif id == 0 {\r\n\t\tid = raftReq.Header.ID\r\n\t}\r\n\tvar ar *applyResult\r\n\tneedResult := s.w.IsRegistered(id)\r\n\tif needResult || !noSideEffect(&raftReq) {\r\n\t\tif !needResult && raftReq.Txn != nil {\r\n\t\t\tremoveNeedlessRangeReqs(raftReq.Txn)\r\n\t\t}\r\n\t\tar = s.applyV3.Apply(&raftReq)\r\n\t}\r\n\tif ar == nil {\r\n\t\treturn\r\n\t}\r\n\tif ar.err != ErrNoSpace || len(s.alarmStore.Get(pb.AlarmType_NOSPACE)) > 0 {\r\n\t\ts.w.Trigger(id, ar)\r\n\t\treturn\r\n\t}\r\n\tif lg := s.getLogger(); lg != nil {\r\n\t\tlg.Warn(\r\n\t\t\t\"message exceeded backend quota; raising alarm\",\r\n\t\t\tzap.Int64(\"quota-size-bytes\", s.Cfg.QuotaBackendBytes),\r\n\t\t\tzap.String(\"quota-size\", humanize.Bytes(uint64(s.Cfg.QuotaBackendBytes))),\r\n\t\t\tzap.Error(ar.err),\r\n\t\t)\r\n\t} else {\r\n\t\tplog.Errorf(\"applying raft message exceeded backend quota\")\r\n\t}\r\n\ts.goAttach(func() {\r\n\t\ta := &pb.AlarmRequest{\r\n\t\t\tMemberID: uint64(s.ID()),\r\n\t\t\tAction:   pb.AlarmRequest_ACTIVATE,\r\n\t\t\tAlarm:    pb.AlarmType_NOSPACE,\r\n\t\t}\r\n\t\ts.raftRequest(s.ctx, pb.InternalRaftRequest{Alarm: a})\r\n\t\ts.w.Trigger(id, ar)\r\n\t})\r\n}","code-length":833,"reference":"\/\/ applyEntryNormal apples an EntryNormal type raftpb request to the EtcdServer","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) applyConfChange(cc raftpb.ConfChange, confState *raftpb.ConfState) (bool, error) {\r\n\tif err := s.cluster.ValidateConfigurationChange(cc); err != nil {\r\n\t\tcc.NodeID = raft.None\r\n\t\ts.r.ApplyConfChange(cc)\r\n\t\treturn false, err\r\n\t}\r\n\tlg := s.getLogger()\r\n\t*confState = *s.r.ApplyConfChange(cc)\r\n\tswitch cc.Type {\r\n\tcase raftpb.ConfChangeAddNode:\r\n\t\tm := new(membership.Member)\r\n\t\tif err := json.Unmarshal(cc.Context, m); err != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Panic(\"failed to unmarshal member\", zap.Error(err))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"unmarshal member should never fail: %v\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t\tif cc.NodeID != uint64(m.ID) {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Panic(\r\n\t\t\t\t\t\"got different member ID\",\r\n\t\t\t\t\tzap.String(\"member-id-from-config-change-entry\", types.ID(cc.NodeID).String()),\r\n\t\t\t\t\tzap.String(\"member-id-from-message\", m.ID.String()),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"nodeID should always be equal to member ID\")\r\n\t\t\t}\r\n\t\t}\r\n\t\ts.cluster.AddMember(m)\r\n\t\tif m.ID != s.id {\r\n\t\t\ts.r.transport.AddPeer(m.ID, m.PeerURLs)\r\n\t\t}\r\n\tcase raftpb.ConfChangeRemoveNode:\r\n\t\tid := types.ID(cc.NodeID)\r\n\t\ts.cluster.RemoveMember(id)\r\n\t\tif id == s.id {\r\n\t\t\treturn true, nil\r\n\t\t}\r\n\t\ts.r.transport.RemovePeer(id)\r\n\tcase raftpb.ConfChangeUpdateNode:\r\n\t\tm := new(membership.Member)\r\n\t\tif err := json.Unmarshal(cc.Context, m); err != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Panic(\"failed to unmarshal member\", zap.Error(err))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"unmarshal member should never fail: %v\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t\tif cc.NodeID != uint64(m.ID) {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Panic(\r\n\t\t\t\t\t\"got different member ID\",\r\n\t\t\t\t\tzap.String(\"member-id-from-config-change-entry\", types.ID(cc.NodeID).String()),\r\n\t\t\t\t\tzap.String(\"member-id-from-message\", m.ID.String()),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"nodeID should always be equal to member ID\")\r\n\t\t\t}\r\n\t\t}\r\n\t\ts.cluster.UpdateRaftAttributes(m.ID, m.RaftAttributes)\r\n\t\tif m.ID != s.id {\r\n\t\t\ts.r.transport.UpdatePeer(m.ID, m.PeerURLs)\r\n\t\t}\r\n\t}\r\n\treturn false, nil\r\n}","code-length":851,"reference":"\/\/ applyConfChange applies a ConfChange to the server. It is only\n\/\/ invoked with a ConfChange that has already passed through Raft","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) monitorVersions() {\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase <-s.forceVersionC:\r\n\t\tcase <-time.After(monitorVersionInterval):\r\n\t\tcase <-s.stopping:\r\n\t\t\treturn\r\n\t\t}\r\n\t\tif s.Leader() != s.ID() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tv := decideClusterVersion(s.getLogger(), getVersions(s.getLogger(), s.cluster, s.id, s.peerRt))\r\n\t\tif v != nil {\r\n\t\t\t\r\n\t\t\tv = &semver.Version{\r\n\t\t\t\tMajor: v.Major,\r\n\t\t\t\tMinor: v.Minor,\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif s.cluster.Version() == nil {\r\n\t\t\tverStr := version.MinClusterVersion\r\n\t\t\tif v != nil {\r\n\t\t\t\tverStr = v.String()\r\n\t\t\t}\r\n\t\t\ts.goAttach(func() { s.updateClusterVersion(verStr) })\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tif v != nil && s.cluster.Version().LessThan(*v) {\r\n\t\t\ts.goAttach(func() { s.updateClusterVersion(v.String()) })\r\n\t\t}\r\n\t}\r\n}","code-length":349,"reference":"\/\/ monitorVersions checks the member's version every monitorVersionInterval.\n\/\/ It updates the cluster version if all members agrees on a higher one.\n\/\/ It prints out log if there is a member with a higher version than the\n\/\/ local version.","result":"Monitor the cluster version.","score":[0.0,0.0402]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) goAttach(f func()) {\r\n\ts.wgMu.RLock()\r\n\tdefer s.wgMu.RUnlock()\r\n\tselect {\r\n\tcase <-s.stopping:\r\n\t\tif lg := s.getLogger(); lg != nil {\r\n\t\t\tlg.Warn(\"server has stopped; skipping goAttach\")\r\n\t\t} else {\r\n\t\t\tplog.Warning(\"server has stopped (skipping goAttach)\")\r\n\t\t}\r\n\t\treturn\r\n\tdefault:\r\n\t}\r\n\t\r\n\ts.wg.Add(1)\r\n\tgo func() {\r\n\t\tdefer s.wg.Done()\r\n\t\tf()\r\n\t}()\r\n}","code-length":184,"reference":"\/\/ goAttach creates a goroutine on a given function and tracks it using\n\/\/ the etcdserver waitgroup.","result":"Attach to the etcd server.","score":[0.0218,0.0316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRoundrobinBalanced(\r\n\tlg *zap.Logger,\r\n\tscs []balancer.SubConn,\r\n\taddrToSc map[resolver.Address]balancer.SubConn,\r\n\tscToAddr map[balancer.SubConn]resolver.Address,\r\n) Picker {\r\n\treturn &rrBalanced{\r\n\t\tlg:       lg,\r\n\t\tscs:      scs,\r\n\t\taddrToSc: addrToSc,\r\n\t\tscToAddr: scToAddr,\r\n\t}\r\n}","code-length":138,"reference":"\/\/ NewRoundrobinBalanced returns a new roundrobin balanced picker.","result":"Create a new Picker.","score":[0.1662,0.3363]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rb *rrBalanced) Pick(ctx context.Context, opts balancer.PickOptions) (balancer.SubConn, func(balancer.DoneInfo), error) {\r\n\trb.mu.RLock()\r\n\tn := len(rb.scs)\r\n\trb.mu.RUnlock()\r\n\tif n == 0 {\r\n\t\treturn nil, nil, balancer.ErrNoSubConnAvailable\r\n\t}\r\n\trb.mu.Lock()\r\n\tcur := rb.next\r\n\tsc := rb.scs[cur]\r\n\tpicked := rb.scToAddr[sc].Addr\r\n\trb.next = (rb.next + 1) % len(rb.scs)\r\n\trb.mu.Unlock()\r\n\trb.lg.Debug(\r\n\t\t\"picked\",\r\n\t\tzap.String(\"address\", picked),\r\n\t\tzap.Int(\"subconn-index\", cur),\r\n\t\tzap.Int(\"subconn-size\", n),\r\n\t)\r\n\tdoneFunc := func(info balancer.DoneInfo) {\r\n\t\t\r\n\t\tfss := []zapcore.Field{\r\n\t\t\tzap.Error(info.Err),\r\n\t\t\tzap.String(\"address\", picked),\r\n\t\t\tzap.Bool(\"success\", info.Err == nil),\r\n\t\t\tzap.Bool(\"bytes-sent\", info.BytesSent),\r\n\t\t\tzap.Bool(\"bytes-received\", info.BytesReceived),\r\n\t\t}\r\n\t\tif info.Err == nil {\r\n\t\t\trb.lg.Debug(\"balancer done\", fss...)\r\n\t\t} else {\r\n\t\t\trb.lg.Warn(\"balancer failed\", fss...)\r\n\t\t}\r\n\t}\r\n\treturn sc, doneFunc, nil\r\n}","code-length":435,"reference":"\/\/ Pick is called for every client request.","result":"Pick a subconn from the pool.","score":[0.1383,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTLSListener(l net.Listener, tlsinfo *TLSInfo) (net.Listener, error) {\r\n\tcheck := func(context.Context, *tls.Conn) error { return nil }\r\n\treturn newTLSListener(l, tlsinfo, check)\r\n}","code-length":72,"reference":"\/\/ NewTLSListener handshakes TLS connections and performs optional CRL checking.","result":"Create a new listener.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *tlsListener) acceptLoop() {\r\n\tvar wg sync.WaitGroup\r\n\tvar pendingMu sync.Mutex\r\n\tpending := make(map[net.Conn]struct{})\r\n\tctx, cancel := context.WithCancel(context.Background())\r\n\tdefer func() {\r\n\t\tcancel()\r\n\t\tpendingMu.Lock()\r\n\t\tfor c := range pending {\r\n\t\t\tc.Close()\r\n\t\t}\r\n\t\tpendingMu.Unlock()\r\n\t\twg.Wait()\r\n\t\tclose(l.donec)\r\n\t}()\r\n\tfor {\r\n\t\tconn, err := l.Listener.Accept()\r\n\t\tif err != nil {\r\n\t\t\tl.err = err\r\n\t\t\treturn\r\n\t\t}\r\n\t\tpendingMu.Lock()\r\n\t\tpending[conn] = struct{}{}\r\n\t\tpendingMu.Unlock()\r\n\t\twg.Add(1)\r\n\t\tgo func() {\r\n\t\t\tdefer func() {\r\n\t\t\t\tif conn != nil {\r\n\t\t\t\t\tconn.Close()\r\n\t\t\t\t}\r\n\t\t\t\twg.Done()\r\n\t\t\t}()\r\n\t\t\ttlsConn := conn.(*tls.Conn)\r\n\t\t\therr := tlsConn.Handshake()\r\n\t\t\tpendingMu.Lock()\r\n\t\t\tdelete(pending, conn)\r\n\t\t\tpendingMu.Unlock()\r\n\t\t\tif herr != nil {\r\n\t\t\t\tl.handshakeFailure(tlsConn, herr)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tif err := l.check(ctx, tlsConn); err != nil {\r\n\t\t\t\tl.handshakeFailure(tlsConn, err)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tselect {\r\n\t\t\tcase l.connc <- tlsConn:\r\n\t\t\t\tconn = nil\r\n\t\t\tcase <-ctx.Done():\r\n\t\t\t}\r\n\t\t}()\r\n\t}\r\n}","code-length":476,"reference":"\/\/ acceptLoop launches each TLS handshake in a separate goroutine\n\/\/ to prevent a hanging TLS connection from blocking other connections.","result":"Avoid deadlock.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *ResolverGroup) SetEndpoints(endpoints []string) {\r\n\taddrs := epsToAddrs(endpoints...)\r\n\te.mu.Lock()\r\n\te.endpoints = endpoints\r\n\tfor _, r := range e.resolvers {\r\n\t\tr.cc.NewAddress(addrs)\r\n\t}\r\n\te.mu.Unlock()\r\n}","code-length":95,"reference":"\/\/ SetEndpoints updates the endpoints for ResolverGroup. All registered resolver are updated\n\/\/ immediately with the new endpoints.","result":"Set the endpoints of the resolver group.","score":[0.0564,0.1868]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *ResolverGroup) Target(endpoint string) string {\r\n\treturn Target(e.id, endpoint)\r\n}","code-length":38,"reference":"\/\/ Target constructs a endpoint target using the endpoint id of the ResolverGroup.","result":"Generate the code.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Target(id, endpoint string) string {\r\n\treturn fmt.Sprintf(\"%s:\r\n}","code-length":33,"reference":"\/\/ Target constructs a endpoint resolver target.","result":"Create the target .","score":[0,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *builder) Build(target resolver.Target, cc resolver.ClientConn, opts resolver.BuildOption) (resolver.Resolver, error) {\r\n\tif len(target.Authority) < 1 {\r\n\t\treturn nil, fmt.Errorf(\"'etcd' target scheme requires non-empty authority identifying etcd cluster being routed to\")\r\n\t}\r\n\tid := target.Authority\r\n\tes, err := b.getResolverGroup(id)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to build resolver: %v\", err)\r\n\t}\r\n\tr := &Resolver{\r\n\t\tendpointID: id,\r\n\t\tcc:         cc,\r\n\t}\r\n\tes.addResolver(r)\r\n\treturn r, nil\r\n}","code-length":194,"reference":"\/\/ Build creates or reuses an etcd resolver for the etcd cluster name identified by the authority part of the target.","result":"Generate code for the generated code.","score":[0.0224,0.0513]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *RequestV2) Handle(ctx context.Context, v2api RequestV2Handler) (Response, error) {\r\n\tif r.Method == \"GET\" && r.Quorum {\r\n\t\tr.Method = \"QGET\"\r\n\t}\r\n\tswitch r.Method {\r\n\tcase \"POST\":\r\n\t\treturn v2api.Post(ctx, r)\r\n\tcase \"PUT\":\r\n\t\treturn v2api.Put(ctx, r)\r\n\tcase \"DELETE\":\r\n\t\treturn v2api.Delete(ctx, r)\r\n\tcase \"QGET\":\r\n\t\treturn v2api.QGet(ctx, r)\r\n\tcase \"GET\":\r\n\t\treturn v2api.Get(ctx, r)\r\n\tcase \"HEAD\":\r\n\t\treturn v2api.Head(ctx, r)\r\n\t}\r\n\treturn Response{}, ErrUnknownMethod\r\n}","code-length":229,"reference":"\/\/ Handle interprets r and performs an operation on s.store according to r.Method\n\/\/ and other fields. If r.Method is \"POST\", \"PUT\", \"DELETE\", or a \"GET\" with\n\/\/ Quorum == true, r will be sent through consensus before performing its\n\/\/ respective operation. Do will block until an action is performed or there is\n\/\/ an error.","result":"Handle request v.","score":[0.0,0.0097]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewElectionCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"election [election name (defaults to 'elector')]\",\r\n\t\tShort: \"Performs election operation\",\r\n\t\tRun:   runElectionFunc,\r\n\t}\r\n\tcmd.Flags().IntVar(&totalClientConnections, \"total-client-connections\", 10, \"total number of client connections\")\r\n\treturn cmd\r\n}","code-length":121,"reference":"\/\/ NewElectionCommand returns the cobra command for \"election runner\".","result":"Create a new command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc nodeToMember(n *v2store.NodeExtern) (*Member, error) {\r\n\tm := &Member{ID: MustParseMemberIDFromKey(n.Key)}\r\n\tattrs := make(map[string][]byte)\r\n\traftAttrKey := path.Join(n.Key, raftAttributesSuffix)\r\n\tattrKey := path.Join(n.Key, attributesSuffix)\r\n\tfor _, nn := range n.Nodes {\r\n\t\tif nn.Key != raftAttrKey && nn.Key != attrKey {\r\n\t\t\treturn nil, fmt.Errorf(\"unknown key %q\", nn.Key)\r\n\t\t}\r\n\t\tattrs[nn.Key] = []byte(*nn.Value)\r\n\t}\r\n\tif data := attrs[raftAttrKey]; data != nil {\r\n\t\tif err := json.Unmarshal(data, &m.RaftAttributes); err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"unmarshal raftAttributes error: %v\", err)\r\n\t\t}\r\n\t} else {\r\n\t\treturn nil, fmt.Errorf(\"raftAttributes key doesn't exist\")\r\n\t}\r\n\tif data := attrs[attrKey]; data != nil {\r\n\t\tif err := json.Unmarshal(data, &m.Attributes); err != nil {\r\n\t\t\treturn m, fmt.Errorf(\"unmarshal attributes error: %v\", err)\r\n\t\t}\r\n\t}\r\n\treturn m, nil\r\n}","code-length":353,"reference":"\/\/ nodeToMember builds member from a key value node.\n\/\/ the child nodes of the given node MUST be sorted by key.","result":"Convert a node to a member .","score":[0.0249,0.0732]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTmpBackend(batchInterval time.Duration, batchLimit int) (*backend, string) {\r\n\tdir, err := ioutil.TempDir(os.TempDir(), \"etcd_backend_test\")\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\ttmpPath := filepath.Join(dir, \"database\")\r\n\tbcfg := DefaultBackendConfig()\r\n\tbcfg.Path, bcfg.BatchInterval, bcfg.BatchLimit = tmpPath, batchInterval, batchLimit\r\n\treturn newBackend(bcfg), tmpPath\r\n}","code-length":145,"reference":"\/\/ NewTmpBackend creates a backend implementation for testing.","result":"Create a temporary backend.","score":[0.1175,0.2467]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newRevision(lg *zap.Logger, clock clockwork.Clock, retention int64, rg RevGetter, c Compactable) *Revision {\r\n\trc := &Revision{\r\n\t\tlg:        lg,\r\n\t\tclock:     clock,\r\n\t\tretention: retention,\r\n\t\trg:        rg,\r\n\t\tc:         c,\r\n\t}\r\n\trc.ctx, rc.cancel = context.WithCancel(context.Background())\r\n\treturn rc\r\n}","code-length":126,"reference":"\/\/ newRevision creates a new instance of Revisonal compactor that purges\n\/\/ the log older than retention revisions from the current revision.","result":"Create a new revision.","score":[0.0056,0.1856]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rc *Revision) Run() {\r\n\tprev := int64(0)\r\n\tgo func() {\r\n\t\tfor {\r\n\t\t\tselect {\r\n\t\t\tcase <-rc.ctx.Done():\r\n\t\t\t\treturn\r\n\t\t\tcase <-rc.clock.After(revInterval):\r\n\t\t\t\trc.mu.Lock()\r\n\t\t\t\tp := rc.paused\r\n\t\t\t\trc.mu.Unlock()\r\n\t\t\t\tif p {\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\trev := rc.rg.Rev() - rc.retention\r\n\t\t\tif rev <= 0 || rev == prev {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tnow := time.Now()\r\n\t\t\tif rc.lg != nil {\r\n\t\t\t\trc.lg.Info(\r\n\t\t\t\t\t\"starting auto revision compaction\",\r\n\t\t\t\t\tzap.Int64(\"revision\", rev),\r\n\t\t\t\t\tzap.Int64(\"revision-compaction-retention\", rc.retention),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Noticef(\"Starting auto-compaction at revision %d (retention: %d revisions)\", rev, rc.retention)\r\n\t\t\t}\r\n\t\t\t_, err := rc.c.Compact(rc.ctx, &pb.CompactionRequest{Revision: rev})\r\n\t\t\tif err == nil || err == mvcc.ErrCompacted {\r\n\t\t\t\tprev = rev\r\n\t\t\t\tif rc.lg != nil {\r\n\t\t\t\t\trc.lg.Info(\r\n\t\t\t\t\t\t\"completed auto revision compaction\",\r\n\t\t\t\t\t\tzap.Int64(\"revision\", rev),\r\n\t\t\t\t\t\tzap.Int64(\"revision-compaction-retention\", rc.retention),\r\n\t\t\t\t\t\tzap.Duration(\"took\", time.Since(now)),\r\n\t\t\t\t\t)\r\n\t\t\t\t} else {\r\n\t\t\t\t\tplog.Noticef(\"Finished auto-compaction at revision %d\", rev)\r\n\t\t\t\t}\r\n\t\t\t} else {\r\n\t\t\t\tif rc.lg != nil {\r\n\t\t\t\t\trc.lg.Warn(\r\n\t\t\t\t\t\t\"failed auto revision compaction\",\r\n\t\t\t\t\t\tzap.Int64(\"revision\", rev),\r\n\t\t\t\t\t\tzap.Int64(\"revision-compaction-retention\", rc.retention),\r\n\t\t\t\t\t\tzap.Duration(\"retry-interval\", revInterval),\r\n\t\t\t\t\t\tzap.Error(err),\r\n\t\t\t\t\t)\r\n\t\t\t\t} else {\r\n\t\t\t\t\tplog.Noticef(\"Failed auto-compaction at revision %d (%v)\", rev, err)\r\n\t\t\t\t\tplog.Noticef(\"Retry after %v\", revInterval)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}()\r\n}","code-length":663,"reference":"\/\/ Run runs revision-based compactor.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rc *Revision) Pause() {\r\n\trc.mu.Lock()\r\n\trc.paused = true\r\n\trc.mu.Unlock()\r\n}","code-length":48,"reference":"\/\/ Pause pauses revision-based compactor.","result":"Pause the revision.","score":[0.2096,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rc *Revision) Resume() {\r\n\trc.mu.Lock()\r\n\trc.paused = false\r\n\trc.mu.Unlock()\r\n}","code-length":49,"reference":"\/\/ Resume resumes revision-based compactor.","result":"Avoid recursive call to Resume.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc voteRespMsgType(msgt pb.MessageType) pb.MessageType {\r\n\tswitch msgt {\r\n\tcase pb.MsgVote:\r\n\t\treturn pb.MsgVoteResp\r\n\tcase pb.MsgPreVote:\r\n\t\treturn pb.MsgPreVoteResp\r\n\tdefault:\r\n\t\tpanic(fmt.Sprintf(\"not a vote message: %s\", msgt))\r\n\t}\r\n}","code-length":107,"reference":"\/\/ voteResponseType maps vote and prevote message types to their corresponding responses.","result":"Generate the vote response message.","score":[0.0593,0.0442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DescribeMessage(m pb.Message, f EntryFormatter) string {\r\n\tvar buf bytes.Buffer\r\n\tfmt.Fprintf(&buf, \"%x->%x %v Term:%d Log:%d\/%d\", m.From, m.To, m.Type, m.Term, m.LogTerm, m.Index)\r\n\tif m.Reject {\r\n\t\tfmt.Fprintf(&buf, \" Rejected (Hint: %d)\", m.RejectHint)\r\n\t}\r\n\tif m.Commit != 0 {\r\n\t\tfmt.Fprintf(&buf, \" Commit:%d\", m.Commit)\r\n\t}\r\n\tif len(m.Entries) > 0 {\r\n\t\tfmt.Fprintf(&buf, \" Entries:[\")\r\n\t\tfor i, e := range m.Entries {\r\n\t\t\tif i != 0 {\r\n\t\t\t\tbuf.WriteString(\", \")\r\n\t\t\t}\r\n\t\t\tbuf.WriteString(DescribeEntry(e, f))\r\n\t\t}\r\n\t\tfmt.Fprintf(&buf, \"]\")\r\n\t}\r\n\tif !IsEmptySnap(m.Snapshot) {\r\n\t\tfmt.Fprintf(&buf, \" Snapshot:%v\", m.Snapshot)\r\n\t}\r\n\treturn buf.String()\r\n}","code-length":316,"reference":"\/\/ DescribeMessage returns a concise human-readable description of a\n\/\/ Message for debugging.","result":"Describe a message.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DescribeEntry(e pb.Entry, f EntryFormatter) string {\r\n\tvar formatted string\r\n\tif e.Type == pb.EntryNormal && f != nil {\r\n\t\tformatted = f(e.Data)\r\n\t} else {\r\n\t\tformatted = fmt.Sprintf(\"%q\", e.Data)\r\n\t}\r\n\treturn fmt.Sprintf(\"%d\/%d %s %s\", e.Term, e.Index, e.Type, formatted)\r\n}","code-length":120,"reference":"\/\/ DescribeEntry returns a concise human-readable description of an\n\/\/ Entry for debugging.","result":"Describe the entry.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DescribeEntries(ents []pb.Entry, f EntryFormatter) string {\r\n\tvar buf bytes.Buffer\r\n\tfor _, e := range ents {\r\n\t\t_, _ = buf.WriteString(DescribeEntry(e, f) + \"\\n\")\r\n\t}\r\n\treturn buf.String()\r\n}","code-length":84,"reference":"\/\/ DescribeEntries calls DescribeEntry for each Entry, adding a newline to\n\/\/ each.","result":"Describe entries.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetLogger(l grpclog.LoggerV2) {\r\n\tlgMu.Lock()\r\n\tlg = logutil.NewLogger(l)\r\n\t\r\n\tgrpclog.SetLoggerV2(lg)\r\n\tlgMu.Unlock()\r\n}","code-length":70,"reference":"\/\/ SetLogger sets client-side Logger.","result":"Set the logger.","score":[0,0.2083]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetLogger() logutil.Logger {\r\n\tlgMu.RLock()\r\n\tl := lg\r\n\tlgMu.RUnlock()\r\n\treturn l\r\n}","code-length":50,"reference":"\/\/ GetLogger returns the current logutil.Logger.","result":"Get the logger.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *unstable) maybeFirstIndex() (uint64, bool) {\r\n\tif u.snapshot != nil {\r\n\t\treturn u.snapshot.Metadata.Index + 1, true\r\n\t}\r\n\treturn 0, false\r\n}","code-length":67,"reference":"\/\/ maybeFirstIndex returns the index of the first possible entry in entries\n\/\/ if it has a snapshot.","result":"Determine if the index is first index of the unstable.","score":[0.1284,0.2972]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *unstable) maybeLastIndex() (uint64, bool) {\r\n\tif l := len(u.entries); l != 0 {\r\n\t\treturn u.offset + uint64(l) - 1, true\r\n\t}\r\n\tif u.snapshot != nil {\r\n\t\treturn u.snapshot.Metadata.Index, true\r\n\t}\r\n\treturn 0, false\r\n}","code-length":103,"reference":"\/\/ maybeLastIndex returns the last index if it has at least one\n\/\/ unstable entry or snapshot.","result":"Determine if the last index is stable.","score":[0.0857,0.2344]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *unstable) maybeTerm(i uint64) (uint64, bool) {\r\n\tif i < u.offset {\r\n\t\tif u.snapshot == nil {\r\n\t\t\treturn 0, false\r\n\t\t}\r\n\t\tif u.snapshot.Metadata.Index == i {\r\n\t\t\treturn u.snapshot.Metadata.Term, true\r\n\t\t}\r\n\t\treturn 0, false\r\n\t}\r\n\tlast, ok := u.maybeLastIndex()\r\n\tif !ok {\r\n\t\treturn 0, false\r\n\t}\r\n\tif i > last {\r\n\t\treturn 0, false\r\n\t}\r\n\treturn u.entries[i-u.offset].Term, true\r\n}","code-length":182,"reference":"\/\/ maybeTerm returns the term of the entry at index i, if there\n\/\/ is any.","result":"Check the term of the entry.","score":[0.1141,0.2646]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *unstable) shrinkEntriesArray() {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tconst lenMultiple = 2\r\n\tif len(u.entries) == 0 {\r\n\t\tu.entries = nil\r\n\t} else if len(u.entries)*lenMultiple < cap(u.entries) {\r\n\t\tnewEntries := make([]pb.Entry, len(u.entries))\r\n\t\tcopy(newEntries, u.entries)\r\n\t\tu.entries = newEntries\r\n\t}\r\n}","code-length":135,"reference":"\/\/ shrinkEntriesArray discards the underlying array used by the entries slice\n\/\/ if most of it isn't being used. This avoids holding references to a bunch of\n\/\/ potentially large entries that aren't needed anymore. Simply clearing the\n\/\/ entries wouldn't be safe because clients might still be using them.","result":"Shrink entries array.","score":[0.0,0.011]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (st *storage) SaveSnap(snap raftpb.Snapshot) error {\r\n\twalsnap := walpb.Snapshot{\r\n\t\tIndex: snap.Metadata.Index,\r\n\t\tTerm:  snap.Metadata.Term,\r\n\t}\r\n\terr := st.WAL.SaveSnapshot(walsnap)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = st.Snapshotter.SaveSnap(snap)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn st.WAL.ReleaseLockTo(snap.Metadata.Index)\r\n}","code-length":157,"reference":"\/\/ SaveSnap saves the snapshot to disk and release the locked\n\/\/ wal files since they will not be used.","result":"Save snapshot.","score":[0,0.0275]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(cfg Config) (*Client, error) {\r\n\tif len(cfg.Endpoints) == 0 {\r\n\t\treturn nil, ErrNoAvailableEndpoints\r\n\t}\r\n\treturn newClient(&cfg)\r\n}","code-length":61,"reference":"\/\/ New creates a new etcdv3 client from a given configuration.","result":"Create a new client.","score":[0.0785,0.1456]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCtxClient(ctx context.Context) *Client {\r\n\tcctx, cancel := context.WithCancel(ctx)\r\n\treturn &Client{ctx: cctx, cancel: cancel}\r\n}","code-length":56,"reference":"\/\/ NewCtxClient creates a client with a context but no underlying grpc\n\/\/ connection. This is useful for embedded cases that override the\n\/\/ service interface implementations and do not need connection management.","result":"Create a new client.","score":[0.0002,0.0332]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFromURL(url string) (*Client, error) {\r\n\treturn New(Config{Endpoints: []string{url}})\r\n}","code-length":43,"reference":"\/\/ NewFromURL creates a new etcdv3 client from a URL.","result":"Create a new client.","score":[0.1008,0.1596]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Close() error {\r\n\tc.cancel()\r\n\tc.Watcher.Close()\r\n\tc.Lease.Close()\r\n\tif c.resolverGroup != nil {\r\n\t\tc.resolverGroup.Close()\r\n\t}\r\n\tif c.conn != nil {\r\n\t\treturn toErr(c.ctx, c.conn.Close())\r\n\t}\r\n\treturn c.ctx.Err()\r\n}","code-length":115,"reference":"\/\/ Close shuts down the client's etcd connections.","result":"Close the client.","score":[0.0917,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Endpoints() []string {\r\n\t\r\n\tc.mu.RLock()\r\n\tdefer c.mu.RUnlock()\r\n\teps := make([]string, len(c.cfg.Endpoints))\r\n\tcopy(eps, c.cfg.Endpoints)\r\n\treturn eps\r\n}","code-length":83,"reference":"\/\/ Endpoints lists the registered endpoints for the client.","result":"Get the endpoints of the client.","score":[0.1969,0.3628]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) SetEndpoints(eps ...string) {\r\n\tc.mu.Lock()\r\n\tdefer c.mu.Unlock()\r\n\tc.cfg.Endpoints = eps\r\n\tc.resolverGroup.SetEndpoints(eps)\r\n}","code-length":68,"reference":"\/\/ SetEndpoints updates client's endpoints.","result":"Set the endpoints of the client.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Sync(ctx context.Context) error {\r\n\tmresp, err := c.MemberList(ctx)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tvar eps []string\r\n\tfor _, m := range mresp.Members {\r\n\t\teps = append(eps, m.ClientURLs...)\r\n\t}\r\n\tc.SetEndpoints(eps...)\r\n\treturn nil\r\n}","code-length":115,"reference":"\/\/ Sync synchronizes client's endpoints with the known endpoints from the etcd membership.","result":"Sync members.","score":[0.002,0.042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) dialSetupOpts(creds *credentials.TransportCredentials, dopts ...grpc.DialOption) (opts []grpc.DialOption, err error) {\r\n\tif c.cfg.DialKeepAliveTime > 0 {\r\n\t\tparams := keepalive.ClientParameters{\r\n\t\t\tTime:                c.cfg.DialKeepAliveTime,\r\n\t\t\tTimeout:             c.cfg.DialKeepAliveTimeout,\r\n\t\t\tPermitWithoutStream: c.cfg.PermitWithoutStream,\r\n\t\t}\r\n\t\topts = append(opts, grpc.WithKeepaliveParams(params))\r\n\t}\r\n\topts = append(opts, dopts...)\r\n\t\r\n\tf := func(dialEp string, t time.Duration) (net.Conn, error) {\r\n\t\tproto, host, _ := endpoint.ParseEndpoint(dialEp)\r\n\t\tselect {\r\n\t\tcase <-c.ctx.Done():\r\n\t\t\treturn nil, c.ctx.Err()\r\n\t\tdefault:\r\n\t\t}\r\n\t\tdialer := &net.Dialer{Timeout: t}\r\n\t\treturn dialer.DialContext(c.ctx, proto, host)\r\n\t}\r\n\topts = append(opts, grpc.WithDialer(f))\r\n\tif creds != nil {\r\n\t\topts = append(opts, grpc.WithTransportCredentials(*creds))\r\n\t} else {\r\n\t\topts = append(opts, grpc.WithInsecure())\r\n\t}\r\n\t\r\n\t\r\n\ttBetween, defaultBackoffJitterFraction))\r\n\topts = append(opts,\r\n\t\t\r\n\t\t\r\n\t\tgrpc.WithStreamInterceptor(c.streamClientInterceptor(c.lg, withMax(0), rrBackoff)),\r\n\t\tgrpc.WithUnaryInterceptor(c.unaryClientInterceptor(c.lg, withMax(defaultUnaryMaxRetries), rrBackoff)),\r\n\t)\r\n\treturn opts, nil\r\n}","code-length":461,"reference":"\/\/ dialSetupOpts gives the dial opts prior to any authentication.","result":"Create a new client.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Dial(ep string) (*grpc.ClientConn, error) {\r\n\tcreds := c.directDialCreds(ep)\r\n\t\r\n\t\r\n\t\r\n\t\r\n\treturn c.dial(fmt.Sprintf(\"passthrough:\r\n}","code-length":75,"reference":"\/\/ Dial connects to a single endpoint using the client's config.","result":"Connect to the endpoint.","score":[0.066,0.2481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) dialWithBalancer(ep string, dopts ...grpc.DialOption) (*grpc.ClientConn, error) {\r\n\t_, host, _ := endpoint.ParseEndpoint(ep)\r\n\ttarget := c.resolverGroup.Target(host)\r\n\tcreds := c.dialWithBalancerCreds(ep)\r\n\treturn c.dial(target, creds, dopts...)\r\n}","code-length":102,"reference":"\/\/ dialWithBalancer dials the client's current load balanced resolver group.  The scheme of the host\n\/\/ of the provided endpoint determines the scheme used for all endpoints of the client connection.","result":"Dial with balancer.","score":[0,0.0177]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) dial(target string, creds *credentials.TransportCredentials, dopts ...grpc.DialOption) (*grpc.ClientConn, error) {\r\n\topts, err := c.dialSetupOpts(creds, dopts...)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to configure dialer: %v\", err)\r\n\t}\r\n\tif c.Username != \"\" && c.Password != \"\" {\r\n\t\tc.tokenCred = &authTokenCredential{\r\n\t\t\ttokenMu: &sync.RWMutex{},\r\n\t\t}\r\n\t\tctx, cancel := c.ctx, func() {}\r\n\t\tif c.cfg.DialTimeout > 0 {\r\n\t\t\tctx, cancel = context.WithTimeout(ctx, c.cfg.DialTimeout)\r\n\t\t}\r\n\t\terr = c.getToken(ctx)\r\n\t\tif err != nil {\r\n\t\t\tif toErr(ctx, err) != rpctypes.ErrAuthNotEnabled {\r\n\t\t\t\tif err == ctx.Err() && ctx.Err() != c.ctx.Err() {\r\n\t\t\t\t\terr = context.DeadlineExceeded\r\n\t\t\t\t}\r\n\t\t\t\tcancel()\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\topts = append(opts, grpc.WithPerRPCCredentials(c.tokenCred))\r\n\t\t}\r\n\t\tcancel()\r\n\t}\r\n\topts = append(opts, c.cfg.DialOptions...)\r\n\tdctx := c.ctx\r\n\tif c.cfg.DialTimeout > 0 {\r\n\t\tvar cancel context.CancelFunc\r\n\t\tdctx, cancel = context.WithTimeout(c.ctx, c.cfg.DialTimeout)\r\n\t\tdefer cancel()\r\n\t}\r\n\tconn, err := grpc.DialContext(dctx, target, opts...)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn conn, nil\r\n}","code-length":480,"reference":"\/\/ dial configures and dials any grpc balancer target.","result":"Connect to the server.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WithRequireLeader(ctx context.Context) context.Context {\r\n\tmd := metadata.Pairs(rpctypes.MetadataRequireLeaderKey, rpctypes.MetadataHasLeader)\r\n\treturn metadata.NewOutgoingContext(ctx, md)\r\n}","code-length":66,"reference":"\/\/ WithRequireLeader requires client requests to only succeed\n\/\/ when the cluster has a leader.","result":"Disable the leader check.","score":[0.0204,0.036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) roundRobinQuorumBackoff(waitBetween time.Duration, jitterFraction float64) backoffFunc {\r\n\treturn func(attempt uint) time.Duration {\r\n\t\t\r\n\t\tn := uint(len(c.Endpoints()))\r\n\t\tquorum := (n\/2 + 1)\r\n\t\tif attempt%quorum == 0 {\r\n\t\t\tc.lg.Debug(\"backoff\", zap.Uint(\"attempt\", attempt), zap.Uint(\"quorum\", quorum), zap.Duration(\"waitBetween\", waitBetween), zap.Float64(\"jitterFraction\", jitterFraction))\r\n\t\t\treturn jitterUp(waitBetween, jitterFraction)\r\n\t\t}\r\n\t\tc.lg.Debug(\"backoff skipped\", zap.Uint(\"attempt\", attempt), zap.Uint(\"quorum\", quorum))\r\n\t\treturn 0\r\n\t}\r\n}","code-length":207,"reference":"\/\/ roundRobinQuorumBackoff retries against quorum between each backoff.\n\/\/ This is intended for use with a round robin load balancer.","result":"Avoid the need for the following code.","score":[0.0252,0.0267]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isHaltErr(ctx context.Context, err error) bool {\r\n\tif ctx != nil && ctx.Err() != nil {\r\n\t\treturn true\r\n\t}\r\n\tif err == nil {\r\n\t\treturn false\r\n\t}\r\n\tev, _ := status.FromError(err)\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\treturn ev.Code() != codes.Unavailable && ev.Code() != codes.Internal\r\n}","code-length":123,"reference":"\/\/ isHaltErr returns true if the given error and context indicate no forward\n\/\/ progress can be made, even after reconnecting.","result":"Check if the error is a halt error.","score":[0.0428,0.1602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLease(l clientv3.Lease, prefix string) clientv3.Lease {\r\n\treturn &leasePrefix{l, []byte(prefix)}\r\n}","code-length":47,"reference":"\/\/ NewLease wraps a Lease interface to filter for only keys with a prefix\n\/\/ and remove that prefix when fetching attached keys through TimeToLive.","result":"Create a new lease.","score":[0.0017,0.0218]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Event) IsCreate() bool {\r\n\treturn e.Type == EventTypePut && e.Kv.CreateRevision == e.Kv.ModRevision\r\n}","code-length":49,"reference":"\/\/ IsCreate returns true if the event tells that the key is newly created.","result":"Check if an event is created.","score":[0.072,0.1515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wr *WatchResponse) Err() error {\r\n\tswitch {\r\n\tcase wr.closeErr != nil:\r\n\t\treturn v3rpc.Error(wr.closeErr)\r\n\tcase wr.CompactRevision != 0:\r\n\t\treturn v3rpc.ErrCompacted\r\n\tcase wr.Canceled:\r\n\t\tif len(wr.cancelReason) != 0 {\r\n\t\t\treturn v3rpc.Error(status.Error(codes.FailedPrecondition, wr.cancelReason))\r\n\t\t}\r\n\t\treturn v3rpc.ErrFutureRev\r\n\t}\r\n\treturn nil\r\n}","code-length":156,"reference":"\/\/ Err is the error value if this WatchResponse holds an error.","result":"Return errors from the WatchResponse.","score":[0.0593,0.0885]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wr *WatchResponse) IsProgressNotify() bool {\r\n\treturn len(wr.Events) == 0 && !wr.Canceled && !wr.Created && wr.CompactRevision == 0 && wr.Header.Revision != 0\r\n}","code-length":66,"reference":"\/\/ IsProgressNotify returns true if the WatchResponse is progress notification.","result":"Detect progress notifications.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *watcher) RequestProgress(ctx context.Context) (err error) {\r\n\tctxKey := streamKeyFromCtx(ctx)\r\n\tw.mu.Lock()\r\n\tif w.streams == nil {\r\n\t\treturn fmt.Errorf(\"no stream found for context\")\r\n\t}\r\n\twgs := w.streams[ctxKey]\r\n\tif wgs == nil {\r\n\t\twgs = w.newWatcherGrpcStream(ctx)\r\n\t\tw.streams[ctxKey] = wgs\r\n\t}\r\n\tdonec := wgs.donec\r\n\treqc := wgs.reqc\r\n\tw.mu.Unlock()\r\n\tpr := &progressRequest{}\r\n\tselect {\r\n\tcase reqc <- pr:\r\n\t\treturn nil\r\n\tcase <-ctx.Done():\r\n\t\tif err == nil {\r\n\t\t\treturn ctx.Err()\r\n\t\t}\r\n\t\treturn err\r\n\tcase <-donec:\r\n\t\tif wgs.closeErr != nil {\r\n\t\t\treturn wgs.closeErr\r\n\t\t}\r\n\t\t\r\n\t\treturn w.RequestProgress(ctx)\r\n\t}\r\n}","code-length":292,"reference":"\/\/ RequestProgress requests a progress notify response be sent in all watch channels.","result":"Request progress on the server.","score":[0.0485,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *watchGrpcStream) nextResume() *watcherStream {\r\n\tfor len(w.resuming) != 0 {\r\n\t\tif w.resuming[0] != nil {\r\n\t\t\treturn w.resuming[0]\r\n\t\t}\r\n\t\tw.resuming = w.resuming[1:len(w.resuming)]\r\n\t}\r\n\treturn nil\r\n}","code-length":106,"reference":"\/\/ nextResume chooses the next resuming to register with the grpc stream. Abandoned\n\/\/ streams are marked as nil in the queue since the head must wait for its inflight registration.","result":"Resume the stream.","score":[0.0,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *watchGrpcStream) dispatchEvent(pbresp *pb.WatchResponse) bool {\r\n\tevents := make([]*Event, len(pbresp.Events))\r\n\tfor i, ev := range pbresp.Events {\r\n\t\tevents[i] = (*Event)(ev)\r\n\t}\r\n\t\r\n\twr := &WatchResponse{\r\n\t\tHeader:          *pbresp.Header,\r\n\t\tEvents:          events,\r\n\t\tCompactRevision: pbresp.CompactRevision,\r\n\t\tCreated:         pbresp.Created,\r\n\t\tCanceled:        pbresp.Canceled,\r\n\t\tcancelReason:    pbresp.CancelReason,\r\n\t}\r\n\t\r\n\t\r\n\tif wr.IsProgressNotify() && pbresp.WatchId == -1 {\r\n\t\treturn w.broadcastResponse(wr)\r\n\t}\r\n\treturn w.unicastResponse(wr, pbresp.WatchId)\r\n}","code-length":235,"reference":"\/\/ dispatchEvent sends a WatchResponse to the appropriate watcher stream","result":"Broadcast response to all watchers.","score":[0.0884,0.1053]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *watchGrpcStream) broadcastResponse(wr *WatchResponse) bool {\r\n\tfor _, ws := range w.substreams {\r\n\t\tselect {\r\n\t\tcase ws.recvc <- wr:\r\n\t\tcase <-ws.donec:\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":89,"reference":"\/\/ broadcastResponse send a watch response to all watch substreams.","result":"Broadcast the response to all substreams.","score":[0.2194,0.4646]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *watchGrpcStream) unicastResponse(wr *WatchResponse, watchId int64) bool {\r\n\tws, ok := w.substreams[watchId]\r\n\tif !ok {\r\n\t\treturn false\r\n\t}\r\n\tselect {\r\n\tcase ws.recvc <- wr:\r\n\tcase <-ws.donec:\r\n\t\treturn false\r\n\t}\r\n\treturn true\r\n}","code-length":111,"reference":"\/\/ unicastResponse sends a watch response to a specific watch substream.","result":"Unicast the response to the client.","score":[0.1187,0.1786]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *watchGrpcStream) joinSubstreams() {\r\n\tfor _, ws := range w.substreams {\r\n\t\t<-ws.donec\r\n\t}\r\n\tfor _, ws := range w.resuming {\r\n\t\tif ws != nil {\r\n\t\t\t<-ws.donec\r\n\t\t}\r\n\t}\r\n}","code-length":96,"reference":"\/\/ joinSubstreams waits for all substream goroutines to complete.","result":"Join substreams.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wr *watchRequest) toPB() *pb.WatchRequest {\r\n\treq := &pb.WatchCreateRequest{\r\n\t\tStartRevision:  wr.rev,\r\n\t\tKey:            []byte(wr.key),\r\n\t\tRangeEnd:       []byte(wr.end),\r\n\t\tProgressNotify: wr.progressNotify,\r\n\t\tFilters:        wr.filters,\r\n\t\tPrevKv:         wr.prevKV,\r\n\t\tFragment:       wr.fragment,\r\n\t}\r\n\tcr := &pb.WatchRequest_CreateRequest{CreateRequest: req}\r\n\treturn &pb.WatchRequest{RequestUnion: cr}\r\n}","code-length":170,"reference":"\/\/ toPB converts an internal watch request structure to its protobuf WatchRequest structure.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pr *progressRequest) toPB() *pb.WatchRequest {\r\n\treq := &pb.WatchProgressRequest{}\r\n\tcr := &pb.WatchRequest_ProgressRequest{ProgressRequest: req}\r\n\treturn &pb.WatchRequest{RequestUnion: cr}\r\n}","code-length":74,"reference":"\/\/ toPB converts an internal progress request structure to its protobuf WatchRequest structure.","result":"Convert progressRequest to pb.","score":[0.0337,0.0826]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (us *unsafeSet) Contains(value string) (exists bool) {\r\n\t_, exists = us.d[value]\r\n\treturn exists\r\n}","code-length":48,"reference":"\/\/ Contains returns whether the set contains the given value","result":"Check unsafeSet equality.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (us *unsafeSet) ContainsAll(values []string) bool {\r\n\tfor _, s := range values {\r\n\t\tif !us.Contains(s) {\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":73,"reference":"\/\/ ContainsAll returns whether the set contains all given values","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (us *unsafeSet) Equals(other Set) bool {\r\n\tv1 := sort.StringSlice(us.Values())\r\n\tv2 := sort.StringSlice(other.Values())\r\n\tv1.Sort()\r\n\tv2.Sort()\r\n\treturn reflect.DeepEqual(v1, v2)\r\n}","code-length":88,"reference":"\/\/ Equals returns whether the contents of two sets are identical","result":"Compare unsafeSets.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (us *unsafeSet) Values() (values []string) {\r\n\tvalues = make([]string, 0)\r\n\tfor val := range us.d {\r\n\t\tvalues = append(values, val)\r\n\t}\r\n\treturn values\r\n}","code-length":72,"reference":"\/\/ Values returns the values of the Set in an unspecified order.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (us *unsafeSet) Copy() Set {\r\n\tcp := NewUnsafeSet()\r\n\tfor val := range us.d {\r\n\t\tcp.Add(val)\r\n\t}\r\n\treturn cp\r\n}","code-length":63,"reference":"\/\/ Copy creates a new Set containing the values of the first","result":"Copy unsafeSet.","score":[0.0034,0.0455]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (us *unsafeSet) Sub(other Set) Set {\r\n\toValues := other.Values()\r\n\tresult := us.Copy().(*unsafeSet)\r\n\tfor _, val := range oValues {\r\n\t\tif _, ok := result.d[val]; !ok {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tdelete(result.d, val)\r\n\t}\r\n\treturn result\r\n}","code-length":112,"reference":"\/\/ Sub removes all elements in other from the set","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc v2MembersURL(ep url.URL) *url.URL {\r\n\tep.Path = path.Join(ep.Path, defaultV2MembersPrefix)\r\n\treturn &ep\r\n}","code-length":55,"reference":"\/\/ v2MembersURL add the necessary path to the provided endpoint\n\/\/ to route requests to the default v2 members API.","result":"Members URL.","score":[0,0.0275]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMigrateCommand() *cobra.Command {\r\n\tmc := &cobra.Command{\r\n\t\tUse:   \"migrate\",\r\n\t\tShort: \"Migrates keys in a v2 store to a mvcc store\",\r\n\t\tRun:   migrateCommandFunc,\r\n\t}\r\n\tmc.Flags().BoolVar(&migrateExcludeTTLKey, \"no-ttl\", false, \"Do not convert TTL keys\")\r\n\tmc.Flags().StringVar(&migrateDatadir, \"data-dir\", \"\", \"Path to the data directory\")\r\n\tmc.Flags().StringVar(&migrateWALdir, \"wal-dir\", \"\", \"Path to the WAL directory\")\r\n\tmc.Flags().StringVar(&migrateTransformer, \"transformer\", \"\", \"Path to the user-provided transformer program\")\r\n\treturn mc\r\n}","code-length":204,"reference":"\/\/ NewMigrateCommand returns the cobra command for \"migrate\".","result":"Create a new command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rc *raftNode) publishEntries(ents []raftpb.Entry) bool {\r\n\tfor i := range ents {\r\n\t\tswitch ents[i].Type {\r\n\t\tcase raftpb.EntryNormal:\r\n\t\t\tif len(ents[i].Data) == 0 {\r\n\t\t\t\t\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\ts := string(ents[i].Data)\r\n\t\t\tselect {\r\n\t\t\tcase rc.commitC <- &s:\r\n\t\t\tcase <-rc.stopc:\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\tcase raftpb.EntryConfChange:\r\n\t\t\tvar cc raftpb.ConfChange\r\n\t\t\tcc.Unmarshal(ents[i].Data)\r\n\t\t\trc.confState = *rc.node.ApplyConfChange(cc)\r\n\t\t\tswitch cc.Type {\r\n\t\t\tcase raftpb.ConfChangeAddNode:\r\n\t\t\t\tif len(cc.Context) > 0 {\r\n\t\t\t\t\trc.transport.AddPeer(types.ID(cc.NodeID), []string{string(cc.Context)})\r\n\t\t\t\t}\r\n\t\t\tcase raftpb.ConfChangeRemoveNode:\r\n\t\t\t\tif cc.NodeID == uint64(rc.id) {\r\n\t\t\t\t\tlog.Println(\"I've been removed from the cluster! Shutting down.\")\r\n\t\t\t\t\treturn false\r\n\t\t\t\t}\r\n\t\t\t\trc.transport.RemovePeer(types.ID(cc.NodeID))\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\trc.appliedIndex = ents[i].Index\r\n\t\t\r\n\t\tif ents[i].Index == rc.lastIndex {\r\n\t\t\tselect {\r\n\t\t\tcase rc.commitC <- nil:\r\n\t\t\tcase <-rc.stopc:\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":460,"reference":"\/\/ publishEntries writes committed log entries to commit channel and returns\n\/\/ whether all entries could be published.","result":"Publish entries to the raft node.","score":[0.0369,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rc *raftNode) openWAL(snapshot *raftpb.Snapshot) *wal.WAL {\r\n\tif !wal.Exist(rc.waldir) {\r\n\t\tif err := os.Mkdir(rc.waldir, 0750); err != nil {\r\n\t\t\tlog.Fatalf(\"raftexample: cannot create dir for wal (%v)\", err)\r\n\t\t}\r\n\t\tw, err := wal.Create(zap.NewExample(), rc.waldir, nil)\r\n\t\tif err != nil {\r\n\t\t\tlog.Fatalf(\"raftexample: create wal error (%v)\", err)\r\n\t\t}\r\n\t\tw.Close()\r\n\t}\r\n\twalsnap := walpb.Snapshot{}\r\n\tif snapshot != nil {\r\n\t\twalsnap.Index, walsnap.Term = snapshot.Metadata.Index, snapshot.Metadata.Term\r\n\t}\r\n\tlog.Printf(\"loading WAL at term %d and index %d\", walsnap.Term, walsnap.Index)\r\n\tw, err := wal.Open(zap.NewExample(), rc.waldir, walsnap)\r\n\tif err != nil {\r\n\t\tlog.Fatalf(\"raftexample: error loading wal (%v)\", err)\r\n\t}\r\n\treturn w\r\n}","code-length":326,"reference":"\/\/ openWAL returns a WAL ready for reading.","result":"Create a new WAL.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rc *raftNode) replayWAL() *wal.WAL {\r\n\tlog.Printf(\"replaying WAL of member %d\", rc.id)\r\n\tsnapshot := rc.loadSnapshot()\r\n\tw := rc.openWAL(snapshot)\r\n\t_, st, ents, err := w.ReadAll()\r\n\tif err != nil {\r\n\t\tlog.Fatalf(\"raftexample: failed to read WAL (%v)\", err)\r\n\t}\r\n\trc.raftStorage = raft.NewMemoryStorage()\r\n\tif snapshot != nil {\r\n\t\trc.raftStorage.ApplySnapshot(*snapshot)\r\n\t}\r\n\trc.raftStorage.SetHardState(st)\r\n\t\r\n\trc.raftStorage.Append(ents)\r\n\t\r\n\tif len(ents) > 0 {\r\n\t\trc.lastIndex = ents[len(ents)-1].Index\r\n\t} else {\r\n\t\trc.commitC <- nil\r\n\t}\r\n\treturn w\r\n}","code-length":251,"reference":"\/\/ replayWAL replays WAL entries into the raft instance.","result":"Replay member.","score":[0,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rc *raftNode) stop() {\r\n\trc.stopHTTP()\r\n\tclose(rc.commitC)\r\n\tclose(rc.errorC)\r\n\trc.node.Stop()\r\n}","code-length":59,"reference":"\/\/ stop closes http, closes all channels, and stops raft.","result":"Stop the raft node.","score":[0,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewWatchCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"watch [options] [key or prefix] [range_end] [--] [exec-command arg1 arg2 ...]\",\r\n\t\tShort: \"Watches events stream on keys or prefixes\",\r\n\t\tRun:   watchCommandFunc,\r\n\t}\r\n\tcmd.Flags().BoolVarP(&watchInteractive, \"interactive\", \"i\", false, \"Interactive mode\")\r\n\tcmd.Flags().BoolVar(&watchPrefix, \"prefix\", false, \"Watch on a prefix if prefix is set\")\r\n\tcmd.Flags().Int64Var(&watchRev, \"rev\", 0, \"Revision to start watching\")\r\n\tcmd.Flags().BoolVar(&watchPrevKey, \"prev-kv\", false, \"get the previous key-value pair before the event happens\")\r\n\treturn cmd\r\n}","code-length":225,"reference":"\/\/ NewWatchCommand returns the cobra command for \"watch\".","result":"Create a command to watch events stream on a.","score":[0.1219,0.0617]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MemoryStorage) InitialState() (pb.HardState, pb.ConfState, error) {\r\n\treturn ms.hardState, ms.snapshot.Metadata.ConfState, nil\r\n}","code-length":55,"reference":"\/\/ InitialState implements the Storage interface.","result":"Store the state in memory.","score":[0.1967,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MemoryStorage) SetHardState(st pb.HardState) error {\r\n\tms.Lock()\r\n\tdefer ms.Unlock()\r\n\tms.hardState = st\r\n\treturn nil\r\n}","code-length":60,"reference":"\/\/ SetHardState saves the current HardState.","result":"Store the generated code.","score":[0.1938,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MemoryStorage) Entries(lo, hi, maxSize uint64) ([]pb.Entry, error) {\r\n\tms.Lock()\r\n\tdefer ms.Unlock()\r\n\toffset := ms.ents[0].Index\r\n\tif lo <= offset {\r\n\t\treturn nil, ErrCompacted\r\n\t}\r\n\tif hi > ms.lastIndex()+1 {\r\n\t\traftLogger.Panicf(\"entries' hi(%d) is out of bound lastindex(%d)\", hi, ms.lastIndex())\r\n\t}\r\n\t\r\n\tif len(ms.ents) == 1 {\r\n\t\treturn nil, ErrUnavailable\r\n\t}\r\n\tents := ms.ents[lo-offset : hi-offset]\r\n\treturn limitSize(ents, maxSize), nil\r\n}","code-length":196,"reference":"\/\/ Entries implements the Storage interface.","result":"Fetch the entries from the storage.","score":[0.193,0.1667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MemoryStorage) Term(i uint64) (uint64, error) {\r\n\tms.Lock()\r\n\tdefer ms.Unlock()\r\n\toffset := ms.ents[0].Index\r\n\tif i < offset {\r\n\t\treturn 0, ErrCompacted\r\n\t}\r\n\tif int(i-offset) >= len(ms.ents) {\r\n\t\treturn 0, ErrUnavailable\r\n\t}\r\n\treturn ms.ents[i-offset].Term, nil\r\n}","code-length":127,"reference":"\/\/ Term implements the Storage interface.","result":"Store the term in the storage.","score":[0.193,0.1667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MemoryStorage) LastIndex() (uint64, error) {\r\n\tms.Lock()\r\n\tdefer ms.Unlock()\r\n\treturn ms.lastIndex(), nil\r\n}","code-length":53,"reference":"\/\/ LastIndex implements the Storage interface.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MemoryStorage) FirstIndex() (uint64, error) {\r\n\tms.Lock()\r\n\tdefer ms.Unlock()\r\n\treturn ms.firstIndex(), nil\r\n}","code-length":54,"reference":"\/\/ FirstIndex implements the Storage interface.","result":"Generate the generated code.","score":[0.1938,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MemoryStorage) Snapshot() (pb.Snapshot, error) {\r\n\tms.Lock()\r\n\tdefer ms.Unlock()\r\n\treturn ms.snapshot, nil\r\n}","code-length":53,"reference":"\/\/ Snapshot implements the Storage interface.","result":"Generate the generated code.","score":[0.1938,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MemoryStorage) ApplySnapshot(snap pb.Snapshot) error {\r\n\tms.Lock()\r\n\tdefer ms.Unlock()\r\n\t\r\n\tmsIndex := ms.snapshot.Metadata.Index\r\n\tsnapIndex := snap.Metadata.Index\r\n\tif msIndex >= snapIndex {\r\n\t\treturn ErrSnapOutOfDate\r\n\t}\r\n\tms.snapshot = snap\r\n\tms.ents = []pb.Entry{{Term: snap.Metadata.Term, Index: snap.Metadata.Index}}\r\n\treturn nil\r\n}","code-length":135,"reference":"\/\/ ApplySnapshot overwrites the contents of this Storage object with\n\/\/ those of the given snapshot.","result":"Apply snapshot to the storage.","score":[0.0266,0.0336]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MemoryStorage) Compact(compactIndex uint64) error {\r\n\tms.Lock()\r\n\tdefer ms.Unlock()\r\n\toffset := ms.ents[0].Index\r\n\tif compactIndex <= offset {\r\n\t\treturn ErrCompacted\r\n\t}\r\n\tif compactIndex > ms.lastIndex() {\r\n\t\traftLogger.Panicf(\"compact %d is out of bound lastindex(%d)\", compactIndex, ms.lastIndex())\r\n\t}\r\n\ti := compactIndex - offset\r\n\tents := make([]pb.Entry, 1, 1+uint64(len(ms.ents))-i)\r\n\tents[0].Index = ms.ents[i].Index\r\n\tents[0].Term = ms.ents[i].Term\r\n\tents = append(ents, ms.ents[i+1:]...)\r\n\tms.ents = ents\r\n\treturn nil\r\n}","code-length":225,"reference":"\/\/ Compact discards all log entries prior to compactIndex.\n\/\/ It is the application's responsibility to not attempt to compact an index\n\/\/ greater than raftLog.applied.","result":"Avoid the need for the function to be executed.","score":[0.0219,0.0412]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *urlPicker) unreachable(u url.URL) {\r\n\tp.mu.Lock()\r\n\tdefer p.mu.Unlock()\r\n\tif u == p.urls[p.picked] {\r\n\t\tp.picked = (p.picked + 1) % len(p.urls)\r\n\t}\r\n}","code-length":90,"reference":"\/\/ unreachable notices the picker that the given url is unreachable,\n\/\/ and it should use other possible urls.","result":"Avoid circular references.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewEndpointCommand() *cobra.Command {\r\n\tec := &cobra.Command{\r\n\t\tUse:   \"endpoint <subcommand>\",\r\n\t\tShort: \"Endpoint related commands\",\r\n\t}\r\n\tec.PersistentFlags().BoolVar(&epClusterEndpoints, \"cluster\", false, \"use all endpoints from the cluster member list\")\r\n\tec.AddCommand(newEpHealthCommand())\r\n\tec.AddCommand(newEpStatusCommand())\r\n\tec.AddCommand(newEpHashKVCommand())\r\n\treturn ec\r\n}","code-length":141,"reference":"\/\/ NewEndpointCommand returns the cobra command for \"endpoint\".","result":"Create a new endpoint command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc epHealthCommandFunc(cmd *cobra.Command, args []string) {\r\n\tflags.SetPflagsFromEnv(\"ETCDCTL\", cmd.InheritedFlags())\r\n\tinitDisplayFromCmd(cmd)\r\n\tsec := secureCfgFromCmd(cmd)\r\n\tdt := dialTimeoutFromCmd(cmd)\r\n\tka := keepAliveTimeFromCmd(cmd)\r\n\tkat := keepAliveTimeoutFromCmd(cmd)\r\n\tauth := authCfgFromCmd(cmd)\r\n\tcfgs := []*v3.Config{}\r\n\tfor _, ep := range endpointsFromCluster(cmd) {\r\n\t\tcfg, err := newClientCfg([]string{ep}, dt, ka, kat, sec, auth)\r\n\t\tif err != nil {\r\n\t\t\tExitWithError(ExitBadArgs, err)\r\n\t\t}\r\n\t\tcfgs = append(cfgs, cfg)\r\n\t}\r\n\tvar wg sync.WaitGroup\r\n\thch := make(chan epHealth, len(cfgs))\r\n\tfor _, cfg := range cfgs {\r\n\t\twg.Add(1)\r\n\t\tgo func(cfg *v3.Config) {\r\n\t\t\tdefer wg.Done()\r\n\t\t\tep := cfg.Endpoints[0]\r\n\t\t\tcli, err := v3.New(*cfg)\r\n\t\t\tif err != nil {\r\n\t\t\t\thch <- epHealth{Ep: ep, Health: false, Error: err.Error()}\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tst := time.Now()\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tctx, cancel := commandCtx(cmd)\r\n\t\t\t_, err = cli.Get(ctx, \"health\")\r\n\t\t\tcancel()\r\n\t\t\teh := epHealth{Ep: ep, Health: false, Took: time.Since(st).String()}\r\n\t\t\t\r\n\t\t\tif err == nil || err == rpctypes.ErrPermissionDenied {\r\n\t\t\t\teh.Health = true\r\n\t\t\t} else {\r\n\t\t\t\teh.Error = err.Error()\r\n\t\t\t}\r\n\t\t\thch <- eh\r\n\t\t}(cfg)\r\n\t}\r\n\twg.Wait()\r\n\tclose(hch)\r\n\terrs := false\r\n\thealthList := []epHealth{}\r\n\tfor h := range hch {\r\n\t\thealthList = append(healthList, h)\r\n\t\tif h.Error != \"\" {\r\n\t\t\terrs = true\r\n\t\t}\r\n\t}\r\n\tdisplay.EndpointHealth(healthList)\r\n\tif errs {\r\n\t\tExitWithError(ExitError, fmt.Errorf(\"unhealthy cluster\"))\r\n\t}\r\n}","code-length":648,"reference":"\/\/ epHealthCommandFunc executes the \"endpoint-health\" command.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewElectCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"elect <election-name> [proposal]\",\r\n\t\tShort: \"Observes and participates in leader election\",\r\n\t\tRun:   electCommandFunc,\r\n\t}\r\n\tcmd.Flags().BoolVarP(&electListen, \"listen\", \"l\", false, \"observation mode\")\r\n\treturn cmd\r\n}","code-length":119,"reference":"\/\/ NewElectCommand returns the cobra command for \"elect\".","result":"Create a command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDefragCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"defrag\",\r\n\t\tShort: \"Defragments the storage of the etcd members with given endpoints\",\r\n\t\tRun:   defragCommandFunc,\r\n\t}\r\n\tcmd.PersistentFlags().BoolVar(&epClusterEndpoints, \"cluster\", false, \"use all endpoints from the cluster member list\")\r\n\tcmd.Flags().StringVar(&defragDataDir, \"data-dir\", \"\", \"Optional. If present, defragments a data directory not in use by etcd.\")\r\n\treturn cmd\r\n}","code-length":161,"reference":"\/\/ NewDefragCommand returns the cobra command for \"Defrag\".","result":"Create a new command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterBuilder(cfg Config) {\r\n\tbb := &builder{cfg}\r\n\tbalancer.Register(bb)\r\n\tbb.cfg.Logger.Debug(\r\n\t\t\"registered balancer\",\r\n\t\tzap.String(\"policy\", bb.cfg.Policy.String()),\r\n\t\tzap.String(\"name\", bb.cfg.Name),\r\n\t)\r\n}","code-length":99,"reference":"\/\/ RegisterBuilder creates and registers a builder. Since this function calls balancer.Register, it\n\/\/ must be invoked at initialization time.","result":"Register balancer builder.","score":[0.0014,0.0546]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *builder) Build(cc balancer.ClientConn, opt balancer.BuildOptions) balancer.Balancer {\r\n\tbb := &baseBalancer{\r\n\t\tid:     strconv.FormatInt(time.Now().UnixNano(), 36),\r\n\t\tpolicy: b.cfg.Policy,\r\n\t\tname:   b.cfg.Name,\r\n\t\tlg:     b.cfg.Logger,\r\n\t\taddrToSc: make(map[resolver.Address]balancer.SubConn),\r\n\t\tscToAddr: make(map[balancer.SubConn]resolver.Address),\r\n\t\tscToSt:   make(map[balancer.SubConn]connectivity.State),\r\n\t\tcurrentConn: nil,\r\n\t\tcsEvltr:     &connectivityStateEvaluator{},\r\n\t\t\r\n\t\tPicker: picker.NewErr(balancer.ErrNoSubConnAvailable),\r\n\t}\r\n\tif bb.lg == nil {\r\n\t\tbb.lg = zap.NewNop()\r\n\t}\r\n\t\r\n\tbb.mu.Lock()\r\n\tbb.currentConn = cc\r\n\tbb.mu.Unlock()\r\n\tbb.lg.Info(\r\n\t\t\"built balancer\",\r\n\t\tzap.String(\"balancer-id\", bb.id),\r\n\t\tzap.String(\"policy\", bb.policy.String()),\r\n\t\tzap.String(\"resolver-target\", cc.Target()),\r\n\t)\r\n\treturn bb\r\n}","code-length":358,"reference":"\/\/ Build is called initially when creating \"ccBalancerWrapper\".\n\/\/ \"grpc.Dial\" is called to this client connection.\n\/\/ Then, resolved addresses will be handled via \"HandleResolvedAddrs\".","result":"Build the balancer.","score":[0.0003,0.0219]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cse *connectivityStateEvaluator) recordTransition(oldState, newState connectivity.State) connectivity.State {\r\n\t\r\n\tfor idx, state := range []connectivity.State{oldState, newState} {\r\n\t\tupdateVal := 2*uint64(idx) - 1\r\n\t\tswitch state {\r\n\t\tcase connectivity.Ready:\r\n\t\t\tcse.numReady += updateVal\r\n\t\tcase connectivity.Connecting:\r\n\t\t\tcse.numConnecting += updateVal\r\n\t\tcase connectivity.TransientFailure:\r\n\t\t\tcse.numTransientFailure += updateVal\r\n\t\t}\r\n\t}\r\n\t\r\n\tif cse.numReady > 0 {\r\n\t\treturn connectivity.Ready\r\n\t}\r\n\tif cse.numConnecting > 0 {\r\n\t\treturn connectivity.Connecting\r\n\t}\r\n\treturn connectivity.TransientFailure\r\n}","code-length":217,"reference":"\/\/ recordTransition records state change happening in every subConn and based on\n\/\/ that it evaluates what aggregated state should be.\n\/\/ It can only transition between Ready, Connecting and TransientFailure. Other states,\n\/\/ Idle and Shutdown are transitioned into by ClientConn; in the beginning of the connection\n\/\/ before any subConn is created ClientConn is in idle state. In the end when ClientConn\n\/\/ closes it is in Shutdown state.\n\/\/\n\/\/ recordTransition should only be called synchronously from the same goroutine.","result":"Record transition .","score":[0.0,0.0133]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) doSerialize(ctx context.Context, chk func(*auth.AuthInfo) error, get func()) error {\r\n\tai, err := s.AuthInfoFromCtx(ctx)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif ai == nil {\r\n\t\t\r\n\t\tai = &auth.AuthInfo{}\r\n\t}\r\n\tif err = chk(ai); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tget()\r\n\t\r\n\t\r\n\tif ai.Revision != 0 && ai.Revision != s.authStore.Revision() {\r\n\t\treturn auth.ErrAuthOldRevision\r\n\t}\r\n\treturn nil\r\n}","code-length":183,"reference":"\/\/ doSerialize handles the auth logic, with permissions checked by \"chk\", for a serialized request \"get\". Returns a non-nil error on authentication failure.","result":"Serialize the auth info.","score":[0.0039,0.1211]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *watcher) send(wr clientv3.WatchResponse) {\r\n\tif wr.IsProgressNotify() && !w.progress {\r\n\t\treturn\r\n\t}\r\n\tif w.nextrev > wr.Header.Revision && len(wr.Events) > 0 {\r\n\t\treturn\r\n\t}\r\n\tif w.nextrev == 0 {\r\n\t\t\r\n\t\tw.nextrev = wr.Header.Revision + 1\r\n\t}\r\n\tevents := make([]*mvccpb.Event, 0, len(wr.Events))\r\n\tvar lastRev int64\r\n\tfor i := range wr.Events {\r\n\t\tev := (*mvccpb.Event)(wr.Events[i])\r\n\t\tif ev.Kv.ModRevision < w.nextrev {\r\n\t\t\tcontinue\r\n\t\t} else {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tlastRev = ev.Kv.ModRevision\r\n\t\t}\r\n\t\tfiltered := false\r\n\t\tfor _, filter := range w.filters {\r\n\t\t\tif filter(*ev) {\r\n\t\t\t\tfiltered = true\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif filtered {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif !w.prevKV {\r\n\t\t\tevCopy := *ev\r\n\t\t\tevCopy.PrevKv = nil\r\n\t\t\tev = &evCopy\r\n\t\t}\r\n\t\tevents = append(events, ev)\r\n\t}\r\n\tif lastRev >= w.nextrev {\r\n\t\tw.nextrev = lastRev + 1\r\n\t}\r\n\t\r\n\tif !wr.IsProgressNotify() && !wr.Created && len(events) == 0 && wr.CompactRevision == 0 {\r\n\t\treturn\r\n\t}\r\n\tw.lastHeader = wr.Header\r\n\tw.post(&pb.WatchResponse{\r\n\t\tHeader:          &wr.Header,\r\n\t\tCreated:         wr.Created,\r\n\t\tCompactRevision: wr.CompactRevision,\r\n\t\tCanceled:        wr.Canceled,\r\n\t\tWatchId:         w.id,\r\n\t\tEvents:          events,\r\n\t})\r\n}","code-length":546,"reference":"\/\/ send filters out repeated events by discarding revisions older\n\/\/ than the last one sent over the watch channel.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *watcher) post(wr *pb.WatchResponse) bool {\r\n\tselect {\r\n\tcase w.wps.watchCh <- wr:\r\n\tcase <-time.After(50 * time.Millisecond):\r\n\t\tw.wps.cancel()\r\n\t\treturn false\r\n\t}\r\n\treturn true\r\n}","code-length":92,"reference":"\/\/ post puts a watch response on the watcher's proxy stream channel","result":"Post the watch event.","score":[0.0514,0.1339]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ac *AccessController) OriginAllowed(origin string) bool {\r\n\tac.corsMu.RLock()\r\n\tdefer ac.corsMu.RUnlock()\r\n\tif len(ac.CORS) == 0 {\r\n\t\treturn true\r\n\t}\r\n\t_, ok := ac.CORS[\"*\"]\r\n\tif ok {\r\n\t\treturn true\r\n\t}\r\n\t_, ok = ac.CORS[origin]\r\n\treturn ok\r\n}","code-length":125,"reference":"\/\/ OriginAllowed determines whether the server will allow a given CORS origin.\n\/\/ If CORS is empty, allow all.","result":"Check if the origin is allowed.","score":[0.0263,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ac *AccessController) IsHostWhitelisted(host string) bool {\r\n\tac.hostWhitelistMu.RLock()\r\n\tdefer ac.hostWhitelistMu.RUnlock()\r\n\tif len(ac.HostWhitelist) == 0 {\r\n\t\treturn true\r\n\t}\r\n\t_, ok := ac.HostWhitelist[\"*\"]\r\n\tif ok {\r\n\t\treturn true\r\n\t}\r\n\t_, ok = ac.HostWhitelist[host]\r\n\treturn ok\r\n}","code-length":127,"reference":"\/\/ IsHostWhitelisted returns true if the host is whitelisted.\n\/\/ If whitelist is empty, allow all.","result":"Check if host is whitelisted.","score":[0.0589,0.1342]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ss *SelectiveStringValue) Valids() []string {\r\n\ts := make([]string, 0, len(ss.valids))\r\n\tfor k := range ss.valids {\r\n\t\ts = append(s, k)\r\n\t}\r\n\tsort.Strings(s)\r\n\treturn s\r\n}","code-length":87,"reference":"\/\/ Valids returns the list of valid strings.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSelectiveStringsValue(valids ...string) *SelectiveStringsValue {\r\n\tvm := make(map[string]struct{})\r\n\tfor _, v := range valids {\r\n\t\tvm[v] = struct{}{}\r\n\t}\r\n\treturn &SelectiveStringsValue{valids: vm, vs: []string{}}\r\n}","code-length":93,"reference":"\/\/ NewSelectiveStringsValue creates a new string slice flag\n\/\/ for which any one of the given strings is a valid value,\n\/\/ and any other value is an error.","result":"Create a new SelectiveStringsValue.","score":[0.0009,0.0566]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewKV(kv clientv3.KV, prefix string) clientv3.KV {\r\n\treturn &kvPrefix{kv, prefix}\r\n}","code-length":44,"reference":"\/\/ NewKV wraps a KV instance so that all requests\n\/\/ are prefixed with a given string.","result":"Create a new KV object.","score":[0.0259,0.0633]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewURLsValue(s string) *URLsValue {\r\n\tif s == \"\" {\r\n\t\treturn &URLsValue{}\r\n\t}\r\n\tv := &URLsValue{}\r\n\tif err := v.Set(s); err != nil {\r\n\t\tplog.Panicf(\"new URLsValue should never fail: %v\", err)\r\n\t}\r\n\treturn v\r\n}","code-length":101,"reference":"\/\/ NewURLsValue implements \"url.URL\" slice as flag.Value interface.\n\/\/ Given value is to be separated by comma.","result":"Create a new URLsValue.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc URLsFromFlag(fs *flag.FlagSet, urlsFlagName string) []url.URL {\r\n\treturn []url.URL(*fs.Lookup(urlsFlagName).Value.(*URLsValue))\r\n}","code-length":57,"reference":"\/\/ URLsFromFlag returns a slices from url got from the flag.","result":"Generate the generated code.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Etcd) servePeers() (err error) {\r\n\tph := etcdhttp.NewPeerHandler(e.GetLogger(), e.Server)\r\n\tvar peerTLScfg *tls.Config\r\n\tif !e.cfg.PeerTLSInfo.Empty() {\r\n\t\tif peerTLScfg, err = e.cfg.PeerTLSInfo.ServerConfig(); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tfor _, p := range e.Peers {\r\n\t\tu := p.Listener.Addr().String()\r\n\t\tgs := v3rpc.Server(e.Server, peerTLScfg)\r\n\t\tm := cmux.New(p.Listener)\r\n\t\tgo gs.Serve(m.Match(cmux.HTTP2()))\r\n\t\tsrv := &http.Server{\r\n\t\t\tHandler:     grpcHandlerFunc(gs, ph),\r\n\t\t\tReadTimeout: 5 * time.Minute,\r\n\t\t\tErrorLog:    defaultLog.New(ioutil.Discard, \"\", 0),\r\n\t\t}\r\n\t\tgo srv.Serve(m.Match(cmux.Any()))\r\n\t\tp.serve = func() error { return m.Serve() }\r\n\t\tp.close = func(ctx context.Context) error {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tif e.cfg.logger != nil {\r\n\t\t\t\te.cfg.logger.Info(\r\n\t\t\t\t\t\"stopping serving peer traffic\",\r\n\t\t\t\t\tzap.String(\"address\", u),\r\n\t\t\t\t)\r\n\t\t\t}\r\n\t\t\tstopServers(ctx, &servers{secure: peerTLScfg != nil, grpc: gs, http: srv})\r\n\t\t\tif e.cfg.logger != nil {\r\n\t\t\t\te.cfg.logger.Info(\r\n\t\t\t\t\t\"stopped serving peer traffic\",\r\n\t\t\t\t\tzap.String(\"address\", u),\r\n\t\t\t\t)\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor _, pl := range e.Peers {\r\n\t\tgo func(l *peerListener) {\r\n\t\t\tu := l.Addr().String()\r\n\t\t\tif e.cfg.logger != nil {\r\n\t\t\t\te.cfg.logger.Info(\r\n\t\t\t\t\t\"serving peer traffic\",\r\n\t\t\t\t\tzap.String(\"address\", u),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Info(\"listening for peers on \", u)\r\n\t\t\t}\r\n\t\t\te.errHandler(l.serve())\r\n\t\t}(pl)\r\n\t}\r\n\treturn nil\r\n}","code-length":642,"reference":"\/\/ configure peer handlers after rafthttp.Transport started","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewStore(lg *zap.Logger, b backend.Backend, le lease.Lessor, ig ConsistentIndexGetter) *store {\r\n\ts := &store{\r\n\t\tb:       b,\r\n\t\tig:      ig,\r\n\t\tkvindex: newTreeIndex(lg),\r\n\t\tle: le,\r\n\t\tcurrentRev:     1,\r\n\t\tcompactMainRev: -1,\r\n\t\tbytesBuf8: make([]byte, 8),\r\n\t\tfifoSched: schedule.NewFIFOScheduler(),\r\n\t\tstopc: make(chan struct{}),\r\n\t\tlg: lg,\r\n\t}\r\n\ts.ReadView = &readView{s}\r\n\ts.WriteView = &writeView{s}\r\n\tif s.le != nil {\r\n\t\ts.le.SetRangeDeleter(func() lease.TxnDelete { return s.Write() })\r\n\t}\r\n\ttx := s.b.BatchTx()\r\n\ttx.Lock()\r\n\ttx.UnsafeCreateBucket(keyBucketName)\r\n\ttx.UnsafeCreateBucket(metaBucketName)\r\n\ttx.Unlock()\r\n\ts.b.ForceCommit()\r\n\ts.mu.Lock()\r\n\tdefer s.mu.Unlock()\r\n\tif err := s.restore(); err != nil {\r\n\t\t\r\n\t\tpanic(\"failed to recover store from backend\")\r\n\t}\r\n\treturn s\r\n}","code-length":356,"reference":"\/\/ NewStore returns a new store. It is useful to create a store inside\n\/\/ mvcc pkg. It should only be used for testing externally.","result":"Create a new store.","score":[0.0035,0.1638]}
{"code":"\/*is used to<extra_id_0>\r\nfunc appendMarkTombstone(lg *zap.Logger, b []byte) []byte {\r\n\tif len(b) != revBytesLen {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Panic(\r\n\t\t\t\t\"cannot append tombstone mark to non-normal revision bytes\",\r\n\t\t\t\tzap.Int(\"expected-revision-bytes-size\", revBytesLen),\r\n\t\t\t\tzap.Int(\"given-revision-bytes-size\", len(b)),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Panicf(\"cannot append mark to non normal revision bytes\")\r\n\t\t}\r\n\t}\r\n\treturn append(b, markTombstone)\r\n}","code-length":176,"reference":"\/\/ appendMarkTombstone appends tombstone mark to normal revision bytes.","result":"Append tombstones to the revision.","score":[0.108,0.2972]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsDirWriteable(dir string) error {\r\n\tf := filepath.Join(dir, \".touch\")\r\n\tif err := ioutil.WriteFile(f, []byte(\"\"), PrivateFileMode); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn os.Remove(f)\r\n}","code-length":82,"reference":"\/\/ IsDirWriteable checks if dir is writable by writing and removing a file\n\/\/ to dir. It returns nil if dir is writable.","result":"Check if a directory is writeable.","score":[0.0149,0.0939]}
{"code":"\/*is used to<extra_id_0>\r\nfunc TouchDirAll(dir string) error {\r\n\t\r\n\t\r\n\terr := os.MkdirAll(dir, PrivateDirMode)\r\n\tif err != nil {\r\n\t\t\r\n\t\t\r\n\t\treturn err\r\n\t}\r\n\treturn IsDirWriteable(dir)\r\n}","code-length":79,"reference":"\/\/ TouchDirAll is similar to os.MkdirAll. It creates directories with 0700 permission if any directory\n\/\/ does not exists. TouchDirAll also ensures the given directory is writable.","result":"Touch a directory.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CreateDirAll(dir string) error {\r\n\terr := TouchDirAll(dir)\r\n\tif err == nil {\r\n\t\tvar ns []string\r\n\t\tns, err = ReadDir(dir)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif len(ns) != 0 {\r\n\t\t\terr = fmt.Errorf(\"expected %q to be empty, got %q\", dir, ns)\r\n\t\t}\r\n\t}\r\n\treturn err\r\n}","code-length":133,"reference":"\/\/ CreateDirAll is similar to TouchDirAll but returns error\n\/\/ if the deepest directory was not empty.","result":"Create a directory.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ZeroToEnd(f *os.File) error {\r\n\t\r\n\toff, err := f.Seek(0, io.SeekCurrent)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tlenf, lerr := f.Seek(0, io.SeekEnd)\r\n\tif lerr != nil {\r\n\t\treturn lerr\r\n\t}\r\n\tif err = f.Truncate(off); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif err = Preallocate(f, lenf, true); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t_, err = f.Seek(off, io.SeekStart)\r\n\treturn err\r\n}","code-length":186,"reference":"\/\/ ZeroToEnd zeros a file starting from SEEK_CUR to its SEEK_END. May temporarily\n\/\/ shorten the length of the file.","result":"End the file.","score":[0.002,0.1025]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (fp *filePipeline) Open() (f *fileutil.LockedFile, err error) {\r\n\tselect {\r\n\tcase f = <-fp.filec:\r\n\tcase err = <-fp.errc:\r\n\t}\r\n\treturn f, err\r\n}","code-length":74,"reference":"\/\/ Open returns a fresh file for writing. Rename the file before calling\n\/\/ Open again or there will be file collisions.","result":"Open the file pipeline.","score":[0.0056,0.0743]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRaftLoggerFromZapCore(cr zapcore.Core, syncer zapcore.WriteSyncer) raft.Logger {\r\n\t\r\n\tlg := zap.New(cr, zap.AddCaller(), zap.AddCallerSkip(1), zap.ErrorOutput(syncer))\r\n\treturn &zapRaftLogger{lg: lg, sugar: lg.Sugar()}\r\n}","code-length":98,"reference":"\/\/ NewRaftLoggerFromZapCore creates \"raft.Logger\" from \"zap.Core\"\n\/\/ and \"zapcore.WriteSyncer\".","result":"Create a new raft logger from zap core.","score":[0.1226,0.1124]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewConfig(fpath string) (*clientv3.Config, error) {\r\n\tb, err := ioutil.ReadFile(fpath)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tyc := &yamlConfig{}\r\n\terr = yaml.Unmarshal(b, yc)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif yc.InsecureTransport {\r\n\t\treturn &yc.Config, nil\r\n\t}\r\n\tvar (\r\n\t\tcert *tls.Certificate\r\n\t\tcp   *x509.CertPool\r\n\t)\r\n\tif yc.Certfile != \"\" && yc.Keyfile != \"\" {\r\n\t\tcert, err = tlsutil.NewCert(yc.Certfile, yc.Keyfile, nil)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\tif yc.TrustedCAfile != \"\" {\r\n\t\tcp, err = tlsutil.NewCertPool([]string{yc.TrustedCAfile})\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\ttlscfg := &tls.Config{\r\n\t\tMinVersion:         tls.VersionTLS12,\r\n\t\tInsecureSkipVerify: yc.InsecureSkipTLSVerify,\r\n\t\tRootCAs:            cp,\r\n\t}\r\n\tif cert != nil {\r\n\t\ttlscfg.Certificates = []tls.Certificate{*cert}\r\n\t}\r\n\tyc.Config.TLS = tlscfg\r\n\treturn &yc.Config, nil\r\n}","code-length":407,"reference":"\/\/ NewConfig creates a new clientv3.Config from a yaml file.","result":"Create a clientv.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterElectionHandler(ctx context.Context, mux *runtime.ServeMux, conn *grpc.ClientConn) error {\r\n\treturn RegisterElectionHandlerClient(ctx, mux, v3electionpb.NewElectionClient(conn))\r\n}","code-length":63,"reference":"\/\/ RegisterElectionHandler registers the http handlers for service Election to \"mux\".\n\/\/ The handlers forward requests to the grpc endpoint over \"conn\".","result":"Register the election handler.","score":[0.0035,0.0743]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UpdateCapability(lg *zap.Logger, v *semver.Version) {\r\n\tif v == nil {\r\n\t\t\r\n\t\treturn\r\n\t}\r\n\tenableMapMu.Lock()\r\n\tif curVersion != nil && !curVersion.LessThan(*v) {\r\n\t\tenableMapMu.Unlock()\r\n\t\treturn\r\n\t}\r\n\tcurVersion = v\r\n\tenabledMap = capabilityMaps[curVersion.String()]\r\n\tenableMapMu.Unlock()\r\n\tif lg != nil {\r\n\t\tlg.Info(\r\n\t\t\t\"enabled capabilities for version\",\r\n\t\t\tzap.String(\"cluster-version\", version.Cluster(v.String())),\r\n\t\t)\r\n\t} else {\r\n\t\tplog.Infof(\"enabled capabilities for version %s\", version.Cluster(v.String()))\r\n\t}\r\n}","code-length":217,"reference":"\/\/ UpdateCapability updates the enabledMap when the cluster version increases.","result":"Update the capability map.","score":[0.0713,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLockCommand() *cobra.Command {\r\n\tc := &cobra.Command{\r\n\t\tUse:   \"lock <lockname> [exec-command arg1 arg2 ...]\",\r\n\t\tShort: \"Acquires a named lock\",\r\n\t\tRun:   lockCommandFunc,\r\n\t}\r\n\tc.Flags().IntVarP(&lockTTL, \"ttl\", \"\", lockTTL, \"timeout for session\")\r\n\treturn c\r\n}","code-length":120,"reference":"\/\/ NewLockCommand returns the cobra command for \"lock\".","result":"Create a new lock.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raftNode) tick() {\r\n\tr.tickMu.Lock()\r\n\tr.Tick()\r\n\tr.tickMu.Unlock()\r\n}","code-length":49,"reference":"\/\/ raft.Node does not have locks in Raft package","result":"Tick the raftNode.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raftNode) advanceTicks(ticks int) {\r\n\tfor i := 0; i < ticks; i++ {\r\n\t\tr.tick()\r\n\t}\r\n}","code-length":53,"reference":"\/\/ advanceTicks advances ticks of Raft node.\n\/\/ This can be used for fast-forwarding election\n\/\/ ticks in multi data-center deployments, thus\n\/\/ speeding up election process.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewAuthCommand() *cobra.Command {\r\n\tac := &cobra.Command{\r\n\t\tUse:   \"auth <enable or disable>\",\r\n\t\tShort: \"Enable or disable authentication\",\r\n\t}\r\n\tac.AddCommand(newAuthEnableCommand())\r\n\tac.AddCommand(newAuthDisableCommand())\r\n\treturn ac\r\n}","code-length":98,"reference":"\/\/ NewAuthCommand returns the cobra command for \"auth\".","result":"Create a new command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc authEnableCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 0 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"auth enable command does not accept any arguments\"))\r\n\t}\r\n\tctx, cancel := commandCtx(cmd)\r\n\tcli := mustClientFromCmd(cmd)\r\n\tvar err error\r\n\tfor err == nil {\r\n\t\tif _, err = cli.AuthEnable(ctx); err == nil {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif err == rpctypes.ErrRootRoleNotExist {\r\n\t\t\tif _, err = cli.RoleAdd(ctx, \"root\"); err != nil {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\tif _, err = cli.UserGrantRole(ctx, \"root\", \"root\"); err != nil {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tfmt.Println(\"Authentication Enabled\")\r\n}","code-length":274,"reference":"\/\/ authEnableCommandFunc executes the \"auth enable\" command.","result":"Disable auth.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc authDisableCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 0 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"auth disable command does not accept any arguments\"))\r\n\t}\r\n\tctx, cancel := commandCtx(cmd)\r\n\t_, err := mustClientFromCmd(cmd).Auth.AuthDisable(ctx)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tfmt.Println(\"Authentication Disabled\")\r\n}","code-length":144,"reference":"\/\/ authDisableCommandFunc executes the \"auth disable\" command.","result":"Execute the command.","score":[0.128,0.3872]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RetryKVClient(c *Client) pb.KVClient {\r\n\treturn &retryKVClient{\r\n\t\tkc: pb.NewKVClient(c.conn),\r\n\t}\r\n}","code-length":56,"reference":"\/\/ RetryKVClient implements a KVClient.","result":"Retry the RPC.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RetryLeaseClient(c *Client) pb.LeaseClient {\r\n\treturn &retryLeaseClient{\r\n\t\tlc: pb.NewLeaseClient(c.conn),\r\n\t}\r\n}","code-length":55,"reference":"\/\/ RetryLeaseClient implements a LeaseClient.","result":"Retry the request.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RetryClusterClient(c *Client) pb.ClusterClient {\r\n\treturn &retryClusterClient{\r\n\t\tcc: pb.NewClusterClient(c.conn),\r\n\t}\r\n}","code-length":55,"reference":"\/\/ RetryClusterClient implements a ClusterClient.","result":"Retry cluster operations.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RetryMaintenanceClient(c *Client, conn *grpc.ClientConn) pb.MaintenanceClient {\r\n\treturn &retryMaintenanceClient{\r\n\t\tmc: pb.NewMaintenanceClient(conn),\r\n\t}\r\n}","code-length":60,"reference":"\/\/ RetryMaintenanceClient implements a Maintenance.","result":"Retry the operation.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RetryAuthClient(c *Client) pb.AuthClient {\r\n\treturn &retryAuthClient{\r\n\t\tac: pb.NewAuthClient(c.conn),\r\n\t}\r\n}","code-length":55,"reference":"\/\/ RetryAuthClient implements a AuthClient.","result":"Retry auth.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSetDirCommand() cli.Command {\r\n\treturn cli.Command{\r\n\t\tName:      \"setdir\",\r\n\t\tUsage:     \"create a new directory or update an existing directory TTL\",\r\n\t\tArgsUsage: \"<key>\",\r\n\t\tFlags: []cli.Flag{\r\n\t\t\tcli.IntFlag{Name: \"ttl\", Value: 0, Usage: \"key time-to-live in seconds\"},\r\n\t\t},\r\n\t\tAction: func(c *cli.Context) error {\r\n\t\t\tmkdirCommandFunc(c, mustNewKeyAPI(c), client.PrevIgnore)\r\n\t\t\treturn nil\r\n\t\t},\r\n\t}\r\n}","code-length":171,"reference":"\/\/ NewSetDirCommand returns the CLI command for \"setDir\".","result":"Create a new directory.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *DoubleBarrier) Enter() error {\r\n\tclient := b.s.Client()\r\n\tek, err := newUniqueEphemeralKey(b.s, b.key+\"\/waiters\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tb.myKey = ek\r\n\tresp, err := client.Get(b.ctx, b.key+\"\/waiters\", clientv3.WithPrefix())\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif len(resp.Kvs) > b.count {\r\n\t\treturn ErrTooManyClients\r\n\t}\r\n\tif len(resp.Kvs) == b.count {\r\n\t\t\r\n\t\t_, err = client.Put(b.ctx, b.key+\"\/ready\", \"\")\r\n\t\treturn err\r\n\t}\r\n\t_, err = WaitEvents(\r\n\t\tclient,\r\n\t\tb.key+\"\/ready\",\r\n\t\tek.Revision(),\r\n\t\t[]mvccpb.Event_EventType{mvccpb.PUT})\r\n\treturn err\r\n}","code-length":276,"reference":"\/\/ Enter waits for \"count\" processes to enter the barrier then returns","result":"Detect if the barrier is already in progress.","score":[0.1191,0.1616]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *DoubleBarrier) Leave() error {\r\n\tclient := b.s.Client()\r\n\tresp, err := client.Get(b.ctx, b.key+\"\/waiters\", clientv3.WithPrefix())\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif len(resp.Kvs) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\tlowest, highest := resp.Kvs[0], resp.Kvs[0]\r\n\tfor _, k := range resp.Kvs {\r\n\t\tif k.ModRevision < lowest.ModRevision {\r\n\t\t\tlowest = k\r\n\t\t}\r\n\t\tif k.ModRevision > highest.ModRevision {\r\n\t\t\thighest = k\r\n\t\t}\r\n\t}\r\n\tisLowest := string(lowest.Key) == b.myKey.Key()\r\n\tif len(resp.Kvs) == 1 {\r\n\t\t\r\n\t\tif _, err = client.Delete(b.ctx, b.key+\"\/ready\"); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn b.myKey.Delete()\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tif isLowest {\r\n\t\t_, err = WaitEvents(\r\n\t\t\tclient,\r\n\t\t\tstring(highest.Key),\r\n\t\t\thighest.ModRevision,\r\n\t\t\t[]mvccpb.Event_EventType{mvccpb.DELETE})\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn b.Leave()\r\n\t}\r\n\t\r\n\tif err = b.myKey.Delete(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tkey := string(lowest.Key)\r\n\t_, err = WaitEvents(\r\n\t\tclient,\r\n\t\tkey,\r\n\t\tlowest.ModRevision,\r\n\t\t[]mvccpb.Event_EventType{mvccpb.DELETE})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn b.Leave()\r\n}","code-length":523,"reference":"\/\/ Leave waits for \"count\" processes to leave the barrier then returns","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HandleBasic(mux *http.ServeMux, server etcdserver.ServerPeer) {\r\n\tmux.HandleFunc(varsPath, serveVars)\r\n\t\r\n\tmux.HandleFunc(configPath+\"\/local\/log\", logHandleFunc)\r\n\tHandleMetricsHealth(mux, server)\r\n\tmux.HandleFunc(versionPath, versionHandler(server.Cluster(), serveVersion))\r\n}","code-length":105,"reference":"\/\/ HandleBasic adds handlers to a mux for serving JSON etcd client requests\n\/\/ that do not access the v2 store.","result":"Handle basic etcd server .","score":[0.0098,0.0258]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WriteError(lg *zap.Logger, w http.ResponseWriter, r *http.Request, err error) {\r\n\tif err == nil {\r\n\t\treturn\r\n\t}\r\n\tswitch e := err.(type) {\r\n\tcase *v2error.Error:\r\n\t\te.WriteTo(w)\r\n\tcase *httptypes.HTTPError:\r\n\t\tif et := e.WriteTo(w); et != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Debug(\r\n\t\t\t\t\t\"failed to write v2 HTTP error\",\r\n\t\t\t\t\tzap.String(\"remote-addr\", r.RemoteAddr),\r\n\t\t\t\t\tzap.String(\"internal-server-error\", e.Error()),\r\n\t\t\t\t\tzap.Error(et),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Debugf(\"error writing HTTPError (%v) to %s\", et, r.RemoteAddr)\r\n\t\t\t}\r\n\t\t}\r\n\tdefault:\r\n\t\tswitch err {\r\n\t\tcase etcdserver.ErrTimeoutDueToLeaderFail, etcdserver.ErrTimeoutDueToConnectionLost, etcdserver.ErrNotEnoughStartedMembers,\r\n\t\t\tetcdserver.ErrUnhealthy:\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"v2 response error\",\r\n\t\t\t\t\tzap.String(\"remote-addr\", r.RemoteAddr),\r\n\t\t\t\t\tzap.String(\"internal-server-error\", err.Error()),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tmlog.MergeError(err)\r\n\t\t\t}\r\n\t\tdefault:\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"unexpected v2 response error\",\r\n\t\t\t\t\tzap.String(\"remote-addr\", r.RemoteAddr),\r\n\t\t\t\t\tzap.String(\"internal-server-error\", err.Error()),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tmlog.MergeErrorf(\"got unexpected response error (%v)\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t\therr := httptypes.NewHTTPError(http.StatusInternalServerError, \"Internal Server Error\")\r\n\t\tif et := herr.WriteTo(w); et != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Debug(\r\n\t\t\t\t\t\"failed to write v2 HTTP error\",\r\n\t\t\t\t\tzap.String(\"remote-addr\", r.RemoteAddr),\r\n\t\t\t\t\tzap.String(\"internal-server-error\", err.Error()),\r\n\t\t\t\t\tzap.Error(et),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Debugf(\"error writing HTTPError (%v) to %s\", et, r.RemoteAddr)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":689,"reference":"\/\/ WriteError logs and writes the given Error to the ResponseWriter\n\/\/ If Error is an etcdErr, it is rendered to the ResponseWriter\n\/\/ Otherwise, it is assumed to be a StatusInternalServerError","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *RaftCluster) MemberByName(name string) *Member {\r\n\tc.Lock()\r\n\tdefer c.Unlock()\r\n\tvar memb *Member\r\n\tfor _, m := range c.members {\r\n\t\tif m.Name == name {\r\n\t\t\tif memb != nil {\r\n\t\t\t\tif c.lg != nil {\r\n\t\t\t\t\tc.lg.Panic(\"two member with same name found\", zap.String(\"name\", name))\r\n\t\t\t\t} else {\r\n\t\t\t\t\tplog.Panicf(\"two members with the given name %q exist\", name)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tmemb = m\r\n\t\t}\r\n\t}\r\n\treturn memb.Clone()\r\n}","code-length":187,"reference":"\/\/ MemberByName returns a Member with the given name if exists.\n\/\/ If more than one member has the given name, it will panic.","result":"Generate the generated code.","score":[0.0022,0.0227]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *RaftCluster) PeerURLs() []string {\r\n\tc.Lock()\r\n\tdefer c.Unlock()\r\n\turls := make([]string, 0)\r\n\tfor _, p := range c.members {\r\n\t\turls = append(urls, p.PeerURLs...)\r\n\t}\r\n\tsort.Strings(urls)\r\n\treturn urls\r\n}","code-length":99,"reference":"\/\/ PeerURLs returns a list of all peer addresses.\n\/\/ The returned list is sorted in ascending lexicographical order.","result":"Generate the code.","score":[0,0.0287]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *RaftCluster) ValidateConfigurationChange(cc raftpb.ConfChange) error {\r\n\tmembers, removed := membersFromStore(c.lg, c.v2store)\r\n\tid := types.ID(cc.NodeID)\r\n\tif removed[id] {\r\n\t\treturn ErrIDRemoved\r\n\t}\r\n\tswitch cc.Type {\r\n\tcase raftpb.ConfChangeAddNode:\r\n\t\tif members[id] != nil {\r\n\t\t\treturn ErrIDExists\r\n\t\t}\r\n\t\turls := make(map[string]bool)\r\n\t\tfor _, m := range members {\r\n\t\t\tfor _, u := range m.PeerURLs {\r\n\t\t\t\turls[u] = true\r\n\t\t\t}\r\n\t\t}\r\n\t\tm := new(Member)\r\n\t\tif err := json.Unmarshal(cc.Context, m); err != nil {\r\n\t\t\tif c.lg != nil {\r\n\t\t\t\tc.lg.Panic(\"failed to unmarshal member\", zap.Error(err))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"unmarshal member should never fail: %v\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t\tfor _, u := range m.PeerURLs {\r\n\t\t\tif urls[u] {\r\n\t\t\t\treturn ErrPeerURLexists\r\n\t\t\t}\r\n\t\t}\r\n\tcase raftpb.ConfChangeRemoveNode:\r\n\t\tif members[id] == nil {\r\n\t\t\treturn ErrIDNotFound\r\n\t\t}\r\n\tcase raftpb.ConfChangeUpdateNode:\r\n\t\tif members[id] == nil {\r\n\t\t\treturn ErrIDNotFound\r\n\t\t}\r\n\t\turls := make(map[string]bool)\r\n\t\tfor _, m := range members {\r\n\t\t\tif m.ID == id {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tfor _, u := range m.PeerURLs {\r\n\t\t\t\turls[u] = true\r\n\t\t\t}\r\n\t\t}\r\n\t\tm := new(Member)\r\n\t\tif err := json.Unmarshal(cc.Context, m); err != nil {\r\n\t\t\tif c.lg != nil {\r\n\t\t\t\tc.lg.Panic(\"failed to unmarshal member\", zap.Error(err))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"unmarshal member should never fail: %v\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t\tfor _, u := range m.PeerURLs {\r\n\t\t\tif urls[u] {\r\n\t\t\t\treturn ErrPeerURLexists\r\n\t\t\t}\r\n\t\t}\r\n\tdefault:\r\n\t\tif c.lg != nil {\r\n\t\t\tc.lg.Panic(\"unknown ConfChange type\", zap.String(\"type\", cc.Type.String()))\r\n\t\t} else {\r\n\t\t\tplog.Panicf(\"ConfChange type should be either AddNode, RemoveNode or UpdateNode\")\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":732,"reference":"\/\/ ValidateConfigurationChange takes a proposed ConfChange and\n\/\/ ensures that it is still valid.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *RaftCluster) AddMember(m *Member) {\r\n\tc.Lock()\r\n\tdefer c.Unlock()\r\n\tif c.v2store != nil {\r\n\t\tmustSaveMemberToStore(c.v2store, m)\r\n\t}\r\n\tif c.be != nil {\r\n\t\tmustSaveMemberToBackend(c.be, m)\r\n\t}\r\n\tc.members[m.ID] = m\r\n\tif c.lg != nil {\r\n\t\tc.lg.Info(\r\n\t\t\t\"added member\",\r\n\t\t\tzap.String(\"cluster-id\", c.cid.String()),\r\n\t\t\tzap.String(\"local-member-id\", c.localID.String()),\r\n\t\t\tzap.String(\"added-peer-id\", m.ID.String()),\r\n\t\t\tzap.Strings(\"added-peer-peer-urls\", m.PeerURLs),\r\n\t\t)\r\n\t} else {\r\n\t\tplog.Infof(\"added member %s %v to cluster %s\", m.ID, m.PeerURLs, c.cid)\r\n\t}\r\n}","code-length":284,"reference":"\/\/ AddMember adds a new Member into the cluster, and saves the given member's\n\/\/ raftAttributes into the store. The given member should have empty attributes.\n\/\/ A Member with a matching id must not exist.","result":"Add a member to the cluster.","score":[0.0017,0.0606]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *RaftCluster) RemoveMember(id types.ID) {\r\n\tc.Lock()\r\n\tdefer c.Unlock()\r\n\tif c.v2store != nil {\r\n\t\tmustDeleteMemberFromStore(c.v2store, id)\r\n\t}\r\n\tif c.be != nil {\r\n\t\tmustDeleteMemberFromBackend(c.be, id)\r\n\t}\r\n\tm, ok := c.members[id]\r\n\tdelete(c.members, id)\r\n\tc.removed[id] = true\r\n\tif c.lg != nil {\r\n\t\tif ok {\r\n\t\t\tc.lg.Info(\r\n\t\t\t\t\"removed member\",\r\n\t\t\t\tzap.String(\"cluster-id\", c.cid.String()),\r\n\t\t\t\tzap.String(\"local-member-id\", c.localID.String()),\r\n\t\t\t\tzap.String(\"removed-remote-peer-id\", id.String()),\r\n\t\t\t\tzap.Strings(\"removed-remote-peer-urls\", m.PeerURLs),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tc.lg.Warn(\r\n\t\t\t\t\"skipped removing already removed member\",\r\n\t\t\t\tzap.String(\"cluster-id\", c.cid.String()),\r\n\t\t\t\tzap.String(\"local-member-id\", c.localID.String()),\r\n\t\t\t\tzap.String(\"removed-remote-peer-id\", id.String()),\r\n\t\t\t)\r\n\t\t}\r\n\t} else {\r\n\t\tplog.Infof(\"removed member %s from cluster %s\", id, c.cid)\r\n\t}\r\n}","code-length":408,"reference":"\/\/ RemoveMember removes a member from the store.\n\/\/ The given id MUST exist, or the function panics.","result":"Remove member from the cluster.","score":[0.0368,0.189]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ValidateClusterAndAssignIDs(lg *zap.Logger, local *RaftCluster, existing *RaftCluster) error {\r\n\tems := existing.Members()\r\n\tlms := local.Members()\r\n\tif len(ems) != len(lms) {\r\n\t\treturn fmt.Errorf(\"member count is unequal\")\r\n\t}\r\n\tsort.Sort(MembersByPeerURLs(ems))\r\n\tsort.Sort(MembersByPeerURLs(lms))\r\n\tctx, cancel := context.WithTimeout(context.TODO(), 30*time.Second)\r\n\tdefer cancel()\r\n\tfor i := range ems {\r\n\t\tif ok, err := netutil.URLStringsEqual(ctx, lg, ems[i].PeerURLs, lms[i].PeerURLs); !ok {\r\n\t\t\treturn fmt.Errorf(\"unmatched member while checking PeerURLs (%v)\", err)\r\n\t\t}\r\n\t\tlms[i].ID = ems[i].ID\r\n\t}\r\n\tlocal.members = make(map[types.ID]*Member)\r\n\tfor _, m := range lms {\r\n\t\tlocal.members[m.ID] = m\r\n\t}\r\n\treturn nil\r\n}","code-length":299,"reference":"\/\/ ValidateClusterAndAssignIDs validates the local cluster by matching the PeerURLs\n\/\/ with the existing cluster. If the validation succeeds, it assigns the IDs\n\/\/ from the existing cluster to the local cluster.\n\/\/ If the validation fails, an error will be returned.","result":"Validate cluster members and assign IDs.","score":[0.0005,0.0391]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ti *treeIndex) Keep(rev int64) map[revision]struct{} {\r\n\tavailable := make(map[revision]struct{})\r\n\tti.RLock()\r\n\tdefer ti.RUnlock()\r\n\tti.tree.Ascend(func(i btree.Item) bool {\r\n\t\tkeyi := i.(*keyIndex)\r\n\t\tkeyi.keep(rev, available)\r\n\t\treturn true\r\n\t})\r\n\treturn available\r\n}","code-length":124,"reference":"\/\/ Keep finds all revisions to be kept for a Compaction at the given rev.","result":"Keep the given revision.","score":[0.032,0.1839]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *lessor) closeRequireLeader() {\r\n\tl.mu.Lock()\r\n\tdefer l.mu.Unlock()\r\n\tfor _, ka := range l.keepAlives {\r\n\t\treqIdxs := 0\r\n\t\t\r\n\t\tfor i, ctx := range ka.ctxs {\r\n\t\t\tmd, ok := metadata.FromOutgoingContext(ctx)\r\n\t\t\tif !ok {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tks := md[rpctypes.MetadataRequireLeaderKey]\r\n\t\t\tif len(ks) < 1 || ks[0] != rpctypes.MetadataHasLeader {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tclose(ka.chs[i])\r\n\t\t\tka.chs[i] = nil\r\n\t\t\treqIdxs++\r\n\t\t}\r\n\t\tif reqIdxs == 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tnewChs := make([]chan<- *LeaseKeepAliveResponse, len(ka.chs)-reqIdxs)\r\n\t\tnewCtxs := make([]context.Context, len(newChs))\r\n\t\tnewIdx := 0\r\n\t\tfor i := range ka.chs {\r\n\t\t\tif ka.chs[i] == nil {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tnewChs[newIdx], newCtxs[newIdx] = ka.chs[i], ka.ctxs[newIdx]\r\n\t\t\tnewIdx++\r\n\t\t}\r\n\t\tka.chs, ka.ctxs = newChs, newCtxs\r\n\t}\r\n}","code-length":402,"reference":"\/\/ closeRequireLeader scans keepAlives for ctxs that have require leader\n\/\/ and closes the associated channels.","result":"Close the leader channel.","score":[0.0189,0.1727]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *lessor) resetRecv() (pb.Lease_LeaseKeepAliveClient, error) {\r\n\tsctx, cancel := context.WithCancel(l.stopCtx)\r\n\tstream, err := l.remote.LeaseKeepAlive(sctx, append(l.callOpts, withMax(0))...)\r\n\tif err != nil {\r\n\t\tcancel()\r\n\t\treturn nil, err\r\n\t}\r\n\tl.mu.Lock()\r\n\tdefer l.mu.Unlock()\r\n\tif l.stream != nil && l.streamCancel != nil {\r\n\t\tl.streamCancel()\r\n\t}\r\n\tl.streamCancel = cancel\r\n\tl.stream = stream\r\n\tgo l.sendKeepAliveLoop(stream)\r\n\treturn stream, nil\r\n}","code-length":193,"reference":"\/\/ resetRecv opens a new lease stream and starts sending keep alive requests.","result":"Reset the recv loop.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *lessor) recvKeepAlive(resp *pb.LeaseKeepAliveResponse) {\r\n\tkaresp := &LeaseKeepAliveResponse{\r\n\t\tResponseHeader: resp.GetHeader(),\r\n\t\tID:             LeaseID(resp.ID),\r\n\t\tTTL:            resp.TTL,\r\n\t}\r\n\tl.mu.Lock()\r\n\tdefer l.mu.Unlock()\r\n\tka, ok := l.keepAlives[karesp.ID]\r\n\tif !ok {\r\n\t\treturn\r\n\t}\r\n\tif karesp.TTL <= 0 {\r\n\t\t\r\n\t\tdelete(l.keepAlives, karesp.ID)\r\n\t\tka.close()\r\n\t\treturn\r\n\t}\r\n\t\r\n\tnextKeepAlive := time.Now().Add((time.Duration(karesp.TTL) * time.Second) \/ 3.0)\r\n\tka.deadline = time.Now().Add(time.Duration(karesp.TTL) * time.Second)\r\n\tfor _, ch := range ka.chs {\r\n\t\tselect {\r\n\t\tcase ch <- karesp:\r\n\t\tdefault:\r\n\t\t\tif l.lg != nil {\r\n\t\t\t\tl.lg.Warn(\"lease keepalive response queue is full; dropping response send\",\r\n\t\t\t\t\tzap.Int(\"queue-size\", len(ch)),\r\n\t\t\t\t\tzap.Int(\"queue-capacity\", cap(ch)),\r\n\t\t\t\t)\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tka.nextKeepAlive = nextKeepAlive\r\n\t}\r\n}","code-length":391,"reference":"\/\/ recvKeepAlive updates a lease based on its LeaseKeepAliveResponse","result":"Alive responses to the leader.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *lessor) deadlineLoop() {\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase <-time.After(time.Second):\r\n\t\tcase <-l.donec:\r\n\t\t\treturn\r\n\t\t}\r\n\t\tnow := time.Now()\r\n\t\tl.mu.Lock()\r\n\t\tfor id, ka := range l.keepAlives {\r\n\t\t\tif ka.deadline.Before(now) {\r\n\t\t\t\t\r\n\t\t\t\tka.close()\r\n\t\t\t\tdelete(l.keepAlives, id)\r\n\t\t\t}\r\n\t\t}\r\n\t\tl.mu.Unlock()\r\n\t}\r\n}","code-length":169,"reference":"\/\/ deadlineLoop reaps any keep alive channels that have not received a response\n\/\/ within the lease TTL","result":"Loop until the deadline.","score":[0.0096,0.0301]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *lessor) sendKeepAliveLoop(stream pb.Lease_LeaseKeepAliveClient) {\r\n\tfor {\r\n\t\tvar tosend []LeaseID\r\n\t\tnow := time.Now()\r\n\t\tl.mu.Lock()\r\n\t\tfor id, ka := range l.keepAlives {\r\n\t\t\tif ka.nextKeepAlive.Before(now) {\r\n\t\t\t\ttosend = append(tosend, id)\r\n\t\t\t}\r\n\t\t}\r\n\t\tl.mu.Unlock()\r\n\t\tfor _, id := range tosend {\r\n\t\t\tr := &pb.LeaseKeepAliveRequest{ID: int64(id)}\r\n\t\t\tif err := stream.Send(r); err != nil {\r\n\t\t\t\t\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t}\r\n\t\tselect {\r\n\t\tcase <-time.After(retryConnWait):\r\n\t\tcase <-stream.Context().Done():\r\n\t\t\treturn\r\n\t\tcase <-l.donec:\r\n\t\t\treturn\r\n\t\tcase <-l.stopCtx.Done():\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":281,"reference":"\/\/ sendKeepAliveLoop sends keep alive requests for the lifetime of the given stream.","result":"Send keep alive requests to the leader.","score":[0.1517,0.3903]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewKV(cl *v3.Client, pfx string, opts ...concurrency.SessionOption) (v3.KV, func(), error) {\r\n\tcctx, cancel := context.WithCancel(cl.Ctx())\r\n\tlkv := &leasingKV{\r\n\t\tcl:          cl,\r\n\t\tkv:          cl.KV,\r\n\t\tpfx:         pfx,\r\n\t\tleases:      leaseCache{revokes: make(map[string]time.Time)},\r\n\t\tctx:         cctx,\r\n\t\tcancel:      cancel,\r\n\t\tsessionOpts: opts,\r\n\t\tsessionc:    make(chan struct{}),\r\n\t}\r\n\tlkv.wg.Add(2)\r\n\tgo func() {\r\n\t\tdefer lkv.wg.Done()\r\n\t\tlkv.monitorSession()\r\n\t}()\r\n\tgo func() {\r\n\t\tdefer lkv.wg.Done()\r\n\t\tlkv.leases.clearOldRevokes(cctx)\r\n\t}()\r\n\treturn lkv, lkv.Close, lkv.waitSession(cctx)\r\n}","code-length":285,"reference":"\/\/ NewKV wraps a KV instance so that all requests are wired through a leasing protocol.","result":"Create a new kv object.","score":[0.0266,0.0671]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lkv *leasingKV) rescind(ctx context.Context, key string, rev int64) {\r\n\tif lkv.leases.Evict(key) > rev {\r\n\t\treturn\r\n\t}\r\n\tcmp := v3.Compare(v3.CreateRevision(lkv.pfx+key), \"<\", rev)\r\n\top := v3.OpDelete(lkv.pfx + key)\r\n\tfor ctx.Err() == nil {\r\n\t\tif _, err := lkv.kv.Txn(ctx).If(cmp).Then(op).Commit(); err == nil {\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":168,"reference":"\/\/ rescind releases a lease from this client.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LeaseValue(key string) Cmp {\r\n\treturn Cmp{Key: []byte(key), Target: pb.Compare_LEASE}\r\n}","code-length":42,"reference":"\/\/ LeaseValue compares a key's LeaseID to a value of your choosing. The empty\n\/\/ LeaseID is 0, otherwise known as `NoLease`.","result":"Generate the code.","score":[0,0.0249]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cmp *Cmp) ValueBytes() []byte {\r\n\tif tu, ok := cmp.TargetUnion.(*pb.Compare_Value); ok {\r\n\t\treturn tu.Value\r\n\t}\r\n\treturn nil\r\n}","code-length":63,"reference":"\/\/ ValueBytes returns the byte slice holding the comparison value, if any.","result":"Generate the value bytes .","score":[0.0593,0.0885]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cmp Cmp) WithRange(end string) Cmp {\r\n\tcmp.RangeEnd = []byte(end)\r\n\treturn cmp\r\n}","code-length":43,"reference":"\/\/ WithRange sets the comparison to scan the range [key, end).","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cmp Cmp) WithPrefix() Cmp {\r\n\tcmp.RangeEnd = getPrefix(cmp.Key)\r\n\treturn cmp\r\n}","code-length":41,"reference":"\/\/ WithPrefix sets the comparison to scan all keys prefixed by the key.","result":"Create a new function.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc mustInt64(val interface{}) int64 {\r\n\tif v, ok := val.(int64); ok {\r\n\t\treturn v\r\n\t}\r\n\tif v, ok := val.(int); ok {\r\n\t\treturn int64(v)\r\n\t}\r\n\tpanic(\"bad value\")\r\n}","code-length":88,"reference":"\/\/ mustInt64 panics if val isn't an int or int64. It returns an int64 otherwise.","result":"Check if val is int.","score":[0.046,0.1339]}
{"code":"\/*is used to<extra_id_0>\r\nfunc mustInt64orLeaseID(val interface{}) int64 {\r\n\tif v, ok := val.(LeaseID); ok {\r\n\t\treturn int64(v)\r\n\t}\r\n\treturn mustInt64(val)\r\n}","code-length":67,"reference":"\/\/ mustInt64orLeaseID panics if val isn't a LeaseID, int or int64. It returns an\n\/\/ int64 otherwise.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gw *gRPCWatcher) Next() ([]*naming.Update, error) {\r\n\tif gw.wch == nil {\r\n\t\t\r\n\t\treturn gw.firstNext()\r\n\t}\r\n\tif gw.err != nil {\r\n\t\treturn nil, gw.err\r\n\t}\r\n\t\r\n\twr, ok := <-gw.wch\r\n\tif !ok {\r\n\t\tgw.err = status.Error(codes.Unavailable, ErrWatcherClosed.Error())\r\n\t\treturn nil, gw.err\r\n\t}\r\n\tif gw.err = wr.Err(); gw.err != nil {\r\n\t\treturn nil, gw.err\r\n\t}\r\n\tupdates := make([]*naming.Update, 0, len(wr.Events))\r\n\tfor _, e := range wr.Events {\r\n\t\tvar jupdate naming.Update\r\n\t\tvar err error\r\n\t\tswitch e.Type {\r\n\t\tcase etcd.EventTypePut:\r\n\t\t\terr = json.Unmarshal(e.Kv.Value, &jupdate)\r\n\t\t\tjupdate.Op = naming.Add\r\n\t\tcase etcd.EventTypeDelete:\r\n\t\t\terr = json.Unmarshal(e.PrevKv.Value, &jupdate)\r\n\t\t\tjupdate.Op = naming.Delete\r\n\t\tdefault:\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif err == nil {\r\n\t\t\tupdates = append(updates, &jupdate)\r\n\t\t}\r\n\t}\r\n\treturn updates, nil\r\n}","code-length":378,"reference":"\/\/ Next gets the next set of updates from the etcd resolver.\n\/\/ Calls to Next should be serialized; concurrent calls are not safe since\n\/\/ there is no way to reconcile the update ordering.","result":"Get the next event from the watcher.","score":[0.0055,0.0776]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getJournalWriteSyncer() (zapcore.WriteSyncer, error) {\r\n\tjw, err := logutil.NewJournalWriter(os.Stderr)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"can't find journal (%v)\", err)\r\n\t}\r\n\treturn zapcore.AddSync(jw), nil\r\n}","code-length":97,"reference":"\/\/ use stderr as fallback","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newKV(store *store, nodePath string, value string, createdIndex uint64, parent *node, expireTime time.Time) *node {\r\n\treturn &node{\r\n\t\tPath:          nodePath,\r\n\t\tCreatedIndex:  createdIndex,\r\n\t\tModifiedIndex: createdIndex,\r\n\t\tParent:        parent,\r\n\t\tstore:         store,\r\n\t\tExpireTime:    expireTime,\r\n\t\tValue:         value,\r\n\t}\r\n}","code-length":123,"reference":"\/\/ newKV creates a Key-Value pair","result":"Create a new KV node.","score":[0.1967,0.3178]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newDir(store *store, nodePath string, createdIndex uint64, parent *node, expireTime time.Time) *node {\r\n\treturn &node{\r\n\t\tPath:          nodePath,\r\n\t\tCreatedIndex:  createdIndex,\r\n\t\tModifiedIndex: createdIndex,\r\n\t\tParent:        parent,\r\n\t\tExpireTime:    expireTime,\r\n\t\tChildren:      make(map[string]*node),\r\n\t\tstore:         store,\r\n\t}\r\n}","code-length":126,"reference":"\/\/ newDir creates a directory","result":"Create a new directory.","score":[0.2488,0.3827]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *node) Read() (string, *v2error.Error) {\r\n\tif n.IsDir() {\r\n\t\treturn \"\", v2error.NewError(v2error.EcodeNotFile, \"\", n.store.CurrentIndex)\r\n\t}\r\n\treturn n.Value, nil\r\n}","code-length":84,"reference":"\/\/ Read function gets the value of the node.\n\/\/ If the receiver node is not a key-value pair, a \"Not A File\" error will be returned.","result":"Read the file.","score":[0.0002,0.0407]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *node) Write(value string, index uint64) *v2error.Error {\r\n\tif n.IsDir() {\r\n\t\treturn v2error.NewError(v2error.EcodeNotFile, \"\", n.store.CurrentIndex)\r\n\t}\r\n\tn.Value = value\r\n\tn.ModifiedIndex = index\r\n\treturn nil\r\n}","code-length":99,"reference":"\/\/ Write function set the value of the node to the given value.\n\/\/ If the receiver node is a directory, a \"Not A File\" error will be returned.","result":"Write to the store.","score":[0.001,0.0566]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *node) List() ([]*node, *v2error.Error) {\r\n\tif !n.IsDir() {\r\n\t\treturn nil, v2error.NewError(v2error.EcodeNotDir, \"\", n.store.CurrentIndex)\r\n\t}\r\n\tnodes := make([]*node, len(n.Children))\r\n\ti := 0\r\n\tfor _, node := range n.Children {\r\n\t\tnodes[i] = node\r\n\t\ti++\r\n\t}\r\n\treturn nodes, nil\r\n}","code-length":140,"reference":"\/\/ List function return a slice of nodes under the receiver node.\n\/\/ If the receiver node is not a directory, a \"Not A Directory\" error will be returned.","result":"List the contents of the node.","score":[0.0062,0.0936]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *node) GetChild(name string) (*node, *v2error.Error) {\r\n\tif !n.IsDir() {\r\n\t\treturn nil, v2error.NewError(v2error.EcodeNotDir, n.Path, n.store.CurrentIndex)\r\n\t}\r\n\tchild, ok := n.Children[name]\r\n\tif ok {\r\n\t\treturn child, nil\r\n\t}\r\n\treturn nil, nil\r\n}","code-length":123,"reference":"\/\/ GetChild function returns the child node under the directory node.\n\/\/ On success, it returns the file node","result":"Get the child node.","score":[0.0118,0.0857]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *node) Add(child *node) *v2error.Error {\r\n\tif !n.IsDir() {\r\n\t\treturn v2error.NewError(v2error.EcodeNotDir, \"\", n.store.CurrentIndex)\r\n\t}\r\n\t_, name := path.Split(child.Path)\r\n\tif _, ok := n.Children[name]; ok {\r\n\t\treturn v2error.NewError(v2error.EcodeNodeExist, \"\", n.store.CurrentIndex)\r\n\t}\r\n\tn.Children[name] = child\r\n\treturn nil\r\n}","code-length":155,"reference":"\/\/ Add function adds a node to the receiver node.\n\/\/ If the receiver is not a directory, a \"Not A Directory\" error will be returned.\n\/\/ If there is an existing node with the same name under the directory, a \"Already Exist\"\n\/\/ error will be returned","result":"Add a child node to the node.","score":[0.0011,0.0683]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *node) Remove(dir, recursive bool, callback func(path string)) *v2error.Error {\r\n\tif !n.IsDir() {\r\n\t\t_, name := path.Split(n.Path)\r\n\t\t\r\n\t\tif n.Parent != nil && n.Parent.Children[name] == n {\r\n\t\t\tdelete(n.Parent.Children, name)\r\n\t\t}\r\n\t\tif callback != nil {\r\n\t\t\tcallback(n.Path)\r\n\t\t}\r\n\t\tif !n.IsPermanent() {\r\n\t\t\tn.store.ttlKeyHeap.remove(n)\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\tif !dir {\r\n\t\t\r\n\t\treturn v2error.NewError(v2error.EcodeNotFile, n.Path, n.store.CurrentIndex)\r\n\t}\r\n\tif len(n.Children) != 0 && !recursive {\r\n\t\t\r\n\t\t\r\n\t\treturn v2error.NewError(v2error.EcodeDirNotEmpty, n.Path, n.store.CurrentIndex)\r\n\t}\r\n\tfor _, child := range n.Children {\r\n\t\tchild.Remove(true, true, callback)\r\n\t}\r\n\t\r\n\t_, name := path.Split(n.Path)\r\n\tif n.Parent != nil && n.Parent.Children[name] == n {\r\n\t\tdelete(n.Parent.Children, name)\r\n\t\tif callback != nil {\r\n\t\t\tcallback(n.Path)\r\n\t\t}\r\n\t\tif !n.IsPermanent() {\r\n\t\t\tn.store.ttlKeyHeap.remove(n)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":430,"reference":"\/\/ Remove function remove the node.","result":"Remove a node.","score":[0.1786,0.1754]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *node) Compare(prevValue string, prevIndex uint64) (ok bool, which int) {\r\n\tindexMatch := prevIndex == 0 || n.ModifiedIndex == prevIndex\r\n\tvalueMatch := prevValue == \"\" || n.Value == prevValue\r\n\tok = valueMatch && indexMatch\r\n\tswitch {\r\n\tcase valueMatch && indexMatch:\r\n\t\twhich = CompareMatch\r\n\tcase indexMatch && !valueMatch:\r\n\t\twhich = CompareValueNotMatch\r\n\tcase valueMatch && !indexMatch:\r\n\t\twhich = CompareIndexNotMatch\r\n\tdefault:\r\n\t\twhich = CompareNotMatch\r\n\t}\r\n\treturn ok, which\r\n}","code-length":172,"reference":"\/\/ Compare function compares node index and value with provided ones.\n\/\/ second result value explains result and equals to one of Compare.. constants","result":"Compare the value of a node.","score":[0.0126,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *node) Clone() *node {\r\n\tif !n.IsDir() {\r\n\t\tnewkv := newKV(n.store, n.Path, n.Value, n.CreatedIndex, n.Parent, n.ExpireTime)\r\n\t\tnewkv.ModifiedIndex = n.ModifiedIndex\r\n\t\treturn newkv\r\n\t}\r\n\tclone := newDir(n.store, n.Path, n.CreatedIndex, n.Parent, n.ExpireTime)\r\n\tclone.ModifiedIndex = n.ModifiedIndex\r\n\tfor key, child := range n.Children {\r\n\t\tclone.Children[key] = child.Clone()\r\n\t}\r\n\treturn clone\r\n}","code-length":174,"reference":"\/\/ Clone function clone the node recursively and return the new node.\n\/\/ If the node is a directory, it will clone all the content under this directory.\n\/\/ If the node is a key-value pair, it will clone the pair.","result":"Clone a node.","score":[0.0,0.0403]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isConnectedToQuorumSince(transport rafthttp.Transporter, since time.Time, self types.ID, members []*membership.Member) bool {\r\n\treturn numConnectedSince(transport, since, self, members) >= (len(members)\/2)+1\r\n}","code-length":70,"reference":"\/\/ isConnectedToQuorumSince checks whether the local member is connected to the\n\/\/ quorum of the cluster since the given time.","result":"Check if the member is in the middle of a quorum.","score":[0.0768,0.2232]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isConnectedSince(transport rafthttp.Transporter, since time.Time, remote types.ID) bool {\r\n\tt := transport.ActiveSince(remote)\r\n\treturn !t.IsZero() && t.Before(since)\r\n}","code-length":65,"reference":"\/\/ isConnectedSince checks whether the local member is connected to the\n\/\/ remote member since the given time.","result":"Check if the remote is connected to a remote server.","score":[0.1142,0.2972]}
{"code":"\/*is used to<extra_id_0>\r\nfunc numConnectedSince(transport rafthttp.Transporter, since time.Time, self types.ID, members []*membership.Member) int {\r\n\tconnectedNum := 0\r\n\tfor _, m := range members {\r\n\t\tif m.ID == self || isConnectedSince(transport, since, m.ID) {\r\n\t\t\tconnectedNum++\r\n\t\t}\r\n\t}\r\n\treturn connectedNum\r\n}","code-length":107,"reference":"\/\/ numConnectedSince counts how many members are connected to the local member\n\/\/ since the given time.","result":"Determine the number of members connected to the current member.","score":[0.1262,0.2616]}
{"code":"\/*is used to<extra_id_0>\r\nfunc longestConnected(tp rafthttp.Transporter, membs []types.ID) (types.ID, bool) {\r\n\tvar longest types.ID\r\n\tvar oldest time.Time\r\n\tfor _, id := range membs {\r\n\t\ttm := tp.ActiveSince(id)\r\n\t\tif tm.IsZero() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif oldest.IsZero() {\r\n\t\t\toldest = tm\r\n\t\t\tlongest = id\r\n\t\t}\r\n\t\tif tm.Before(oldest) {\r\n\t\t\toldest = tm\r\n\t\t\tlongest = id\r\n\t\t}\r\n\t}\r\n\tif uint64(longest) == 0 {\r\n\t\treturn longest, false\r\n\t}\r\n\treturn longest, true\r\n}","code-length":203,"reference":"\/\/ longestConnected chooses the member with longest active-since-time.\n\/\/ It returns false, if nothing is active.","result":"Determine the longest connected ID.","score":[0.0317,0.0671]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *decoder) isTornEntry(data []byte) bool {\r\n\tif len(d.brs) != 1 {\r\n\t\treturn false\r\n\t}\r\n\tfileOff := d.lastValidOff + frameSizeBytes\r\n\tcurOff := 0\r\n\tchunks := [][]byte{}\r\n\t\r\n\tfor curOff < len(data) {\r\n\t\tchunkLen := int(minSectorSize - (fileOff % minSectorSize))\r\n\t\tif chunkLen > len(data)-curOff {\r\n\t\t\tchunkLen = len(data) - curOff\r\n\t\t}\r\n\t\tchunks = append(chunks, data[curOff:curOff+chunkLen])\r\n\t\tfileOff += int64(chunkLen)\r\n\t\tcurOff += chunkLen\r\n\t}\r\n\t\r\n\tfor _, sect := range chunks {\r\n\t\tisZero := true\r\n\t\tfor _, v := range sect {\r\n\t\t\tif v != 0 {\r\n\t\t\t\tisZero = false\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif isZero {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":297,"reference":"\/\/ isTornEntry determines whether the last entry of the WAL was partially written\n\/\/ and corrupted because of a torn write.","result":"Detect if a frame is to be torn.","score":[0.0273,0.0254]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StartMockServersOnNetwork(count int, network string) (ms *MockServers, err error) {\r\n\tswitch network {\r\n\tcase \"tcp\":\r\n\t\treturn startMockServersTcp(count)\r\n\tcase \"unix\":\r\n\t\treturn startMockServersUnix(count)\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"unsupported network type: %s\", network)\r\n\t}\r\n}","code-length":108,"reference":"\/\/ StartMockServersOnNetwork creates mock servers on either 'tcp' or 'unix' sockets.","result":"Start the mock servers on a specific network.","score":[0.1966,0.2752]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MockServers) StartAt(idx int) (err error) {\r\n\tms.mu.Lock()\r\n\tdefer ms.mu.Unlock()\r\n\tif ms.Servers[idx].ln == nil {\r\n\t\tms.Servers[idx].ln, err = net.Listen(ms.Servers[idx].Network, ms.Servers[idx].Address)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to listen %v\", err)\r\n\t\t}\r\n\t}\r\n\tsvr := grpc.NewServer()\r\n\tpb.RegisterKVServer(svr, &mockKVServer{})\r\n\tms.Servers[idx].GrpcServer = svr\r\n\tms.wg.Add(1)\r\n\tgo func(svr *grpc.Server, l net.Listener) {\r\n\t\tsvr.Serve(l)\r\n\t}(ms.Servers[idx].GrpcServer, ms.Servers[idx].ln)\r\n\treturn nil\r\n}","code-length":245,"reference":"\/\/ StartAt restarts mock server at given index.","result":"Start the server at the specified index.","score":[0.2191,0.3235]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MockServers) StopAt(idx int) {\r\n\tms.mu.Lock()\r\n\tdefer ms.mu.Unlock()\r\n\tif ms.Servers[idx].ln == nil {\r\n\t\treturn\r\n\t}\r\n\tms.Servers[idx].GrpcServer.Stop()\r\n\tms.Servers[idx].GrpcServer = nil\r\n\tms.Servers[idx].ln = nil\r\n\tms.wg.Done()\r\n}","code-length":118,"reference":"\/\/ StopAt stops mock server at given index.","result":"Stop the server at the given index.","score":[0.2606,0.5646]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MockServers) Stop() {\r\n\tfor idx := range ms.Servers {\r\n\t\tms.StopAt(idx)\r\n\t}\r\n\tms.wg.Wait()\r\n}","code-length":57,"reference":"\/\/ Stop stops the mock server, immediately closing all open connections and listeners.","result":"Stop the servers.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCheckCommand() *cobra.Command {\r\n\tcc := &cobra.Command{\r\n\t\tUse:   \"check <subcommand>\",\r\n\t\tShort: \"commands for checking properties of the etcd cluster\",\r\n\t}\r\n\tcc.AddCommand(NewCheckPerfCommand())\r\n\tcc.AddCommand(NewCheckDatascaleCommand())\r\n\treturn cc\r\n}","code-length":102,"reference":"\/\/ NewCheckCommand returns the cobra command for \"check\".","result":"Create the check command.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCheckPerfCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"perf [options]\",\r\n\t\tShort: \"Check the performance of the etcd cluster\",\r\n\t\tRun:   newCheckPerfCommand,\r\n\t}\r\n\t\r\n\tcmd.Flags().StringVar(&checkPerfLoad, \"load\", \"s\", \"The performance check's workload model. Accepted workloads: s(small), m(medium), l(large), xl(xLarge)\")\r\n\tcmd.Flags().StringVar(&checkPerfPrefix, \"prefix\", \"\/etcdctl-check-perf\/\", \"The prefix for writing the performance check's keys.\")\r\n\tcmd.Flags().BoolVar(&autoCompact, \"auto-compact\", false, \"Compact storage with last revision after test is finished.\")\r\n\tcmd.Flags().BoolVar(&autoDefrag, \"auto-defrag\", false, \"Defragment storage after test is finished.\")\r\n\treturn cmd\r\n}","code-length":248,"reference":"\/\/ NewCheckPerfCommand returns the cobra command for \"check perf\".","result":"Generate the test code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCheckDatascaleCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"datascale [options]\",\r\n\t\tShort: \"Check the memory usage of holding data for different workloads on a given server endpoint.\",\r\n\t\tLong:  \"If no endpoint is provided, localhost will be used. If multiple endpoints are provided, first endpoint will be used.\",\r\n\t\tRun:   newCheckDatascaleCommand,\r\n\t}\r\n\tcmd.Flags().StringVar(&checkDatascaleLoad, \"load\", \"s\", \"The datascale check's workload model. Accepted workloads: s(small), m(medium), l(large), xl(xLarge)\")\r\n\tcmd.Flags().StringVar(&checkDatascalePrefix, \"prefix\", \"\/etcdctl-check-datascale\/\", \"The prefix for writing the datascale check's keys.\")\r\n\tcmd.Flags().BoolVar(&autoCompact, \"auto-compact\", false, \"Compact storage with last revision after test is finished.\")\r\n\tcmd.Flags().BoolVar(&autoDefrag, \"auto-defrag\", false, \"Defragment storage after test is finished.\")\r\n\treturn cmd\r\n}","code-length":295,"reference":"\/\/ NewCheckDatascaleCommand returns the cobra command for \"check datascale\".","result":"Check the memory usage of the etcd server.","score":[0.1226,0.0562]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewGetCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"get [options] <key> [range_end]\",\r\n\t\tShort: \"Gets the key or a range of keys\",\r\n\t\tRun:   getCommandFunc,\r\n\t}\r\n\tcmd.Flags().StringVar(&getConsistency, \"consistency\", \"l\", \"Linearizable(l) or Serializable(s)\")\r\n\tcmd.Flags().StringVar(&getSortOrder, \"order\", \"\", \"Order of results; ASCEND or DESCEND (ASCEND by default)\")\r\n\tcmd.Flags().StringVar(&getSortTarget, \"sort-by\", \"\", \"Sort target; CREATE, KEY, MODIFY, VALUE, or VERSION\")\r\n\tcmd.Flags().Int64Var(&getLimit, \"limit\", 0, \"Maximum number of results\")\r\n\tcmd.Flags().BoolVar(&getPrefix, \"prefix\", false, \"Get keys with matching prefix\")\r\n\tcmd.Flags().BoolVar(&getFromKey, \"from-key\", false, \"Get keys that are greater than or equal to the given key using byte compare\")\r\n\tcmd.Flags().Int64Var(&getRev, \"rev\", 0, \"Specify the kv revision\")\r\n\tcmd.Flags().BoolVar(&getKeysOnly, \"keys-only\", false, \"Get only the keys\")\r\n\tcmd.Flags().BoolVar(&printValueOnly, \"print-value-only\", false, `Only write values when using the \"simple\" output format`)\r\n\treturn cmd\r\n}","code-length":377,"reference":"\/\/ NewGetCommand returns the cobra command for \"get\".","result":"Generate the command .","score":[0.1398,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewGetCommand() cli.Command {\r\n\treturn cli.Command{\r\n\t\tName:      \"get\",\r\n\t\tUsage:     \"retrieve the value of a key\",\r\n\t\tArgsUsage: \"<key>\",\r\n\t\tFlags: []cli.Flag{\r\n\t\t\tcli.BoolFlag{Name: \"sort\", Usage: \"returns result in sorted order\"},\r\n\t\t\tcli.BoolFlag{Name: \"quorum, q\", Usage: \"require quorum for get request\"},\r\n\t\t},\r\n\t\tAction: func(c *cli.Context) error {\r\n\t\t\tgetCommandFunc(c, mustNewKeyAPI(c))\r\n\t\t\treturn nil\r\n\t\t},\r\n\t}\r\n}","code-length":179,"reference":"\/\/ NewGetCommand returns the CLI command for \"get\".","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) PickPeerURL() string {\r\n\tif len(m.PeerURLs) == 0 {\r\n\t\tpanic(\"member should always have some peer url\")\r\n\t}\r\n\treturn m.PeerURLs[rand.Intn(len(m.PeerURLs))]\r\n}","code-length":79,"reference":"\/\/ PickPeerURL chooses a random address from a given Member's PeerURLs.\n\/\/ It will panic if there is no PeerURLs available in Member.","result":"Pick a random peer.","score":[0.0039,0.0474]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HandleMetricsHealth(mux *http.ServeMux, srv etcdserver.ServerV2) {\r\n\tmux.Handle(PathMetrics, promhttp.Handler())\r\n\tmux.Handle(PathHealth, NewHealthHandler(func() Health { return checkHealth(srv) }))\r\n}","code-length":77,"reference":"\/\/ HandleMetricsHealth registers metrics and health handlers.","result":"Handle metrics and health.","score":[0.2134,0.2799]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRemoveCommand() cli.Command {\r\n\treturn cli.Command{\r\n\t\tName:      \"rm\",\r\n\t\tUsage:     \"remove a key or a directory\",\r\n\t\tArgsUsage: \"<key>\",\r\n\t\tFlags: []cli.Flag{\r\n\t\t\tcli.BoolFlag{Name: \"dir\", Usage: \"removes the key if it is an empty directory or a key-value pair\"},\r\n\t\t\tcli.BoolFlag{Name: \"recursive, r\", Usage: \"removes the key and all child keys(if it is a directory)\"},\r\n\t\t\tcli.StringFlag{Name: \"with-value\", Value: \"\", Usage: \"previous value\"},\r\n\t\t\tcli.IntFlag{Name: \"with-index\", Value: 0, Usage: \"previous index\"},\r\n\t\t},\r\n\t\tAction: func(c *cli.Context) error {\r\n\t\t\trmCommandFunc(c, mustNewKeyAPI(c))\r\n\t\t\treturn nil\r\n\t\t},\r\n\t}\r\n}","code-length":252,"reference":"\/\/ NewRemoveCommand returns the CLI command for \"rm\".","result":"Create a new key .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc rmCommandFunc(c *cli.Context, ki client.KeysAPI) {\r\n\tif len(c.Args()) == 0 {\r\n\t\thandleError(c, ExitBadArgs, errors.New(\"key required\"))\r\n\t}\r\n\tkey := c.Args()[0]\r\n\trecursive := c.Bool(\"recursive\")\r\n\tdir := c.Bool(\"dir\")\r\n\tprevValue := c.String(\"with-value\")\r\n\tprevIndex := c.Int(\"with-index\")\r\n\tctx, cancel := contextWithTotalTimeout(c)\r\n\tresp, err := ki.Delete(ctx, key, &client.DeleteOptions{PrevIndex: uint64(prevIndex), PrevValue: prevValue, Dir: dir, Recursive: recursive})\r\n\tcancel()\r\n\tif err != nil {\r\n\t\thandleError(c, ExitServerError, err)\r\n\t}\r\n\tif !resp.Node.Dir || c.GlobalString(\"output\") != \"simple\" {\r\n\t\tprintResponseKey(resp, c.GlobalString(\"output\"))\r\n\t}\r\n}","code-length":264,"reference":"\/\/ rmCommandFunc executes the \"rm\" command.","result":"Execute a command like.","score":[0,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkIntervals(reqs []*pb.RequestOp) (map[string]struct{}, adt.IntervalTree, error) {\r\n\tvar dels adt.IntervalTree\r\n\t\r\n\tfor _, req := range reqs {\r\n\t\ttv, ok := req.Request.(*pb.RequestOp_RequestDeleteRange)\r\n\t\tif !ok {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tdreq := tv.RequestDeleteRange\r\n\t\tif dreq == nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvar iv adt.Interval\r\n\t\tif len(dreq.RangeEnd) != 0 {\r\n\t\t\tiv = adt.NewStringAffineInterval(string(dreq.Key), string(dreq.RangeEnd))\r\n\t\t} else {\r\n\t\t\tiv = adt.NewStringAffinePoint(string(dreq.Key))\r\n\t\t}\r\n\t\tdels.Insert(iv, struct{}{})\r\n\t}\r\n\t\r\n\tputs := make(map[string]struct{})\r\n\tfor _, req := range reqs {\r\n\t\ttv, ok := req.Request.(*pb.RequestOp_RequestTxn)\r\n\t\tif !ok {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tputsThen, delsThen, err := checkIntervals(tv.RequestTxn.Success)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, dels, err\r\n\t\t}\r\n\t\tputsElse, delsElse, err := checkIntervals(tv.RequestTxn.Failure)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, dels, err\r\n\t\t}\r\n\t\tfor k := range putsThen {\r\n\t\t\tif _, ok := puts[k]; ok {\r\n\t\t\t\treturn nil, dels, rpctypes.ErrGRPCDuplicateKey\r\n\t\t\t}\r\n\t\t\tif dels.Intersects(adt.NewStringAffinePoint(k)) {\r\n\t\t\t\treturn nil, dels, rpctypes.ErrGRPCDuplicateKey\r\n\t\t\t}\r\n\t\t\tputs[k] = struct{}{}\r\n\t\t}\r\n\t\tfor k := range putsElse {\r\n\t\t\tif _, ok := puts[k]; ok {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tif _, isSafe := putsThen[k]; !isSafe {\r\n\t\t\t\t\treturn nil, dels, rpctypes.ErrGRPCDuplicateKey\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tif dels.Intersects(adt.NewStringAffinePoint(k)) {\r\n\t\t\t\treturn nil, dels, rpctypes.ErrGRPCDuplicateKey\r\n\t\t\t}\r\n\t\t\tputs[k] = struct{}{}\r\n\t\t}\r\n\t\tdels.Union(delsThen, adt.NewStringAffineInterval(\"\\x00\", \"\"))\r\n\t\tdels.Union(delsElse, adt.NewStringAffineInterval(\"\\x00\", \"\"))\r\n\t}\r\n\t\r\n\tfor _, req := range reqs {\r\n\t\ttv, ok := req.Request.(*pb.RequestOp_RequestPut)\r\n\t\tif !ok || tv.RequestPut == nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tk := string(tv.RequestPut.Key)\r\n\t\tif _, ok := puts[k]; ok {\r\n\t\t\treturn nil, dels, rpctypes.ErrGRPCDuplicateKey\r\n\t\t}\r\n\t\tif dels.Intersects(adt.NewStringAffinePoint(k)) {\r\n\t\t\treturn nil, dels, rpctypes.ErrGRPCDuplicateKey\r\n\t\t}\r\n\t\tputs[k] = struct{}{}\r\n\t}\r\n\treturn puts, dels, nil\r\n}","code-length":907,"reference":"\/\/ checkIntervals tests whether puts and deletes overlap for a list of ops. If\n\/\/ there is an overlap, returns an error. If no overlap, return put and delete\n\/\/ sets for recursive evaluation.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReportEventReceived(n int) {\r\n\tpendingEventsGauge.Sub(float64(n))\r\n\ttotalEventsCounter.Add(float64(n))\r\n}","code-length":49,"reference":"\/\/ ReportEventReceived reports that an event is received.\n\/\/ This function should be called when the external systems received an\n\/\/ event from mvcc.Watcher.","result":"Report event received.","score":[0.0004,0.0685]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterKVHandler(ctx context.Context, mux *runtime.ServeMux, conn *grpc.ClientConn) error {\r\n\treturn RegisterKVHandlerClient(ctx, mux, etcdserverpb.NewKVClient(conn))\r\n}","code-length":61,"reference":"\/\/ RegisterKVHandler registers the http handlers for service KV to \"mux\".\n\/\/ The handlers forward requests to the grpc endpoint over \"conn\".","result":"Register the handler.","score":[0.0007,0.0498]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterWatchHandler(ctx context.Context, mux *runtime.ServeMux, conn *grpc.ClientConn) error {\r\n\treturn RegisterWatchHandlerClient(ctx, mux, etcdserverpb.NewWatchClient(conn))\r\n}","code-length":61,"reference":"\/\/ RegisterWatchHandler registers the http handlers for service Watch to \"mux\".\n\/\/ The handlers forward requests to the grpc endpoint over \"conn\".","result":"Register the watch handler.","score":[0.0035,0.0743]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterLeaseHandler(ctx context.Context, mux *runtime.ServeMux, conn *grpc.ClientConn) error {\r\n\treturn RegisterLeaseHandlerClient(ctx, mux, etcdserverpb.NewLeaseClient(conn))\r\n}","code-length":61,"reference":"\/\/ RegisterLeaseHandler registers the http handlers for service Lease to \"mux\".\n\/\/ The handlers forward requests to the grpc endpoint over \"conn\".","result":"Register the lease handler.","score":[0.0035,0.0743]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterClusterHandler(ctx context.Context, mux *runtime.ServeMux, conn *grpc.ClientConn) error {\r\n\treturn RegisterClusterHandlerClient(ctx, mux, etcdserverpb.NewClusterClient(conn))\r\n}","code-length":61,"reference":"\/\/ RegisterClusterHandler registers the http handlers for service Cluster to \"mux\".\n\/\/ The handlers forward requests to the grpc endpoint over \"conn\".","result":"Register the cluster handler.","score":[0.0035,0.0743]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterMaintenanceHandler(ctx context.Context, mux *runtime.ServeMux, conn *grpc.ClientConn) error {\r\n\treturn RegisterMaintenanceHandlerClient(ctx, mux, etcdserverpb.NewMaintenanceClient(conn))\r\n}","code-length":61,"reference":"\/\/ RegisterMaintenanceHandler registers the http handlers for service Maintenance to \"mux\".\n\/\/ The handlers forward requests to the grpc endpoint over \"conn\".","result":"Register the maintenance handler.","score":[0.0035,0.0743]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterAuthHandler(ctx context.Context, mux *runtime.ServeMux, conn *grpc.ClientConn) error {\r\n\treturn RegisterAuthHandlerClient(ctx, mux, etcdserverpb.NewAuthClient(conn))\r\n}","code-length":61,"reference":"\/\/ RegisterAuthHandler registers the http handlers for service Auth to \"mux\".\n\/\/ The handlers forward requests to the grpc endpoint over \"conn\".","result":"Register the auth handler.","score":[0.0035,0.0743]}
{"code":"\/*is used to<extra_id_0>\r\nfunc startEtcd(cfg *embed.Config) (<-chan struct{}, <-chan error, error) {\r\n\te, err := embed.StartEtcd(cfg)\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\tosutil.RegisterInterruptHandler(e.Close)\r\n\tselect {\r\n\tcase <-e.Server.ReadyNotify():\r\n\tcase <-e.Server.StopNotify():\r\n\t}\r\n\treturn e.Server.StopNotify(), e.Err(), nil\r\n}","code-length":135,"reference":"\/\/ startEtcd runs StartEtcd in addition to hooks needed for standalone etcd.","result":"Start etcd server.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc identifyDataDirOrDie(lg *zap.Logger, dir string) dirType {\r\n\tnames, err := fileutil.ReadDir(dir)\r\n\tif err != nil {\r\n\t\tif os.IsNotExist(err) {\r\n\t\t\treturn dirEmpty\r\n\t\t}\r\n\t\tif lg != nil {\r\n\t\t\tlg.Fatal(\"failed to list data directory\", zap.String(\"dir\", dir), zap.Error(err))\r\n\t\t} else {\r\n\t\t\tplog.Fatalf(\"error listing data dir: %s\", dir)\r\n\t\t}\r\n\t}\r\n\tvar m, p bool\r\n\tfor _, name := range names {\r\n\t\tswitch dirType(name) {\r\n\t\tcase dirMember:\r\n\t\t\tm = true\r\n\t\tcase dirProxy:\r\n\t\t\tp = true\r\n\t\tdefault:\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"found invalid file under data directory\",\r\n\t\t\t\t\tzap.String(\"filename\", name),\r\n\t\t\t\t\tzap.String(\"data-dir\", dir),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Warningf(\"found invalid file\/dir %s under data dir %s (Ignore this if you are upgrading etcd)\", name, dir)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif m && p {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Fatal(\"invalid datadir; both member and proxy directories exist\")\r\n\t\t} else {\r\n\t\t\tplog.Fatal(\"invalid datadir. Both member and proxy directories exist.\")\r\n\t\t}\r\n\t}\r\n\tif m {\r\n\t\treturn dirMember\r\n\t}\r\n\tif p {\r\n\t\treturn dirProxy\r\n\t}\r\n\treturn dirEmpty\r\n}","code-length":451,"reference":"\/\/ identifyDataDirOrDie returns the type of the data dir.\n\/\/ Dies if the datadir is invalid.","result":"Identify the data directory.","score":[0.0225,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc openLast(lg *zap.Logger, dirpath string) (*fileutil.LockedFile, error) {\r\n\tnames, err := readWALNames(lg, dirpath)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tlast := filepath.Join(dirpath, names[len(names)-1])\r\n\treturn fileutil.LockFile(last, os.O_RDWR, fileutil.PrivateFileMode)\r\n}","code-length":119,"reference":"\/\/ openLast opens the last wal file for read and write.","result":"Open the last WAL file.","score":[0.1023,0.3816]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *leader) gotLeader() {\r\n\tl.mu.Lock()\r\n\tdefer l.mu.Unlock()\r\n\tselect {\r\n\tcase <-l.leaderc:\r\n\t\tl.leaderc = make(chan struct{})\r\n\tdefault:\r\n\t}\r\n}","code-length":80,"reference":"\/\/ gotLeader will force update the leadership status to having a leader.","result":"Detect when the leader is lost.","score":[0.071,0.0439]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *leader) lostNotify() <-chan struct{} {\r\n\tl.mu.RLock()\r\n\tdefer l.mu.RUnlock()\r\n\treturn l.leaderc\r\n}","code-length":55,"reference":"\/\/ lostNotify returns a channel that is closed if there has been\n\/\/ a leader loss not yet followed by a leader reacquire.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newGRPCProxyCommand() *cobra.Command {\r\n\tlpc := &cobra.Command{\r\n\t\tUse:   \"grpc-proxy <subcommand>\",\r\n\t\tShort: \"grpc-proxy related command\",\r\n\t}\r\n\tlpc.AddCommand(newGRPCProxyStartCommand())\r\n\treturn lpc\r\n}","code-length":92,"reference":"\/\/ newGRPCProxyCommand returns the cobra command for \"grpc-proxy\".","result":"Create a new command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMemberCommand() *cobra.Command {\r\n\tmc := &cobra.Command{\r\n\t\tUse:   \"member <subcommand>\",\r\n\t\tShort: \"Membership related commands\",\r\n\t}\r\n\tmc.AddCommand(NewMemberAddCommand())\r\n\tmc.AddCommand(NewMemberRemoveCommand())\r\n\tmc.AddCommand(NewMemberUpdateCommand())\r\n\tmc.AddCommand(NewMemberListCommand())\r\n\treturn mc\r\n}","code-length":122,"reference":"\/\/ NewMemberCommand returns the cobra command for \"member\".","result":"Create a member command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMemberAddCommand() *cobra.Command {\r\n\tcc := &cobra.Command{\r\n\t\tUse:   \"add <memberName> [options]\",\r\n\t\tShort: \"Adds a member into the cluster\",\r\n\t\tRun: memberAddCommandFunc,\r\n\t}\r\n\tcc.Flags().StringVar(&memberPeerURLs, \"peer-urls\", \"\", \"comma separated peer URLs for the new member.\")\r\n\treturn cc\r\n}","code-length":120,"reference":"\/\/ NewMemberAddCommand returns the cobra command for \"member add\".","result":"Create a new member.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMemberRemoveCommand() *cobra.Command {\r\n\tcc := &cobra.Command{\r\n\t\tUse:   \"remove <memberID>\",\r\n\t\tShort: \"Removes a member from the cluster\",\r\n\t\tRun: memberRemoveCommandFunc,\r\n\t}\r\n\treturn cc\r\n}","code-length":85,"reference":"\/\/ NewMemberRemoveCommand returns the cobra command for \"member remove\".","result":"Create a new member remove command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMemberUpdateCommand() *cobra.Command {\r\n\tcc := &cobra.Command{\r\n\t\tUse:   \"update <memberID> [options]\",\r\n\t\tShort: \"Updates a member in the cluster\",\r\n\t\tRun: memberUpdateCommandFunc,\r\n\t}\r\n\tcc.Flags().StringVar(&memberPeerURLs, \"peer-urls\", \"\", \"comma separated peer URLs for the updated member.\")\r\n\treturn cc\r\n}","code-length":120,"reference":"\/\/ NewMemberUpdateCommand returns the cobra command for \"member update\".","result":"Create a new member in the cluster.","score":[0.1214,0.0568]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMemberListCommand() *cobra.Command {\r\n\tcc := &cobra.Command{\r\n\t\tUse:   \"list\",\r\n\t\tShort: \"Lists all members in the cluster\",\r\n\t\tLong: `When --write-out is set to simple, this command prints out comma-separated member lists for each endpoint.\r\nThe items in the lists are ID, Status, Name, Peer Addrs, Client Addrs.\r\n`,\r\n\t\tRun: memberListCommandFunc,\r\n\t}\r\n\treturn cc\r\n}","code-length":136,"reference":"\/\/ NewMemberListCommand returns the cobra command for \"member list\".","result":"Create a new member list command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc memberAddCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) < 1 {\r\n\t\tExitWithError(ExitBadArgs, errors.New(\"member name not provided\"))\r\n\t}\r\n\tif len(args) > 1 {\r\n\t\tev := \"too many arguments\"\r\n\t\tfor _, s := range args {\r\n\t\t\tif strings.HasPrefix(strings.ToLower(s), \"http\") {\r\n\t\t\t\tev += fmt.Sprintf(`, did you mean --peer-urls=%s`, s)\r\n\t\t\t}\r\n\t\t}\r\n\t\tExitWithError(ExitBadArgs, errors.New(ev))\r\n\t}\r\n\tnewMemberName := args[0]\r\n\tif len(memberPeerURLs) == 0 {\r\n\t\tExitWithError(ExitBadArgs, errors.New(\"member peer urls not provided\"))\r\n\t}\r\n\turls := strings.Split(memberPeerURLs, \",\")\r\n\tctx, cancel := commandCtx(cmd)\r\n\tcli := mustClientFromCmd(cmd)\r\n\tresp, err := cli.MemberAdd(ctx, urls)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tnewID := resp.Member.ID\r\n\tdisplay.MemberAdd(*resp)\r\n\tif _, ok := (display).(*simplePrinter); ok {\r\n\t\tctx, cancel = commandCtx(cmd)\r\n\t\tlistResp, err := cli.MemberList(ctx)\r\n\t\t\r\n\t\tfor {\r\n\t\t\tif err != nil {\r\n\t\t\t\tExitWithError(ExitError, err)\r\n\t\t\t}\r\n\t\t\tif listResp.Header.MemberId == resp.Header.MemberId {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tgresp, gerr := cli.Get(ctx, \"_\")\r\n\t\t\tif gerr != nil {\r\n\t\t\t\tExitWithError(ExitError, err)\r\n\t\t\t}\r\n\t\t\tresp.Header.MemberId = gresp.Header.MemberId\r\n\t\t\tlistResp, err = cli.MemberList(ctx)\r\n\t\t}\r\n\t\tcancel()\r\n\t\tconf := []string{}\r\n\t\tfor _, memb := range listResp.Members {\r\n\t\t\tfor _, u := range memb.PeerURLs {\r\n\t\t\t\tn := memb.Name\r\n\t\t\t\tif memb.ID == newID {\r\n\t\t\t\t\tn = newMemberName\r\n\t\t\t\t}\r\n\t\t\t\tconf = append(conf, fmt.Sprintf(\"%s=%s\", n, u))\r\n\t\t\t}\r\n\t\t}\r\n\t\tfmt.Print(\"\\n\")\r\n\t\tfmt.Printf(\"ETCD_NAME=%q\\n\", newMemberName)\r\n\t\tfmt.Printf(\"ETCD_INITIAL_CLUSTER=%q\\n\", strings.Join(conf, \",\"))\r\n\t\tfmt.Printf(\"ETCD_INITIAL_ADVERTISE_PEER_URLS=%q\\n\", memberPeerURLs)\r\n\t\tfmt.Printf(\"ETCD_INITIAL_CLUSTER_STATE=\\\"existing\\\"\\n\")\r\n\t}\r\n}","code-length":764,"reference":"\/\/ memberAddCommandFunc executes the \"member add\" command.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc memberRemoveCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"member ID is not provided\"))\r\n\t}\r\n\tid, err := strconv.ParseUint(args[0], 16, 64)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"bad member ID arg (%v), expecting ID in Hex\", err))\r\n\t}\r\n\tctx, cancel := commandCtx(cmd)\r\n\tresp, err := mustClientFromCmd(cmd).MemberRemove(ctx, id)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.MemberRemove(id, *resp)\r\n}","code-length":204,"reference":"\/\/ memberRemoveCommandFunc executes the \"member remove\" command.","result":"Remove members from the cluster.","score":[0.1611,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc memberUpdateCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"member ID is not provided\"))\r\n\t}\r\n\tid, err := strconv.ParseUint(args[0], 16, 64)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"bad member ID arg (%v), expecting ID in Hex\", err))\r\n\t}\r\n\tif len(memberPeerURLs) == 0 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"member peer urls not provided\"))\r\n\t}\r\n\turls := strings.Split(memberPeerURLs, \",\")\r\n\tctx, cancel := commandCtx(cmd)\r\n\tresp, err := mustClientFromCmd(cmd).MemberUpdate(ctx, id, urls)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.MemberUpdate(id, *resp)\r\n}","code-length":260,"reference":"\/\/ memberUpdateCommandFunc executes the \"member update\" command.","result":"Update members.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc memberListCommandFunc(cmd *cobra.Command, args []string) {\r\n\tctx, cancel := commandCtx(cmd)\r\n\tresp, err := mustClientFromCmd(cmd).MemberList(ctx)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.MemberList(*resp)\r\n}","code-length":101,"reference":"\/\/ memberListCommandFunc executes the \"member list\" command.","result":"Generate the member list command.","score":[0.1915,0.1471]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Open(lg *zap.Logger, dirpath string, snap walpb.Snapshot) (*WAL, error) {\r\n\tw, err := openAtIndex(lg, dirpath, snap, true)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif w.dirFile, err = fileutil.OpenDir(w.dir); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn w, nil\r\n}","code-length":121,"reference":"\/\/ Open opens the WAL at the given snap.\n\/\/ The snap SHOULD have been previously saved to the WAL, or the following\n\/\/ ReadAll will fail.\n\/\/ The returned WAL is ready to read and the first record will be the one after\n\/\/ the given snap. The WAL cannot be appended to before reading out all of its\n\/\/ previous records.","result":"Open the WAL.","score":[0.0,0.0175]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OpenForRead(lg *zap.Logger, dirpath string, snap walpb.Snapshot) (*WAL, error) {\r\n\treturn openAtIndex(lg, dirpath, snap, false)\r\n}","code-length":56,"reference":"\/\/ OpenForRead only opens the wal files for read.\n\/\/ Write on a read only wal panics.","result":"Open directory for read.","score":[0.0175,0.1628]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Verify(lg *zap.Logger, walDir string, snap walpb.Snapshot) error {\r\n\tvar metadata []byte\r\n\tvar err error\r\n\tvar match bool\r\n\trec := &walpb.Record{}\r\n\tnames, nameIndex, err := selectWALFiles(lg, walDir, snap)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t\r\n\trs, _, closer, err := openWALFiles(lg, walDir, names, nameIndex, false)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tdecoder := newDecoder(rs...)\r\n\tfor err = decoder.decode(rec); err == nil; err = decoder.decode(rec) {\r\n\t\tswitch rec.Type {\r\n\t\tcase metadataType:\r\n\t\t\tif metadata != nil && !bytes.Equal(metadata, rec.Data) {\r\n\t\t\t\treturn ErrMetadataConflict\r\n\t\t\t}\r\n\t\t\tmetadata = rec.Data\r\n\t\tcase crcType:\r\n\t\t\tcrc := decoder.crc.Sum32()\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tif crc != 0 && rec.Validate(crc) != nil {\r\n\t\t\t\treturn ErrCRCMismatch\r\n\t\t\t}\r\n\t\t\tdecoder.updateCRC(rec.Crc)\r\n\t\tcase snapshotType:\r\n\t\t\tvar loadedSnap walpb.Snapshot\r\n\t\t\tpbutil.MustUnmarshal(&loadedSnap, rec.Data)\r\n\t\t\tif loadedSnap.Index == snap.Index {\r\n\t\t\t\tif loadedSnap.Term != snap.Term {\r\n\t\t\t\t\treturn ErrSnapshotMismatch\r\n\t\t\t\t}\r\n\t\t\t\tmatch = true\r\n\t\t\t}\r\n\t\t\r\n\t\t\r\n\t\tcase entryType:\r\n\t\tcase stateType:\r\n\t\tdefault:\r\n\t\t\treturn fmt.Errorf(\"unexpected block type %d\", rec.Type)\r\n\t\t}\r\n\t}\r\n\tif closer != nil {\r\n\t\tcloser()\r\n\t}\r\n\t\r\n\t\r\n\tif err != io.EOF && err != io.ErrUnexpectedEOF {\r\n\t\treturn err\r\n\t}\r\n\tif !match {\r\n\t\treturn ErrSnapshotNotFound\r\n\t}\r\n\treturn nil\r\n}","code-length":551,"reference":"\/\/ Verify reads through the given WAL and verifies that it is not corrupted.\n\/\/ It creates a new decoder to read through the records of the given WAL.\n\/\/ It does not conflict with any open WAL, but it is recommended not to\n\/\/ call this function after opening the WAL for writing.\n\/\/ If it cannot read out the expected snap, it will return ErrSnapshotNotFound.\n\/\/ If the loaded snap doesn't match with the expected one, it will\n\/\/ return error ErrSnapshotMismatch.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WAL) Close() error {\r\n\tw.mu.Lock()\r\n\tdefer w.mu.Unlock()\r\n\tif w.fp != nil {\r\n\t\tw.fp.Close()\r\n\t\tw.fp = nil\r\n\t}\r\n\tif w.tail() != nil {\r\n\t\tif err := w.sync(); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tfor _, l := range w.locks {\r\n\t\tif l == nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif err := l.Close(); err != nil {\r\n\t\t\tif w.lg != nil {\r\n\t\t\t\tw.lg.Warn(\"failed to close WAL\", zap.Error(err))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Errorf(\"failed to unlock during closing wal: %s\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn w.dirFile.Close()\r\n}","code-length":248,"reference":"\/\/ Close closes the current WAL file and directory.","result":"Close the WAL file.","score":[0.1205,0.1765]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *watcher) notify(e *Event, originalPath bool, deleted bool) bool {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif (w.recursive || originalPath || deleted) && e.Index() >= w.sinceIndex {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tselect {\r\n\t\tcase w.eventChan <- e:\r\n\t\tdefault:\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tw.remove()\r\n\t\t}\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":164,"reference":"\/\/ notify function notifies the watcher. If the watcher interests in the given path,\n\/\/ the function will return true.","result":"Notify watchers.","score":[0,0.0275]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *watcher) Remove() {\r\n\tw.hub.mutex.Lock()\r\n\tdefer w.hub.mutex.Unlock()\r\n\tclose(w.eventChan)\r\n\tif w.remove != nil {\r\n\t\tw.remove()\r\n\t}\r\n}","code-length":76,"reference":"\/\/ Remove removes the watcher from watcherHub\n\/\/ The actual remove function is guaranteed to only be executed once","result":"Remove the watcher.","score":[0.0023,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *v2v3Store) mkPathDepth(nodePath string, depth int) string {\r\n\tnormalForm := path.Clean(path.Join(\"\/\", nodePath))\r\n\tn := strings.Count(normalForm, \"\/\") + depth\r\n\treturn fmt.Sprintf(\"%s\/%03d\/k\/%s\", s.pfx, n, normalForm)\r\n}","code-length":97,"reference":"\/\/ mkPathDepth makes a path to a key that encodes its directory depth\n\/\/ for fast directory listing. If a depth is provided, it is added\n\/\/ to the computed depth.","result":"Create a new path.","score":[0.0004,0.0177]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *v2v3Store) mkV2Node(kv *mvccpb.KeyValue) *v2store.NodeExtern {\r\n\tif kv == nil {\r\n\t\treturn nil\r\n\t}\r\n\tn := &v2store.NodeExtern{\r\n\t\tKey:           s.mkNodePath(string(kv.Key)),\r\n\t\tDir:           kv.Key[len(kv.Key)-1] == '\/',\r\n\t\tCreatedIndex:  mkV2Rev(kv.CreateRevision),\r\n\t\tModifiedIndex: mkV2Rev(kv.ModRevision),\r\n\t}\r\n\tif !n.Dir {\r\n\t\tv := string(kv.Value)\r\n\t\tn.Value = &v\r\n\t}\r\n\treturn n\r\n}","code-length":195,"reference":"\/\/ mkV2Node creates a V2 NodeExtern from a V3 KeyValue","result":"Create a new node.","score":[0.0713,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc prevKeyFromPuts(resp *clientv3.TxnResponse) *mvccpb.KeyValue {\r\n\tfor _, r := range resp.Responses {\r\n\t\tpkv := r.GetResponsePut().PrevKv\r\n\t\tif pkv != nil && pkv.CreateRevision > 0 {\r\n\t\t\treturn pkv\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":102,"reference":"\/\/ prevKeyFromPuts gets the prev key that is being put; ignores\n\/\/ the put action response.","result":"Generate the code.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewWeightedReport(r Report, precision string) Report {\r\n\treturn &weightedReport{\r\n\t\tbaseReport: r,\r\n\t\treport:     newReport(precision),\r\n\t\tresults:    make(chan Result, 16),\r\n\t}\r\n}","code-length":73,"reference":"\/\/ NewWeightedReport returns a report that includes\n\/\/ both weighted and unweighted statistics.","result":"Create a new weighted report.","score":[0.0577,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewURLsMapFromStringMap(m map[string]string, sep string) (URLsMap, error) {\r\n\tvar err error\r\n\tum := URLsMap{}\r\n\tfor k, v := range m {\r\n\t\tum[k], err = NewURLs(strings.Split(v, sep))\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\treturn um, nil\r\n}","code-length":115,"reference":"\/\/ NewURLsMapFromStringMap takes a map of strings and returns a URLsMap. The\n\/\/ string values in the map can be multiple values separated by the sep string.","result":"Create a new URLSMap.","score":[0.001,0.0405]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c URLsMap) String() string {\r\n\tvar pairs []string\r\n\tfor name, urls := range c {\r\n\t\tfor _, url := range urls {\r\n\t\t\tpairs = append(pairs, fmt.Sprintf(\"%s=%s\", name, url.String()))\r\n\t\t}\r\n\t}\r\n\tsort.Strings(pairs)\r\n\treturn strings.Join(pairs, \",\")\r\n}","code-length":108,"reference":"\/\/ String turns URLsMap into discovery-formatted name-to-URLs sorted by name.","result":"Sort the URLsMap.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c URLsMap) URLs() []string {\r\n\tvar urls []string\r\n\tfor _, us := range c {\r\n\t\tfor _, u := range us {\r\n\t\t\turls = append(urls, u.String())\r\n\t\t}\r\n\t}\r\n\tsort.Strings(urls)\r\n\treturn urls\r\n}","code-length":90,"reference":"\/\/ URLs returns a list of all URLs.\n\/\/ The returned list is sorted in ascending lexicographical order.","result":"Generate the generated code.","score":[0,0.0301]}
{"code":"\/*is used to<extra_id_0>\r\nfunc parse(s string) map[string][]string {\r\n\tm := make(map[string][]string)\r\n\tfor s != \"\" {\r\n\t\tkey := s\r\n\t\tif i := strings.IndexAny(key, \",\"); i >= 0 {\r\n\t\t\tkey, s = key[:i], key[i+1:]\r\n\t\t} else {\r\n\t\t\ts = \"\"\r\n\t\t}\r\n\t\tif key == \"\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvalue := \"\"\r\n\t\tif i := strings.Index(key, \"=\"); i >= 0 {\r\n\t\t\tkey, value = key[:i], key[i+1:]\r\n\t\t}\r\n\t\tm[key] = append(m[key], value)\r\n\t}\r\n\treturn m\r\n}","code-length":205,"reference":"\/\/ parse parses the given string and returns a map listing the values specified for each key.","result":"Parse a string into a map of key.","score":[0.0758,0.2311]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClientHandler(lg *zap.Logger, server etcdserver.ServerPeer, timeout time.Duration) http.Handler {\r\n\tmux := http.NewServeMux()\r\n\tetcdhttp.HandleBasic(mux, server)\r\n\thandleV2(lg, mux, server, timeout)\r\n\treturn requestLogger(lg, mux)\r\n}","code-length":92,"reference":"\/\/ NewClientHandler generates a muxed http.Handler with the given parameters to serve etcd client requests.","result":"Create a new client handler.","score":[0.0387,0.0714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc writeKeyEvent(w http.ResponseWriter, resp etcdserver.Response, noValueOnSuccess bool) error {\r\n\tev := resp.Event\r\n\tif ev == nil {\r\n\t\treturn errors.New(\"cannot write empty Event\")\r\n\t}\r\n\tw.Header().Set(\"Content-Type\", \"application\/json\")\r\n\tw.Header().Set(\"X-Etcd-Index\", fmt.Sprint(ev.EtcdIndex))\r\n\tw.Header().Set(\"X-Raft-Index\", fmt.Sprint(resp.Index))\r\n\tw.Header().Set(\"X-Raft-Term\", fmt.Sprint(resp.Term))\r\n\tif ev.IsCreated() {\r\n\t\tw.WriteHeader(http.StatusCreated)\r\n\t}\r\n\tev = trimEventPrefix(ev, etcdserver.StoreKeysPrefix)\r\n\tif noValueOnSuccess &&\r\n\t\t(ev.Action == v2store.Set || ev.Action == v2store.CompareAndSwap ||\r\n\t\t\tev.Action == v2store.Create || ev.Action == v2store.Update) {\r\n\t\tev.Node = nil\r\n\t\tev.PrevNode = nil\r\n\t}\r\n\treturn json.NewEncoder(w).Encode(ev)\r\n}","code-length":309,"reference":"\/\/ writeKeyEvent trims the prefix of key path in a single Event under\n\/\/ StoreKeysPrefix, serializes it and writes the resulting JSON to the given\n\/\/ ResponseWriter, along with the appropriate headers.","result":"Write key events to the response.","score":[0.004,0.085]}
{"code":"\/*is used to<extra_id_0>\r\nfunc writeKeyError(lg *zap.Logger, w http.ResponseWriter, err error) {\r\n\tif err == nil {\r\n\t\treturn\r\n\t}\r\n\tswitch e := err.(type) {\r\n\tcase *v2error.Error:\r\n\t\te.WriteTo(w)\r\n\tdefault:\r\n\t\tswitch err {\r\n\t\tcase etcdserver.ErrTimeoutDueToLeaderFail, etcdserver.ErrTimeoutDueToConnectionLost:\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"v2 response error\",\r\n\t\t\t\t\tzap.String(\"internal-server-error\", err.Error()),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tmlog.MergeError(err)\r\n\t\t\t}\r\n\t\tdefault:\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"unexpected v2 response error\",\r\n\t\t\t\t\tzap.String(\"internal-server-error\", err.Error()),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tmlog.MergeErrorf(\"got unexpected response error (%v)\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t\tee := v2error.NewError(v2error.EcodeRaftInternal, err.Error(), 0)\r\n\t\tee.WriteTo(w)\r\n\t}\r\n}","code-length":338,"reference":"\/\/ writeKeyError logs and writes the given Error to the ResponseWriter.\n\/\/ If Error is not an etcdErr, the error will be converted to an etcd error.","result":"Write key errors to the response.","score":[0.0082,0.0803]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getUint64(form url.Values, key string) (i uint64, err error) {\r\n\tif vals, ok := form[key]; ok {\r\n\t\ti, err = strconv.ParseUint(vals[0], 10, 64)\r\n\t}\r\n\treturn\r\n}","code-length":77,"reference":"\/\/ getUint64 extracts a uint64 by the given key from a Form. If the key does\n\/\/ not exist in the form, 0 is returned. If the key exists but the value is\n\/\/ badly formed, an error is returned. If multiple values are present only the\n\/\/ first is considered.","result":"Parse the form values.","score":[0.0,0.0108]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getBool(form url.Values, key string) (b bool, err error) {\r\n\tif vals, ok := form[key]; ok {\r\n\t\tb, err = strconv.ParseBool(vals[0])\r\n\t}\r\n\treturn\r\n}","code-length":71,"reference":"\/\/ getBool extracts a bool by the given key from a Form. If the key does not\n\/\/ exist in the form, false is returned. If the key exists but the value is\n\/\/ badly formed, an error is returned. If multiple values are present only the\n\/\/ first is considered.","result":"Parse the form values.","score":[0.0,0.0108]}
{"code":"\/*is used to<extra_id_0>\r\nfunc waitDeletes(ctx context.Context, client *v3.Client, pfx string, maxCreateRev int64) (*pb.ResponseHeader, error) {\r\n\tgetOpts := append(v3.WithLastCreate(), v3.WithMaxCreateRev(maxCreateRev))\r\n\tfor {\r\n\t\tresp, err := client.Get(ctx, pfx, getOpts...)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tif len(resp.Kvs) == 0 {\r\n\t\t\treturn resp.Header, nil\r\n\t\t}\r\n\t\tlastKey := string(resp.Kvs[0].Key)\r\n\t\tif err = waitDelete(ctx, client, lastKey, resp.Header.Revision); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n}","code-length":211,"reference":"\/\/ waitDeletes efficiently waits until all keys matching the prefix and no greater\n\/\/ than the create revision.","result":"Wait for deletes to be deleted.","score":[0,0.0298]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AddOutputPaths(cfg zap.Config, outputPaths, errorOutputPaths []string) zap.Config {\r\n\toutputs := make(map[string]struct{})\r\n\tfor _, v := range cfg.OutputPaths {\r\n\t\toutputs[v] = struct{}{}\r\n\t}\r\n\tfor _, v := range outputPaths {\r\n\t\toutputs[v] = struct{}{}\r\n\t}\r\n\toutputSlice := make([]string, 0)\r\n\tif _, ok := outputs[\"\/dev\/null\"]; ok {\r\n\t\t\r\n\t\toutputSlice = []string{\"\/dev\/null\"}\r\n\t} else {\r\n\t\tfor k := range outputs {\r\n\t\t\toutputSlice = append(outputSlice, k)\r\n\t\t}\r\n\t}\r\n\tcfg.OutputPaths = outputSlice\r\n\tsort.Strings(cfg.OutputPaths)\r\n\terrOutputs := make(map[string]struct{})\r\n\tfor _, v := range cfg.ErrorOutputPaths {\r\n\t\terrOutputs[v] = struct{}{}\r\n\t}\r\n\tfor _, v := range errorOutputPaths {\r\n\t\terrOutputs[v] = struct{}{}\r\n\t}\r\n\terrOutputSlice := make([]string, 0)\r\n\tif _, ok := errOutputs[\"\/dev\/null\"]; ok {\r\n\t\t\r\n\t\terrOutputSlice = []string{\"\/dev\/null\"}\r\n\t} else {\r\n\t\tfor k := range errOutputs {\r\n\t\t\terrOutputSlice = append(errOutputSlice, k)\r\n\t\t}\r\n\t}\r\n\tcfg.ErrorOutputPaths = errOutputSlice\r\n\tsort.Strings(cfg.ErrorOutputPaths)\r\n\treturn cfg\r\n}","code-length":420,"reference":"\/\/ AddOutputPaths adds output paths to the existing output paths, resolving conflicts.","result":"Add output paths to the config.","score":[0.2223,0.3912]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewConfig() *Config {\r\n\tlpurl, _ := url.Parse(DefaultListenPeerURLs)\r\n\tapurl, _ := url.Parse(DefaultInitialAdvertisePeerURLs)\r\n\tlcurl, _ := url.Parse(DefaultListenClientURLs)\r\n\tacurl, _ := url.Parse(DefaultAdvertiseClientURLs)\r\n\tcfg := &Config{\r\n\t\tMaxSnapFiles: DefaultMaxSnapshots,\r\n\t\tMaxWalFiles:  DefaultMaxWALs,\r\n\t\tName: DefaultName,\r\n\t\tSnapshotCount:          etcdserver.DefaultSnapshotCount,\r\n\t\tSnapshotCatchUpEntries: etcdserver.DefaultSnapshotCatchUpEntries,\r\n\t\tMaxTxnOps:       DefaultMaxTxnOps,\r\n\t\tMaxRequestBytes: DefaultMaxRequestBytes,\r\n\t\tGRPCKeepAliveMinTime:  DefaultGRPCKeepAliveMinTime,\r\n\t\tGRPCKeepAliveInterval: DefaultGRPCKeepAliveInterval,\r\n\t\tGRPCKeepAliveTimeout:  DefaultGRPCKeepAliveTimeout,\r\n\t\tTickMs:                     100,\r\n\t\tElectionMs:                 1000,\r\n\t\tInitialElectionTickAdvance: true,\r\n\t\tLPUrls: []url.URL{*lpurl},\r\n\t\tLCUrls: []url.URL{*lcurl},\r\n\t\tAPUrls: []url.URL{*apurl},\r\n\t\tACUrls: []url.URL{*acurl},\r\n\t\tClusterState:        ClusterStateFlagNew,\r\n\t\tInitialClusterToken: \"etcd-cluster\",\r\n\t\tStrictReconfigCheck: DefaultStrictReconfigCheck,\r\n\t\tMetrics:             \"basic\",\r\n\t\tEnableV2:            DefaultEnableV2,\r\n\t\tCORS:          map[string]struct{}{\"*\": {}},\r\n\t\tHostWhitelist: map[string]struct{}{\"*\": {}},\r\n\t\tAuthToken:  \"simple\",\r\n\t\tBcryptCost: uint(bcrypt.DefaultCost),\r\n\t\tPreVote: false,\r\n\t\tloggerMu:            new(sync.RWMutex),\r\n\t\tlogger:              nil,\r\n\t\tLogger:              \"capnslog\",\r\n\t\tDeprecatedLogOutput: []string{DefaultLogOutput},\r\n\t\tLogOutputs:          []string{DefaultLogOutput},\r\n\t\tDebug:               false,\r\n\t\tLogPkgLevels:        \"\",\r\n\t}\r\n\tcfg.InitialCluster = cfg.InitialClusterFromName(cfg.Name)\r\n\treturn cfg\r\n}","code-length":602,"reference":"\/\/ NewConfig creates a new Config populated with default values.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cfg *Config) PeerURLsMapAndToken(which string) (urlsmap types.URLsMap, token string, err error) {\r\n\ttoken = cfg.InitialClusterToken\r\n\tswitch {\r\n\tcase cfg.Durl != \"\":\r\n\t\turlsmap = types.URLsMap{}\r\n\t\t\r\n\t\t\r\n\t\turlsmap[cfg.Name] = cfg.APUrls\r\n\t\ttoken = cfg.Durl\r\n\tcase cfg.DNSCluster != \"\":\r\n\t\tclusterStrs, cerr := cfg.GetDNSClusterNames()\r\n\t\tlg := cfg.logger\r\n\t\tif cerr != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\"failed to resolve during SRV discovery\", zap.Error(cerr))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Errorf(\"couldn't resolve during SRV discovery (%v)\", cerr)\r\n\t\t\t}\r\n\t\t\treturn nil, \"\", cerr\r\n\t\t}\r\n\t\tfor _, s := range clusterStrs {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Info(\"got bootstrap from DNS for etcd-server\", zap.String(\"node\", s))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Noticef(\"got bootstrap from DNS for etcd-server at %s\", s)\r\n\t\t\t}\r\n\t\t}\r\n\t\tclusterStr := strings.Join(clusterStrs, \",\")\r\n\t\tif strings.Contains(clusterStr, \"https:\r\n\t\t\tcfg.PeerTLSInfo.ServerName = cfg.DNSCluster\r\n\t\t}\r\n\t\turlsmap, err = types.NewURLsMap(clusterStr)\r\n\t\t\r\n\t\t\r\n\t\tif which == \"etcd\" {\r\n\t\t\tif _, ok := urlsmap[cfg.Name]; !ok {\r\n\t\t\t\treturn nil, \"\", fmt.Errorf(\"cannot find local etcd member %q in SRV records\", cfg.Name)\r\n\t\t\t}\r\n\t\t}\r\n\tdefault:\r\n\t\t\r\n\t\turlsmap, err = types.NewURLsMap(cfg.InitialCluster)\r\n\t}\r\n\treturn urlsmap, token, err\r\n}","code-length":513,"reference":"\/\/ PeerURLsMapAndToken sets up an initial peer URLsMap and cluster token for bootstrap or discovery.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cfg *Config) GetDNSClusterNames() ([]string, error) {\r\n\tvar (\r\n\t\tclusterStrs       []string\r\n\t\tcerr              error\r\n\t\tserviceNameSuffix string\r\n\t)\r\n\tif cfg.DNSClusterServiceName != \"\" {\r\n\t\tserviceNameSuffix = \"-\" + cfg.DNSClusterServiceName\r\n\t}\r\n\tlg := cfg.GetLogger()\r\n\t\r\n\t\r\n\tclusterStrs, cerr = srv.GetCluster(\"https\", \"etcd-server-ssl\"+serviceNameSuffix, cfg.Name, cfg.DNSCluster, cfg.APUrls)\r\n\tif cerr != nil {\r\n\t\tclusterStrs = make([]string, 0)\r\n\t}\r\n\tif lg != nil {\r\n\t\tlg.Info(\r\n\t\t\t\"get cluster for etcd-server-ssl SRV\",\r\n\t\t\tzap.String(\"service-scheme\", \"https\"),\r\n\t\t\tzap.String(\"service-name\", \"etcd-server-ssl\"+serviceNameSuffix),\r\n\t\t\tzap.String(\"server-name\", cfg.Name),\r\n\t\t\tzap.String(\"discovery-srv\", cfg.DNSCluster),\r\n\t\t\tzap.Strings(\"advertise-peer-urls\", cfg.getAPURLs()),\r\n\t\t\tzap.Strings(\"found-cluster\", clusterStrs),\r\n\t\t\tzap.Error(cerr),\r\n\t\t)\r\n\t}\r\n\tdefaultHTTPClusterStrs, httpCerr := srv.GetCluster(\"http\", \"etcd-server\"+serviceNameSuffix, cfg.Name, cfg.DNSCluster, cfg.APUrls)\r\n\tif httpCerr != nil {\r\n\t\tclusterStrs = append(clusterStrs, defaultHTTPClusterStrs...)\r\n\t}\r\n\tif lg != nil {\r\n\t\tlg.Info(\r\n\t\t\t\"get cluster for etcd-server SRV\",\r\n\t\t\tzap.String(\"service-scheme\", \"http\"),\r\n\t\t\tzap.String(\"service-name\", \"etcd-server\"+serviceNameSuffix),\r\n\t\t\tzap.String(\"server-name\", cfg.Name),\r\n\t\t\tzap.String(\"discovery-srv\", cfg.DNSCluster),\r\n\t\t\tzap.Strings(\"advertise-peer-urls\", cfg.getAPURLs()),\r\n\t\t\tzap.Strings(\"found-cluster\", clusterStrs),\r\n\t\t\tzap.Error(httpCerr),\r\n\t\t)\r\n\t}\r\n\treturn clusterStrs, cerr\r\n}","code-length":593,"reference":"\/\/ GetDNSClusterNames uses DNS SRV records to get a list of initial nodes for cluster bootstrapping.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkBindURLs(urls []url.URL) error {\r\n\tfor _, url := range urls {\r\n\t\tif url.Scheme == \"unix\" || url.Scheme == \"unixs\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\thost, _, err := net.SplitHostPort(url.Host)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif host == \"localhost\" {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif net.ParseIP(host) == nil {\r\n\t\t\treturn fmt.Errorf(\"expected IP in URL for binding (%s)\", url.String())\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":186,"reference":"\/\/ checkBindURLs returns an error if any URL uses a domain name.","result":"Check bind URLs.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetCluster(serviceScheme, service, name, dns string, apurls types.URLs) ([]string, error) {\r\n\ttempName := int(0)\r\n\ttcp2ap := make(map[string]url.URL)\r\n\t\r\n\tfor _, url := range apurls {\r\n\t\ttcpAddr, err := resolveTCPAddr(\"tcp\", url.Host)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\ttcp2ap[tcpAddr.String()] = url\r\n\t}\r\n\tstringParts := []string{}\r\n\tupdateNodeMap := func(service, scheme string) error {\r\n\t\t_, addrs, err := lookupSRV(service, \"tcp\", dns)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tfor _, srv := range addrs {\r\n\t\t\tport := fmt.Sprintf(\"%d\", srv.Port)\r\n\t\t\thost := net.JoinHostPort(srv.Target, port)\r\n\t\t\ttcpAddr, terr := resolveTCPAddr(\"tcp\", host)\r\n\t\t\tif terr != nil {\r\n\t\t\t\terr = terr\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tn := \"\"\r\n\t\t\turl, ok := tcp2ap[tcpAddr.String()]\r\n\t\t\tif ok {\r\n\t\t\t\tn = name\r\n\t\t\t}\r\n\t\t\tif n == \"\" {\r\n\t\t\t\tn = fmt.Sprintf(\"%d\", tempName)\r\n\t\t\t\ttempName++\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tshortHost := strings.TrimSuffix(srv.Target, \".\")\r\n\t\t\turlHost := net.JoinHostPort(shortHost, port)\r\n\t\t\tif ok && url.Scheme != scheme {\r\n\t\t\t\terr = fmt.Errorf(\"bootstrap at %s from DNS for %s has scheme mismatch with expected peer %s\", scheme+\":\r\n\t\t\t} else {\r\n\t\t\t\tstringParts = append(stringParts, fmt.Sprintf(\"%s=%s:\r\n\t\t\t}\r\n\t\t}\r\n\t\tif len(stringParts) == 0 {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\terr := updateNodeMap(service, serviceScheme)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error querying DNS SRV records for _%s %s\", service, err)\r\n\t}\r\n\treturn stringParts, nil\r\n}","code-length":594,"reference":"\/\/ GetCluster gets the cluster information via DNS discovery.\n\/\/ Also sees each entry as a separate instance.","result":"Code too long,keep in 512.","score":[0,0.0299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetClient(service, domain string, serviceName string) (*SRVClients, error) {\r\n\tvar urls []*url.URL\r\n\tvar srvs []*net.SRV\r\n\tupdateURLs := func(service, scheme string) error {\r\n\t\t_, addrs, err := lookupSRV(service, \"tcp\", domain)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tfor _, srv := range addrs {\r\n\t\t\turls = append(urls, &url.URL{\r\n\t\t\t\tScheme: scheme,\r\n\t\t\t\tHost:   net.JoinHostPort(srv.Target, fmt.Sprintf(\"%d\", srv.Port)),\r\n\t\t\t})\r\n\t\t}\r\n\t\tsrvs = append(srvs, addrs...)\r\n\t\treturn nil\r\n\t}\r\n\terrHTTPS := updateURLs(GetSRVService(service, serviceName, \"https\"), \"https\")\r\n\terrHTTP := updateURLs(GetSRVService(service, serviceName, \"http\"), \"http\")\r\n\tif errHTTPS != nil && errHTTP != nil {\r\n\t\treturn nil, fmt.Errorf(\"dns lookup errors: %s and %s\", errHTTPS, errHTTP)\r\n\t}\r\n\tendpoints := make([]string, len(urls))\r\n\tfor i := range urls {\r\n\t\tendpoints[i] = urls[i].String()\r\n\t}\r\n\treturn &SRVClients{Endpoints: endpoints, SRVs: srvs}, nil\r\n}","code-length":365,"reference":"\/\/ GetClient looks up the client endpoints for a service and domain.","result":"Get the client from the DNS server.","score":[0.1118,0.087]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetSRVService(service, serviceName string, scheme string) (SRVService string) {\r\n\tif scheme == \"https\" {\r\n\t\tservice = fmt.Sprintf(\"%s-ssl\", service)\r\n\t}\r\n\tif serviceName != \"\" {\r\n\t\treturn fmt.Sprintf(\"%s-%s\", service, serviceName)\r\n\t}\r\n\treturn service\r\n}","code-length":99,"reference":"\/\/ GetSRVService generates a SRV service including an optional suffix.","result":"Get the SRV service.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReadDir(d string, opts ...ReadDirOption) ([]string, error) {\r\n\top := &ReadDirOp{}\r\n\top.applyOpts(opts)\r\n\tdir, err := os.Open(d)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer dir.Close()\r\n\tnames, err := dir.Readdirnames(-1)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tsort.Strings(names)\r\n\tif op.ext != \"\" {\r\n\t\ttss := make([]string, 0)\r\n\t\tfor _, v := range names {\r\n\t\t\tif filepath.Ext(v) == op.ext {\r\n\t\t\t\ttss = append(tss, v)\r\n\t\t\t}\r\n\t\t}\r\n\t\tnames = tss\r\n\t}\r\n\treturn names, nil\r\n}","code-length":232,"reference":"\/\/ ReadDir returns the filenames in the given directory in sorted order.","result":"Read a directory.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc compact(c *v3.Client, rev int64) {\r\n\tfmt.Printf(\"Compacting with revision %d\\n\", rev)\r\n\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\r\n\t_, err := c.Compact(ctx, rev, v3.WithCompactPhysical())\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tfmt.Printf(\"Compacted with revision %d\\n\", rev)\r\n}","code-length":136,"reference":"\/\/ compact keyspace history to a provided revision","result":"Compact the revision.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc defrag(c *v3.Client, ep string) {\r\n\tfmt.Printf(\"Defragmenting %q\\n\", ep)\r\n\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\r\n\t_, err := c.Defragment(ctx, ep)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tfmt.Printf(\"Defragmented %q\\n\", ep)\r\n}","code-length":128,"reference":"\/\/ defrag a given endpoint","result":"Avoid the need for v.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewUserCommand() *cobra.Command {\r\n\tac := &cobra.Command{\r\n\t\tUse:   \"user <subcommand>\",\r\n\t\tShort: \"User related commands\",\r\n\t}\r\n\tac.AddCommand(newUserAddCommand())\r\n\tac.AddCommand(newUserDeleteCommand())\r\n\tac.AddCommand(newUserGetCommand())\r\n\tac.AddCommand(newUserListCommand())\r\n\tac.AddCommand(newUserChangePasswordCommand())\r\n\tac.AddCommand(newUserGrantRoleCommand())\r\n\tac.AddCommand(newUserRevokeRoleCommand())\r\n\treturn ac\r\n}","code-length":164,"reference":"\/\/ NewUserCommand returns the cobra command for \"user\".","result":"Generate the user command.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc userAddCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"user add command requires user name as its argument\"))\r\n\t}\r\n\tvar password string\r\n\tvar user string\r\n\tif passwordFromFlag != \"\" {\r\n\t\tuser = args[0]\r\n\t\tpassword = passwordFromFlag\r\n\t} else {\r\n\t\tsplitted := strings.SplitN(args[0], \":\", 2)\r\n\t\tif len(splitted) < 2 {\r\n\t\t\tuser = args[0]\r\n\t\t\tif !passwordInteractive {\r\n\t\t\t\tfmt.Scanf(\"%s\", &password)\r\n\t\t\t} else {\r\n\t\t\t\tpassword = readPasswordInteractive(args[0])\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\tuser = splitted[0]\r\n\t\t\tpassword = splitted[1]\r\n\t\t\tif len(user) == 0 {\r\n\t\t\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"empty user name is not allowed\"))\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tresp, err := mustClientFromCmd(cmd).Auth.UserAdd(context.TODO(), user, password)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.UserAdd(user, *resp)\r\n}","code-length":351,"reference":"\/\/ userAddCommandFunc executes the \"user add\" command.","result":"Var userAddCommandFunc userAddCommandFunc.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc userGetCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"user get command requires user name as its argument\"))\r\n\t}\r\n\tname := args[0]\r\n\tclient := mustClientFromCmd(cmd)\r\n\tresp, err := client.Auth.UserGet(context.TODO(), name)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tif userShowDetail {\r\n\t\tfmt.Printf(\"User: %s\\n\", name)\r\n\t\tfor _, role := range resp.Roles {\r\n\t\t\tfmt.Printf(\"\\n\")\r\n\t\t\troleResp, err := client.Auth.RoleGet(context.TODO(), role)\r\n\t\t\tif err != nil {\r\n\t\t\t\tExitWithError(ExitError, err)\r\n\t\t\t}\r\n\t\t\tdisplay.RoleGet(role, *roleResp)\r\n\t\t}\r\n\t} else {\r\n\t\tdisplay.UserGet(name, *resp)\r\n\t}\r\n}","code-length":278,"reference":"\/\/ userGetCommandFunc executes the \"user get\" command.","result":"Generate the user get command.","score":[0.1915,0.1471]}
{"code":"\/*is used to<extra_id_0>\r\nfunc userChangePasswordCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"user passwd command requires user name as its argument\"))\r\n\t}\r\n\tvar password string\r\n\tif !passwordInteractive {\r\n\t\tfmt.Scanf(\"%s\", &password)\r\n\t} else {\r\n\t\tpassword = readPasswordInteractive(args[0])\r\n\t}\r\n\tresp, err := mustClientFromCmd(cmd).Auth.UserChangePassword(context.TODO(), args[0], password)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.UserChangePassword(*resp)\r\n}","code-length":190,"reference":"\/\/ userChangePasswordCommandFunc executes the \"user passwd\" command.","result":"Change password.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (eh *EventHistory) addEvent(e *Event) *Event {\r\n\teh.rwl.Lock()\r\n\tdefer eh.rwl.Unlock()\r\n\teh.Queue.insert(e)\r\n\teh.LastIndex = e.Index()\r\n\teh.StartIndex = eh.Queue.Events[eh.Queue.Front].Index()\r\n\treturn e\r\n}","code-length":104,"reference":"\/\/ addEvent function adds event into the eventHistory","result":"Add events to the event history.","score":[0.1645,0.1923]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (eh *EventHistory) scan(key string, recursive bool, index uint64) (*Event, *v2error.Error) {\r\n\teh.rwl.RLock()\r\n\tdefer eh.rwl.RUnlock()\r\n\t\r\n\tif index < eh.StartIndex {\r\n\t\treturn nil,\r\n\t\t\tv2error.NewError(v2error.EcodeEventIndexCleared,\r\n\t\t\t\tfmt.Sprintf(\"the requested history has been cleared [%v\/%v]\",\r\n\t\t\t\t\teh.StartIndex, index), 0)\r\n\t}\r\n\t\r\n\tif index > eh.LastIndex {\r\n\t\treturn nil, nil\r\n\t}\r\n\toffset := index - eh.StartIndex\r\n\ti := (eh.Queue.Front + int(offset)) % eh.Queue.Capacity\r\n\tfor {\r\n\t\te := eh.Queue.Events[i]\r\n\t\tif !e.Refresh {\r\n\t\t\tok := e.Node.Key == key\r\n\t\t\tif recursive {\r\n\t\t\t\t\r\n\t\t\t\tnkey := path.Clean(key)\r\n\t\t\t\tif nkey[len(nkey)-1] != '\/' {\r\n\t\t\t\t\tnkey = nkey + \"\/\"\r\n\t\t\t\t}\r\n\t\t\t\tok = ok || strings.HasPrefix(e.Node.Key, nkey)\r\n\t\t\t}\r\n\t\t\tif (e.Action == Delete || e.Action == Expire) && e.PrevNode != nil && e.PrevNode.Dir {\r\n\t\t\t\tok = ok || strings.HasPrefix(key, e.PrevNode.Key)\r\n\t\t\t}\r\n\t\t\tif ok {\r\n\t\t\t\treturn e, nil\r\n\t\t\t}\r\n\t\t}\r\n\t\ti = (i + 1) % eh.Queue.Capacity\r\n\t\tif i == eh.Queue.Back {\r\n\t\t\treturn nil, nil\r\n\t\t}\r\n\t}\r\n}","code-length":466,"reference":"\/\/ scan enumerates events from the index history and stops at the first point\n\/\/ where the key matches.","result":"Scan the event history .","score":[0.0174,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (eh *EventHistory) clone() *EventHistory {\r\n\tclonedQueue := eventQueue{\r\n\t\tCapacity: eh.Queue.Capacity,\r\n\t\tEvents:   make([]*Event, eh.Queue.Capacity),\r\n\t\tSize:     eh.Queue.Size,\r\n\t\tFront:    eh.Queue.Front,\r\n\t\tBack:     eh.Queue.Back,\r\n\t}\r\n\tcopy(clonedQueue.Events, eh.Queue.Events)\r\n\treturn &EventHistory{\r\n\t\tStartIndex: eh.StartIndex,\r\n\t\tQueue:      clonedQueue,\r\n\t\tLastIndex:  eh.LastIndex,\r\n\t}\r\n}","code-length":171,"reference":"\/\/ clone will be protected by a stop-world lock\n\/\/ do not need to obtain internal lock","result":"Clone the event history.","score":[0,0.0318]}
{"code":"\/*is used to<extra_id_0>\r\nfunc openSnapshotBackend(cfg ServerConfig, ss *snap.Snapshotter, snapshot raftpb.Snapshot) (backend.Backend, error) {\r\n\tsnapPath, err := ss.DBFilePath(snapshot.Metadata.Index)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to find database snapshot file (%v)\", err)\r\n\t}\r\n\tif err := os.Rename(snapPath, cfg.backendPath()); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to rename database snapshot file (%v)\", err)\r\n\t}\r\n\treturn openBackend(cfg), nil\r\n}","code-length":155,"reference":"\/\/ openSnapshotBackend renames a snapshot db to the current etcd db and opens it.","result":"Open a snapshot backend.","score":[0.0371,0.1966]}
{"code":"\/*is used to<extra_id_0>\r\nfunc openBackend(cfg ServerConfig) backend.Backend {\r\n\tfn := cfg.backendPath()\r\n\tnow, beOpened := time.Now(), make(chan backend.Backend)\r\n\tgo func() {\r\n\t\tbeOpened <- newBackend(cfg)\r\n\t}()\r\n\tselect {\r\n\tcase be := <-beOpened:\r\n\t\tif cfg.Logger != nil {\r\n\t\t\tcfg.Logger.Info(\"opened backend db\", zap.String(\"path\", fn), zap.Duration(\"took\", time.Since(now)))\r\n\t\t}\r\n\t\treturn be\r\n\tcase <-time.After(10 * time.Second):\r\n\t\tif cfg.Logger != nil {\r\n\t\t\tcfg.Logger.Info(\r\n\t\t\t\t\"db file is flocked by another process, or taking too long\",\r\n\t\t\t\tzap.String(\"path\", fn),\r\n\t\t\t\tzap.Duration(\"took\", time.Since(now)),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Warningf(\"another etcd process is using %q and holds the file lock, or loading backend file is taking >10 seconds\", fn)\r\n\t\t\tplog.Warningf(\"waiting for it to exit before starting...\")\r\n\t\t}\r\n\t}\r\n\treturn <-beOpened\r\n}","code-length":319,"reference":"\/\/ openBackend returns a backend using the current etcd db.","result":"Open backend db file.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc recoverSnapshotBackend(cfg ServerConfig, oldbe backend.Backend, snapshot raftpb.Snapshot) (backend.Backend, error) {\r\n\tvar cIndex consistentIndex\r\n\tkv := mvcc.New(cfg.Logger, oldbe, &lease.FakeLessor{}, &cIndex)\r\n\tdefer kv.Close()\r\n\tif snapshot.Metadata.Index <= kv.ConsistentIndex() {\r\n\t\treturn oldbe, nil\r\n\t}\r\n\toldbe.Close()\r\n\treturn openSnapshotBackend(cfg, snap.New(cfg.Logger, cfg.SnapDir()), snapshot)\r\n}","code-length":150,"reference":"\/\/ recoverBackendSnapshot recovers the DB from a snapshot in case etcd crashes\n\/\/ before updating the backend db after persisting raft snapshot to disk,\n\/\/ violating the invariant snapshot.Metadata.Index < db.consistentIndex. In this\n\/\/ case, replace the db with the snapshot db sent by the leader.","result":"Recover the backend from a snapshot.","score":[0.0005,0.0886]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewUpdateCommand() cli.Command {\r\n\treturn cli.Command{\r\n\t\tName:      \"update\",\r\n\t\tUsage:     \"update an existing key with a given value\",\r\n\t\tArgsUsage: \"<key> <value>\",\r\n\t\tFlags: []cli.Flag{\r\n\t\t\tcli.IntFlag{Name: \"ttl\", Value: 0, Usage: \"key time-to-live in seconds\"},\r\n\t\t},\r\n\t\tAction: func(c *cli.Context) error {\r\n\t\t\tupdateCommandFunc(c, mustNewKeyAPI(c))\r\n\t\t\treturn nil\r\n\t\t},\r\n\t}\r\n}","code-length":165,"reference":"\/\/ NewUpdateCommand returns the CLI command for \"update\".","result":"Update the value of a key.","score":[0.1383,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc updateCommandFunc(c *cli.Context, ki client.KeysAPI) {\r\n\tif len(c.Args()) == 0 {\r\n\t\thandleError(c, ExitBadArgs, errors.New(\"key required\"))\r\n\t}\r\n\tkey := c.Args()[0]\r\n\tvalue, err := argOrStdin(c.Args(), os.Stdin, 1)\r\n\tif err != nil {\r\n\t\thandleError(c, ExitBadArgs, errors.New(\"value required\"))\r\n\t}\r\n\tttl := c.Int(\"ttl\")\r\n\tctx, cancel := contextWithTotalTimeout(c)\r\n\tresp, err := ki.Set(ctx, key, value, &client.SetOptions{TTL: time.Duration(ttl) * time.Second, PrevExist: client.PrevExist})\r\n\tcancel()\r\n\tif err != nil {\r\n\t\thandleError(c, ExitServerError, err)\r\n\t}\r\n\tprintResponseKey(resp, c.GlobalString(\"output\"))\r\n}","code-length":253,"reference":"\/\/ updateCommandFunc executes the \"update\" command.","result":"Update a key.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *statsQueue) frontAndBack() (*RequestStats, *RequestStats) {\r\n\tq.rwl.RLock()\r\n\tdefer q.rwl.RUnlock()\r\n\tif q.size != 0 {\r\n\t\treturn q.items[q.front], q.items[q.back]\r\n\t}\r\n\treturn nil, nil\r\n}","code-length":98,"reference":"\/\/ FrontAndBack gets the front and back elements in the queue\n\/\/ We must grab front and back together with the protection of the lock","result":"Get the front and back stats from the queue.","score":[0.0682,0.2184]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *statsQueue) Insert(p *RequestStats) {\r\n\tq.rwl.Lock()\r\n\tdefer q.rwl.Unlock()\r\n\tq.back = (q.back + 1) % queueCapacity\r\n\tif q.size == queueCapacity {\r\n\t\tq.totalReqSize -= q.items[q.front].Size\r\n\t\tq.front = (q.back + 1) % queueCapacity\r\n\t} else {\r\n\t\tq.size++\r\n\t}\r\n\tq.items[q.back] = p\r\n\tq.totalReqSize += q.items[q.back].Size\r\n}","code-length":162,"reference":"\/\/ Insert function insert a RequestStats into the queue and update the records","result":"Insert a new request stats into the queue.","score":[0.125,0.2525]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *statsQueue) Rate() (float64, float64) {\r\n\tfront, back := q.frontAndBack()\r\n\tif front == nil || back == nil {\r\n\t\treturn 0, 0\r\n\t}\r\n\tif time.Since(back.SendingTime) > time.Second {\r\n\t\tq.Clear()\r\n\t\treturn 0, 0\r\n\t}\r\n\tsampleDuration := back.SendingTime.Sub(front.SendingTime)\r\n\tpr := float64(q.Len()) \/ float64(sampleDuration) * float64(time.Second)\r\n\tbr := float64(q.ReqSize()) \/ float64(sampleDuration) * float64(time.Second)\r\n\treturn pr, br\r\n}","code-length":184,"reference":"\/\/ Rate function returns the package rate and byte rate","result":"Calculate the rate of the queue.","score":[0.1179,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *statsQueue) Clear() {\r\n\tq.rwl.Lock()\r\n\tdefer q.rwl.Unlock()\r\n\tq.back = -1\r\n\tq.front = 0\r\n\tq.size = 0\r\n\tq.totalReqSize = 0\r\n}","code-length":78,"reference":"\/\/ Clear function clear up the statsQueue","result":"Clear the queue.","score":[0.128,0.1515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UniqueStrings(slen uint, n int) (ss []string) {\r\n\texist := make(map[string]struct{})\r\n\tss = make([]string, 0, n)\r\n\tfor len(ss) < n {\r\n\t\ts := randString(slen)\r\n\t\tif _, ok := exist[s]; !ok {\r\n\t\t\tss = append(ss, s)\r\n\t\t\texist[s] = struct{}{}\r\n\t\t}\r\n\t}\r\n\treturn ss\r\n}","code-length":134,"reference":"\/\/ UniqueStrings returns a slice of randomly generated unique strings.","result":"Generate unique strings.","score":[0.056,0.3166]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RandomStrings(slen uint, n int) (ss []string) {\r\n\tss = make([]string, 0, n)\r\n\tfor i := 0; i < n; i++ {\r\n\t\tss = append(ss, randString(slen))\r\n\t}\r\n\treturn ss\r\n}","code-length":83,"reference":"\/\/ RandomStrings returns a slice of randomly generated strings.","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsKeyNotFound(err error) bool {\r\n\tif cErr, ok := err.(Error); ok {\r\n\t\treturn cErr.Code == ErrorCodeKeyNotFound\r\n\t}\r\n\treturn false\r\n}","code-length":60,"reference":"\/\/ IsKeyNotFound returns true if the error code is ErrorCodeKeyNotFound.","result":"Test the error .","score":[0.1008,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsRoleNotFound(err error) bool {\r\n\tif ae, ok := err.(authError); ok {\r\n\t\treturn roleNotFoundRegExp.MatchString(ae.Message)\r\n\t}\r\n\treturn false\r\n}","code-length":63,"reference":"\/\/ IsRoleNotFound returns true if the error means role not found of v2 API.","result":"Match the regex.","score":[0.0104,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsUserNotFound(err error) bool {\r\n\tif ae, ok := err.(authError); ok {\r\n\t\treturn userNotFoundRegExp.MatchString(ae.Message)\r\n\t}\r\n\treturn false\r\n}","code-length":63,"reference":"\/\/ IsUserNotFound returns true if the error means user not found of v2 API.","result":"Detect user not found error.","score":[0.0818,0.2248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc JoinCluster(lg *zap.Logger, durl, dproxyurl string, id types.ID, config string) (string, error) {\r\n\td, err := newDiscovery(lg, durl, dproxyurl, id)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn d.joinCluster(config)\r\n}","code-length":96,"reference":"\/\/ JoinCluster will connect to the discovery service at the given url, and\n\/\/ register the server represented by the given id and config to the cluster","result":"Config string.","score":[0,0.0204]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetCluster(lg *zap.Logger, durl, dproxyurl string) (string, error) {\r\n\td, err := newDiscovery(lg, durl, dproxyurl, 0)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn d.getCluster()\r\n}","code-length":86,"reference":"\/\/ GetCluster will connect to the discovery service at the given url and\n\/\/ retrieve a string describing the cluster","result":"Get the cluster name.","score":[0.0083,0.1019]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newProxyFunc(lg *zap.Logger, proxy string) (func(*http.Request) (*url.URL, error), error) {\r\n\tif proxy == \"\" {\r\n\t\treturn nil, nil\r\n\t}\r\n\t\r\n\t\r\n\tproxyURL, err := url.Parse(proxy)\r\n\tif err != nil || !strings.HasPrefix(proxyURL.Scheme, \"http\") {\r\n\t\terr2 error\r\n\t\tproxyURL, err2 = url.Parse(\"http:\r\n\t\tif err2 == nil {\r\n\t\t\terr = nil\r\n\t\t}\r\n\t}\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"invalid proxy address %q: %v\", proxy, err)\r\n\t}\r\n\tif lg != nil {\r\n\t\tlg.Info(\"running proxy with discovery\", zap.String(\"proxy-url\", proxyURL.String()))\r\n\t} else {\r\n\t\tplog.Infof(\"using proxy %q\", proxyURL.String())\r\n\t}\r\n\treturn http.ProxyURL(proxyURL), nil\r\n}","code-length":271,"reference":"\/\/ newProxyFunc builds a proxy function from the given string, which should\n\/\/ represent a URL that can be used as a proxy. It performs basic\n\/\/ sanitization of the URL and returns any error encountered.","result":"Create a proxy function .","score":[0.001,0.0777]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isSafeRetry(lg *zap.Logger, err error, callOpts *options) bool {\r\n\tif isContextError(err) {\r\n\t\treturn false\r\n\t}\r\n\tswitch callOpts.retryPolicy {\r\n\tcase repeatable:\r\n\t\treturn isSafeRetryImmutableRPC(err)\r\n\tcase nonRepeatable:\r\n\t\treturn isSafeRetryMutableRPC(err)\r\n\tdefault:\r\n\t\tlg.Warn(\"unrecognized retry policy\", zap.String(\"retryPolicy\", callOpts.retryPolicy.String()))\r\n\t\treturn false\r\n\t}\r\n}","code-length":150,"reference":"\/\/ isSafeRetry returns \"true\", if request is safe for retry with the given error.","result":"Check if the error is safe to retry.","score":[0.1103,0.2355]}
{"code":"\/*is used to<extra_id_0>\r\nfunc withRetryPolicy(rp retryPolicy) retryOption {\r\n\treturn retryOption{applyFunc: func(o *options) {\r\n\t\to.retryPolicy = rp\r\n\t}}\r\n}","code-length":55,"reference":"\/\/ withRetryPolicy sets the retry policy of this call.","result":"Generate the file.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc withAuthRetry(retryAuth bool) retryOption {\r\n\treturn retryOption{applyFunc: func(o *options) {\r\n\t\to.retryAuth = retryAuth\r\n\t}}\r\n}","code-length":56,"reference":"\/\/ withAuthRetry sets enables authentication retries.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc withMax(maxRetries uint) retryOption {\r\n\treturn retryOption{applyFunc: func(o *options) {\r\n\t\to.max = maxRetries\r\n\t}}\r\n}","code-length":53,"reference":"\/\/ withMax sets the maximum number of retries on this call, or this interceptor.","result":"Generate the generated code.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc withBackoff(bf backoffFunc) retryOption {\r\n\treturn retryOption{applyFunc: func(o *options) {\r\n\t\to.backoffFunc = bf\r\n\t}}\r\n}","code-length":55,"reference":"\/\/ WithBackoff sets the `BackoffFunc `used to control time between retries.","result":"Generate the code.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ss *ServerStats) RecvAppendReq(leader string, reqSize int) {\r\n\tss.Lock()\r\n\tdefer ss.Unlock()\r\n\tnow := time.Now()\r\n\tss.State = raft.StateFollower\r\n\tif leader != ss.LeaderInfo.Name {\r\n\t\tss.LeaderInfo.Name = leader\r\n\t\tss.LeaderInfo.StartTime = now\r\n\t}\r\n\tss.recvRateQueue.Insert(\r\n\t\t&RequestStats{\r\n\t\t\tSendingTime: now,\r\n\t\t\tSize:        reqSize,\r\n\t\t},\r\n\t)\r\n\tss.RecvAppendRequestCnt++\r\n}","code-length":165,"reference":"\/\/ RecvAppendReq updates the ServerStats in response to an AppendRequest\n\/\/ from the given leader being received","result":"Send a request to the leader.","score":[0.0367,0.0629]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ss *ServerStats) SendAppendReq(reqSize int) {\r\n\tss.Lock()\r\n\tdefer ss.Unlock()\r\n\tss.becomeLeader()\r\n\tss.sendRateQueue.Insert(\r\n\t\t&RequestStats{\r\n\t\t\tSendingTime: time.Now(),\r\n\t\t\tSize:        reqSize,\r\n\t\t},\r\n\t)\r\n\tss.SendAppendRequestCnt++\r\n}","code-length":112,"reference":"\/\/ SendAppendReq updates the ServerStats in response to an AppendRequest\n\/\/ being sent by this server","result":"Send append requests to the leader.","score":[0.0434,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (bb *bucketBuffer) merge(bbsrc *bucketBuffer) {\r\n\tfor i := 0; i < bbsrc.used; i++ {\r\n\t\tbb.add(bbsrc.buf[i].key, bbsrc.buf[i].val)\r\n\t}\r\n\tif bb.used == bbsrc.used {\r\n\t\treturn\r\n\t}\r\n\tif bytes.Compare(bb.buf[(bb.used-bbsrc.used)-1].key, bbsrc.buf[0].key) < 0 {\r\n\t\treturn\r\n\t}\r\n\tsort.Stable(bb)\r\n\t\r\n\twidx := 0\r\n\tfor ridx := 1; ridx < bb.used; ridx++ {\r\n\t\tif !bytes.Equal(bb.buf[ridx].key, bb.buf[widx].key) {\r\n\t\t\twidx++\r\n\t\t}\r\n\t\tbb.buf[widx] = bb.buf[ridx]\r\n\t}\r\n\tbb.used = widx + 1\r\n}","code-length":266,"reference":"\/\/ merge merges data from bb into bbsrc.","result":"Merge the two buffers.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc deleteRevKey(kv v3.KV, key string, rev int64) (bool, error) {\r\n\tcmp := v3.Compare(v3.ModRevision(key), \"=\", rev)\r\n\treq := v3.OpDelete(key)\r\n\ttxnresp, err := kv.Txn(context.TODO()).If(cmp).Then(req).Commit()\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t} else if !txnresp.Succeeded {\r\n\t\treturn false, nil\r\n\t}\r\n\treturn true, nil\r\n}","code-length":145,"reference":"\/\/ deleteRevKey deletes a key by revision, returning false if key is missing","result":"Delete rev key.","score":[0,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isMemberBootstrapped(lg *zap.Logger, cl *membership.RaftCluster, member string, rt http.RoundTripper, timeout time.Duration) bool {\r\n\trcl, err := getClusterFromRemotePeers(lg, getRemotePeerURLs(cl, member), timeout, false, rt)\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\tid := cl.MemberByName(member).ID\r\n\tm := rcl.Member(id)\r\n\tif m == nil {\r\n\t\treturn false\r\n\t}\r\n\tif len(m.ClientURLs) > 0 {\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":169,"reference":"\/\/ isMemberBootstrapped tries to check if the given member has been bootstrapped\n\/\/ in the given cluster.","result":"Check if the member is bootstrapped.","score":[0.0483,0.1985]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetClusterFromRemotePeers(lg *zap.Logger, urls []string, rt http.RoundTripper) (*membership.RaftCluster, error) {\r\n\treturn getClusterFromRemotePeers(lg, urls, 10*time.Second, true, rt)\r\n}","code-length":71,"reference":"\/\/ GetClusterFromRemotePeers takes a set of URLs representing etcd peers, and\n\/\/ attempts to construct a Cluster by accessing the members endpoint on one of\n\/\/ these URLs. The first URL to provide a response is used. If no URLs provide\n\/\/ a response, or a Cluster cannot be successfully created from a received\n\/\/ response, an error is returned.\n\/\/ Each request has a 10-second timeout. Because the upper limit of TTL is 5s,\n\/\/ 10 second is enough for building connection and finishing request.","result":"Get cluster from remote peers.","score":[0.0,0.0193]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getClusterFromRemotePeers(lg *zap.Logger, urls []string, timeout time.Duration, logerr bool, rt http.RoundTripper) (*membership.RaftCluster, error) {\r\n\tcc := &http.Client{\r\n\t\tTransport: rt,\r\n\t\tTimeout:   timeout,\r\n\t}\r\n\tfor _, u := range urls {\r\n\t\taddr := u + \"\/members\"\r\n\t\tresp, err := cc.Get(addr)\r\n\t\tif err != nil {\r\n\t\t\tif logerr {\r\n\t\t\t\tif lg != nil {\r\n\t\t\t\t\tlg.Warn(\"failed to get cluster response\", zap.String(\"address\", addr), zap.Error(err))\r\n\t\t\t\t} else {\r\n\t\t\t\t\tplog.Warningf(\"could not get cluster response from %s: %v\", u, err)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tb, err := ioutil.ReadAll(resp.Body)\r\n\t\tresp.Body.Close()\r\n\t\tif err != nil {\r\n\t\t\tif logerr {\r\n\t\t\t\tif lg != nil {\r\n\t\t\t\t\tlg.Warn(\"failed to read body of cluster response\", zap.String(\"address\", addr), zap.Error(err))\r\n\t\t\t\t} else {\r\n\t\t\t\t\tplog.Warningf(\"could not read the body of cluster response: %v\", err)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvar membs []*membership.Member\r\n\t\tif err = json.Unmarshal(b, &membs); err != nil {\r\n\t\t\tif logerr {\r\n\t\t\t\tif lg != nil {\r\n\t\t\t\t\tlg.Warn(\"failed to unmarshal cluster response\", zap.String(\"address\", addr), zap.Error(err))\r\n\t\t\t\t} else {\r\n\t\t\t\t\tplog.Warningf(\"could not unmarshal cluster response: %v\", err)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tid, err := types.IDFromString(resp.Header.Get(\"X-Etcd-Cluster-ID\"))\r\n\t\tif err != nil {\r\n\t\t\tif logerr {\r\n\t\t\t\tif lg != nil {\r\n\t\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\t\"failed to parse cluster ID\",\r\n\t\t\t\t\t\tzap.String(\"address\", addr),\r\n\t\t\t\t\t\tzap.String(\"header\", resp.Header.Get(\"X-Etcd-Cluster-ID\")),\r\n\t\t\t\t\t\tzap.Error(err),\r\n\t\t\t\t\t)\r\n\t\t\t\t} else {\r\n\t\t\t\t\tplog.Warningf(\"could not parse the cluster ID from cluster res: %v\", err)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif len(membs) > 0 {\r\n\t\t\treturn membership.NewClusterFromMembers(lg, \"\", id, membs), nil\r\n\t\t}\r\n\t\treturn nil, fmt.Errorf(\"failed to get raft cluster member(s) from the given URLs\")\r\n\t}\r\n\treturn nil, fmt.Errorf(\"could not retrieve cluster information from the given URLs\")\r\n}","code-length":770,"reference":"\/\/ If logerr is true, it prints out more error messages.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getRemotePeerURLs(cl *membership.RaftCluster, local string) []string {\r\n\tus := make([]string, 0)\r\n\tfor _, m := range cl.Members() {\r\n\t\tif m.Name == local {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tus = append(us, m.PeerURLs...)\r\n\t}\r\n\tsort.Strings(us)\r\n\treturn us\r\n}","code-length":111,"reference":"\/\/ getRemotePeerURLs returns peer urls of remote members in the cluster. The\n\/\/ returned list is sorted in ascending lexicographical order.","result":"Get remote peer URLs.","score":[0.0054,0.0518]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getVersions(lg *zap.Logger, cl *membership.RaftCluster, local types.ID, rt http.RoundTripper) map[string]*version.Versions {\r\n\tmembers := cl.Members()\r\n\tvers := make(map[string]*version.Versions)\r\n\tfor _, m := range members {\r\n\t\tif m.ID == local {\r\n\t\t\tcv := \"not_decided\"\r\n\t\t\tif cl.Version() != nil {\r\n\t\t\t\tcv = cl.Version().String()\r\n\t\t\t}\r\n\t\t\tvers[m.ID.String()] = &version.Versions{Server: version.Version, Cluster: cv}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tver, err := getVersion(lg, m, rt)\r\n\t\tif err != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\"failed to get version\", zap.String(\"remote-member-id\", m.ID.String()), zap.Error(err))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Warningf(\"cannot get the version of member %s (%v)\", m.ID, err)\r\n\t\t\t}\r\n\t\t\tvers[m.ID.String()] = nil\r\n\t\t} else {\r\n\t\t\tvers[m.ID.String()] = ver\r\n\t\t}\r\n\t}\r\n\treturn vers\r\n}","code-length":338,"reference":"\/\/ getVersions returns the versions of the members in the given cluster.\n\/\/ The key of the returned map is the member's ID. The value of the returned map\n\/\/ is the semver versions string, including server and cluster.\n\/\/ If it fails to get the version of a member, the key will be nil.","result":"Get the versions of all members in the cluster.","score":[0.0024,0.1252]}
{"code":"\/*is used to<extra_id_0>\r\nfunc decideClusterVersion(lg *zap.Logger, vers map[string]*version.Versions) *semver.Version {\r\n\tvar cv *semver.Version\r\n\tlv := semver.Must(semver.NewVersion(version.Version))\r\n\tfor mid, ver := range vers {\r\n\t\tif ver == nil {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tv, err := semver.NewVersion(ver.Server)\r\n\t\tif err != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"failed to parse server version of remote member\",\r\n\t\t\t\t\tzap.String(\"remote-member-id\", mid),\r\n\t\t\t\t\tzap.String(\"remote-member-version\", ver.Server),\r\n\t\t\t\t\tzap.Error(err),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Errorf(\"cannot understand the version of member %s (%v)\", mid, err)\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tif lv.LessThan(*v) {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"leader found higher-versioned member\",\r\n\t\t\t\t\tzap.String(\"local-member-version\", lv.String()),\r\n\t\t\t\t\tzap.String(\"remote-member-id\", mid),\r\n\t\t\t\t\tzap.String(\"remote-member-version\", ver.Server),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Warningf(\"the local etcd version %s is not up-to-date\", lv.String())\r\n\t\t\t\tplog.Warningf(\"member %s has a higher version %s\", mid, ver.Server)\r\n\t\t\t}\r\n\t\t}\r\n\t\tif cv == nil {\r\n\t\t\tcv = v\r\n\t\t} else if v.LessThan(*cv) {\r\n\t\t\tcv = v\r\n\t\t}\r\n\t}\r\n\treturn cv\r\n}","code-length":480,"reference":"\/\/ decideClusterVersion decides the cluster version based on the versions map.\n\/\/ The returned version is the min server version in the map, or nil if the min\n\/\/ version in unknown.","result":"Decide the cluster version.","score":[0.0004,0.0514]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getVersion(lg *zap.Logger, m *membership.Member, rt http.RoundTripper) (*version.Versions, error) {\r\n\tcc := &http.Client{\r\n\t\tTransport: rt,\r\n\t}\r\n\tvar (\r\n\t\terr  error\r\n\t\tresp *http.Response\r\n\t)\r\n\tfor _, u := range m.PeerURLs {\r\n\t\taddr := u + \"\/version\"\r\n\t\tresp, err = cc.Get(addr)\r\n\t\tif err != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"failed to reach the peer URL\",\r\n\t\t\t\t\tzap.String(\"address\", addr),\r\n\t\t\t\t\tzap.String(\"remote-member-id\", m.ID.String()),\r\n\t\t\t\t\tzap.Error(err),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Warningf(\"failed to reach the peerURL(%s) of member %s (%v)\", u, m.ID, err)\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvar b []byte\r\n\t\tb, err = ioutil.ReadAll(resp.Body)\r\n\t\tresp.Body.Close()\r\n\t\tif err != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"failed to read body of response\",\r\n\t\t\t\t\tzap.String(\"address\", addr),\r\n\t\t\t\t\tzap.String(\"remote-member-id\", m.ID.String()),\r\n\t\t\t\t\tzap.Error(err),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Warningf(\"failed to read out the response body from the peerURL(%s) of member %s (%v)\", u, m.ID, err)\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvar vers version.Versions\r\n\t\tif err = json.Unmarshal(b, &vers); err != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"failed to unmarshal response\",\r\n\t\t\t\t\tzap.String(\"address\", addr),\r\n\t\t\t\t\tzap.String(\"remote-member-id\", m.ID.String()),\r\n\t\t\t\t\tzap.Error(err),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Warningf(\"failed to unmarshal the response body got from the peerURL(%s) of member %s (%v)\", u, m.ID, err)\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\treturn &vers, nil\r\n\t}\r\n\treturn nil, err\r\n}","code-length":651,"reference":"\/\/ getVersion returns the Versions of the given member via its\n\/\/ peerURLs. Returns the last error if it fails to get the version.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTimeoutDetector(maxDuration time.Duration) *TimeoutDetector {\r\n\treturn &TimeoutDetector{\r\n\t\tmaxDuration: maxDuration,\r\n\t\trecords:     make(map[uint64]time.Time),\r\n\t}\r\n}","code-length":67,"reference":"\/\/ NewTimeoutDetector creates the TimeoutDetector.","result":"Create a new timeout detector.","score":[0,0.1]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (td *TimeoutDetector) Reset() {\r\n\ttd.mu.Lock()\r\n\tdefer td.mu.Unlock()\r\n\ttd.records = make(map[uint64]time.Time)\r\n}","code-length":59,"reference":"\/\/ Reset resets the NewTimeoutDetector.","result":"Reset the timeout detector.","score":[0.2959,0.2041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (td *TimeoutDetector) Observe(which uint64) (bool, time.Duration) {\r\n\ttd.mu.Lock()\r\n\tdefer td.mu.Unlock()\r\n\tok := true\r\n\tnow := time.Now()\r\n\texceed := time.Duration(0)\r\n\tif pt, found := td.records[which]; found {\r\n\t\texceed = now.Sub(pt) - td.maxDuration\r\n\t\tif exceed > 0 {\r\n\t\t\tok = false\r\n\t\t}\r\n\t}\r\n\ttd.records[which] = now\r\n\treturn ok, exceed\r\n}","code-length":156,"reference":"\/\/ Observe observes an event for given id. It returns false and exceeded duration\n\/\/ if the interval is longer than the expectation.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPeerHandler(lg *zap.Logger, s etcdserver.ServerPeer) http.Handler {\r\n\treturn newPeerHandler(lg, s.Cluster(), s.RaftHandler(), s.LeaseHandler())\r\n}","code-length":60,"reference":"\/\/ NewPeerHandler generates an http.Handler to handle etcd peer requests.","result":"Create a new peer handler.","score":[0.0884,0.0526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ki *keyIndex) put(lg *zap.Logger, main int64, sub int64) {\r\n\trev := revision{main: main, sub: sub}\r\n\tif !rev.GreaterThan(ki.modified) {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Panic(\r\n\t\t\t\t\"'put' with an unexpected smaller revision\",\r\n\t\t\t\tzap.Int64(\"given-revision-main\", rev.main),\r\n\t\t\t\tzap.Int64(\"given-revision-sub\", rev.sub),\r\n\t\t\t\tzap.Int64(\"modified-revision-main\", ki.modified.main),\r\n\t\t\t\tzap.Int64(\"modified-revision-sub\", ki.modified.sub),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Panicf(\"store.keyindex: put with unexpected smaller revision [%v \/ %v]\", rev, ki.modified)\r\n\t\t}\r\n\t}\r\n\tif len(ki.generations) == 0 {\r\n\t\tki.generations = append(ki.generations, generation{})\r\n\t}\r\n\tg := &ki.generations[len(ki.generations)-1]\r\n\tif len(g.revs) == 0 {\r\n\t\tkeysGauge.Inc()\r\n\t\tg.created = rev\r\n\t}\r\n\tg.revs = append(g.revs, rev)\r\n\tg.ver++\r\n\tki.modified = rev\r\n}","code-length":359,"reference":"\/\/ put puts a revision to the keyIndex.","result":"Store the keyIndex.","score":[0.109,0.25]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ki *keyIndex) tombstone(lg *zap.Logger, main int64, sub int64) error {\r\n\tif ki.isEmpty() {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Panic(\r\n\t\t\t\t\"'tombstone' got an unexpected empty keyIndex\",\r\n\t\t\t\tzap.String(\"key\", string(ki.key)),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Panicf(\"store.keyindex: unexpected tombstone on empty keyIndex %s\", string(ki.key))\r\n\t\t}\r\n\t}\r\n\tif ki.generations[len(ki.generations)-1].isEmpty() {\r\n\t\treturn ErrRevisionNotFound\r\n\t}\r\n\tki.put(lg, main, sub)\r\n\tki.generations = append(ki.generations, generation{})\r\n\tkeysGauge.Dec()\r\n\treturn nil\r\n}","code-length":230,"reference":"\/\/ tombstone puts a revision, pointing to a tombstone, to the keyIndex.\n\/\/ It also creates a new empty generation in the keyIndex.\n\/\/ It returns ErrRevisionNotFound when tombstone on an empty generation.","result":"Store tombstones in the store.","score":[0.0013,0.0846]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ki *keyIndex) get(lg *zap.Logger, atRev int64) (modified, created revision, ver int64, err error) {\r\n\tif ki.isEmpty() {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Panic(\r\n\t\t\t\t\"'get' got an unexpected empty keyIndex\",\r\n\t\t\t\tzap.String(\"key\", string(ki.key)),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Panicf(\"store.keyindex: unexpected get on empty keyIndex %s\", string(ki.key))\r\n\t\t}\r\n\t}\r\n\tg := ki.findGeneration(atRev)\r\n\tif g.isEmpty() {\r\n\t\treturn revision{}, revision{}, 0, ErrRevisionNotFound\r\n\t}\r\n\tn := g.walk(func(rev revision) bool { return rev.main > atRev })\r\n\tif n != -1 {\r\n\t\treturn g.revs[n], g.created, g.ver - int64(len(g.revs)-n-1), nil\r\n\t}\r\n\treturn revision{}, revision{}, 0, ErrRevisionNotFound\r\n}","code-length":288,"reference":"\/\/ get gets the modified, created revision and version of the key that satisfies the given atRev.\n\/\/ Rev must be higher than or equal to the given atRev.","result":"Get the revision of a key.","score":[0.0055,0.0749]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ki *keyIndex) since(lg *zap.Logger, rev int64) []revision {\r\n\tif ki.isEmpty() {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Panic(\r\n\t\t\t\t\"'since' got an unexpected empty keyIndex\",\r\n\t\t\t\tzap.String(\"key\", string(ki.key)),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Panicf(\"store.keyindex: unexpected get on empty keyIndex %s\", string(ki.key))\r\n\t\t}\r\n\t}\r\n\tsince := revision{rev, 0}\r\n\tvar gi int\r\n\t\r\n\tfor gi = len(ki.generations) - 1; gi > 0; gi-- {\r\n\t\tg := ki.generations[gi]\r\n\t\tif g.isEmpty() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif since.GreaterThan(g.created) {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tvar revs []revision\r\n\tvar last int64\r\n\tfor ; gi < len(ki.generations); gi++ {\r\n\t\tfor _, r := range ki.generations[gi].revs {\r\n\t\t\tif since.GreaterThan(r) {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tif r.main == last {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\trevs[len(revs)-1] = r\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\trevs = append(revs, r)\r\n\t\t\tlast = r.main\r\n\t\t}\r\n\t}\r\n\treturn revs\r\n}","code-length":405,"reference":"\/\/ since returns revisions since the given rev. Only the revision with the\n\/\/ largest sub revision will be returned if multiple revisions have the same\n\/\/ main revision.","result":"Get the latest revision of a key.","score":[0.0083,0.0954]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ki *keyIndex) keep(atRev int64, available map[revision]struct{}) {\r\n\tif ki.isEmpty() {\r\n\t\treturn\r\n\t}\r\n\tgenIdx, revIndex := ki.doCompact(atRev, available)\r\n\tg := &ki.generations[genIdx]\r\n\tif !g.isEmpty() {\r\n\t\t\r\n\t\tif revIndex == len(g.revs)-1 && genIdx != len(ki.generations)-1 {\r\n\t\t\tdelete(available, g.revs[revIndex])\r\n\t\t}\r\n\t}\r\n}","code-length":155,"reference":"\/\/ keep finds the revision to be kept if compact is called at given atRev.","result":"Keep the index.","score":[0.0075,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ki *keyIndex) findGeneration(rev int64) *generation {\r\n\tlastg := len(ki.generations) - 1\r\n\tcg := lastg\r\n\tfor cg >= 0 {\r\n\t\tif len(ki.generations[cg].revs) == 0 {\r\n\t\t\tcg--\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tg := ki.generations[cg]\r\n\t\tif cg != lastg {\r\n\t\t\tif tomb := g.revs[len(g.revs)-1].main; tomb <= rev {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t}\r\n\t\tif g.revs[0].main <= rev {\r\n\t\t\treturn &ki.generations[cg]\r\n\t\t}\r\n\t\tcg--\r\n\t}\r\n\treturn nil\r\n}","code-length":210,"reference":"\/\/ findGeneration finds out the generation of the keyIndex that the\n\/\/ given rev belongs to. If the given rev is at the gap of two generations,\n\/\/ which means that the key does not exist at the given rev, it returns nil.","result":"Find the generation of a key.","score":[0.0008,0.0509]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *watchableStore) cancelWatcher(wa *watcher) {\r\n\tfor {\r\n\t\ts.mu.Lock()\r\n\t\tif s.unsynced.delete(wa) {\r\n\t\t\tslowWatcherGauge.Dec()\r\n\t\t\tbreak\r\n\t\t} else if s.synced.delete(wa) {\r\n\t\t\tbreak\r\n\t\t} else if wa.compacted {\r\n\t\t\tbreak\r\n\t\t} else if wa.ch == nil {\r\n\t\t\t\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif !wa.victim {\r\n\t\t\tpanic(\"watcher not victim but not in watch groups\")\r\n\t\t}\r\n\t\tvar victimBatch watcherBatch\r\n\t\tfor _, wb := range s.victims {\r\n\t\t\tif wb[wa] != nil {\r\n\t\t\t\tvictimBatch = wb\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif victimBatch != nil {\r\n\t\t\tslowWatcherGauge.Dec()\r\n\t\t\tdelete(victimBatch, wa)\r\n\t\t\tbreak\r\n\t\t}\r\n\t\t\r\n\t\ts.mu.Unlock()\r\n\t\ttime.Sleep(time.Millisecond)\r\n\t}\r\n\twatcherGauge.Dec()\r\n\twa.ch = nil\r\n\ts.mu.Unlock()\r\n}","code-length":340,"reference":"\/\/ cancelWatcher removes references of the watcher from the watchableStore","result":"Cancel watchers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *watchableStore) syncWatchersLoop() {\r\n\tdefer s.wg.Done()\r\n\tfor {\r\n\t\ts.mu.RLock()\r\n\t\tst := time.Now()\r\n\t\tlastUnsyncedWatchers := s.unsynced.size()\r\n\t\ts.mu.RUnlock()\r\n\t\tunsyncedWatchers := 0\r\n\t\tif lastUnsyncedWatchers > 0 {\r\n\t\t\tunsyncedWatchers = s.syncWatchers()\r\n\t\t}\r\n\t\tsyncDuration := time.Since(st)\r\n\t\twaitDuration := 100 * time.Millisecond\r\n\t\t\r\n\t\tif unsyncedWatchers != 0 && lastUnsyncedWatchers > unsyncedWatchers {\r\n\t\t\t\r\n\t\t\twaitDuration = syncDuration\r\n\t\t}\r\n\t\tselect {\r\n\t\tcase <-time.After(waitDuration):\r\n\t\tcase <-s.stopc:\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":255,"reference":"\/\/ syncWatchersLoop syncs the watcher in the unsynced map every 100ms.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *watchableStore) syncVictimsLoop() {\r\n\tdefer s.wg.Done()\r\n\tfor {\r\n\t\tfor s.moveVictims() != 0 {\r\n\t\t\t\r\n\t\t}\r\n\t\ts.mu.RLock()\r\n\t\tisEmpty := len(s.victims) == 0\r\n\t\ts.mu.RUnlock()\r\n\t\tvar tickc <-chan time.Time\r\n\t\tif !isEmpty {\r\n\t\t\ttickc = time.After(10 * time.Millisecond)\r\n\t\t}\r\n\t\tselect {\r\n\t\tcase <-tickc:\r\n\t\tcase <-s.victimc:\r\n\t\tcase <-s.stopc:\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":200,"reference":"\/\/ syncVictimsLoop tries to write precomputed watcher responses to\n\/\/ watchers that had a blocked watcher channel","result":"Sync victims.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *watchableStore) moveVictims() (moved int) {\r\n\ts.mu.Lock()\r\n\tvictims := s.victims\r\n\ts.victims = nil\r\n\ts.mu.Unlock()\r\n\tvar newVictim watcherBatch\r\n\tfor _, wb := range victims {\r\n\t\t\r\n\t\tfor w, eb := range wb {\r\n\t\t\t\r\n\t\t\trev := w.minRev - 1\r\n\t\t\tif w.send(WatchResponse{WatchID: w.id, Events: eb.evs, Revision: rev}) {\r\n\t\t\t\tpendingEventsGauge.Add(float64(len(eb.evs)))\r\n\t\t\t} else {\r\n\t\t\t\tif newVictim == nil {\r\n\t\t\t\t\tnewVictim = make(watcherBatch)\r\n\t\t\t\t}\r\n\t\t\t\tnewVictim[w] = eb\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tmoved++\r\n\t\t}\r\n\t\t\r\n\t\ts.mu.Lock()\r\n\t\ts.store.revMu.RLock()\r\n\t\tcurRev := s.store.currentRev\r\n\t\tfor w, eb := range wb {\r\n\t\t\tif newVictim != nil && newVictim[w] != nil {\r\n\t\t\t\t\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tw.victim = false\r\n\t\t\tif eb.moreRev != 0 {\r\n\t\t\t\tw.minRev = eb.moreRev\r\n\t\t\t}\r\n\t\t\tif w.minRev <= curRev {\r\n\t\t\t\ts.unsynced.add(w)\r\n\t\t\t} else {\r\n\t\t\t\tslowWatcherGauge.Dec()\r\n\t\t\t\ts.synced.add(w)\r\n\t\t\t}\r\n\t\t}\r\n\t\ts.store.revMu.RUnlock()\r\n\t\ts.mu.Unlock()\r\n\t}\r\n\tif len(newVictim) > 0 {\r\n\t\ts.mu.Lock()\r\n\t\ts.victims = append(s.victims, newVictim)\r\n\t\ts.mu.Unlock()\r\n\t}\r\n\treturn moved\r\n}","code-length":531,"reference":"\/\/ moveVictims tries to update watches with already pending event data","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc kvsToEvents(lg *zap.Logger, wg *watcherGroup, revs, vals [][]byte) (evs []mvccpb.Event) {\r\n\tfor i, v := range vals {\r\n\t\tvar kv mvccpb.KeyValue\r\n\t\tif err := kv.Unmarshal(v); err != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Panic(\"failed to unmarshal mvccpb.KeyValue\", zap.Error(err))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"cannot unmarshal event: %v\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t\tif !wg.contains(string(kv.Key)) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tty := mvccpb.PUT\r\n\t\tif isTombstone(revs[i]) {\r\n\t\t\tty = mvccpb.DELETE\r\n\t\t\t\r\n\t\t\tkv.ModRevision = bytesToRev(revs[i]).main\r\n\t\t}\r\n\t\tevs = append(evs, mvccpb.Event{Kv: &kv, Type: ty})\r\n\t}\r\n\treturn evs\r\n}","code-length":286,"reference":"\/\/ kvsToEvents gets all events for the watchers from all key-value pairs","result":"Convert kvs to events.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *watchableStore) notify(rev int64, evs []mvccpb.Event) {\r\n\tvar victim watcherBatch\r\n\tfor w, eb := range newWatcherBatch(&s.synced, evs) {\r\n\t\tif eb.revs != 1 {\r\n\t\t\tif s.store != nil && s.store.lg != nil {\r\n\t\t\t\ts.store.lg.Panic(\r\n\t\t\t\t\t\"unexpected multiple revisions in watch notification\",\r\n\t\t\t\t\tzap.Int(\"number-of-revisions\", eb.revs),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"unexpected multiple revisions in notification\")\r\n\t\t\t}\r\n\t\t}\r\n\t\tif w.send(WatchResponse{WatchID: w.id, Events: eb.evs, Revision: rev}) {\r\n\t\t\tpendingEventsGauge.Add(float64(len(eb.evs)))\r\n\t\t} else {\r\n\t\t\t\r\n\t\t\tw.minRev = rev + 1\r\n\t\t\tif victim == nil {\r\n\t\t\t\tvictim = make(watcherBatch)\r\n\t\t\t}\r\n\t\t\tw.victim = true\r\n\t\t\tvictim[w] = eb\r\n\t\t\ts.synced.delete(w)\r\n\t\t\tslowWatcherGauge.Inc()\r\n\t\t}\r\n\t}\r\n\ts.addVictim(victim)\r\n}","code-length":347,"reference":"\/\/ notify notifies the fact that given event at the given rev just happened to\n\/\/ watchers that watch on the key of the event.","result":"Notify watchers.","score":[0,0.022]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isOpFuncCalled(op string, opts []OpOption) bool {\r\n\tfor _, opt := range opts {\r\n\t\tv := reflect.ValueOf(opt)\r\n\t\tif v.Kind() == reflect.Func {\r\n\t\t\tif opFunc := runtime.FuncForPC(v.Pointer()); opFunc != nil {\r\n\t\t\t\tif strings.Contains(opFunc.Name(), op) {\r\n\t\t\t\t\treturn true\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":136,"reference":"\/\/ Check if the provided function is being called in the op options.","result":"Check if the op is a function call.","score":[0.1957,0.4089]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *batchTx) UnsafePut(bucketName []byte, key []byte, value []byte) {\r\n\tt.unsafePut(bucketName, key, value, false)\r\n}","code-length":54,"reference":"\/\/ UnsafePut must be called holding the lock on the tx.","result":"Store the state of the transaction.","score":[0.0998,0.0952]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *batchTx) UnsafeSeqPut(bucketName []byte, key []byte, value []byte) {\r\n\tt.unsafePut(bucketName, key, value, true)\r\n}","code-length":55,"reference":"\/\/ UnsafeSeqPut must be called holding the lock on the tx.","result":"Store the transaction context.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *batchTx) UnsafeRange(bucketName, key, endKey []byte, limit int64) ([][]byte, [][]byte) {\r\n\tbucket := t.tx.Bucket(bucketName)\r\n\tif bucket == nil {\r\n\t\tif t.backend.lg != nil {\r\n\t\t\tt.backend.lg.Fatal(\r\n\t\t\t\t\"failed to find a bucket\",\r\n\t\t\t\tzap.String(\"bucket-name\", string(bucketName)),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Fatalf(\"bucket %s does not exist\", bucketName)\r\n\t\t}\r\n\t}\r\n\treturn unsafeRange(bucket.Cursor(), key, endKey, limit)\r\n}","code-length":181,"reference":"\/\/ UnsafeRange must be called holding the lock on the tx.","result":"Fetch the range of keys in.","score":[0.0839,0.0952]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *batchTx) UnsafeDelete(bucketName []byte, key []byte) {\r\n\tbucket := t.tx.Bucket(bucketName)\r\n\tif bucket == nil {\r\n\t\tif t.backend.lg != nil {\r\n\t\t\tt.backend.lg.Fatal(\r\n\t\t\t\t\"failed to find a bucket\",\r\n\t\t\t\tzap.String(\"bucket-name\", string(bucketName)),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Fatalf(\"bucket %s does not exist\", bucketName)\r\n\t\t}\r\n\t}\r\n\terr := bucket.Delete(key)\r\n\tif err != nil {\r\n\t\tif t.backend.lg != nil {\r\n\t\t\tt.backend.lg.Fatal(\r\n\t\t\t\t\"failed to delete a key\",\r\n\t\t\t\tzap.String(\"bucket-name\", string(bucketName)),\r\n\t\t\t\tzap.Error(err),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Fatalf(\"cannot delete key from bucket (%v)\", err)\r\n\t\t}\r\n\t}\r\n\tt.pending++\r\n}","code-length":283,"reference":"\/\/ UnsafeDelete must be called holding the lock on the tx.","result":"Delete a key from a bucket.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *batchTx) UnsafeForEach(bucketName []byte, visitor func(k, v []byte) error) error {\r\n\treturn unsafeForEach(t.tx, bucketName, visitor)\r\n}","code-length":57,"reference":"\/\/ UnsafeForEach must be called holding the lock on the tx.","result":"Generate the generated code.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *batchTx) Commit() {\r\n\tt.Lock()\r\n\tt.commit(false)\r\n\tt.Unlock()\r\n}","code-length":45,"reference":"\/\/ Commit commits a previous tx and begins a new writable one.","result":"Commit the transaction.","score":[0.0203,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *batchTx) CommitAndStop() {\r\n\tt.Lock()\r\n\tt.commit(true)\r\n\tt.Unlock()\r\n}","code-length":47,"reference":"\/\/ CommitAndStop commits the previous tx and does not create a new one.","result":"Commit and stop the transaction.","score":[0.0577,0.123]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (le *lessor) Renew(id LeaseID) (int64, error) {\r\n\tle.mu.RLock()\r\n\tif !le.isPrimary() {\r\n\t\t\r\n\t\tle.mu.RUnlock()\r\n\t\treturn -1, ErrNotPrimary\r\n\t}\r\n\tdemotec := le.demotec\r\n\tl := le.leaseMap[id]\r\n\tif l == nil {\r\n\t\tle.mu.RUnlock()\r\n\t\treturn -1, ErrLeaseNotFound\r\n\t}\r\n\t\r\n\tclearRemainingTTL := le.cp != nil && l.remainingTTL > 0\r\n\tle.mu.RUnlock()\r\n\tif l.expired() {\r\n\t\tselect {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tcase <-l.revokec:\r\n\t\t\treturn -1, ErrLeaseNotFound\r\n\t\t\r\n\t\t\r\n\t\tcase <-demotec:\r\n\t\t\treturn -1, ErrNotPrimary\r\n\t\tcase <-le.stopC:\r\n\t\t\treturn -1, ErrNotPrimary\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tif clearRemainingTTL {\r\n\t\tle.cp(context.Background(), &pb.LeaseCheckpointRequest{Checkpoints: []*pb.LeaseCheckpoint{{ID: int64(l.ID), Remaining_TTL: 0}}})\r\n\t}\r\n\tle.mu.Lock()\r\n\tl.refresh(0)\r\n\titem := &LeaseWithTime{id: l.ID, time: l.expiry.UnixNano()}\r\n\theap.Push(&le.leaseHeap, item)\r\n\tle.mu.Unlock()\r\n\tleaseRenewed.Inc()\r\n\treturn l.ttl, nil\r\n}","code-length":427,"reference":"\/\/ Renew renews an existing lease. If the given lease does not exist or\n\/\/ has expired, an error will be returned.","result":"Renew a lease in the lessor.","score":[0.0177,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (le *lessor) Attach(id LeaseID, items []LeaseItem) error {\r\n\tle.mu.Lock()\r\n\tdefer le.mu.Unlock()\r\n\tl := le.leaseMap[id]\r\n\tif l == nil {\r\n\t\treturn ErrLeaseNotFound\r\n\t}\r\n\tl.mu.Lock()\r\n\tfor _, it := range items {\r\n\t\tl.itemSet[it] = struct{}{}\r\n\t\tle.itemMap[it] = id\r\n\t}\r\n\tl.mu.Unlock()\r\n\treturn nil\r\n}","code-length":149,"reference":"\/\/ Attach attaches items to the lease with given ID. When the lease\n\/\/ expires, the attached items will be automatically removed.\n\/\/ If the given lease does not exist, an error will be returned.","result":"Create a new lessor.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (le *lessor) revokeExpiredLeases() {\r\n\tvar ls []*Lease\r\n\t\r\n\trevokeLimit := leaseRevokeRate \/ 2\r\n\tle.mu.RLock()\r\n\tif le.isPrimary() {\r\n\t\tls = le.findExpiredLeases(revokeLimit)\r\n\t}\r\n\tle.mu.RUnlock()\r\n\tif len(ls) != 0 {\r\n\t\tselect {\r\n\t\tcase <-le.stopC:\r\n\t\t\treturn\r\n\t\tcase le.expiredC <- ls:\r\n\t\tdefault:\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t}\r\n\t}\r\n}","code-length":168,"reference":"\/\/ revokeExpiredLeases finds all leases past their expiry and sends them to epxired channel for\n\/\/ to be revoked.","result":"Revoke expired leases.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (le *lessor) checkpointScheduledLeases() {\r\n\tvar cps []*pb.LeaseCheckpoint\r\n\t\r\n\tfor i := 0; i < leaseCheckpointRate\/2; i++ {\r\n\t\tle.mu.Lock()\r\n\t\tif le.isPrimary() {\r\n\t\t\tcps = le.findDueScheduledCheckpoints(maxLeaseCheckpointBatchSize)\r\n\t\t}\r\n\t\tle.mu.Unlock()\r\n\t\tif len(cps) != 0 {\r\n\t\t\tle.cp(context.Background(), &pb.LeaseCheckpointRequest{Checkpoints: cps})\r\n\t\t}\r\n\t\tif len(cps) < maxLeaseCheckpointBatchSize {\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":188,"reference":"\/\/ checkpointScheduledLeases finds all scheduled lease checkpoints that are due and\n\/\/ submits them to the checkpointer to persist them to the consensus log.","result":"Checkpoint scheduled leases.","score":[0.0004,0.0457]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (le *lessor) expireExists() (l *Lease, ok bool, next bool) {\r\n\tif le.leaseHeap.Len() == 0 {\r\n\t\treturn nil, false, false\r\n\t}\r\n\titem := le.leaseHeap[0]\r\n\tl = le.leaseMap[item.id]\r\n\tif l == nil {\r\n\t\t\r\n\t\t\r\n\t\theap.Pop(&le.leaseHeap)\r\n\t\treturn nil, false, true\r\n\t}\r\n\tif time.Now().UnixNano() < item.time  {\r\n\t\t\r\n\t\t\r\n\t\treturn l, false, false\r\n\t}\r\n\t\r\n\theap.Pop(&le.leaseHeap)\r\n\treturn l, true, false\r\n}","code-length":192,"reference":"\/\/ expireExists returns true if expiry items exist.\n\/\/ It pops only when expiry item exists.\n\/\/ \"next\" is true, to indicate that it may exist in next attempt.","result":"Check if the lease is expired.","score":[0.005,0.0375]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (le *lessor) findExpiredLeases(limit int) []*Lease {\r\n\tleases := make([]*Lease, 0, 16)\r\n\tfor {\r\n\t\tl, ok, next := le.expireExists()\r\n\t\tif !ok && !next {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif !ok {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif next {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif l.expired() {\r\n\t\t\tleases = append(leases, l)\r\n\t\t\t\r\n\t\t\tif len(leases) == limit {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn leases\r\n}","code-length":187,"reference":"\/\/ findExpiredLeases loops leases in the leaseMap until reaching expired limit\n\/\/ and returns the expired leases that needed to be revoked.","result":"Find expired leases.","score":[0.0007,0.0249]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *Lease) refresh(extend time.Duration) {\r\n\tnewExpiry := time.Now().Add(extend + time.Duration(l.RemainingTTL())*time.Second)\r\n\tl.expiryMu.Lock()\r\n\tdefer l.expiryMu.Unlock()\r\n\tl.expiry = newExpiry\r\n}","code-length":84,"reference":"\/\/ refresh refreshes the expiry of the lease.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *Lease) forever() {\r\n\tl.expiryMu.Lock()\r\n\tdefer l.expiryMu.Unlock()\r\n\tl.expiry = forever\r\n}","code-length":50,"reference":"\/\/ forever sets the expiry of lease to be forever.","result":"Create a new file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *Lease) Keys() []string {\r\n\tl.mu.RLock()\r\n\tkeys := make([]string, 0, len(l.itemSet))\r\n\tfor k := range l.itemSet {\r\n\t\tkeys = append(keys, k.Key)\r\n\t}\r\n\tl.mu.RUnlock()\r\n\treturn keys\r\n}","code-length":97,"reference":"\/\/ Keys returns all the keys attached to the lease.","result":"Generate the keys for the itemSet.","score":[0.1551,0.2662]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *Lease) Remaining() time.Duration {\r\n\tl.expiryMu.RLock()\r\n\tdefer l.expiryMu.RUnlock()\r\n\tif l.expiry.IsZero() {\r\n\t\treturn time.Duration(math.MaxInt64)\r\n\t}\r\n\treturn time.Until(l.expiry)\r\n}","code-length":91,"reference":"\/\/ Remaining returns the remaining time of the lease.","result":"Calculate the remaining time of the lease.","score":[0.6287,0.6802]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCompactionCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"compaction [options] <revision>\",\r\n\t\tShort: \"Compacts the event history in etcd\",\r\n\t\tRun:   compactionCommandFunc,\r\n\t}\r\n\tcmd.Flags().BoolVar(&compactPhysical, \"physical\", false, \"'true' to wait for compaction to physically remove all old revisions\")\r\n\treturn cmd\r\n}","code-length":123,"reference":"\/\/ NewCompactionCommand returns the cobra command for \"compaction\".","result":"Create a new compaction command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc compactionCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"compaction command needs 1 argument\"))\r\n\t}\r\n\trev, err := strconv.ParseInt(args[0], 10, 64)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tvar opts []clientv3.CompactOption\r\n\tif compactPhysical {\r\n\t\topts = append(opts, clientv3.WithCompactPhysical())\r\n\t}\r\n\tc := mustClientFromCmd(cmd)\r\n\tctx, cancel := commandCtx(cmd)\r\n\t_, cerr := c.Compact(ctx, rev, opts...)\r\n\tcancel()\r\n\tif cerr != nil {\r\n\t\tExitWithError(ExitError, cerr)\r\n\t}\r\n\tfmt.Println(\"compacted revision\", rev)\r\n}","code-length":237,"reference":"\/\/ compactionCommandFunc executes the \"compaction\" command.","result":"Run the compaction command.","score":[0.2304,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPutCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"put [options] <key> <value> (<value> can also be given from stdin)\",\r\n\t\tShort: \"Puts the given key into the store\",\r\n\t\tLong: `\r\nPuts the given key into the store.\r\nWhen <value> begins with '-', <value> is interpreted as a flag.\r\nInsert '--' for workaround:\r\n$ put <key> -- <value>\r\n$ put -- <key> <value>\r\nIf <value> isn't given as a command line argument and '--ignore-value' is not specified,\r\nthis command tries to read the value from standard input.\r\nIf <lease> isn't given as a command line argument and '--ignore-lease' is not specified,\r\nthis command tries to read the value from standard input.\r\nFor example,\r\n$ cat file | put <key>\r\nwill store the content of the file to <key>.\r\n`,\r\n\t\tRun: putCommandFunc,\r\n\t}\r\n\tcmd.Flags().StringVar(&leaseStr, \"lease\", \"0\", \"lease ID (in hexadecimal) to attach to the key\")\r\n\tcmd.Flags().BoolVar(&putPrevKV, \"prev-kv\", false, \"return the previous key-value pair before modification\")\r\n\tcmd.Flags().BoolVar(&putIgnoreVal, \"ignore-value\", false, \"updates the key using its current value\")\r\n\tcmd.Flags().BoolVar(&putIgnoreLease, \"ignore-lease\", false, \"updates the key using its current lease\")\r\n\treturn cmd\r\n}","code-length":398,"reference":"\/\/ NewPutCommand returns the cobra command for \"put\".","result":"Generate the command .","score":[0.1398,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc putCommandFunc(cmd *cobra.Command, args []string) {\r\n\tkey, value, opts := getPutOp(args)\r\n\tctx, cancel := commandCtx(cmd)\r\n\tresp, err := mustClientFromCmd(cmd).Put(ctx, key, value, opts...)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.Put(*resp)\r\n}","code-length":119,"reference":"\/\/ putCommandFunc executes the \"put\" command.","result":"Replace the default command function.","score":[0.1967,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewHandler(t *http.Transport, urlsFunc GetProxyURLs, failureWait time.Duration, refreshInterval time.Duration) http.Handler {\r\n\tif t.TLSClientConfig != nil {\r\n\t\t\r\n\t\terr := http2.ConfigureTransport(t)\r\n\t\tif err != nil {\r\n\t\t\tplog.Infof(\"Error enabling Transport HTTP\/2 support: %v\", err)\r\n\t\t}\r\n\t}\r\n\tp := &reverseProxy{\r\n\t\tdirector:  newDirector(urlsFunc, failureWait, refreshInterval),\r\n\t\ttransport: t,\r\n\t}\r\n\tmux := http.NewServeMux()\r\n\tmux.Handle(\"\/\", p)\r\n\tmux.HandleFunc(\"\/v2\/config\/local\/proxy\", p.configHandler)\r\n\treturn mux\r\n}","code-length":208,"reference":"\/\/ NewHandler creates a new HTTP handler, listening on the given transport,\n\/\/ which will proxy requests to an etcd cluster.\n\/\/ The handler will periodically update its view of the cluster.","result":"Create a reverse proxy handler.","score":[0.0013,0.0872]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewReadonlyHandler(hdlr http.Handler) http.Handler {\r\n\treadonly := readonlyHandlerFunc(hdlr)\r\n\treturn http.HandlerFunc(readonly)\r\n}","code-length":53,"reference":"\/\/ NewReadonlyHandler wraps the given HTTP handler to allow only GET requests","result":"Create a readonly handler.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSetCommand() cli.Command {\r\n\treturn cli.Command{\r\n\t\tName:      \"set\",\r\n\t\tUsage:     \"set the value of a key\",\r\n\t\tArgsUsage: \"<key> <value>\",\r\n\t\tDescription: `Set sets the value of a key.\r\n   When <value> begins with '-', <value> is interpreted as a flag.\r\n   Insert '--' for workaround:\r\n   $ set -- <key> <value>`,\r\n\t\tFlags: []cli.Flag{\r\n\t\t\tcli.IntFlag{Name: \"ttl\", Value: 0, Usage: \"key time-to-live in seconds\"},\r\n\t\t\tcli.StringFlag{Name: \"swap-with-value\", Value: \"\", Usage: \"previous value\"},\r\n\t\t\tcli.IntFlag{Name: \"swap-with-index\", Value: 0, Usage: \"previous index\"},\r\n\t\t},\r\n\t\tAction: func(c *cli.Context) error {\r\n\t\t\tsetCommandFunc(c, mustNewKeyAPI(c))\r\n\t\t\treturn nil\r\n\t\t},\r\n\t}\r\n}","code-length":276,"reference":"\/\/ NewSetCommand returns the CLI command for \"set\".","result":"Set the value of a key.","score":[0.1383,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc setCommandFunc(c *cli.Context, ki client.KeysAPI) {\r\n\tif len(c.Args()) == 0 {\r\n\t\thandleError(c, ExitBadArgs, errors.New(\"key required\"))\r\n\t}\r\n\tkey := c.Args()[0]\r\n\tvalue, err := argOrStdin(c.Args(), os.Stdin, 1)\r\n\tif err != nil {\r\n\t\thandleError(c, ExitBadArgs, errors.New(\"value required\"))\r\n\t}\r\n\tttl := c.Int(\"ttl\")\r\n\tprevValue := c.String(\"swap-with-value\")\r\n\tprevIndex := c.Int(\"swap-with-index\")\r\n\tctx, cancel := contextWithTotalTimeout(c)\r\n\tresp, err := ki.Set(ctx, key, value, &client.SetOptions{TTL: time.Duration(ttl) * time.Second, PrevIndex: uint64(prevIndex), PrevValue: prevValue})\r\n\tcancel()\r\n\tif err != nil {\r\n\t\thandleError(c, ExitServerError, err)\r\n\t}\r\n\tprintResponseKey(resp, c.GlobalString(\"output\"))\r\n}","code-length":292,"reference":"\/\/ setCommandFunc executes the \"set\" command.","result":"Set a value.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rwm *RWMutex) waitOnLastRev(pfx string) (bool, error) {\r\n\tclient := rwm.s.Client()\r\n\t\r\n\topts := append(v3.WithLastRev(), v3.WithMaxModRev(rwm.myKey.Revision()-1))\r\n\tlastKey, err := client.Get(rwm.ctx, pfx, opts...)\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\tif len(lastKey.Kvs) == 0 {\r\n\t\treturn true, nil\r\n\t}\r\n\t\r\n\t_, err = WaitEvents(\r\n\t\tclient,\r\n\t\tstring(lastKey.Kvs[0].Key),\r\n\t\trwm.myKey.Revision(),\r\n\t\t[]mvccpb.Event_EventType{mvccpb.DELETE})\r\n\treturn false, err\r\n}","code-length":224,"reference":"\/\/ waitOnLowest will wait on the last key with a revision < rwm.myKey.Revision with a\n\/\/ given prefix. If there are no keys left to wait on, return true.","result":"Wait on last rev.","score":[0.0007,0.0566]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetDefaultInterfaces() (map[string]uint8, error) {\r\n\treturn nil, fmt.Errorf(\"default host not supported on %s_%s\", runtime.GOOS, runtime.GOARCH)\r\n}","code-length":58,"reference":"\/\/ GetDefaultInterfaces fetches the device name of default routable interface.","result":"Get default interfaces.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSnapshotCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"snapshot <subcommand>\",\r\n\t\tShort: \"Manages etcd node snapshots\",\r\n\t}\r\n\tcmd.AddCommand(NewSnapshotSaveCommand())\r\n\tcmd.AddCommand(NewSnapshotRestoreCommand())\r\n\tcmd.AddCommand(newSnapshotStatusCommand())\r\n\treturn cmd\r\n}","code-length":112,"reference":"\/\/ NewSnapshotCommand returns the cobra command for \"snapshot\".","result":"Create a snapshot command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMoveLeaderCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"move-leader <transferee-member-id>\",\r\n\t\tShort: \"Transfers leadership to another etcd cluster member.\",\r\n\t\tRun:   transferLeadershipCommandFunc,\r\n\t}\r\n\treturn cmd\r\n}","code-length":97,"reference":"\/\/ NewMoveLeaderCommand returns the cobra command for \"move-leader\".","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc transferLeadershipCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"move-leader command needs 1 argument\"))\r\n\t}\r\n\ttarget, err := strconv.ParseUint(args[0], 16, 64)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitBadArgs, err)\r\n\t}\r\n\tc := mustClientFromCmd(cmd)\r\n\teps := c.Endpoints()\r\n\tc.Close()\r\n\tctx, cancel := commandCtx(cmd)\r\n\t\r\n\tvar leaderCli *clientv3.Client\r\n\tvar leaderID uint64\r\n\tfor _, ep := range eps {\r\n\t\tcfg := clientConfigFromCmd(cmd)\r\n\t\tcfg.endpoints = []string{ep}\r\n\t\tcli := cfg.mustClient()\r\n\t\tresp, serr := cli.Status(ctx, ep)\r\n\t\tif serr != nil {\r\n\t\t\tExitWithError(ExitError, serr)\r\n\t\t}\r\n\t\tif resp.Header.GetMemberId() == resp.Leader {\r\n\t\t\tleaderCli = cli\r\n\t\t\tleaderID = resp.Leader\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tcli.Close()\r\n\t}\r\n\tif leaderCli == nil {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"no leader endpoint given at %v\", eps))\r\n\t}\r\n\tvar resp *clientv3.MoveLeaderResponse\r\n\tresp, err = leaderCli.MoveLeader(ctx, target)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.MoveLeader(leaderID, target, *resp)\r\n}","code-length":442,"reference":"\/\/ transferLeadershipCommandFunc executes the \"compaction\" command.","result":"Transfer leadership to other members.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OpenDir(path string) (*os.File, error) {\r\n\tfd, err := openDir(path)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn os.NewFile(uintptr(fd), path), nil\r\n}","code-length":77,"reference":"\/\/ OpenDir opens a directory in windows with write access for syncing.","result":"Open a directory.","score":[0.0203,0.1689]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRemoveDirCommand() cli.Command {\r\n\treturn cli.Command{\r\n\t\tName:      \"rmdir\",\r\n\t\tUsage:     \"removes the key if it is an empty directory or a key-value pair\",\r\n\t\tArgsUsage: \"<key>\",\r\n\t\tAction: func(c *cli.Context) error {\r\n\t\t\trmdirCommandFunc(c, mustNewKeyAPI(c))\r\n\t\t\treturn nil\r\n\t\t},\r\n\t}\r\n}","code-length":126,"reference":"\/\/ NewRemoveDirCommand returns the CLI command for \"rmdir\".","result":"Remove a directory.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc rmdirCommandFunc(c *cli.Context, ki client.KeysAPI) {\r\n\tif len(c.Args()) == 0 {\r\n\t\thandleError(c, ExitBadArgs, errors.New(\"key required\"))\r\n\t}\r\n\tkey := c.Args()[0]\r\n\tctx, cancel := contextWithTotalTimeout(c)\r\n\tresp, err := ki.Delete(ctx, key, &client.DeleteOptions{Dir: true})\r\n\tcancel()\r\n\tif err != nil {\r\n\t\thandleError(c, ExitServerError, err)\r\n\t}\r\n\tif !resp.Node.Dir || c.GlobalString(\"output\") != \"simple\" {\r\n\t\tprintResponseKey(resp, c.GlobalString(\"output\"))\r\n\t}\r\n}","code-length":195,"reference":"\/\/ rmdirCommandFunc executes the \"rmdir\" command.","result":"Remove a directory.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDelCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"del [options] <key> [range_end]\",\r\n\t\tShort: \"Removes the specified key or range of keys [key, range_end)\",\r\n\t\tRun:   delCommandFunc,\r\n\t}\r\n\tcmd.Flags().BoolVar(&delPrefix, \"prefix\", false, \"delete keys with matching prefix\")\r\n\tcmd.Flags().BoolVar(&delPrevKV, \"prev-kv\", false, \"return deleted key-value pairs\")\r\n\tcmd.Flags().BoolVar(&delFromKey, \"from-key\", false, \"delete keys that are greater than or equal to the given key using byte compare\")\r\n\treturn cmd\r\n}","code-length":195,"reference":"\/\/ NewDelCommand returns the cobra command for \"del\".","result":"Create a new DelCommand.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc delCommandFunc(cmd *cobra.Command, args []string) {\r\n\tkey, opts := getDelOp(args)\r\n\tctx, cancel := commandCtx(cmd)\r\n\tresp, err := mustClientFromCmd(cmd).Delete(ctx, key, opts...)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.Del(*resp)\r\n}","code-length":114,"reference":"\/\/ delCommandFunc executes the \"del\" command.","result":"Delete a key.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewExpect(name string, arg ...string) (ep *ExpectProcess, err error) {\r\n\t\r\n\treturn NewExpectWithEnv(name, arg, nil)\r\n}","code-length":51,"reference":"\/\/ NewExpect creates a new process for expect testing.","result":"Create a new expect process.","score":[0.169,0.436]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewExpectWithEnv(name string, args []string, env []string) (ep *ExpectProcess, err error) {\r\n\tcmd := exec.Command(name, args...)\r\n\tcmd.Env = env\r\n\tep = &ExpectProcess{\r\n\t\tcmd:        cmd,\r\n\t\tStopSignal: syscall.SIGKILL,\r\n\t}\r\n\tep.cond = sync.NewCond(&ep.mu)\r\n\tep.cmd.Stderr = ep.cmd.Stdout\r\n\tep.cmd.Stdin = nil\r\n\tif ep.fpty, err = pty.Start(ep.cmd); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tep.wg.Add(1)\r\n\tgo ep.read()\r\n\treturn ep, nil\r\n}","code-length":199,"reference":"\/\/ NewExpectWithEnv creates a new process with user defined env variables for expect testing.","result":"Create a new expect process.","score":[0.0622,0.2863]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ep *ExpectProcess) ExpectFunc(f func(string) bool) (string, error) {\r\n\tep.mu.Lock()\r\n\tfor {\r\n\t\tfor len(ep.lines) == 0 && ep.err == nil {\r\n\t\t\tep.cond.Wait()\r\n\t\t}\r\n\t\tif len(ep.lines) == 0 {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tl := ep.lines[0]\r\n\t\tep.lines = ep.lines[1:]\r\n\t\tif f(l) {\r\n\t\t\tep.mu.Unlock()\r\n\t\t\treturn l, nil\r\n\t\t}\r\n\t}\r\n\tep.mu.Unlock()\r\n\treturn \"\", ep.err\r\n}","code-length":188,"reference":"\/\/ ExpectFunc returns the first line satisfying the function f.","result":"Test the code.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ep *ExpectProcess) Expect(s string) (string, error) {\r\n\treturn ep.ExpectFunc(func(txt string) bool { return strings.Contains(txt, s) })\r\n}","code-length":57,"reference":"\/\/ Expect returns the first line containing the given string.","result":"Test the ExpectProcess interface .","score":[0.0884,0.0526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ep *ExpectProcess) LineCount() int {\r\n\tep.mu.Lock()\r\n\tdefer ep.mu.Unlock()\r\n\treturn ep.count\r\n}","code-length":50,"reference":"\/\/ LineCount returns the number of recorded lines since\n\/\/ the beginning of the process.","result":"Test the tests.","score":[0.0075,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ep *ExpectProcess) Signal(sig os.Signal) error {\r\n\treturn ep.cmd.Process.Signal(sig)\r\n}","code-length":42,"reference":"\/\/ Signal sends a signal to the expect process","result":"Test the tests.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc keyFunc(req *pb.RangeRequest) string {\r\n\t\r\n\tb, err := req.Marshal()\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\treturn string(b)\r\n}","code-length":68,"reference":"\/\/ keyFunc returns the key of a request, which is used to look up its caching response in the cache.","result":"Generate the keyFunc.","score":[0.0014,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *cache) Add(req *pb.RangeRequest, resp *pb.RangeResponse) {\r\n\tkey := keyFunc(req)\r\n\tc.mu.Lock()\r\n\tdefer c.mu.Unlock()\r\n\tif req.Revision > c.compactedRev {\r\n\t\tc.lru.Add(key, resp)\r\n\t}\r\n\t\r\n\t\r\n\tif req.Revision != 0 {\r\n\t\treturn\r\n\t}\r\n\tvar (\r\n\t\tiv  *adt.IntervalValue\r\n\t\tivl adt.Interval\r\n\t)\r\n\tif len(req.RangeEnd) != 0 {\r\n\t\tivl = adt.NewStringAffineInterval(string(req.Key), string(req.RangeEnd))\r\n\t} else {\r\n\t\tivl = adt.NewStringAffinePoint(string(req.Key))\r\n\t}\r\n\tiv = c.cachedRanges.Find(ivl)\r\n\tif iv == nil {\r\n\t\tval := map[string]struct{}{key: {}}\r\n\t\tc.cachedRanges.Insert(ivl, val)\r\n\t} else {\r\n\t\tval := iv.Val.(map[string]struct{})\r\n\t\tval[key] = struct{}{}\r\n\t\tiv.Val = val\r\n\t}\r\n}","code-length":333,"reference":"\/\/ Add adds the response of a request to the cache if its revision is larger than the compacted revision of the cache.","result":"Add range requests to the cache.","score":[0.0211,0.2094]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *cache) Get(req *pb.RangeRequest) (*pb.RangeResponse, error) {\r\n\tkey := keyFunc(req)\r\n\tc.mu.Lock()\r\n\tdefer c.mu.Unlock()\r\n\tif req.Revision > 0 && req.Revision < c.compactedRev {\r\n\t\tc.lru.Remove(key)\r\n\t\treturn nil, ErrCompacted\r\n\t}\r\n\tif resp, ok := c.lru.Get(key); ok {\r\n\t\treturn resp.(*pb.RangeResponse), nil\r\n\t}\r\n\treturn nil, errors.New(\"not exist\")\r\n}","code-length":163,"reference":"\/\/ Get looks up the caching response for a given request.\n\/\/ Get is also responsible for lazy eviction when accessing compacted entries.","result":"Get the range from the cache.","score":[0.0135,0.0469]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *cache) Invalidate(key, endkey []byte) {\r\n\tc.mu.Lock()\r\n\tdefer c.mu.Unlock()\r\n\tvar (\r\n\t\tivs []*adt.IntervalValue\r\n\t\tivl adt.Interval\r\n\t)\r\n\tif len(endkey) == 0 {\r\n\t\tivl = adt.NewStringAffinePoint(string(key))\r\n\t} else {\r\n\t\tivl = adt.NewStringAffineInterval(string(key), string(endkey))\r\n\t}\r\n\tivs = c.cachedRanges.Stab(ivl)\r\n\tfor _, iv := range ivs {\r\n\t\tkeys := iv.Val.(map[string]struct{})\r\n\t\tfor key := range keys {\r\n\t\t\tc.lru.Remove(key)\r\n\t\t}\r\n\t}\r\n\t\r\n\tc.cachedRanges.Delete(ivl)\r\n}","code-length":242,"reference":"\/\/ Invalidate invalidates the cache entries that intersecting with the given range from key to endkey.","result":"Invalidate the cache.","score":[0.0064,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *cache) Compact(revision int64) {\r\n\tc.mu.Lock()\r\n\tdefer c.mu.Unlock()\r\n\tif revision > c.compactedRev {\r\n\t\tc.compactedRev = revision\r\n\t}\r\n}","code-length":71,"reference":"\/\/ Compact invalidate all caching response before the given rev.\n\/\/ Replace with the invalidation is lazy. The actual removal happens when the entries is accessed.","result":"Compact the cache.","score":[0.0002,0.0422]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewUniqueURLsWithExceptions(s string, exceptions ...string) *UniqueURLs {\r\n\tus := &UniqueURLs{Values: make(map[string]struct{}), Allowed: make(map[string]struct{})}\r\n\tfor _, v := range exceptions {\r\n\t\tus.Allowed[v] = struct{}{}\r\n\t}\r\n\tif s == \"\" {\r\n\t\treturn us\r\n\t}\r\n\tif err := us.Set(s); err != nil {\r\n\t\tplog.Panicf(\"new UniqueURLs should never fail: %v\", err)\r\n\t}\r\n\treturn us\r\n}","code-length":155,"reference":"\/\/ NewUniqueURLsWithExceptions implements \"url.URL\" slice as flag.Value interface.\n\/\/ Given value is to be separated by comma.","result":"Create a new unique URL .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UniqueURLsFromFlag(fs *flag.FlagSet, urlsFlagName string) []url.URL {\r\n\treturn (*fs.Lookup(urlsFlagName).Value.(*UniqueURLs)).uss\r\n}","code-length":57,"reference":"\/\/ UniqueURLsFromFlag returns a slice from urls got from the flag.","result":"Generate the generated code.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UniqueURLsMapFromFlag(fs *flag.FlagSet, urlsFlagName string) map[string]struct{} {\r\n\treturn (*fs.Lookup(urlsFlagName).Value.(*UniqueURLs)).Values\r\n}","code-length":60,"reference":"\/\/ UniqueURLsMapFromFlag returns a map from url strings got from the flag.","result":"Generate the generated code.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Barrier) Hold() error {\r\n\t_, err := newKey(b.client, b.key, v3.NoLease)\r\n\treturn err\r\n}","code-length":52,"reference":"\/\/ Hold creates the barrier key causing processes to block on Wait.","result":"Hold the barrier.","score":[0.0242,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Barrier) Release() error {\r\n\t_, err := b.client.Delete(b.ctx, b.key)\r\n\treturn err\r\n}","code-length":49,"reference":"\/\/ Release deletes the barrier key to unblock all waiting processes.","result":"Release the barrier.","score":[0.0337,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Barrier) Wait() error {\r\n\tresp, err := b.client.Get(b.ctx, b.key, v3.WithFirstKey()...)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif len(resp.Kvs) == 0 {\r\n\t\t\r\n\t\treturn nil\r\n\t}\r\n\t_, err = WaitEvents(\r\n\t\tb.client,\r\n\t\tb.key,\r\n\t\tresp.Header.Revision,\r\n\t\t[]mvccpb.Event_EventType{mvccpb.PUT, mvccpb.DELETE})\r\n\treturn err\r\n}","code-length":163,"reference":"\/\/ Wait blocks on the barrier key until it is deleted. If there is no key, Wait\n\/\/ assumes Release has already been called and returns immediately.","result":"Wait for the barrier.","score":[0.0012,0.0405]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLockRacerCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"lock-racer [name of lock (defaults to 'racers')]\",\r\n\t\tShort: \"Performs lock race operation\",\r\n\t\tRun:   runRacerFunc,\r\n\t}\r\n\tcmd.Flags().IntVar(&totalClientConnections, \"total-client-connections\", 10, \"total number of client connections\")\r\n\treturn cmd\r\n}","code-length":127,"reference":"\/\/ NewLockRacerCommand returns the cobra command for \"lock-racer runner\".","result":"Create a new command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) ElectionTimeout() time.Duration {\r\n\treturn time.Duration(m.Etcd.ElectionTimeoutMs) * time.Millisecond\r\n}","code-length":48,"reference":"\/\/ ElectionTimeout returns an election timeout duration.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) DialEtcdGRPCServer(opts ...grpc.DialOption) (*grpc.ClientConn, error) {\r\n\tdialOpts := []grpc.DialOption{\r\n\t\tgrpc.WithTimeout(5 * time.Second),\r\n\t\tgrpc.WithBlock(),\r\n\t}\r\n\tsecure := false\r\n\tfor _, cu := range m.Etcd.AdvertiseClientURLs {\r\n\t\tu, err := url.Parse(cu)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tif u.Scheme == \"https\" {\r\n\t\t\tsecure = true\r\n\t\t}\r\n\t}\r\n\tif secure {\r\n\t\t\r\n\t\ttlsInfo := transport.TLSInfo{\r\n\t\t\tCertFile:      m.ClientCertPath,\r\n\t\t\tKeyFile:       m.ClientKeyPath,\r\n\t\t\tTrustedCAFile: m.ClientTrustedCAPath,\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tInsecureSkipVerify: true,\r\n\t\t}\r\n\t\ttlsConfig, err := tlsInfo.ClientConfig()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tcreds := credentials.NewTLS(tlsConfig)\r\n\t\tdialOpts = append(dialOpts, grpc.WithTransportCredentials(creds))\r\n\t} else {\r\n\t\tdialOpts = append(dialOpts, grpc.WithInsecure())\r\n\t}\r\n\tdialOpts = append(dialOpts, opts...)\r\n\treturn grpc.Dial(m.EtcdClientEndpoint, dialOpts...)\r\n}","code-length":381,"reference":"\/\/ DialEtcdGRPCServer creates a raw gRPC connection to an etcd member.","result":"Connect to etcd server.","score":[0.066,0.2481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) CreateEtcdClientConfig(opts ...grpc.DialOption) (cfg *clientv3.Config, err error) {\r\n\tsecure := false\r\n\tfor _, cu := range m.Etcd.AdvertiseClientURLs {\r\n\t\tvar u *url.URL\r\n\t\tu, err = url.Parse(cu)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tif u.Scheme == \"https\" {\r\n\t\t\tsecure = true\r\n\t\t}\r\n\t}\r\n\tcfg = &clientv3.Config{\r\n\t\tEndpoints:   []string{m.EtcdClientEndpoint},\r\n\t\tDialTimeout: 10 * time.Second,\r\n\t\tDialOptions: opts,\r\n\t}\r\n\tif secure {\r\n\t\t\r\n\t\ttlsInfo := transport.TLSInfo{\r\n\t\t\tCertFile:      m.ClientCertPath,\r\n\t\t\tKeyFile:       m.ClientKeyPath,\r\n\t\t\tTrustedCAFile: m.ClientTrustedCAPath,\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tInsecureSkipVerify: true,\r\n\t\t}\r\n\t\tvar tlsConfig *tls.Config\r\n\t\ttlsConfig, err = tlsInfo.ClientConfig()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tcfg.TLS = tlsConfig\r\n\t}\r\n\treturn cfg, err\r\n}","code-length":345,"reference":"\/\/ CreateEtcdClientConfig creates a client configuration from member.","result":"Create a new member .","score":[0.1319,0.2435]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) CreateEtcdClient(opts ...grpc.DialOption) (*clientv3.Client, error) {\r\n\tcfg, err := m.CreateEtcdClientConfig(opts...)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn clientv3.New(*cfg)\r\n}","code-length":87,"reference":"\/\/ CreateEtcdClient creates a client from member.","result":"Create the client.","score":[0,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) CheckCompact(rev int64) error {\r\n\tcli, err := m.CreateEtcdClient()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"%v (%q)\", err, m.EtcdClientEndpoint)\r\n\t}\r\n\tdefer cli.Close()\r\n\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\r\n\twch := cli.Watch(ctx, \"\\x00\", clientv3.WithFromKey(), clientv3.WithRev(rev-1))\r\n\twr, ok := <-wch\r\n\tcancel()\r\n\tif !ok {\r\n\t\treturn fmt.Errorf(\"watch channel terminated (endpoint %q)\", m.EtcdClientEndpoint)\r\n\t}\r\n\tif wr.CompactRevision != rev {\r\n\t\treturn fmt.Errorf(\"got compact revision %v, wanted %v (endpoint %q)\", wr.CompactRevision, rev, m.EtcdClientEndpoint)\r\n\t}\r\n\treturn nil\r\n}","code-length":247,"reference":"\/\/ CheckCompact ensures that historical data before given revision has been compacted.","result":"Check the compact revision.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) Defrag() error {\r\n\tcli, err := m.CreateEtcdClient()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"%v (%q)\", err, m.EtcdClientEndpoint)\r\n\t}\r\n\tdefer cli.Close()\r\n\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)\r\n\t_, err = cli.Defragment(ctx, m.EtcdClientEndpoint)\r\n\tcancel()\r\n\treturn err\r\n}","code-length":130,"reference":"\/\/ Defrag runs defragmentation on this member.","result":"Defragment a member.","score":[0.1076,0.1515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) RevHash() (int64, int64, error) {\r\n\tconn, err := m.DialEtcdGRPCServer()\r\n\tif err != nil {\r\n\t\treturn 0, 0, err\r\n\t}\r\n\tdefer conn.Close()\r\n\tmt := pb.NewMaintenanceClient(conn)\r\n\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\r\n\tresp, err := mt.Hash(ctx, &pb.HashRequest{}, grpc.FailFast(false))\r\n\tcancel()\r\n\tif err != nil {\r\n\t\treturn 0, 0, err\r\n\t}\r\n\treturn resp.Header.Revision, int64(resp.Hash), nil\r\n}","code-length":182,"reference":"\/\/ RevHash fetches current revision and hash on this member.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) Rev(ctx context.Context) (int64, error) {\r\n\tcli, err := m.CreateEtcdClient()\r\n\tif err != nil {\r\n\t\treturn 0, fmt.Errorf(\"%v (%q)\", err, m.EtcdClientEndpoint)\r\n\t}\r\n\tdefer cli.Close()\r\n\tresp, err := cli.Status(ctx, m.EtcdClientEndpoint)\r\n\tif err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\treturn resp.Header.Revision, nil\r\n}","code-length":139,"reference":"\/\/ Rev fetches current revision on this member.","result":"Get the member.","score":[0.0771,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) Compact(rev int64, timeout time.Duration) error {\r\n\tcli, err := m.CreateEtcdClient()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"%v (%q)\", err, m.EtcdClientEndpoint)\r\n\t}\r\n\tdefer cli.Close()\r\n\tctx, cancel := context.WithTimeout(context.Background(), timeout)\r\n\t_, err = cli.Compact(ctx, rev, clientv3.WithCompactPhysical())\r\n\tcancel()\r\n\treturn err\r\n}","code-length":137,"reference":"\/\/ Compact compacts member storage with given revision.\n\/\/ It blocks until it's physically done.","result":"Compact the cluster member.","score":[0.0204,0.036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) IsLeader() (bool, error) {\r\n\tcli, err := m.CreateEtcdClient()\r\n\tif err != nil {\r\n\t\treturn false, fmt.Errorf(\"%v (%q)\", err, m.EtcdClientEndpoint)\r\n\t}\r\n\tdefer cli.Close()\r\n\tresp, err := cli.Status(context.Background(), m.EtcdClientEndpoint)\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\treturn resp.Header.MemberId == resp.Leader, nil\r\n}","code-length":141,"reference":"\/\/ IsLeader returns true if this member is the current cluster leader.","result":"Check if the member is the leader.","score":[0.185,0.3878]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) WriteHealthKey() error {\r\n\tcli, err := m.CreateEtcdClient()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"%v (%q)\", err, m.EtcdClientEndpoint)\r\n\t}\r\n\tdefer cli.Close()\r\n\t\r\n\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\r\n\t_, err = cli.Put(ctx, \"health\", \"good\")\r\n\tcancel()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"%v (%q)\", err, m.EtcdClientEndpoint)\r\n\t}\r\n\treturn nil\r\n}","code-length":167,"reference":"\/\/ WriteHealthKey writes a health key to this member.","result":"Write the health key to the etcd cluster.","score":[0.2524,0.4213]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) SaveSnapshot(lg *zap.Logger) (err error) {\r\n\t\r\n\tif err = os.RemoveAll(m.SnapshotPath); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tvar ccfg *clientv3.Config\r\n\tccfg, err = m.CreateEtcdClientConfig()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"%v (%q)\", err, m.EtcdClientEndpoint)\r\n\t}\r\n\tlg.Info(\r\n\t\t\"snapshot save START\",\r\n\t\tzap.String(\"member-name\", m.Etcd.Name),\r\n\t\tzap.Strings(\"member-client-urls\", m.Etcd.AdvertiseClientURLs),\r\n\t\tzap.String(\"snapshot-path\", m.SnapshotPath),\r\n\t)\r\n\tnow := time.Now()\r\n\tmgr := snapshot.NewV3(lg)\r\n\tif err = mgr.Save(context.Background(), *ccfg, m.SnapshotPath); err != nil {\r\n\t\treturn err\r\n\t}\r\n\ttook := time.Since(now)\r\n\tvar fi os.FileInfo\r\n\tfi, err = os.Stat(m.SnapshotPath)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tvar st snapshot.Status\r\n\tst, err = mgr.Status(m.SnapshotPath)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tm.SnapshotInfo = &SnapshotInfo{\r\n\t\tMemberName:        m.Etcd.Name,\r\n\t\tMemberClientURLs:  m.Etcd.AdvertiseClientURLs,\r\n\t\tSnapshotPath:      m.SnapshotPath,\r\n\t\tSnapshotFileSize:  humanize.Bytes(uint64(fi.Size())),\r\n\t\tSnapshotTotalSize: humanize.Bytes(uint64(st.TotalSize)),\r\n\t\tSnapshotTotalKey:  int64(st.TotalKey),\r\n\t\tSnapshotHash:      int64(st.Hash),\r\n\t\tSnapshotRevision:  st.Revision,\r\n\t\tTook:              fmt.Sprintf(\"%v\", took),\r\n\t}\r\n\tlg.Info(\r\n\t\t\"snapshot save END\",\r\n\t\tzap.String(\"member-name\", m.SnapshotInfo.MemberName),\r\n\t\tzap.Strings(\"member-client-urls\", m.SnapshotInfo.MemberClientURLs),\r\n\t\tzap.String(\"snapshot-path\", m.SnapshotPath),\r\n\t\tzap.String(\"snapshot-file-size\", m.SnapshotInfo.SnapshotFileSize),\r\n\t\tzap.String(\"snapshot-total-size\", m.SnapshotInfo.SnapshotTotalSize),\r\n\t\tzap.Int64(\"snapshot-total-key\", m.SnapshotInfo.SnapshotTotalKey),\r\n\t\tzap.Int64(\"snapshot-hash\", m.SnapshotInfo.SnapshotHash),\r\n\t\tzap.Int64(\"snapshot-revision\", m.SnapshotInfo.SnapshotRevision),\r\n\t\tzap.String(\"took\", m.SnapshotInfo.Took),\r\n\t)\r\n\treturn nil\r\n}","code-length":749,"reference":"\/\/ SaveSnapshot downloads a snapshot file from this member, locally.\n\/\/ It's meant to requested remotely, so that local member can store\n\/\/ snapshot file on local disk.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) RestoreSnapshot(lg *zap.Logger) (err error) {\r\n\tif err = os.RemoveAll(m.EtcdOnSnapshotRestore.DataDir); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err = os.RemoveAll(m.EtcdOnSnapshotRestore.WALDir); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tlg.Info(\r\n\t\t\"snapshot restore START\",\r\n\t\tzap.String(\"member-name\", m.Etcd.Name),\r\n\t\tzap.Strings(\"member-client-urls\", m.Etcd.AdvertiseClientURLs),\r\n\t\tzap.String(\"snapshot-path\", m.SnapshotPath),\r\n\t)\r\n\tnow := time.Now()\r\n\tmgr := snapshot.NewV3(lg)\r\n\terr = mgr.Restore(snapshot.RestoreConfig{\r\n\t\tSnapshotPath:        m.SnapshotInfo.SnapshotPath,\r\n\t\tName:                m.EtcdOnSnapshotRestore.Name,\r\n\t\tOutputDataDir:       m.EtcdOnSnapshotRestore.DataDir,\r\n\t\tOutputWALDir:        m.EtcdOnSnapshotRestore.WALDir,\r\n\t\tPeerURLs:            m.EtcdOnSnapshotRestore.AdvertisePeerURLs,\r\n\t\tInitialCluster:      m.EtcdOnSnapshotRestore.InitialCluster,\r\n\t\tInitialClusterToken: m.EtcdOnSnapshotRestore.InitialClusterToken,\r\n\t\tSkipHashCheck:       false,\r\n\t\t\r\n\t})\r\n\ttook := time.Since(now)\r\n\tlg.Info(\r\n\t\t\"snapshot restore END\",\r\n\t\tzap.String(\"member-name\", m.SnapshotInfo.MemberName),\r\n\t\tzap.Strings(\"member-client-urls\", m.SnapshotInfo.MemberClientURLs),\r\n\t\tzap.String(\"snapshot-path\", m.SnapshotPath),\r\n\t\tzap.String(\"snapshot-file-size\", m.SnapshotInfo.SnapshotFileSize),\r\n\t\tzap.String(\"snapshot-total-size\", m.SnapshotInfo.SnapshotTotalSize),\r\n\t\tzap.Int64(\"snapshot-total-key\", m.SnapshotInfo.SnapshotTotalKey),\r\n\t\tzap.Int64(\"snapshot-hash\", m.SnapshotInfo.SnapshotHash),\r\n\t\tzap.Int64(\"snapshot-revision\", m.SnapshotInfo.SnapshotRevision),\r\n\t\tzap.String(\"took\", took.String()),\r\n\t\tzap.Error(err),\r\n\t)\r\n\treturn err\r\n}","code-length":612,"reference":"\/\/ RestoreSnapshot restores a cluster from a given snapshot file on disk.\n\/\/ It's meant to requested remotely, so that local member can load the\n\/\/ snapshot file from local disk.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewWatcher(w clientv3.Watcher, prefix string) clientv3.Watcher {\r\n\treturn &watcherPrefix{Watcher: w, pfx: prefix, stopc: make(chan struct{})}\r\n}","code-length":57,"reference":"\/\/ NewWatcher wraps a Watcher instance so that all Watch requests\n\/\/ are prefixed with a given string and all Watch responses have\n\/\/ the prefix removed.","result":"Create a new watcher.","score":[0.001,0.0202]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRawNode(config *Config, peers []Peer) (*RawNode, error) {\r\n\tif config.ID == 0 {\r\n\t\tpanic(\"config.ID must not be zero\")\r\n\t}\r\n\tr := newRaft(config)\r\n\trn := &RawNode{\r\n\t\traft: r,\r\n\t}\r\n\tlastIndex, err := config.Storage.LastIndex()\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif lastIndex == 0 {\r\n\t\tr.becomeFollower(1, None)\r\n\t\tents := make([]pb.Entry, len(peers))\r\n\t\tfor i, peer := range peers {\r\n\t\t\tcc := pb.ConfChange{Type: pb.ConfChangeAddNode, NodeID: peer.ID, Context: peer.Context}\r\n\t\t\tdata, err := cc.Marshal()\r\n\t\t\tif err != nil {\r\n\t\t\t\tpanic(\"unexpected marshal error\")\r\n\t\t\t}\r\n\t\t\tents[i] = pb.Entry{Type: pb.EntryConfChange, Term: 1, Index: uint64(i + 1), Data: data}\r\n\t\t}\r\n\t\tr.raftLog.append(ents...)\r\n\t\tr.raftLog.committed = uint64(len(ents))\r\n\t\tfor _, peer := range peers {\r\n\t\t\tr.addNode(peer.ID)\r\n\t\t}\r\n\t}\r\n\t\r\n\trn.prevSoftSt = r.softState()\r\n\tif lastIndex == 0 {\r\n\t\trn.prevHardSt = emptyState\r\n\t} else {\r\n\t\trn.prevHardSt = r.hardState()\r\n\t}\r\n\treturn rn, nil\r\n}","code-length":442,"reference":"\/\/ NewRawNode returns a new RawNode given configuration and a list of raft peers.","result":"Create a raw node.","score":[0.0262,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) Campaign() error {\r\n\treturn rn.raft.Step(pb.Message{\r\n\t\tType: pb.MsgHup,\r\n\t})\r\n}","code-length":53,"reference":"\/\/ Campaign causes this RawNode to transition to candidate state.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) Propose(data []byte) error {\r\n\treturn rn.raft.Step(pb.Message{\r\n\t\tType: pb.MsgProp,\r\n\t\tFrom: rn.raft.id,\r\n\t\tEntries: []pb.Entry{\r\n\t\t\t{Data: data},\r\n\t\t}})\r\n}","code-length":91,"reference":"\/\/ Propose proposes data be appended to the raft log.","result":"Create a new node.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) ProposeConfChange(cc pb.ConfChange) error {\r\n\tdata, err := cc.Marshal()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn rn.raft.Step(pb.Message{\r\n\t\tType: pb.MsgProp,\r\n\t\tEntries: []pb.Entry{\r\n\t\t\t{Type: pb.EntryConfChange, Data: data},\r\n\t\t},\r\n\t})\r\n}","code-length":123,"reference":"\/\/ ProposeConfChange proposes a config change.","result":"Propose a conf change.","score":[0.2304,0.4406]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) ApplyConfChange(cc pb.ConfChange) *pb.ConfState {\r\n\tif cc.NodeID == None {\r\n\t\treturn &pb.ConfState{Nodes: rn.raft.nodes(), Learners: rn.raft.learnerNodes()}\r\n\t}\r\n\tswitch cc.Type {\r\n\tcase pb.ConfChangeAddNode:\r\n\t\trn.raft.addNode(cc.NodeID)\r\n\tcase pb.ConfChangeAddLearnerNode:\r\n\t\trn.raft.addLearner(cc.NodeID)\r\n\tcase pb.ConfChangeRemoveNode:\r\n\t\trn.raft.removeNode(cc.NodeID)\r\n\tcase pb.ConfChangeUpdateNode:\r\n\tdefault:\r\n\t\tpanic(\"unexpected conf type\")\r\n\t}\r\n\treturn &pb.ConfState{Nodes: rn.raft.nodes(), Learners: rn.raft.learnerNodes()}\r\n}","code-length":230,"reference":"\/\/ ApplyConfChange applies a config change to the local node.","result":"Apply a configuration change.","score":[0.0713,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) Step(m pb.Message) error {\r\n\t\r\n\tif IsLocalMsg(m.Type) {\r\n\t\treturn ErrStepLocalMsg\r\n\t}\r\n\tif pr := rn.raft.getProgress(m.From); pr != nil || !IsResponseMsg(m.Type) {\r\n\t\treturn rn.raft.Step(m)\r\n\t}\r\n\treturn ErrStepPeerNotFound\r\n}","code-length":113,"reference":"\/\/ Step advances the state machine using the given message.","result":"Step a node.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) Ready() Ready {\r\n\trd := rn.newReady()\r\n\trn.raft.msgs = nil\r\n\trn.raft.reduceUncommittedSize(rd.CommittedEntries)\r\n\treturn rd\r\n}","code-length":66,"reference":"\/\/ Ready returns the current point-in-time state of this RawNode.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) WithProgress(visitor func(id uint64, typ ProgressType, pr Progress)) {\r\n\tfor id, pr := range rn.raft.prs {\r\n\t\tpr := *pr\r\n\t\tpr.ins = nil\r\n\t\tvisitor(id, ProgressTypePeer, pr)\r\n\t}\r\n\tfor id, pr := range rn.raft.learnerPrs {\r\n\t\tpr := *pr\r\n\t\tpr.ins = nil\r\n\t\tvisitor(id, ProgressTypeLearner, pr)\r\n\t}\r\n}","code-length":145,"reference":"\/\/ WithProgress is a helper to introspect the Progress for this node and its\n\/\/ peers.","result":"Set the node.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) ReportUnreachable(id uint64) {\r\n\t_ = rn.raft.Step(pb.Message{Type: pb.MsgUnreachable, From: id})\r\n}","code-length":55,"reference":"\/\/ ReportUnreachable reports the given node is not reachable for the last send.","result":"Report unreachable nodes.","score":[0,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) ReportSnapshot(id uint64, status SnapshotStatus) {\r\n\trej := status == SnapshotFailure\r\n\t_ = rn.raft.Step(pb.Message{Type: pb.MsgSnapStatus, From: id, Reject: rej})\r\n}","code-length":73,"reference":"\/\/ ReportSnapshot reports the status of the sent snapshot.","result":"Report snapshot.","score":[0.0151,0.1205]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) TransferLeader(transferee uint64) {\r\n\t_ = rn.raft.Step(pb.Message{Type: pb.MsgTransferLeader, From: transferee})\r\n}","code-length":56,"reference":"\/\/ TransferLeader tries to transfer leadership to the given transferee.","result":"Store the raw data in a file.","score":[0.1052,0.0515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) ReadIndex(rctx []byte) {\r\n\t_ = rn.raft.Step(pb.Message{Type: pb.MsgReadIndex, Entries: []pb.Entry{{Data: rctx}}})\r\n}","code-length":63,"reference":"\/\/ ReadIndex requests a read state. The read state will be set in ready.\n\/\/ Read State has a read index. Once the application advances further than the read\n\/\/ index, any linearizable read requests issued before the read request can be\n\/\/ processed safely. The read state will have the same rctx attached.","result":"Read index.","score":[0.0,0.0205]}
{"code":"\/*is used to<extra_id_0>\r\nfunc printcURL(req *http.Request) error {\r\n\tif !cURLDebug {\r\n\t\treturn nil\r\n\t}\r\n\tvar (\r\n\t\tcommand string\r\n\t\tb       []byte\r\n\t\terr     error\r\n\t)\r\n\tif req.URL != nil {\r\n\t\tcommand = fmt.Sprintf(\"curl -X %s %s\", req.Method, req.URL.String())\r\n\t}\r\n\tif req.Body != nil {\r\n\t\tb, err = ioutil.ReadAll(req.Body)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tcommand += fmt.Sprintf(\" -d %q\", string(b))\r\n\t}\r\n\tfmt.Fprintf(os.Stderr, \"cURL Command: %s\\n\", command)\r\n\t\r\n\tbody := bytes.NewBuffer(b)\r\n\treq.Body = ioutil.NopCloser(body)\r\n\treturn nil\r\n}","code-length":247,"reference":"\/\/ printcURL prints the cURL equivalent request to stderr.\n\/\/ It returns an error if the body of the request cannot\n\/\/ be read.\n\/\/ The caller MUST cancel the request if there is an error.","result":"Print the cURL command.","score":[0.0002,0.0457]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StartNode(c *Config, peers []Peer) Node {\r\n\tr := newRaft(c)\r\n\t\r\n\t\r\n\tr.becomeFollower(1, None)\r\n\tfor _, peer := range peers {\r\n\t\tcc := pb.ConfChange{Type: pb.ConfChangeAddNode, NodeID: peer.ID, Context: peer.Context}\r\n\t\td, err := cc.Marshal()\r\n\t\tif err != nil {\r\n\t\t\tpanic(\"unexpected marshal error\")\r\n\t\t}\r\n\t\te := pb.Entry{Type: pb.EntryConfChange, Term: 1, Index: r.raftLog.lastIndex() + 1, Data: d}\r\n\t\tr.raftLog.append(e)\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tr.raftLog.committed = r.raftLog.lastIndex()\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tfor _, peer := range peers {\r\n\t\tr.addNode(peer.ID)\r\n\t}\r\n\tn := newNode()\r\n\tn.logger = c.Logger\r\n\tgo n.run(r)\r\n\treturn &n\r\n}","code-length":310,"reference":"\/\/ StartNode returns a new Node given configuration and a list of raft peers.\n\/\/ It appends a ConfChangeAddNode entry for each given peer to the initial log.","result":"Start a new node.","score":[0.0011,0.0391]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RestartNode(c *Config) Node {\r\n\tr := newRaft(c)\r\n\tn := newNode()\r\n\tn.logger = c.Logger\r\n\tgo n.run(r)\r\n\treturn &n\r\n}","code-length":66,"reference":"\/\/ RestartNode is similar to StartNode but does not take a list of peers.\n\/\/ The current membership of the cluster will be restored from the Storage.\n\/\/ If the caller has an existing state machine, pass in the last log index that\n\/\/ has been applied to it; otherwise use zero.","result":"Restart raft.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *node) Tick() {\r\n\tselect {\r\n\tcase n.tickc <- struct{}{}:\r\n\tcase <-n.done:\r\n\tdefault:\r\n\t\tn.logger.Warningf(\"A tick missed to fire. Node blocks too long!\")\r\n\t}\r\n}","code-length":80,"reference":"\/\/ Tick increments the internal logical clock for this Node. Election timeouts\n\/\/ and heartbeat timeouts are in units of ticks.","result":"Fire a tick on the node.","score":[0.0158,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MustSync(st, prevst pb.HardState, entsnum int) bool {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\treturn entsnum != 0 || st.Vote != prevst.Vote || st.Term != prevst.Term\r\n}","code-length":74,"reference":"\/\/ MustSync returns true if the hard state and count of Raft entries indicate\n\/\/ that a synchronous write to persistent storage is required.","result":"Sync the state.","score":[0.0004,0.0228]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewGRPC17Health(\r\n\teps []string,\r\n\ttimeout time.Duration,\r\n\tdialFunc DialFunc,\r\n) *GRPC17Health {\r\n\tnotifyCh := make(chan []grpc.Address)\r\n\taddrs := eps2addrs(eps)\r\n\thb := &GRPC17Health{\r\n\t\taddrs:              addrs,\r\n\t\teps:                eps,\r\n\t\tnotifyCh:           notifyCh,\r\n\t\treadyc:             make(chan struct{}),\r\n\t\thealthCheck:        func(ep string) (bool, error) { return grpcHealthCheck(ep, dialFunc) },\r\n\t\tunhealthyHostPorts: make(map[string]time.Time),\r\n\t\tupc:                make(chan struct{}),\r\n\t\tstopc:              make(chan struct{}),\r\n\t\tdownc:              make(chan struct{}),\r\n\t\tdonec:              make(chan struct{}),\r\n\t\tupdateAddrsC:       make(chan NotifyMsg),\r\n\t\thostPort2ep:        getHostPort2ep(eps),\r\n\t}\r\n\tif timeout < minHealthRetryDuration {\r\n\t\ttimeout = minHealthRetryDuration\r\n\t}\r\n\thb.healthCheckTimeout = timeout\r\n\tclose(hb.downc)\r\n\tgo hb.updateNotifyLoop()\r\n\thb.wg.Add(1)\r\n\tgo func() {\r\n\t\tdefer hb.wg.Done()\r\n\t\thb.updateUnhealthy()\r\n\t}()\r\n\treturn hb\r\n}","code-length":376,"reference":"\/\/ NewGRPC17Health returns a new health balancer with gRPC v1.7.","result":"Create a new health check .","score":[0.2042,0.3067]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *GRPC17Health) NeedUpdate() bool {\r\n\t\r\n\t\r\n\t\r\n\tb.mu.RLock()\r\n\tupdate := !hasAddr(b.addrs, b.pinAddr)\r\n\tb.mu.RUnlock()\r\n\treturn update\r\n}","code-length":77,"reference":"\/\/ NeedUpdate returns true if all connections are down or\n\/\/ addresses do not include current pinned address.","result":"Check if the health is up.","score":[0.0261,0.0298]}
{"code":"\/*is used to<extra_id_0>\r\nfunc dflSignal(sig syscall.Signal) {\r\n\t\r\n\tvar sigactBuf [32]uint64\r\n\tptr := unsafe.Pointer(&sigactBuf)\r\n\tsyscall.Syscall6(uintptr(syscall.SYS_RT_SIGACTION), uintptr(sig), uintptr(ptr), 0, 8, 0, 0)\r\n}","code-length":91,"reference":"\/\/ dflSignal sets the given signal to SIG_DFL","result":"Signal the DFL driver.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(namespaces ...string) Store {\r\n\ts := newStore(namespaces...)\r\n\ts.clock = clockwork.NewRealClock()\r\n\treturn s\r\n}","code-length":50,"reference":"\/\/ New creates a store where the given namespaces will be created as initial directories.","result":"Create a new store.","score":[0.0204,0.1079]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) Index() uint64 {\r\n\ts.worldLock.RLock()\r\n\tdefer s.worldLock.RUnlock()\r\n\treturn s.CurrentIndex\r\n}","code-length":54,"reference":"\/\/ Index retrieves the current index of the store.","result":"Generate the index code.","score":[0.1088,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) Get(nodePath string, recursive, sorted bool) (*Event, error) {\r\n\tvar err *v2error.Error\r\n\ts.worldLock.RLock()\r\n\tdefer s.worldLock.RUnlock()\r\n\tdefer func() {\r\n\t\tif err == nil {\r\n\t\t\ts.Stats.Inc(GetSuccess)\r\n\t\t\tif recursive {\r\n\t\t\t\treportReadSuccess(GetRecursive)\r\n\t\t\t} else {\r\n\t\t\t\treportReadSuccess(Get)\r\n\t\t\t}\r\n\t\t\treturn\r\n\t\t}\r\n\t\ts.Stats.Inc(GetFail)\r\n\t\tif recursive {\r\n\t\t\treportReadFailure(GetRecursive)\r\n\t\t} else {\r\n\t\t\treportReadFailure(Get)\r\n\t\t}\r\n\t}()\r\n\tn, err := s.internalGet(nodePath)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\te := newEvent(Get, nodePath, n.ModifiedIndex, n.CreatedIndex)\r\n\te.EtcdIndex = s.CurrentIndex\r\n\te.Node.loadInternalNode(n, recursive, sorted, s.clock)\r\n\treturn e, nil\r\n}","code-length":304,"reference":"\/\/ Get returns a get event.\n\/\/ If recursive is true, it will return all the content under the node path.\n\/\/ If sorted is true, it will sort the content by keys.","result":"Get the node at the given path.","score":[0.007,0.1403]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) Create(nodePath string, dir bool, value string, unique bool, expireOpts TTLOptionSet) (*Event, error) {\r\n\tvar err *v2error.Error\r\n\ts.worldLock.Lock()\r\n\tdefer s.worldLock.Unlock()\r\n\tdefer func() {\r\n\t\tif err == nil {\r\n\t\t\ts.Stats.Inc(CreateSuccess)\r\n\t\t\treportWriteSuccess(Create)\r\n\t\t\treturn\r\n\t\t}\r\n\t\ts.Stats.Inc(CreateFail)\r\n\t\treportWriteFailure(Create)\r\n\t}()\r\n\te, err := s.internalCreate(nodePath, dir, value, unique, false, expireOpts.ExpireTime, Create)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\te.EtcdIndex = s.CurrentIndex\r\n\ts.WatcherHub.notify(e)\r\n\treturn e, nil\r\n}","code-length":238,"reference":"\/\/ Create creates the node at nodePath. Create will help to create intermediate directories with no ttl.\n\/\/ If the node has already existed, create will fail.\n\/\/ If any node on the path is a file, create will fail.","result":"Create a node in etcd.","score":[0.0003,0.0411]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) Set(nodePath string, dir bool, value string, expireOpts TTLOptionSet) (*Event, error) {\r\n\tvar err *v2error.Error\r\n\ts.worldLock.Lock()\r\n\tdefer s.worldLock.Unlock()\r\n\tdefer func() {\r\n\t\tif err == nil {\r\n\t\t\ts.Stats.Inc(SetSuccess)\r\n\t\t\treportWriteSuccess(Set)\r\n\t\t\treturn\r\n\t\t}\r\n\t\ts.Stats.Inc(SetFail)\r\n\t\treportWriteFailure(Set)\r\n\t}()\r\n\t\r\n\tn, getErr := s.internalGet(nodePath)\r\n\tif getErr != nil && getErr.ErrorCode != v2error.EcodeKeyNotFound {\r\n\t\terr = getErr\r\n\t\treturn nil, err\r\n\t}\r\n\tif expireOpts.Refresh {\r\n\t\tif getErr != nil {\r\n\t\t\terr = getErr\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tvalue = n.Value\r\n\t}\r\n\t\r\n\te, err := s.internalCreate(nodePath, dir, value, false, true, expireOpts.ExpireTime, Set)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\te.EtcdIndex = s.CurrentIndex\r\n\t\r\n\tif getErr == nil {\r\n\t\tprev := newEvent(Get, nodePath, n.ModifiedIndex, n.CreatedIndex)\r\n\t\tprev.Node.loadInternalNode(n, false, false, s.clock)\r\n\t\te.PrevNode = prev.Node\r\n\t}\r\n\tif !expireOpts.Refresh {\r\n\t\ts.WatcherHub.notify(e)\r\n\t} else {\r\n\t\te.SetRefresh()\r\n\t\ts.WatcherHub.add(e)\r\n\t}\r\n\treturn e, nil\r\n}","code-length":469,"reference":"\/\/ Set creates or replace the node at nodePath.","result":"Set the value of a node in etcd.","score":[0.1613,0.1685]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getCompareFailCause(n *node, which int, prevValue string, prevIndex uint64) string {\r\n\tswitch which {\r\n\tcase CompareIndexNotMatch:\r\n\t\treturn fmt.Sprintf(\"[%v != %v]\", prevIndex, n.ModifiedIndex)\r\n\tcase CompareValueNotMatch:\r\n\t\treturn fmt.Sprintf(\"[%v != %v]\", prevValue, n.Value)\r\n\tdefault:\r\n\t\treturn fmt.Sprintf(\"[%v != %v] [%v != %v]\", prevValue, n.Value, prevIndex, n.ModifiedIndex)\r\n\t}\r\n}","code-length":156,"reference":"\/\/ returns user-readable cause of failed comparison","result":"Get the compare fail cause.","score":[0,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) Delete(nodePath string, dir, recursive bool) (*Event, error) {\r\n\tvar err *v2error.Error\r\n\ts.worldLock.Lock()\r\n\tdefer s.worldLock.Unlock()\r\n\tdefer func() {\r\n\t\tif err == nil {\r\n\t\t\ts.Stats.Inc(DeleteSuccess)\r\n\t\t\treportWriteSuccess(Delete)\r\n\t\t\treturn\r\n\t\t}\r\n\t\ts.Stats.Inc(DeleteFail)\r\n\t\treportWriteFailure(Delete)\r\n\t}()\r\n\tnodePath = path.Clean(path.Join(\"\/\", nodePath))\r\n\t\r\n\tif s.readonlySet.Contains(nodePath) {\r\n\t\treturn nil, v2error.NewError(v2error.EcodeRootROnly, \"\/\", s.CurrentIndex)\r\n\t}\r\n\t\r\n\tif recursive {\r\n\t\tdir = true\r\n\t}\r\n\tn, err := s.internalGet(nodePath)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tnextIndex := s.CurrentIndex + 1\r\n\te := newEvent(Delete, nodePath, nextIndex, n.CreatedIndex)\r\n\te.EtcdIndex = nextIndex\r\n\te.PrevNode = n.Repr(false, false, s.clock)\r\n\teNode := e.Node\r\n\tif n.IsDir() {\r\n\t\teNode.Dir = true\r\n\t}\r\n\tcallback := func(path string) {\r\n\t\t\r\n\t\ts.WatcherHub.notifyWatchers(e, path, true)\r\n\t}\r\n\terr = n.Remove(dir, recursive, callback)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\ts.CurrentIndex++\r\n\ts.WatcherHub.notify(e)\r\n\treturn e, nil\r\n}","code-length":467,"reference":"\/\/ Delete deletes the node at the given path.\n\/\/ If the node is a directory, recursive must be true to delete it.","result":"Delete a node.","score":[0.0006,0.0476]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) walk(nodePath string, walkFunc func(prev *node, component string) (*node, *v2error.Error)) (*node, *v2error.Error) {\r\n\tcomponents := strings.Split(nodePath, \"\/\")\r\n\tcurr := s.Root\r\n\tvar err *v2error.Error\r\n\tfor i := 1; i < len(components); i++ {\r\n\t\tif len(components[i]) == 0 {\r\n\t\t\treturn curr, nil\r\n\t\t}\r\n\t\tcurr, err = walkFunc(curr, components[i])\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\treturn curr, nil\r\n}","code-length":185,"reference":"\/\/ walk walks all the nodePath and apply the walkFunc on each directory","result":"Generate the code.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) internalGet(nodePath string) (*node, *v2error.Error) {\r\n\tnodePath = path.Clean(path.Join(\"\/\", nodePath))\r\n\twalkFunc := func(parent *node, name string) (*node, *v2error.Error) {\r\n\t\tif !parent.IsDir() {\r\n\t\t\terr := v2error.NewError(v2error.EcodeNotDir, parent.Path, s.CurrentIndex)\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tchild, ok := parent.Children[name]\r\n\t\tif ok {\r\n\t\t\treturn child, nil\r\n\t\t}\r\n\t\treturn nil, v2error.NewError(v2error.EcodeKeyNotFound, path.Join(parent.Path, name), s.CurrentIndex)\r\n\t}\r\n\tf, err := s.walk(nodePath, walkFunc)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn f, nil\r\n}","code-length":258,"reference":"\/\/ InternalGet gets the node of the given nodePath.","result":"Get the value of a node.","score":[0.1392,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) DeleteExpiredKeys(cutoff time.Time) {\r\n\ts.worldLock.Lock()\r\n\tdefer s.worldLock.Unlock()\r\n\tfor {\r\n\t\tnode := s.ttlKeyHeap.top()\r\n\t\tif node == nil || node.ExpireTime.After(cutoff) {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\ts.CurrentIndex++\r\n\t\te := newEvent(Expire, node.Path, s.CurrentIndex, node.CreatedIndex)\r\n\t\te.EtcdIndex = s.CurrentIndex\r\n\t\te.PrevNode = node.Repr(false, false, s.clock)\r\n\t\tif node.IsDir() {\r\n\t\t\te.Node.Dir = true\r\n\t\t}\r\n\t\tcallback := func(path string) {\r\n\t\t\t\r\n\t\t\ts.WatcherHub.notifyWatchers(e, path, true)\r\n\t\t}\r\n\t\ts.ttlKeyHeap.pop()\r\n\t\tnode.Remove(true, true, callback)\r\n\t\treportExpiredKey()\r\n\t\ts.Stats.Inc(ExpireCount)\r\n\t\ts.WatcherHub.notify(e)\r\n\t}\r\n}","code-length":296,"reference":"\/\/ DeleteExpiredKeys will delete all expired keys","result":"Delete expired keys.","score":[0.1076,0.1515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) checkDir(parent *node, dirName string) (*node, *v2error.Error) {\r\n\tnode, ok := parent.Children[dirName]\r\n\tif ok {\r\n\t\tif node.IsDir() {\r\n\t\t\treturn node, nil\r\n\t\t}\r\n\t\treturn nil, v2error.NewError(v2error.EcodeNotDir, node.Path, s.CurrentIndex)\r\n\t}\r\n\tn := newDir(s, path.Join(parent.Path, dirName), s.CurrentIndex+1, parent, Permanent)\r\n\tparent.Children[dirName] = n\r\n\treturn n, nil\r\n}","code-length":171,"reference":"\/\/ checkDir will check whether the component is a directory under parent node.\n\/\/ If it is a directory, this function will return the pointer to that node.\n\/\/ If it does not exist, this function will create a new directory and return the pointer to that node.\n\/\/ If it is a file, this function will return error.","result":"Check if a directory exists in a file.","score":[0.0004,0.0464]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) Save() ([]byte, error) {\r\n\tb, err := json.Marshal(s.Clone())\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn b, nil\r\n}","code-length":69,"reference":"\/\/ Save saves the static state of the store system.\n\/\/ It will not be able to save the state of watchers.\n\/\/ It will not save the parent field of the node. Or there will\n\/\/ be cyclic dependencies issue for the json package.","result":"Save the store.","score":[0.0,0.0245]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) Recovery(state []byte) error {\r\n\ts.worldLock.Lock()\r\n\tdefer s.worldLock.Unlock()\r\n\terr := json.Unmarshal(state, s)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ts.ttlKeyHeap = newTtlKeyHeap()\r\n\ts.Root.recoverAndclean()\r\n\treturn nil\r\n}","code-length":109,"reference":"\/\/ Recovery recovers the store system from a static state\n\/\/ It needs to recover the parent field of the nodes.\n\/\/ It needs to delete the expired nodes since the saved time and also\n\/\/ needs to create monitoring go routines.","result":"Recover the state.","score":[0.0,0.0262]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Generator) Next() uint64 {\r\n\tsuffix := atomic.AddUint64(&g.suffix, 1)\r\n\tid := g.prefix | lowbit(suffix, suffixLen)\r\n\treturn id\r\n}","code-length":63,"reference":"\/\/ Next generates a id that is unique.","result":"Generate the next value.","score":[0,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMakeMirrorCommand() *cobra.Command {\r\n\tc := &cobra.Command{\r\n\t\tUse:   \"make-mirror [options] <destination>\",\r\n\t\tShort: \"Makes a mirror at the destination etcd cluster\",\r\n\t\tRun:   makeMirrorCommandFunc,\r\n\t}\r\n\tc.Flags().StringVar(&mmprefix, \"prefix\", \"\", \"Key-value prefix to mirror\")\r\n\tc.Flags().StringVar(&mmdestprefix, \"dest-prefix\", \"\", \"destination prefix to mirror a prefix to a different prefix in the destination cluster\")\r\n\tc.Flags().BoolVar(&mmnodestprefix, \"no-dest-prefix\", false, \"mirror key-values to the root of the destination cluster\")\r\n\tc.Flags().StringVar(&mmcert, \"dest-cert\", \"\", \"Identify secure client using this TLS certificate file for the destination cluster\")\r\n\tc.Flags().StringVar(&mmkey, \"dest-key\", \"\", \"Identify secure client using this TLS key file\")\r\n\tc.Flags().StringVar(&mmcacert, \"dest-cacert\", \"\", \"Verify certificates of TLS enabled secure servers using this CA bundle\")\r\n\t\r\n\tc.Flags().BoolVar(&mminsecureTr, \"dest-insecure-transport\", true, \"Disable transport security for client connections\")\r\n\treturn c\r\n}","code-length":334,"reference":"\/\/ NewMakeMirrorCommand returns the cobra command for \"makeMirror\".","result":"Create a new etcd cluster.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewZapCoreLoggerBuilder(lg *zap.Logger, cr zapcore.Core, syncer zapcore.WriteSyncer) func(*Config) error {\r\n\treturn func(cfg *Config) error {\r\n\t\tcfg.loggerMu.Lock()\r\n\t\tdefer cfg.loggerMu.Unlock()\r\n\t\tcfg.logger = lg\r\n\t\tcfg.loggerConfig = nil\r\n\t\tcfg.loggerCore = cr\r\n\t\tcfg.loggerWriteSyncer = syncer\r\n\t\tgrpcLogOnce.Do(func() {\r\n\t\t\tgrpclog.SetLoggerV2(logutil.NewGRPCLoggerV2FromZapCore(cr, syncer))\r\n\t\t})\r\n\t\treturn nil\r\n\t}\r\n}","code-length":183,"reference":"\/\/ NewZapCoreLoggerBuilder generates a zap core logger builder.","result":"Build the zap core logger builder.","score":[0.433,0.5088]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSyncer(c *clientv3.Client, prefix string, rev int64) Syncer {\r\n\treturn &syncer{c: c, prefix: prefix, rev: rev}\r\n}","code-length":55,"reference":"\/\/ NewSyncer creates a Syncer.","result":"Create a new syncer.","score":[0.2488,0.5215]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DropPort(port int) error {\r\n\tcmdStr := fmt.Sprintf(\"sudo iptables -A OUTPUT -p tcp --destination-port %d -j DROP\", port)\r\n\tif _, err := exec.Command(\"\/bin\/sh\", \"-c\", cmdStr).Output(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tcmdStr = fmt.Sprintf(\"sudo iptables -A INPUT -p tcp --destination-port %d -j DROP\", port)\r\n\t_, err := exec.Command(\"\/bin\/sh\", \"-c\", cmdStr).Output()\r\n\treturn err\r\n}","code-length":151,"reference":"\/\/ DropPort drops all tcp packets that are received from the given port and sent to the given port.","result":"Drop a port.","score":[0.002,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetLatency(ms, rv int) error {\r\n\tifces, err := GetDefaultInterfaces()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif rv > ms {\r\n\t\trv = 1\r\n\t}\r\n\tfor ifce := range ifces {\r\n\t\tcmdStr := fmt.Sprintf(\"sudo tc qdisc add dev %s root netem delay %dms %dms distribution normal\", ifce, ms, rv)\r\n\t\t_, err = exec.Command(\"\/bin\/sh\", \"-c\", cmdStr).Output()\r\n\t\tif err != nil {\r\n\t\t\t\r\n\t\t\tcmdStr = fmt.Sprintf(\"sudo tc qdisc change dev %s root netem delay %dms %dms distribution normal\", ifce, ms, rv)\r\n\t\t\t_, err = exec.Command(\"\/bin\/sh\", \"-c\", cmdStr).Output()\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":261,"reference":"\/\/ SetLatency adds latency in millisecond scale with random variations.","result":"Set the latency of the network interface.","score":[0.1052,0.0515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RemoveLatency() error {\r\n\tifces, err := GetDefaultInterfaces()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfor ifce := range ifces {\r\n\t\t_, err = exec.Command(\"\/bin\/sh\", \"-c\", fmt.Sprintf(\"sudo tc qdisc del dev %s root netem\", ifce)).Output()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":132,"reference":"\/\/ RemoveLatency resets latency configurations.","result":"Remove latency from the network interface.","score":[0.193,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTxnCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"txn [options]\",\r\n\t\tShort: \"Txn processes all the requests in one transaction\",\r\n\t\tRun:   txnCommandFunc,\r\n\t}\r\n\tcmd.Flags().BoolVarP(&txnInteractive, \"interactive\", \"i\", false, \"Input transaction in interactive mode\")\r\n\treturn cmd\r\n}","code-length":115,"reference":"\/\/ NewTxnCommand returns the cobra command for \"txn\".","result":"Create a transaction.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc txnCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 0 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"txn command does not accept argument\"))\r\n\t}\r\n\treader := bufio.NewReader(os.Stdin)\r\n\ttxn := mustClientFromCmd(cmd).Txn(context.Background())\r\n\tpromptInteractive(\"compares:\")\r\n\ttxn.If(readCompares(reader)...)\r\n\tpromptInteractive(\"success requests (get, put, del):\")\r\n\ttxn.Then(readOps(reader)...)\r\n\tpromptInteractive(\"failure requests (get, put, del):\")\r\n\ttxn.Else(readOps(reader)...)\r\n\tresp, err := txn.Commit()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.Txn(*resp)\r\n}","code-length":228,"reference":"\/\/ txnCommandFunc executes the \"txn\" command.","result":"Run the command .","score":[0.1938,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(\r\n\tlg *zap.Logger,\r\n\tmode string,\r\n\tretention time.Duration,\r\n\trg RevGetter,\r\n\tc Compactable,\r\n) (Compactor, error) {\r\n\tswitch mode {\r\n\tcase ModePeriodic:\r\n\t\treturn newPeriodic(lg, clockwork.NewRealClock(), retention, rg, c), nil\r\n\tcase ModeRevision:\r\n\t\treturn newRevision(lg, clockwork.NewRealClock(), int64(retention), rg, c), nil\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"unsupported compaction mode %s\", mode)\r\n\t}\r\n}","code-length":164,"reference":"\/\/ New returns a new Compactor based on given \"mode\".","result":"Create a new compactor.","score":[0.1008,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc printResponseKey(resp *client.Response, format string) {\r\n\t\r\n\tswitch format {\r\n\tcase \"simple\":\r\n\t\tif resp.Action != \"delete\" {\r\n\t\t\tfmt.Println(resp.Node.Value)\r\n\t\t} else {\r\n\t\t\tfmt.Println(\"PrevNode.Value:\", resp.PrevNode.Value)\r\n\t\t}\r\n\tcase \"extended\":\r\n\t\t\r\n\t\tfmt.Println(\"Key:\", resp.Node.Key)\r\n\t\tfmt.Println(\"Created-Index:\", resp.Node.CreatedIndex)\r\n\t\tfmt.Println(\"Modified-Index:\", resp.Node.ModifiedIndex)\r\n\t\tif resp.PrevNode != nil {\r\n\t\t\tfmt.Println(\"PrevNode.Value:\", resp.PrevNode.Value)\r\n\t\t}\r\n\t\tfmt.Println(\"TTL:\", resp.Node.TTL)\r\n\t\tfmt.Println(\"Index:\", resp.Index)\r\n\t\tif resp.Action != \"delete\" {\r\n\t\t\tfmt.Println(\"\")\r\n\t\t\tfmt.Println(resp.Node.Value)\r\n\t\t}\r\n\tcase \"json\":\r\n\t\tb, err := json.Marshal(resp)\r\n\t\tif err != nil {\r\n\t\t\tpanic(err)\r\n\t\t}\r\n\t\tfmt.Println(string(b))\r\n\tdefault:\r\n\t\tfmt.Fprintln(os.Stderr, \"Unsupported output format:\", format)\r\n\t}\r\n}","code-length":378,"reference":"\/\/ printResponseKey only supports to print key correctly.","result":"Print the response key.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterLockHandler(ctx context.Context, mux *runtime.ServeMux, conn *grpc.ClientConn) error {\r\n\treturn RegisterLockHandlerClient(ctx, mux, v3lockpb.NewLockClient(conn))\r\n}","code-length":62,"reference":"\/\/ RegisterLockHandler registers the http handlers for service Lock to \"mux\".\n\/\/ The handlers forward requests to the grpc endpoint over \"conn\".","result":"Register the handler for the v.","score":[0.0177,0.1824]}
{"code":"\/*is used to<extra_id_0>\r\nfunc grpcHandlerFunc(grpcServer *grpc.Server, otherHandler http.Handler) http.Handler {\r\n\tif otherHandler == nil {\r\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\r\n\t\t\tgrpcServer.ServeHTTP(w, r)\r\n\t\t})\r\n\t}\r\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\r\n\t\tif r.ProtoMajor == 2 && strings.Contains(r.Header.Get(\"Content-Type\"), \"application\/grpc\") {\r\n\t\t\tgrpcServer.ServeHTTP(w, r)\r\n\t\t} else {\r\n\t\t\totherHandler.ServeHTTP(w, r)\r\n\t\t}\r\n\t})\r\n}","code-length":192,"reference":"\/\/ grpcHandlerFunc returns an http.Handler that delegates to grpcServer on incoming gRPC\n\/\/ connections or otherHandler otherwise. Given in gRPC docs.","result":"Handle grpc requests.","score":[0,0.026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc addCORSHeader(w http.ResponseWriter, origin string) {\r\n\tw.Header().Add(\"Access-Control-Allow-Methods\", \"POST, GET, OPTIONS, PUT, DELETE\")\r\n\tw.Header().Add(\"Access-Control-Allow-Origin\", origin)\r\n\tw.Header().Add(\"Access-Control-Allow-Headers\", \"accept, content-type, authorization\")\r\n}","code-length":101,"reference":"\/\/ addCORSHeader adds the correct cors headers given an origin","result":"Add CORS headers.","score":[0,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (txn *txnLeasing) fallback(ops []v3.Op) (fbOps []v3.Op) {\r\n\tfor _, op := range ops {\r\n\t\tif op.IsGet() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tlkey, lend := txn.lkv.pfx+string(op.KeyBytes()), \"\"\r\n\t\tif len(op.RangeBytes()) > 0 {\r\n\t\t\tlend = txn.lkv.pfx + string(op.RangeBytes())\r\n\t\t}\r\n\t\tfbOps = append(fbOps, v3.OpGet(lkey, v3.WithRange(lend)))\r\n\t}\r\n\treturn fbOps\r\n}","code-length":180,"reference":"\/\/ fallback computes the ops to fetch all possible conflicting\n\/\/ leasing keys for a list of ops.","result":"Fallback to leasing transaction.","score":[0.0115,0.0904]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IDFromString(s string) (ID, error) {\r\n\ti, err := strconv.ParseUint(s, 16, 64)\r\n\treturn ID(i), err\r\n}","code-length":52,"reference":"\/\/ IDFromString attempts to create an ID from a base-16 string.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (guard *directoryLockGuard) release() error {\r\n\tvar err error\r\n\tif !guard.readOnly {\r\n\t\t\r\n\t\terr = os.Remove(guard.path)\r\n\t}\r\n\tif closeErr := guard.f.Close(); err == nil {\r\n\t\terr = closeErr\r\n\t}\r\n\tguard.path = \"\"\r\n\tguard.f = nil\r\n\treturn err\r\n}","code-length":111,"reference":"\/\/ Release deletes the pid file and releases our lock on the directory.","result":"Release the lock.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v *ValueStruct) EncodedSize() uint16 {\r\n\tsz := len(v.Value) + 2\r\n\tif v.ExpiresAt == 0 {\r\n\t\treturn uint16(sz + 1)\r\n\t}\r\n\tenc := sizeVarint(v.ExpiresAt)\r\n\treturn uint16(sz + enc)\r\n}","code-length":89,"reference":"\/\/ EncodedSize is the size of the ValueStruct when encoded","result":"Encode the value.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v *ValueStruct) Decode(b []byte) {\r\n\tv.Meta = b[0]\r\n\tv.UserMeta = b[1]\r\n\tvar sz int\r\n\tv.ExpiresAt, sz = binary.Uvarint(b[2:])\r\n\tv.Value = b[2+sz:]\r\n}","code-length":88,"reference":"\/\/ Decode uses the length of the slice to infer the length of the Value field.","result":"Decode the value.","score":[0.0064,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMergeIterator(iters []Iterator, reversed bool) *MergeIterator {\r\n\tm := &MergeIterator{all: iters, reversed: reversed}\r\n\tm.h = make(elemHeap, 0, len(iters))\r\n\tm.initHeap()\r\n\treturn m\r\n}","code-length":77,"reference":"\/\/ NewMergeIterator returns a new MergeIterator from a list of Iterators.","result":"Create a new iterator.","score":[0.0785,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MergeIterator) initHeap() {\r\n\ts.h = s.h[:0]\r\n\tfor idx, itr := range s.all {\r\n\t\tif !itr.Valid() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\te := &elem{itr: itr, nice: idx, reversed: s.reversed}\r\n\t\ts.h = append(s.h, e)\r\n\t}\r\n\theap.Init(&s.h)\r\n\tfor len(s.h) > 0 {\r\n\t\tit := s.h[0].itr\r\n\t\tif it == nil || !it.Valid() {\r\n\t\t\theap.Pop(&s.h)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\ts.storeKey(s.h[0].itr)\r\n\t\tbreak\r\n\t}\r\n}","code-length":220,"reference":"\/\/ initHeap checks all iterators and initializes our heap and array of keys.\n\/\/ Whenever we reverse direction, we need to run this.","result":"Initialize the heap.","score":[0,0.0238]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MergeIterator) Valid() bool {\r\n\tif s == nil {\r\n\t\treturn false\r\n\t}\r\n\tif len(s.h) == 0 {\r\n\t\treturn false\r\n\t}\r\n\treturn s.h[0].itr.Valid()\r\n}","code-length":79,"reference":"\/\/ Valid returns whether the MergeIterator is at a valid element.","result":"Validate the merge iterator.","score":[0.0555,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MergeIterator) Key() []byte {\r\n\tif len(s.h) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\treturn s.h[0].itr.Key()\r\n}","code-length":62,"reference":"\/\/ Key returns the key associated with the current iterator","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MergeIterator) Value() ValueStruct {\r\n\tif len(s.h) == 0 {\r\n\t\treturn ValueStruct{}\r\n\t}\r\n\treturn s.h[0].itr.Value()\r\n}","code-length":64,"reference":"\/\/ Value returns the value associated with the iterator.","result":"Avoid recursive call.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MergeIterator) Next() {\r\n\tif len(s.h) == 0 {\r\n\t\treturn\r\n\t}\r\n\tsmallest := s.h[0].itr\r\n\tsmallest.Next()\r\n\tfor len(s.h) > 0 {\r\n\t\tsmallest = s.h[0].itr\r\n\t\tif !smallest.Valid() {\r\n\t\t\theap.Pop(&s.h)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\theap.Fix(&s.h, 0)\r\n\t\tsmallest = s.h[0].itr\r\n\t\tif smallest.Valid() {\r\n\t\t\tif !bytes.Equal(smallest.Key(), s.curKey) {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\tsmallest.Next()\r\n\t\t}\r\n\t}\r\n\tif !smallest.Valid() {\r\n\t\treturn\r\n\t}\r\n\ts.storeKey(smallest)\r\n}","code-length":249,"reference":"\/\/ Next returns the next element. If it is the same as the current key, ignore it.","result":"Avoid recursive call to Next.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MergeIterator) Seek(key []byte) {\r\n\tfor _, itr := range s.all {\r\n\t\titr.Seek(key)\r\n\t}\r\n\ts.initHeap()\r\n}","code-length":62,"reference":"\/\/ Seek brings us to element with key >= given key.","result":"Test the merge iterator.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MergeIterator) Close() error {\r\n\tfor _, itr := range s.all {\r\n\t\tif err := itr.Close(); err != nil {\r\n\t\t\treturn errors.Wrap(err, \"MergeIterator\")\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":80,"reference":"\/\/ Close implements y.Iterator","result":"Close the iterator.","score":[0.2925,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p valuePointer) Encode(b []byte) []byte {\r\n\tbinary.BigEndian.PutUint32(b[:4], p.Fid)\r\n\tbinary.BigEndian.PutUint32(b[4:8], p.Len)\r\n\tbinary.BigEndian.PutUint32(b[8:12], p.Offset)\r\n\treturn b[:vptrSize]\r\n}","code-length":102,"reference":"\/\/ Encode encodes Pointer into byte buffer.","result":"Encode the pointer to a value.","score":[0.1634,0.1449]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *header) Decode(buf []byte) {\r\n\th.klen = binary.BigEndian.Uint32(buf[0:4])\r\n\th.vlen = binary.BigEndian.Uint32(buf[4:8])\r\n\th.expiresAt = binary.BigEndian.Uint64(buf[8:16])\r\n\th.meta = buf[16]\r\n\th.userMeta = buf[17]\r\n}","code-length":114,"reference":"\/\/ Decodes h from buf.","result":"Decode the header.","score":[0,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc encodeEntry(e *Entry, buf *bytes.Buffer) (int, error) {\r\n\th := header{\r\n\t\tklen:      uint32(len(e.Key)),\r\n\t\tvlen:      uint32(len(e.Value)),\r\n\t\texpiresAt: e.ExpiresAt,\r\n\t\tmeta:      e.meta,\r\n\t\tuserMeta:  e.UserMeta,\r\n\t}\r\n\tvar headerEnc [headerBufSize]byte\r\n\th.Encode(headerEnc[:])\r\n\thash := crc32.New(y.CastagnoliCrcTable)\r\n\tbuf.Write(headerEnc[:])\r\n\thash.Write(headerEnc[:])\r\n\tbuf.Write(e.Key)\r\n\thash.Write(e.Key)\r\n\tbuf.Write(e.Value)\r\n\thash.Write(e.Value)\r\n\tvar crcBuf [crc32.Size]byte\r\n\tbinary.BigEndian.PutUint32(crcBuf[:], hash.Sum32())\r\n\tbuf.Write(crcBuf[:])\r\n\treturn len(headerEnc) + len(e.Key) + len(e.Value) + len(crcBuf), nil\r\n}","code-length":300,"reference":"\/\/ Encodes e to buf. Returns number of bytes written.","result":"Encode the entry.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wb *WriteBatch) SetEntry(e *Entry) error {\r\n\twb.Lock()\r\n\tdefer wb.Unlock()\r\n\tif err := wb.txn.SetEntry(e); err != ErrTxnTooBig {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif cerr := wb.commit(); cerr != nil {\r\n\t\treturn cerr\r\n\t}\r\n\t\r\n\t\r\n\tif err := wb.txn.SetEntry(e); err != nil {\r\n\t\twb.err = err\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":151,"reference":"\/\/ SetEntry is the equivalent of Txn.SetEntry.","result":"Set the entry in the batch.","score":[0.1634,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wb *WriteBatch) Set(k, v []byte, meta byte) error {\r\n\te := &Entry{Key: k, Value: v, UserMeta: meta}\r\n\treturn wb.SetEntry(e)\r\n}","code-length":64,"reference":"\/\/ Set is equivalent of Txn.SetWithMeta.","result":"Set the value of a key in a write batch.","score":[0.1291,0.1562]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wb *WriteBatch) SetWithTTL(key, val []byte, dur time.Duration) error {\r\n\texpire := time.Now().Add(dur).Unix()\r\n\te := &Entry{Key: key, Value: val, ExpiresAt: uint64(expire)}\r\n\treturn wb.SetEntry(e)\r\n}","code-length":86,"reference":"\/\/ SetWithTTL is equivalent of Txn.SetWithTTL.","result":"Set the value of a key in a write batch.","score":[0.1086,0.0781]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wb *WriteBatch) Delete(k []byte) error {\r\n\twb.Lock()\r\n\tdefer wb.Unlock()\r\n\tif err := wb.txn.Delete(k); err != ErrTxnTooBig {\r\n\t\treturn err\r\n\t}\r\n\tif err := wb.commit(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := wb.txn.Delete(k); err != nil {\r\n\t\twb.err = err\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":139,"reference":"\/\/ Delete is equivalent of Txn.Delete.","result":"Delete a key.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wb *WriteBatch) commit() error {\r\n\tif wb.err != nil {\r\n\t\treturn wb.err\r\n\t}\r\n\t\r\n\t\r\n\twb.wg.Add(1)\r\n\twb.txn.CommitWith(wb.callback)\r\n\twb.txn = wb.db.newTransaction(true, true)\r\n\t\r\n\twb.txn.readTs = wb.db.orc.readMark.DoneUntil()\r\n\treturn wb.err\r\n}","code-length":127,"reference":"\/\/ Caller to commit must hold a write lock.","result":"Commit the batch.","score":[0,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wb *WriteBatch) Flush() error {\r\n\twb.Lock()\r\n\t_ = wb.commit()\r\n\twb.txn.Discard()\r\n\twb.Unlock()\r\n\twb.wg.Wait()\r\n\t\r\n\treturn wb.err\r\n}","code-length":74,"reference":"\/\/ Flush must be called at the end to ensure that any pending writes get committed to Badger. Flush\n\/\/ returns any error stored by WriteBatch.","result":"Flush the batch.","score":[0.0002,0.0422]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wb *WriteBatch) Error() error {\r\n\twb.Lock()\r\n\tdefer wb.Unlock()\r\n\treturn wb.err\r\n}","code-length":45,"reference":"\/\/ Error returns any errors encountered so far. No commits would be run once an error is detected.","result":"Generate the error message.","score":[0.0096,0.0301]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) getMemTables() ([]*skl.Skiplist, func()) {\r\n\tdb.RLock()\r\n\tdefer db.RUnlock()\r\n\ttables := make([]*skl.Skiplist, len(db.imm)+1)\r\n\t\r\n\ttables[0] = db.mt\r\n\ttables[0].IncrRef()\r\n\t\r\n\tlast := len(db.imm) - 1\r\n\tfor i := range db.imm {\r\n\t\ttables[i+1] = db.imm[last-i]\r\n\t\ttables[i+1].IncrRef()\r\n\t}\r\n\treturn tables, func() {\r\n\t\tfor _, tbl := range tables {\r\n\t\t\ttbl.DecrRef()\r\n\t\t}\r\n\t}\r\n}","code-length":206,"reference":"\/\/ getMemtables returns the current memtables and get references.","result":"Avoid the need for the function .","score":[0.1214,0.0568]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) writeRequests(reqs []*request) error {\r\n\tif len(reqs) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\tdone := func(err error) {\r\n\t\tfor _, r := range reqs {\r\n\t\t\tr.Err = err\r\n\t\t\tr.Wg.Done()\r\n\t\t}\r\n\t}\r\n\tdb.elog.Printf(\"writeRequests called. Writing to value log\")\r\n\terr := db.vlog.write(reqs)\r\n\tif err != nil {\r\n\t\tdone(err)\r\n\t\treturn err\r\n\t}\r\n\tdb.elog.Printf(\"Writing to memtable\")\r\n\tvar count int\r\n\tfor _, b := range reqs {\r\n\t\tif len(b.Entries) == 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tcount += len(b.Entries)\r\n\t\tvar i uint64\r\n\t\tfor err = db.ensureRoomForWrite(); err == errNoRoom; err = db.ensureRoomForWrite() {\r\n\t\t\ti++\r\n\t\t\tif i%100 == 0 {\r\n\t\t\t\tdb.elog.Printf(\"Making room for writes\")\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\ttime.Sleep(10 * time.Millisecond)\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\tdone(err)\r\n\t\t\treturn errors.Wrap(err, \"writeRequests\")\r\n\t\t}\r\n\t\tif err := db.writeToLSM(b); err != nil {\r\n\t\t\tdone(err)\r\n\t\t\treturn errors.Wrap(err, \"writeRequests\")\r\n\t\t}\r\n\t\tdb.updateHead(b.Ptrs)\r\n\t}\r\n\tdone(nil)\r\n\tdb.elog.Printf(\"%d entries written\", count)\r\n\treturn nil\r\n}","code-length":463,"reference":"\/\/ writeRequests is called serially by only one goroutine.","result":"Var errNoRoom error.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) ensureRoomForWrite() error {\r\n\tvar err error\r\n\tdb.Lock()\r\n\tdefer db.Unlock()\r\n\tif db.mt.MemSize() < db.opt.MaxTableSize {\r\n\t\treturn nil\r\n\t}\r\n\ty.AssertTrue(db.mt != nil)\r\n\tselect {\r\n\tcase db.flushChan <- flushTask{mt: db.mt, vptr: db.vhead}:\r\n\t\tdb.elog.Printf(\"Flushing value log to disk if async mode.\")\r\n\t\t\r\n\t\terr = db.vlog.sync(db.vhead.Fid)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdb.elog.Printf(\"Flushing memtable, mt.size=%d size of flushChan: %d\\n\",\r\n\t\t\tdb.mt.MemSize(), len(db.flushChan))\r\n\t\t\r\n\t\tdb.imm = append(db.imm, db.mt)\r\n\t\tdb.mt = skl.NewSkiplist(arenaSize(db.opt))\r\n\t\t\r\n\t\treturn nil\r\n\tdefault:\r\n\t\t\r\n\t\treturn errNoRoom\r\n\t}\r\n}","code-length":310,"reference":"\/\/ ensureRoomForWrite is always called serially.","result":"Ensure room for write.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc writeLevel0Table(ft flushTask, f io.Writer) error {\r\n\titer := ft.mt.NewIterator()\r\n\tdefer iter.Close()\r\n\tb := table.NewTableBuilder()\r\n\tdefer b.Close()\r\n\tfor iter.SeekToFirst(); iter.Valid(); iter.Next() {\r\n\t\tif len(ft.dropPrefix) > 0 && bytes.HasPrefix(iter.Key(), ft.dropPrefix) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif err := b.Add(iter.Key(), iter.Value()); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\t_, err := f.Write(b.Finish())\r\n\treturn err\r\n}","code-length":185,"reference":"\/\/ WriteLevel0Table flushes memtable.","result":"Write the level.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) handleFlushTask(ft flushTask) error {\r\n\tif !ft.mt.Empty() {\r\n\t\t\r\n\t\tdb.opt.Debugf(\"Storing value log head: %+v\\n\", ft.vptr)\r\n\t\tdb.elog.Printf(\"Storing offset: %+v\\n\", ft.vptr)\r\n\t\toffset := make([]byte, vptrSize)\r\n\t\tft.vptr.Encode(offset)\r\n\t\t\r\n\t\t\r\n\t\theadTs := y.KeyWithTs(head, db.orc.nextTs())\r\n\t\tft.mt.Put(headTs, y.ValueStruct{Value: offset})\r\n\t\t\r\n\t\tdiscardStatsKey := y.KeyWithTs(lfDiscardStatsKey, 1)\r\n\t\tft.mt.Put(discardStatsKey, y.ValueStruct{Value: db.vlog.encodedDiscardStats()})\r\n\t}\r\n\tfileID := db.lc.reserveFileID()\r\n\tfd, err := y.CreateSyncedFile(table.NewFilename(fileID, db.opt.Dir), true)\r\n\tif err != nil {\r\n\t\treturn y.Wrap(err)\r\n\t}\r\n\t\r\n\tdirSyncCh := make(chan error)\r\n\tgo func() { dirSyncCh <- syncDir(db.opt.Dir) }()\r\n\terr = writeLevel0Table(ft, fd)\r\n\tdirSyncErr := <-dirSyncCh\r\n\tif err != nil {\r\n\t\tdb.elog.Errorf(\"ERROR while writing to level 0: %v\", err)\r\n\t\treturn err\r\n\t}\r\n\tif dirSyncErr != nil {\r\n\t\t\r\n\t\tdb.elog.Errorf(\"ERROR while syncing level directory: %v\", dirSyncErr)\r\n\t}\r\n\ttbl, err := table.OpenTable(fd, db.opt.TableLoadingMode, nil)\r\n\tif err != nil {\r\n\t\tdb.elog.Printf(\"ERROR while opening table: %v\", err)\r\n\t\treturn err\r\n\t}\r\n\t\r\n\terr = db.lc.addLevel0Table(tbl)\r\n\ttbl.DecrRef()\r\n\treturn err\r\n}","code-length":538,"reference":"\/\/ handleFlushTask must be run serially.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) flushMemtable(lc *y.Closer) error {\r\n\tdefer lc.Done()\r\n\tfor ft := range db.flushChan {\r\n\t\tif ft.mt == nil {\r\n\t\t\t\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tfor {\r\n\t\t\terr := db.handleFlushTask(ft)\r\n\t\t\tif err == nil {\r\n\t\t\t\t\r\n\t\t\t\tdb.Lock()\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\ty.AssertTrue(ft.mt == db.imm[0])\r\n\t\t\t\tdb.imm = db.imm[1:]\r\n\t\t\t\tft.mt.DecrRef()\r\n\t\t\t\tdb.Unlock()\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tdb.opt.Errorf(\"Failure while flushing memtable to disk: %v. Retrying...\\n\", err)\r\n\t\t\ttime.Sleep(time.Second)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":253,"reference":"\/\/ flushMemtable must keep running until we send it an empty flushTask. If there\n\/\/ are errors during handling the flush task, we'll retry indefinitely.","result":"Flush memtable to disk.","score":[0,0.0218]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) calculateSize() {\r\n\tnewInt := func(val int64) *expvar.Int {\r\n\t\tv := new(expvar.Int)\r\n\t\tv.Add(val)\r\n\t\treturn v\r\n\t}\r\n\ttotalSize := func(dir string) (int64, int64) {\r\n\t\tvar lsmSize, vlogSize int64\r\n\t\terr := filepath.Walk(dir, func(path string, info os.FileInfo, err error) error {\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\text := filepath.Ext(path)\r\n\t\t\tif ext == \".sst\" {\r\n\t\t\t\tlsmSize += info.Size()\r\n\t\t\t} else if ext == \".vlog\" {\r\n\t\t\t\tvlogSize += info.Size()\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t})\r\n\t\tif err != nil {\r\n\t\t\tdb.elog.Printf(\"Got error while calculating total size of directory: %s\", dir)\r\n\t\t}\r\n\t\treturn lsmSize, vlogSize\r\n\t}\r\n\tlsmSize, vlogSize := totalSize(db.opt.Dir)\r\n\ty.LSMSize.Set(db.opt.Dir, newInt(lsmSize))\r\n\t\r\n\tif db.opt.ValueDir != db.opt.Dir {\r\n\t\t_, vlogSize = totalSize(db.opt.ValueDir)\r\n\t}\r\n\ty.VlogSize.Set(db.opt.Dir, newInt(vlogSize))\r\n}","code-length":395,"reference":"\/\/ This function does a filewalk, calculates the size of vlog and sst files and stores it in\n\/\/ y.LSMSize and y.VlogSize.","result":"Calculate the size of the database.","score":[0.0276,0.1547]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) Size() (lsm, vlog int64) {\r\n\tif y.LSMSize.Get(db.opt.Dir) == nil {\r\n\t\tlsm, vlog = 0, 0\r\n\t\treturn\r\n\t}\r\n\tlsm = y.LSMSize.Get(db.opt.Dir).(*expvar.Int).Value()\r\n\tvlog = y.VlogSize.Get(db.opt.Dir).(*expvar.Int).Value()\r\n\treturn\r\n}","code-length":133,"reference":"\/\/ Size returns the size of lsm and value log files in bytes. It can be used to decide how often to\n\/\/ call RunValueLogGC.","result":"Compute the size of the database.","score":[0.0168,0.1106]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (seq *Sequence) Next() (uint64, error) {\r\n\tseq.Lock()\r\n\tdefer seq.Unlock()\r\n\tif seq.next >= seq.leased {\r\n\t\tif err := seq.updateLease(); err != nil {\r\n\t\t\treturn 0, err\r\n\t\t}\r\n\t}\r\n\tval := seq.next\r\n\tseq.next++\r\n\treturn val, nil\r\n}","code-length":110,"reference":"\/\/ Next would return the next integer in the sequence, updating the lease by running a transaction\n\/\/ if needed.","result":"Generate the code.","score":[0.0014,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (seq *Sequence) Release() error {\r\n\tseq.Lock()\r\n\tdefer seq.Unlock()\r\n\terr := seq.db.Update(func(txn *Txn) error {\r\n\t\tvar buf [8]byte\r\n\t\tbinary.BigEndian.PutUint64(buf[:], seq.next)\r\n\t\treturn txn.Set(seq.key, buf[:])\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tseq.leased = seq.next\r\n\treturn nil\r\n}","code-length":140,"reference":"\/\/ Release the leased sequence to avoid wasted integers. This should be done right\n\/\/ before closing the associated DB. However it is valid to use the sequence after\n\/\/ it was released, causing a new lease with full bandwidth.","result":"Release the sequence.","score":[0.0,0.0275]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) KeySplits(prefix []byte) []string {\r\n\tvar splits []string\r\n\tfor _, ti := range db.Tables() {\r\n\t\t\r\n\t\t\r\n\t\tif bytes.HasPrefix(ti.Right, prefix) {\r\n\t\t\tsplits = append(splits, string(ti.Right))\r\n\t\t}\r\n\t}\r\n\tsort.Strings(splits)\r\n\treturn splits\r\n}","code-length":111,"reference":"\/\/ KeySplits can be used to get rough key ranges to divide up iteration over\n\/\/ the DB.","result":"Split keys.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) Flatten(workers int) error {\r\n\tdb.stopCompactions()\r\n\tdefer db.startCompactions()\r\n\tcompactAway := func(cp compactionPriority) error {\r\n\t\tdb.opt.Infof(\"Attempting to compact with %+v\\n\", cp)\r\n\t\terrCh := make(chan error, 1)\r\n\t\tfor i := 0; i < workers; i++ {\r\n\t\t\tgo func() {\r\n\t\t\t\terrCh <- db.lc.doCompact(cp)\r\n\t\t\t}()\r\n\t\t}\r\n\t\tvar success int\r\n\t\tvar rerr error\r\n\t\tfor i := 0; i < workers; i++ {\r\n\t\t\terr := <-errCh\r\n\t\t\tif err != nil {\r\n\t\t\t\trerr = err\r\n\t\t\t\tdb.opt.Warningf(\"While running doCompact with %+v. Error: %v\\n\", cp, err)\r\n\t\t\t} else {\r\n\t\t\t\tsuccess++\r\n\t\t\t}\r\n\t\t}\r\n\t\tif success == 0 {\r\n\t\t\treturn rerr\r\n\t\t}\r\n\t\t\r\n\t\tdb.opt.Infof(\"%d compactor(s) succeeded. One or more tables from level %d compacted.\\n\",\r\n\t\t\tsuccess, cp.level)\r\n\t\treturn nil\r\n\t}\r\n\thbytes := func(sz int64) string {\r\n\t\treturn humanize.Bytes(uint64(sz))\r\n\t}\r\n\tfor {\r\n\t\tdb.opt.Infof(\"\\n\")\r\n\t\tvar levels []int\r\n\t\tfor i, l := range db.lc.levels {\r\n\t\t\tsz := l.getTotalSize()\r\n\t\t\tdb.opt.Infof(\"Level: %d. %8s Size. %8s Max.\\n\",\r\n\t\t\t\ti, hbytes(l.getTotalSize()), hbytes(l.maxTotalSize))\r\n\t\t\tif sz > 0 {\r\n\t\t\t\tlevels = append(levels, i)\r\n\t\t\t}\r\n\t\t}\r\n\t\tif len(levels) <= 1 {\r\n\t\t\tprios := db.lc.pickCompactLevels()\r\n\t\t\tif len(prios) == 0 || prios[0].score <= 1.0 {\r\n\t\t\t\tdb.opt.Infof(\"All tables consolidated into one level. Flattening done.\\n\")\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\tif err := compactAway(prios[0]); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tcp := compactionPriority{level: levels[0], score: 1.71}\r\n\t\tif err := compactAway(cp); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n}","code-length":688,"reference":"\/\/ Flatten can be used to force compactions on the LSM tree so all the tables fall on the same\n\/\/ level. This ensures that all the versions of keys are colocated and not split across multiple\n\/\/ levels, which is necessary after a restore from backup. During Flatten, live compactions are\n\/\/ stopped. Ideally, no writes are going on during Flatten. Otherwise, it would create competition\n\/\/ between flattening the tree and new tables being created at level zero.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Mmap(fd *os.File, writable bool, size int64) ([]byte, error) {\r\n\tmtype := unix.PROT_READ\r\n\tif writable {\r\n\t\tmtype |= unix.PROT_WRITE\r\n\t}\r\n\treturn unix.Mmap(int(fd.Fd()), 0, int(size), mtype, unix.MAP_SHARED)\r\n}","code-length":102,"reference":"\/\/ Mmap uses the mmap system call to memory-map a file. If writable is true,\n\/\/ memory protection of the pages is set so that they may be written to as well.","result":"Create a file map.","score":[0.0003,0.0171]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Madvise(b []byte, readahead bool) error {\r\n\tflags := unix.MADV_NORMAL\r\n\tif !readahead {\r\n\t\tflags = unix.MADV_RANDOM\r\n\t}\r\n\treturn madvise(b, flags)\r\n}","code-length":77,"reference":"\/\/ Madvise uses the madvise system call to give advise about the use of memory\n\/\/ when using a slice that is memory-mapped to a file. Set the readahead flag to\n\/\/ false if page references are expected in random order.","result":"Avoid the need for the madvise function.","score":[0.002,0.0399]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *oracle) setDiscardTs(ts uint64) {\r\n\to.Lock()\r\n\tdefer o.Unlock()\r\n\to.discardTs = ts\r\n}","code-length":52,"reference":"\/\/ Any deleted or invalid versions at or below ts would be discarded during\n\/\/ compaction to reclaim disk space in LSM tree and thence value log.","result":"Discard the current timestamp.","score":[0,0.0202]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *oracle) hasConflict(txn *Txn) bool {\r\n\tif len(txn.reads) == 0 {\r\n\t\treturn false\r\n\t}\r\n\tfor _, ro := range txn.reads {\r\n\t\t\r\n\t\t\r\n\t\tif ts, has := o.commits[ro]; has && ts > txn.readTs {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":114,"reference":"\/\/ hasConflict must be called while having a lock.","result":"Check for conflicts in the transaction.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (txn *Txn) Set(key, val []byte) error {\r\n\te := &Entry{\r\n\t\tKey:   key,\r\n\t\tValue: val,\r\n\t}\r\n\treturn txn.SetEntry(e)\r\n}","code-length":68,"reference":"\/\/ Set adds a key-value pair to the database.\n\/\/\n\/\/ It will return ErrReadOnlyTxn if update flag was set to false when creating the\n\/\/ transaction.\n\/\/\n\/\/ The current transaction keeps a reference to the key and val byte slice\n\/\/ arguments. Users must not modify key and val until the end of the transaction.","result":"Set the value of a key in a transaction.","score":[0.001,0.067]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (txn *Txn) SetWithMeta(key, val []byte, meta byte) error {\r\n\te := &Entry{Key: key, Value: val, UserMeta: meta}\r\n\treturn txn.SetEntry(e)\r\n}","code-length":65,"reference":"\/\/ SetWithMeta adds a key-value pair to the database, along with a metadata\n\/\/ byte.\n\/\/\n\/\/ This byte is stored alongside the key, and can be used as an aid to\n\/\/ interpret the value or store other contextual bits corresponding to the\n\/\/ key-value pair.\n\/\/\n\/\/ The current transaction keeps a reference to the key and val byte slice\n\/\/ arguments. Users must not modify key and val until the end of the transaction.","result":"Set the value of a key.","score":[0.0,0.0286]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (txn *Txn) Delete(key []byte) error {\r\n\te := &Entry{\r\n\t\tKey:  key,\r\n\t\tmeta: bitDelete,\r\n\t}\r\n\treturn txn.modify(e)\r\n}","code-length":66,"reference":"\/\/ Delete deletes a key.\n\/\/\n\/\/ This is done by adding a delete marker for the key at commit timestamp.  Any\n\/\/ reads happening before this timestamp would be unaffected. Any reads after\n\/\/ this commit would see the deletion.\n\/\/\n\/\/ The current transaction keeps a reference to the key byte slice argument.\n\/\/ Users must not modify the key until the end of the transaction.","result":"Delete a key.","score":[0.0,0.0244]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (txn *Txn) Get(key []byte) (item *Item, rerr error) {\r\n\tif len(key) == 0 {\r\n\t\treturn nil, ErrEmptyKey\r\n\t} else if txn.discarded {\r\n\t\treturn nil, ErrDiscardedTxn\r\n\t}\r\n\titem = new(Item)\r\n\tif txn.update {\r\n\t\tif e, has := txn.pendingWrites[string(key)]; has && bytes.Equal(key, e.Key) {\r\n\t\t\tif isDeletedOrExpired(e.meta, e.ExpiresAt) {\r\n\t\t\t\treturn nil, ErrKeyNotFound\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\titem.meta = e.meta\r\n\t\t\titem.val = e.Value\r\n\t\t\titem.userMeta = e.UserMeta\r\n\t\t\titem.key = key\r\n\t\t\titem.status = prefetched\r\n\t\t\titem.version = txn.readTs\r\n\t\t\titem.expiresAt = e.ExpiresAt\r\n\t\t\t\r\n\t\t\treturn item, nil\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\ttxn.addReadKey(key)\r\n\t}\r\n\tseek := y.KeyWithTs(key, txn.readTs)\r\n\tvs, err := txn.db.get(seek)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrapf(err, \"DB::Get key: %q\", key)\r\n\t}\r\n\tif vs.Value == nil && vs.Meta == 0 {\r\n\t\treturn nil, ErrKeyNotFound\r\n\t}\r\n\tif isDeletedOrExpired(vs.Meta, vs.ExpiresAt) {\r\n\t\treturn nil, ErrKeyNotFound\r\n\t}\r\n\titem.key = key\r\n\titem.version = vs.Version\r\n\titem.meta = vs.Meta\r\n\titem.userMeta = vs.UserMeta\r\n\titem.db = txn.db\r\n\titem.vptr = vs.Value\r\n\titem.txn = txn\r\n\titem.expiresAt = vs.ExpiresAt\r\n\treturn item, nil\r\n}","code-length":504,"reference":"\/\/ Get looks for key and returns corresponding Item.\n\/\/ If key is not found, ErrKeyNotFound is returned.","result":"Get the value of a key in a transaction.","score":[0.0533,0.0585]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (txn *Txn) CommitWith(cb func(error)) {\r\n\ttxn.commitPrecheck()\r\n\tdefer txn.Discard()\r\n\tif cb == nil {\r\n\t\tpanic(\"Nil callback provided to CommitWith\")\r\n\t}\r\n\tif len(txn.writes) == 0 {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tgo runTxnCallback(&txnCb{user: cb, err: nil})\r\n\t\treturn\r\n\t}\r\n\tcommitCb, err := txn.commitAndSend()\r\n\tif err != nil {\r\n\t\tgo runTxnCallback(&txnCb{user: cb, err: err})\r\n\t\treturn\r\n\t}\r\n\tgo runTxnCallback(&txnCb{user: cb, commit: commitCb})\r\n}","code-length":195,"reference":"\/\/ CommitWith acts like Commit, but takes a callback, which gets run via a\n\/\/ goroutine to avoid blocking this function. The callback is guaranteed to run,\n\/\/ so it is safe to increment sync.WaitGroup before calling CommitWith, and\n\/\/ decrementing it in the callback; to block until all callbacks are run.","result":"Avoid the need for the following code.","score":[0.0003,0.0421]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) View(fn func(txn *Txn) error) error {\r\n\tvar txn *Txn\r\n\tif db.opt.managedTxns {\r\n\t\ttxn = db.NewTransactionAt(math.MaxUint64, false)\r\n\t} else {\r\n\t\ttxn = db.NewTransaction(false)\r\n\t}\r\n\tdefer txn.Discard()\r\n\treturn fn(txn)\r\n}","code-length":108,"reference":"\/\/ View executes a function creating and managing a read-only transaction for the user. Error\n\/\/ returned by the function is relayed by the View method.\n\/\/ If View is used with managed transactions, it would assume a read timestamp of MaxUint64.","result":"Generate the code for the view function.","score":[0.0017,0.0519]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) Update(fn func(txn *Txn) error) error {\r\n\tif db.opt.managedTxns {\r\n\t\tpanic(\"Update can only be used with managedDB=false.\")\r\n\t}\r\n\ttxn := db.NewTransaction(true)\r\n\tdefer txn.Discard()\r\n\tif err := fn(txn); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn txn.Commit()\r\n}","code-length":117,"reference":"\/\/ Update executes a function, creating and managing a read-write transaction\n\/\/ for the user. Error returned by the function is relayed by the Update method.\n\/\/ Update cannot be used with managed transactions.","result":"Generate code for the generated code.","score":[0.0026,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (itr *blockIterator) Seek(key []byte, whence int) {\r\n\titr.err = nil\r\n\tswitch whence {\r\n\tcase origin:\r\n\t\titr.Reset()\r\n\tcase current:\r\n\t}\r\n\tvar done bool\r\n\tfor itr.Init(); itr.Valid(); itr.Next() {\r\n\t\tk := itr.Key()\r\n\t\tif y.CompareKeys(k, key) >= 0 {\r\n\t\t\t\r\n\t\t\tdone = true\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif !done {\r\n\t\titr.err = io.EOF\r\n\t}\r\n}","code-length":167,"reference":"\/\/ Seek brings us to the first block element that is >= input key.","result":"Seek the iterator.","score":[0.0124,0.0775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (itr *blockIterator) SeekToLast() {\r\n\titr.err = nil\r\n\tfor itr.Init(); itr.Valid(); itr.Next() {\r\n\t}\r\n\titr.Prev()\r\n}","code-length":63,"reference":"\/\/ SeekToLast brings us to the last element. Valid should return true.","result":"Seek to the last block in the iterator.","score":[0.1735,0.1293]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (itr *blockIterator) parseKV(h header) {\r\n\tif cap(itr.key) < int(h.plen+h.klen) {\r\n\t\tsz := int(h.plen) + int(h.klen)\r\n\t\titr.key = make([]byte, 2*sz)\r\n\t}\r\n\titr.key = itr.key[:h.plen+h.klen]\r\n\tcopy(itr.key, itr.baseKey[:h.plen])\r\n\tcopy(itr.key[h.plen:], itr.data[itr.pos:itr.pos+uint32(h.klen)])\r\n\titr.pos += uint32(h.klen)\r\n\tif itr.pos+uint32(h.vlen) > uint32(len(itr.data)) {\r\n\t\titr.err = errors.Errorf(\"Value exceeded size of block: %d %d %d %d %v\",\r\n\t\t\titr.pos, h.klen, h.vlen, len(itr.data), h)\r\n\t\treturn\r\n\t}\r\n\titr.val = y.SafeCopy(itr.val, itr.data[itr.pos:itr.pos+uint32(h.vlen)])\r\n\titr.pos += uint32(h.vlen)\r\n}","code-length":339,"reference":"\/\/ parseKV would allocate a new byte slice for key and for value.","result":"Parse the block header.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Table) NewIterator(reversed bool) *Iterator {\r\n\tt.IncrRef()\r\n\tti := &Iterator{t: t, reversed: reversed}\r\n\tti.next()\r\n\treturn ti\r\n}","code-length":65,"reference":"\/\/ NewIterator returns a new iterator of the Table","result":"Create a new iterator.","score":[0.1294,0.2206]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (itr *Iterator) seekFrom(key []byte, whence int) {\r\n\titr.err = nil\r\n\tswitch whence {\r\n\tcase origin:\r\n\t\titr.reset()\r\n\tcase current:\r\n\t}\r\n\tidx := sort.Search(len(itr.t.blockIndex), func(idx int) bool {\r\n\t\tko := itr.t.blockIndex[idx]\r\n\t\treturn y.CompareKeys(ko.key, key) > 0\r\n\t})\r\n\tif idx == 0 {\r\n\t\t\r\n\t\t\r\n\t\titr.seekHelper(0, key)\r\n\t\treturn\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\titr.seekHelper(idx-1, key)\r\n\tif itr.err == io.EOF {\r\n\t\t\r\n\t\tif idx == len(itr.t.blockIndex) {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\titr.seekHelper(idx, key)\r\n\t}\r\n\t\r\n}","code-length":276,"reference":"\/\/ seekFrom brings us to a key that is >= input key.","result":"Avoid recursion.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (itr *Iterator) seekForPrev(key []byte) {\r\n\t\r\n\titr.seekFrom(key, origin)\r\n\tif !bytes.Equal(itr.Key(), key) {\r\n\t\titr.prev()\r\n\t}\r\n}","code-length":74,"reference":"\/\/ seekForPrev will reset iterator and seek to <= key.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (itr *Iterator) Value() (ret y.ValueStruct) {\r\n\tret.Decode(itr.bi.Value())\r\n\treturn\r\n}","code-length":47,"reference":"\/\/ Value follows the y.Iterator interface","result":"Return the value of the value of the iterator.","score":[0.1219,0.1587]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (itr *Iterator) Seek(key []byte) {\r\n\tif !itr.reversed {\r\n\t\titr.seek(key)\r\n\t} else {\r\n\t\titr.seekForPrev(key)\r\n\t}\r\n}","code-length":71,"reference":"\/\/ Seek follows the y.Iterator interface","result":"Set the iterator.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewConcatIterator(tbls []*Table, reversed bool) *ConcatIterator {\r\n\titers := make([]*Iterator, len(tbls))\r\n\tfor i := 0; i < len(tbls); i++ {\r\n\t\titers[i] = tbls[i].NewIterator(reversed)\r\n\t}\r\n\treturn &ConcatIterator{\r\n\t\treversed: reversed,\r\n\t\titers:    iters,\r\n\t\ttables:   tbls,\r\n\t\tidx:      -1,\r\n\t}\r\n}","code-length":138,"reference":"\/\/ NewConcatIterator creates a new concatenated iterator","result":"Create a new iterator for the concatenation.","score":[0.2528,0.5357]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *ConcatIterator) Valid() bool {\r\n\treturn s.cur != nil && s.cur.Valid()\r\n}","code-length":39,"reference":"\/\/ Valid implements y.Interface","result":"Validate the current value of the current iterator.","score":[0,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *ConcatIterator) Next() {\r\n\ts.cur.Next()\r\n\tif s.cur.Valid() {\r\n\t\t\r\n\t\treturn\r\n\t}\r\n\tfor {\r\n\t\tif !s.reversed {\r\n\t\t\ts.setIdx(s.idx + 1)\r\n\t\t} else {\r\n\t\t\ts.setIdx(s.idx - 1)\r\n\t\t}\r\n\t\tif s.cur == nil {\r\n\t\t\t\r\n\t\t\treturn\r\n\t\t}\r\n\t\ts.cur.Rewind()\r\n\t\tif s.cur.Valid() {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n}","code-length":173,"reference":"\/\/ Next advances our concat iterator.","result":"Iterate through the iterator.","score":[0.1938,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *ConcatIterator) Close() error {\r\n\tfor _, it := range s.iters {\r\n\t\tif err := it.Close(); err != nil {\r\n\t\t\treturn errors.Wrap(err, \"ConcatIterator\")\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":80,"reference":"\/\/ Close implements y.Interface.","result":"Close the iterator.","score":[0.2925,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OpenExistingFile(filename string, flags uint32) (*os.File, error) {\r\n\topenFlags := os.O_RDWR\r\n\tif flags&ReadOnly != 0 {\r\n\t\topenFlags = os.O_RDONLY\r\n\t}\r\n\tif flags&Sync != 0 {\r\n\t\topenFlags |= datasyncFileFlag\r\n\t}\r\n\treturn os.OpenFile(filename, openFlags, 0)\r\n}","code-length":113,"reference":"\/\/ OpenExistingFile opens an existing file, errors if it doesn't exist.","result":"Open a file.","score":[0,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Copy(a []byte) []byte {\r\n\tb := make([]byte, len(a))\r\n\tcopy(b, a)\r\n\treturn b\r\n}","code-length":50,"reference":"\/\/ Copy copies a byte slice and returns the copied slice.","result":"Copy a byte array.","score":[0.0869,0.2481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc KeyWithTs(key []byte, ts uint64) []byte {\r\n\tout := make([]byte, len(key)+8)\r\n\tcopy(out, key)\r\n\tbinary.BigEndian.PutUint64(out[len(key):], math.MaxUint64-ts)\r\n\treturn out\r\n}","code-length":85,"reference":"\/\/ KeyWithTs generates a new key by appending ts to key.","result":"Generate the key with ts.","score":[0.0724,0.0962]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseTs(key []byte) uint64 {\r\n\tif len(key) <= 8 {\r\n\t\treturn 0\r\n\t}\r\n\treturn math.MaxUint64 - binary.BigEndian.Uint64(key[len(key)-8:])\r\n}","code-length":71,"reference":"\/\/ ParseTs parses the timestamp from the key bytes.","result":"Parse timestamp keys.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseKey(key []byte) []byte {\r\n\tif key == nil {\r\n\t\treturn nil\r\n\t}\r\n\tAssertTrue(len(key) > 8)\r\n\treturn key[:len(key)-8]\r\n}","code-length":66,"reference":"\/\/ ParseKey parses the actual key from the key bytes.","result":"Parse the key.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SameKey(src, dst []byte) bool {\r\n\tif len(src) != len(dst) {\r\n\t\treturn false\r\n\t}\r\n\treturn bytes.Equal(ParseKey(src), ParseKey(dst))\r\n}","code-length":66,"reference":"\/\/ SameKey checks for key equality ignoring the version timestamp suffix.","result":"Compare two keys.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FixedDuration(d time.Duration) string {\r\n\tstr := fmt.Sprintf(\"%02ds\", int(d.Seconds())%60)\r\n\tif d >= time.Minute {\r\n\t\tstr = fmt.Sprintf(\"%02dm\", int(d.Minutes())%60) + str\r\n\t}\r\n\tif d >= time.Hour {\r\n\t\tstr = fmt.Sprintf(\"%02dh\", int(d.Hours())) + str\r\n\t}\r\n\treturn str\r\n}","code-length":126,"reference":"\/\/ FixedDuration returns a string representation of the given duration with the\n\/\/ hours, minutes, and seconds.","result":"Generate the string representation of the time.","score":[0.1281,0.2788]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCloser(initial int) *Closer {\r\n\tret := &Closer{closed: make(chan struct{})}\r\n\tret.waiting.Add(initial)\r\n\treturn ret\r\n}","code-length":54,"reference":"\/\/ NewCloser constructs a new Closer, with an initial count on the WaitGroup.","result":"Create a new closer.","score":[0.0476,0.155]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewThrottle(max int) *Throttle {\r\n\treturn &Throttle{\r\n\t\tch:    make(chan struct{}, max),\r\n\t\terrCh: make(chan error, max),\r\n\t}\r\n}","code-length":62,"reference":"\/\/ NewThrottle creates a new throttle with a max number of workers.","result":"Create a new throttle.","score":[0.0611,0.1339]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Throttle) Do() error {\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase t.ch <- struct{}{}:\r\n\t\t\tt.wg.Add(1)\r\n\t\t\treturn nil\r\n\t\tcase err := <-t.errCh:\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":106,"reference":"\/\/ Do should be called by workers before they start working. It blocks if there\n\/\/ are already maximum number of workers working. If it detects an error from\n\/\/ previously Done workers, it would return it.","result":"Avoid the need for the function.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Throttle) Done(err error) {\r\n\tif err != nil {\r\n\t\tt.errCh <- err\r\n\t}\r\n\tselect {\r\n\tcase <-t.ch:\r\n\tdefault:\r\n\t\tpanic(\"Throttle Do Done mismatch\")\r\n\t}\r\n\tt.wg.Done()\r\n}","code-length":90,"reference":"\/\/ Done should be called by workers when they finish working. They can also\n\/\/ pass the error status of work done.","result":"Call the done function.","score":[0.0035,0.0743]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Throttle) Finish() error {\r\n\tt.wg.Wait()\r\n\tclose(t.ch)\r\n\tclose(t.errCh)\r\n\tfor err := range t.errCh {\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":91,"reference":"\/\/ Finish waits until all workers have finished working. It would return any\n\/\/ error passed by Done.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) SetDiscardTs(ts uint64) {\r\n\tif !db.opt.managedTxns {\r\n\t\tpanic(\"Cannot use SetDiscardTs with managedDB=false.\")\r\n\t}\r\n\tdb.orc.setDiscardTs(ts)\r\n}","code-length":76,"reference":"\/\/ SetDiscardTs sets a timestamp at or below which, any invalid or deleted\n\/\/ versions can be discarded from the LSM tree, and thence from the value log to\n\/\/ reclaim disk space. Can only be used with managed transactions.","result":"Set the discard timestamp.","score":[0.0,0.0412]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lf *logFile) openReadOnly() error {\r\n\tvar err error\r\n\tlf.fd, err = os.OpenFile(lf.path, os.O_RDONLY, 0666)\r\n\tif err != nil {\r\n\t\treturn errors.Wrapf(err, \"Unable to open %q as RDONLY.\", lf.path)\r\n\t}\r\n\tfi, err := lf.fd.Stat()\r\n\tif err != nil {\r\n\t\treturn errors.Wrapf(err, \"Unable to check stat for %q\", lf.path)\r\n\t}\r\n\ty.AssertTrue(fi.Size() <= math.MaxUint32)\r\n\tlf.size = uint32(fi.Size())\r\n\tif err = lf.mmap(fi.Size()); err != nil {\r\n\t\t_ = lf.fd.Close()\r\n\t\treturn y.Wrapf(err, \"Unable to map file\")\r\n\t}\r\n\treturn nil\r\n}","code-length":239,"reference":"\/\/ openReadOnly assumes that we have a write lock on logFile.","result":"Create a new file.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (vlog *valueLog) iterate(lf *logFile, offset uint32, fn logEntry) (uint32, error) {\r\n\tfi, err := lf.fd.Stat()\r\n\tif err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\tif int64(offset) == fi.Size() {\r\n\t\t\r\n\t\treturn offset, nil\r\n\t}\r\n\tif vlog.opt.ReadOnly {\r\n\t\t\r\n\t\t\r\n\t\treturn 0, ErrReplayNeeded\r\n\t}\r\n\t\r\n\tif _, err := lf.fd.Seek(int64(offset), io.SeekStart); err != nil {\r\n\t\treturn 0, errFile(err, lf.path, \"Unable to seek\")\r\n\t}\r\n\treader := bufio.NewReader(lf.fd)\r\n\tread := &safeRead{\r\n\t\tk:            make([]byte, 10),\r\n\t\tv:            make([]byte, 10),\r\n\t\trecordOffset: offset,\r\n\t}\r\n\tvar lastCommit uint64\r\n\tvar validEndOffset uint32\r\n\tfor {\r\n\t\te, err := read.Entry(reader)\r\n\t\tif err == io.EOF {\r\n\t\t\tbreak\r\n\t\t} else if err == io.ErrUnexpectedEOF || err == errTruncate {\r\n\t\t\tbreak\r\n\t\t} else if err != nil {\r\n\t\t\treturn 0, err\r\n\t\t} else if e == nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvar vp valuePointer\r\n\t\tvp.Len = uint32(headerBufSize + len(e.Key) + len(e.Value) + crc32.Size)\r\n\t\tread.recordOffset += vp.Len\r\n\t\tvp.Offset = e.offset\r\n\t\tvp.Fid = lf.fid\r\n\t\tif e.meta&bitTxn > 0 {\r\n\t\t\ttxnTs := y.ParseTs(e.Key)\r\n\t\t\tif lastCommit == 0 {\r\n\t\t\t\tlastCommit = txnTs\r\n\t\t\t}\r\n\t\t\tif lastCommit != txnTs {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t} else if e.meta&bitFinTxn > 0 {\r\n\t\t\ttxnTs, err := strconv.ParseUint(string(e.Value), 10, 64)\r\n\t\t\tif err != nil || lastCommit != txnTs {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tlastCommit = 0\r\n\t\t\tvalidEndOffset = read.recordOffset\r\n\t\t} else {\r\n\t\t\tif lastCommit != 0 {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\tvalidEndOffset = read.recordOffset\r\n\t\t}\r\n\t\tif err := fn(*e, vp); err != nil {\r\n\t\t\tif err == errStop {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\treturn 0, errFile(err, lf.path, \"Iteration function\")\r\n\t\t}\r\n\t}\r\n\treturn validEndOffset, nil\r\n}","code-length":739,"reference":"\/\/ iterate iterates over log file. It doesn't not allocate new memory for every kv pair.\n\/\/ Therefore, the kv pair is only valid for the duration of fn call.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (vlog *valueLog) sortedFids() []uint32 {\r\n\ttoBeDeleted := make(map[uint32]struct{})\r\n\tfor _, fid := range vlog.filesToBeDeleted {\r\n\t\ttoBeDeleted[fid] = struct{}{}\r\n\t}\r\n\tret := make([]uint32, 0, len(vlog.filesMap))\r\n\tfor fid := range vlog.filesMap {\r\n\t\tif _, ok := toBeDeleted[fid]; !ok {\r\n\t\t\tret = append(ret, fid)\r\n\t\t}\r\n\t}\r\n\tsort.Slice(ret, func(i, j int) bool {\r\n\t\treturn ret[i] < ret[j]\r\n\t})\r\n\treturn ret\r\n}","code-length":192,"reference":"\/\/ sortedFids returns the file id's not pending deletion, sorted.  Assumes we have shared access to\n\/\/ filesMap.","result":"Sort the files in the log.","score":[0.0261,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (vlog *valueLog) write(reqs []*request) error {\r\n\tvlog.filesLock.RLock()\r\n\tmaxFid := atomic.LoadUint32(&vlog.maxFid)\r\n\tcurlf := vlog.filesMap[maxFid]\r\n\tvlog.filesLock.RUnlock()\r\n\tvar buf bytes.Buffer\r\n\ttoDisk := func() error {\r\n\t\tif buf.Len() == 0 {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tvlog.elog.Printf(\"Flushing %d blocks of total size: %d\", len(reqs), buf.Len())\r\n\t\tn, err := curlf.fd.Write(buf.Bytes())\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"Unable to write to value log file: %q\", curlf.path)\r\n\t\t}\r\n\t\tbuf.Reset()\r\n\t\ty.NumWrites.Add(1)\r\n\t\ty.NumBytesWritten.Add(int64(n))\r\n\t\tvlog.elog.Printf(\"Done\")\r\n\t\tatomic.AddUint32(&vlog.writableLogOffset, uint32(n))\r\n\t\tif vlog.woffset() > uint32(vlog.opt.ValueLogFileSize) ||\r\n\t\t\tvlog.numEntriesWritten > vlog.opt.ValueLogMaxEntries {\r\n\t\t\tvar err error\r\n\t\t\tif err = curlf.doneWriting(vlog.woffset()); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tnewid := atomic.AddUint32(&vlog.maxFid, 1)\r\n\t\t\ty.AssertTruef(newid > 0, \"newid has overflown uint32: %v\", newid)\r\n\t\t\tnewlf, err := vlog.createVlogFile(newid)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tcurlf = newlf\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\tfor i := range reqs {\r\n\t\tb := reqs[i]\r\n\t\tb.Ptrs = b.Ptrs[:0]\r\n\t\tfor j := range b.Entries {\r\n\t\t\te := b.Entries[j]\r\n\t\t\tvar p valuePointer\r\n\t\t\tp.Fid = curlf.fid\r\n\t\t\t\r\n\t\t\tp.Offset = vlog.woffset() + uint32(buf.Len())\r\n\t\t\tplen, err := encodeEntry(e, &buf)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tp.Len = uint32(plen)\r\n\t\t\tb.Ptrs = append(b.Ptrs, p)\r\n\t\t}\r\n\t\tvlog.numEntriesWritten += uint32(len(b.Entries))\r\n\t\t\r\n\t\t\r\n\t\twriteNow :=\r\n\t\t\tvlog.woffset()+uint32(buf.Len()) > uint32(vlog.opt.ValueLogFileSize) ||\r\n\t\t\t\tvlog.numEntriesWritten > uint32(vlog.opt.ValueLogMaxEntries)\r\n\t\tif writeNow {\r\n\t\t\tif err := toDisk(); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn toDisk()\r\n}","code-length":817,"reference":"\/\/ write is thread-unsafe by design and should not be called concurrently.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (vlog *valueLog) populateDiscardStats() error {\r\n\tdiscardStatsKey := y.KeyWithTs(lfDiscardStatsKey, math.MaxUint64)\r\n\tvs, err := vlog.db.get(discardStatsKey)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif vs.Value == nil || len(vs.Value) == 0 {\r\n\t\tvlog.lfDiscardStats = &lfDiscardStats{m: make(map[uint32]int64)}\r\n\t\treturn nil\r\n\t}\r\n\tvar statsMap map[uint32]int64\r\n\tif err := json.Unmarshal(vs.Value, &statsMap); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tvlog.opt.Debugf(\"Value Log Discard stats: %v\", statsMap)\r\n\tvlog.lfDiscardStats = &lfDiscardStats{m: statsMap}\r\n\treturn nil\r\n}","code-length":237,"reference":"\/\/ populateDiscardStats populates vlog.lfDiscardStats\n\/\/ This function will be called while initializing valueLog","result":"Populate the discard stats in the value log.","score":[0,0.04]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) Backup(w io.Writer, since uint64) (uint64, error) {\r\n\tstream := db.NewStream()\r\n\tstream.LogPrefix = \"DB.Backup\"\r\n\treturn stream.Backup(w, since)\r\n}","code-length":71,"reference":"\/\/ Backup is a wrapper function over Stream.Backup to generate full and incremental backups of the\n\/\/ DB. For more control over how many goroutines are used to generate the backup, or if you wish to\n\/\/ backup only a certain range of keys, use Stream.Backup directly.","result":"Create a backup.","score":[0.0,0.0117]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (st *Stream) ToList(key []byte, itr *Iterator) (*pb.KVList, error) {\r\n\tlist := &pb.KVList{}\r\n\tfor ; itr.Valid(); itr.Next() {\r\n\t\titem := itr.Item()\r\n\t\tif item.IsDeletedOrExpired() {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif !bytes.Equal(key, item.Key()) {\r\n\t\t\t\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tvalCopy, err := item.ValueCopy(nil)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tkv := &pb.KV{\r\n\t\t\tKey:       item.KeyCopy(nil),\r\n\t\t\tValue:     valCopy,\r\n\t\t\tUserMeta:  []byte{item.UserMeta()},\r\n\t\t\tVersion:   item.Version(),\r\n\t\t\tExpiresAt: item.ExpiresAt(),\r\n\t\t}\r\n\t\tlist.Kv = append(list.Kv, kv)\r\n\t\tif st.db.opt.NumVersionsToKeep == 1 {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif item.DiscardEarlierVersions() {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\treturn list, nil\r\n}","code-length":326,"reference":"\/\/ ToList is a default implementation of KeyToList. It picks up all valid versions of the key,\n\/\/ skipping over deleted or expired keys.","result":"Generate the generated code.","score":[0.0022,0.0227]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (st *Stream) produceRanges(ctx context.Context) {\r\n\tsplits := st.db.KeySplits(st.Prefix)\r\n\tstart := y.SafeCopy(nil, st.Prefix)\r\n\tfor _, key := range splits {\r\n\t\tst.rangeCh <- keyRange{left: start, right: y.SafeCopy(nil, []byte(key))}\r\n\t\tstart = y.SafeCopy(nil, []byte(key))\r\n\t}\r\n\t\r\n\t\r\n\tst.rangeCh <- keyRange{left: start}\r\n\tclose(st.rangeCh)\r\n}","code-length":154,"reference":"\/\/ keyRange is [start, end), including start, excluding end. Do ensure that the start,\n\/\/ end byte slices are owned by keyRange struct.","result":"Produce ranges.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (st *Stream) produceKVs(ctx context.Context) error {\r\n\tvar size int\r\n\tvar txn *Txn\r\n\tif st.readTs > 0 {\r\n\t\ttxn = st.db.NewTransactionAt(st.readTs, false)\r\n\t} else {\r\n\t\ttxn = st.db.NewTransaction(false)\r\n\t}\r\n\tdefer txn.Discard()\r\n\titerate := func(kr keyRange) error {\r\n\t\titerOpts := DefaultIteratorOptions\r\n\t\titerOpts.AllVersions = true\r\n\t\titerOpts.Prefix = st.Prefix\r\n\t\titerOpts.PrefetchValues = false\r\n\t\titr := txn.NewIterator(iterOpts)\r\n\t\tdefer itr.Close()\r\n\t\toutList := new(pb.KVList)\r\n\t\tvar prevKey []byte\r\n\t\tfor itr.Seek(kr.left); itr.Valid(); {\r\n\t\t\t\r\n\t\t\titem := itr.Item()\r\n\t\t\tif bytes.Equal(item.Key(), prevKey) {\r\n\t\t\t\titr.Next()\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tprevKey = append(prevKey[:0], item.Key()...)\r\n\t\t\t\r\n\t\t\tif len(kr.right) > 0 && bytes.Compare(item.Key(), kr.right) >= 0 {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif st.ChooseKey != nil && !st.ChooseKey(item) {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tlist, err := st.KeyToList(item.KeyCopy(nil), itr)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif list == nil || len(list.Kv) == 0 {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\toutList.Kv = append(outList.Kv, list.Kv...)\r\n\t\t\tsize += list.Size()\r\n\t\t\tif size >= pageSize {\r\n\t\t\t\tst.kvChan <- outList\r\n\t\t\t\toutList = new(pb.KVList)\r\n\t\t\t\tsize = 0\r\n\t\t\t}\r\n\t\t}\r\n\t\tif len(outList.Kv) > 0 {\r\n\t\t\tst.kvChan <- outList\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase kr, ok := <-st.rangeCh:\r\n\t\t\tif !ok {\r\n\t\t\t\t\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\tif err := iterate(kr); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\tcase <-ctx.Done():\r\n\t\t\treturn ctx.Err()\r\n\t\t}\r\n\t}\r\n}","code-length":679,"reference":"\/\/ produceKVs picks up ranges from rangeCh, generates KV lists and sends them to kvChan.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (st *Stream) Orchestrate(ctx context.Context) error {\r\n\tst.rangeCh = make(chan keyRange, 3)\r\n\t\r\n\t\r\n\t\r\n\tst.kvChan = make(chan *pb.KVList, 16)\r\n\tif st.KeyToList == nil {\r\n\t\tst.KeyToList = st.ToList\r\n\t}\r\n\t\r\n\tgo st.produceRanges(ctx)\r\n\terrCh := make(chan error, 1)\r\n\tvar wg sync.WaitGroup\r\n\tfor i := 0; i < st.NumGo; i++ {\r\n\t\twg.Add(1)\r\n\t\tgo func() {\r\n\t\t\tdefer wg.Done()\r\n\t\t\t\r\n\t\t\tif err := st.produceKVs(ctx); err != nil {\r\n\t\t\t\tselect {\r\n\t\t\t\tcase errCh <- err:\r\n\t\t\t\tdefault:\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}()\r\n\t}\r\n\t\r\n\tkvErr := make(chan error, 1)\r\n\tgo func() {\r\n\t\t\r\n\t\tkvErr <- st.streamKVs(ctx)\r\n\t}()\r\n\twg.Wait()\r\n\tclose(st.kvChan)\r\n\tselect {\r\n\tcase err := <-errCh:\r\n\t\treturn err\r\n\tdefault:\r\n\t}\r\n\t\r\n\terr := <-kvErr\r\n\treturn err\r\n}","code-length":355,"reference":"\/\/ Orchestrate runs Stream. It picks up ranges from the SSTables, then runs NumGo number of\n\/\/ goroutines to iterate over these ranges and batch up KVs in lists. It concurrently runs a single\n\/\/ goroutine to pick these lists, batch them up further and send to Output.Send. Orchestrate also\n\/\/ spits logs out to Infof, using provided LogPrefix. Note that all calls to Output.Send\n\/\/ are serial. In case any of these steps encounter an error, Orchestrate would stop execution and\n\/\/ return that error. Orchestrate can be called multiple times, but in serial order.","result":"Create a stream .","score":[0.0,0.0058]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) NewStream() *Stream {\r\n\tif db.opt.managedTxns {\r\n\t\tpanic(\"This API can not be called in managed mode.\")\r\n\t}\r\n\treturn db.newStream()\r\n}","code-length":66,"reference":"\/\/ NewStream creates a new Stream.","result":"Create a new stream.","score":[0.274,0.6843]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) NewStreamAt(readTs uint64) *Stream {\r\n\tif !db.opt.managedTxns {\r\n\t\tpanic(\"This API can only be called in managed mode.\")\r\n\t}\r\n\tstream := db.newStream()\r\n\tstream.readTs = readTs\r\n\treturn stream\r\n}","code-length":89,"reference":"\/\/ NewStreamAt creates a new Stream at a particular timestamp. Should only be used with managed DB.","result":"Create a new stream.","score":[0.0175,0.0955]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Table) DecrRef() error {\r\n\tnewRef := atomic.AddInt32(&t.ref, -1)\r\n\tif newRef == 0 {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif t.loadingMode == options.MemoryMap {\r\n\t\t\ty.Munmap(t.mmap)\r\n\t\t}\r\n\t\tif err := t.fd.Truncate(0); err != nil {\r\n\t\t\t\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tfilename := t.fd.Name()\r\n\t\tif err := t.fd.Close(); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif err := os.Remove(filename); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":207,"reference":"\/\/ DecrRef decrements the refcount and possibly deletes the table","result":"Avoid recursive call to the function .","score":[0.1052,0.0515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseFileID(name string) (uint64, bool) {\r\n\tname = path.Base(name)\r\n\tif !strings.HasSuffix(name, fileSuffix) {\r\n\t\treturn 0, false\r\n\t}\r\n\t\r\n\tname = strings.TrimSuffix(name, fileSuffix)\r\n\tid, err := strconv.Atoi(name)\r\n\tif err != nil {\r\n\t\treturn 0, false\r\n\t}\r\n\ty.AssertTrue(id >= 0)\r\n\treturn uint64(id), true\r\n}","code-length":140,"reference":"\/\/ ParseFileID reads the file id out of a filename.","result":"Parse file IDs.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) PrintHistogram(keyPrefix []byte) {\r\n\tif db == nil {\r\n\t\tfmt.Println(\"\\nCannot build histogram: DB is nil.\")\r\n\t\treturn\r\n\t}\r\n\thistogram := db.buildHistogram(keyPrefix)\r\n\tfmt.Printf(\"Histogram of key sizes (in bytes)\\n\")\r\n\thistogram.keySizeHistogram.printHistogram()\r\n\tfmt.Printf(\"Histogram of value sizes (in bytes)\\n\")\r\n\thistogram.valueSizeHistogram.printHistogram()\r\n}","code-length":134,"reference":"\/\/ PrintHistogram builds and displays the key-value size histogram.\n\/\/ When keyPrefix is set, only the keys that have prefix \"keyPrefix\" are\n\/\/ considered for creating the histogram","result":"Print the histogram of key sizes and value sizes.","score":[0.0231,0.1425]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newSizeHistogram() *sizeHistogram {\r\n\t\r\n\tkeyBins := createHistogramBins(1, 16)\r\n\tvalueBins := createHistogramBins(1, 30)\r\n\treturn &sizeHistogram{\r\n\t\tkeySizeHistogram: histogramData{\r\n\t\t\tbins:        keyBins,\r\n\t\t\tcountPerBin: make([]int64, len(keyBins)+1),\r\n\t\t\tmax:         math.MinInt64,\r\n\t\t\tmin:         math.MaxInt64,\r\n\t\t\tsum:         0,\r\n\t\t},\r\n\t\tvalueSizeHistogram: histogramData{\r\n\t\t\tbins:        valueBins,\r\n\t\t\tcountPerBin: make([]int64, len(valueBins)+1),\r\n\t\t\tmax:         math.MinInt64,\r\n\t\t\tmin:         math.MaxInt64,\r\n\t\t\tsum:         0,\r\n\t\t},\r\n\t}\r\n}","code-length":235,"reference":"\/\/ newSizeHistogram returns a new instance of keyValueSizeHistogram with\n\/\/ properly initialized fields.","result":"Create a new size histogram.","score":[0.0686,0.1537]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) buildHistogram(keyPrefix []byte) *sizeHistogram {\r\n\ttxn := db.NewTransaction(false)\r\n\tdefer txn.Discard()\r\n\titr := txn.NewIterator(DefaultIteratorOptions)\r\n\tdefer itr.Close()\r\n\tbadgerHistogram := newSizeHistogram()\r\n\t\r\n\tfor itr.Seek(keyPrefix); itr.ValidForPrefix(keyPrefix); itr.Next() {\r\n\t\titem := itr.Item()\r\n\t\tbadgerHistogram.keySizeHistogram.Update(item.KeySize())\r\n\t\tbadgerHistogram.valueSizeHistogram.Update(item.ValueSize())\r\n\t}\r\n\treturn badgerHistogram\r\n}","code-length":170,"reference":"\/\/ buildHistogram builds the key-value size histogram.\n\/\/ When keyPrefix is set, only the keys that have prefix \"keyPrefix\" are\n\/\/ considered for creating the histogram","result":"Build the size histogram.","score":[0.002,0.1326]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (histogram histogramData) printHistogram() {\r\n\tfmt.Printf(\"Total count: %d\\n\", histogram.totalCount)\r\n\tfmt.Printf(\"Min value: %d\\n\", histogram.min)\r\n\tfmt.Printf(\"Max value: %d\\n\", histogram.max)\r\n\tfmt.Printf(\"Mean: %.2f\\n\", float64(histogram.sum)\/float64(histogram.totalCount))\r\n\tfmt.Printf(\"%24s %9s\\n\", \"Range\", \"Count\")\r\n\tnumBins := len(histogram.bins)\r\n\tfor index, count := range histogram.countPerBin {\r\n\t\tif count == 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif index == len(histogram.countPerBin)-1 {\r\n\t\t\tlowerBound := int(histogram.bins[numBins-1])\r\n\t\t\tfmt.Printf(\"[%10d, %10s) %9d\\n\", lowerBound, \"infinity\", count)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tupperBound := int(histogram.bins[index])\r\n\t\tlowerBound := 0\r\n\t\tif index > 0 {\r\n\t\t\tlowerBound = int(histogram.bins[index-1])\r\n\t\t}\r\n\t\tfmt.Printf(\"[%10d, %10d) %9d\\n\", lowerBound, upperBound, count)\r\n\t}\r\n\tfmt.Println()\r\n}","code-length":357,"reference":"\/\/ printHistogram prints the histogram data in a human-readable format.","result":"Print the histogram data.","score":[0.1008,0.3132]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WaterMark) Init(closer *Closer) {\r\n\tw.markCh = make(chan mark, 100)\r\n\tw.elog = trace.NewEventLog(\"Watermark\", w.Name)\r\n\tgo w.process(closer)\r\n}","code-length":70,"reference":"\/\/ Init initializes a WaterMark struct. MUST be called before using it.","result":"Initialize the water mark.","score":[0,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WaterMark) Begin(index uint64) {\r\n\tatomic.StoreUint64(&w.lastIndex, index)\r\n\tw.markCh <- mark{index: index, done: false}\r\n}","code-length":61,"reference":"\/\/ Begin sets the last index to the given value.","result":"Create the function .","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WaterMark) BeginMany(indices []uint64) {\r\n\tatomic.StoreUint64(&w.lastIndex, indices[len(indices)-1])\r\n\tw.markCh <- mark{index: 0, indices: indices, done: false}\r\n}","code-length":73,"reference":"\/\/ BeginMany works like Begin but accepts multiple indices.","result":"Create the water mark.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WaterMark) Done(index uint64) {\r\n\tw.markCh <- mark{index: index, done: true}\r\n}","code-length":44,"reference":"\/\/ Done sets a single index as done.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WaterMark) DoneMany(indices []uint64) {\r\n\tw.markCh <- mark{index: 0, indices: indices, done: true}\r\n}","code-length":50,"reference":"\/\/ DoneMany works like Done but accepts multiple indices.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WaterMark) SetDoneUntil(val uint64) {\r\n\tatomic.StoreUint64(&w.doneUntil, val)\r\n}","code-length":45,"reference":"\/\/ SetDoneUntil sets the maximum index that has the property that all indices\n\/\/ less than or equal to it are done.","result":"Generate the code.","score":[0.0007,0.0249]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WaterMark) WaitForMark(ctx context.Context, index uint64) error {\r\n\tif w.DoneUntil() >= index {\r\n\t\treturn nil\r\n\t}\r\n\twaitCh := make(chan struct{})\r\n\tw.markCh <- mark{index: index, waiter: waitCh}\r\n\tselect {\r\n\tcase <-ctx.Done():\r\n\t\treturn ctx.Err()\r\n\tcase <-waitCh:\r\n\t\treturn nil\r\n\t}\r\n}","code-length":127,"reference":"\/\/ WaitForMark waits until the given index is marked as done.","result":"Create a new function to create a new object.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h header) Encode(b []byte) {\r\n\tbinary.BigEndian.PutUint16(b[0:2], h.plen)\r\n\tbinary.BigEndian.PutUint16(b[2:4], h.klen)\r\n\tbinary.BigEndian.PutUint16(b[4:6], h.vlen)\r\n\tbinary.BigEndian.PutUint32(b[6:10], h.prev)\r\n}","code-length":114,"reference":"\/\/ Encode encodes the header.","result":"Encode the header.","score":[0.328,0.5324]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *header) Decode(buf []byte) int {\r\n\th.plen = binary.BigEndian.Uint16(buf[0:2])\r\n\th.klen = binary.BigEndian.Uint16(buf[2:4])\r\n\th.vlen = binary.BigEndian.Uint16(buf[4:6])\r\n\th.prev = binary.BigEndian.Uint32(buf[6:10])\r\n\treturn h.Size()\r\n}","code-length":120,"reference":"\/\/ Decode decodes the header.","result":"Decode the header.","score":[0.328,0.5324]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTableBuilder() *Builder {\r\n\treturn &Builder{\r\n\t\tkeyBuf:     newBuffer(1 << 20),\r\n\t\tbuf:        newBuffer(1 << 20),\r\n\t\tprevOffset: math.MaxUint32,\r\n\t}\r\n}","code-length":73,"reference":"\/\/ NewTableBuilder makes a new TableBuilder.","result":"Create a table builder.","score":[0.1938,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b Builder) keyDiff(newKey []byte) []byte {\r\n\tvar i int\r\n\tfor i = 0; i < len(newKey) && i < len(b.baseKey); i++ {\r\n\t\tif newKey[i] != b.baseKey[i] {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\treturn newKey[i:]\r\n}","code-length":102,"reference":"\/\/ keyDiff returns a suffix of newKey that is different from b.baseKey.","result":"Generate the keyDiff function.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Builder) Add(key []byte, value y.ValueStruct) error {\r\n\tif b.counter >= restartInterval {\r\n\t\tb.finishBlock()\r\n\t\t\r\n\t\tb.restarts = append(b.restarts, uint32(b.buf.Len()))\r\n\t\tb.counter = 0\r\n\t\tb.baseKey = []byte{}\r\n\t\tb.baseOffset = uint32(b.buf.Len())\r\n\t\tb.prevOffset = math.MaxUint32\r\n\t}\r\n\tb.addHelper(key, value)\r\n\treturn nil\r\n}","code-length":155,"reference":"\/\/ Add adds a key-value pair to the block.\n\/\/ If doNotRestart is true, we will not restart even if b.counter >= restartInterval.","result":"Build the builder.","score":[0.0005,0.0238]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Builder) blockIndex() []byte {\r\n\t\r\n\tb.restarts = append(b.restarts, uint32(b.buf.Len()))\r\n\t\r\n\tsz := 4*len(b.restarts) + 4\r\n\tout := make([]byte, sz)\r\n\tbuf := out\r\n\tfor _, r := range b.restarts {\r\n\t\tbinary.BigEndian.PutUint32(buf[:4], r)\r\n\t\tbuf = buf[4:]\r\n\t}\r\n\tbinary.BigEndian.PutUint32(buf[:4], uint32(len(b.restarts)))\r\n\treturn out\r\n}","code-length":167,"reference":"\/\/ blockIndex generates the block index for the table.\n\/\/ It is mainly a list of all the block base offsets.","result":"Build the block index.","score":[0.0064,0.0972]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Builder) Finish() []byte {\r\n\tbf := bbloom.New(float64(b.keyCount), 0.01)\r\n\tvar klen [2]byte\r\n\tkey := make([]byte, 1024)\r\n\tfor {\r\n\t\tif _, err := b.keyBuf.Read(klen[:]); err == io.EOF {\r\n\t\t\tbreak\r\n\t\t} else if err != nil {\r\n\t\t\ty.Check(err)\r\n\t\t}\r\n\t\tkl := int(binary.BigEndian.Uint16(klen[:]))\r\n\t\tif cap(key) < kl {\r\n\t\t\tkey = make([]byte, 2*int(kl))\r\n\t\t}\r\n\t\tkey = key[:kl]\r\n\t\ty.Check2(b.keyBuf.Read(key))\r\n\t\tbf.Add(key)\r\n\t}\r\n\tb.finishBlock()\r\n\tindex := b.blockIndex()\r\n\tb.buf.Write(index)\r\n\t\r\n\tbdata := bf.JSONMarshal()\r\n\tn, err := b.buf.Write(bdata)\r\n\ty.Check(err)\r\n\tvar buf [4]byte\r\n\tbinary.BigEndian.PutUint32(buf[:], uint32(n))\r\n\tb.buf.Write(buf[:])\r\n\treturn b.buf.Bytes()\r\n}","code-length":344,"reference":"\/\/ Finish finishes the table by appending the index.","result":"Build the builder.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (opt *Options) Errorf(format string, v ...interface{}) {\r\n\tif opt.Logger == nil {\r\n\t\treturn\r\n\t}\r\n\topt.Logger.Errorf(format, v...)\r\n}","code-length":61,"reference":"\/\/ Errorf logs an ERROR log message to the logger specified in opts or to the\n\/\/ global logger if no logger is specified in opts.","result":"Print errors to stdout.","score":[0.0013,0.042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (opt *Options) Infof(format string, v ...interface{}) {\r\n\tif opt.Logger == nil {\r\n\t\treturn\r\n\t}\r\n\topt.Logger.Infof(format, v...)\r\n}","code-length":62,"reference":"\/\/ Infof logs an INFO message to the logger specified in opts.","result":"Print the log message.","score":[0.0432,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Skiplist) DecrRef() {\r\n\tnewRef := atomic.AddInt32(&s.ref, -1)\r\n\tif newRef > 0 {\r\n\t\treturn\r\n\t}\r\n\ts.arena.reset()\r\n\t\r\n\t\r\n\ts.arena = nil\r\n}","code-length":88,"reference":"\/\/ DecrRef decrements the refcount, deallocating the Skiplist when done using it","result":"Avoid recursion.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSkiplist(arenaSize int64) *Skiplist {\r\n\tarena := newArena(arenaSize)\r\n\thead := newNode(arena, nil, y.ValueStruct{}, maxHeight)\r\n\treturn &Skiplist{\r\n\t\theight: 1,\r\n\t\thead:   head,\r\n\t\tarena:  arena,\r\n\t\tref:    1,\r\n\t}\r\n}","code-length":114,"reference":"\/\/ NewSkiplist makes a new empty skiplist, with a given arena size","result":"Create a new Skiplist.","score":[0.0611,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Skiplist) Put(key []byte, v y.ValueStruct) {\r\n\t\r\n\t\r\n\tlistHeight := s.getHeight()\r\n\tvar prev [maxHeight + 1]*node\r\n\tvar next [maxHeight + 1]*node\r\n\tprev[listHeight] = s.head\r\n\tnext[listHeight] = nil\r\n\tfor i := int(listHeight) - 1; i >= 0; i-- {\r\n\t\t\r\n\t\tprev[i], next[i] = s.findSpliceForLevel(key, prev[i+1], i)\r\n\t\tif prev[i] == next[i] {\r\n\t\t\tprev[i].setValue(s.arena, v)\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n\t\r\n\theight := randomHeight()\r\n\tx := newNode(s.arena, key, v, height)\r\n\t\r\n\tlistHeight = s.getHeight()\r\n\tfor height > int(listHeight) {\r\n\t\tif atomic.CompareAndSwapInt32(&s.height, listHeight, int32(height)) {\r\n\t\t\t\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tlistHeight = s.getHeight()\r\n\t}\r\n\t\r\n\t\r\n\tfor i := 0; i < height; i++ {\r\n\t\tfor {\r\n\t\t\tif prev[i] == nil {\r\n\t\t\t\ty.AssertTrue(i > 1)\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tprev[i], next[i] = s.findSpliceForLevel(key, s.head, i)\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\ty.AssertTrue(prev[i] != next[i])\r\n\t\t\t}\r\n\t\t\tnextOffset := s.arena.getNodeOffset(next[i])\r\n\t\t\tx.tower[i] = nextOffset\r\n\t\t\tif prev[i].casNextOffset(i, nextOffset, s.arena.getNodeOffset(x)) {\r\n\t\t\t\t\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tprev[i], next[i] = s.findSpliceForLevel(key, prev[i], i)\r\n\t\t\tif prev[i] == next[i] {\r\n\t\t\t\ty.AssertTruef(i == 0, \"Equality can happen only on base level: %d\", i)\r\n\t\t\t\tprev[i].setValue(s.arena, v)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":620,"reference":"\/\/ Put inserts the key-value pair.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Skiplist) Get(key []byte) y.ValueStruct {\r\n\tn, _ := s.findNear(key, false, true)\r\n\tif n == nil {\r\n\t\treturn y.ValueStruct{}\r\n\t}\r\n\tnextKey := s.arena.getKey(n.keyOffset, n.keySize)\r\n\tif !y.SameKey(key, nextKey) {\r\n\t\treturn y.ValueStruct{}\r\n\t}\r\n\tvalOffset, valSize := n.getValueOffset()\r\n\tvs := s.arena.getVal(valOffset, valSize)\r\n\tvs.Version = y.ParseTs(nextKey)\r\n\treturn vs\r\n}","code-length":178,"reference":"\/\/ Get gets the value associated with the key. It returns a valid value if it finds equal or earlier\n\/\/ version of the same key.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Iterator) Key() []byte {\r\n\treturn s.list.arena.getKey(s.n.keyOffset, s.n.keySize)\r\n}","code-length":51,"reference":"\/\/ Key returns the key at the current position.","result":"Get the key of the iterator.","score":[0.1833,0.2937]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Iterator) Value() y.ValueStruct {\r\n\tvalOffset, valSize := s.n.getValueOffset()\r\n\treturn s.list.arena.getVal(valOffset, valSize)\r\n}","code-length":61,"reference":"\/\/ Value returns value.","result":"Get the value of the iterator.","score":[0,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Iterator) Next() {\r\n\ty.AssertTrue(s.Valid())\r\n\ts.n = s.list.getNext(s.n, 0)\r\n}","code-length":53,"reference":"\/\/ Next advances to the next position.","result":"Iterate over the iterator.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Iterator) Prev() {\r\n\ty.AssertTrue(s.Valid())\r\n\ts.n, _ = s.list.findNear(s.Key(), true, false)\r\n}","code-length":57,"reference":"\/\/ Prev advances to the previous position.","result":"Iterate backwards.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Iterator) Seek(target []byte) {\r\n\ts.n, _ = s.list.findNear(target, false, true)\r\n}","code-length":47,"reference":"\/\/ Seek advances to the first entry with a key >= target.","result":"Create a new iterator.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Iterator) SeekForPrev(target []byte) {\r\n\ts.n, _ = s.list.findNear(target, true, true)\r\n}","code-length":49,"reference":"\/\/ SeekForPrev finds an entry with key <= target.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Skiplist) NewUniIterator(reversed bool) *UniIterator {\r\n\treturn &UniIterator{\r\n\t\titer:     s.NewIterator(),\r\n\t\treversed: reversed,\r\n\t}\r\n}","code-length":68,"reference":"\/\/ NewUniIterator returns a UniIterator.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *UniIterator) Next() {\r\n\tif !s.reversed {\r\n\t\ts.iter.Next()\r\n\t} else {\r\n\t\ts.iter.Prev()\r\n\t}\r\n}","code-length":63,"reference":"\/\/ Next implements y.Interface","result":"Avoid recursion.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *UniIterator) Seek(key []byte) {\r\n\tif !s.reversed {\r\n\t\ts.iter.Seek(key)\r\n\t} else {\r\n\t\ts.iter.SeekForPrev(key)\r\n\t}\r\n}","code-length":73,"reference":"\/\/ Seek implements y.Interface","result":"Store the iterator in a map.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Manifest) asChanges() []*pb.ManifestChange {\r\n\tchanges := make([]*pb.ManifestChange, 0, len(m.Tables))\r\n\tfor id, tm := range m.Tables {\r\n\t\tchanges = append(changes, newCreateChange(id, int(tm.Level), tm.Checksum))\r\n\t}\r\n\treturn changes\r\n}","code-length":97,"reference":"\/\/ asChanges returns a sequence of changes that could be used to recreate the Manifest in its\n\/\/ present state.","result":"Create a manifest.","score":[0.0014,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mf *manifestFile) rewrite() error {\r\n\t\r\n\tif err := mf.fp.Close(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfp, netCreations, err := helpRewrite(mf.directory, &mf.manifest)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tmf.fp = fp\r\n\tmf.manifest.Creations = netCreations\r\n\tmf.manifest.Deletions = 0\r\n\treturn nil\r\n}","code-length":130,"reference":"\/\/ Must be called while appendLock is held.","result":"Rewrite the manifest file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelHandler) validate() error {\r\n\tif s.level == 0 {\r\n\t\treturn nil\r\n\t}\r\n\ts.RLock()\r\n\tdefer s.RUnlock()\r\n\tnumTables := len(s.tables)\r\n\tfor j := 1; j < numTables; j++ {\r\n\t\tif j >= len(s.tables) {\r\n\t\t\treturn errors.Errorf(\"Level %d, j=%d numTables=%d\", s.level, j, numTables)\r\n\t\t}\r\n\t\tif y.CompareKeys(s.tables[j-1].Biggest(), s.tables[j].Smallest()) >= 0 {\r\n\t\t\treturn errors.Errorf(\r\n\t\t\t\t\"Inter: Biggest(j-1) \\n%s\\n vs Smallest(j): \\n%s\\n: level=%d j=%d numTables=%d\",\r\n\t\t\t\thex.Dump(s.tables[j-1].Biggest()), hex.Dump(s.tables[j].Smallest()),\r\n\t\t\t\ts.level, j, numTables)\r\n\t\t}\r\n\t\tif y.CompareKeys(s.tables[j].Smallest(), s.tables[j].Biggest()) > 0 {\r\n\t\t\treturn errors.Errorf(\r\n\t\t\t\t\"Intra: %q vs %q: level=%d j=%d numTables=%d\",\r\n\t\t\t\ts.tables[j].Smallest(), s.tables[j].Biggest(), s.level, j, numTables)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":386,"reference":"\/\/ Check does some sanity check on one level of data or in-memory index.","result":"Validate the tables in the table handler.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc acquireDirectoryLock(dirPath string, pidFileName string, readOnly bool) (*directoryLockGuard, error) {\r\n\tif readOnly {\r\n\t\treturn nil, ErrWindowsNotSupported\r\n\t}\r\n\t\r\n\t\r\n\tabsLockFilePath, err := filepath.Abs(filepath.Join(dirPath, pidFileName))\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Cannot get absolute path for pid lock file\")\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\th, err := syscall.CreateFile(\r\n\t\tsyscall.StringToUTF16Ptr(absLockFilePath), 0, 0, nil,\r\n\t\tsyscall.OPEN_ALWAYS,\r\n\t\tuint32(FILE_ATTRIBUTE_TEMPORARY|FILE_FLAG_DELETE_ON_CLOSE),\r\n\t\t0)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrapf(err,\r\n\t\t\t\"Cannot create lock file %q.  Another process is using this Badger database\",\r\n\t\t\tabsLockFilePath)\r\n\t}\r\n\treturn &directoryLockGuard{h: h, path: absLockFilePath}, nil\r\n}","code-length":293,"reference":"\/\/ AcquireDirectoryLock acquires exclusive access to a directory.","result":"Acquire a directory lock.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *directoryLockGuard) release() error {\r\n\tg.path = \"\"\r\n\treturn syscall.CloseHandle(g.h)\r\n}","code-length":45,"reference":"\/\/ Release removes the directory lock.","result":"Release the lock.","score":[0.1977,0.2632]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AssertTruef(b bool, format string, args ...interface{}) {\r\n\tif !b {\r\n\t\tlog.Fatalf(\"%+v\", errors.Errorf(format, args...))\r\n\t}\r\n}","code-length":61,"reference":"\/\/ AssertTruef is AssertTrue with extra info.","result":"Assert a true value.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Wrapf(err error, format string, args ...interface{}) error {\r\n\tif !debugMode {\r\n\t\tif err == nil {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\treturn fmt.Errorf(format+\" error: %+v\", append(args, err)...)\r\n\t}\r\n\treturn errors.Wrapf(err, format, args...)\r\n}","code-length":99,"reference":"\/\/ Wrapf is Wrap with extra info.","result":"Wrap errors.","score":[0.041,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelHandler) initTables(tables []*table.Table) {\r\n\ts.Lock()\r\n\tdefer s.Unlock()\r\n\ts.tables = tables\r\n\ts.totalSize = 0\r\n\tfor _, t := range tables {\r\n\t\ts.totalSize += t.Size()\r\n\t}\r\n\tif s.level == 0 {\r\n\t\t\r\n\t\t\r\n\t\tsort.Slice(s.tables, func(i, j int) bool {\r\n\t\t\treturn s.tables[i].ID() < s.tables[j].ID()\r\n\t\t})\r\n\t} else {\r\n\t\t\r\n\t\tsort.Slice(s.tables, func(i, j int) bool {\r\n\t\t\treturn y.CompareKeys(s.tables[i].Smallest(), s.tables[j].Smallest()) < 0\r\n\t\t})\r\n\t}\r\n}","code-length":223,"reference":"\/\/ initTables replaces s.tables with given tables. This is done during loading.","result":"Initialize the tables .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelHandler) deleteTables(toDel []*table.Table) error {\r\n\ts.Lock()\r\n\ttoDelMap := make(map[uint64]struct{})\r\n\tfor _, t := range toDel {\r\n\t\ttoDelMap[t.ID()] = struct{}{}\r\n\t}\r\n\t\r\n\tvar newTables []*table.Table\r\n\tfor _, t := range s.tables {\r\n\t\t_, found := toDelMap[t.ID()]\r\n\t\tif !found {\r\n\t\t\tnewTables = append(newTables, t)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\ts.totalSize -= t.Size()\r\n\t}\r\n\ts.tables = newTables\r\n\ts.Unlock()\r\n\treturn decrRefs(toDel)\r\n}","code-length":209,"reference":"\/\/ deleteTables remove tables idx0, ..., idx1-1.","result":"Delete tables.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelHandler) tryAddLevel0Table(t *table.Table) bool {\r\n\ty.AssertTrue(s.level == 0)\r\n\t\r\n\ts.Lock()\r\n\tdefer s.Unlock()\r\n\tif len(s.tables) >= s.db.opt.NumLevelZeroTablesStall {\r\n\t\treturn false\r\n\t}\r\n\ts.tables = append(s.tables, t)\r\n\tt.IncrRef()\r\n\ts.totalSize += t.Size()\r\n\treturn true\r\n}","code-length":140,"reference":"\/\/ tryAddLevel0Table returns true if ok and no stalling.","result":"Add a table to the level .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelHandler) getTableForKey(key []byte) ([]*table.Table, func() error) {\r\n\ts.RLock()\r\n\tdefer s.RUnlock()\r\n\tif s.level == 0 {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tout := make([]*table.Table, 0, len(s.tables))\r\n\t\tfor i := len(s.tables) - 1; i >= 0; i-- {\r\n\t\t\tout = append(out, s.tables[i])\r\n\t\t\ts.tables[i].IncrRef()\r\n\t\t}\r\n\t\treturn out, func() error {\r\n\t\t\tfor _, t := range out {\r\n\t\t\t\tif err := t.DecrRef(); err != nil {\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t}\r\n\t}\r\n\t\r\n\tidx := sort.Search(len(s.tables), func(i int) bool {\r\n\t\treturn y.CompareKeys(s.tables[i].Biggest(), key) >= 0\r\n\t})\r\n\tif idx >= len(s.tables) {\r\n\t\t\r\n\t\treturn nil, func() error { return nil }\r\n\t}\r\n\ttbl := s.tables[idx]\r\n\ttbl.IncrRef()\r\n\treturn []*table.Table{tbl}, tbl.DecrRef\r\n}","code-length":346,"reference":"\/\/ getTableForKey acquires a read-lock to access s.tables. It returns a list of tableHandlers.","result":"Get the table for a given key.","score":[0.0594,0.0752]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelHandler) get(key []byte) (y.ValueStruct, error) {\r\n\ttables, decr := s.getTableForKey(key)\r\n\tkeyNoTs := y.ParseKey(key)\r\n\tvar maxVs y.ValueStruct\r\n\tfor _, th := range tables {\r\n\t\tif th.DoesNotHave(keyNoTs) {\r\n\t\t\ty.NumLSMBloomHits.Add(s.strLevel, 1)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tit := th.NewIterator(false)\r\n\t\tdefer it.Close()\r\n\t\ty.NumLSMGets.Add(s.strLevel, 1)\r\n\t\tit.Seek(key)\r\n\t\tif !it.Valid() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif y.SameKey(key, it.Key()) {\r\n\t\t\tif version := y.ParseTs(it.Key()); maxVs.Version < version {\r\n\t\t\t\tmaxVs = it.Value()\r\n\t\t\t\tmaxVs.Version = version\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn maxVs, decr()\r\n}","code-length":290,"reference":"\/\/ get returns value for a given key or the key after that. If not found, return nil.","result":"Get the value of a key in the table.","score":[0.0634,0.1462]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelHandler) overlappingTables(_ levelHandlerRLocked, kr keyRange) (int, int) {\r\n\tif len(kr.left) == 0 || len(kr.right) == 0 {\r\n\t\treturn 0, 0\r\n\t}\r\n\tleft := sort.Search(len(s.tables), func(i int) bool {\r\n\t\treturn y.CompareKeys(kr.left, s.tables[i].Biggest()) <= 0\r\n\t})\r\n\tright := sort.Search(len(s.tables), func(i int) bool {\r\n\t\treturn y.CompareKeys(kr.right, s.tables[i].Smallest()) < 0\r\n\t})\r\n\treturn left, right\r\n}","code-length":184,"reference":"\/\/ overlappingTables returns the tables that intersect with key range. Returns a half-interval.\n\/\/ This function should already have acquired a read lock, and this is so important the caller must\n\/\/ pass an empty parameter declaring such.","result":"Check if overlapping tables are present in the table tableCache.","score":[0.0079,0.0284]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (item *Item) String() string {\r\n\treturn fmt.Sprintf(\"key=%q, version=%d, meta=%x\", item.Key(), item.Version(), item.meta)\r\n}","code-length":55,"reference":"\/\/ String returns a string representation of Item","result":"Generate the string representation of the item.","score":[0.2884,0.3727]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (item *Item) KeyCopy(dst []byte) []byte {\r\n\treturn y.SafeCopy(dst, item.key)\r\n}","code-length":43,"reference":"\/\/ KeyCopy returns a copy of the key of the item, writing it to dst slice.\n\/\/ If nil is passed, or capacity of dst isn't sufficient, a new slice would be allocated and\n\/\/ returned.","result":"Copy the key.","score":[0.0,0.0306]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (item *Item) ValueSize() int64 {\r\n\tif !item.hasValue() {\r\n\t\treturn 0\r\n\t}\r\n\tif (item.meta & bitValuePointer) == 0 {\r\n\t\treturn int64(len(item.vptr))\r\n\t}\r\n\tvar vp valuePointer\r\n\tvp.Decode(item.vptr)\r\n\tklen := int64(len(item.key) + 8)\r\n\treturn int64(vp.Len) - klen - headerBufSize - crc32.Size\r\n}","code-length":140,"reference":"\/\/ ValueSize returns the exact size of the value.\n\/\/\n\/\/ This can be called to quickly estimate the size of a value without fetching\n\/\/ it.","result":"Calculate the value size.","score":[0.0012,0.0405]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (txn *Txn) NewKeyIterator(key []byte, opt IteratorOptions) *Iterator {\r\n\tif len(opt.Prefix) > 0 {\r\n\t\tpanic(\"opt.Prefix should be nil for NewKeyIterator.\")\r\n\t}\r\n\topt.Prefix = key\r\n\topt.prefixIsKey = true\r\n\treturn txn.NewIterator(opt)\r\n}","code-length":98,"reference":"\/\/ NewKeyIterator is just like NewIterator, but allows the user to iterate over all versions of a\n\/\/ single key. Internally, it sets the Prefix option in provided opt, and uses that prefix to\n\/\/ additionally run bloom filter lookups before picking tables from the LSM tree.","result":"Create a new iterator for the given key.","score":[0.0014,0.0464]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (it *Iterator) Valid() bool {\r\n\tif it.item == nil {\r\n\t\treturn false\r\n\t}\r\n\treturn bytes.HasPrefix(it.item.key, it.opt.Prefix)\r\n}","code-length":63,"reference":"\/\/ Valid returns false when iteration is done.","result":"Validate the iterator.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (it *Iterator) ValidForPrefix(prefix []byte) bool {\r\n\treturn it.Valid() && bytes.HasPrefix(it.item.key, prefix)\r\n}","code-length":50,"reference":"\/\/ ValidForPrefix returns false when iteration is done\n\/\/ or when the current key is not prefixed by the specified prefix.","result":"Validate the iterator.","score":[0.001,0.026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (it *Iterator) Close() {\r\n\tif it.closed {\r\n\t\treturn\r\n\t}\r\n\tit.closed = true\r\n\tit.iitr.Close()\r\n\t\r\n\t\r\n\twaitFor := func(l list) {\r\n\t\titem := l.pop()\r\n\t\tfor item != nil {\r\n\t\t\titem.wg.Wait()\r\n\t\t\titem = l.pop()\r\n\t\t}\r\n\t}\r\n\twaitFor(it.waste)\r\n\twaitFor(it.data)\r\n\t\r\n\t_ = it.txn.db.vlog.decrIteratorCount()\r\n\tatomic.AddInt32(&it.txn.numIterators, -1)\r\n}","code-length":187,"reference":"\/\/ Close would close the iterator. It is important to call this when you're done with iteration.","result":"Close the iterator.","score":[0.006,0.1887]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (it *Iterator) parseItem() bool {\r\n\tmi := it.iitr\r\n\tkey := mi.Key()\r\n\tsetItem := func(item *Item) {\r\n\t\tif it.item == nil {\r\n\t\t\tit.item = item\r\n\t\t} else {\r\n\t\t\tit.data.push(item)\r\n\t\t}\r\n\t}\r\n\t\r\n\tif !it.opt.internalAccess && bytes.HasPrefix(key, badgerPrefix) {\r\n\t\tmi.Next()\r\n\t\treturn false\r\n\t}\r\n\t\r\n\tversion := y.ParseTs(key)\r\n\tif version > it.readTs {\r\n\t\tmi.Next()\r\n\t\treturn false\r\n\t}\r\n\tif it.opt.AllVersions {\r\n\t\t\r\n\t\t\r\n\t\titem := it.newItem()\r\n\t\tit.fill(item)\r\n\t\tsetItem(item)\r\n\t\tmi.Next()\r\n\t\treturn true\r\n\t}\r\n\t\r\n\t\r\n\tif !it.opt.Reverse {\r\n\t\tif y.SameKey(it.lastKey, key) {\r\n\t\t\tmi.Next()\r\n\t\t\treturn false\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tit.lastKey = y.SafeCopy(it.lastKey, mi.Key())\r\n\t}\r\nFILL:\r\n\t\r\n\tvs := mi.Value()\r\n\tif isDeletedOrExpired(vs.Meta, vs.ExpiresAt) {\r\n\t\tmi.Next()\r\n\t\treturn false\r\n\t}\r\n\titem := it.newItem()\r\n\tit.fill(item)\r\n\t\r\n\t\r\n\tmi.Next()\r\n\tif !it.opt.Reverse || !mi.Valid() {\r\n\t\tsetItem(item)\r\n\t\treturn true\r\n\t}\r\n\t\r\n\tnextTs := y.ParseTs(mi.Key())\r\n\tmik := y.ParseKey(mi.Key())\r\n\tif nextTs <= it.readTs && bytes.Equal(mik, item.key) {\r\n\t\t\r\n\t\tgoto FILL\r\n\t}\r\n\t\r\n\tsetItem(item)\r\n\treturn true\r\n}","code-length":561,"reference":"\/\/ parseItem is a complex function because it needs to handle both forward and reverse iteration\n\/\/ implementation. We store keys such that their versions are sorted in descending order. This makes\n\/\/ forward iteration efficient, but revese iteration complicated. This tradeoff is better because\n\/\/ forward iteration is more common than reverse.\n\/\/\n\/\/ This function advances the iterator.","result":"Code too long,keep in 512.","score":[0.0,0.0092]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (it *Iterator) Seek(key []byte) {\r\n\tfor i := it.data.pop(); i != nil; i = it.data.pop() {\r\n\t\ti.wg.Wait()\r\n\t\tit.waste.push(i)\r\n\t}\r\n\tit.lastKey = it.lastKey[:0]\r\n\tif len(key) == 0 {\r\n\t\tkey = it.opt.Prefix\r\n\t}\r\n\tif len(key) == 0 {\r\n\t\tit.iitr.Rewind()\r\n\t\tit.prefetch()\r\n\t\treturn\r\n\t}\r\n\tif !it.opt.Reverse {\r\n\t\tkey = y.KeyWithTs(key, it.txn.readTs)\r\n\t} else {\r\n\t\tkey = y.KeyWithTs(key, 0)\r\n\t}\r\n\tit.iitr.Seek(key)\r\n\tit.prefetch()\r\n}","code-length":239,"reference":"\/\/ Seek would seek to the provided key if present. If absent, it would seek to the next smallest key\n\/\/ greater than the provided key if iterating in the forward direction. Behavior would be reversed if\n\/\/ iterating backwards.","result":"Seek the iterator.","score":[0.0,0.0275]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) GetMergeOperator(key []byte,\r\n\tf MergeFunc, dur time.Duration) *MergeOperator {\r\n\top := &MergeOperator{\r\n\t\tf:      f,\r\n\t\tdb:     db,\r\n\t\tkey:    key,\r\n\t\tcloser: y.NewCloser(1),\r\n\t}\r\n\tgo op.runCompactions(dur)\r\n\treturn op\r\n}","code-length":112,"reference":"\/\/ GetMergeOperator creates a new MergeOperator for a given key and returns a\n\/\/ pointer to it. It also fires off a goroutine that performs a compaction using\n\/\/ the merge function that runs periodically, as specified by dur.","result":"Get the merge operator.","score":[0.0001,0.0528]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (op *MergeOperator) Get() ([]byte, error) {\r\n\top.RLock()\r\n\tdefer op.RUnlock()\r\n\tvar existing []byte\r\n\terr := op.db.View(func(txn *Txn) (err error) {\r\n\t\texisting, err = op.iterateAndMerge(txn)\r\n\t\treturn err\r\n\t})\r\n\tif err == errNoMerge {\r\n\t\treturn existing, nil\r\n\t}\r\n\treturn existing, err\r\n}","code-length":129,"reference":"\/\/ Get returns the latest value for the merge operator, which is derived by\n\/\/ applying the merge function to all the values added so far.\n\/\/\n\/\/ If Add has not been called even once, Get will return ErrKeyNotFound.","result":"Get the current value of the current value of the current value.","score":[0.0129,0.0806]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cs *compactStatus) compareAndAdd(_ thisAndNextLevelRLocked, cd compactDef) bool {\r\n\tcs.Lock()\r\n\tdefer cs.Unlock()\r\n\tlevel := cd.thisLevel.level\r\n\ty.AssertTruef(level < len(cs.levels)-1, \"Got level %d. Max levels: %d\", level, len(cs.levels))\r\n\tthisLevel := cs.levels[level]\r\n\tnextLevel := cs.levels[level+1]\r\n\tif thisLevel.overlapsWith(cd.thisRange) {\r\n\t\treturn false\r\n\t}\r\n\tif nextLevel.overlapsWith(cd.nextRange) {\r\n\t\treturn false\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tthisLevel.ranges = append(thisLevel.ranges, cd.thisRange)\r\n\tnextLevel.ranges = append(nextLevel.ranges, cd.nextRange)\r\n\tthisLevel.delSize += cd.thisSize\r\n\treturn true\r\n}","code-length":250,"reference":"\/\/ compareAndAdd will check whether we can run this compactDef. That it doesn't overlap with any\n\/\/ other running compaction. If it can be run, it would store this run in the compactStatus state.","result":"Compare and add compactDef to compactStatus.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newArena(n int64) *Arena {\r\n\t\r\n\t\r\n\tout := &Arena{\r\n\t\tn:   1,\r\n\t\tbuf: make([]byte, n),\r\n\t}\r\n\treturn out\r\n}","code-length":74,"reference":"\/\/ newArena returns a new arena.","result":"Create a new Arena.","score":[0.274,0.5077]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Arena) putNode(height int) uint32 {\r\n\t\r\n\t\r\n\tunusedSize := (maxHeight - height) * offsetSize\r\n\t\r\n\tl := uint32(MaxNodeSize - unusedSize + nodeAlign)\r\n\tn := atomic.AddUint32(&s.n, l)\r\n\ty.AssertTruef(int(n) <= len(s.buf),\r\n\t\t\"Arena too small, toWrite:%d newTotal:%d limit:%d\",\r\n\t\tl, n, len(s.buf))\r\n\t\r\n\tm := (n - l + uint32(nodeAlign)) & ^uint32(nodeAlign)\r\n\treturn m\r\n}","code-length":178,"reference":"\/\/ putNode allocates a node in the arena. The node is aligned on a pointer-sized\n\/\/ boundary. The arena offset of the node is returned.","result":"Store the node in the buffer.","score":[0.0194,0.0866]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Arena) getNode(offset uint32) *node {\r\n\tif offset == 0 {\r\n\t\treturn nil\r\n\t}\r\n\treturn (*node)(unsafe.Pointer(&s.buf[offset]))\r\n}","code-length":67,"reference":"\/\/ getNode returns a pointer to the node located at offset. If the offset is\n\/\/ zero, then the nil node pointer is returned.","result":"Generate the code.","score":[0.0004,0.0228]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Arena) getKey(offset uint32, size uint16) []byte {\r\n\treturn s.buf[offset : offset+uint32(size)]\r\n}","code-length":50,"reference":"\/\/ getKey returns byte slice at offset.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Arena) getVal(offset uint32, size uint16) (ret y.ValueStruct) {\r\n\tret.Decode(s.buf[offset : offset+uint32(size)])\r\n\treturn\r\n}","code-length":64,"reference":"\/\/ getVal returns byte slice at offset. The given size should be just the value\n\/\/ size and should NOT include the meta bytes.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Arena) getNodeOffset(nd *node) uint32 {\r\n\tif nd == nil {\r\n\t\treturn 0\r\n\t}\r\n\treturn uint32(uintptr(unsafe.Pointer(nd)) - uintptr(unsafe.Pointer(&s.buf[0])))\r\n}","code-length":81,"reference":"\/\/ getNodeOffset returns the offset of node in the arena. If the node pointer is\n\/\/ nil, then the zero offset is returned.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc init() {\r\n\tNumReads = expvar.NewInt(\"badger_disk_reads_total\")\r\n\tNumWrites = expvar.NewInt(\"badger_disk_writes_total\")\r\n\tNumBytesRead = expvar.NewInt(\"badger_read_bytes\")\r\n\tNumBytesWritten = expvar.NewInt(\"badger_written_bytes\")\r\n\tNumLSMGets = expvar.NewMap(\"badger_lsm_level_gets_total\")\r\n\tNumLSMBloomHits = expvar.NewMap(\"badger_lsm_bloom_hits_total\")\r\n\tNumGets = expvar.NewInt(\"badger_gets_total\")\r\n\tNumPuts = expvar.NewInt(\"badger_puts_total\")\r\n\tNumBlockedPuts = expvar.NewInt(\"badger_blocked_puts_total\")\r\n\tNumMemtableGets = expvar.NewInt(\"badger_memtable_gets_total\")\r\n\tLSMSize = expvar.NewMap(\"badger_lsm_size_bytes\")\r\n\tVlogSize = expvar.NewMap(\"badger_vlog_size_bytes\")\r\n\tPendingWrites = expvar.NewMap(\"badger_pending_writes_total\")\r\n}","code-length":303,"reference":"\/\/ These variables are global and have cumulative values for all kv stores.","result":"Initialize the module.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc revertToManifest(kv *DB, mf *Manifest, idMap map[uint64]struct{}) error {\r\n\t\r\n\tfor id := range mf.Tables {\r\n\t\tif _, ok := idMap[id]; !ok {\r\n\t\t\treturn fmt.Errorf(\"file does not exist for table %d\", id)\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor id := range idMap {\r\n\t\tif _, ok := mf.Tables[id]; !ok {\r\n\t\t\tkv.elog.Printf(\"Table file %d not referenced in MANIFEST\\n\", id)\r\n\t\t\tfilename := table.NewFilename(id, kv.opt.Dir)\r\n\t\t\tif err := os.Remove(filename); err != nil {\r\n\t\t\t\treturn y.Wrapf(err, \"While removing table %d\", id)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":228,"reference":"\/\/ revertToManifest checks that all necessary table files exist and removes all table files not\n\/\/ referenced by the manifest.  idMap is a set of table file id's that were read from the directory\n\/\/ listing.","result":"Revert the manifest to the database.","score":[0.0015,0.0303]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelsController) dropTree() (int, error) {\r\n\t\r\n\tvar all []*table.Table\r\n\tfor _, l := range s.levels {\r\n\t\tl.RLock()\r\n\t\tall = append(all, l.tables...)\r\n\t\tl.RUnlock()\r\n\t}\r\n\tif len(all) == 0 {\r\n\t\treturn 0, nil\r\n\t}\r\n\t\r\n\tchanges := []*pb.ManifestChange{}\r\n\tfor _, table := range all {\r\n\t\tchanges = append(changes, newDeleteChange(table.ID()))\r\n\t}\r\n\tchangeSet := pb.ManifestChangeSet{Changes: changes}\r\n\tif err := s.kv.manifest.addChanges(changeSet.Changes); err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\t\r\n\tfor _, l := range s.levels {\r\n\t\tl.Lock()\r\n\t\tl.totalSize = 0\r\n\t\tl.tables = l.tables[:0]\r\n\t\tl.Unlock()\r\n\t}\r\n\tfor _, table := range all {\r\n\t\tif err := table.DecrRef(); err != nil {\r\n\t\t\treturn 0, err\r\n\t\t}\r\n\t}\r\n\treturn len(all), nil\r\n}","code-length":327,"reference":"\/\/ dropTree picks all tables from all levels, creates a manifest changeset,\n\/\/ applies it, and then decrements the refs of these tables, which would result\n\/\/ in their deletion.","result":"Drop the tree.","score":[0.0001,0.0183]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelsController) dropPrefix(prefix []byte) error {\r\n\topt := s.kv.opt\r\n\tfor _, l := range s.levels {\r\n\t\tl.RLock()\r\n\t\tif l.level == 0 {\r\n\t\t\tsize := len(l.tables)\r\n\t\t\tl.RUnlock()\r\n\t\t\tif size > 0 {\r\n\t\t\t\tcp := compactionPriority{\r\n\t\t\t\t\tlevel: 0,\r\n\t\t\t\t\tscore: 1.74,\r\n\t\t\t\t\t\r\n\t\t\t\t\t\r\n\t\t\t\t\tdropPrefix: prefix,\r\n\t\t\t\t}\r\n\t\t\t\tif err := s.doCompact(cp); err != nil {\r\n\t\t\t\t\topt.Warningf(\"While compacting level 0: %v\", err)\r\n\t\t\t\t\treturn nil\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvar tables []*table.Table\r\n\t\tfor _, table := range l.tables {\r\n\t\t\tvar absent bool\r\n\t\t\tswitch {\r\n\t\t\tcase bytes.HasPrefix(table.Smallest(), prefix):\r\n\t\t\tcase bytes.HasPrefix(table.Biggest(), prefix):\r\n\t\t\tcase bytes.Compare(prefix, table.Smallest()) > 0 &&\r\n\t\t\t\tbytes.Compare(prefix, table.Biggest()) < 0:\r\n\t\t\tdefault:\r\n\t\t\t\tabsent = true\r\n\t\t\t}\r\n\t\t\tif !absent {\r\n\t\t\t\ttables = append(tables, table)\r\n\t\t\t}\r\n\t\t}\r\n\t\tl.RUnlock()\r\n\t\tif len(tables) == 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tcd := compactDef{\r\n\t\t\telog:       trace.New(fmt.Sprintf(\"Badger.L%d\", l.level), \"Compact\"),\r\n\t\t\tthisLevel:  l,\r\n\t\t\tnextLevel:  l,\r\n\t\t\ttop:        []*table.Table{},\r\n\t\t\tbot:        tables,\r\n\t\t\tdropPrefix: prefix,\r\n\t\t}\r\n\t\tif err := s.runCompactDef(l.level, cd); err != nil {\r\n\t\t\topt.Warningf(\"While running compact def: %+v. Error: %v\", cd, err)\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":569,"reference":"\/\/ dropPrefix runs a L0->L1 compaction, and then runs same level compaction on the rest of the\n\/\/ levels. For L0->L1 compaction, it runs compactions normally, but skips over all the keys with the\n\/\/ provided prefix. For Li->Li compactions, it picks up the tables which would have the prefix. The\n\/\/ tables who only have keys with this prefix are quickly dropped. The ones which have other keys\n\/\/ are run through MergeIterator and compacted to create new tables. All the mechanisms of\n\/\/ compactions apply, i.e. level sizes and MANIFEST are updated as in the normal flow.","result":"Code too long,keep in 512.","score":[0.0,0.0056]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelsController) isLevel0Compactable() bool {\r\n\treturn s.levels[0].numTables() >= s.kv.opt.NumLevelZeroTables\r\n}","code-length":51,"reference":"\/\/ Returns true if level zero may be compacted, without accounting for compactions that already\n\/\/ might be happening.","result":"Check if level .","score":[0.0106,0.1071]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelsController) doCompact(p compactionPriority) error {\r\n\tl := p.level\r\n\ty.AssertTrue(l+1 < s.kv.opt.MaxLevels)\r\n\tcd := compactDef{\r\n\t\telog:       trace.New(fmt.Sprintf(\"Badger.L%d\", l), \"Compact\"),\r\n\t\tthisLevel:  s.levels[l],\r\n\t\tnextLevel:  s.levels[l+1],\r\n\t\tdropPrefix: p.dropPrefix,\r\n\t}\r\n\tcd.elog.SetMaxEvents(100)\r\n\tdefer cd.elog.Finish()\r\n\ts.kv.opt.Infof(\"Got compaction priority: %+v\", p)\r\n\t\r\n\t\r\n\tif l == 0 {\r\n\t\tif !s.fillTablesL0(&cd) {\r\n\t\t\treturn errFillTables\r\n\t\t}\r\n\t} else {\r\n\t\tif !s.fillTables(&cd) {\r\n\t\t\treturn errFillTables\r\n\t\t}\r\n\t}\r\n\tdefer s.cstatus.delete(cd)\r\n\ts.kv.opt.Infof(\"Running for level: %d\\n\", cd.thisLevel.level)\r\n\ts.cstatus.toLog(cd.elog)\r\n\tif err := s.runCompactDef(l, cd); err != nil {\r\n\t\t\r\n\t\ts.kv.opt.Warningf(\"LOG Compact FAILED with error: %+v: %+v\", err, cd)\r\n\t\treturn err\r\n\t}\r\n\ts.cstatus.toLog(cd.elog)\r\n\ts.kv.opt.Infof(\"Compaction for level: %d DONE\", cd.thisLevel.level)\r\n\treturn nil\r\n}","code-length":434,"reference":"\/\/ doCompact picks some table on level l and compacts it away to the next level.","result":"Run compact on the level.","score":[0.035,0.1342]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelsController) get(key []byte, maxVs *y.ValueStruct) (y.ValueStruct, error) {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tversion := y.ParseTs(key)\r\n\tfor _, h := range s.levels {\r\n\t\tvs, err := h.get(key)\r\n\t\tif err != nil {\r\n\t\t\treturn y.ValueStruct{}, errors.Wrapf(err, \"get key: %q\", key)\r\n\t\t}\r\n\t\tif vs.Value == nil && vs.Meta == 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif maxVs == nil || vs.Version == version {\r\n\t\t\treturn vs, nil\r\n\t\t}\r\n\t\tif maxVs.Version < vs.Version {\r\n\t\t\t*maxVs = vs\r\n\t\t}\r\n\t}\r\n\tif maxVs != nil {\r\n\t\treturn *maxVs, nil\r\n\t}\r\n\treturn y.ValueStruct{}, nil\r\n}","code-length":259,"reference":"\/\/ get returns the found value if any. If not found, we return nil.","result":"Get the value of a key.","score":[0.0605,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc seekTotal(txn *badger.Txn) ([]account, error) {\r\n\texpected := uint64(numAccounts) * uint64(initialBal)\r\n\tvar accounts []account\r\n\tvar total uint64\r\n\tfor i := 0; i < numAccounts; i++ {\r\n\t\titem, err := txn.Get(key(i))\r\n\t\tif err != nil {\r\n\t\t\tlog.Printf(\"Error for account: %d. err=%v. key=%q\\n\", i, err, key(i))\r\n\t\t\treturn accounts, err\r\n\t\t}\r\n\t\tval, err := item.ValueCopy(nil)\r\n\t\tif err != nil {\r\n\t\t\treturn accounts, err\r\n\t\t}\r\n\t\tacc := account{\r\n\t\t\tId:  i,\r\n\t\t\tBal: toUint64(val),\r\n\t\t}\r\n\t\taccounts = append(accounts, acc)\r\n\t\ttotal += acc.Bal\r\n\t}\r\n\tif total != expected {\r\n\t\tlog.Printf(\"Balance did NOT match up. Expected: %d. Received: %d\",\r\n\t\t\texpected, total)\r\n\t\tatomic.AddInt32(&stopAll, 1)\r\n\t\treturn accounts, errFailure\r\n\t}\r\n\treturn accounts, nil\r\n}","code-length":324,"reference":"\/\/ seekTotal retrives the total of all accounts by seeking for each account key.","result":"Determine the total balance of all accounts.","score":[0.1106,0.282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc findFirstInvalidTxn(db *badger.DB, lowTs, highTs uint64) uint64 {\r\n\tcheckAt := func(ts uint64) error {\r\n\t\ttxn := db.NewTransactionAt(ts, false)\r\n\t\t_, err := seekTotal(txn)\r\n\t\ttxn.Discard()\r\n\t\treturn err\r\n\t}\r\n\tif highTs-lowTs < 1 {\r\n\t\tlog.Printf(\"Checking at lowTs: %d\\n\", lowTs)\r\n\t\terr := checkAt(lowTs)\r\n\t\tif err == errFailure {\r\n\t\t\tfmt.Printf(\"Violation at ts: %d\\n\", lowTs)\r\n\t\t\treturn lowTs\r\n\t\t} else if err != nil {\r\n\t\t\tlog.Printf(\"Error at lowTs: %d. Err=%v\\n\", lowTs, err)\r\n\t\t\treturn 0\r\n\t\t}\r\n\t\tfmt.Printf(\"No violation found at ts: %d\\n\", lowTs)\r\n\t\treturn 0\r\n\t}\r\n\tmidTs := (lowTs + highTs) \/ 2\r\n\tlog.Println()\r\n\tlog.Printf(\"Checking. low=%d. high=%d. mid=%d\\n\", lowTs, highTs, midTs)\r\n\terr := checkAt(midTs)\r\n\tif err == badger.ErrKeyNotFound || err == nil {\r\n\t\t\r\n\t\treturn findFirstInvalidTxn(db, midTs+1, highTs)\r\n\t}\r\n\t\r\n\treturn findFirstInvalidTxn(db, lowTs, midTs)\r\n}","code-length":387,"reference":"\/\/ Range is [lowTs, highTs).","result":"Find the first invalid txn.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *InmemSnapshotStore) Create(version SnapshotVersion, index, term uint64,\r\n\tconfiguration Configuration, configurationIndex uint64, trans Transport) (SnapshotSink, error) {\r\n\t\r\n\tif version != 1 {\r\n\t\treturn nil, fmt.Errorf(\"unsupported snapshot version %d\", version)\r\n\t}\r\n\tname := snapshotName(term, index)\r\n\tm.Lock()\r\n\tdefer m.Unlock()\r\n\tsink := &InmemSnapshotSink{\r\n\t\tmeta: SnapshotMeta{\r\n\t\t\tVersion:            version,\r\n\t\t\tID:                 name,\r\n\t\t\tIndex:              index,\r\n\t\t\tTerm:               term,\r\n\t\t\tPeers:              encodePeers(configuration, trans),\r\n\t\t\tConfiguration:      configuration,\r\n\t\t\tConfigurationIndex: configurationIndex,\r\n\t\t},\r\n\t\tcontents: &bytes.Buffer{},\r\n\t}\r\n\tm.hasSnapshot = true\r\n\tm.latest = sink\r\n\treturn sink, nil\r\n}","code-length":249,"reference":"\/\/ Create replaces the stored snapshot with a new one using the given args","result":"Create a new snapshot.","score":[0.041,0.1966]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *InmemSnapshotStore) List() ([]*SnapshotMeta, error) {\r\n\tm.RLock()\r\n\tdefer m.RUnlock()\r\n\tif !m.hasSnapshot {\r\n\t\treturn []*SnapshotMeta{}, nil\r\n\t}\r\n\treturn []*SnapshotMeta{&m.latest.meta}, nil\r\n}","code-length":91,"reference":"\/\/ List returns the latest snapshot taken","result":"List all snapshots in the store.","score":[0.1943,0.2174]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *InmemSnapshotStore) Open(id string) (*SnapshotMeta, io.ReadCloser, error) {\r\n\tm.RLock()\r\n\tdefer m.RUnlock()\r\n\tif m.latest.meta.ID != id {\r\n\t\treturn nil, nil, fmt.Errorf(\"[ERR] snapshot: failed to open snapshot id: %s\", id)\r\n\t}\r\n\treturn &m.latest.meta, ioutil.NopCloser(m.latest.contents), nil\r\n}","code-length":127,"reference":"\/\/ Open wraps an io.ReadCloser around the snapshot contents","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *InmemSnapshotSink) Write(p []byte) (n int, err error) {\r\n\twritten, err := io.Copy(s.contents, bytes.NewReader(p))\r\n\ts.meta.Size += written\r\n\treturn int(written), err\r\n}","code-length":76,"reference":"\/\/ Write appends the given bytes to the snapshot contents","result":"Write to the snapshot sink.","score":[0.1956,0.3947]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFileSnapshotStoreWithLogger(base string, retain int, logger *log.Logger) (*FileSnapshotStore, error) {\r\n\tif retain < 1 {\r\n\t\treturn nil, fmt.Errorf(\"must retain at least one snapshot\")\r\n\t}\r\n\tif logger == nil {\r\n\t\tlogger = log.New(os.Stderr, \"\", log.LstdFlags)\r\n\t}\r\n\t\r\n\tpath := filepath.Join(base, snapPath)\r\n\tif err := os.MkdirAll(path, 0755); err != nil && !os.IsExist(err) {\r\n\t\treturn nil, fmt.Errorf(\"snapshot path not accessible: %v\", err)\r\n\t}\r\n\t\r\n\tstore := &FileSnapshotStore{\r\n\t\tpath:   path,\r\n\t\tretain: retain,\r\n\t\tlogger: logger,\r\n\t}\r\n\t\r\n\tif err := store.testPermissions(); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"permissions test failed: %v\", err)\r\n\t}\r\n\treturn store, nil\r\n}","code-length":266,"reference":"\/\/ NewFileSnapshotStoreWithLogger creates a new FileSnapshotStore based\n\/\/ on a base directory. The `retain` parameter controls how many\n\/\/ snapshots are retained. Must be at least 1.","result":"Create a new snapshot store with a logger.","score":[0.0202,0.1777]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFileSnapshotStore(base string, retain int, logOutput io.Writer) (*FileSnapshotStore, error) {\r\n\tif logOutput == nil {\r\n\t\tlogOutput = os.Stderr\r\n\t}\r\n\treturn NewFileSnapshotStoreWithLogger(base, retain, log.New(logOutput, \"\", log.LstdFlags))\r\n}","code-length":89,"reference":"\/\/ NewFileSnapshotStore creates a new FileSnapshotStore based\n\/\/ on a base directory. The `retain` parameter controls how many\n\/\/ snapshots are retained. Must be at least 1.","result":"Create a new file snapshot store.","score":[0.0082,0.0803]}
{"code":"\/*is used to<extra_id_0>\r\nfunc snapshotName(term, index uint64) string {\r\n\tnow := time.Now()\r\n\tmsec := now.UnixNano() \/ int64(time.Millisecond)\r\n\treturn fmt.Sprintf(\"%d-%d-%d\", term, index, msec)\r\n}","code-length":76,"reference":"\/\/ snapshotName generates a name for the snapshot.","result":"Generate snapshot names.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FileSnapshotStore) Create(version SnapshotVersion, index, term uint64,\r\n\tconfiguration Configuration, configurationIndex uint64, trans Transport) (SnapshotSink, error) {\r\n\t\r\n\tif version != 1 {\r\n\t\treturn nil, fmt.Errorf(\"unsupported snapshot version %d\", version)\r\n\t}\r\n\t\r\n\tname := snapshotName(term, index)\r\n\tpath := filepath.Join(f.path, name+tmpSuffix)\r\n\tf.logger.Printf(\"[INFO] snapshot: Creating new snapshot at %s\", path)\r\n\t\r\n\tif err := os.MkdirAll(path, 0755); err != nil {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: Failed to make snapshot directory: %v\", err)\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tsink := &FileSnapshotSink{\r\n\t\tstore:     f,\r\n\t\tlogger:    f.logger,\r\n\t\tdir:       path,\r\n\t\tparentDir: f.path,\r\n\t\tmeta: fileSnapshotMeta{\r\n\t\t\tSnapshotMeta: SnapshotMeta{\r\n\t\t\t\tVersion:            version,\r\n\t\t\t\tID:                 name,\r\n\t\t\t\tIndex:              index,\r\n\t\t\t\tTerm:               term,\r\n\t\t\t\tPeers:              encodePeers(configuration, trans),\r\n\t\t\t\tConfiguration:      configuration,\r\n\t\t\t\tConfigurationIndex: configurationIndex,\r\n\t\t\t},\r\n\t\t\tCRC: nil,\r\n\t\t},\r\n\t}\r\n\t\r\n\tif err := sink.writeMeta(); err != nil {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: Failed to write metadata: %v\", err)\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tstatePath := filepath.Join(path, stateFilePath)\r\n\tfh, err := os.Create(statePath)\r\n\tif err != nil {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: Failed to create state file: %v\", err)\r\n\t\treturn nil, err\r\n\t}\r\n\tsink.stateFile = fh\r\n\t\r\n\tsink.stateHash = crc64.New(crc64.MakeTable(crc64.ECMA))\r\n\t\r\n\tmulti := io.MultiWriter(sink.stateFile, sink.stateHash)\r\n\tsink.buffered = bufio.NewWriter(multi)\r\n\t\r\n\treturn sink, nil\r\n}","code-length":585,"reference":"\/\/ Create is used to start a new snapshot","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FileSnapshotStore) List() ([]*SnapshotMeta, error) {\r\n\t\r\n\tsnapshots, err := f.getSnapshots()\r\n\tif err != nil {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: Failed to get snapshots: %v\", err)\r\n\t\treturn nil, err\r\n\t}\r\n\tvar snapMeta []*SnapshotMeta\r\n\tfor _, meta := range snapshots {\r\n\t\tsnapMeta = append(snapMeta, &meta.SnapshotMeta)\r\n\t\tif len(snapMeta) == f.retain {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\treturn snapMeta, nil\r\n}","code-length":167,"reference":"\/\/ List returns available snapshots in the store.","result":"List all snapshots in a file.","score":[0.2165,0.3276]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FileSnapshotStore) getSnapshots() ([]*fileSnapshotMeta, error) {\r\n\t\r\n\tsnapshots, err := ioutil.ReadDir(f.path)\r\n\tif err != nil {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: Failed to scan snapshot dir: %v\", err)\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tvar snapMeta []*fileSnapshotMeta\r\n\tfor _, snap := range snapshots {\r\n\t\t\r\n\t\tif !snap.IsDir() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tdirName := snap.Name()\r\n\t\tif strings.HasSuffix(dirName, tmpSuffix) {\r\n\t\t\tf.logger.Printf(\"[WARN] snapshot: Found temporary snapshot: %v\", dirName)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tmeta, err := f.readMeta(dirName)\r\n\t\tif err != nil {\r\n\t\t\tf.logger.Printf(\"[WARN] snapshot: Failed to read metadata for %v: %v\", dirName, err)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tif meta.Version < SnapshotVersionMin || meta.Version > SnapshotVersionMax {\r\n\t\t\tf.logger.Printf(\"[WARN] snapshot: Snapshot version for %v not supported: %d\", dirName, meta.Version)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tsnapMeta = append(snapMeta, meta)\r\n\t}\r\n\t\r\n\tsort.Sort(sort.Reverse(snapMetaSlice(snapMeta)))\r\n\treturn snapMeta, nil\r\n}","code-length":397,"reference":"\/\/ getSnapshots returns all the known snapshots.","result":"Store snapshot metadata.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FileSnapshotStore) readMeta(name string) (*fileSnapshotMeta, error) {\r\n\t\r\n\tmetaPath := filepath.Join(f.path, name, metaFilePath)\r\n\tfh, err := os.Open(metaPath)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer fh.Close()\r\n\t\r\n\tbuffered := bufio.NewReader(fh)\r\n\t\r\n\tmeta := &fileSnapshotMeta{}\r\n\tdec := json.NewDecoder(buffered)\r\n\tif err := dec.Decode(meta); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn meta, nil\r\n}","code-length":174,"reference":"\/\/ readMeta is used to read the meta data for a given named backup","result":"Read the meta file.","score":[0.0371,0.2265]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FileSnapshotStore) Open(id string) (*SnapshotMeta, io.ReadCloser, error) {\r\n\t\r\n\tmeta, err := f.readMeta(id)\r\n\tif err != nil {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: Failed to get meta data to open snapshot: %v\", err)\r\n\t\treturn nil, nil, err\r\n\t}\r\n\t\r\n\tstatePath := filepath.Join(f.path, id, stateFilePath)\r\n\tfh, err := os.Open(statePath)\r\n\tif err != nil {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: Failed to open state file: %v\", err)\r\n\t\treturn nil, nil, err\r\n\t}\r\n\t\r\n\tstateHash := crc64.New(crc64.MakeTable(crc64.ECMA))\r\n\t\r\n\t_, err = io.Copy(stateHash, fh)\r\n\tif err != nil {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: Failed to read state file: %v\", err)\r\n\t\tfh.Close()\r\n\t\treturn nil, nil, err\r\n\t}\r\n\t\r\n\tcomputed := stateHash.Sum(nil)\r\n\tif bytes.Compare(meta.CRC, computed) != 0 {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: CRC checksum failed (stored: %v computed: %v)\",\r\n\t\t\tmeta.CRC, computed)\r\n\t\tfh.Close()\r\n\t\treturn nil, nil, fmt.Errorf(\"CRC mismatch\")\r\n\t}\r\n\t\r\n\tif _, err := fh.Seek(0, 0); err != nil {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: State file seek failed: %v\", err)\r\n\t\tfh.Close()\r\n\t\treturn nil, nil, err\r\n\t}\r\n\t\r\n\tbuffered := &bufferedFile{\r\n\t\tbh: bufio.NewReader(fh),\r\n\t\tfh: fh,\r\n\t}\r\n\treturn &meta.SnapshotMeta, buffered, nil\r\n}","code-length":511,"reference":"\/\/ Open takes a snapshot ID and returns a ReadCloser for that snapshot.","result":"Open the file.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FileSnapshotStore) ReapSnapshots() error {\r\n\tsnapshots, err := f.getSnapshots()\r\n\tif err != nil {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: Failed to get snapshots: %v\", err)\r\n\t\treturn err\r\n\t}\r\n\tfor i := f.retain; i < len(snapshots); i++ {\r\n\t\tpath := filepath.Join(f.path, snapshots[i].ID)\r\n\t\tf.logger.Printf(\"[INFO] snapshot: reaping snapshot %v\", path)\r\n\t\tif err := os.RemoveAll(path); err != nil {\r\n\t\t\tf.logger.Printf(\"[ERR] snapshot: Failed to reap snapshot %v: %v\", path, err)\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":212,"reference":"\/\/ ReapSnapshots reaps any snapshots beyond the retain count.","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *FileSnapshotSink) Write(b []byte) (int, error) {\r\n\treturn s.buffered.Write(b)\r\n}","code-length":44,"reference":"\/\/ Write is used to append to the state file. We write to the\n\/\/ buffered IO object to reduce the amount of context switches.","result":"Generate the generated code.","score":[0.0017,0.0218]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *FileSnapshotSink) Close() error {\r\n\t\r\n\tif s.closed {\r\n\t\treturn nil\r\n\t}\r\n\ts.closed = true\r\n\t\r\n\tif err := s.finalize(); err != nil {\r\n\t\ts.logger.Printf(\"[ERR] snapshot: Failed to finalize snapshot: %v\", err)\r\n\t\tif delErr := os.RemoveAll(s.dir); delErr != nil {\r\n\t\t\ts.logger.Printf(\"[ERR] snapshot: Failed to delete temporary snapshot directory at path %v: %v\", s.dir, delErr)\r\n\t\t\treturn delErr\r\n\t\t}\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif err := s.writeMeta(); err != nil {\r\n\t\ts.logger.Printf(\"[ERR] snapshot: Failed to write metadata: %v\", err)\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tnewPath := strings.TrimSuffix(s.dir, tmpSuffix)\r\n\tif err := os.Rename(s.dir, newPath); err != nil {\r\n\t\ts.logger.Printf(\"[ERR] snapshot: Failed to move snapshot into place: %v\", err)\r\n\t\treturn err\r\n\t}\r\n\tif runtime.GOOS != \"windows\" {\r\n\t\tparentFH, err := os.Open(s.parentDir)\r\n\t\tdefer parentFH.Close()\r\n\t\tif err != nil {\r\n\t\t\ts.logger.Printf(\"[ERR] snapshot: Failed to open snapshot parent directory %v, error: %v\", s.parentDir, err)\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif err = parentFH.Sync(); err != nil {\r\n\t\t\ts.logger.Printf(\"[ERR] snapshot: Failed syncing parent directory %v, error: %v\", s.parentDir, err)\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\t\r\n\tif err := s.store.ReapSnapshots(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":508,"reference":"\/\/ Close is used to indicate a successful end.","result":"Close the sink.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *FileSnapshotSink) Cancel() error {\r\n\t\r\n\tif s.closed {\r\n\t\treturn nil\r\n\t}\r\n\ts.closed = true\r\n\t\r\n\tif err := s.finalize(); err != nil {\r\n\t\ts.logger.Printf(\"[ERR] snapshot: Failed to finalize snapshot: %v\", err)\r\n\t\treturn err\r\n\t}\r\n\t\r\n\treturn os.RemoveAll(s.dir)\r\n}","code-length":121,"reference":"\/\/ Cancel is used to indicate an unsuccessful end.","result":"Cancel the snapshot.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *FileSnapshotSink) finalize() error {\r\n\t\r\n\tif err := s.buffered.Flush(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif err := s.stateFile.Sync(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tstat, statErr := s.stateFile.Stat()\r\n\t\r\n\tif err := s.stateFile.Close(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif statErr != nil {\r\n\t\treturn statErr\r\n\t}\r\n\ts.meta.Size = stat.Size()\r\n\t\r\n\ts.meta.CRC = s.stateHash.Sum(nil)\r\n\treturn nil\r\n}","code-length":193,"reference":"\/\/ finalize is used to close all of our resources.","result":"Finalize the snapshot sink.","score":[0,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *FileSnapshotSink) writeMeta() error {\r\n\t\r\n\tmetaPath := filepath.Join(s.dir, metaFilePath)\r\n\tfh, err := os.Create(metaPath)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer fh.Close()\r\n\t\r\n\tbuffered := bufio.NewWriter(fh)\r\n\t\r\n\tenc := json.NewEncoder(buffered)\r\n\tif err := enc.Encode(&s.meta); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err = buffered.Flush(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err = fh.Sync(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":197,"reference":"\/\/ writeMeta is used to write out the metadata we have.","result":"Generate the generated code.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewNetworkTransportWithConfig(\r\n\tconfig *NetworkTransportConfig,\r\n) *NetworkTransport {\r\n\tif config.Logger == nil {\r\n\t\tconfig.Logger = log.New(os.Stderr, \"\", log.LstdFlags)\r\n\t}\r\n\ttrans := &NetworkTransport{\r\n\t\tconnPool:              make(map[ServerAddress][]*netConn),\r\n\t\tconsumeCh:             make(chan RPC),\r\n\t\tlogger:                config.Logger,\r\n\t\tmaxPool:               config.MaxPool,\r\n\t\tshutdownCh:            make(chan struct{}),\r\n\t\tstream:                config.Stream,\r\n\t\ttimeout:               config.Timeout,\r\n\t\tTimeoutScale:          DefaultTimeoutScale,\r\n\t\tserverAddressProvider: config.ServerAddressProvider,\r\n\t}\r\n\t\r\n\ttrans.setupStreamContext()\r\n\tgo trans.listen()\r\n\treturn trans\r\n}","code-length":228,"reference":"\/\/ NewNetworkTransportWithConfig creates a new network transport with the given config struct","result":"Create a new network transport.","score":[0.122,0.3512]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) setupStreamContext() {\r\n\tctx, cancel := context.WithCancel(context.Background())\r\n\tn.streamCtx = ctx\r\n\tn.streamCancel = cancel\r\n}","code-length":58,"reference":"\/\/ setupStreamContext is used to create a new stream context. This should be\n\/\/ called with the stream lock held.","result":"Setup the stream context.","score":[0.0101,0.1389]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) getStreamContext() context.Context {\r\n\tn.streamCtxLock.RLock()\r\n\tdefer n.streamCtxLock.RUnlock()\r\n\treturn n.streamCtx\r\n}","code-length":59,"reference":"\/\/ getStreamContext is used retrieve the current stream context.","result":"Create the stream context.","score":[0.1433,0.3007]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) SetHeartbeatHandler(cb func(rpc RPC)) {\r\n\tn.heartbeatFnLock.Lock()\r\n\tdefer n.heartbeatFnLock.Unlock()\r\n\tn.heartbeatFn = cb\r\n}","code-length":62,"reference":"\/\/ SetHeartbeatHandler is used to setup a heartbeat handler\n\/\/ as a fast-pass. This is to avoid head-of-line blocking from\n\/\/ disk IO.","result":"Set the heartbeat handler.","score":[0.0028,0.0237]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) CloseStreams() {\r\n\tn.connPoolLock.Lock()\r\n\tdefer n.connPoolLock.Unlock()\r\n\t\r\n\t\r\n\tfor k, e := range n.connPool {\r\n\t\tfor _, conn := range e {\r\n\t\t\tconn.Release()\r\n\t\t}\r\n\t\tdelete(n.connPool, k)\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tn.streamCtxLock.Lock()\r\n\tn.streamCancel()\r\n\tn.setupStreamContext()\r\n\tn.streamCtxLock.Unlock()\r\n}","code-length":159,"reference":"\/\/ CloseStreams closes the current streams.","result":"Close all streams in the network transport.","score":[0.1615,0.2459]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) Close() error {\r\n\tn.shutdownLock.Lock()\r\n\tdefer n.shutdownLock.Unlock()\r\n\tif !n.shutdown {\r\n\t\tclose(n.shutdownCh)\r\n\t\tn.stream.Close()\r\n\t\tn.shutdown = true\r\n\t}\r\n\treturn nil\r\n}","code-length":92,"reference":"\/\/ Close is used to stop the network transport.","result":"Close the transport.","score":[0.0727,0.1786]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) getPooledConn(target ServerAddress) *netConn {\r\n\tn.connPoolLock.Lock()\r\n\tdefer n.connPoolLock.Unlock()\r\n\tconns, ok := n.connPool[target]\r\n\tif !ok || len(conns) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\tvar conn *netConn\r\n\tnum := len(conns)\r\n\tconn, conns[num-1] = conns[num-1], nil\r\n\tn.connPool[target] = conns[:num-1]\r\n\treturn conn\r\n}","code-length":153,"reference":"\/\/ getExistingConn is used to grab a pooled connection.","result":"Get a connection from the pool.","score":[0.1171,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) getConnFromAddressProvider(id ServerID, target ServerAddress) (*netConn, error) {\r\n\taddress := n.getProviderAddressOrFallback(id, target)\r\n\treturn n.getConn(address)\r\n}","code-length":69,"reference":"\/\/ getConnFromAddressProvider returns a connection from the server address provider if available, or defaults to a connection using the target server address","result":"Generate code for the generated code.","score":[0.0134,0.0245]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) getConn(target ServerAddress) (*netConn, error) {\r\n\t\r\n\tif conn := n.getPooledConn(target); conn != nil {\r\n\t\treturn conn, nil\r\n\t}\r\n\t\r\n\tconn, err := n.stream.Dial(target, n.timeout)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tnetConn := &netConn{\r\n\t\ttarget: target,\r\n\t\tconn:   conn,\r\n\t\tr:      bufio.NewReader(conn),\r\n\t\tw:      bufio.NewWriter(conn),\r\n\t}\r\n\t\r\n\tnetConn.dec = codec.NewDecoder(netConn.r, &codec.MsgpackHandle{})\r\n\tnetConn.enc = codec.NewEncoder(netConn.w, &codec.MsgpackHandle{})\r\n\t\r\n\treturn netConn, nil\r\n}","code-length":238,"reference":"\/\/ getConn is used to get a connection from the pool.","result":"Get a connection from the pool.","score":[0.3492,0.5701]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) returnConn(conn *netConn) {\r\n\tn.connPoolLock.Lock()\r\n\tdefer n.connPoolLock.Unlock()\r\n\tkey := conn.target\r\n\tconns, _ := n.connPool[key]\r\n\tif !n.IsShutdown() && len(conns) < n.maxPool {\r\n\t\tn.connPool[key] = append(conns, conn)\r\n\t} else {\r\n\t\tconn.Release()\r\n\t}\r\n}","code-length":133,"reference":"\/\/ returnConn returns a connection back to the pool.","result":"Return the connection to the pool.","score":[0.2592,0.5126]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) listen() {\r\n\tconst baseDelay = 5 * time.Millisecond\r\n\tconst maxDelay = 1 * time.Second\r\n\tvar loopDelay time.Duration\r\n\tfor {\r\n\t\t\r\n\t\tconn, err := n.stream.Accept()\r\n\t\tif err != nil {\r\n\t\t\tif loopDelay == 0 {\r\n\t\t\t\tloopDelay = baseDelay\r\n\t\t\t} else {\r\n\t\t\t\tloopDelay *= 2\r\n\t\t\t}\r\n\t\t\tif loopDelay > maxDelay {\r\n\t\t\t\tloopDelay = maxDelay\r\n\t\t\t}\r\n\t\t\tif !n.IsShutdown() {\r\n\t\t\t\tn.logger.Printf(\"[ERR] raft-net: Failed to accept connection: %v\", err)\r\n\t\t\t}\r\n\t\t\tselect {\r\n\t\t\tcase <-n.shutdownCh:\r\n\t\t\t\treturn\r\n\t\t\tcase <-time.After(loopDelay):\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tloopDelay = 0\r\n\t\tn.logger.Printf(\"[DEBUG] raft-net: %v accepted connection from: %v\", n.LocalAddr(), conn.RemoteAddr())\r\n\t\t\r\n\t\tgo n.handleConn(n.getStreamContext(), conn)\r\n\t}\r\n}","code-length":318,"reference":"\/\/ listen is used to handling incoming connections.","result":"Listen for incoming connections.","score":[0.1662,0.3363]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) handleConn(connCtx context.Context, conn net.Conn) {\r\n\tdefer conn.Close()\r\n\tr := bufio.NewReader(conn)\r\n\tw := bufio.NewWriter(conn)\r\n\tdec := codec.NewDecoder(r, &codec.MsgpackHandle{})\r\n\tenc := codec.NewEncoder(w, &codec.MsgpackHandle{})\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase <-connCtx.Done():\r\n\t\t\tn.logger.Println(\"[DEBUG] raft-net: stream layer is closed\")\r\n\t\t\treturn\r\n\t\tdefault:\r\n\t\t}\r\n\t\tif err := n.handleCommand(r, dec, enc); err != nil {\r\n\t\t\tif err != io.EOF {\r\n\t\t\t\tn.logger.Printf(\"[ERR] raft-net: Failed to decode incoming command: %v\", err)\r\n\t\t\t}\r\n\t\t\treturn\r\n\t\t}\r\n\t\tif err := w.Flush(); err != nil {\r\n\t\t\tn.logger.Printf(\"[ERR] raft-net: Failed to flush response: %v\", err)\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":299,"reference":"\/\/ handleConn is used to handle an inbound connection for its lifespan. The\n\/\/ handler will exit when the passed context is cancelled or the connection is\n\/\/ closed.","result":"Handle the connection.","score":[0.0001,0.0379]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) handleCommand(r *bufio.Reader, dec *codec.Decoder, enc *codec.Encoder) error {\r\n\t\r\n\trpcType, err := r.ReadByte()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\trespCh := make(chan RPCResponse, 1)\r\n\trpc := RPC{\r\n\t\tRespChan: respCh,\r\n\t}\r\n\t\r\n\tisHeartbeat := false\r\n\tswitch rpcType {\r\n\tcase rpcAppendEntries:\r\n\t\tvar req AppendEntriesRequest\r\n\t\tif err := dec.Decode(&req); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\trpc.Command = &req\r\n\t\t\r\n\t\tif req.Term != 0 && req.Leader != nil &&\r\n\t\t\treq.PrevLogEntry == 0 && req.PrevLogTerm == 0 &&\r\n\t\t\tlen(req.Entries) == 0 && req.LeaderCommitIndex == 0 {\r\n\t\t\tisHeartbeat = true\r\n\t\t}\r\n\tcase rpcRequestVote:\r\n\t\tvar req RequestVoteRequest\r\n\t\tif err := dec.Decode(&req); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\trpc.Command = &req\r\n\tcase rpcInstallSnapshot:\r\n\t\tvar req InstallSnapshotRequest\r\n\t\tif err := dec.Decode(&req); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\trpc.Command = &req\r\n\t\trpc.Reader = io.LimitReader(r, req.Size)\r\n\tdefault:\r\n\t\treturn fmt.Errorf(\"unknown rpc type %d\", rpcType)\r\n\t}\r\n\t\r\n\tif isHeartbeat {\r\n\t\tn.heartbeatFnLock.Lock()\r\n\t\tfn := n.heartbeatFn\r\n\t\tn.heartbeatFnLock.Unlock()\r\n\t\tif fn != nil {\r\n\t\t\tfn(rpc)\r\n\t\t\tgoto RESP\r\n\t\t}\r\n\t}\r\n\t\r\n\tselect {\r\n\tcase n.consumeCh <- rpc:\r\n\tcase <-n.shutdownCh:\r\n\t\treturn ErrTransportShutdown\r\n\t}\r\n\t\r\nRESP:\r\n\tselect {\r\n\tcase resp := <-respCh:\r\n\t\t\r\n\t\trespErr := \"\"\r\n\t\tif resp.Error != nil {\r\n\t\t\trespErr = resp.Error.Error()\r\n\t\t}\r\n\t\tif err := enc.Encode(respErr); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\tif err := enc.Encode(resp.Response); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\tcase <-n.shutdownCh:\r\n\t\treturn ErrTransportShutdown\r\n\t}\r\n\treturn nil\r\n}","code-length":689,"reference":"\/\/ handleCommand is used to decode and dispatch a single command.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc decodeResponse(conn *netConn, resp interface{}) (bool, error) {\r\n\t\r\n\tvar rpcError string\r\n\tif err := conn.dec.Decode(&rpcError); err != nil {\r\n\t\tconn.Release()\r\n\t\treturn false, err\r\n\t}\r\n\t\r\n\tif err := conn.dec.Decode(resp); err != nil {\r\n\t\tconn.Release()\r\n\t\treturn false, err\r\n\t}\r\n\t\r\n\tif rpcError != \"\" {\r\n\t\treturn true, fmt.Errorf(rpcError)\r\n\t}\r\n\treturn true, nil\r\n}","code-length":159,"reference":"\/\/ decodeResponse is used to decode an RPC response and reports whether\n\/\/ the connection can be reused.","result":"Decode response from RPC server.","score":[0.0212,0.0898]}
{"code":"\/*is used to<extra_id_0>\r\nfunc sendRPC(conn *netConn, rpcType uint8, args interface{}) error {\r\n\t\r\n\tif err := conn.w.WriteByte(rpcType); err != nil {\r\n\t\tconn.Release()\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif err := conn.enc.Encode(args); err != nil {\r\n\t\tconn.Release()\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif err := conn.w.Flush(); err != nil {\r\n\t\tconn.Release()\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":154,"reference":"\/\/ sendRPC is used to encode and send the RPC.","result":"Send RPCs to the network.","score":[0.1051,0.1579]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newNetPipeline(trans *NetworkTransport, conn *netConn) *netPipeline {\r\n\tn := &netPipeline{\r\n\t\tconn:         conn,\r\n\t\ttrans:        trans,\r\n\t\tdoneCh:       make(chan AppendFuture, rpcMaxPipeline),\r\n\t\tinprogressCh: make(chan *appendFuture, rpcMaxPipeline),\r\n\t\tshutdownCh:   make(chan struct{}),\r\n\t}\r\n\tgo n.decodeResponses()\r\n\treturn n\r\n}","code-length":127,"reference":"\/\/ newNetPipeline is used to construct a netPipeline from a given\n\/\/ transport and connection.","result":"Create a new NetPipeline .","score":[0.0325,0.0714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *netPipeline) decodeResponses() {\r\n\ttimeout := n.trans.timeout\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase future := <-n.inprogressCh:\r\n\t\t\tif timeout > 0 {\r\n\t\t\t\tn.conn.conn.SetReadDeadline(time.Now().Add(timeout))\r\n\t\t\t}\r\n\t\t\t_, err := decodeResponse(n.conn, future.resp)\r\n\t\t\tfuture.respond(err)\r\n\t\t\tselect {\r\n\t\t\tcase n.doneCh <- future:\r\n\t\t\tcase <-n.shutdownCh:\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\tcase <-n.shutdownCh:\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":187,"reference":"\/\/ decodeResponses is a long running routine that decodes the responses\n\/\/ sent on the connection.","result":"Decode responses.","score":[0,0.0342]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *netPipeline) AppendEntries(args *AppendEntriesRequest, resp *AppendEntriesResponse) (AppendFuture, error) {\r\n\t\r\n\tfuture := &appendFuture{\r\n\t\tstart: time.Now(),\r\n\t\targs:  args,\r\n\t\tresp:  resp,\r\n\t}\r\n\tfuture.init()\r\n\t\r\n\tif timeout := n.trans.timeout; timeout > 0 {\r\n\t\tn.conn.conn.SetWriteDeadline(time.Now().Add(timeout))\r\n\t}\r\n\t\r\n\tif err := sendRPC(n.conn, rpcAppendEntries, future.args); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\t\r\n\tselect {\r\n\tcase n.inprogressCh <- future:\r\n\t\treturn future, nil\r\n\tcase <-n.shutdownCh:\r\n\t\treturn nil, ErrPipelineShutdown\r\n\t}\r\n}","code-length":232,"reference":"\/\/ AppendEntries is used to pipeline a new append entries request.","result":"Avoid the need for the following code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *netPipeline) Close() error {\r\n\tn.shutdownLock.Lock()\r\n\tdefer n.shutdownLock.Unlock()\r\n\tif n.shutdown {\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\tn.conn.Release()\r\n\tn.shutdown = true\r\n\tclose(n.shutdownCh)\r\n\treturn nil\r\n}","code-length":97,"reference":"\/\/ Closed is used to shutdown the pipeline connection.","result":"Close the netPipeline.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewObserver(channel chan Observation, blocking bool, filter FilterFn) *Observer {\r\n\treturn &Observer{\r\n\t\tchannel:  channel,\r\n\t\tblocking: blocking,\r\n\t\tfilter:   filter,\r\n\t\tid:       atomic.AddUint64(&nextObserverID, 1),\r\n\t}\r\n}","code-length":88,"reference":"\/\/ NewObserver creates a new observer that can be registered\n\/\/ to make observations on a Raft instance. Observations\n\/\/ will be sent on the given channel if they satisfy the\n\/\/ given filter.\n\/\/\n\/\/ If blocking is true, the observer will block when it can't\n\/\/ send on the channel, otherwise it may discard events.","result":"Create a new observer.","score":[0.0,0.029]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) RegisterObserver(or *Observer) {\r\n\tr.observersLock.Lock()\r\n\tdefer r.observersLock.Unlock()\r\n\tr.observers[or.id] = or\r\n}","code-length":64,"reference":"\/\/ RegisterObserver registers a new observer.","result":"Register the observer.","score":[0.1502,0.1754]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) DeregisterObserver(or *Observer) {\r\n\tr.observersLock.Lock()\r\n\tdefer r.observersLock.Unlock()\r\n\tdelete(r.observers, or.id)\r\n}","code-length":64,"reference":"\/\/ DeregisterObserver deregisters an observer.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) observe(o interface{}) {\r\n\t\r\n\t\r\n\t\r\n\tr.observersLock.RLock()\r\n\tdefer r.observersLock.RUnlock()\r\n\tfor _, or := range r.observers {\r\n\t\t\r\n\t\t\r\n\t\tob := Observation{Raft: r, Data: o}\r\n\t\tif or.filter != nil && !or.filter(&ob) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif or.channel == nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif or.blocking {\r\n\t\t\tor.channel <- ob\r\n\t\t\tatomic.AddUint64(&or.numObserved, 1)\r\n\t\t} else {\r\n\t\t\tselect {\r\n\t\t\tcase or.channel <- ob:\r\n\t\t\t\tatomic.AddUint64(&or.numObserved, 1)\r\n\t\t\tdefault:\r\n\t\t\t\tatomic.AddUint64(&or.numDropped, 1)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":267,"reference":"\/\/ observe sends an observation to every observer.","result":"Observe a single object.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewInmemStore() *InmemStore {\r\n\ti := &InmemStore{\r\n\t\tlogs:  make(map[uint64]*Log),\r\n\t\tkv:    make(map[string][]byte),\r\n\t\tkvInt: make(map[string]uint64),\r\n\t}\r\n\treturn i\r\n}","code-length":90,"reference":"\/\/ NewInmemStore returns a new in-memory backend. Do not ever\n\/\/ use for production. Only for testing.","result":"Create a new InmemStore.","score":[0.0175,0.1194]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemStore) FirstIndex() (uint64, error) {\r\n\ti.l.RLock()\r\n\tdefer i.l.RUnlock()\r\n\treturn i.lowIndex, nil\r\n}","code-length":61,"reference":"\/\/ FirstIndex implements the LogStore interface.","result":"Generate the code.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemStore) LastIndex() (uint64, error) {\r\n\ti.l.RLock()\r\n\tdefer i.l.RUnlock()\r\n\treturn i.highIndex, nil\r\n}","code-length":60,"reference":"\/\/ LastIndex implements the LogStore interface.","result":"Store the index in the store.","score":[0.193,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemStore) GetLog(index uint64, log *Log) error {\r\n\ti.l.RLock()\r\n\tdefer i.l.RUnlock()\r\n\tl, ok := i.logs[index]\r\n\tif !ok {\r\n\t\treturn ErrLogNotFound\r\n\t}\r\n\t*log = *l\r\n\treturn nil\r\n}","code-length":99,"reference":"\/\/ GetLog implements the LogStore interface.","result":"Store the log in the inmem store.","score":[0.1615,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemStore) StoreLog(log *Log) error {\r\n\treturn i.StoreLogs([]*Log{log})\r\n}","code-length":43,"reference":"\/\/ StoreLog implements the LogStore interface.","result":"Generate the code.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemStore) StoreLogs(logs []*Log) error {\r\n\ti.l.Lock()\r\n\tdefer i.l.Unlock()\r\n\tfor _, l := range logs {\r\n\t\ti.logs[l.Index] = l\r\n\t\tif i.lowIndex == 0 {\r\n\t\t\ti.lowIndex = l.Index\r\n\t\t}\r\n\t\tif l.Index > i.highIndex {\r\n\t\t\ti.highIndex = l.Index\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":143,"reference":"\/\/ StoreLogs implements the LogStore interface.","result":"Store logs in memory.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemStore) DeleteRange(min, max uint64) error {\r\n\ti.l.Lock()\r\n\tdefer i.l.Unlock()\r\n\tfor j := min; j <= max; j++ {\r\n\t\tdelete(i.logs, j)\r\n\t}\r\n\tif min <= i.lowIndex {\r\n\t\ti.lowIndex = max + 1\r\n\t}\r\n\tif max >= i.highIndex {\r\n\t\ti.highIndex = min - 1\r\n\t}\r\n\tif i.lowIndex > i.highIndex {\r\n\t\ti.lowIndex = 0\r\n\t\ti.highIndex = 0\r\n\t}\r\n\treturn nil\r\n}","code-length":178,"reference":"\/\/ DeleteRange implements the LogStore interface.","result":"Delete log entries.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemStore) Set(key []byte, val []byte) error {\r\n\ti.l.Lock()\r\n\tdefer i.l.Unlock()\r\n\ti.kv[string(key)] = val\r\n\treturn nil\r\n}","code-length":69,"reference":"\/\/ Set implements the StableStore interface.","result":"Set the value of a key in the store.","score":[0.1449,0.1587]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemStore) Get(key []byte) ([]byte, error) {\r\n\ti.l.RLock()\r\n\tdefer i.l.RUnlock()\r\n\tval := i.kv[string(key)]\r\n\tif val == nil {\r\n\t\treturn nil, errors.New(\"not found\")\r\n\t}\r\n\treturn val, nil\r\n}","code-length":100,"reference":"\/\/ Get implements the StableStore interface.","result":"Store the value in the store.","score":[0.193,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemStore) SetUint64(key []byte, val uint64) error {\r\n\ti.l.Lock()\r\n\tdefer i.l.Unlock()\r\n\ti.kvInt[string(key)] = val\r\n\treturn nil\r\n}","code-length":72,"reference":"\/\/ SetUint64 implements the StableStore interface.","result":"Store the data in memory.","score":[0.1967,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemStore) GetUint64(key []byte) (uint64, error) {\r\n\ti.l.RLock()\r\n\tdefer i.l.RUnlock()\r\n\treturn i.kvInt[string(key)], nil\r\n}","code-length":71,"reference":"\/\/ GetUint64 implements the StableStore interface.","result":"Store the data in memory.","score":[0.1967,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLogCache(capacity int, store LogStore) (*LogCache, error) {\r\n\tif capacity <= 0 {\r\n\t\treturn nil, fmt.Errorf(\"capacity must be positive\")\r\n\t}\r\n\tc := &LogCache{\r\n\t\tstore: store,\r\n\t\tcache: make([]*Log, capacity),\r\n\t}\r\n\treturn c, nil\r\n}","code-length":101,"reference":"\/\/ NewLogCache is used to create a new LogCache with the\n\/\/ given capacity and backend store.","result":"Create a new log cache.","score":[0.0308,0.1864]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemTransport) Connect(peer ServerAddress, t Transport) {\r\n\ttrans := t.(*InmemTransport)\r\n\ti.Lock()\r\n\tdefer i.Unlock()\r\n\ti.peers[peer] = trans\r\n}","code-length":68,"reference":"\/\/ Connect is used to connect this transport to another transport for\n\/\/ a given peer name. This allows for local routing.","result":"Connect to peers.","score":[0.0009,0.0498]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemTransport) Disconnect(peer ServerAddress) {\r\n\ti.Lock()\r\n\tdefer i.Unlock()\r\n\tdelete(i.peers, peer)\r\n\t\r\n\tn := len(i.pipelines)\r\n\tfor idx := 0; idx < n; idx++ {\r\n\t\tif i.pipelines[idx].peerAddr == peer {\r\n\t\t\ti.pipelines[idx].Close()\r\n\t\t\ti.pipelines[idx], i.pipelines[n-1] = i.pipelines[n-1], nil\r\n\t\t\tidx--\r\n\t\t\tn--\r\n\t\t}\r\n\t}\r\n\ti.pipelines = i.pipelines[:n]\r\n}","code-length":180,"reference":"\/\/ Disconnect is used to remove the ability to route to a given peer.","result":"Disconnect from a peer.","score":[0.0345,0.1154]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemTransport) DisconnectAll() {\r\n\ti.Lock()\r\n\tdefer i.Unlock()\r\n\ti.peers = make(map[ServerAddress]*InmemTransport)\r\n\t\r\n\tfor _, pipeline := range i.pipelines {\r\n\t\tpipeline.Close()\r\n\t}\r\n\ti.pipelines = nil\r\n}","code-length":95,"reference":"\/\/ DisconnectAll is used to remove all routes to peers.","result":"Disconnect all peers.","score":[0.0471,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *RPC) Respond(resp interface{}, err error) {\r\n\tr.RespChan <- RPCResponse{resp, err}\r\n}","code-length":43,"reference":"\/\/ Respond is used to respond with a response, error or both","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *userSnapshotFuture) Open() (*SnapshotMeta, io.ReadCloser, error) {\r\n\tif u.opener == nil {\r\n\t\treturn nil, nil, fmt.Errorf(\"no snapshot available\")\r\n\t} else {\r\n\t\t\r\n\t\t\r\n\t\tdefer func() {\r\n\t\t\tu.opener = nil\r\n\t\t}()\r\n\t\treturn u.opener()\r\n\t}\r\n}","code-length":110,"reference":"\/\/ Open is a function you can call to access the underlying snapshot and its\n\/\/ metadata.","result":"Open the snapshot.","score":[0.0046,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v *verifyFuture) vote(leader bool) {\r\n\tv.voteLock.Lock()\r\n\tdefer v.voteLock.Unlock()\r\n\t\r\n\tif v.notifyCh == nil {\r\n\t\treturn\r\n\t}\r\n\tif leader {\r\n\t\tv.votes++\r\n\t\tif v.votes >= v.quorumSize {\r\n\t\t\tv.notifyCh <- v\r\n\t\t\tv.notifyCh = nil\r\n\t\t}\r\n\t} else {\r\n\t\tv.notifyCh <- v\r\n\t\tv.notifyCh = nil\r\n\t}\r\n}","code-length":153,"reference":"\/\/ vote is used to respond to a verifyFuture.\n\/\/ This may block when responding on the notifyCh.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *followerReplication) notifyAll(leader bool) {\r\n\t\r\n\ts.notifyLock.Lock()\r\n\tn := s.notify\r\n\ts.notify = make(map[*verifyFuture]struct{})\r\n\ts.notifyLock.Unlock()\r\n\t\r\n\tfor v, _ := range n {\r\n\t\tv.vote(leader)\r\n\t}\r\n}","code-length":104,"reference":"\/\/ notifyAll is used to notify all the waiting verify futures\n\/\/ if the follower believes we are still the leader.","result":"Notify all the followers.","score":[0.0064,0.1324]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *followerReplication) cleanNotify(v *verifyFuture) {\r\n\ts.notifyLock.Lock()\r\n\tdelete(s.notify, v)\r\n\ts.notifyLock.Unlock()\r\n}","code-length":60,"reference":"\/\/ cleanNotify is used to delete notify, .","result":"Clean up the following code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *followerReplication) LastContact() time.Time {\r\n\ts.lastContactLock.RLock()\r\n\tlast := s.lastContact\r\n\ts.lastContactLock.RUnlock()\r\n\treturn last\r\n}","code-length":65,"reference":"\/\/ LastContact returns the time of last contact.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *followerReplication) setLastContact() {\r\n\ts.lastContactLock.Lock()\r\n\ts.lastContact = time.Now()\r\n\ts.lastContactLock.Unlock()\r\n}","code-length":58,"reference":"\/\/ setLastContact sets the last contact to the current time.","result":"Set the lastContact time.","score":[0.0848,0.1596]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) replicate(s *followerReplication) {\r\n\t\r\n\tstopHeartbeat := make(chan struct{})\r\n\tdefer close(stopHeartbeat)\r\n\tr.goFunc(func() { r.heartbeat(s, stopHeartbeat) })\r\nRPC:\r\n\tshouldStop := false\r\n\tfor !shouldStop {\r\n\t\tselect {\r\n\t\tcase maxIndex := <-s.stopCh:\r\n\t\t\t\r\n\t\t\tif maxIndex > 0 {\r\n\t\t\t\tr.replicateTo(s, maxIndex)\r\n\t\t\t}\r\n\t\t\treturn\r\n\t\tcase <-s.triggerCh:\r\n\t\t\tlastLogIdx, _ := r.getLastLog()\r\n\t\t\tshouldStop = r.replicateTo(s, lastLogIdx)\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tmeout):\r\n\t\t\tlastLogIdx, _ := r.getLastLog()\r\n\t\t\tshouldStop = r.replicateTo(s, lastLogIdx)\r\n\t\t}\r\n\t\t\r\n\t\tif !shouldStop && s.allowPipeline {\r\n\t\t\tgoto PIPELINE\r\n\t\t}\r\n\t}\r\n\treturn\r\nPIPELINE:\r\n\t\r\n\ts.allowPipeline = false\r\n\t\r\n\t\r\n\t\r\n\tif err := r.pipelineReplicate(s); err != nil {\r\n\t\tif err != ErrPipelineReplicationNotSupported {\r\n\t\t\tr.logger.Error(fmt.Sprintf(\"Failed to start pipeline replication to %s: %s\", s.peer, err))\r\n\t\t}\r\n\t}\r\n\tgoto RPC\r\n}","code-length":399,"reference":"\/\/ replicate is a long running routine that replicates log entries to a single\n\/\/ follower.","result":"Replicate to a follower.","score":[0.0249,0.2133]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) pipelineReplicate(s *followerReplication) error {\r\n\t\r\n\tpipeline, err := r.trans.AppendEntriesPipeline(s.peer.ID, s.peer.Address)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer pipeline.Close()\r\n\t\r\n\tr.logger.Info(fmt.Sprintf(\"pipelining replication to peer %v\", s.peer))\r\n\tdefer r.logger.Info(fmt.Sprintf(\"aborting pipeline replication to peer %v\", s.peer))\r\n\t\r\n\tstopCh := make(chan struct{})\r\n\tfinishCh := make(chan struct{})\r\n\t\r\n\tr.goFunc(func() { r.pipelineDecode(s, pipeline, stopCh, finishCh) })\r\n\t\r\n\tnextIndex := s.nextIndex\r\n\tshouldStop := false\r\nSEND:\r\n\tfor !shouldStop {\r\n\t\tselect {\r\n\t\tcase <-finishCh:\r\n\t\t\tbreak SEND\r\n\t\tcase maxIndex := <-s.stopCh:\r\n\t\t\t\r\n\t\t\tif maxIndex > 0 {\r\n\t\t\t\tr.pipelineSend(s, pipeline, &nextIndex, maxIndex)\r\n\t\t\t}\r\n\t\t\tbreak SEND\r\n\t\tcase <-s.triggerCh:\r\n\t\t\tlastLogIdx, _ := r.getLastLog()\r\n\t\t\tshouldStop = r.pipelineSend(s, pipeline, &nextIndex, lastLogIdx)\r\n\t\tcase <-randomTimeout(r.conf.CommitTimeout):\r\n\t\t\tlastLogIdx, _ := r.getLastLog()\r\n\t\t\tshouldStop = r.pipelineSend(s, pipeline, &nextIndex, lastLogIdx)\r\n\t\t}\r\n\t}\r\n\t\r\n\tclose(stopCh)\r\n\tselect {\r\n\tcase <-finishCh:\r\n\tcase <-r.shutdownCh:\r\n\t}\r\n\treturn nil\r\n}","code-length":470,"reference":"\/\/ pipelineReplicate is used when we have synchronized our state with the follower,\n\/\/ and want to switch to a higher performance pipeline mode of replication.\n\/\/ We only pipeline AppendEntries commands, and if we ever hit an error, we fall\n\/\/ back to the standard replication which can handle more complex situations.","result":"Replicate the follower replication.","score":[0.0,0.0312]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) pipelineSend(s *followerReplication, p AppendPipeline, nextIdx *uint64, lastIndex uint64) (shouldStop bool) {\r\n\t\r\n\treq := new(AppendEntriesRequest)\r\n\tif err := r.setupAppendEntries(s, req, *nextIdx, lastIndex); err != nil {\r\n\t\treturn true\r\n\t}\r\n\t\r\n\tif _, err := p.AppendEntries(req, new(AppendEntriesResponse)); err != nil {\r\n\t\tr.logger.Error(fmt.Sprintf(\"Failed to pipeline AppendEntries to %v: %v\", s.peer, err))\r\n\t\treturn true\r\n\t}\r\n\t\r\n\tif n := len(req.Entries); n > 0 {\r\n\t\tlast := req.Entries[n-1]\r\n\t\t*nextIdx = last.Index + 1\r\n\t}\r\n\treturn false\r\n}","code-length":224,"reference":"\/\/ pipelineSend is used to send data over a pipeline. It is a helper to\n\/\/ pipelineReplicate.","result":"Send the request to the Raft server.","score":[0.0387,0.0625]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) pipelineDecode(s *followerReplication, p AppendPipeline, stopCh, finishCh chan struct{}) {\r\n\tdefer close(finishCh)\r\n\trespCh := p.Consumer()\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase ready := <-respCh:\r\n\t\t\treq, resp := ready.Request(), ready.Response()\r\n\t\t\tappendStats(string(s.peer.ID), ready.Start(), float32(len(req.Entries)))\r\n\t\t\t\r\n\t\t\tif resp.Term > req.Term {\r\n\t\t\t\tr.handleStaleTerm(s)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\ts.setLastContact()\r\n\t\t\t\r\n\t\t\tif !resp.Success {\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tupdateLastAppended(s, req)\r\n\t\tcase <-stopCh:\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":239,"reference":"\/\/ pipelineDecode is used to decode the responses of pipelined requests.","result":"Detect if the file contains a comment.","score":[0.0912,0.0472]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) setupAppendEntries(s *followerReplication, req *AppendEntriesRequest, nextIndex, lastIndex uint64) error {\r\n\treq.RPCHeader = r.getRPCHeader()\r\n\treq.Term = s.currentTerm\r\n\treq.Leader = r.trans.EncodePeer(r.localID, r.localAddr)\r\n\treq.LeaderCommitIndex = r.getCommitIndex()\r\n\tif err := r.setPreviousLog(req, nextIndex); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := r.setNewLogs(req, nextIndex, lastIndex); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":174,"reference":"\/\/ setupAppendEntries is used to setup an append entries request.","result":"Setup the append entries request.","score":[0.1821,0.3947]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) setPreviousLog(req *AppendEntriesRequest, nextIndex uint64) error {\r\n\t\r\n\t\r\n\tlastSnapIdx, lastSnapTerm := r.getLastSnapshot()\r\n\tif nextIndex == 1 {\r\n\t\treq.PrevLogEntry = 0\r\n\t\treq.PrevLogTerm = 0\r\n\t} else if (nextIndex - 1) == lastSnapIdx {\r\n\t\treq.PrevLogEntry = lastSnapIdx\r\n\t\treq.PrevLogTerm = lastSnapTerm\r\n\t} else {\r\n\t\tvar l Log\r\n\t\tif err := r.logs.GetLog(nextIndex-1, &l); err != nil {\r\n\t\t\tr.logger.Error(fmt.Sprintf(\"Failed to get log at index %d: %v\", nextIndex-1, err))\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\treq.PrevLogEntry = l.Index\r\n\t\treq.PrevLogTerm = l.Term\r\n\t}\r\n\treturn nil\r\n}","code-length":249,"reference":"\/\/ setPreviousLog is used to setup the PrevLogEntry and PrevLogTerm for an\n\/\/ AppendEntriesRequest given the next index to replicate.","result":"Set the previous log index.","score":[0.012,0.027]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) setNewLogs(req *AppendEntriesRequest, nextIndex, lastIndex uint64) error {\r\n\t\r\n\treq.Entries = make([]*Log, 0, r.conf.MaxAppendEntries)\r\n\tmaxIndex := min(nextIndex+uint64(r.conf.MaxAppendEntries)-1, lastIndex)\r\n\tfor i := nextIndex; i <= maxIndex; i++ {\r\n\t\toldLog := new(Log)\r\n\t\tif err := r.logs.GetLog(i, oldLog); err != nil {\r\n\t\t\tr.logger.Error(fmt.Sprintf(\"Failed to get log at index %d: %v\", i, err))\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treq.Entries = append(req.Entries, oldLog)\r\n\t}\r\n\treturn nil\r\n}","code-length":204,"reference":"\/\/ setNewLogs is used to setup the logs which should be appended for a request.","result":"Set the log index.","score":[0.0204,0.1349]}
{"code":"\/*is used to<extra_id_0>\r\nfunc appendStats(peer string, start time.Time, logs float32) {\r\n\tmetrics.MeasureSince([]string{\"raft\", \"replication\", \"appendEntries\", \"rpc\", peer}, start)\r\n\tmetrics.IncrCounter([]string{\"raft\", \"replication\", \"appendEntries\", \"logs\", peer}, logs)\r\n}","code-length":84,"reference":"\/\/ appendStats is used to emit stats about an AppendEntries invocation.","result":"Collect raft stats.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) handleStaleTerm(s *followerReplication) {\r\n\tr.logger.Error(fmt.Sprintf(\"peer %v has newer term, stopping replication\", s.peer))\r\n\ts.notifyAll(false)\r\n\tasyncNotifyCh(s.stepDown)\r\n}","code-length":80,"reference":"\/\/ handleStaleTerm is used when a follower indicates that we have a stale term.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *transport) AppendEntries(id raft.ServerID, target raft.ServerAddress, args *raft.AppendEntriesRequest, resp *raft.AppendEntriesResponse) error {\r\n\tae := appendEntries{\r\n\t\tsource:      t.node,\r\n\t\ttarget:      target,\r\n\t\tfirstIndex:  firstIndex(args),\r\n\t\tlastIndex:   lastIndex(args),\r\n\t\tcommitIndex: args.LeaderCommitIndex,\r\n\t}\r\n\tif len(t.ae) < cap(t.ae) {\r\n\t\tt.ae = append(t.ae, ae)\r\n\t}\r\n\treturn t.sendRPC(string(target), args, resp)\r\n}","code-length":176,"reference":"\/\/ AppendEntries sends the appropriate RPC to the target node.","result":"Transport AppendEntries RPCs.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *transport) RequestVote(id raft.ServerID, target raft.ServerAddress, args *raft.RequestVoteRequest, resp *raft.RequestVoteResponse) error {\r\n\treturn t.sendRPC(string(target), args, resp)\r\n}","code-length":68,"reference":"\/\/ RequestVote sends the appropriate RPC to the target node.","result":"RequestVoteRequest.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *transport) InstallSnapshot(id raft.ServerID, target raft.ServerAddress, args *raft.InstallSnapshotRequest, resp *raft.InstallSnapshotResponse, data io.Reader) error {\r\n\tt.log.Printf(\"INSTALL SNAPSHOT *************************************\")\r\n\treturn errors.New(\"huh\")\r\n}","code-length":82,"reference":"\/\/ InstallSnapshot is used to push a snapshot down to a follower. The data is read from\n\/\/ the ReadCloser and streamed to the client.","result":"Create a new snapshot.","score":[0.0017,0.0218]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *transport) EncodePeer(id raft.ServerID, p raft.ServerAddress) []byte {\r\n\treturn []byte(p)\r\n}","code-length":45,"reference":"\/\/ EncodePeer is used to serialize a peer name.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *transport) DecodePeer(p []byte) raft.ServerAddress {\r\n\treturn raft.ServerAddress(p)\r\n}","code-length":41,"reference":"\/\/ DecodePeer is used to deserialize a peer name.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *pipeline) AppendEntries(args *raft.AppendEntriesRequest, resp *raft.AppendEntriesResponse) (raft.AppendFuture, error) {\r\n\te := &appendEntry{\r\n\t\treq:      args,\r\n\t\tres:      resp,\r\n\t\tstart:    time.Now(),\r\n\t\tready:    make(chan error),\r\n\t\tconsumer: p.consumer,\r\n\t}\r\n\tp.work <- e\r\n\treturn e, nil\r\n}","code-length":125,"reference":"\/\/ AppendEntries is used to add another request to the pipeline.\n\/\/ The send may block which is an effective form of back-pressure.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReadPeersJSON(path string) (Configuration, error) {\r\n\t\r\n\tbuf, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\treturn Configuration{}, err\r\n\t}\r\n\t\r\n\tvar peers []string\r\n\tdec := json.NewDecoder(bytes.NewReader(buf))\r\n\tif err := dec.Decode(&peers); err != nil {\r\n\t\treturn Configuration{}, err\r\n\t}\r\n\t\r\n\t\r\n\tvar configuration Configuration\r\n\tfor _, peer := range peers {\r\n\t\tserver := Server{\r\n\t\t\tSuffrage: Voter,\r\n\t\t\tID:       ServerID(peer),\r\n\t\t\tAddress:  ServerAddress(peer),\r\n\t\t}\r\n\t\tconfiguration.Servers = append(configuration.Servers, server)\r\n\t}\r\n\t\r\n\tif err := checkConfiguration(configuration); err != nil {\r\n\t\treturn Configuration{}, err\r\n\t}\r\n\treturn configuration, nil\r\n}","code-length":251,"reference":"\/\/ ReadPeersJSON consumes a legacy peers.json file in the format of the old JSON\n\/\/ peer store and creates a new-style configuration structure. This can be used\n\/\/ to migrate this data or perform manual recovery when running protocol versions\n\/\/ that can interoperate with older, unversioned Raft servers. This should not be\n\/\/ used once server IDs are in use, because the old peers.json file didn't have\n\/\/ support for these, nor non-voter suffrage types.","result":"Read peers from a JSON file.","score":[0.0,0.0217]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReadConfigJSON(path string) (Configuration, error) {\r\n\t\r\n\tbuf, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\treturn Configuration{}, err\r\n\t}\r\n\t\r\n\tvar peers []configEntry\r\n\tdec := json.NewDecoder(bytes.NewReader(buf))\r\n\tif err := dec.Decode(&peers); err != nil {\r\n\t\treturn Configuration{}, err\r\n\t}\r\n\t\r\n\tvar configuration Configuration\r\n\tfor _, peer := range peers {\r\n\t\tsuffrage := Voter\r\n\t\tif peer.NonVoter {\r\n\t\t\tsuffrage = Nonvoter\r\n\t\t}\r\n\t\tserver := Server{\r\n\t\t\tSuffrage: suffrage,\r\n\t\t\tID:       peer.ID,\r\n\t\t\tAddress:  peer.Address,\r\n\t\t}\r\n\t\tconfiguration.Servers = append(configuration.Servers, server)\r\n\t}\r\n\t\r\n\tif err := checkConfiguration(configuration); err != nil {\r\n\t\treturn Configuration{}, err\r\n\t}\r\n\treturn configuration, nil\r\n}","code-length":288,"reference":"\/\/ ReadConfigJSON reads a new-style peers.json and returns a configuration\n\/\/ structure. This can be used to perform manual recovery when running protocol\n\/\/ versions that use server IDs.","result":"Read the config file.","score":[0,0.0189]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTCPTransport(\r\n\tbindAddr string,\r\n\tadvertise net.Addr,\r\n\tmaxPool int,\r\n\ttimeout time.Duration,\r\n\tlogOutput io.Writer,\r\n) (*NetworkTransport, error) {\r\n\treturn newTCPTransport(bindAddr, advertise, func(stream StreamLayer) *NetworkTransport {\r\n\t\treturn NewNetworkTransport(stream, maxPool, timeout, logOutput)\r\n\t})\r\n}","code-length":114,"reference":"\/\/ NewTCPTransport returns a NetworkTransport that is built on top of\n\/\/ a TCP streaming transport layer.","result":"Create a new TCP transport.","score":[0.0259,0.0633]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTCPTransportWithLogger(\r\n\tbindAddr string,\r\n\tadvertise net.Addr,\r\n\tmaxPool int,\r\n\ttimeout time.Duration,\r\n\tlogger *log.Logger,\r\n) (*NetworkTransport, error) {\r\n\treturn newTCPTransport(bindAddr, advertise, func(stream StreamLayer) *NetworkTransport {\r\n\t\treturn NewNetworkTransportWithLogger(stream, maxPool, timeout, logger)\r\n\t})\r\n}","code-length":117,"reference":"\/\/ NewTCPTransportWithLogger returns a NetworkTransport that is built on top of\n\/\/ a TCP streaming transport layer, with log output going to the supplied Logger","result":"Create a new TCP transport with a logger.","score":[0.0248,0.1073]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTCPTransportWithConfig(\r\n\tbindAddr string,\r\n\tadvertise net.Addr,\r\n\tconfig *NetworkTransportConfig,\r\n) (*NetworkTransport, error) {\r\n\treturn newTCPTransport(bindAddr, advertise, func(stream StreamLayer) *NetworkTransport {\r\n\t\tconfig.Stream = stream\r\n\t\treturn NewNetworkTransportWithConfig(config)\r\n\t})\r\n}","code-length":104,"reference":"\/\/ NewTCPTransportWithConfig returns a NetworkTransport that is built on top of\n\/\/ a TCP streaming transport layer, using the given config struct.","result":"Create a new TCP transport.","score":[0.0095,0.0493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *TCPStreamLayer) Dial(address ServerAddress, timeout time.Duration) (net.Conn, error) {\r\n\treturn net.DialTimeout(\"tcp\", string(address), timeout)\r\n}","code-length":56,"reference":"\/\/ Dial implements the StreamLayer interface.","result":"Create the stream layer.","score":[0.1938,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *TCPStreamLayer) Accept() (c net.Conn, err error) {\r\n\treturn t.listener.Accept()\r\n}","code-length":42,"reference":"\/\/ Accept implements the net.Listener interface.","result":"Generate the code.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *TCPStreamLayer) Addr() net.Addr {\r\n\t\r\n\tif t.advertise != nil {\r\n\t\treturn t.advertise\r\n\t}\r\n\treturn t.listener.Addr()\r\n}","code-length":63,"reference":"\/\/ Addr implements the net.Listener interface.","result":"Get the address of the layer.","score":[0.193,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) restoreSnapshot() error {\r\n\tsnapshots, err := r.snapshots.List()\r\n\tif err != nil {\r\n\t\tr.logger.Error(fmt.Sprintf(\"Failed to list snapshots: %v\", err))\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tfor _, snapshot := range snapshots {\r\n\t\t_, source, err := r.snapshots.Open(snapshot.ID)\r\n\t\tif err != nil {\r\n\t\t\tr.logger.Error(fmt.Sprintf(\"Failed to open snapshot %v: %v\", snapshot.ID, err))\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tdefer source.Close()\r\n\t\tif err := r.fsm.Restore(source); err != nil {\r\n\t\t\tr.logger.Error(fmt.Sprintf(\"Failed to restore snapshot %v: %v\", snapshot.ID, err))\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tr.logger.Info(fmt.Sprintf(\"Restored from snapshot %v\", snapshot.ID))\r\n\t\t\r\n\t\tr.setLastApplied(snapshot.Index)\r\n\t\t\r\n\t\tr.setLastSnapshot(snapshot.Index, snapshot.Term)\r\n\t\t\r\n\t\tif snapshot.Version > 0 {\r\n\t\t\tr.configurations.committed = snapshot.Configuration\r\n\t\t\tr.configurations.committedIndex = snapshot.ConfigurationIndex\r\n\t\t\tr.configurations.latest = snapshot.Configuration\r\n\t\t\tr.configurations.latestIndex = snapshot.ConfigurationIndex\r\n\t\t} else {\r\n\t\t\tconfiguration := decodePeers(snapshot.Peers, r.trans)\r\n\t\t\tr.configurations.committed = configuration\r\n\t\t\tr.configurations.committedIndex = snapshot.Index\r\n\t\t\tr.configurations.latest = configuration\r\n\t\t\tr.configurations.latestIndex = snapshot.Index\r\n\t\t}\r\n\t\t\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\tif len(snapshots) > 0 {\r\n\t\treturn fmt.Errorf(\"failed to load any existing snapshots\")\r\n\t}\r\n\treturn nil\r\n}","code-length":506,"reference":"\/\/ restoreSnapshot attempts to restore the latest snapshots, and fails if none\n\/\/ of them can be restored. This is called at initialization time, and is\n\/\/ completely unsafe to call at any other time.","result":"Restore a snapshot.","score":[0,0.0157]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) BootstrapCluster(configuration Configuration) Future {\r\n\tbootstrapReq := &bootstrapFuture{}\r\n\tbootstrapReq.init()\r\n\tbootstrapReq.configuration = configuration\r\n\tselect {\r\n\tcase <-r.shutdownCh:\r\n\t\treturn errorFuture{ErrRaftShutdown}\r\n\tcase r.bootstrapCh <- bootstrapReq:\r\n\t\treturn bootstrapReq\r\n\t}\r\n}","code-length":105,"reference":"\/\/ BootstrapCluster is equivalent to non-member BootstrapCluster but can be\n\/\/ called on an un-bootstrapped Raft instance after it has been created. This\n\/\/ should only be called at the beginning of time for the cluster, and you\n\/\/ absolutely must make sure that you call it with the same configuration on all\n\/\/ the Voter servers. There is no need to bootstrap Nonvoter and Staging\n\/\/ servers.","result":"Create a new cluster.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) Leader() ServerAddress {\r\n\tr.leaderLock.RLock()\r\n\tleader := r.leader\r\n\tr.leaderLock.RUnlock()\r\n\treturn leader\r\n}","code-length":59,"reference":"\/\/ Leader is used to return the current leader of the cluster.\n\/\/ It may return empty string if there is no current leader\n\/\/ or the leader is unknown.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) Apply(cmd []byte, timeout time.Duration) ApplyFuture {\r\n\tmetrics.IncrCounter([]string{\"raft\", \"apply\"}, 1)\r\n\tvar timer <-chan time.Time\r\n\tif timeout > 0 {\r\n\t\ttimer = time.After(timeout)\r\n\t}\r\n\t\r\n\tlogFuture := &logFuture{\r\n\t\tlog: Log{\r\n\t\t\tType: LogCommand,\r\n\t\t\tData: cmd,\r\n\t\t},\r\n\t}\r\n\tlogFuture.init()\r\n\tselect {\r\n\tcase <-timer:\r\n\t\treturn errorFuture{ErrEnqueueTimeout}\r\n\tcase <-r.shutdownCh:\r\n\t\treturn errorFuture{ErrRaftShutdown}\r\n\tcase r.applyCh <- logFuture:\r\n\t\treturn logFuture\r\n\t}\r\n}","code-length":212,"reference":"\/\/ Apply is used to apply a command to the FSM in a highly consistent\n\/\/ manner. This returns a future that can be used to wait on the application.\n\/\/ An optional timeout can be provided to limit the amount of time we wait\n\/\/ for the command to be started. This must be run on the leader or it\n\/\/ will fail.","result":"Apply a command to a raft node.","score":[0.0001,0.0638]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) Barrier(timeout time.Duration) Future {\r\n\tmetrics.IncrCounter([]string{\"raft\", \"barrier\"}, 1)\r\n\tvar timer <-chan time.Time\r\n\tif timeout > 0 {\r\n\t\ttimer = time.After(timeout)\r\n\t}\r\n\t\r\n\tlogFuture := &logFuture{\r\n\t\tlog: Log{\r\n\t\t\tType: LogBarrier,\r\n\t\t},\r\n\t}\r\n\tlogFuture.init()\r\n\tselect {\r\n\tcase <-timer:\r\n\t\treturn errorFuture{ErrEnqueueTimeout}\r\n\tcase <-r.shutdownCh:\r\n\t\treturn errorFuture{ErrRaftShutdown}\r\n\tcase r.applyCh <- logFuture:\r\n\t\treturn logFuture\r\n\t}\r\n}","code-length":202,"reference":"\/\/ Barrier is used to issue a command that blocks until all preceeding\n\/\/ operations have been applied to the FSM. It can be used to ensure the\n\/\/ FSM reflects all queued writes. An optional timeout can be provided to\n\/\/ limit the amount of time we wait for the command to be started. This\n\/\/ must be run on the leader or it will fail.","result":"Avoid the need for the following code.","score":[0.0,0.0328]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) VerifyLeader() Future {\r\n\tmetrics.IncrCounter([]string{\"raft\", \"verify_leader\"}, 1)\r\n\tverifyFuture := &verifyFuture{}\r\n\tverifyFuture.init()\r\n\tselect {\r\n\tcase <-r.shutdownCh:\r\n\t\treturn errorFuture{ErrRaftShutdown}\r\n\tcase r.verifyCh <- verifyFuture:\r\n\t\treturn verifyFuture\r\n\t}\r\n}","code-length":115,"reference":"\/\/ VerifyLeader is used to ensure the current node is still\n\/\/ the leader. This can be done to prevent stale reads when a\n\/\/ new leader has potentially been elected.","result":"Verify the leader.","score":[0.0001,0.0665]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) AddVoter(id ServerID, address ServerAddress, prevIndex uint64, timeout time.Duration) IndexFuture {\r\n\tif r.protocolVersion < 2 {\r\n\t\treturn errorFuture{ErrUnsupportedProtocol}\r\n\t}\r\n\treturn r.requestConfigChange(configurationChangeRequest{\r\n\t\tcommand:       AddStaging,\r\n\t\tserverID:      id,\r\n\t\tserverAddress: address,\r\n\t\tprevIndex:     prevIndex,\r\n\t}, timeout)\r\n}","code-length":132,"reference":"\/\/ AddVoter will add the given server to the cluster as a staging server. If the\n\/\/ server is already in the cluster as a voter, this updates the server's address.\n\/\/ This must be run on the leader or it will fail. The leader will promote the\n\/\/ staging server to a voter once that server is ready. If nonzero, prevIndex is\n\/\/ the index of the only configuration upon which this change may be applied; if\n\/\/ another configuration entry has been added in the meantime, this request will\n\/\/ fail. If nonzero, timeout is how long this server should wait before the\n\/\/ configuration change log entry is appended.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) RemoveServer(id ServerID, prevIndex uint64, timeout time.Duration) IndexFuture {\r\n\tif r.protocolVersion < 2 {\r\n\t\treturn errorFuture{ErrUnsupportedProtocol}\r\n\t}\r\n\treturn r.requestConfigChange(configurationChangeRequest{\r\n\t\tcommand:   RemoveServer,\r\n\t\tserverID:  id,\r\n\t\tprevIndex: prevIndex,\r\n\t}, timeout)\r\n}","code-length":116,"reference":"\/\/ RemoveServer will remove the given server from the cluster. If the current\n\/\/ leader is being removed, it will cause a new election to occur. This must be\n\/\/ run on the leader or it will fail. For prevIndex and timeout, see AddVoter.","result":"Remove a server from the raft.","score":[0.0008,0.0925]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) Shutdown() Future {\r\n\tr.shutdownLock.Lock()\r\n\tdefer r.shutdownLock.Unlock()\r\n\tif !r.shutdown {\r\n\t\tclose(r.shutdownCh)\r\n\t\tr.shutdown = true\r\n\t\tr.setState(Shutdown)\r\n\t\treturn &shutdownFuture{r}\r\n\t}\r\n\t\r\n\treturn &shutdownFuture{nil}\r\n}","code-length":112,"reference":"\/\/ Shutdown is used to stop the Raft background routines.\n\/\/ This is not a graceful operation. Provides a future that\n\/\/ can be used to block until all background routines have exited.","result":"Shutdown the raft.","score":[0.0,0.0333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) Snapshot() SnapshotFuture {\r\n\tfuture := &userSnapshotFuture{}\r\n\tfuture.init()\r\n\tselect {\r\n\tcase r.userSnapshotCh <- future:\r\n\t\treturn future\r\n\tcase <-r.shutdownCh:\r\n\t\tfuture.respond(ErrRaftShutdown)\r\n\t\treturn future\r\n\t}\r\n}","code-length":97,"reference":"\/\/ Snapshot is used to manually force Raft to take a snapshot. Returns a future\n\/\/ that can be used to block until complete, and that contains a function that\n\/\/ can be used to open the snapshot.","result":"Create a snapshot of the raft.","score":[0.0011,0.0431]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) Restore(meta *SnapshotMeta, reader io.Reader, timeout time.Duration) error {\r\n\tmetrics.IncrCounter([]string{\"raft\", \"restore\"}, 1)\r\n\tvar timer <-chan time.Time\r\n\tif timeout > 0 {\r\n\t\ttimer = time.After(timeout)\r\n\t}\r\n\t\r\n\trestore := &userRestoreFuture{\r\n\t\tmeta:   meta,\r\n\t\treader: reader,\r\n\t}\r\n\trestore.init()\r\n\tselect {\r\n\tcase <-timer:\r\n\t\treturn ErrEnqueueTimeout\r\n\tcase <-r.shutdownCh:\r\n\t\treturn ErrRaftShutdown\r\n\tcase r.userRestoreCh <- restore:\r\n\t\t\r\n\t\tif err := restore.Error(); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tnoop := &logFuture{\r\n\t\tlog: Log{\r\n\t\t\tType: LogNoop,\r\n\t\t},\r\n\t}\r\n\tnoop.init()\r\n\tselect {\r\n\tcase <-timer:\r\n\t\treturn ErrEnqueueTimeout\r\n\tcase <-r.shutdownCh:\r\n\t\treturn ErrRaftShutdown\r\n\tcase r.applyCh <- noop:\r\n\t\treturn noop.Error()\r\n\t}\r\n}","code-length":337,"reference":"\/\/ Restore is used to manually force Raft to consume an external snapshot, such\n\/\/ as if restoring from a backup. We will use the current Raft configuration,\n\/\/ not the one from the snapshot, so that we can restore into a new cluster. We\n\/\/ will also use the higher of the index of the snapshot, or the current index,\n\/\/ and then add 1 to that, so we force a new state with a hole in the Raft log,\n\/\/ so that the snapshot will be sent to followers and used for any new joiners.\n\/\/ This can only be run on the leader, and blocks until the restore is complete\n\/\/ or an error occurs.\n\/\/\n\/\/ WARNING! This operation has the leader take on the state of the snapshot and\n\/\/ then sets itself up so that it replicates that to its followers though the\n\/\/ install snapshot process. This involves a potentially dangerous period where\n\/\/ the leader commits ahead of its followers, so should only be used for disaster\n\/\/ recovery into a fresh cluster, and should not be used in normal operations.","result":"Restore a snapshot.","score":[5.753e-28,0.0059]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) String() string {\r\n\treturn fmt.Sprintf(\"Node at %s [%v]\", r.localAddr, r.getState())\r\n}","code-length":50,"reference":"\/\/ String returns a string representation of this Raft node.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) LastContact() time.Time {\r\n\tr.lastContactLock.RLock()\r\n\tlast := r.lastContact\r\n\tr.lastContactLock.RUnlock()\r\n\treturn last\r\n}","code-length":64,"reference":"\/\/ LastContact returns the time of last contact by a leader.\n\/\/ This only makes sense if we are currently a follower.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *LoggerAdapter) Logf(s string, v ...interface{}) {\r\n\ta.log.Printf(s, v...)\r\n}","code-length":44,"reference":"\/\/ Logf will record a formatted message to the contained debug log","result":"Log messages.","score":[0,0.0455]}
{"code":"\/*is used to<extra_id_0>\r\nfunc containsNode(nodes []*raftNode, n *raftNode) bool {\r\n\tfor _, rn := range nodes {\r\n\t\tif rn == n {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":69,"reference":"\/\/ containsNode returns true if the slice 'nodes' contains 'n'","result":"Check if the node is in the list.","score":[0.153,0.1531]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *cluster) LeaderPlus(n int) []*raftNode {\r\n\tr := make([]*raftNode, 0, n+1)\r\n\tldr := c.Leader(time.Second)\r\n\tif ldr != nil {\r\n\t\tr = append(r, ldr)\r\n\t}\r\n\tif len(r) >= n {\r\n\t\treturn r\r\n\t}\r\n\tfor _, node := range c.nodes {\r\n\t\tif !containsNode(r, node) {\r\n\t\t\tr = append(r, node)\r\n\t\t\tif len(r) >= n {\r\n\t\t\t\treturn r\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn r\r\n}","code-length":182,"reference":"\/\/ LeaderPlus returns the leader + n additional nodes from the cluster\n\/\/ the leader is always the first node in the returned slice.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *cluster) WaitTilUptoDate(t *testing.T, maxWait time.Duration) {\r\n\tidx := c.lastApplySuccess.Index()\r\n\tstart := time.Now()\r\n\tfor true {\r\n\t\tallAtIdx := true\r\n\t\tfor i := 0; i < len(c.nodes); i++ {\r\n\t\t\tnodeAppliedIdx := c.nodes[i].raft.AppliedIndex()\r\n\t\t\tif nodeAppliedIdx < idx {\r\n\t\t\t\tallAtIdx = false\r\n\t\t\t\tbreak\r\n\t\t\t} else if nodeAppliedIdx > idx {\r\n\t\t\t\tallAtIdx = false\r\n\t\t\t\tidx = nodeAppliedIdx\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif allAtIdx {\r\n\t\t\tt.Logf(\"All nodes have appliedIndex=%d\", idx)\r\n\t\t\treturn\r\n\t\t}\r\n\t\tif time.Now().Sub(start) > maxWait {\r\n\t\t\tt.Fatalf(\"Gave up waiting for all nodes to reach raft Index %d, [currently at %v]\", idx, c.appliedIndexes())\r\n\t\t}\r\n\t\ttime.Sleep(time.Millisecond * 10)\r\n\t}\r\n}","code-length":305,"reference":"\/\/ WaitTilUptoDate blocks until all nodes in the cluster have gotten their\n\/\/ commitedIndex upto the Index from the last successful call to Apply","result":"Test the code.","score":[0.0004,0.0228]}
{"code":"\/*is used to<extra_id_0>\r\nfunc assertLogEntryEqual(t *testing.T, node string, exp *raft.Log, act *raft.Log) bool {\r\n\tres := true\r\n\tif exp.Term != act.Term {\r\n\t\tt.Errorf(\"Log Entry at Index %d for node %v has mismatched terms %d\/%d\", exp.Index, node, exp.Term, act.Term)\r\n\t\tres = false\r\n\t}\r\n\tif exp.Index != act.Index {\r\n\t\tt.Errorf(\"Node %v, Log Entry should be Index %d,but is %d\", node, exp.Index, act.Index)\r\n\t\tres = false\r\n\t}\r\n\tif exp.Type != act.Type {\r\n\t\tt.Errorf(\"Node %v, Log Entry at Index %d should have type %v but is %v\", node, exp.Index, exp.Type, act.Type)\r\n\t\tres = false\r\n\t}\r\n\tif !bytes.Equal(exp.Data, act.Data) {\r\n\t\tt.Errorf(\"Node %v, Log Entry at Index %d should have data %v, but has %v\", node, exp.Index, exp.Data, act.Data)\r\n\t\tres = false\r\n\t}\r\n\treturn res\r\n}","code-length":311,"reference":"\/\/ assertLogEntryEqual compares the 2 raft Log entries and reports any differences to the supplied testing.T instance\n\/\/ it return true if the 2 entries are equal, false otherwise.","result":"Assert log entries are equal .","score":[0.0059,0.0957]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) runFSM() {\r\n\tvar lastIndex, lastTerm uint64\r\n\tcommit := func(req *commitTuple) {\r\n\t\t\r\n\t\tvar resp interface{}\r\n\t\tif req.log.Type == LogCommand {\r\n\t\t\tstart := time.Now()\r\n\t\t\tresp = r.fsm.Apply(req.log)\r\n\t\t\tmetrics.MeasureSince([]string{\"raft\", \"fsm\", \"apply\"}, start)\r\n\t\t}\r\n\t\t\r\n\t\tlastIndex = req.log.Index\r\n\t\tlastTerm = req.log.Term\r\n\t\t\r\n\t\tif req.future != nil {\r\n\t\t\treq.future.response = resp\r\n\t\t\treq.future.respond(nil)\r\n\t\t}\r\n\t}\r\n\trestore := func(req *restoreFuture) {\r\n\t\t\r\n\t\tmeta, source, err := r.snapshots.Open(req.ID)\r\n\t\tif err != nil {\r\n\t\t\treq.respond(fmt.Errorf(\"failed to open snapshot %v: %v\", req.ID, err))\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\tstart := time.Now()\r\n\t\tif err := r.fsm.Restore(source); err != nil {\r\n\t\t\treq.respond(fmt.Errorf(\"failed to restore snapshot %v: %v\", req.ID, err))\r\n\t\t\tsource.Close()\r\n\t\t\treturn\r\n\t\t}\r\n\t\tsource.Close()\r\n\t\tmetrics.MeasureSince([]string{\"raft\", \"fsm\", \"restore\"}, start)\r\n\t\t\r\n\t\tlastIndex = meta.Index\r\n\t\tlastTerm = meta.Term\r\n\t\treq.respond(nil)\r\n\t}\r\n\tsnapshot := func(req *reqSnapshotFuture) {\r\n\t\t\r\n\t\tif lastIndex == 0 {\r\n\t\t\treq.respond(ErrNothingNewToSnapshot)\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\tstart := time.Now()\r\n\t\tsnap, err := r.fsm.Snapshot()\r\n\t\tmetrics.MeasureSince([]string{\"raft\", \"fsm\", \"snapshot\"}, start)\r\n\t\t\r\n\t\treq.index = lastIndex\r\n\t\treq.term = lastTerm\r\n\t\treq.snapshot = snap\r\n\t\treq.respond(err)\r\n\t}\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase ptr := <-r.fsmMutateCh:\r\n\t\t\tswitch req := ptr.(type) {\r\n\t\t\tcase *commitTuple:\r\n\t\t\t\tcommit(req)\r\n\t\t\tcase *restoreFuture:\r\n\t\t\t\trestore(req)\r\n\t\t\tdefault:\r\n\t\t\t\tpanic(fmt.Errorf(\"bad type passed to fsmMutateCh: %#v\", ptr))\r\n\t\t\t}\r\n\t\tcase req := <-r.fsmSnapshotCh:\r\n\t\t\tsnapshot(req)\r\n\t\tcase <-r.shutdownCh:\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":738,"reference":"\/\/ runFSM is a long running goroutine responsible for applying logs\n\/\/ to the FSM. This is done async of other logs since we don't want\n\/\/ the FSM to block our internal operations.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Configuration) Clone() (copy Configuration) {\r\n\tcopy.Servers = append(copy.Servers, c.Servers...)\r\n\treturn\r\n}","code-length":46,"reference":"\/\/ Clone makes a deep copy of a Configuration.","result":"Clone the configuration.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *configurations) Clone() (copy configurations) {\r\n\tcopy.committed = c.committed.Clone()\r\n\tcopy.committedIndex = c.committedIndex\r\n\tcopy.latest = c.latest.Clone()\r\n\tcopy.latestIndex = c.latestIndex\r\n\treturn\r\n}","code-length":83,"reference":"\/\/ Clone makes a deep copy of a configurations object.","result":"Clone the configurations.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc hasVote(configuration Configuration, id ServerID) bool {\r\n\tfor _, server := range configuration.Servers {\r\n\t\tif server.ID == id {\r\n\t\t\treturn server.Suffrage == Voter\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":77,"reference":"\/\/ hasVote returns true if the server identified by 'id' is a Voter in the\n\/\/ provided Configuration.","result":"Check if a server has a vote.","score":[0.0442,0.0888]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkConfiguration(configuration Configuration) error {\r\n\tidSet := make(map[ServerID]bool)\r\n\taddressSet := make(map[ServerAddress]bool)\r\n\tvar voters int\r\n\tfor _, server := range configuration.Servers {\r\n\t\tif server.ID == \"\" {\r\n\t\t\treturn fmt.Errorf(\"Empty ID in configuration: %v\", configuration)\r\n\t\t}\r\n\t\tif server.Address == \"\" {\r\n\t\t\treturn fmt.Errorf(\"Empty address in configuration: %v\", server)\r\n\t\t}\r\n\t\tif idSet[server.ID] {\r\n\t\t\treturn fmt.Errorf(\"Found duplicate ID in configuration: %v\", server.ID)\r\n\t\t}\r\n\t\tidSet[server.ID] = true\r\n\t\tif addressSet[server.Address] {\r\n\t\t\treturn fmt.Errorf(\"Found duplicate address in configuration: %v\", server.Address)\r\n\t\t}\r\n\t\taddressSet[server.Address] = true\r\n\t\tif server.Suffrage == Voter {\r\n\t\t\tvoters++\r\n\t\t}\r\n\t}\r\n\tif voters == 0 {\r\n\t\treturn fmt.Errorf(\"Need at least one voter in configuration: %v\", configuration)\r\n\t}\r\n\treturn nil\r\n}","code-length":322,"reference":"\/\/ checkConfiguration tests a cluster membership configuration for common\n\/\/ errors.","result":"Check the configuration of the server.","score":[0.0839,0.0476]}
{"code":"\/*is used to<extra_id_0>\r\nfunc nextConfiguration(current Configuration, currentIndex uint64, change configurationChangeRequest) (Configuration, error) {\r\n\tif change.prevIndex > 0 && change.prevIndex != currentIndex {\r\n\t\treturn Configuration{}, fmt.Errorf(\"Configuration changed since %v (latest is %v)\", change.prevIndex, currentIndex)\r\n\t}\r\n\tconfiguration := current.Clone()\r\n\tswitch change.command {\r\n\tcase AddStaging:\r\n\t\t\r\n\t\tnewServer := Server{\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tSuffrage: Voter,\r\n\t\t\tID:       change.serverID,\r\n\t\t\tAddress:  change.serverAddress,\r\n\t\t}\r\n\t\tfound := false\r\n\t\tfor i, server := range configuration.Servers {\r\n\t\t\tif server.ID == change.serverID {\r\n\t\t\t\tif server.Suffrage == Voter {\r\n\t\t\t\t\tconfiguration.Servers[i].Address = change.serverAddress\r\n\t\t\t\t} else {\r\n\t\t\t\t\tconfiguration.Servers[i] = newServer\r\n\t\t\t\t}\r\n\t\t\t\tfound = true\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif !found {\r\n\t\t\tconfiguration.Servers = append(configuration.Servers, newServer)\r\n\t\t}\r\n\tcase AddNonvoter:\r\n\t\tnewServer := Server{\r\n\t\t\tSuffrage: Nonvoter,\r\n\t\t\tID:       change.serverID,\r\n\t\t\tAddress:  change.serverAddress,\r\n\t\t}\r\n\t\tfound := false\r\n\t\tfor i, server := range configuration.Servers {\r\n\t\t\tif server.ID == change.serverID {\r\n\t\t\t\tif server.Suffrage != Nonvoter {\r\n\t\t\t\t\tconfiguration.Servers[i].Address = change.serverAddress\r\n\t\t\t\t} else {\r\n\t\t\t\t\tconfiguration.Servers[i] = newServer\r\n\t\t\t\t}\r\n\t\t\t\tfound = true\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif !found {\r\n\t\t\tconfiguration.Servers = append(configuration.Servers, newServer)\r\n\t\t}\r\n\tcase DemoteVoter:\r\n\t\tfor i, server := range configuration.Servers {\r\n\t\t\tif server.ID == change.serverID {\r\n\t\t\t\tconfiguration.Servers[i].Suffrage = Nonvoter\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\tcase RemoveServer:\r\n\t\tfor i, server := range configuration.Servers {\r\n\t\t\tif server.ID == change.serverID {\r\n\t\t\t\tconfiguration.Servers = append(configuration.Servers[:i], configuration.Servers[i+1:]...)\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\tcase Promote:\r\n\t\tfor i, server := range configuration.Servers {\r\n\t\t\tif server.ID == change.serverID && server.Suffrage == Staging {\r\n\t\t\t\tconfiguration.Servers[i].Suffrage = Voter\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\tif err := checkConfiguration(configuration); err != nil {\r\n\t\treturn Configuration{}, err\r\n\t}\r\n\treturn configuration, nil\r\n}","code-length":794,"reference":"\/\/ nextConfiguration generates a new Configuration from the current one and a\n\/\/ configuration change request. It's split from appendConfigurationEntry so\n\/\/ that it can be unit tested easily.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc encodePeers(configuration Configuration, trans Transport) []byte {\r\n\t\r\n\t\r\n\tvar encPeers [][]byte\r\n\tfor _, server := range configuration.Servers {\r\n\t\tif server.Suffrage == Voter {\r\n\t\t\tencPeers = append(encPeers, trans.EncodePeer(server.ID, server.Address))\r\n\t\t}\r\n\t}\r\n\t\r\n\tbuf, err := encodeMsgPack(encPeers)\r\n\tif err != nil {\r\n\t\tpanic(fmt.Errorf(\"failed to encode peers: %v\", err))\r\n\t}\r\n\treturn buf.Bytes()\r\n}","code-length":160,"reference":"\/\/ encodePeers is used to serialize a Configuration into the old peers format.\n\/\/ This is here for backwards compatibility when operating with a mix of old\n\/\/ servers and should be removed once we deprecate support for protocol version 1.","result":"Encode peers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc decodePeers(buf []byte, trans Transport) Configuration {\r\n\t\r\n\tvar encPeers [][]byte\r\n\tif err := decodeMsgPack(buf, &encPeers); err != nil {\r\n\t\tpanic(fmt.Errorf(\"failed to decode peers: %v\", err))\r\n\t}\r\n\t\r\n\tvar servers []Server\r\n\tfor _, enc := range encPeers {\r\n\t\tp := trans.DecodePeer(enc)\r\n\t\tservers = append(servers, Server{\r\n\t\t\tSuffrage: Voter,\r\n\t\t\tID:       ServerID(p),\r\n\t\t\tAddress:  ServerAddress(p),\r\n\t\t})\r\n\t}\r\n\treturn Configuration{\r\n\t\tServers: servers,\r\n\t}\r\n}","code-length":192,"reference":"\/\/ decodePeers is used to deserialize an old list of peers into a Configuration.\n\/\/ This is here for backwards compatibility with old log entries and snapshots;\n\/\/ it should be removed eventually.","result":"Decode peers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc encodeConfiguration(configuration Configuration) []byte {\r\n\tbuf, err := encodeMsgPack(configuration)\r\n\tif err != nil {\r\n\t\tpanic(fmt.Errorf(\"failed to encode configuration: %v\", err))\r\n\t}\r\n\treturn buf.Bytes()\r\n}","code-length":76,"reference":"\/\/ encodeConfiguration serializes a Configuration using MsgPack, or panics on\n\/\/ errors.","result":"Encode the configuration.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc decodeConfiguration(buf []byte) Configuration {\r\n\tvar configuration Configuration\r\n\tif err := decodeMsgPack(buf, &configuration); err != nil {\r\n\t\tpanic(fmt.Errorf(\"failed to decode configuration: %v\", err))\r\n\t}\r\n\treturn configuration\r\n}","code-length":77,"reference":"\/\/ decodeConfiguration deserializes a Configuration using MsgPack, or panics on\n\/\/ errors.","result":"Decode configuration messages.","score":[0,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raftState) goFunc(f func()) {\r\n\tr.routinesGroup.Add(1)\r\n\tgo func() {\r\n\t\tdefer r.routinesGroup.Done()\r\n\t\tf()\r\n\t}()\r\n}","code-length":70,"reference":"\/\/ Start a goroutine and properly handle the race between a routine\n\/\/ starting and incrementing, and exiting and decrementing.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raftState) getLastIndex() uint64 {\r\n\tr.lastLock.Lock()\r\n\tdefer r.lastLock.Unlock()\r\n\treturn max(r.lastLogIndex, r.lastSnapshotIndex)\r\n}","code-length":64,"reference":"\/\/ getLastIndex returns the last index in stable storage.\n\/\/ Either from the last log or from the last snapshot.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raftState) getLastEntry() (uint64, uint64) {\r\n\tr.lastLock.Lock()\r\n\tdefer r.lastLock.Unlock()\r\n\tif r.lastLogIndex >= r.lastSnapshotIndex {\r\n\t\treturn r.lastLogIndex, r.lastLogTerm\r\n\t}\r\n\treturn r.lastSnapshotIndex, r.lastSnapshotTerm\r\n}","code-length":102,"reference":"\/\/ getLastEntry returns the last index and term in stable storage.\n\/\/ Either from the last log or from the last snapshot.","result":"Get the last entry in the raft state.","score":[0.0406,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) checkRPCHeader(rpc RPC) error {\r\n\t\r\n\twh, ok := rpc.Command.(WithRPCHeader)\r\n\tif !ok {\r\n\t\treturn fmt.Errorf(\"RPC does not have a header\")\r\n\t}\r\n\theader := wh.GetRPCHeader()\r\n\t\r\n\t\r\n\tif header.ProtocolVersion < ProtocolVersionMin ||\r\n\t\theader.ProtocolVersion > ProtocolVersionMax {\r\n\t\treturn ErrUnsupportedProtocol\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif header.ProtocolVersion < r.conf.ProtocolVersion-1 {\r\n\t\treturn ErrUnsupportedProtocol\r\n\t}\r\n\treturn nil\r\n}","code-length":178,"reference":"\/\/ checkRPCHeader houses logic about whether this instance of Raft can process\n\/\/ the given RPC message.","result":"Check the RPC header.","score":[0.0147,0.0637]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) setLeader(leader ServerAddress) {\r\n\tr.leaderLock.Lock()\r\n\toldLeader := r.leader\r\n\tr.leader = leader\r\n\tr.leaderLock.Unlock()\r\n\tif oldLeader != leader {\r\n\t\tr.observe(LeaderObservation{leader: leader})\r\n\t}\r\n}","code-length":94,"reference":"\/\/ setLeader is used to modify the current leader of the cluster","result":"Set the leader of the raft.","score":[0.1572,0.3289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) requestConfigChange(req configurationChangeRequest, timeout time.Duration) IndexFuture {\r\n\tvar timer <-chan time.Time\r\n\tif timeout > 0 {\r\n\t\ttimer = time.After(timeout)\r\n\t}\r\n\tfuture := &configurationChangeFuture{\r\n\t\treq: req,\r\n\t}\r\n\tfuture.init()\r\n\tselect {\r\n\tcase <-timer:\r\n\t\treturn errorFuture{ErrEnqueueTimeout}\r\n\tcase r.configurationChangeCh <- future:\r\n\t\treturn future\r\n\tcase <-r.shutdownCh:\r\n\t\treturn errorFuture{ErrRaftShutdown}\r\n\t}\r\n}","code-length":168,"reference":"\/\/ requestConfigChange is a helper for the above functions that make\n\/\/ configuration change requests. 'req' describes the change. For timeout,\n\/\/ see AddVoter.","result":"Send configuration change requests to the Raft.","score":[0.0223,0.1146]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) run() {\r\n\tfor {\r\n\t\t\r\n\t\tselect {\r\n\t\tcase <-r.shutdownCh:\r\n\t\t\t\r\n\t\t\tr.setLeader(\"\")\r\n\t\t\treturn\r\n\t\tdefault:\r\n\t\t}\r\n\t\t\r\n\t\tswitch r.getState() {\r\n\t\tcase Follower:\r\n\t\t\tr.runFollower()\r\n\t\tcase Candidate:\r\n\t\t\tr.runCandidate()\r\n\t\tcase Leader:\r\n\t\t\tr.runLeader()\r\n\t\t}\r\n\t}\r\n}","code-length":150,"reference":"\/\/ run is a long running goroutine that runs the Raft FSM.","result":"Run the raft.","score":[0.0203,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) runFollower() {\r\n\tdidWarn := false\r\n\tr.logger.Info(fmt.Sprintf(\"%v entering Follower state (Leader: %q)\", r, r.Leader()))\r\n\tmetrics.IncrCounter([]string{\"raft\", \"state\", \"follower\"}, 1)\r\n\theartbeatTimer := randomTimeout(r.conf.HeartbeatTimeout)\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase rpc := <-r.rpcCh:\r\n\t\t\tr.processRPC(rpc)\r\n\t\tcase c := <-r.configurationChangeCh:\r\n\t\t\t\r\n\t\t\tc.respond(ErrNotLeader)\r\n\t\tcase a := <-r.applyCh:\r\n\t\t\t\r\n\t\t\ta.respond(ErrNotLeader)\r\n\t\tcase v := <-r.verifyCh:\r\n\t\t\t\r\n\t\t\tv.respond(ErrNotLeader)\r\n\t\tcase r := <-r.userRestoreCh:\r\n\t\t\t\r\n\t\t\tr.respond(ErrNotLeader)\r\n\t\tcase c := <-r.configurationsCh:\r\n\t\t\tc.configurations = r.configurations.Clone()\r\n\t\t\tc.respond(nil)\r\n\t\tcase b := <-r.bootstrapCh:\r\n\t\t\tb.respond(r.liveBootstrap(b.configuration))\r\n\t\tcase <-heartbeatTimer:\r\n\t\t\t\r\n\t\t\theartbeatTimer = randomTimeout(r.conf.HeartbeatTimeout)\r\n\t\t\t\r\n\t\t\tlastContact := r.LastContact()\r\n\t\t\tif time.Now().Sub(lastContact) < r.conf.HeartbeatTimeout {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tlastLeader := r.Leader()\r\n\t\t\tr.setLeader(\"\")\r\n\t\t\tif r.configurations.latestIndex == 0 {\r\n\t\t\t\tif !didWarn {\r\n\t\t\t\t\tr.logger.Warn(\"no known peers, aborting election\")\r\n\t\t\t\t\tdidWarn = true\r\n\t\t\t\t}\r\n\t\t\t} else if r.configurations.latestIndex == r.configurations.committedIndex &&\r\n\t\t\t\t!hasVote(r.configurations.latest, r.localID) {\r\n\t\t\t\tif !didWarn {\r\n\t\t\t\t\tr.logger.Warn(\"not part of stable configuration, aborting election\")\r\n\t\t\t\t\tdidWarn = true\r\n\t\t\t\t}\r\n\t\t\t} else {\r\n\t\t\t\tr.logger.Warn(fmt.Sprintf(\"Heartbeat timeout from %q reached, starting election\", lastLeader))\r\n\t\t\t\tmetrics.IncrCounter([]string{\"raft\", \"transition\", \"heartbeat_timeout\"}, 1)\r\n\t\t\t\tr.setState(Candidate)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\tcase <-r.shutdownCh:\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":665,"reference":"\/\/ runFollower runs the FSM for a follower.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) liveBootstrap(configuration Configuration) error {\r\n\t\r\n\terr := BootstrapCluster(&r.conf, r.logs, r.stable, r.snapshots,\r\n\t\tr.trans, configuration)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tvar entry Log\r\n\tif err := r.logs.GetLog(1, &entry); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tr.setCurrentTerm(1)\r\n\tr.setLastLog(entry.Index, entry.Term)\r\n\tr.processConfigurationLogEntry(&entry)\r\n\treturn nil\r\n}","code-length":172,"reference":"\/\/ liveBootstrap attempts to seed an initial configuration for the cluster. See\n\/\/ the Raft object's member BootstrapCluster for more details. This must only be\n\/\/ called on the main thread, and only makes sense in the follower state.","result":"Avoid the need for the function to be executed.","score":[0.0077,0.0694]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) runCandidate() {\r\n\tr.logger.Info(fmt.Sprintf(\"%v entering Candidate state in term %v\", r, r.getCurrentTerm()+1))\r\n\tmetrics.IncrCounter([]string{\"raft\", \"state\", \"candidate\"}, 1)\r\n\t\r\n\tvoteCh := r.electSelf()\r\n\telectionTimer := randomTimeout(r.conf.ElectionTimeout)\r\n\t\r\n\tgrantedVotes := 0\r\n\tvotesNeeded := r.quorumSize()\r\n\tr.logger.Debug(fmt.Sprintf(\"Votes needed: %d\", votesNeeded))\r\n\tfor r.getState() == Candidate {\r\n\t\tselect {\r\n\t\tcase rpc := <-r.rpcCh:\r\n\t\t\tr.processRPC(rpc)\r\n\t\tcase vote := <-voteCh:\r\n\t\t\t\r\n\t\t\tif vote.Term > r.getCurrentTerm() {\r\n\t\t\t\tr.logger.Debug(\"Newer term discovered, fallback to follower\")\r\n\t\t\t\tr.setState(Follower)\r\n\t\t\t\tr.setCurrentTerm(vote.Term)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif vote.Granted {\r\n\t\t\t\tgrantedVotes++\r\n\t\t\t\tr.logger.Debug(fmt.Sprintf(\"Vote granted from %s in term %v. Tally: %d\",\r\n\t\t\t\t\tvote.voterID, vote.Term, grantedVotes))\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif grantedVotes >= votesNeeded {\r\n\t\t\t\tr.logger.Info(fmt.Sprintf(\"Election won. Tally: %d\", grantedVotes))\r\n\t\t\t\tr.setState(Leader)\r\n\t\t\t\tr.setLeader(r.localAddr)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\tcase c := <-r.configurationChangeCh:\r\n\t\t\t\r\n\t\t\tc.respond(ErrNotLeader)\r\n\t\tcase a := <-r.applyCh:\r\n\t\t\t\r\n\t\t\ta.respond(ErrNotLeader)\r\n\t\tcase v := <-r.verifyCh:\r\n\t\t\t\r\n\t\t\tv.respond(ErrNotLeader)\r\n\t\tcase r := <-r.userRestoreCh:\r\n\t\t\t\r\n\t\t\tr.respond(ErrNotLeader)\r\n\t\tcase c := <-r.configurationsCh:\r\n\t\t\tc.configurations = r.configurations.Clone()\r\n\t\t\tc.respond(nil)\r\n\t\tcase b := <-r.bootstrapCh:\r\n\t\t\tb.respond(ErrCantBootstrap)\r\n\t\tcase <-electionTimer:\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tr.logger.Warn(\"Election timeout reached, restarting election\")\r\n\t\t\treturn\r\n\t\tcase <-r.shutdownCh:\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":677,"reference":"\/\/ runCandidate runs the FSM for a candidate.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) runLeader() {\r\n\tr.logger.Info(fmt.Sprintf(\"%v entering Leader state\", r))\r\n\tmetrics.IncrCounter([]string{\"raft\", \"state\", \"leader\"}, 1)\r\n\t\r\n\tasyncNotifyBool(r.leaderCh, true)\r\n\t\r\n\tif notify := r.conf.NotifyCh; notify != nil {\r\n\t\tselect {\r\n\t\tcase notify <- true:\r\n\t\tcase <-r.shutdownCh:\r\n\t\t}\r\n\t}\r\n\t\r\n\tr.leaderState.commitCh = make(chan struct{}, 1)\r\n\tr.leaderState.commitment = newCommitment(r.leaderState.commitCh,\r\n\t\tr.configurations.latest,\r\n\t\tr.getLastIndex()+1 )\r\n\tr.leaderState.inflight = list.New()\r\n\tr.leaderState.replState = make(map[ServerID]*followerReplication)\r\n\tr.leaderState.notify = make(map[*verifyFuture]struct{})\r\n\tr.leaderState.stepDown = make(chan struct{}, 1)\r\n\t\r\n\tdefer func() {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tr.setLastContact()\r\n\t\t\r\n\t\tfor _, p := range r.leaderState.replState {\r\n\t\t\tclose(p.stopCh)\r\n\t\t}\r\n\t\t\r\n\t\tfor e := r.leaderState.inflight.Front(); e != nil; e = e.Next() {\r\n\t\t\te.Value.(*logFuture).respond(ErrLeadershipLost)\r\n\t\t}\r\n\t\t\r\n\t\tfor future := range r.leaderState.notify {\r\n\t\t\tfuture.respond(ErrLeadershipLost)\r\n\t\t}\r\n\t\t\r\n\t\tr.leaderState.commitCh = nil\r\n\t\tr.leaderState.commitment = nil\r\n\t\tr.leaderState.inflight = nil\r\n\t\tr.leaderState.replState = nil\r\n\t\tr.leaderState.notify = nil\r\n\t\tr.leaderState.stepDown = nil\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tr.leaderLock.Lock()\r\n\t\tif r.leader == r.localAddr {\r\n\t\t\tr.leader = \"\"\r\n\t\t}\r\n\t\tr.leaderLock.Unlock()\r\n\t\t\r\n\t\tasyncNotifyBool(r.leaderCh, false)\r\n\t\t\r\n\t\tif notify := r.conf.NotifyCh; notify != nil {\r\n\t\t\tselect {\r\n\t\t\tcase notify <- false:\r\n\t\t\tcase <-r.shutdownCh:\r\n\t\t\t\t\r\n\t\t\t\tselect {\r\n\t\t\t\tcase notify <- false:\r\n\t\t\t\tdefault:\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}()\r\n\t\r\n\tr.startStopReplication()\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tnoop := &logFuture{\r\n\t\tlog: Log{\r\n\t\t\tType: LogNoop,\r\n\t\t},\r\n\t}\r\n\tr.dispatchLogs([]*logFuture{noop})\r\n\t\r\n\tr.leaderLoop()\r\n}","code-length":788,"reference":"\/\/ runLeader runs the FSM for a leader. Do the setup here and drop into\n\/\/ the leaderLoop for the hot loop.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) startStopReplication() {\r\n\tinConfig := make(map[ServerID]bool, len(r.configurations.latest.Servers))\r\n\tlastIdx := r.getLastIndex()\r\n\t\r\n\tfor _, server := range r.configurations.latest.Servers {\r\n\t\tif server.ID == r.localID {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tinConfig[server.ID] = true\r\n\t\tif _, ok := r.leaderState.replState[server.ID]; !ok {\r\n\t\t\tr.logger.Info(fmt.Sprintf(\"Added peer %v, starting replication\", server.ID))\r\n\t\t\ts := &followerReplication{\r\n\t\t\t\tpeer:        server,\r\n\t\t\t\tcommitment:  r.leaderState.commitment,\r\n\t\t\t\tstopCh:      make(chan uint64, 1),\r\n\t\t\t\ttriggerCh:   make(chan struct{}, 1),\r\n\t\t\t\tcurrentTerm: r.getCurrentTerm(),\r\n\t\t\t\tnextIndex:   lastIdx + 1,\r\n\t\t\t\tlastContact: time.Now(),\r\n\t\t\t\tnotify:      make(map[*verifyFuture]struct{}),\r\n\t\t\t\tnotifyCh:    make(chan struct{}, 1),\r\n\t\t\t\tstepDown:    r.leaderState.stepDown,\r\n\t\t\t}\r\n\t\t\tr.leaderState.replState[server.ID] = s\r\n\t\t\tr.goFunc(func() { r.replicate(s) })\r\n\t\t\tasyncNotifyCh(s.triggerCh)\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor serverID, repl := range r.leaderState.replState {\r\n\t\tif inConfig[serverID] {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tr.logger.Info(fmt.Sprintf(\"Removed peer %v, stopping replication after %v\", serverID, lastIdx))\r\n\t\trepl.stopCh <- lastIdx\r\n\t\tclose(repl.stopCh)\r\n\t\tdelete(r.leaderState.replState, serverID)\r\n\t}\r\n}","code-length":512,"reference":"\/\/ startStopReplication will set up state and start asynchronous replication to\n\/\/ new peers, and stop replication to removed peers. Before removing a peer,\n\/\/ it'll instruct the replication routines to try to replicate to the current\n\/\/ index. This must only be called from the main thread.","result":"Start stop replication.","score":[0.0,0.023]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) configurationChangeChIfStable() chan *configurationChangeFuture {\r\n\t\r\n\t\r\n\t\r\n\tdex &&\r\n\t\tr.getCommitIndex() >= r.leaderState.commitment.startIndex {\r\n\t\treturn r.configurationChangeCh\r\n\t}\r\n\treturn nil\r\n}","code-length":86,"reference":"\/\/ configurationChangeChIfStable returns r.configurationChangeCh if it's safe\n\/\/ to process requests from it, or nil otherwise. This must only be called\n\/\/ from the main thread.\n\/\/\n\/\/ Note that if the conditions here were to change outside of leaderLoop to take\n\/\/ this from nil to non-nil, we would need leaderLoop to be kicked.","result":"Get the configuration change channel.","score":[0.0,0.03]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) verifyLeader(v *verifyFuture) {\r\n\t\r\n\tv.votes = 1\r\n\t\r\n\tv.quorumSize = r.quorumSize()\r\n\tif v.quorumSize == 1 {\r\n\t\tv.respond(nil)\r\n\t\treturn\r\n\t}\r\n\t\r\n\tv.notifyCh = r.verifyCh\r\n\tr.leaderState.notify[v] = struct{}{}\r\n\t\r\n\tfor _, repl := range r.leaderState.replState {\r\n\t\trepl.notifyLock.Lock()\r\n\t\trepl.notify[v] = struct{}{}\r\n\t\trepl.notifyLock.Unlock()\r\n\t\tasyncNotifyCh(repl.notifyCh)\r\n\t}\r\n}","code-length":192,"reference":"\/\/ verifyLeader must be called from the main thread for safety.\n\/\/ Causes the followers to attempt an immediate heartbeat.","result":"Verify the leader.","score":[0.0014,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) checkLeaderLease() time.Duration {\r\n\t\r\n\tcontacted := 1\r\n\t\r\n\tvar maxDiff time.Duration\r\n\tnow := time.Now()\r\n\tfor peer, f := range r.leaderState.replState {\r\n\t\tdiff := now.Sub(f.LastContact())\r\n\t\tif diff <= r.conf.LeaderLeaseTimeout {\r\n\t\t\tcontacted++\r\n\t\t\tif diff > maxDiff {\r\n\t\t\t\tmaxDiff = diff\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\t\r\n\t\t\tif diff <= 3*r.conf.LeaderLeaseTimeout {\r\n\t\t\t\tr.logger.Warn(fmt.Sprintf(\"Failed to contact %v in %v\", peer, diff))\r\n\t\t\t} else {\r\n\t\t\t\tr.logger.Debug(fmt.Sprintf(\"Failed to contact %v in %v\", peer, diff))\r\n\t\t\t}\r\n\t\t}\r\n\t\tmetrics.AddSample([]string{\"raft\", \"leader\", \"lastContact\"}, float32(diff\/time.Millisecond))\r\n\t}\r\n\t\r\n\tquorum := r.quorumSize()\r\n\tif contacted < quorum {\r\n\t\tr.logger.Warn(\"Failed to contact quorum of nodes, stepping down\")\r\n\t\tr.setState(Follower)\r\n\t\tmetrics.IncrCounter([]string{\"raft\", \"transition\", \"leader_lease_timeout\"}, 1)\r\n\t}\r\n\treturn maxDiff\r\n}","code-length":367,"reference":"\/\/ checkLeaderLease is used to check if we can contact a quorum of nodes\n\/\/ within the last leader lease interval. If not, we need to step down,\n\/\/ as we may have lost connectivity. Returns the maximum duration without\n\/\/ contact. This must only be called from the main thread.","result":"Check the leader lease timeout.","score":[0.0,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) restoreUserSnapshot(meta *SnapshotMeta, reader io.Reader) error {\r\n\tdefer metrics.MeasureSince([]string{\"raft\", \"restoreUserSnapshot\"}, time.Now())\r\n\t\r\n\tversion := meta.Version\r\n\tif version < SnapshotVersionMin || version > SnapshotVersionMax {\r\n\t\treturn fmt.Errorf(\"unsupported snapshot version %d\", version)\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tcommittedIndex := r.configurations.committedIndex\r\n\tlatestIndex := r.configurations.latestIndex\r\n\tif committedIndex != latestIndex {\r\n\t\treturn fmt.Errorf(\"cannot restore snapshot now, wait until the configuration entry at %v has been applied (have applied %v)\",\r\n\t\t\tlatestIndex, committedIndex)\r\n\t}\r\n\t\r\n\tfor {\r\n\t\te := r.leaderState.inflight.Front()\r\n\t\tif e == nil {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\te.Value.(*logFuture).respond(ErrAbortedByRestore)\r\n\t\tr.leaderState.inflight.Remove(e)\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tterm := r.getCurrentTerm()\r\n\tlastIndex := r.getLastIndex()\r\n\tif meta.Index > lastIndex {\r\n\t\tlastIndex = meta.Index\r\n\t}\r\n\tlastIndex++\r\n\t\r\n\t\r\n\tsink, err := r.snapshots.Create(version, lastIndex, term,\r\n\t\tr.configurations.latest, r.configurations.latestIndex, r.trans)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to create snapshot: %v\", err)\r\n\t}\r\n\tn, err := io.Copy(sink, reader)\r\n\tif err != nil {\r\n\t\tsink.Cancel()\r\n\t\treturn fmt.Errorf(\"failed to write snapshot: %v\", err)\r\n\t}\r\n\tif n != meta.Size {\r\n\t\tsink.Cancel()\r\n\t\treturn fmt.Errorf(\"failed to write snapshot, size didn't match (%d != %d)\", n, meta.Size)\r\n\t}\r\n\tif err := sink.Close(); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to close snapshot: %v\", err)\r\n\t}\r\n\tr.logger.Info(fmt.Sprintf(\"Copied %d bytes to local snapshot\", n))\r\n\t\r\n\t\r\n\tfsm := &restoreFuture{ID: sink.ID()}\r\n\tfsm.init()\r\n\tselect {\r\n\tcase r.fsmMutateCh <- fsm:\r\n\tcase <-r.shutdownCh:\r\n\t\treturn ErrRaftShutdown\r\n\t}\r\n\tif err := fsm.Error(); err != nil {\r\n\t\tpanic(fmt.Errorf(\"failed to restore snapshot: %v\", err))\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tr.setLastLog(lastIndex, term)\r\n\tr.setLastApplied(lastIndex)\r\n\tr.setLastSnapshot(lastIndex, term)\r\n\tr.logger.Info(fmt.Sprintf(\"Restored user snapshot (index %d)\", lastIndex))\r\n\treturn nil\r\n}","code-length":790,"reference":"\/\/ restoreUserSnapshot is used to manually consume an external snapshot, such\n\/\/ as if restoring from a backup. We will use the current Raft configuration,\n\/\/ not the one from the snapshot, so that we can restore into a new cluster. We\n\/\/ will also use the higher of the index of the snapshot, or the current index,\n\/\/ and then add 1 to that, so we force a new state with a hole in the Raft log,\n\/\/ so that the snapshot will be sent to followers and used for any new joiners.\n\/\/ This can only be run on the leader, and returns a future that can be used to\n\/\/ block until complete.","result":"Code too long,keep in 512.","score":[0.0,0.0095]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) appendConfigurationEntry(future *configurationChangeFuture) {\r\n\tconfiguration, err := nextConfiguration(r.configurations.latest, r.configurations.latestIndex, future.req)\r\n\tif err != nil {\r\n\t\tfuture.respond(err)\r\n\t\treturn\r\n\t}\r\n\tr.logger.Info(fmt.Sprintf(\"Updating configuration with %s (%v, %v) to %+v\",\r\n\t\tfuture.req.command, future.req.serverID, future.req.serverAddress, configuration.Servers))\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif r.protocolVersion < 2 {\r\n\t\tfuture.log = Log{\r\n\t\t\tType: LogRemovePeerDeprecated,\r\n\t\t\tData: encodePeers(configuration, r.trans),\r\n\t\t}\r\n\t} else {\r\n\t\tfuture.log = Log{\r\n\t\t\tType: LogConfiguration,\r\n\t\t\tData: encodeConfiguration(configuration),\r\n\t\t}\r\n\t}\r\n\tr.dispatchLogs([]*logFuture{&future.logFuture})\r\n\tindex := future.Index()\r\n\tr.configurations.latest = configuration\r\n\tr.configurations.latestIndex = index\r\n\tr.leaderState.commitment.setConfiguration(configuration)\r\n\tr.startStopReplication()\r\n}","code-length":333,"reference":"\/\/ appendConfigurationEntry changes the configuration and adds a new\n\/\/ configuration entry to the log. This must only be called from the\n\/\/ main thread.","result":"Update the raft raft configuration.","score":[0.0044,0.0217]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) dispatchLogs(applyLogs []*logFuture) {\r\n\tnow := time.Now()\r\n\tdefer metrics.MeasureSince([]string{\"raft\", \"leader\", \"dispatchLog\"}, now)\r\n\tterm := r.getCurrentTerm()\r\n\tlastIndex := r.getLastIndex()\r\n\tn := len(applyLogs)\r\n\tlogs := make([]*Log, n)\r\n\tmetrics.SetGauge([]string{\"raft\", \"leader\", \"dispatchNumLogs\"}, float32(n))\r\n\tfor idx, applyLog := range applyLogs {\r\n\t\tapplyLog.dispatch = now\r\n\t\tlastIndex++\r\n\t\tapplyLog.log.Index = lastIndex\r\n\t\tapplyLog.log.Term = term\r\n\t\tlogs[idx] = &applyLog.log\r\n\t\tr.leaderState.inflight.PushBack(applyLog)\r\n\t}\r\n\t\r\n\tif err := r.logs.StoreLogs(logs); err != nil {\r\n\t\tr.logger.Error(fmt.Sprintf(\"Failed to commit logs: %v\", err))\r\n\t\tfor _, applyLog := range applyLogs {\r\n\t\t\tapplyLog.respond(err)\r\n\t\t}\r\n\t\tr.setState(Follower)\r\n\t\treturn\r\n\t}\r\n\tr.leaderState.commitment.match(r.localID, lastIndex)\r\n\t\r\n\tr.setLastLog(lastIndex, term)\r\n\t\r\n\tfor _, f := range r.leaderState.replState {\r\n\t\tasyncNotifyCh(f.triggerCh)\r\n\t}\r\n}","code-length":397,"reference":"\/\/ dispatchLog is called on the leader to push a log to disk, mark it\n\/\/ as inflight and begin replication of it.","result":"Dispatch logs.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) processLogs(index uint64, future *logFuture) {\r\n\t\r\n\tlastApplied := r.getLastApplied()\r\n\tif index <= lastApplied {\r\n\t\tr.logger.Warn(fmt.Sprintf(\"Skipping application of old log: %d\", index))\r\n\t\treturn\r\n\t}\r\n\t\r\n\tfor idx := r.getLastApplied() + 1; idx <= index; idx++ {\r\n\t\t\r\n\t\tif future != nil && future.log.Index == idx {\r\n\t\t\tr.processLog(&future.log, future)\r\n\t\t} else {\r\n\t\t\tl := new(Log)\r\n\t\t\tif err := r.logs.GetLog(idx, l); err != nil {\r\n\t\t\t\tr.logger.Error(fmt.Sprintf(\"Failed to get log at %d: %v\", idx, err))\r\n\t\t\t\tpanic(err)\r\n\t\t\t}\r\n\t\t\tr.processLog(l, nil)\r\n\t\t}\r\n\t\t\r\n\t\tr.setLastApplied(idx)\r\n\t}\r\n}","code-length":272,"reference":"\/\/ processLogs is used to apply all the committed entries that haven't been\n\/\/ applied up to the given index limit.\n\/\/ This can be called from both leaders and followers.\n\/\/ Followers call this from AppendEntries, for n entries at a time, and always\n\/\/ pass future=nil.\n\/\/ Leaders call this once per inflight when entries are committed. They pass\n\/\/ the future from inflights.","result":"Process logs in the raft .","score":[0.0,0.0083]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) processLog(l *Log, future *logFuture) {\r\n\tswitch l.Type {\r\n\tcase LogBarrier:\r\n\t\t\r\n\t\tfallthrough\r\n\tcase LogCommand:\r\n\t\t\r\n\t\tselect {\r\n\t\tcase r.fsmMutateCh <- &commitTuple{l, future}:\r\n\t\tcase <-r.shutdownCh:\r\n\t\t\tif future != nil {\r\n\t\t\t\tfuture.respond(ErrRaftShutdown)\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\treturn\r\n\tcase LogConfiguration:\r\n\tcase LogAddPeerDeprecated:\r\n\tcase LogRemovePeerDeprecated:\r\n\tcase LogNoop:\r\n\t\t\r\n\tdefault:\r\n\t\tpanic(fmt.Errorf(\"unrecognized log type: %#v\", l))\r\n\t}\r\n\t\r\n\tif future != nil {\r\n\t\tfuture.respond(nil)\r\n\t}\r\n}","code-length":240,"reference":"\/\/ processLog is invoked to process the application of a single committed log entry.","result":"Generate code for the generated code.","score":[0.0509,0.0379]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) processRPC(rpc RPC) {\r\n\tif err := r.checkRPCHeader(rpc); err != nil {\r\n\t\trpc.Respond(nil, err)\r\n\t\treturn\r\n\t}\r\n\tswitch cmd := rpc.Command.(type) {\r\n\tcase *AppendEntriesRequest:\r\n\t\tr.appendEntries(rpc, cmd)\r\n\tcase *RequestVoteRequest:\r\n\t\tr.requestVote(rpc, cmd)\r\n\tcase *InstallSnapshotRequest:\r\n\t\tr.installSnapshot(rpc, cmd)\r\n\tdefault:\r\n\t\tr.logger.Error(fmt.Sprintf(\"Got unexpected command: %#v\", rpc.Command))\r\n\t\trpc.Respond(nil, fmt.Errorf(\"unexpected command\"))\r\n\t}\r\n}","code-length":198,"reference":"\/\/ processRPC is called to handle an incoming RPC request. This must only be\n\/\/ called from the main thread.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) processHeartbeat(rpc RPC) {\r\n\tdefer metrics.MeasureSince([]string{\"raft\", \"rpc\", \"processHeartbeat\"}, time.Now())\r\n\t\r\n\tselect {\r\n\tcase <-r.shutdownCh:\r\n\t\treturn\r\n\tdefault:\r\n\t}\r\n\t\r\n\tswitch cmd := rpc.Command.(type) {\r\n\tcase *AppendEntriesRequest:\r\n\t\tr.appendEntries(rpc, cmd)\r\n\tdefault:\r\n\t\tr.logger.Error(fmt.Sprintf(\"Expected heartbeat, got command: %#v\", rpc.Command))\r\n\t\trpc.Respond(nil, fmt.Errorf(\"unexpected command\"))\r\n\t}\r\n}","code-length":179,"reference":"\/\/ processHeartbeat is a special handler used just for heartbeat requests\n\/\/ so that they can be fast-pathed if a transport supports it. This must only\n\/\/ be called from the main thread.","result":"Trigger the raft heartbeat routine.","score":[0.0011,0.0331]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) setLastContact() {\r\n\tr.lastContactLock.Lock()\r\n\tr.lastContact = time.Now()\r\n\tr.lastContactLock.Unlock()\r\n}","code-length":57,"reference":"\/\/ setLastContact is used to set the last contact time to now","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) persistVote(term uint64, candidate []byte) error {\r\n\tif err := r.stable.SetUint64(keyLastVoteTerm, term); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := r.stable.Set(keyLastVoteCand, candidate); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":106,"reference":"\/\/ persistVote is used to persist our vote for safety.","result":"Store the last vote in the raft.","score":[0.1052,0.0515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) setCurrentTerm(t uint64) {\r\n\t\r\n\tif err := r.stable.SetUint64(keyCurrentTerm, t); err != nil {\r\n\t\tpanic(fmt.Errorf(\"failed to save current term: %v\", err))\r\n\t}\r\n\tr.raftState.setCurrentTerm(t)\r\n}","code-length":94,"reference":"\/\/ setCurrentTerm is used to set the current term in a durable manner.","result":"Set the current term in the raft state.","score":[0.2327,0.3568]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) setState(state RaftState) {\r\n\tr.setLeader(\"\")\r\n\toldState := r.raftState.getState()\r\n\tr.raftState.setState(state)\r\n\tif oldState != state {\r\n\t\tr.observe(state)\r\n\t}\r\n}","code-length":85,"reference":"\/\/ setState is used to update the current state. Any state\n\/\/ transition causes the known leader to be cleared. This means\n\/\/ that leader should be set only after updating the state.","result":"Set the state of the raft.","score":[0.0028,0.066]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *commitment) getCommitIndex() uint64 {\r\n\tc.Lock()\r\n\tdefer c.Unlock()\r\n\treturn c.commitIndex\r\n}","code-length":49,"reference":"\/\/ Called by leader after commitCh is notified","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *commitment) recalculate() {\r\n\tif len(c.matchIndexes) == 0 {\r\n\t\treturn\r\n\t}\r\n\tmatched := make([]uint64, 0, len(c.matchIndexes))\r\n\tfor _, idx := range c.matchIndexes {\r\n\t\tmatched = append(matched, idx)\r\n\t}\r\n\tsort.Sort(uint64Slice(matched))\r\n\tquorumMatchIndex := matched[(len(matched)-1)\/2]\r\n\tif quorumMatchIndex > c.commitIndex && quorumMatchIndex >= c.startIndex {\r\n\t\tc.commitIndex = quorumMatchIndex\r\n\t\tasyncNotifyCh(c.commitCh)\r\n\t}\r\n}","code-length":178,"reference":"\/\/ Internal helper to calculate new commitIndex from matchIndexes.\n\/\/ Must be called with lock held.","result":"Recalculate commit indexes.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc randomTimeout(minVal time.Duration) <-chan time.Time {\r\n\tif minVal == 0 {\r\n\t\treturn nil\r\n\t}\r\n\textra := (time.Duration(rand.Int63()) % minVal)\r\n\treturn time.After(minVal + extra)\r\n}","code-length":79,"reference":"\/\/ randomTimeout returns a value that is between the minVal and 2x minVal.","result":"Generate a random timeout .","score":[0.0485,0.041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc generateUUID() string {\r\n\tbuf := make([]byte, 16)\r\n\tif _, err := crand.Read(buf); err != nil {\r\n\t\tpanic(fmt.Errorf(\"failed to read random bytes: %v\", err))\r\n\t}\r\n\treturn fmt.Sprintf(\"%08x-%04x-%04x-%04x-%12x\",\r\n\t\tbuf[0:4],\r\n\t\tbuf[4:6],\r\n\t\tbuf[6:8],\r\n\t\tbuf[8:10],\r\n\t\tbuf[10:16])\r\n}","code-length":149,"reference":"\/\/ generateUUID is used to generate a random UUID.","result":"Generate a random UUID.","score":[0.1885,0.4669]}
{"code":"\/*is used to<extra_id_0>\r\nfunc decodeMsgPack(buf []byte, out interface{}) error {\r\n\tr := bytes.NewBuffer(buf)\r\n\thd := codec.MsgpackHandle{}\r\n\tdec := codec.NewDecoder(r, &hd)\r\n\treturn dec.Decode(out)\r\n}","code-length":75,"reference":"\/\/ Decode reverses the encode operation on a byte slice input.","result":"Decode a message.","score":[0.0337,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc encodeMsgPack(in interface{}) (*bytes.Buffer, error) {\r\n\tbuf := bytes.NewBuffer(nil)\r\n\thd := codec.MsgpackHandle{}\r\n\tenc := codec.NewEncoder(buf, &hd)\r\n\terr := enc.Encode(in)\r\n\treturn buf, err\r\n}","code-length":86,"reference":"\/\/ Encode writes an encoded object to a new bytes buffer.","result":"Encode a message.","score":[0.0337,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc backoff(base time.Duration, round, limit uint64) time.Duration {\r\n\tpower := min(round, limit)\r\n\tfor power > 2 {\r\n\t\tbase *= 2\r\n\t\tpower--\r\n\t}\r\n\treturn base\r\n}","code-length":71,"reference":"\/\/ backoff is used to compute an exponential backoff\n\/\/ duration. Base time is scaled by the current round,\n\/\/ up to some maximum scale factor.","result":"Generate the code.","score":[0.0002,0.0211]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newApplySource(seed string) *applySource {\r\n\th := fnv.New32()\r\n\th.Write([]byte(seed))\r\n\ts := &applySource{seed: int64(h.Sum32())}\r\n\ts.reset()\r\n\treturn s\r\n}","code-length":79,"reference":"\/\/ newApplySource will create a new source, any source created with the same seed will generate the same sequence of data.","result":"Create a new applySource.","score":[0.0064,0.1526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *applySource) reset() {\r\n\ta.rnd = rand.New(rand.NewSource(a.seed))\r\n}","code-length":43,"reference":"\/\/ reset this source back to its initial state, it'll generate the same sequence of data it initially did","result":"Reset the source.","score":[0.002,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DefaultConfig() *Config {\r\n\treturn &Config{\r\n\t\tProtocolVersion:    ProtocolVersionMax,\r\n\t\tHeartbeatTimeout:   1000 * time.Millisecond,\r\n\t\tElectionTimeout:    1000 * time.Millisecond,\r\n\t\tCommitTimeout:      50 * time.Millisecond,\r\n\t\tMaxAppendEntries:   64,\r\n\t\tShutdownOnRemove:   true,\r\n\t\tTrailingLogs:       10240,\r\n\t\tSnapshotInterval:   120 * time.Second,\r\n\t\tSnapshotThreshold:  8192,\r\n\t\tLeaderLeaseTimeout: 500 * time.Millisecond,\r\n\t\tLogLevel:           \"DEBUG\",\r\n\t}\r\n}","code-length":172,"reference":"\/\/ DefaultConfig returns a Config with usable defaults.","result":"Initialize the default config.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ValidateConfig(config *Config) error {\r\n\t\r\n\t\r\n\tprotocolMin := ProtocolVersionMin\r\n\tif protocolMin == 0 {\r\n\t\tprotocolMin = 1\r\n\t}\r\n\tif config.ProtocolVersion < protocolMin ||\r\n\t\tconfig.ProtocolVersion > ProtocolVersionMax {\r\n\t\treturn fmt.Errorf(\"Protocol version %d must be >= %d and <= %d\",\r\n\t\t\tconfig.ProtocolVersion, protocolMin, ProtocolVersionMax)\r\n\t}\r\n\tif len(config.LocalID) == 0 {\r\n\t\treturn fmt.Errorf(\"LocalID cannot be empty\")\r\n\t}\r\n\tif config.HeartbeatTimeout < 5*time.Millisecond {\r\n\t\treturn fmt.Errorf(\"Heartbeat timeout is too low\")\r\n\t}\r\n\tif config.ElectionTimeout < 5*time.Millisecond {\r\n\t\treturn fmt.Errorf(\"Election timeout is too low\")\r\n\t}\r\n\tif config.CommitTimeout < time.Millisecond {\r\n\t\treturn fmt.Errorf(\"Commit timeout is too low\")\r\n\t}\r\n\tif config.MaxAppendEntries <= 0 {\r\n\t\treturn fmt.Errorf(\"MaxAppendEntries must be positive\")\r\n\t}\r\n\tif config.MaxAppendEntries > 1024 {\r\n\t\treturn fmt.Errorf(\"MaxAppendEntries is too large\")\r\n\t}\r\n\tif config.SnapshotInterval < 5*time.Millisecond {\r\n\t\treturn fmt.Errorf(\"Snapshot interval is too low\")\r\n\t}\r\n\tif config.LeaderLeaseTimeout < 5*time.Millisecond {\r\n\t\treturn fmt.Errorf(\"Leader lease timeout is too low\")\r\n\t}\r\n\tif config.LeaderLeaseTimeout > config.HeartbeatTimeout {\r\n\t\treturn fmt.Errorf(\"Leader lease timeout cannot be larger than heartbeat timeout\")\r\n\t}\r\n\tif config.ElectionTimeout < config.HeartbeatTimeout {\r\n\t\treturn fmt.Errorf(\"Election timeout must be equal or greater than Heartbeat Timeout\")\r\n\t}\r\n\treturn nil\r\n}","code-length":481,"reference":"\/\/ ValidateConfig is used to validate a sane configuration","result":"Validate the config.","score":[0,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) runSnapshots() {\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase <-randomTimeout(r.conf.SnapshotInterval):\r\n\t\t\t\r\n\t\t\tif !r.shouldSnapshot() {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif _, err := r.takeSnapshot(); err != nil {\r\n\t\t\t\tr.logger.Error(fmt.Sprintf(\"Failed to take snapshot: %v\", err))\r\n\t\t\t}\r\n\t\tcase future := <-r.userSnapshotCh:\r\n\t\t\t\r\n\t\t\tid, err := r.takeSnapshot()\r\n\t\t\tif err != nil {\r\n\t\t\t\tr.logger.Error(fmt.Sprintf(\"Failed to take snapshot: %v\", err))\r\n\t\t\t} else {\r\n\t\t\t\tfuture.opener = func() (*SnapshotMeta, io.ReadCloser, error) {\r\n\t\t\t\t\treturn r.snapshots.Open(id)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tfuture.respond(err)\r\n\t\tcase <-r.shutdownCh:\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":278,"reference":"\/\/ runSnapshots is a long running goroutine used to manage taking\n\/\/ new snapshots of the FSM. It runs in parallel to the FSM and\n\/\/ main goroutines, so that snapshots do not block normal operation.","result":"Run the snapshot routine .","score":[0.0005,0.0456]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) shouldSnapshot() bool {\r\n\t\r\n\tlastSnap, _ := r.getLastSnapshot()\r\n\t\r\n\tlastIdx, err := r.logs.LastIndex()\r\n\tif err != nil {\r\n\t\tr.logger.Error(fmt.Sprintf(\"Failed to get last log index: %v\", err))\r\n\t\treturn false\r\n\t}\r\n\t\r\n\tdelta := lastIdx - lastSnap\r\n\treturn delta >= r.conf.SnapshotThreshold\r\n}","code-length":129,"reference":"\/\/ shouldSnapshot checks if we meet the conditions to take\n\/\/ a new snapshot.","result":"Create a new function to create a new snapshot.","score":[0.1547,0.2778]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) takeSnapshot() (string, error) {\r\n\tdefer metrics.MeasureSince([]string{\"raft\", \"snapshot\", \"takeSnapshot\"}, time.Now())\r\n\t\r\n\tsnapReq := &reqSnapshotFuture{}\r\n\tsnapReq.init()\r\n\t\r\n\tselect {\r\n\tcase r.fsmSnapshotCh <- snapReq:\r\n\tcase <-r.shutdownCh:\r\n\t\treturn \"\", ErrRaftShutdown\r\n\t}\r\n\t\r\n\tif err := snapReq.Error(); err != nil {\r\n\t\tif err != ErrNothingNewToSnapshot {\r\n\t\t\terr = fmt.Errorf(\"failed to start snapshot: %v\", err)\r\n\t\t}\r\n\t\treturn \"\", err\r\n\t}\r\n\tdefer snapReq.snapshot.Release()\r\n\t\r\n\t\r\n\t\r\n\tconfigReq := &configurationsFuture{}\r\n\tconfigReq.init()\r\n\tselect {\r\n\tcase r.configurationsCh <- configReq:\r\n\tcase <-r.shutdownCh:\r\n\t\treturn \"\", ErrRaftShutdown\r\n\t}\r\n\tif err := configReq.Error(); err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tcommitted := configReq.configurations.committed\r\n\tcommittedIndex := configReq.configurations.committedIndex\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif snapReq.index < committedIndex {\r\n\t\treturn \"\", fmt.Errorf(\"cannot take snapshot now, wait until the configuration entry at %v has been applied (have applied %v)\",\r\n\t\t\tcommittedIndex, snapReq.index)\r\n\t}\r\n\t\r\n\tr.logger.Info(fmt.Sprintf(\"Starting snapshot up to %d\", snapReq.index))\r\n\tstart := time.Now()\r\n\tversion := getSnapshotVersion(r.protocolVersion)\r\n\tsink, err := r.snapshots.Create(version, snapReq.index, snapReq.term, committed, committedIndex, r.trans)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"failed to create snapshot: %v\", err)\r\n\t}\r\n\tmetrics.MeasureSince([]string{\"raft\", \"snapshot\", \"create\"}, start)\r\n\t\r\n\tstart = time.Now()\r\n\tif err := snapReq.snapshot.Persist(sink); err != nil {\r\n\t\tsink.Cancel()\r\n\t\treturn \"\", fmt.Errorf(\"failed to persist snapshot: %v\", err)\r\n\t}\r\n\tmetrics.MeasureSince([]string{\"raft\", \"snapshot\", \"persist\"}, start)\r\n\t\r\n\tif err := sink.Close(); err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"failed to close snapshot: %v\", err)\r\n\t}\r\n\t\r\n\tr.setLastSnapshot(snapReq.index, snapReq.term)\r\n\t\r\n\tif err := r.compactLogs(snapReq.index); err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tr.logger.Info(fmt.Sprintf(\"Snapshot to %d complete\", snapReq.index))\r\n\treturn sink.ID(), nil\r\n}","code-length":764,"reference":"\/\/ takeSnapshot is used to take a new snapshot. This must only be called from\n\/\/ the snapshot thread, never the main thread. This returns the ID of the new\n\/\/ snapshot, along with an error.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) compactLogs(snapIdx uint64) error {\r\n\tdefer metrics.MeasureSince([]string{\"raft\", \"compactLogs\"}, time.Now())\r\n\t\r\n\tminLog, err := r.logs.FirstIndex()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to get first log index: %v\", err)\r\n\t}\r\n\t\r\n\tlastLogIdx, _ := r.getLastLog()\r\n\tif lastLogIdx <= r.conf.TrailingLogs {\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tmaxLog := min(snapIdx, lastLogIdx-r.conf.TrailingLogs)\r\n\t\r\n\tr.logger.Info(fmt.Sprintf(\"Compacting logs from %d to %d\", minLog, maxLog))\r\n\t\r\n\tif err := r.logs.DeleteRange(minLog, maxLog); err != nil {\r\n\t\treturn fmt.Errorf(\"log compaction failed: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":266,"reference":"\/\/ compactLogs takes the last inclusive index of a snapshot\n\/\/ and trims the logs that are no longer needed.","result":"Avoid the need for a function to be called.","score":[0.0427,0.0794]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WebpackCheck(r *Runner) error {\r\n\tfmt.Println(\"~~~ Checking webpack.config.js ~~~\")\r\n\tif !r.App.WithWebpack {\r\n\t\treturn nil\r\n\t}\r\n\tbox := webpack.Templates\r\n\tf, err := box.FindString(\"webpack.config.js.tmpl\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ttmpl, err := template.New(\"webpack\").Parse(f)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tbb := &bytes.Buffer{}\r\n\terr = tmpl.Execute(bb, map[string]interface{}{\r\n\t\t\"opts\": &webpack.Options{\r\n\t\t\tApp: r.App,\r\n\t\t},\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tb, err := ioutil.ReadFile(\"webpack.config.js\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif string(b) == bb.String() {\r\n\t\treturn nil\r\n\t}\r\n\tif !ask(\"Your webpack.config.js file is different from the latest Buffalo template.\\nWould you like to replace yours with the latest template?\") {\r\n\t\tfmt.Println(\"\\tSkipping webpack.config.js\")\r\n\t\treturn nil\r\n\t}\r\n\twf, err := os.Create(\"webpack.config.js\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t_, err = wf.Write(bb.Bytes())\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn wf.Close()\r\n}","code-length":427,"reference":"\/\/ WebpackCheck will compare the current default Buffalo\n\/\/ webpack.config.js against the applications webpack.config.js. If they are\n\/\/ different you have the option to overwrite the existing webpack.config.js\n\/\/ file with the new one.","result":"Check the webpack.","score":[0.0,0.0162]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Generator, error) {\r\n\tg := genny.New()\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn g, err\r\n\t}\r\n\tif opts.Provider == \"none\" {\r\n\t\treturn g, nil\r\n\t}\r\n\tbox := packr.New(\"buffalo:genny:vcs\", \"..\/vcs\/templates\")\r\n\ts, err := box.FindString(\"ignore.tmpl\")\r\n\tif err != nil {\r\n\t\treturn g, err\r\n\t}\r\n\tp := opts.Provider\r\n\tn := fmt.Sprintf(\".%signore\", p)\r\n\tg.File(genny.NewFileS(n, s))\r\n\tg.Command(exec.Command(p, \"init\"))\r\n\targs := []string{\"add\", \".\"}\r\n\tif p == \"bzr\" {\r\n\t\t\r\n\t\targs = append(args, \"-q\")\r\n\t}\r\n\tg.Command(exec.Command(p, args...))\r\n\tg.Command(exec.Command(p, \"commit\", \"-q\", \"-m\", \"Initial Commit\"))\r\n\treturn g, nil\r\n}","code-length":302,"reference":"\/\/ New generator for adding VCS to an application","result":"Generate the generator.","score":[0,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UnixSocket(addr string) (*Listener, error) {\r\n\tlistener, err := net.Listen(\"unix\", addr)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &Listener{\r\n\t\tServer:   &http.Server{},\r\n\t\tListener: listener,\r\n\t}, nil\r\n}","code-length":94,"reference":"\/\/ UnixSocket returns a new Listener on that address","result":"Listen on unix socket.","score":[0.0915,0.2206]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e ErrorHandlers) Get(status int) ErrorHandler {\r\n\tif eh, ok := e[status]; ok {\r\n\t\treturn eh\r\n\t}\r\n\tif eh, ok := e[0]; ok {\r\n\t\treturn eh\r\n\t}\r\n\treturn defaultErrorHandler\r\n}","code-length":79,"reference":"\/\/ Get a registered ErrorHandler for this status code. If\n\/\/ no ErrorHandler has been registered, a default one will\n\/\/ be returned.","result":"Get error handlers for status.","score":[0.0078,0.0472]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *App) PanicHandler(next Handler) Handler {\r\n\treturn func(c Context) error {\r\n\t\tdefer func() {\r\n\t\t\tr := recover()\r\n\t\t\tvar err error\r\n\t\t\tif r != nil {\r\n\t\t\t\tswitch t := r.(type) {\r\n\t\t\t\tcase error:\r\n\t\t\t\t\terr = t\r\n\t\t\t\tcase string:\r\n\t\t\t\t\terr = errors.New(t)\r\n\t\t\t\tdefault:\r\n\t\t\t\t\terr = errors.New(fmt.Sprint(t))\r\n\t\t\t\t}\r\n\t\t\t\terr = err\r\n\t\t\t\tevents.EmitError(events.ErrPanic, err,\r\n\t\t\t\t\tmap[string]interface{}{\r\n\t\t\t\t\t\t\"context\": c,\r\n\t\t\t\t\t\t\"app\":     a,\r\n\t\t\t\t\t},\r\n\t\t\t\t)\r\n\t\t\t\teh := a.ErrorHandlers.Get(500)\r\n\t\t\t\teh(500, err, c)\r\n\t\t\t}\r\n\t\t}()\r\n\t\treturn next(c)\r\n\t}\r\n}","code-length":259,"reference":"\/\/ PanicHandler recovers from panics gracefully and calls\n\/\/ the error handling code for a 500 error.","result":"Handle panic in the application.","score":[0.0218,0.0949]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s templateRenderer) partialFeeder(name string) (string, error) {\r\n\tct := strings.ToLower(s.contentType)\r\n\td, f := filepath.Split(name)\r\n\tname = filepath.Join(d, \"_\"+f)\r\n\tname = fixExtension(name, ct)\r\n\treturn s.TemplatesBox.FindString(name)\r\n}","code-length":99,"reference":"\/\/ partialFeeder returns template string for the name from `TemplateBox`.\n\/\/ It should be registered as helper named `partialFeeder` so plush can\n\/\/ find it with the name.","result":"Generate feeder templates.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts Options) *Engine {\r\n\tif opts.Helpers == nil {\r\n\t\topts.Helpers = map[string]interface{}{}\r\n\t}\r\n\tif opts.TemplateEngines == nil {\r\n\t\topts.TemplateEngines = map[string]TemplateEngine{}\r\n\t}\r\n\tif _, ok := opts.TemplateEngines[\"html\"]; !ok {\r\n\t\topts.TemplateEngines[\"html\"] = plush.BuffaloRenderer\r\n\t}\r\n\tif _, ok := opts.TemplateEngines[\"text\"]; !ok {\r\n\t\topts.TemplateEngines[\"text\"] = plush.BuffaloRenderer\r\n\t}\r\n\tif _, ok := opts.TemplateEngines[\"txt\"]; !ok {\r\n\t\topts.TemplateEngines[\"txt\"] = plush.BuffaloRenderer\r\n\t}\r\n\tif _, ok := opts.TemplateEngines[\"js\"]; !ok {\r\n\t\topts.TemplateEngines[\"js\"] = plush.BuffaloRenderer\r\n\t}\r\n\tif _, ok := opts.TemplateEngines[\"md\"]; !ok {\r\n\t\topts.TemplateEngines[\"md\"] = MDTemplateEngine\r\n\t}\r\n\tif _, ok := opts.TemplateEngines[\"tmpl\"]; !ok {\r\n\t\topts.TemplateEngines[\"tmpl\"] = GoTemplateEngine\r\n\t}\r\n\tif opts.DefaultContentType == \"\" {\r\n\t\topts.DefaultContentType = \"text\/html; charset=utf-8\"\r\n\t}\r\n\te := &Engine{\r\n\t\tOptions: opts,\r\n\t}\r\n\treturn e\r\n}","code-length":399,"reference":"\/\/ New render.Engine ready to go with your Options\n\/\/ and some defaults we think you might like.","result":"Create a new engine.","score":[0,0.0301]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) WriteTo(w io.Writer) (int64, error) {\r\n\tmw := &messageWriter{w: w}\r\n\tmw.writeMessage(m)\r\n\treturn mw.n, mw.err\r\n}","code-length":68,"reference":"\/\/ WriteTo implements io.WriterTo. It dumps the whole message into w.","result":"Write message to.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (sm SMTPSender) Send(message Message) error {\r\n\tgm := gomail.NewMessage()\r\n\tgm.SetHeader(\"From\", message.From)\r\n\tgm.SetHeader(\"To\", message.To...)\r\n\tgm.SetHeader(\"Subject\", message.Subject)\r\n\tgm.SetHeader(\"Cc\", message.CC...)\r\n\tgm.SetHeader(\"Bcc\", message.Bcc...)\r\n\tsm.addBodies(message, gm)\r\n\tsm.addAttachments(message, gm)\r\n\tfor field, value := range message.Headers {\r\n\t\tgm.SetHeader(field, value)\r\n\t}\r\n\terr := sm.Dialer.DialAndSend(gm)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":204,"reference":"\/\/Send a message using SMTP configuration or returns an error if something goes wrong.","result":"Send messages.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSMTPSender(host string, port string, user string, password string) (SMTPSender, error) {\r\n\tiport, err := strconv.Atoi(port)\r\n\tif err != nil {\r\n\t\treturn SMTPSender{}, errors.New(\"invalid port for the SMTP mail\")\r\n\t}\r\n\tdialer := &gomail.Dialer{\r\n\t\tHost: host,\r\n\t\tPort: iport,\r\n\t}\r\n\tif user != \"\" {\r\n\t\tdialer.Username = user\r\n\t\tdialer.Password = password\r\n\t}\r\n\treturn SMTPSender{\r\n\t\tDialer: dialer,\r\n\t}, nil\r\n}","code-length":177,"reference":"\/\/NewSMTPSender builds a SMTP mail based in passed config.","result":"Create a new sender.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DefaultContext) Param(key string) string {\r\n\treturn d.Params().Get(key)\r\n}","code-length":38,"reference":"\/\/ Param returns a param, either named or query string,\n\/\/ based on the key.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DefaultContext) Set(key string, value interface{}) {\r\n\td.moot.Lock()\r\n\td.data[key] = value\r\n\td.moot.Unlock()\r\n}","code-length":60,"reference":"\/\/ Set a value onto the Context. Any value set onto the Context\n\/\/ will be automatically available in templates.","result":"Set the value of a key in the default context.","score":[0.0625,0.1842]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DefaultContext) Value(key interface{}) interface{} {\r\n\tif k, ok := key.(string); ok {\r\n\t\td.moot.RLock()\r\n\t\tdefer d.moot.RUnlock()\r\n\t\tif v, ok := d.data[k]; ok {\r\n\t\t\treturn v\r\n\t\t}\r\n\t}\r\n\treturn d.Context.Value(key)\r\n}","code-length":112,"reference":"\/\/ Value that has previously stored on the context.","result":"Access the value of a context value.","score":[0.1214,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DefaultContext) Redirect(status int, url string, args ...interface{}) error {\r\n\td.Flash().persist(d.Session())\r\n\tif strings.HasSuffix(url, \"Path()\") {\r\n\t\tif len(args) > 1 {\r\n\t\t\treturn fmt.Errorf(\"you must pass only a map[string]interface{} to a route path: %T\", args)\r\n\t\t}\r\n\t\tvar m map[string]interface{}\r\n\t\tif len(args) == 1 {\r\n\t\t\trv := reflect.Indirect(reflect.ValueOf(args[0]))\r\n\t\t\tif !rv.Type().ConvertibleTo(mapType) {\r\n\t\t\t\treturn fmt.Errorf(\"you must pass only a map[string]interface{} to a route path: %T\", args)\r\n\t\t\t}\r\n\t\t\tm = rv.Convert(mapType).Interface().(map[string]interface{})\r\n\t\t}\r\n\t\th, ok := d.Value(strings.TrimSuffix(url, \"()\")).(RouteHelperFunc)\r\n\t\tif !ok {\r\n\t\t\treturn fmt.Errorf(\"could not find a route helper named %s\", url)\r\n\t\t}\r\n\t\turl, err := h(m)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\thttp.Redirect(d.Response(), d.Request(), string(url), status)\r\n\t\treturn nil\r\n\t}\r\n\tif len(args) > 0 {\r\n\t\turl = fmt.Sprintf(url, args...)\r\n\t}\r\n\thttp.Redirect(d.Response(), d.Request(), url, status)\r\n\treturn nil\r\n}","code-length":414,"reference":"\/\/ Redirect a request with the given status to the given URL.","result":"Redirect to a specific URL.","score":[0.0838,0.177]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DefaultContext) File(name string) (binding.File, error) {\r\n\treq := d.Request()\r\n\tif err := req.ParseMultipartForm(5 * 1024 * 1024); err != nil {\r\n\t\treturn binding.File{}, err\r\n\t}\r\n\tf, h, err := req.FormFile(name)\r\n\tbf := binding.File{\r\n\t\tFile:       f,\r\n\t\tFileHeader: h,\r\n\t}\r\n\tif err != nil {\r\n\t\treturn bf, err\r\n\t}\r\n\treturn bf, nil\r\n}","code-length":152,"reference":"\/\/ File returns an uploaded file by name, or an error","result":"Generate the file binding.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DefaultContext) MarshalJSON() ([]byte, error) {\r\n\tm := map[string]interface{}{}\r\n\tdata := d.Data()\r\n\tfor k, v := range data {\r\n\t\t\r\n\t\tif _, ok := v.(*DefaultContext); ok {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif _, err := json.Marshal(v); err == nil {\r\n\t\t\t\r\n\t\t\tm[k] = v\r\n\t\t}\r\n\t}\r\n\treturn json.Marshal(m)\r\n}","code-length":141,"reference":"\/\/ MarshalJSON implements json marshaling for the context","result":"Serialize the context.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Group, error) {\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tgg, err := core.New(opts.Options)\r\n\tif err != nil {\r\n\t\treturn gg, err\r\n\t}\r\n\tg := genny.New()\r\n\tdata := map[string]interface{}{\r\n\t\t\"opts\": opts,\r\n\t}\r\n\thelpers := template.FuncMap{}\r\n\tt := gogen.TemplateTransformer(data, helpers)\r\n\tg.Transformer(t)\r\n\tg.Box(packr.New(\"buffalo:genny:newapp:api\", \"..\/api\/templates\"))\r\n\tgg.Add(g)\r\n\treturn gg, nil\r\n}","code-length":206,"reference":"\/\/ New generator for creating a Buffalo API application","result":"Create a new app.","score":[0.0915,0.3007]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts Options) *App {\r\n\tLoadPlugins()\r\n\tenvy.Load()\r\n\topts = optionsWithDefaults(opts)\r\n\ta := &App{\r\n\t\tOptions: opts,\r\n\t\tErrorHandlers: ErrorHandlers{\r\n\t\t\t404: defaultErrorHandler,\r\n\t\t\t500: defaultErrorHandler,\r\n\t\t},\r\n\t\trouter:   mux.NewRouter(),\r\n\t\tmoot:     &sync.RWMutex{},\r\n\t\troutes:   RouteList{},\r\n\t\tchildren: []*App{},\r\n\t}\r\n\tdem := a.defaultErrorMiddleware\r\n\ta.Middleware = newMiddlewareStack(dem)\r\n\tnotFoundHandler := func(errorf string, code int) http.HandlerFunc {\r\n\t\treturn func(res http.ResponseWriter, req *http.Request) {\r\n\t\t\tc := a.newContext(RouteInfo{}, res, req)\r\n\t\t\terr := fmt.Errorf(errorf, req.Method, req.URL.Path)\r\n\t\t\ta.ErrorHandlers.Get(code)(code, err, c)\r\n\t\t}\r\n\t}\r\n\ta.router.NotFoundHandler = notFoundHandler(\"path not found: %s %s\", 404)\r\n\ta.router.MethodNotAllowedHandler = notFoundHandler(\"method not found: %s %s\", 405)\r\n\tif a.MethodOverride == nil {\r\n\t\ta.MethodOverride = MethodOverride\r\n\t}\r\n\ta.Use(a.PanicHandler)\r\n\ta.Use(RequestLogger)\r\n\ta.Use(sessionSaver)\r\n\treturn a\r\n}","code-length":396,"reference":"\/\/ New returns a new instance of App and adds some sane, and useful, defaults.","result":"Create a new app.","score":[0.0289,0.1349]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DeprecrationsCheck(r *Runner) error {\r\n\tfmt.Println(\"~~~ Checking for deprecations ~~~\")\r\n\tb, err := ioutil.ReadFile(\"main.go\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif bytes.Contains(b, []byte(\"app.Start\")) {\r\n\t\tr.Warnings = append(r.Warnings, \"app.Start has been removed in v0.11.0. Use app.Serve Instead. [main.go]\")\r\n\t}\r\n\treturn filepath.Walk(filepath.Join(r.App.Root, \"actions\"), func(path string, info os.FileInfo, _ error) error {\r\n\t\tif info.IsDir() {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tif filepath.Ext(path) != \".go\" {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tb, err := ioutil.ReadFile(path)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif bytes.Contains(b, []byte(\"Websocket()\")) {\r\n\t\t\tr.Warnings = append(r.Warnings, fmt.Sprintf(\"buffalo.Context#Websocket has been deprecated in v0.11.0, and removed in v0.12.0. Use github.com\/gorilla\/websocket directly. [%s]\", path))\r\n\t\t}\r\n\t\tif bytes.Contains(b, []byte(\"meta.Name\")) {\r\n\t\t\tr.Warnings = append(r.Warnings, fmt.Sprintf(\"meta.Name has been deprecated in v0.11.0, and removed in v0.12.0. Use github.com\/markbates\/inflect.Name directly. [%s]\", path))\r\n\t\t}\r\n\t\tif bytes.Contains(b, []byte(\"generators.Find(\")) {\r\n\t\t\tr.Warnings = append(r.Warnings, fmt.Sprintf(\"generators.Find(string) has been deprecated in v0.11.0, and removed in v0.12.0. Use generators.FindByBox() instead. [%s]\", path))\r\n\t\t}\r\n\t\t\r\n\t\tif bytes.Contains(b, []byte(\"T.CookieName\")) {\r\n\t\t\tb = bytes.Replace(b, []byte(\"T.CookieName\"), []byte(\"T.LanguageExtractorOptions[\\\"CookieName\\\"]\"), -1)\r\n\t\t}\r\n\t\tif bytes.Contains(b, []byte(\"T.SessionName\")) {\r\n\t\t\tb = bytes.Replace(b, []byte(\"T.SessionName\"), []byte(\"T.LanguageExtractorOptions[\\\"SessionName\\\"]\"), -1)\r\n\t\t}\r\n\t\tif bytes.Contains(b, []byte(\"T.LanguageFinder=\")) || bytes.Contains(b, []byte(\"T.LanguageFinder \")) {\r\n\t\t\tr.Warnings = append(r.Warnings, fmt.Sprintf(\"i18n.Translator#LanguageFinder has been deprecated in v0.11.1, and has been removed in v0.12.0. Use i18n.Translator#LanguageExtractors instead. [%s]\", path))\r\n\t\t}\r\n\t\tioutil.WriteFile(path, b, 0664)\r\n\t\treturn nil\r\n\t})\r\n}","code-length":794,"reference":"\/\/ DeprecrationsCheck will either log, or fix, deprecated items in the application","result":"Code too long,keep in 512.","score":[0.0593,0.0442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v BaseResource) List(c Context) error {\r\n\treturn c.Error(404, errors.New(\"resource not implemented\"))\r\n}","code-length":44,"reference":"\/\/ List default implementation. Returns a 404","result":"Generate the list of resources.","score":[0,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s funcRenderer) Render(w io.Writer, data Data) error {\r\n\treturn s.renderFunc(w, data)\r\n}","code-length":43,"reference":"\/\/ Render the provided Data to the provider Writer using the\n\/\/ RendererFunc provide.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Session) Save() error {\r\n\treturn s.Session.Save(s.req, s.res)\r\n}","code-length":40,"reference":"\/\/ Save the current session.","result":"Save the session.","score":[0.328,0.5324]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Session) GetOnce(name interface{}) interface{} {\r\n\tif x, ok := s.Session.Values[name]; ok {\r\n\t\ts.Delete(name)\r\n\t\treturn x\r\n\t}\r\n\treturn nil\r\n}","code-length":71,"reference":"\/\/ GetOnce gets a value from the current session and then deletes it.","result":"Get the value of a session value.","score":[0.0969,0.2016]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Session) Set(name, value interface{}) {\r\n\ts.Session.Values[name] = value\r\n}","code-length":40,"reference":"\/\/ Set a value onto the current session. If a value with that name\n\/\/ already exists it will be overridden with the new value.","result":"Set values in session.","score":[0.002,0.0655]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Session) Clear() {\r\n\tfor k := range s.Session.Values {\r\n\t\ts.Delete(k)\r\n\t}\r\n}","code-length":48,"reference":"\/\/ Clear the current session","result":"Clear the session.","score":[0.2964,0.3906]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *App) getSession(r *http.Request, w http.ResponseWriter) *Session {\r\n\tif a.root != nil {\r\n\t\treturn a.root.getSession(r, w)\r\n\t}\r\n\tsession, _ := a.SessionStore.Get(r, a.SessionName)\r\n\treturn &Session{\r\n\t\tSession: session,\r\n\t\treq:     r,\r\n\t\tres:     w,\r\n\t}\r\n}","code-length":123,"reference":"\/\/ Get a session using a request and response.","result":"Get the session from the session store.","score":[0.1443,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Generator, error) {\r\n\tg := genny.New()\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn g, err\r\n\t}\r\n\tdata := map[string]interface{}{\r\n\t\t\"opts\": opts,\r\n\t}\r\n\tt := gogen.TemplateTransformer(data, template.FuncMap{})\r\n\tg.Transformer(t)\r\n\tg.RunFn(func(r *genny.Runner) error {\r\n\t\treturn genFile(r, opts)\r\n\t})\r\n\treturn g, nil\r\n}","code-length":160,"reference":"\/\/ New generator to create a grift task","result":"Generate the generator.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Generator, error) {\r\n\tg := genny.New()\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn g, err\r\n\t}\r\n\tg.RunFn(func(r *genny.Runner) error {\r\n\t\tif _, err := r.LookPath(\"npm\"); err != nil {\r\n\t\t\treturn errors.New(\"could not find npm executable\")\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tg.Box(Templates)\r\n\tdata := map[string]interface{}{\r\n\t\t\"opts\": opts,\r\n\t}\r\n\tt := gogen.TemplateTransformer(data, gogen.TemplateHelpers)\r\n\tg.Transformer(t)\r\n\tg.Transformer(genny.Dot())\r\n\tg.RunFn(func(r *genny.Runner) error {\r\n\t\treturn installPkgs(r, opts)\r\n\t})\r\n\treturn g, nil\r\n}","code-length":251,"reference":"\/\/ New generator for creating webpack asset files","result":"Create a new generator.","score":[0,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Generator, error) {\r\n\tg := genny.New()\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn g, err\r\n\t}\r\n\tg.Box(packr.New(\"buffalo:genny:refresh\", \"..\/refresh\/templates\"))\r\n\tctx := plush.NewContext()\r\n\tctx.Set(\"app\", opts.App)\r\n\tg.Transformer(plushgen.Transformer(ctx))\r\n\tg.Transformer(genny.Dot())\r\n\treturn g, nil\r\n}","code-length":151,"reference":"\/\/ New generator to generate refresh templates","result":"Generate the generator.","score":[0,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMessage(settings ...MessageSetting) *Message {\r\n\tm := &Message{\r\n\t\theader:   make(header),\r\n\t\tcharset:  \"UTF-8\",\r\n\t\tencoding: QuotedPrintable,\r\n\t}\r\n\tm.applySettings(settings)\r\n\tif m.encoding == Base64 {\r\n\t\tm.hEncoder = bEncoding\r\n\t} else {\r\n\t\tm.hEncoder = qEncoding\r\n\t}\r\n\treturn m\r\n}","code-length":128,"reference":"\/\/ NewMessage creates a new message. It uses UTF-8 and quoted-printable encoding\n\/\/ by default.","result":"Create a new message.","score":[0.0421,0.2855]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) Reset() {\r\n\tfor k := range m.header {\r\n\t\tdelete(m.header, k)\r\n\t}\r\n\tm.parts = nil\r\n\tm.attachments = nil\r\n\tm.embedded = nil\r\n}","code-length":72,"reference":"\/\/ Reset resets the message so it can be reused. The message keeps its previous\n\/\/ settings so it is in the same state that after a call to NewMessage.","result":"Reset the message.","score":[0.0001,0.0366]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) SetHeader(field string, value ...string) {\r\n\tm.encodeHeader(value)\r\n\tm.header[field] = value\r\n}","code-length":50,"reference":"\/\/ SetHeader sets a value to the given header field.","result":"Set header fields.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) SetHeaders(h map[string][]string) {\r\n\tfor k, v := range h {\r\n\t\tm.SetHeader(k, v...)\r\n\t}\r\n}","code-length":58,"reference":"\/\/ SetHeaders sets the message headers.","result":"Set headers in the message.","score":[0.1967,0.1695]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) SetAddressHeader(field, address, name string) {\r\n\tm.header[field] = []string{m.FormatAddress(address, name)}\r\n}","code-length":52,"reference":"\/\/ SetAddressHeader sets an address to the given header field.","result":"Set address header.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) FormatAddress(address, name string) string {\r\n\tif name == \"\" {\r\n\t\treturn address\r\n\t}\r\n\tenc := m.encodeString(name)\r\n\tif enc == name {\r\n\t\tm.buf.WriteByte('\"')\r\n\t\tfor i := 0; i < len(name); i++ {\r\n\t\t\tb := name[i]\r\n\t\t\tif b == '\\\\' || b == '\"' {\r\n\t\t\t\tm.buf.WriteByte('\\\\')\r\n\t\t\t}\r\n\t\t\tm.buf.WriteByte(b)\r\n\t\t}\r\n\t\tm.buf.WriteByte('\"')\r\n\t} else if hasSpecials(name) {\r\n\t\tm.buf.WriteString(bEncoding.Encode(m.charset, name))\r\n\t} else {\r\n\t\tm.buf.WriteString(enc)\r\n\t}\r\n\tm.buf.WriteString(\" <\")\r\n\tm.buf.WriteString(address)\r\n\tm.buf.WriteByte('>')\r\n\taddr := m.buf.String()\r\n\tm.buf.Reset()\r\n\treturn addr\r\n}","code-length":288,"reference":"\/\/ FormatAddress formats an address and a name as a valid RFC 5322 address.","result":"Format addresses in the form of a string.","score":[0.0656,0.1119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) SetDateHeader(field string, date time.Time) {\r\n\tm.header[field] = []string{m.FormatDate(date)}\r\n}","code-length":51,"reference":"\/\/ SetDateHeader sets a date to the given header field.","result":"Set the date header.","score":[0.0848,0.1596]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) FormatDate(date time.Time) string {\r\n\treturn date.Format(time.RFC1123Z)\r\n}","code-length":42,"reference":"\/\/ FormatDate formats a date as a valid RFC 5322 date.","result":"Format the date of the message.","score":[0.0839,0.0952]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) SetBody(contentType, body string, settings ...PartSetting) {\r\n\tm.SetBodyWriter(contentType, newCopier(body), settings...)\r\n}","code-length":51,"reference":"\/\/ SetBody sets the body of the message. It replaces any content previously set\n\/\/ by SetBody, SetBodyWriter, AddAlternative or AddAlternativeWriter.","result":"Set the body of a message.","score":[0.0351,0.1908]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetPartEncoding(e Encoding) PartSetting {\r\n\treturn PartSetting(func(p *part) {\r\n\t\tp.encoding = e\r\n\t})\r\n}","code-length":50,"reference":"\/\/ SetPartEncoding sets the encoding of the part added to the message. By\n\/\/ default, parts use the same encoding than the message.","result":"Set the part encoding .","score":[0.0103,0.0943]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetHeader(h map[string][]string) FileSetting {\r\n\treturn func(f *file) {\r\n\t\tfor k, v := range h {\r\n\t\t\tf.Header[k] = v\r\n\t\t}\r\n\t}\r\n}","code-length":71,"reference":"\/\/ SetHeader is a file setting to set the MIME header of the message part that\n\/\/ contains the file content.\n\/\/\n\/\/ Mandatory headers are automatically added if they are not set when sending\n\/\/ the email.","result":"Set the header of the file.","score":[0.0021,0.1069]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetCopyFunc(f func(io.Writer) error) FileSetting {\r\n\treturn func(fi *file) {\r\n\t\tfi.CopyFunc = f\r\n\t}\r\n}","code-length":54,"reference":"\/\/ SetCopyFunc is a file setting to replace the function that runs when the\n\/\/ message is sent. It should copy the content of the file to the io.Writer.\n\/\/\n\/\/ The default copy function opens the file with the given filename, and copy\n\/\/ its content to the io.Writer.","result":"Copy files.","score":[0,0.0111]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) AttachReader(name string, r io.Reader, settings ...FileSetting) {\r\n\tm.attachments = m.appendFile(m.attachments, fileFromReader(name, r), settings)\r\n}","code-length":61,"reference":"\/\/ AttachReader attaches a file using an io.Reader","result":"Attach a file to a message.","score":[0.1956,0.1923]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) Attach(filename string, settings ...FileSetting) {\r\n\tm.attachments = m.appendFile(m.attachments, fileFromFilename(filename), settings)\r\n}","code-length":53,"reference":"\/\/ Attach attaches the files to the email.","result":"Add attachments to a message.","score":[0.1319,0.1299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) EmbedReader(name string, r io.Reader, settings ...FileSetting) {\r\n\tm.embedded = m.appendFile(m.embedded, fileFromReader(name, r), settings)\r\n}","code-length":61,"reference":"\/\/ EmbedReader embeds the images to the email.","result":"Embed embedded files.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) Embed(filename string, settings ...FileSetting) {\r\n\tm.embedded = m.appendFile(m.embedded, fileFromFilename(filename), settings)\r\n}","code-length":53,"reference":"\/\/ Embed embeds the images to the email.","result":"Embed messages.","score":[0.0249,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ValidateTemplates(walk packd.Walker, tvs []TemplateValidator) genny.RunFn {\r\n\tif len(tvs) == 0 {\r\n\t\treturn func(r *genny.Runner) error {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t}\r\n\treturn func(r *genny.Runner) error {\r\n\t\tvar errs []string\r\n\t\terr := packd.SkipWalker(walk, packd.CommonSkipPrefixes, func(path string, file packd.File) error {\r\n\t\t\tinfo, err := file.FileInfo()\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif info.IsDir() {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\tf := genny.NewFile(path, file)\r\n\t\t\tfor _, tv := range tvs {\r\n\t\t\t\terr := safe.Run(func() {\r\n\t\t\t\t\tif err := tv(f); err != nil {\r\n\t\t\t\t\t\terrs = append(errs, fmt.Sprintf(\"template error in file %s: %s\", path, err.Error()))\r\n\t\t\t\t\t}\r\n\t\t\t\t})\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t})\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif len(errs) == 0 {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\treturn errors.New(strings.Join(errs, \"\\n\"))\r\n\t}\r\n}","code-length":393,"reference":"\/\/ ValidateTemplates returns a genny.RunFn that will walk the\n\/\/ given box and run each of the files found through each of the\n\/\/ template validators","result":"Validate templates.","score":[0,0.0212]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PlushValidator(f genny.File) error {\r\n\tif !genny.HasExt(f, \".html\", \".md\", \".plush\") {\r\n\t\treturn nil\r\n\t}\r\n\t_, err := plush.Parse(f.String())\r\n\treturn err\r\n}","code-length":80,"reference":"\/\/ PlushValidator validates the file is a valid\n\/\/ Plush file if the extension is .md, .html, or .plush","result":"Validate Plush files.","score":[0.002,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (opts *Options) Validate() error {\r\n\tif opts.App.IsZero() {\r\n\t\topts.App = meta.New(\".\")\r\n\t}\r\n\tif len(opts.Name.String()) == 0 {\r\n\t\treturn errors.New(\"you must supply a name for your mailer\")\r\n\t}\r\n\treturn nil\r\n}","code-length":94,"reference":"\/\/ Validate options are useful","result":"Validate the options.","score":[0.2096,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadPlugins() error {\r\n\tvar err error\r\n\toncer.Do(\"events.LoadPlugins\", func() {\r\n\t\t\r\n\t\tif envy.Get(\"GO_ENV\", \"development\") == \"test\" {\r\n\t\t\treturn\r\n\t\t}\r\n\t\tplugs, err := plugins.Available()\r\n\t\tif err != nil {\r\n\t\t\terr = err\r\n\t\t\treturn\r\n\t\t}\r\n\t\tfor _, cmds := range plugs {\r\n\t\t\tfor _, c := range cmds {\r\n\t\t\t\tif c.BuffaloCommand != \"events\" {\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\terr := func(c plugins.Command) error {\r\n\t\t\t\t\treturn safe.RunE(func() error {\r\n\t\t\t\t\t\tn := fmt.Sprintf(\"[PLUGIN] %s %s\", c.Binary, c.Name)\r\n\t\t\t\t\t\tfn := func(e events.Event) {\r\n\t\t\t\t\t\t\tb, err := json.Marshal(e)\r\n\t\t\t\t\t\t\tif err != nil {\r\n\t\t\t\t\t\t\t\tfmt.Println(\"error trying to marshal event\", e, err)\r\n\t\t\t\t\t\t\t\treturn\r\n\t\t\t\t\t\t\t}\r\n\t\t\t\t\t\t\tcmd := exec.Command(c.Binary, c.UseCommand, string(b))\r\n\t\t\t\t\t\t\tcmd.Stderr = os.Stderr\r\n\t\t\t\t\t\t\tcmd.Stdout = os.Stdout\r\n\t\t\t\t\t\t\tcmd.Stdin = os.Stdin\r\n\t\t\t\t\t\t\tif err := cmd.Run(); err != nil {\r\n\t\t\t\t\t\t\t\tfmt.Println(\"error trying to send event\", strings.Join(cmd.Args, \" \"), err)\r\n\t\t\t\t\t\t\t}\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\t_, err := events.NamedListen(n, events.Filter(c.ListenFor, fn))\r\n\t\t\t\t\t\tif err != nil {\r\n\t\t\t\t\t\t\treturn err\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\treturn nil\r\n\t\t\t\t\t})\r\n\t\t\t\t}(c)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\terr = err\r\n\t\t\t\t\treturn\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t})\r\n\treturn err\r\n}","code-length":521,"reference":"\/\/ LoadPlugins will add listeners for any plugins that support \"events\"","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *Response) WriteHeader(i int) {\r\n\tw.Status = i\r\n\tw.ResponseWriter.WriteHeader(i)\r\n}","code-length":45,"reference":"\/\/ WriteHeader sets the status code for a response","result":"Write code to the file.","score":[0.1284,0.1163]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *Response) Write(b []byte) (int, error) {\r\n\tw.Size = binary.Size(b)\r\n\treturn w.ResponseWriter.Write(b)\r\n}","code-length":56,"reference":"\/\/ Write the body of the response","result":"Write to the response.","score":[0.1795,0.1493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *Response) Flush() {\r\n\tif f, ok := w.ResponseWriter.(http.Flusher); ok {\r\n\t\tf.Flush()\r\n\t}\r\n}","code-length":54,"reference":"\/\/ Flush the response","result":"Flush the response.","score":[0.4137,0.4808]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *Response) CloseNotify() <-chan bool {\r\n\tif cn, ok := w.ResponseWriter.(closeNotifier); ok {\r\n\t\treturn cn.CloseNotify()\r\n\t}\r\n\treturn nil\r\n}","code-length":63,"reference":"\/\/ CloseNotify implements the http.CloseNotifier interface","result":"Close the response.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Run() error {\r\n\tfmt.Printf(\"! This updater will attempt to update your application to Buffalo version: %s\\n\", runtime.Version)\r\n\tif !ask(\"Do you wish to continue?\") {\r\n\t\tfmt.Println(\"~~~ cancelling update ~~~\")\r\n\t\treturn nil\r\n\t}\r\n\tr := &Runner{\r\n\t\tApp:      meta.New(\".\"),\r\n\t\tWarnings: []string{},\r\n\t}\r\n\tdefer func() {\r\n\t\tif len(r.Warnings) == 0 {\r\n\t\t\treturn\r\n\t\t}\r\n\t\tfmt.Println(\"\\n\\n----------------------------\")\r\n\t\tfmt.Printf(\"!!! (%d) Warnings Were Found !!!\\n\\n\", len(r.Warnings))\r\n\t\tfor _, w := range r.Warnings {\r\n\t\t\tfmt.Printf(\"[WARNING]: %s\\n\", w)\r\n\t\t}\r\n\t}()\r\n\tfor _, c := range checks {\r\n\t\tif err := c(r); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":290,"reference":"\/\/ Run all compatible checks","result":"Update your application.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc onlyRelevantFiles(p string, fi os.FileInfo, err error, fn func(p string) error) error {\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif fi.IsDir() {\r\n\t\tbase := filepath.Base(p)\r\n\t\tif strings.HasPrefix(base, \"_\") {\r\n\t\t\treturn filepath.SkipDir\r\n\t\t}\r\n\t\tfor _, n := range []string{\"vendor\", \"node_modules\", \".git\"} {\r\n\t\t\tif base == n {\r\n\t\t\t\treturn filepath.SkipDir\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\text := filepath.Ext(p)\r\n\tif ext != \".go\" {\r\n\t\treturn nil\r\n\t}\r\n\treturn fn(p)\r\n}","code-length":210,"reference":"\/\/onlyRelevantFiles processes only .go files excluding folders like node_modules and vendor.","result":"Exclude files in the generated code.","score":[0.0839,0.0952]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GoTemplateEngine(input string, data map[string]interface{}, helpers map[string]interface{}) (string, error) {\r\n\t\r\n\t\r\n\t\r\n\tdata[\"nilOpts\"] = map[string]interface{}{}\r\n\tt := template.New(input)\r\n\tif helpers != nil {\r\n\t\tt = t.Funcs(helpers)\r\n\t}\r\n\tt, err := t.Parse(input)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tbb := &bytes.Buffer{}\r\n\terr = t.Execute(bb, data)\r\n\treturn bb.String(), err\r\n}","code-length":166,"reference":"\/\/ GoTemplateEngine implements the TemplateEngine interface for using standard Go templates","result":"Generate the template engine.","score":[0.0555,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *App) GET(p string, h Handler) *RouteInfo {\r\n\treturn a.addRoute(\"GET\", p, h)\r\n}","code-length":45,"reference":"\/\/ GET maps an HTTP \"GET\" request to the path and the specified handler.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *App) Redirect(status int, from, to string) *RouteInfo {\r\n\treturn a.GET(from, func(c Context) error {\r\n\t\treturn c.Redirect(status, to)\r\n\t})\r\n}","code-length":66,"reference":"\/\/ Redirect from one URL to another URL. Only works for \"GET\" requests.","result":"Redirect to a different path.","score":[0.0577,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *App) ANY(p string, h Handler) {\r\n\ta.GET(p, h)\r\n\ta.POST(p, h)\r\n\ta.PUT(p, h)\r\n\ta.PATCH(p, h)\r\n\ta.HEAD(p, h)\r\n\ta.OPTIONS(p, h)\r\n\ta.DELETE(p, h)\r\n}","code-length":104,"reference":"\/\/ ANY accepts a request across any HTTP method for the specified path\n\/\/ and routes it to the specified Handler.","result":"Match the route.","score":[0.001,0.026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *App) buildRouteName(p string) string {\r\n\tif p == \"\/\" || p == \"\" {\r\n\t\treturn \"root\"\r\n\t}\r\n\tresultParts := []string{}\r\n\tparts := strings.Split(p, \"\/\")\r\n\tfor index, part := range parts {\r\n\t\tif strings.Contains(part, \"{\") || part == \"\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tshouldSingularize := (len(parts) > index+1) && strings.Contains(parts[index+1], \"{\")\r\n\t\tif shouldSingularize {\r\n\t\t\tpart = flect.Singularize(part)\r\n\t\t}\r\n\t\tif parts[index] == \"new\" || parts[index] == \"edit\" {\r\n\t\t\tresultParts = append([]string{part}, resultParts...)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif index > 0 && strings.Contains(parts[index-1], \"}\") {\r\n\t\t\tresultParts = append(resultParts, part)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tresultParts = append(resultParts, part)\r\n\t}\r\n\tif len(resultParts) == 0 {\r\n\t\treturn \"unnamed\"\r\n\t}\r\n\tunderscore := strings.TrimSpace(strings.Join(resultParts, \"_\"))\r\n\treturn name.VarCase(underscore)\r\n}","code-length":341,"reference":"\/\/buildRouteName builds a route based on the path passed.","result":"Build the route name .","score":[0.1284,0.1744]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Group, error) {\r\n\tgg := &genny.Group{}\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn gg, err\r\n\t}\r\n\tif !opts.SkipInit {\r\n\t\tg, err := initGenerator(opts)\r\n\t\tif err != nil {\r\n\t\t\treturn gg, err\r\n\t\t}\r\n\t\tgg.Add(g)\r\n\t}\r\n\tg := genny.New()\r\n\th := template.FuncMap{}\r\n\tdata := map[string]interface{}{\r\n\t\t\"opts\": opts,\r\n\t}\r\n\tt := gogen.TemplateTransformer(data, h)\r\n\tg.Transformer(t)\r\n\tfn := opts.Name.File().String()\r\n\tg.File(genny.NewFileS(\"mailers\/\"+fn+\".go.tmpl\", mailerTmpl))\r\n\tg.File(genny.NewFileS(\"templates\/mail\/\"+fn+\".html.tmpl\", mailTmpl))\r\n\tgg.Add(g)\r\n\treturn gg, nil\r\n}","code-length":282,"reference":"\/\/ New mailer generator. It will init the mailers directory if it doesn't already exist","result":"Generate a new generator.","score":[0.0204,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDialer(host string, port int, username, password string) *Dialer {\r\n\treturn &Dialer{\r\n\t\tHost:         host,\r\n\t\tPort:         port,\r\n\t\tUsername:     username,\r\n\t\tPassword:     password,\r\n\t\tSSL:          port == 465,\r\n\t\tTimeout:      10 * time.Second,\r\n\t\tRetryFailure: true,\r\n\t}\r\n}","code-length":111,"reference":"\/\/ NewDialer returns a new SMTP Dialer. The given parameters are used to connect\n\/\/ to the SMTP server.","result":"Create a new dialer.","score":[0.0106,0.146]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *Dialer) Dial() (SendCloser, error) {\r\n\tconn, err := NetDialTimeout(\"tcp\", addr(d.Host, d.Port), d.Timeout)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif d.SSL {\r\n\t\tconn = tlsClient(conn, d.tlsConfig())\r\n\t}\r\n\tc, err := smtpNewClient(conn, d.Host)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif d.Timeout > 0 {\r\n\t\tconn.SetDeadline(time.Now().Add(d.Timeout))\r\n\t}\r\n\tif d.LocalName != \"\" {\r\n\t\tif err := c.Hello(d.LocalName); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\tif !d.SSL && d.StartTLSPolicy != NoStartTLS {\r\n\t\tok, _ := c.Extension(\"STARTTLS\")\r\n\t\tif !ok && d.StartTLSPolicy == MandatoryStartTLS {\r\n\t\t\terr := StartTLSUnsupportedError{\r\n\t\t\t\tPolicy: d.StartTLSPolicy}\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tif ok {\r\n\t\t\tif err := c.StartTLS(d.tlsConfig()); err != nil {\r\n\t\t\t\tc.Close()\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif d.Auth == nil && d.Username != \"\" {\r\n\t\tif ok, auths := c.Extension(\"AUTH\"); ok {\r\n\t\t\tif strings.Contains(auths, \"CRAM-MD5\") {\r\n\t\t\t\td.Auth = smtp.CRAMMD5Auth(d.Username, d.Password)\r\n\t\t\t} else if strings.Contains(auths, \"LOGIN\") &&\r\n\t\t\t\t!strings.Contains(auths, \"PLAIN\") {\r\n\t\t\t\td.Auth = &loginAuth{\r\n\t\t\t\t\tusername: d.Username,\r\n\t\t\t\t\tpassword: d.Password,\r\n\t\t\t\t\thost:     d.Host,\r\n\t\t\t\t}\r\n\t\t\t} else {\r\n\t\t\t\td.Auth = smtp.PlainAuth(\"\", d.Username, d.Password, d.Host)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif d.Auth != nil {\r\n\t\tif err = c.Auth(d.Auth); err != nil {\r\n\t\t\tc.Close()\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\treturn &smtpSender{c, conn, d}, nil\r\n}","code-length":641,"reference":"\/\/ Dial dials and authenticates to an SMTP server. The returned SendCloser\n\/\/ should be closed when done using it.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *Dialer) DialAndSend(m ...*Message) error {\r\n\ts, err := d.Dial()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer s.Close()\r\n\treturn Send(s, m...)\r\n}","code-length":76,"reference":"\/\/ DialAndSend opens a connection to the SMTP server, sends the given emails and\n\/\/ closes the connection.","result":"Dial and send messages.","score":[0.0096,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f Flash) Set(key string, values []string) {\r\n\tf.data[key] = values\r\n}","code-length":38,"reference":"\/\/Set allows to set a list of values into a particular key.","result":"Set flash data.","score":[0,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f Flash) Add(key, value string) {\r\n\tif len(f.data[key]) == 0 {\r\n\t\tf.data[key] = []string{value}\r\n\t\treturn\r\n\t}\r\n\tf.data[key] = append(f.data[key], value)\r\n}","code-length":85,"reference":"\/\/Add adds a flash value for a flash key, if the key already has values the list for that value grows.","result":"Add a new item to the flash.","score":[0.026,0.0765]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f Flash) persist(session *Session) {\r\n\tb, _ := json.Marshal(f.data)\r\n\tsession.Set(flashKey, b)\r\n\tsession.Save()\r\n}","code-length":58,"reference":"\/\/Persist the flash inside the session.","result":"Persist flash data.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newFlash(session *Session) *Flash {\r\n\tresult := &Flash{\r\n\t\tdata: map[string][]string{},\r\n\t}\r\n\tif session.Session != nil {\r\n\t\tif f := session.Get(flashKey); f != nil {\r\n\t\t\tjson.Unmarshal(f.([]byte), &result.data)\r\n\t\t}\r\n\t}\r\n\treturn result\r\n}","code-length":110,"reference":"\/\/newFlash creates a new Flash and loads the session data inside its data.","result":"Create a new flash object.","score":[0.0686,0.3253]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cookies) Get(name string) (string, error) {\r\n\tck, err := c.req.Cookie(name)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn ck.Value, nil\r\n}","code-length":72,"reference":"\/\/ Get returns the value of the cookie with the given name. Returns http.ErrNoCookie if there's no cookie with that name in the request.","result":"Get the value of a cookie.","score":[0.0213,0.1422]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cookies) Set(name, value string, maxAge time.Duration) {\r\n\tck := http.Cookie{\r\n\t\tName:   name,\r\n\t\tValue:  value,\r\n\t\tMaxAge: int(maxAge.Seconds()),\r\n\t}\r\n\thttp.SetCookie(c.res, &ck)\r\n}","code-length":92,"reference":"\/\/ Set a cookie on the response, which will expire after the given duration.","result":"Set cookies.","score":[0.0012,0.0391]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cookies) SetWithExpirationTime(name, value string, expires time.Time) {\r\n\tck := http.Cookie{\r\n\t\tName:    name,\r\n\t\tValue:   value,\r\n\t\tExpires: expires,\r\n\t}\r\n\thttp.SetCookie(c.res, &ck)\r\n}","code-length":88,"reference":"\/\/ SetWithExpirationTime sets a cookie that will expire at a specific time.\n\/\/ Note that the time is determined by the client's browser, so it might not expire at the expected time,\n\/\/ for example if the client has changed the time on their computer.","result":"Set cookies with expiration time.","score":[0.0001,0.0488]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cookies) Delete(name string) {\r\n\tck := http.Cookie{\r\n\t\tName:  name,\r\n\t\tValue: \"v\",\r\n\t\t\r\n\t\t\r\n\t\tExpires: time.Unix(0, 0),\r\n\t}\r\n\thttp.SetCookie(c.res, &ck)\r\n}","code-length":90,"reference":"\/\/ Delete sets a header that tells the browser to remove the cookie with the given name.","result":"Delete a cookie.","score":[0.0046,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMessage() Message {\r\n\treturn Message{\r\n\t\tContext: context.Background(),\r\n\t\tHeaders: map[string]string{},\r\n\t\tData:    render.Data{},\r\n\t\tmoot:    &sync.RWMutex{},\r\n\t}\r\n}","code-length":78,"reference":"\/\/ NewMessage builds a new message.","result":"Create a new message.","score":[0.3991,0.5077]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFromData(data render.Data) Message {\r\n\td := render.Data{}\r\n\tfor k, v := range data {\r\n\t\td[k] = v\r\n\t}\r\n\tm := NewMessage()\r\n\tm.Data = d\r\n\treturn m\r\n}","code-length":79,"reference":"\/\/ NewFromData builds a new message with raw template data given","result":"Create a new message.","score":[0.0785,0.182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(c buffalo.Context) Message {\r\n\tm := NewFromData(c.Data())\r\n\tm.Context = c\r\n\treturn m\r\n}","code-length":50,"reference":"\/\/ New builds a new message with the current buffalo.Context","result":"Create a new message.","score":[0.1008,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (es *EventSource) CloseNotify() <-chan bool {\r\n\tif cn, ok := es.w.(closeNotifier); ok {\r\n\t\treturn cn.CloseNotify()\r\n\t}\r\n\treturn nil\r\n}","code-length":62,"reference":"\/\/ CloseNotify return true across the channel when the connection\n\/\/ in the browser has been severed.","result":"Close the stream.","score":[0.0038,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewEventSource(w http.ResponseWriter) (*EventSource, error) {\r\n\tes := &EventSource{w: w}\r\n\tvar ok bool\r\n\tes.fl, ok = w.(http.Flusher)\r\n\tif !ok {\r\n\t\treturn es, errors.New(\"streaming is not supported\")\r\n\t}\r\n\tes.w.Header().Set(\"Content-Type\", \"text\/event-stream\")\r\n\tes.w.Header().Set(\"Cache-Control\", \"no-cache\")\r\n\tes.w.Header().Set(\"Connection\", \"keep-alive\")\r\n\tes.w.Header().Set(\"Access-Control-Allow-Origin\", \"*\")\r\n\treturn es, nil\r\n}","code-length":180,"reference":"\/\/ NewEventSource returns a new EventSource instance while ensuring\n\/\/ that the http.ResponseWriter is able to handle EventSource messages.\n\/\/ It also makes sure to set the proper response heads.","result":"Create a new event stream.","score":[0.0023,0.0682]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSimpleWithContext(ctx context.Context) *Simple {\r\n\tctx, cancel := context.WithCancel(ctx)\r\n\tl := logrus.New()\r\n\tl.Level = logrus.InfoLevel\r\n\tl.Formatter = &logrus.TextFormatter{}\r\n\treturn &Simple{\r\n\t\tLogger:   l,\r\n\t\tctx:      ctx,\r\n\t\tcancel:   cancel,\r\n\t\thandlers: map[string]Handler{},\r\n\t\tmoot:     &sync.Mutex{},\r\n\t}\r\n}","code-length":138,"reference":"\/\/ NewSimpleWithContext creates a basic implementation of the Worker interface\n\/\/ that is backed using just the standard library and goroutines.","result":"Create a new context.","score":[0.0046,0.0972]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *Simple) Register(name string, h Handler) error {\r\n\tw.moot.Lock()\r\n\tdefer w.moot.Unlock()\r\n\tif _, ok := w.handlers[name]; ok {\r\n\t\treturn fmt.Errorf(\"handler already mapped for name %s\", name)\r\n\t}\r\n\tw.handlers[name] = h\r\n\treturn nil\r\n}","code-length":104,"reference":"\/\/ Register Handler with the worker","result":"Register handlers.","score":[0.0677,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *Simple) Start(ctx context.Context) error {\r\n\tw.Logger.Info(\"Starting Simple Background Worker\")\r\n\tw.ctx, w.cancel = context.WithCancel(ctx)\r\n\treturn nil\r\n}","code-length":64,"reference":"\/\/ Start the worker","result":"Start the background worker.","score":[0.4518,0.4688]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w Simple) Stop() error {\r\n\tw.Logger.Info(\"Stopping Simple Background Worker\")\r\n\tw.cancel()\r\n\treturn nil\r\n}","code-length":47,"reference":"\/\/ Stop the worker","result":"Stop the background worker.","score":[0.4518,0.4688]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w Simple) Perform(job Job) error {\r\n\tw.Logger.Debugf(\"Performing job %s\", job)\r\n\tif job.Handler == \"\" {\r\n\t\terr := fmt.Errorf(\"no handler name given for %s\", job)\r\n\t\tw.Logger.Error(err)\r\n\t\treturn err\r\n\t}\r\n\tw.moot.Lock()\r\n\tdefer w.moot.Unlock()\r\n\tif h, ok := w.handlers[job.Handler]; ok {\r\n\t\tgo func() {\r\n\t\t\terr := safe.RunE(func() error {\r\n\t\t\t\treturn h(job.Args)\r\n\t\t\t})\r\n\t\t\tif err != nil {\r\n\t\t\t\tw.Logger.Error(err)\r\n\t\t\t}\r\n\t\t\tw.Logger.Debugf(\"Completed job %s\", job)\r\n\t\t}()\r\n\t\treturn nil\r\n\t}\r\n\terr := fmt.Errorf(\"no handler mapped for name %s\", job.Handler)\r\n\tw.Logger.Error(err)\r\n\treturn err\r\n}","code-length":267,"reference":"\/\/ Perform a job as soon as possibly using a goroutine.","result":"Perform a job.","score":[0.0401,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w Simple) PerformAt(job Job, t time.Time) error {\r\n\treturn w.PerformIn(job, time.Until(t))\r\n}","code-length":47,"reference":"\/\/ PerformAt performs a job at a particular time using a goroutine.","result":"Create a new function.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w Simple) PerformIn(job Job, d time.Duration) error {\r\n\tgo func() {\r\n\t\tselect {\r\n\t\tcase <-time.After(d):\r\n\t\t\tw.Perform(job)\r\n\t\tcase <-w.ctx.Done():\r\n\t\t\tw.cancel()\r\n\t\t}\r\n\t}()\r\n\treturn nil\r\n}","code-length":100,"reference":"\/\/ PerformIn performs a job after waiting for a specified amount\n\/\/ using a goroutine.","result":"Create a job in the job queue.","score":[0.0728,0.0704]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ri RouteInfo) String() string {\r\n\tb, _ := json.MarshalIndent(ri, \"\", \"  \")\r\n\treturn string(b)\r\n}","code-length":48,"reference":"\/\/ String returns a JSON representation of the RouteInfo","result":"Generate the route info string.","score":[0.108,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ri *RouteInfo) Alias(aliases ...string) *RouteInfo {\r\n\tri.Aliases = append(ri.Aliases, aliases...)\r\n\tfor _, a := range aliases {\r\n\t\tri.App.router.Handle(a, ri).Methods(ri.Method)\r\n\t}\r\n\treturn ri\r\n}","code-length":86,"reference":"\/\/ Alias path patterns to the this route. This is not the\n\/\/ same as a redirect.","result":"Set the alias on the route info.","score":[0.046,0.0938]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ri *RouteInfo) Name(name string) *RouteInfo {\r\n\trouteIndex := -1\r\n\tfor index, route := range ri.App.Routes() {\r\n\t\tif route.Path == ri.Path && route.Method == ri.Method {\r\n\t\t\trouteIndex = index\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tname = flect.Camelize(name)\r\n\tif !strings.HasSuffix(name, \"Path\") {\r\n\t\tname = name + \"Path\"\r\n\t}\r\n\tri.PathName = name\r\n\tif routeIndex != -1 {\r\n\t\tri.App.Routes()[routeIndex] = reflect.ValueOf(ri).Interface().(*RouteInfo)\r\n\t}\r\n\treturn ri\r\n}","code-length":195,"reference":"\/\/ Name allows users to set custom names for the routes.","result":"Set the name of the route .","score":[0.0912,0.1415]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ri *RouteInfo) BuildPathHelper() RouteHelperFunc {\r\n\tcRoute := ri\r\n\treturn func(opts map[string]interface{}) (template.HTML, error) {\r\n\t\tpairs := []string{}\r\n\t\tfor k, v := range opts {\r\n\t\t\tpairs = append(pairs, k)\r\n\t\t\tpairs = append(pairs, fmt.Sprintf(\"%v\", v))\r\n\t\t}\r\n\t\turl, err := cRoute.MuxRoute.URL(pairs...)\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", errors.Wrapf(err, \"missing parameters for %v\", cRoute.Path)\r\n\t\t}\r\n\t\tresult := url.Path\r\n\t\tresult = addExtraParamsTo(result, opts)\r\n\t\treturn template.HTML(result), nil\r\n\t}\r\n}","code-length":209,"reference":"\/\/ BuildPathHelper Builds a routeHelperfunc for a particular RouteInfo","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Generator, error) {\r\n\tg := genny.New()\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn g, err\r\n\t}\r\n\tg.Transformer(genny.Replace(\"-no-pop\", \"\"))\r\n\tg.Transformer(genny.Dot())\r\n\tbox := packr.New(\"buffalo:genny:ci\", \"..\/ci\/templates\")\r\n\tvar fname string\r\n\tswitch opts.Provider {\r\n\tcase \"travis\", \"travis-ci\":\r\n\t\tfname = \"-dot-travis.yml.tmpl\"\r\n\tcase \"gitlab\", \"gitlab-ci\":\r\n\t\tif opts.App.WithPop {\r\n\t\t\tfname = \"-dot-gitlab-ci.yml.tmpl\"\r\n\t\t} else {\r\n\t\t\tfname = \"-dot-gitlab-ci-no-pop.yml.tmpl\"\r\n\t\t}\r\n\tdefault:\r\n\t\treturn g, fmt.Errorf(\"could not find a template for %s\", opts.Provider)\r\n\t}\r\n\tf, err := box.FindString(fname)\r\n\tif err != nil {\r\n\t\treturn g, err\r\n\t}\r\n\tg.File(genny.NewFileS(fname, f))\r\n\tdata := map[string]interface{}{\r\n\t\t\"opts\": opts,\r\n\t}\r\n\tif opts.DBType == \"postgres\" {\r\n\t\tdata[\"testDbUrl\"] = \"postgres:\r\n\t} else if opts.DBType == \"mysql\" {\r\n\t\tdata[\"testDbUrl\"] = \"mysql:\r\n\t} else {\r\n\t\tdata[\"testDbUrl\"] = \"\"\r\n\t}\r\n\thelpers := template.FuncMap{}\r\n\tt := gogen.TemplateTransformer(data, helpers)\r\n\tg.Transformer(t)\r\n\treturn g, nil\r\n}","code-length":477,"reference":"\/\/ New generator for adding travis or gitlab","result":"Generate the generator.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Generator, error) {\r\n\tg := genny.New()\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn g, err\r\n\t}\r\n\tg.RunFn(construct(opts))\r\n\treturn g, nil\r\n}","code-length":84,"reference":"\/\/ New returns a new generator for build actions on a Buffalo app","result":"Create a new generator.","score":[0.0476,0.0826]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterCustomDecoder(fn CustomTypeDecoder, types []interface{}, fields []interface{}) {\r\n\trawFunc := (func([]string) (interface{}, error))(fn)\r\n\tdecoder.RegisterCustomType(rawFunc, types, fields)\r\n}","code-length":70,"reference":"\/\/ RegisterCustomDecoder allows to define custom type decoders.","result":"Register custom type decoders.","score":[0.2421,0.3874]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MiddlewareStack) Replace(mw1 MiddlewareFunc, mw2 MiddlewareFunc) {\r\n\tm1k := funcKey(mw1)\r\n\tstack := []MiddlewareFunc{}\r\n\tfor _, mw := range ms.stack {\r\n\t\tif funcKey(mw) == m1k {\r\n\t\t\tstack = append(stack, mw2)\r\n\t\t} else {\r\n\t\t\tstack = append(stack, mw)\r\n\t\t}\r\n\t}\r\n\tms.stack = stack\r\n}","code-length":134,"reference":"\/\/ Replace a piece of middleware with another piece of middleware. Great for\n\/\/ testing.","result":"Replace middleware functions in the stack.","score":[0.0512,0.0709]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *App) Routes() RouteList {\r\n\tif a.root != nil {\r\n\t\treturn a.root.routes\r\n\t}\r\n\treturn a.routes\r\n}","code-length":54,"reference":"\/\/ Routes returns a list of all of the routes defined\n\/\/ in this application.","result":"Get the routes.","score":[0.0075,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WrapBuffaloHandler(h Handler) http.Handler {\r\n\ta := New(Options{})\r\n\t\r\n\t\r\n\t\r\n\tri := a.GET(\"\/\", h)\r\n\treturn ri\r\n}","code-length":63,"reference":"\/\/ WrapBuffaloHandler wraps a buffalo.Handler to\n\/\/ standard http.Handler","result":"Wrap handler .","score":[0,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PackageJSONCheck(r *Runner) error {\r\n\tfmt.Println(\"~~~ Checking package.json ~~~\")\r\n\tif !r.App.WithWebpack {\r\n\t\treturn nil\r\n\t}\r\n\tbox := webpack.Templates\r\n\tf, err := box.FindString(\"package.json.tmpl\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ttmpl, err := template.New(\"package.json\").Parse(f)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tbb := &bytes.Buffer{}\r\n\terr = tmpl.Execute(bb, map[string]interface{}{\r\n\t\t\"opts\": &webpack.Options{\r\n\t\t\tApp: r.App,\r\n\t\t},\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tb, err := ioutil.ReadFile(\"package.json\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif string(b) == bb.String() {\r\n\t\treturn nil\r\n\t}\r\n\tif !ask(\"Your package.json file is different from the latest Buffalo template.\\nWould you like to REPLACE yours with the latest template?\") {\r\n\t\tfmt.Println(\"\\tskipping package.json\")\r\n\t\treturn nil\r\n\t}\r\n\tpf, err := os.Create(\"package.json\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t_, err = pf.Write(bb.Bytes())\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = pf.Close()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tos.RemoveAll(filepath.Join(r.App.Root, \"node_modules\"))\r\n\tvar cmd *exec.Cmd\r\n\tif r.App.WithYarn {\r\n\t\tcmd = exec.Command(\"yarnpkg\", \"install\")\r\n\t} else {\r\n\t\tcmd = exec.Command(\"npm\", \"install\")\r\n\t}\r\n\tcmd.Stdin = os.Stdin\r\n\tcmd.Stdout = os.Stdout\r\n\tcmd.Stderr = os.Stderr\r\n\treturn cmd.Run()\r\n}","code-length":564,"reference":"\/\/ PackageJSONCheck will compare the current default Buffalo\n\/\/ package.json against the applications package.json. If they are\n\/\/ different you have the option to overwrite the existing package.json\n\/\/ file with the new one.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c ImportConverter) match(importpath string) (string, bool) {\r\n\tfor key, value := range c.Data {\r\n\t\tif !strings.HasPrefix(importpath, key) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tresult := strings.Replace(importpath, key, value, 1)\r\n\t\treturn result, true\r\n\t}\r\n\treturn importpath, false\r\n}","code-length":109,"reference":"\/\/ match takes an import path and replacement map.","result":"Match the importpath.","score":[0,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Send(s Sender, msg ...*Message) error {\r\n\tfor i, m := range msg {\r\n\t\tif err := send(s, m); err != nil {\r\n\t\t\treturn &SendError{Cause: err, Index: uint(i)}\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":86,"reference":"\/\/ Send sends emails using the given Sender.","result":"Send messages to the sender.","score":[0.1568,0.1948]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (opts Options) Last(n name.Ident) bool {\r\n\treturn opts.Parts[len(opts.Parts)-1].String() == n.String()\r\n}","code-length":49,"reference":"\/\/ Last checks if the name is the last of the parts","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *App) Stop(err error) error {\r\n\ta.cancel()\r\n\tif err != nil && errors.Cause(err) != context.Canceled {\r\n\t\ta.Logger.Error(err)\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":78,"reference":"\/\/ Stop the application and attempt to gracefully shutdown","result":"Stop the app.","score":[0.0781,0.2232]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DepEnsure(r *Runner) error {\r\n\tif r.App.WithPop {\r\n\t\tupkg = append(upkg, \"github.com\/gobuffalo\/fizz\", \"github.com\/gobuffalo\/pop\")\r\n\t}\r\n\tif !r.App.WithDep {\r\n\t\tfmt.Println(\"~~~ Running go get ~~~\")\r\n\t\treturn modGetUpdate(r)\r\n\t}\r\n\tfmt.Println(\"~~~ Running dep ensure ~~~\")\r\n\treturn runDepEnsure(r)\r\n}","code-length":146,"reference":"\/\/ DepEnsure runs `dep ensure -v` or `go get -u` depending on app tooling\n\/\/ to make sure that any newly changed imports are added to dep or installed.","result":"Ensure dependencies are present.","score":[0.0006,0.0566]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b BuildInfo) String() string {\r\n\treturn fmt.Sprintf(\"%s (%s)\", b.Version, b.Time)\r\n}","code-length":44,"reference":"\/\/ String implements fmt.String","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Generator, error) {\r\n\tg := genny.New()\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn g, err\r\n\t}\r\n\tif !opts.SkipTemplates {\r\n\t\tcore := packr.New(\"github.com\/gobuffalo\/buffalo\/genny\/resource\/templates\/core\", \"..\/resource\/templates\/core\")\r\n\t\tif err := g.Box(core); err != nil {\r\n\t\t\treturn g, err\r\n\t\t}\r\n\t}\r\n\tvar abox packd.Box\r\n\tif opts.SkipModel {\r\n\t\tabox = packr.New(\"github.com\/gobuffalo\/buffalo\/genny\/resource\/templates\/standard\", \"..\/resource\/templates\/standard\")\r\n\t} else {\r\n\t\tabox = packr.New(\"github.com\/gobuffalo\/buffalo\/genny\/resource\/templates\/use_model\", \"..\/resource\/templates\/use_model\")\r\n\t}\r\n\tif err := g.Box(abox); err != nil {\r\n\t\treturn g, err\r\n\t}\r\n\tpres := presenter{\r\n\t\tApp:   opts.App,\r\n\t\tName:  name.New(opts.Name),\r\n\t\tModel: name.New(opts.Model),\r\n\t\tAttrs: opts.Attrs,\r\n\t}\r\n\tx := pres.Name.Resource().File().String()\r\n\tfolder := pres.Name.Folder().Pluralize().String()\r\n\tg.Transformer(genny.Replace(\"resource-name\", x))\r\n\tg.Transformer(genny.Replace(\"resource-use_model\", x))\r\n\tg.Transformer(genny.Replace(\"folder-name\", folder))\r\n\tdata := map[string]interface{}{\r\n\t\t\"opts\":    pres,\r\n\t\t\"actions\": actions(opts),\r\n\t\t\"folder\":  folder,\r\n\t}\r\n\thelpers := template.FuncMap{\r\n\t\t\"camelize\": func(s string) string {\r\n\t\t\treturn flect.Camelize(s)\r\n\t\t},\r\n\t}\r\n\tg.Transformer(gogen.TemplateTransformer(data, helpers))\r\n\tg.RunFn(installPop(opts))\r\n\tg.RunFn(addResource(pres))\r\n\treturn g, nil\r\n}","code-length":588,"reference":"\/\/ New resource generator","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) AddBody(r render.Renderer, data render.Data) error {\r\n\tbuf := bytes.NewBuffer([]byte{})\r\n\terr := r.Render(buf, m.merge(data))\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tm.Bodies = append(m.Bodies, Body{\r\n\t\tContent:     buf.String(),\r\n\t\tContentType: r.ContentType(),\r\n\t})\r\n\treturn nil\r\n}","code-length":129,"reference":"\/\/ AddBody the message by receiving a renderer and rendering data, first message will be\n\/\/ used as the main message Body rest of them will be passed as alternative bodies on the\n\/\/ email message","result":"Add a body to a message.","score":[0.0013,0.0303]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) AddBodies(data render.Data, renderers ...render.Renderer) error {\r\n\tfor _, r := range renderers {\r\n\t\terr := m.AddBody(r, data)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":90,"reference":"\/\/ AddBodies Allows to add multiple bodies to the message, it returns errors that\n\/\/ could happen in the rendering.","result":"Add a body.","score":[0,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) AddAttachment(name, contentType string, r io.Reader) error {\r\n\tm.Attachments = append(m.Attachments, Attachment{\r\n\t\tName:        name,\r\n\t\tContentType: contentType,\r\n\t\tReader:      r,\r\n\t\tEmbedded:    false,\r\n\t})\r\n\treturn nil\r\n}","code-length":92,"reference":"\/\/AddAttachment adds the attachment to the list of attachments the Message has.","result":"Add attachments to a message.","score":[0.0705,0.1327]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) AddEmbedded(name string, r io.Reader) error {\r\n\tm.Attachments = append(m.Attachments, Attachment{\r\n\t\tName:     name,\r\n\t\tReader:   r,\r\n\t\tEmbedded: true,\r\n\t})\r\n\treturn nil\r\n}","code-length":81,"reference":"\/\/AddEmbedded adds the attachment to the list of attachments\n\/\/ the Message has and uses inline instead of attachement property.","result":"Add embedded attachments to a message.","score":[0.0223,0.0806]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) SetHeader(field, value string) {\r\n\tm.Headers[field] = value\r\n}","code-length":38,"reference":"\/\/ SetHeader sets the heder field and value for the message","result":"Set headers in the message.","score":[0.0724,0.0962]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Group, error) {\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tgg, err := core.New(opts.Options)\r\n\tif err != nil {\r\n\t\treturn gg, err\r\n\t}\r\n\tg := genny.New()\r\n\tg.Transformer(genny.Dot())\r\n\tdata := map[string]interface{}{\r\n\t\t\"opts\": opts,\r\n\t}\r\n\thelpers := template.FuncMap{}\r\n\tt := gogen.TemplateTransformer(data, helpers)\r\n\tg.Transformer(t)\r\n\tg.Box(packr.New(\"buffalo:genny:newapp:web\", \"..\/web\/templates\"))\r\n\tgg.Add(g)\r\n\tif opts.Webpack != nil {\r\n\t\t\r\n\t\tg, err = webpack.New(opts.Webpack)\r\n\t\tif err != nil {\r\n\t\t\treturn gg, err\r\n\t\t}\r\n\t\tgg.Add(g)\r\n\t}\r\n\tif opts.Standard != nil {\r\n\t\t\r\n\t\tg, err = standard.New(opts.Standard)\r\n\t\tif err != nil {\r\n\t\t\treturn gg, err\r\n\t\t}\r\n\t\tgg.Add(g)\r\n\t}\r\n\treturn gg, nil\r\n}","code-length":350,"reference":"\/\/ New generator for creating a Buffalo Web application","result":"Create a new app.","score":[0.0915,0.3007]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Generator, error) {\r\n\tg := genny.New()\r\n\tg.Box(packr.New(\"buffalo:genny:assets:standard\", \"..\/standard\/templates\"))\r\n\tdata := map[string]interface{}{}\r\n\th := template.FuncMap{}\r\n\tt := gogen.TemplateTransformer(data, h)\r\n\tg.Transformer(t)\r\n\tg.RunFn(func(r *genny.Runner) error {\r\n\t\tf, err := r.FindFile(\"templates\/application.html\")\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\ts := strings.Replace(f.String(), \"<\/title>\", \"<\/title>\\n\"+bs4, 1)\r\n\t\treturn r.File(genny.NewFileS(f.Name(), s))\r\n\t})\r\n\treturn g, nil\r\n}","code-length":235,"reference":"\/\/ New generator for creating basic asset files","result":"Generate the generator.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Generator, error) {\r\n\tg := genny.New()\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn g, errors.WithStack(err)\r\n\t}\r\n\tg.RunFn(appDetails(opts))\r\n\tcBox := packr.Folder(filepath.Join(opts.App.Root, \"config\"))\r\n\tg.RunFn(configs(opts, cBox))\r\n\taBox := packr.Folder(opts.App.Root)\r\n\tg.RunFn(pkgChecks(opts, aBox))\r\n\treturn g, nil\r\n}","code-length":164,"reference":"\/\/ New returns a generator that performs buffalo\n\/\/ related rx checks","result":"Generate the generator.","score":[0,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Cleanup(opts *Options) genny.RunFn {\r\n\treturn func(r *genny.Runner) error {\r\n\t\tdefer os.RemoveAll(filepath.Join(opts.Root, \"a\"))\r\n\t\tif err := jam.Clean(); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tvar err error\r\n\t\topts.rollback.Range(func(k, v interface{}) bool {\r\n\t\t\tf := genny.NewFileS(k.(string), v.(string))\r\n\t\t\tr.Logger.Debugf(\"Rollback: %s\", f.Name())\r\n\t\t\tif err = r.File(f); err != nil {\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\t\tr.Disk.Remove(f.Name())\r\n\t\t\treturn true\r\n\t\t})\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tfor _, f := range r.Disk.Files() {\r\n\t\t\tif err := r.Disk.Delete(f.Name()); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\tif envy.Mods() {\r\n\t\t\tif err := r.Exec(exec.Command(genny.GoBin(), \"mod\", \"tidy\")); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n}","code-length":356,"reference":"\/\/ Cleanup all of the generated files","result":"Cleanup the temporary files.","score":[0.1795,0.1493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MDTemplateEngine(input string, data map[string]interface{}, helpers map[string]interface{}) (string, error) {\r\n\tif ct, ok := data[\"contentType\"].(string); ok && ct == \"text\/plain\" {\r\n\t\treturn plush.BuffaloRenderer(input, data, helpers)\r\n\t}\r\n\tsource := github_flavored_markdown.Markdown([]byte(input))\r\n\tsource = []byte(html.UnescapeString(string(source)))\r\n\treturn plush.BuffaloRenderer(string(source), data, helpers)\r\n}","code-length":149,"reference":"\/\/ MDTemplateEngine runs the input through github flavored markdown before sending it to the Plush engine.","result":"Render markdown.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Update(fg FileGetter, kc corev1.ConfigMapInterface, name, namespace string, updates []ConfigMapUpdate, logger *logrus.Entry) error {\r\n\tcm, getErr := kc.Get(name, metav1.GetOptions{})\r\n\tisNotFound := errors.IsNotFound(getErr)\r\n\tif getErr != nil && !isNotFound {\r\n\t\treturn fmt.Errorf(\"failed to fetch current state of configmap: %v\", getErr)\r\n\t}\r\n\tif cm == nil || isNotFound {\r\n\t\tcm = &coreapi.ConfigMap{\r\n\t\t\tObjectMeta: metav1.ObjectMeta{\r\n\t\t\t\tName:      name,\r\n\t\t\t\tNamespace: namespace,\r\n\t\t\t},\r\n\t\t}\r\n\t}\r\n\tif cm.Data == nil {\r\n\t\tcm.Data = map[string]string{}\r\n\t}\r\n\tif cm.BinaryData == nil {\r\n\t\tcm.BinaryData = map[string][]byte{}\r\n\t}\r\n\tfor _, upd := range updates {\r\n\t\tif upd.Filename == \"\" {\r\n\t\t\tlogger.WithField(\"key\", upd.Key).Debug(\"Deleting key.\")\r\n\t\t\tdelete(cm.Data, upd.Key)\r\n\t\t\tdelete(cm.BinaryData, upd.Key)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tcontent, err := fg.GetFile(upd.Filename)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"get file err: %v\", err)\r\n\t\t}\r\n\t\tlogger.WithFields(logrus.Fields{\"key\": upd.Key, \"filename\": upd.Filename}).Debug(\"Populating key.\")\r\n\t\tvalue := content\r\n\t\tif upd.GZIP {\r\n\t\t\tbuff := bytes.NewBuffer([]byte{})\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tz := gzip.NewWriter(buff)\r\n\t\t\tif _, err := z.Write(content); err != nil {\r\n\t\t\t\tlogger.WithError(err).Error(\"failed to gzip content, falling back to raw\")\r\n\t\t\t} else {\r\n\t\t\t\tif err := z.Close(); err != nil {\r\n\t\t\t\t\tlogger.WithError(err).Error(\"failed to flush gzipped content (!?), falling back to raw\")\r\n\t\t\t\t} else {\r\n\t\t\t\t\tvalue = buff.Bytes()\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\tif utf8.ValidString(string(value)) {\r\n\t\t\tdelete(cm.BinaryData, upd.Key)\r\n\t\t\tcm.Data[upd.Key] = string(value)\r\n\t\t} else {\r\n\t\t\tdelete(cm.Data, upd.Key)\r\n\t\t\tcm.BinaryData[upd.Key] = value\r\n\t\t}\r\n\t}\r\n\tvar updateErr error\r\n\tvar verb string\r\n\tif getErr != nil && isNotFound {\r\n\t\tverb = \"create\"\r\n\t\t_, updateErr = kc.Create(cm)\r\n\t} else {\r\n\t\tverb = \"update\"\r\n\t\t_, updateErr = kc.Update(cm)\r\n\t}\r\n\tif updateErr != nil {\r\n\t\treturn fmt.Errorf(\"%s config map err: %v\", verb, updateErr)\r\n\t}\r\n\treturn nil\r\n}","code-length":804,"reference":"\/\/ Update updates the configmap with the data from the identified files","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FilterChanges(cfg plugins.ConfigUpdater, changes []github.PullRequestChange, log *logrus.Entry) map[ConfigMapID][]ConfigMapUpdate {\r\n\ttoUpdate := map[ConfigMapID][]ConfigMapUpdate{}\r\n\tfor _, change := range changes {\r\n\t\tvar cm plugins.ConfigMapSpec\r\n\t\tfound := false\r\n\t\tfor key, configMap := range cfg.Maps {\r\n\t\t\tvar matchErr error\r\n\t\t\tfound, matchErr = zglob.Match(key, change.Filename)\r\n\t\t\tif matchErr != nil {\r\n\t\t\t\t\r\n\t\t\t\tlog.WithError(matchErr).Info(\"key matching error\")\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tif found {\r\n\t\t\t\tcm = configMap\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif !found {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tfor _, ns := range append(cm.Namespaces) {\r\n\t\t\tid := ConfigMapID{Name: cm.Name, Namespace: ns}\r\n\t\t\tkey := cm.Key\r\n\t\t\tif key == \"\" {\r\n\t\t\t\tkey = path.Base(change.Filename)\r\n\t\t\t\t\r\n\t\t\t\tif change.Status == github.PullRequestFileRenamed {\r\n\t\t\t\t\toldKey := path.Base(change.PreviousFilename)\r\n\t\t\t\t\t\r\n\t\t\t\t\t\r\n\t\t\t\t\ttoUpdate[id] = append(toUpdate[id], ConfigMapUpdate{Key: oldKey})\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tif change.Status == github.PullRequestFileRemoved {\r\n\t\t\t\ttoUpdate[id] = append(toUpdate[id], ConfigMapUpdate{Key: key})\r\n\t\t\t} else {\r\n\t\t\t\tgzip := cfg.GZIP\r\n\t\t\t\tif cm.GZIP != nil {\r\n\t\t\t\t\tgzip = *cm.GZIP\r\n\t\t\t\t}\r\n\t\t\t\ttoUpdate[id] = append(toUpdate[id], ConfigMapUpdate{Key: key, Filename: change.Filename, GZIP: gzip})\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn toUpdate\r\n}","code-length":502,"reference":"\/\/ FilterChanges determines which of the changes are relevant for config updating, returning mapping of\n\/\/ config map to key to filename to update that key from.","result":"Filter changes .","score":[0.0001,0.0203]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getLabelsFromREMatches(matches [][]string) (labels []string) {\r\n\tfor _, match := range matches {\r\n\t\tfor _, label := range strings.Split(match[0], \" \")[1:] {\r\n\t\t\tlabel = strings.ToLower(match[1] + \"\/\" + strings.TrimSpace(label))\r\n\t\t\tlabels = append(labels, label)\r\n\t\t}\r\n\t}\r\n\treturn\r\n}","code-length":115,"reference":"\/\/ Get Labels from Regexp matches","result":"Get labels from REMatches.","score":[0.2304,0.5077]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getLabelsFromGenericMatches(matches [][]string, additionalLabels []string) []string {\r\n\tif len(additionalLabels) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\tvar labels []string\r\n\tfor _, match := range matches {\r\n\t\tparts := strings.Split(match[0], \" \")\r\n\t\tif ((parts[0] != \"\/label\") && (parts[0] != \"\/remove-label\")) || len(parts) != 2 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tfor _, l := range additionalLabels {\r\n\t\t\tif l == parts[1] {\r\n\t\t\t\tlabels = append(labels, parts[1])\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn labels\r\n}","code-length":191,"reference":"\/\/ getLabelsFromGenericMatches returns label matches with extra labels if those\n\/\/ have been configured in the plugin config.","result":"Get labels from generic matches.","score":[0.0178,0.0599]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ca *Agent) Start(prowConfig, jobConfig string) error {\r\n\tc, err := Load(prowConfig, jobConfig)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tca.Set(c)\r\n\tgo func() {\r\n\t\tvar lastModTime time.Time\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tskips := 0\r\n\t\tfor range time.Tick(1 * time.Second) {\r\n\t\t\tif skips < 600 {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tprowStat, err := os.Stat(prowConfig)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tlogrus.WithField(\"prowConfig\", prowConfig).WithError(err).Error(\"Error loading prow config.\")\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\trecentModTime := prowStat.ModTime()\r\n\t\t\t\t\r\n\t\t\t\tif jobConfig != \"\" {\r\n\t\t\t\t\tjobConfigStat, err := os.Stat(jobConfig)\r\n\t\t\t\t\tif err != nil {\r\n\t\t\t\t\t\tlogrus.WithField(\"jobConfig\", jobConfig).WithError(err).Error(\"Error loading job configs.\")\r\n\t\t\t\t\t\tcontinue\r\n\t\t\t\t\t}\r\n\t\t\t\t\tif jobConfigStat.ModTime().After(recentModTime) {\r\n\t\t\t\t\t\trecentModTime = jobConfigStat.ModTime()\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t\tif !recentModTime.After(lastModTime) {\r\n\t\t\t\t\tskips++\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\tlastModTime = recentModTime\r\n\t\t\t}\r\n\t\t\tif c, err := Load(prowConfig, jobConfig); err != nil {\r\n\t\t\t\tlogrus.WithField(\"prowConfig\", prowConfig).\r\n\t\t\t\t\tWithField(\"jobConfig\", jobConfig).\r\n\t\t\t\t\tWithError(err).Error(\"Error loading config.\")\r\n\t\t\t} else {\r\n\t\t\t\tskips = 0\r\n\t\t\t\tca.Set(c)\r\n\t\t\t}\r\n\t\t}\r\n\t}()\r\n\treturn nil\r\n}","code-length":507,"reference":"\/\/ Start will begin polling the config file at the path. If the first load\n\/\/ fails, Start will return the error and abort. Future load failures will log\n\/\/ the failure message but continue attempting to load.","result":"Start the agent.","score":[0.0,0.029]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ca *Agent) Subscribe(subscription DeltaChan) {\r\n\tca.mut.Lock()\r\n\tdefer ca.mut.Unlock()\r\n\tca.subscriptions = append(ca.subscriptions, subscription)\r\n}","code-length":59,"reference":"\/\/ Subscribe registers the channel for messages on config reload.\n\/\/ The caller can expect a copy of the previous and current config\n\/\/ to be sent down the subscribed channel when a new configuration\n\/\/ is loaded.","result":"Subscribe to events.","score":[0.0,0.029]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ca *Agent) Config() *Config {\r\n\tca.mut.RLock()\r\n\tdefer ca.mut.RUnlock()\r\n\treturn ca.c\r\n}","code-length":51,"reference":"\/\/ Config returns the latest config. Do not modify the config.","result":"Get the config from the agent.","score":[0.0998,0.1429]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ca *Agent) Set(c *Config) {\r\n\tca.mut.Lock()\r\n\tdefer ca.mut.Unlock()\r\n\tvar oldConfig Config\r\n\tif ca.c != nil {\r\n\t\toldConfig = *ca.c\r\n\t}\r\n\tdelta := Delta{oldConfig, *c}\r\n\tca.c = c\r\n\tfor _, subscription := range ca.subscriptions {\r\n\t\tgo func(sub DeltaChan) {\r\n\t\t\tend := time.NewTimer(time.Minute)\r\n\t\t\tselect {\r\n\t\t\tcase sub <- delta:\r\n\t\t\tcase <-end.C:\r\n\t\t\t}\r\n\t\t\tif !end.Stop() {\r\n\t\t\t\t<-end.C\r\n\t\t\t}\r\n\t\t}(subscription)\r\n\t}\r\n}","code-length":204,"reference":"\/\/ Set sets the config. Useful for testing.","result":"Set the agent.","score":[0.0917,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) IsMember(org, user string) (bool, error) {\r\n\tfor _, m := range f.OrgMembers[org] {\r\n\t\tif m == user {\r\n\t\t\treturn true, nil\r\n\t\t}\r\n\t}\r\n\treturn false, nil\r\n}","code-length":83,"reference":"\/\/ IsMember returns true if user is in org.","result":"Test if the user is a member of an org.","score":[0.1826,0.3468]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ListIssueComments(owner, repo string, number int) ([]github.IssueComment, error) {\r\n\treturn append([]github.IssueComment{}, f.IssueComments[number]...), nil\r\n}","code-length":64,"reference":"\/\/ ListIssueComments returns comments.","result":"List comments in a repo.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ListPullRequestComments(owner, repo string, number int) ([]github.ReviewComment, error) {\r\n\treturn append([]github.ReviewComment{}, f.PullRequestComments[number]...), nil\r\n}","code-length":64,"reference":"\/\/ ListPullRequestComments returns review comments.","result":"List comments in a github issue.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ListReviews(owner, repo string, number int) ([]github.Review, error) {\r\n\treturn append([]github.Review{}, f.Reviews[number]...), nil\r\n}","code-length":62,"reference":"\/\/ ListReviews returns reviews.","result":"Test if the file is not empty.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ListIssueEvents(owner, repo string, number int) ([]github.ListedIssueEvent, error) {\r\n\treturn append([]github.ListedIssueEvent{}, f.IssueEvents[number]...), nil\r\n}","code-length":68,"reference":"\/\/ ListIssueEvents returns issue events","result":"List all issues in a repo.","score":[0,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) CreateComment(owner, repo string, number int, comment string) error {\r\n\tf.IssueCommentsAdded = append(f.IssueCommentsAdded, fmt.Sprintf(\"%s\/%s#%d:%s\", owner, repo, number, comment))\r\n\tf.IssueComments[number] = append(f.IssueComments[number], github.IssueComment{\r\n\t\tID:   f.IssueCommentID,\r\n\t\tBody: comment,\r\n\t\tUser: github.User{Login: botName},\r\n\t})\r\n\tf.IssueCommentID++\r\n\treturn nil\r\n}","code-length":153,"reference":"\/\/ CreateComment adds a comment to a PR","result":"Create a comment in the repo.","score":[0.1956,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) CreateReview(org, repo string, number int, r github.DraftReview) error {\r\n\tf.Reviews[number] = append(f.Reviews[number], github.Review{\r\n\t\tID:   f.ReviewID,\r\n\t\tUser: github.User{Login: botName},\r\n\t\tBody: r.Body,\r\n\t})\r\n\tf.ReviewID++\r\n\treturn nil\r\n}","code-length":116,"reference":"\/\/ CreateReview adds a review to a PR","result":"Create a review.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) CreateCommentReaction(org, repo string, ID int, reaction string) error {\r\n\tf.CommentReactionsAdded = append(f.CommentReactionsAdded, fmt.Sprintf(\"%s\/%s#%d:%s\", org, repo, ID, reaction))\r\n\treturn nil\r\n}","code-length":82,"reference":"\/\/ CreateCommentReaction adds emoji to a comment.","result":"Create comment reactions.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) CreateIssueReaction(org, repo string, ID int, reaction string) error {\r\n\tf.IssueReactionsAdded = append(f.IssueReactionsAdded, fmt.Sprintf(\"%s\/%s#%d:%s\", org, repo, ID, reaction))\r\n\treturn nil\r\n}","code-length":82,"reference":"\/\/ CreateIssueReaction adds an emoji to an issue.","result":"Create issue reactions.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) DeleteComment(owner, repo string, ID int) error {\r\n\tf.IssueCommentsDeleted = append(f.IssueCommentsDeleted, fmt.Sprintf(\"%s\/%s#%d\", owner, repo, ID))\r\n\tfor num, ics := range f.IssueComments {\r\n\t\tfor i, ic := range ics {\r\n\t\t\tif ic.ID == ID {\r\n\t\t\t\tf.IssueComments[num] = append(ics[:i], ics[i+1:]...)\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn fmt.Errorf(\"could not find issue comment %d\", ID)\r\n}","code-length":170,"reference":"\/\/ DeleteComment deletes a comment.","result":"Delete comments.","score":[0,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) DeleteStaleComments(org, repo string, number int, comments []github.IssueComment, isStale func(github.IssueComment) bool) error {\r\n\tif comments == nil {\r\n\t\tcomments, _ = f.ListIssueComments(org, repo, number)\r\n\t}\r\n\tfor _, comment := range comments {\r\n\t\tif isStale(comment) {\r\n\t\t\tif err := f.DeleteComment(org, repo, comment.ID); err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"failed to delete stale comment with ID '%d'\", comment.ID)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":172,"reference":"\/\/ DeleteStaleComments deletes comments flagged by isStale.","result":"Delete stale comments.","score":[0,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetPullRequest(owner, repo string, number int) (*github.PullRequest, error) {\r\n\tval, exists := f.PullRequests[number]\r\n\tif !exists {\r\n\t\treturn nil, fmt.Errorf(\"Pull request number %d does not exit\", number)\r\n\t}\r\n\treturn val, nil\r\n}","code-length":93,"reference":"\/\/ GetPullRequest returns details about the PR.","result":"Test if the code is executed.","score":[0.1634,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetPullRequestChanges(org, repo string, number int) ([]github.PullRequestChange, error) {\r\n\treturn f.PullRequestChanges[number], nil\r\n}","code-length":53,"reference":"\/\/ GetPullRequestChanges returns the file modifications in a PR.","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetRef(owner, repo, ref string) (string, error) {\r\n\treturn TestRef, nil\r\n}","code-length":43,"reference":"\/\/ GetRef returns the hash of a ref.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) DeleteRef(owner, repo, ref string) error {\r\n\tf.RefsDeleted = append(f.RefsDeleted, struct{ Org, Repo, Ref string }{Org: owner, Repo: repo, Ref: ref})\r\n\treturn nil\r\n}","code-length":73,"reference":"\/\/ DeleteRef returns an error indicating if deletion of the given ref was successful","result":"Delete refs.","score":[0,0.0391]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetSingleCommit(org, repo, SHA string) (github.SingleCommit, error) {\r\n\treturn f.Commits[SHA], nil\r\n}","code-length":50,"reference":"\/\/ GetSingleCommit returns a single commit.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) CreateStatus(owner, repo, SHA string, s github.Status) error {\r\n\tif f.CreatedStatuses == nil {\r\n\t\tf.CreatedStatuses = make(map[string][]github.Status)\r\n\t}\r\n\tstatuses := f.CreatedStatuses[SHA]\r\n\tvar updated bool\r\n\tfor i := range statuses {\r\n\t\tif statuses[i].Context == s.Context {\r\n\t\t\tstatuses[i] = s\r\n\t\t\tupdated = true\r\n\t\t}\r\n\t}\r\n\tif !updated {\r\n\t\tstatuses = append(statuses, s)\r\n\t}\r\n\tf.CreatedStatuses[SHA] = statuses\r\n\treturn nil\r\n}","code-length":179,"reference":"\/\/ CreateStatus adds a status context to a commit.","result":"Create a new status.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ListStatuses(org, repo, ref string) ([]github.Status, error) {\r\n\treturn f.CreatedStatuses[ref], nil\r\n}","code-length":50,"reference":"\/\/ ListStatuses returns individual status contexts on a commit.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetCombinedStatus(owner, repo, ref string) (*github.CombinedStatus, error) {\r\n\treturn f.CombinedStatuses[ref], nil\r\n}","code-length":52,"reference":"\/\/ GetCombinedStatus returns the overall status for a commit.","result":"Get the combined status.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetRepoLabels(owner, repo string) ([]github.Label, error) {\r\n\tla := []github.Label{}\r\n\tfor _, l := range f.RepoLabelsExisting {\r\n\t\tla = append(la, github.Label{Name: l})\r\n\t}\r\n\treturn la, nil\r\n}","code-length":91,"reference":"\/\/ GetRepoLabels gets labels in a repo.","result":"Get labels from github.","score":[0.1509,0.2799]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetIssueLabels(owner, repo string, number int) ([]github.Label, error) {\r\n\tre := regexp.MustCompile(fmt.Sprintf(`^%s\/%s#%d:(.*)$`, owner, repo, number))\r\n\tla := []github.Label{}\r\n\tallLabels := sets.NewString(f.IssueLabelsExisting...)\r\n\tallLabels.Insert(f.IssueLabelsAdded...)\r\n\tallLabels.Delete(f.IssueLabelsRemoved...)\r\n\tfor _, l := range allLabels.List() {\r\n\t\tgroups := re.FindStringSubmatch(l)\r\n\t\tif groups != nil {\r\n\t\t\tla = append(la, github.Label{Name: groups[1]})\r\n\t\t}\r\n\t}\r\n\treturn la, nil\r\n}","code-length":204,"reference":"\/\/ GetIssueLabels gets labels on an issue","result":"Test if the file is not empty.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) AddLabel(owner, repo string, number int, label string) error {\r\n\tlabelString := fmt.Sprintf(\"%s\/%s#%d:%s\", owner, repo, number, label)\r\n\tif sets.NewString(f.IssueLabelsAdded...).Has(labelString) {\r\n\t\treturn fmt.Errorf(\"cannot add %v to %s\/%s\/#%d\", label, owner, repo, number)\r\n\t}\r\n\tif f.RepoLabelsExisting == nil {\r\n\t\tf.IssueLabelsAdded = append(f.IssueLabelsAdded, labelString)\r\n\t\treturn nil\r\n\t}\r\n\tfor _, l := range f.RepoLabelsExisting {\r\n\t\tif label == l {\r\n\t\t\tf.IssueLabelsAdded = append(f.IssueLabelsAdded, labelString)\r\n\t\t\treturn nil\r\n\t\t}\r\n\t}\r\n\treturn fmt.Errorf(\"cannot add %v to %s\/%s\/#%d\", label, owner, repo, number)\r\n}","code-length":251,"reference":"\/\/ AddLabel adds a label","result":"Add labels to a github issue.","score":[0.193,0.2941]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) RemoveLabel(owner, repo string, number int, label string) error {\r\n\tlabelString := fmt.Sprintf(\"%s\/%s#%d:%s\", owner, repo, number, label)\r\n\tif !sets.NewString(f.IssueLabelsRemoved...).Has(labelString) {\r\n\t\tf.IssueLabelsRemoved = append(f.IssueLabelsRemoved, labelString)\r\n\t\treturn nil\r\n\t}\r\n\treturn fmt.Errorf(\"cannot remove %v from %s\/%s\/#%d\", label, owner, repo, number)\r\n}","code-length":146,"reference":"\/\/ RemoveLabel removes a label","result":"Remove labels from github.","score":[0,0.2041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) FindIssues(query, sort string, asc bool) ([]github.Issue, error) {\r\n\treturn f.Issues, nil\r\n}","code-length":48,"reference":"\/\/ FindIssues returns f.Issues","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) AssignIssue(owner, repo string, number int, assignees []string) error {\r\n\tvar m github.MissingUsers\r\n\tfor _, a := range assignees {\r\n\t\tif a == \"not-in-the-org\" {\r\n\t\t\tm.Users = append(m.Users, a)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tf.AssigneesAdded = append(f.AssigneesAdded, fmt.Sprintf(\"%s\/%s#%d:%s\", owner, repo, number, a))\r\n\t}\r\n\tif m.Users == nil {\r\n\t\treturn nil\r\n\t}\r\n\treturn m\r\n}","code-length":170,"reference":"\/\/ AssignIssue adds assignees.","result":"Test if the file is not empty.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetFile(org, repo, file, commit string) ([]byte, error) {\r\n\tcontents, ok := f.RemoteFiles[file]\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"could not find file %s\", file)\r\n\t}\r\n\tif commit == \"\" {\r\n\t\tif master, ok := contents[\"master\"]; ok {\r\n\t\t\treturn []byte(master), nil\r\n\t\t}\r\n\t\treturn nil, fmt.Errorf(\"could not find file %s in master\", file)\r\n\t}\r\n\tif content, ok := contents[commit]; ok {\r\n\t\treturn []byte(content), nil\r\n\t}\r\n\treturn nil, fmt.Errorf(\"could not find file %s with ref %s\", file, commit)\r\n}","code-length":203,"reference":"\/\/ GetFile returns the bytes of the file.","result":"Test if the file is not in the package.","score":[0.1449,0.1235]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ListTeams(org string) ([]github.Team, error) {\r\n\treturn []github.Team{\r\n\t\t{\r\n\t\t\tID:   0,\r\n\t\t\tName: \"Admins\",\r\n\t\t},\r\n\t\t{\r\n\t\t\tID:   42,\r\n\t\t\tName: \"Leads\",\r\n\t\t},\r\n\t}, nil\r\n}","code-length":107,"reference":"\/\/ ListTeams return a list of fake teams that correspond to the fake team members returned by ListTeamMembers","result":"List teams in the org.","score":[0.0212,0.0898]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ListTeamMembers(teamID int, role string) ([]github.TeamMember, error) {\r\n\tif role != github.RoleAll {\r\n\t\treturn nil, fmt.Errorf(\"unsupported role %v (only all supported)\", role)\r\n\t}\r\n\tteams := map[int][]github.TeamMember{\r\n\t\t0:  {{Login: \"default-sig-lead\"}},\r\n\t\t42: {{Login: \"sig-lead\"}},\r\n\t}\r\n\tmembers, ok := teams[teamID]\r\n\tif !ok {\r\n\t\treturn []github.TeamMember{}, nil\r\n\t}\r\n\treturn members, nil\r\n}","code-length":173,"reference":"\/\/ ListTeamMembers return a fake team with a single \"sig-lead\" GitHub teammember","result":"Test if the code is not compiled with.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) IsCollaborator(org, repo, login string) (bool, error) {\r\n\tnormed := github.NormLogin(login)\r\n\tfor _, collab := range f.Collaborators {\r\n\t\tif github.NormLogin(collab) == normed {\r\n\t\t\treturn true, nil\r\n\t\t}\r\n\t}\r\n\treturn false, nil\r\n}","code-length":104,"reference":"\/\/ IsCollaborator returns true if the user is a collaborator of the repo.","result":"Test if the repo is a collaborator.","score":[0.1276,0.2545]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ListCollaborators(org, repo string) ([]github.User, error) {\r\n\tresult := make([]github.User, 0, len(f.Collaborators))\r\n\tfor _, login := range f.Collaborators {\r\n\t\tresult = append(result, github.User{Login: login})\r\n\t}\r\n\treturn result, nil\r\n}","code-length":101,"reference":"\/\/ ListCollaborators lists the collaborators.","result":"List collaborators.","score":[0.1116,0.2128]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ClearMilestone(org, repo string, issueNum int) error {\r\n\tf.Milestone = 0\r\n\treturn nil\r\n}","code-length":48,"reference":"\/\/ ClearMilestone removes the milestone","result":"Test the code.","score":[0.2096,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) SetMilestone(org, repo string, issueNum, milestoneNum int) error {\r\n\tif milestoneNum < 0 {\r\n\t\treturn fmt.Errorf(\"Milestone Numbers Cannot Be Negative\")\r\n\t}\r\n\tf.Milestone = milestoneNum\r\n\treturn nil\r\n}","code-length":82,"reference":"\/\/ SetMilestone sets the milestone.","result":"Test if the code is not compiled with.","score":[0.1389,0.0943]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ListMilestones(org, repo string) ([]github.Milestone, error) {\r\n\tmilestones := []github.Milestone{}\r\n\tfor k, v := range f.MilestoneMap {\r\n\t\tmilestones = append(milestones, github.Milestone{Title: k, Number: v})\r\n\t}\r\n\treturn milestones, nil\r\n}","code-length":107,"reference":"\/\/ ListMilestones lists milestones.","result":"List milestones.","score":[0.1839,0.4934]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ListPRCommits(org, repo string, prNumber int) ([]github.RepositoryCommit, error) {\r\n\tk := fmt.Sprintf(\"%s\/%s#%d\", org, repo, prNumber)\r\n\treturn f.CommitMap[k], nil\r\n}","code-length":78,"reference":"\/\/ ListPRCommits lists commits for a given PR.","result":"List PR commits.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetRepoProjects(owner, repo string) ([]github.Project, error) {\r\n\treturn f.RepoProjects[fmt.Sprintf(\"%s\/%s\", owner, repo)], nil\r\n}","code-length":61,"reference":"\/\/ GetRepoProjects returns the list of projects under a repo.","result":"Get the list of all projects in a repo.","score":[0.287,0.5682]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetOrgProjects(org string) ([]github.Project, error) {\r\n\treturn f.RepoProjects[fmt.Sprintf(\"%s\/*\", org)], nil\r\n}","code-length":56,"reference":"\/\/ GetOrgProjects returns the list of projects under an org","result":"Get all the projects in a org.","score":[0.1251,0.1031]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetProjectColumns(projectID int) ([]github.ProjectColumn, error) {\r\n\t\r\n\tfor _, projects := range f.RepoProjects {\r\n\t\tfor _, project := range projects {\r\n\t\t\tif projectID == project.ID {\r\n\t\t\t\treturn f.ProjectColumnsMap[project.Name], nil\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn nil, fmt.Errorf(\"Cannot find project ID\")\r\n}","code-length":123,"reference":"\/\/ GetProjectColumns returns the list of columns for a given project.","result":"Test if the project is not in a package.","score":[0.116,0.0926]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) CreateProjectCard(columnID int, projectCard github.ProjectCard) (*github.ProjectCard, error) {\r\n\tif f.ColumnCardsMap == nil {\r\n\t\tf.ColumnCardsMap = make(map[int][]github.ProjectCard)\r\n\t}\r\n\tfor project, columnIDMap := range f.ColumnIDMap {\r\n\t\tcolumnName, exists := columnIDMap[columnID]\r\n\t\tif exists {\r\n\t\t\tf.ColumnCardsMap[columnID] = append(\r\n\t\t\t\tf.ColumnCardsMap[columnID],\r\n\t\t\t\tprojectCard,\r\n\t\t\t)\r\n\t\t\tf.Column = columnName\r\n\t\t\tf.Project = project\r\n\t\t\treturn &projectCard, nil\r\n\t\t}\r\n\t}\r\n\treturn nil, fmt.Errorf(\"Provided column %d does not exist, ColumnIDMap is %v\", columnID, f.ColumnIDMap)\r\n}","code-length":234,"reference":"\/\/ CreateProjectCard creates a project card under a given column.","result":"Create a project card.","score":[0.1008,0.1596]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) DeleteProjectCard(projectCardID int) error {\r\n\tif f.ColumnCardsMap == nil {\r\n\t\treturn fmt.Errorf(\"Project card doesn't exist\")\r\n\t}\r\n\tf.Project = \"\"\r\n\tf.Column = \"\"\r\n\tnewCards := []github.ProjectCard{}\r\n\toldColumnID := -1\r\n\tfor column, cards := range f.ColumnCardsMap {\r\n\t\tremovalIndex := -1\r\n\t\tfor i, existingCard := range cards {\r\n\t\t\tif existingCard.ContentID == projectCardID {\r\n\t\t\t\toldColumnID = column\r\n\t\t\t\tremovalIndex = i\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif removalIndex != -1 {\r\n\t\t\tnewCards = cards\r\n\t\t\tnewCards[removalIndex] = newCards[len(newCards)-1]\r\n\t\t\tnewCards = newCards[:len(newCards)-1]\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\t\r\n\tif oldColumnID != -1 {\r\n\t\tf.ColumnCardsMap[oldColumnID] = newCards\r\n\t}\r\n\treturn nil\r\n}","code-length":296,"reference":"\/\/ DeleteProjectCard deletes the project card of a specific issue or PR","result":"Delete the project card.","score":[0.0611,0.2629]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) MoveProjectCard(projectCardID int, newColumnID int) error {\r\n\t\r\n\tnewCards := []github.ProjectCard{}\r\n\toldColumnID := -1\r\n\tprojectCard := github.ProjectCard{}\r\n\tfor column, cards := range f.ColumnCardsMap {\r\n\t\tremovalIndex := -1\r\n\t\tfor i, existingCard := range cards {\r\n\t\t\tif existingCard.ContentID == projectCardID {\r\n\t\t\t\toldColumnID = column\r\n\t\t\t\tremovalIndex = i\r\n\t\t\t\tprojectCard = existingCard\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif removalIndex != -1 {\r\n\t\t\tnewCards = cards\r\n\t\t\tnewCards[removalIndex] = newCards[len(newCards)-1]\r\n\t\t\tnewCards = newCards[:len(newCards)-1]\r\n\t\t}\r\n\t}\r\n\tif oldColumnID != -1 {\r\n\t\t\r\n\t\tf.ColumnCardsMap[oldColumnID] = newCards\r\n\t}\r\n\tfor project, columnIDMap := range f.ColumnIDMap {\r\n\t\tif columnName, exists := columnIDMap[newColumnID]; exists {\r\n\t\t\t\r\n\t\t\tf.ColumnCardsMap[newColumnID] = append(\r\n\t\t\t\tf.ColumnCardsMap[newColumnID],\r\n\t\t\t\tprojectCard,\r\n\t\t\t)\r\n\t\t\tf.Column = columnName\r\n\t\t\tf.Project = project\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":386,"reference":"\/\/ MoveProjectCard moves a specific project card to a specified column in the same project","result":"Move a project card.","score":[0.0243,0.1079]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (config *InfluxConfig) CreateDatabaseClient() (*InfluxDB, error) {\r\n\tclient, err := influxdb.NewHTTPClient(influxdb.HTTPConfig{\r\n\t\tAddr:     config.Host,\r\n\t\tUsername: config.User,\r\n\t\tPassword: config.Password,\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &InfluxDB{\r\n\t\tclient:   client,\r\n\t\tdatabase: config.DB,\r\n\t}, nil\r\n}","code-length":139,"reference":"\/\/ CreateDatabaseClient creates and connects a new instance of an InfluxDB\n\/\/ It is created based on the fields set in the configuration.","result":"Create a database client.","score":[0.0028,0.0474]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InfluxDB) Push(measurement string, tags map[string]string, fields map[string]interface{}, date time.Time) error {\r\n\tbatch, err := influxdb.NewBatchPoints(influxdb.BatchPointsConfig{\r\n\t\tDatabase:  i.database,\r\n\t\tPrecision: \"s\",\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tpt, err := influxdb.NewPoint(measurement, tags, fields, date)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tbatch.AddPoint(pt)\r\n\terr = i.client.Write(batch)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tglog.Infof(\"Sent to influx: %s %+v %+v %s\", measurement, tags, fields, date)\r\n\treturn nil\r\n}","code-length":225,"reference":"\/\/ Push a point to the database","result":"Send metrics to influx.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewProwJobWithAnnotation(spec prowapi.ProwJobSpec, labels, annotations map[string]string) prowapi.ProwJob {\r\n\treturn newProwJob(spec, labels, annotations)\r\n}","code-length":62,"reference":"\/\/ NewProwJobWithAnnotation initializes a ProwJob out of a ProwJobSpec with annotations.","result":"Create annotation for the ProwJob.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewProwJob(spec prowapi.ProwJobSpec, labels map[string]string) prowapi.ProwJob {\r\n\treturn newProwJob(spec, labels, nil)\r\n}","code-length":58,"reference":"\/\/ NewProwJob initializes a ProwJob out of a ProwJobSpec.","result":"Create a new ProwJob.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPresubmit(pr github.PullRequest, baseSHA string, job config.Presubmit, eventGUID string) prowapi.ProwJob {\r\n\trefs := createRefs(pr, baseSHA)\r\n\tlabels := make(map[string]string)\r\n\tfor k, v := range job.Labels {\r\n\t\tlabels[k] = v\r\n\t}\r\n\tlabels[github.EventGUID] = eventGUID\r\n\treturn NewProwJob(PresubmitSpec(job, refs), labels)\r\n}","code-length":132,"reference":"\/\/ NewPresubmit converts a config.Presubmit into a prowapi.ProwJob.\n\/\/ The prowapi.Refs are configured correctly per the pr, baseSHA.\n\/\/ The eventGUID becomes a github.EventGUID label.","result":"Create a new PR.","score":[0.0017,0.0218]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PresubmitSpec(p config.Presubmit, refs prowapi.Refs) prowapi.ProwJobSpec {\r\n\tpjs := specFromJobBase(p.JobBase)\r\n\tpjs.Type = prowapi.PresubmitJob\r\n\tpjs.Context = p.Context\r\n\tpjs.Report = !p.SkipReport\r\n\tpjs.RerunCommand = p.RerunCommand\r\n\tif p.JenkinsSpec != nil {\r\n\t\tpjs.JenkinsSpec = &prowapi.JenkinsSpec{\r\n\t\t\tGitHubBranchSourceJob: p.JenkinsSpec.GitHubBranchSourceJob,\r\n\t\t}\r\n\t}\r\n\tpjs.Refs = completePrimaryRefs(refs, p.JobBase)\r\n\treturn pjs\r\n}","code-length":198,"reference":"\/\/ PresubmitSpec initializes a ProwJobSpec for a given presubmit job.","result":"Generate the spec for the job.","score":[0.1179,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PostsubmitSpec(p config.Postsubmit, refs prowapi.Refs) prowapi.ProwJobSpec {\r\n\tpjs := specFromJobBase(p.JobBase)\r\n\tpjs.Type = prowapi.PostsubmitJob\r\n\tpjs.Context = p.Context\r\n\tpjs.Report = !p.SkipReport\r\n\tpjs.Refs = completePrimaryRefs(refs, p.JobBase)\r\n\tif p.JenkinsSpec != nil {\r\n\t\tpjs.JenkinsSpec = &prowapi.JenkinsSpec{\r\n\t\t\tGitHubBranchSourceJob: p.JenkinsSpec.GitHubBranchSourceJob,\r\n\t\t}\r\n\t}\r\n\treturn pjs\r\n}","code-length":180,"reference":"\/\/ PostsubmitSpec initializes a ProwJobSpec for a given postsubmit job.","result":"Generate the spec for the postsubmit job.","score":[0.1647,0.2635]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PeriodicSpec(p config.Periodic) prowapi.ProwJobSpec {\r\n\tpjs := specFromJobBase(p.JobBase)\r\n\tpjs.Type = prowapi.PeriodicJob\r\n\treturn pjs\r\n}","code-length":67,"reference":"\/\/ PeriodicSpec initializes a ProwJobSpec for a given periodic job.","result":"Generate the spec file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc BatchSpec(p config.Presubmit, refs prowapi.Refs) prowapi.ProwJobSpec {\r\n\tpjs := specFromJobBase(p.JobBase)\r\n\tpjs.Type = prowapi.BatchJob\r\n\tpjs.Context = p.Context\r\n\tpjs.Refs = completePrimaryRefs(refs, p.JobBase)\r\n\treturn pjs\r\n}","code-length":105,"reference":"\/\/ BatchSpec initializes a ProwJobSpec for a given batch job and ref spec.","result":"Generate the batch job spec.","score":[0.0759,0.2095]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PartitionActive(pjs []prowapi.ProwJob) (pending, triggered chan prowapi.ProwJob) {\r\n\t\r\n\tpendingCount, triggeredCount := 0, 0\r\n\tfor _, pj := range pjs {\r\n\t\tswitch pj.Status.State {\r\n\t\tcase prowapi.PendingState:\r\n\t\t\tpendingCount++\r\n\t\tcase prowapi.TriggeredState:\r\n\t\t\ttriggeredCount++\r\n\t\t}\r\n\t}\r\n\tpending = make(chan prowapi.ProwJob, pendingCount)\r\n\ttriggered = make(chan prowapi.ProwJob, triggeredCount)\r\n\t\r\n\tfor _, pj := range pjs {\r\n\t\tswitch pj.Status.State {\r\n\t\tcase prowapi.PendingState:\r\n\t\t\tpending <- pj\r\n\t\tcase prowapi.TriggeredState:\r\n\t\t\ttriggered <- pj\r\n\t\t}\r\n\t}\r\n\tclose(pending)\r\n\tclose(triggered)\r\n\treturn pending, triggered\r\n}","code-length":270,"reference":"\/\/ PartitionActive separates the provided prowjobs into pending and triggered\n\/\/ and returns them inside channels so that they can be consumed in parallel\n\/\/ by different goroutines. Complete prowjobs are filtered out. Controller\n\/\/ loops need to handle pending jobs first so they can conform to maximum\n\/\/ concurrency requirements that different jobs may have.","result":"Partition the active jobs in the cluster.","score":[0.0002,0.0294]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ProwJobFields(pj *prowapi.ProwJob) logrus.Fields {\r\n\tfields := make(logrus.Fields)\r\n\tfields[\"name\"] = pj.ObjectMeta.Name\r\n\tfields[\"job\"] = pj.Spec.Job\r\n\tfields[\"type\"] = pj.Spec.Type\r\n\tif len(pj.ObjectMeta.Labels[github.EventGUID]) > 0 {\r\n\t\tfields[github.EventGUID] = pj.ObjectMeta.Labels[github.EventGUID]\r\n\t}\r\n\tif pj.Spec.Refs != nil && len(pj.Spec.Refs.Pulls) == 1 {\r\n\t\tfields[github.PrLogField] = pj.Spec.Refs.Pulls[0].Number\r\n\t\tfields[github.RepoLogField] = pj.Spec.Refs.Repo\r\n\t\tfields[github.OrgLogField] = pj.Spec.Refs.Org\r\n\t}\r\n\tif pj.Spec.JenkinsSpec != nil {\r\n\t\tfields[\"github_based_job\"] = pj.Spec.JenkinsSpec.GitHubBranchSourceJob\r\n\t}\r\n\treturn fields\r\n}","code-length":289,"reference":"\/\/ ProwJobFields extracts logrus fields from a prowjob useful for logging.","result":"Log the fields of the pj.","score":[0.0839,0.0476]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ClusterToCtx(cluster string) string {\r\n\tif cluster == kube.InClusterContext {\r\n\t\treturn kube.DefaultClusterAlias\r\n\t}\r\n\treturn cluster\r\n}","code-length":53,"reference":"\/\/ ClusterToCtx converts the prow job's cluster to a cluster context","result":"Generate the code.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pluginHelp *PluginHelp) AddCommand(command Command) {\r\n\tpluginHelp.Commands = append(pluginHelp.Commands, command)\r\n}","code-length":44,"reference":"\/\/ AddCommand registers new help text for a bot command.","result":"Add commands to plugins.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *FakeProwJobs) Get(name string, options v1.GetOptions) (result *prowjobsv1.ProwJob, err error) {\r\n\tobj, err := c.Fake.\r\n\t\tInvokes(testing.NewGetAction(prowjobsResource, c.ns, name), &prowjobsv1.ProwJob{})\r\n\tif obj == nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn obj.(*prowjobsv1.ProwJob), err\r\n}","code-length":135,"reference":"\/\/ Get takes name of the prowJob, and returns the corresponding prowJob object, and an error if there is any.","result":"Get the specified ProwJob.","score":[0.007,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *FakeProwJobs) Watch(opts v1.ListOptions) (watch.Interface, error) {\r\n\treturn c.Fake.\r\n\t\tInvokesWatch(testing.NewWatchAction(prowjobsResource, c.ns, opts))\r\n}","code-length":70,"reference":"\/\/ Watch returns a watch.Interface that watches the requested prowJobs.","result":"Watch a resource for changes to be persisted.","score":[0.1286,0.102]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *FakeProwJobs) Delete(name string, options *v1.DeleteOptions) error {\r\n\t_, err := c.Fake.\r\n\t\tInvokes(testing.NewDeleteAction(prowjobsResource, c.ns, name), &prowjobsv1.ProwJob{})\r\n\treturn err\r\n}","code-length":88,"reference":"\/\/ Delete takes name of the prowJob and deletes it. Returns an error if one occurs.","result":"Delete the ProwJob.","score":[0.0064,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *FakeProwJobs) Patch(name string, pt types.PatchType, data []byte, subresources ...string) (result *prowjobsv1.ProwJob, err error) {\r\n\tobj, err := c.Fake.\r\n\t\tInvokes(testing.NewPatchSubresourceAction(prowjobsResource, c.ns, name, data, subresources...), &prowjobsv1.ProwJob{})\r\n\tif obj == nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn obj.(*prowjobsv1.ProwJob), err\r\n}","code-length":151,"reference":"\/\/ Patch applies the patch and returns the patched prowJob.","result":"Test if the file contains a comment.","score":[0.1052,0.0515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Tide) MergeMethod(org, repo string) github.PullRequestMergeType {\r\n\tname := org + \"\/\" + repo\r\n\tv, ok := t.MergeType[name]\r\n\tif !ok {\r\n\t\tif ov, found := t.MergeType[org]; found {\r\n\t\t\treturn ov\r\n\t\t}\r\n\t\treturn github.MergeMerge\r\n\t}\r\n\treturn v\r\n}","code-length":111,"reference":"\/\/ MergeMethod returns the merge method to use for a repo. The default of merge is\n\/\/ returned when not overridden.","result":"Define the merge method.","score":[0.0064,0.0518]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tq *TideQuery) Query() string {\r\n\ttoks := []string{\"is:pr\", \"state:open\"}\r\n\tfor _, o := range tq.Orgs {\r\n\t\ttoks = append(toks, fmt.Sprintf(\"org:\\\"%s\\\"\", o))\r\n\t}\r\n\tfor _, r := range tq.Repos {\r\n\t\ttoks = append(toks, fmt.Sprintf(\"repo:\\\"%s\\\"\", r))\r\n\t}\r\n\tfor _, r := range tq.ExcludedRepos {\r\n\t\ttoks = append(toks, fmt.Sprintf(\"-repo:\\\"%s\\\"\", r))\r\n\t}\r\n\tfor _, b := range tq.ExcludedBranches {\r\n\t\ttoks = append(toks, fmt.Sprintf(\"-base:\\\"%s\\\"\", b))\r\n\t}\r\n\tfor _, b := range tq.IncludedBranches {\r\n\t\ttoks = append(toks, fmt.Sprintf(\"base:\\\"%s\\\"\", b))\r\n\t}\r\n\tfor _, l := range tq.Labels {\r\n\t\ttoks = append(toks, fmt.Sprintf(\"label:\\\"%s\\\"\", l))\r\n\t}\r\n\tfor _, l := range tq.MissingLabels {\r\n\t\ttoks = append(toks, fmt.Sprintf(\"-label:\\\"%s\\\"\", l))\r\n\t}\r\n\tif tq.Milestone != \"\" {\r\n\t\ttoks = append(toks, fmt.Sprintf(\"milestone:\\\"%s\\\"\", tq.Milestone))\r\n\t}\r\n\tif tq.ReviewApprovedRequired {\r\n\t\ttoks = append(toks, \"review:approved\")\r\n\t}\r\n\treturn strings.Join(toks, \" \")\r\n}","code-length":442,"reference":"\/\/ Query returns the corresponding github search string for the tide query.","result":"Query the tide.","score":[0.0242,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tq TideQuery) ForRepo(org, repo string) bool {\r\n\tfullName := fmt.Sprintf(\"%s\/%s\", org, repo)\r\n\tfor _, queryOrg := range tq.Orgs {\r\n\t\tif queryOrg != org {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tfor _, excludedRepo := range tq.ExcludedRepos {\r\n\t\t\tif excludedRepo == fullName {\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn true\r\n\t}\r\n\tfor _, queryRepo := range tq.Repos {\r\n\t\tif queryRepo == fullName {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":183,"reference":"\/\/ ForRepo indicates if the tide query applies to the specified repo.","result":"Query tide for repo .","score":[0.0593,0.0885]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tqs TideQueries) OrgExceptionsAndRepos() (map[string]sets.String, sets.String) {\r\n\torgs := make(map[string]sets.String)\r\n\tfor i := range tqs {\r\n\t\tfor _, org := range tqs[i].Orgs {\r\n\t\t\tapplicableRepos := sets.NewString(reposInOrg(org, tqs[i].ExcludedRepos)...)\r\n\t\t\tif excepts, ok := orgs[org]; !ok {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\torgs[org] = applicableRepos\r\n\t\t\t} else {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\torgs[org] = excepts.Intersection(applicableRepos)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\trepos := sets.NewString()\r\n\tfor i := range tqs {\r\n\t\trepos.Insert(tqs[i].Repos...)\r\n\t}\r\n\t\r\n\treposList := repos.UnsortedList()\r\n\tfor _, excepts := range orgs {\r\n\t\texcepts.Delete(reposList...)\r\n\t}\r\n\treturn orgs, repos\r\n}","code-length":281,"reference":"\/\/ OrgExceptionsAndRepos determines which orgs and repos a set of queries cover.\n\/\/ Output is returned as a mapping from 'included org'->'repos excluded in the org'\n\/\/ and a set of included repos.","result":"Generate the TideQuery.","score":[0.0,0.0167]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tqs TideQueries) QueryMap() *QueryMap {\r\n\treturn &QueryMap{\r\n\t\tqueries: tqs,\r\n\t\tcache:   make(map[string]TideQueries),\r\n\t}\r\n}","code-length":65,"reference":"\/\/ QueryMap creates a QueryMap from TideQueries","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (qm *QueryMap) ForRepo(org, repo string) TideQueries {\r\n\tres := TideQueries(nil)\r\n\tfullName := fmt.Sprintf(\"%s\/%s\", org, repo)\r\n\tqm.Lock()\r\n\tdefer qm.Unlock()\r\n\tif qs, ok := qm.cache[fullName]; ok {\r\n\t\treturn append(res, qs...)\r\n\t}\r\n\t\r\n\tfor _, query := range qm.queries {\r\n\t\tif query.ForRepo(org, repo) {\r\n\t\t\tres = append(res, query)\r\n\t\t}\r\n\t}\r\n\tqm.cache[fullName] = res\r\n\treturn res\r\n}","code-length":177,"reference":"\/\/ ForRepo returns the tide queries that apply to a repo.","result":"Query the TideQueryMap.","score":[0.0284,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cp *TideContextPolicy) Validate() error {\r\n\tif inter := sets.NewString(cp.RequiredContexts...).Intersection(sets.NewString(cp.OptionalContexts...)); inter.Len() > 0 {\r\n\t\treturn fmt.Errorf(\"contexts %s are defined as required and optional\", strings.Join(inter.List(), \", \"))\r\n\t}\r\n\tif inter := sets.NewString(cp.RequiredContexts...).Intersection(sets.NewString(cp.RequiredIfPresentContexts...)); inter.Len() > 0 {\r\n\t\treturn fmt.Errorf(\"contexts %s are defined as required and required if present\", strings.Join(inter.List(), \", \"))\r\n\t}\r\n\tif inter := sets.NewString(cp.OptionalContexts...).Intersection(sets.NewString(cp.RequiredIfPresentContexts...)); inter.Len() > 0 {\r\n\t\treturn fmt.Errorf(\"contexts %s are defined as optional and required if present\", strings.Join(inter.List(), \", \"))\r\n\t}\r\n\treturn nil\r\n}","code-length":251,"reference":"\/\/ Validate returns an error if any contexts are listed more than once in the config.","result":"Validate the context.","score":[0.0064,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c Config) GetTideContextPolicy(org, repo, branch string) (*TideContextPolicy, error) {\r\n\toptions := parseTideContextPolicyOptions(org, repo, branch, c.Tide.ContextOptions)\r\n\t\r\n\trequired := sets.NewString(options.RequiredContexts...)\r\n\trequiredIfPresent := sets.NewString(options.RequiredIfPresentContexts...)\r\n\toptional := sets.NewString(options.OptionalContexts...)\r\n\t\r\n\tprowRequired, prowRequiredIfPresent, prowOptional := BranchRequirements(org, repo, branch, c.Presubmits)\r\n\trequired.Insert(prowRequired...)\r\n\trequiredIfPresent.Insert(prowRequiredIfPresent...)\r\n\toptional.Insert(prowOptional...)\r\n\t\r\n\tif options.FromBranchProtection != nil && *options.FromBranchProtection {\r\n\t\tbp, err := c.GetBranchProtection(org, repo, branch)\r\n\t\tif err != nil {\r\n\t\t\tlogrus.WithError(err).Warningf(\"Error getting branch protection for %s\/%s+%s\", org, repo, branch)\r\n\t\t} else if bp != nil && bp.Protect != nil && *bp.Protect && bp.RequiredStatusChecks != nil {\r\n\t\t\trequired.Insert(bp.RequiredStatusChecks.Contexts...)\r\n\t\t}\r\n\t}\r\n\tt := &TideContextPolicy{\r\n\t\tRequiredContexts:          required.List(),\r\n\t\tRequiredIfPresentContexts: requiredIfPresent.List(),\r\n\t\tOptionalContexts:          optional.List(),\r\n\t\tSkipUnknownContexts:       options.SkipUnknownContexts,\r\n\t}\r\n\tif err := t.Validate(); err != nil {\r\n\t\treturn t, err\r\n\t}\r\n\treturn t, nil\r\n}","code-length":431,"reference":"\/\/ GetTideContextPolicy parses the prow config to find context merge options.\n\/\/ If none are set, it will use the prow jobs configured and use the default github combined status.\n\/\/ Otherwise if set it will use the branch protection setting, or the listed jobs.","result":"Validate the tide context policy.","score":[0.0001,0.0244]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cp *TideContextPolicy) IsOptional(c string) bool {\r\n\tif sets.NewString(cp.OptionalContexts...).Has(c) {\r\n\t\treturn true\r\n\t}\r\n\tif sets.NewString(cp.RequiredContexts...).Has(c) {\r\n\t\treturn false\r\n\t}\r\n\t\r\n\tif sets.NewString(cp.RequiredIfPresentContexts...).Has(c) {\r\n\t\treturn false\r\n\t}\r\n\tif cp.SkipUnknownContexts != nil && *cp.SkipUnknownContexts {\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":158,"reference":"\/\/ IsOptional checks whether a context can be ignored.\n\/\/ Will return true if\n\/\/ - context is registered as optional\n\/\/ - required contexts are registered and the context provided is not required\n\/\/ Will return false otherwise. Every context is required.","result":"Check if a context is optional.","score":[0.0008,0.0947]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cp *TideContextPolicy) MissingRequiredContexts(contexts []string) []string {\r\n\tif len(cp.RequiredContexts) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\texistingContexts := sets.NewString()\r\n\tfor _, c := range contexts {\r\n\t\texistingContexts.Insert(c)\r\n\t}\r\n\tvar missingContexts []string\r\n\tfor c := range sets.NewString(cp.RequiredContexts...).Difference(existingContexts) {\r\n\t\tmissingContexts = append(missingContexts, c)\r\n\t}\r\n\treturn missingContexts\r\n}","code-length":149,"reference":"\/\/ MissingRequiredContexts discard the optional contexts and only look of extra required contexts that are not provided.","result":"Check if the context is not in.","score":[0.046,0.0938]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ValidateWebhook(w http.ResponseWriter, r *http.Request, hmacSecret []byte) (string, string, []byte, bool, int) {\r\n\tdefer r.Body.Close()\r\n\t\r\n\tif r.Method == http.MethodGet {\r\n\t\treturn \"\", \"\", nil, false, http.StatusOK\r\n\t}\r\n\t\r\n\tif r.Method != http.MethodPost {\r\n\t\tresponseHTTPError(w, http.StatusMethodNotAllowed, \"405 Method not allowed\")\r\n\t\treturn \"\", \"\", nil, false, http.StatusMethodNotAllowed\r\n\t}\r\n\teventType := r.Header.Get(\"X-GitHub-Event\")\r\n\tif eventType == \"\" {\r\n\t\tresponseHTTPError(w, http.StatusBadRequest, \"400 Bad Request: Missing X-GitHub-Event Header\")\r\n\t\treturn \"\", \"\", nil, false, http.StatusBadRequest\r\n\t}\r\n\teventGUID := r.Header.Get(\"X-GitHub-Delivery\")\r\n\tif eventGUID == \"\" {\r\n\t\tresponseHTTPError(w, http.StatusBadRequest, \"400 Bad Request: Missing X-GitHub-Delivery Header\")\r\n\t\treturn \"\", \"\", nil, false, http.StatusBadRequest\r\n\t}\r\n\tsig := r.Header.Get(\"X-Hub-Signature\")\r\n\tif sig == \"\" {\r\n\t\tresponseHTTPError(w, http.StatusForbidden, \"403 Forbidden: Missing X-Hub-Signature\")\r\n\t\treturn \"\", \"\", nil, false, http.StatusForbidden\r\n\t}\r\n\tcontentType := r.Header.Get(\"content-type\")\r\n\tif contentType != \"application\/json\" {\r\n\t\tresponseHTTPError(w, http.StatusBadRequest, \"400 Bad Request: Hook only accepts content-type: application\/json - please reconfigure this hook on GitHub\")\r\n\t\treturn \"\", \"\", nil, false, http.StatusBadRequest\r\n\t}\r\n\tpayload, err := ioutil.ReadAll(r.Body)\r\n\tif err != nil {\r\n\t\tresponseHTTPError(w, http.StatusInternalServerError, \"500 Internal Server Error: Failed to read request body\")\r\n\t\treturn \"\", \"\", nil, false, http.StatusInternalServerError\r\n\t}\r\n\t\r\n\tif !ValidatePayload(payload, sig, hmacSecret) {\r\n\t\tresponseHTTPError(w, http.StatusForbidden, \"403 Forbidden: Invalid X-Hub-Signature\")\r\n\t\treturn \"\", \"\", nil, false, http.StatusForbidden\r\n\t}\r\n\treturn eventType, eventGUID, payload, true, http.StatusOK\r\n}","code-length":605,"reference":"\/\/ ValidateWebhook ensures that the provided request conforms to the\n\/\/ format of a GitHub webhook and the payload can be validated with\n\/\/ the provided hmac secret. It returns the event type, the event guid,\n\/\/ the payload of the request, whether the webhook is valid or not,\n\/\/ and finally the resultant HTTP status code","result":"Code too long,keep in 512.","score":[0,0.0097]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HelpProvider(enabledRepos []string) (*pluginhelp.PluginHelp, error) {\r\n\treturn &pluginhelp.PluginHelp{\r\n\t\t\tDescription: `The needs-rebase plugin manages the '` + labels.NeedsRebase + `' label by removing it from Pull Requests that are mergeable and adding it to those which are not.\r\nThe plugin reacts to commit changes on PRs in addition to periodically scanning all open PRs for any changes to mergeability that could have resulted from changes in other PRs.`,\r\n\t\t},\r\n\t\tnil\r\n}","code-length":138,"reference":"\/\/ HelpProvider constructs the PluginHelp for this plugin that takes into account enabled repositories.\n\/\/ HelpProvider defines the type for function that construct the PluginHelp for plugins.","result":"Provide the help message.","score":[0.001,0.0202]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HandleEvent(log *logrus.Entry, ghc githubClient, pre *github.PullRequestEvent) error {\r\n\tif pre.Action != github.PullRequestActionOpened && pre.Action != github.PullRequestActionSynchronize && pre.Action != github.PullRequestActionReopened {\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\t\r\n\tsleep(time.Second * 5)\r\n\torg := pre.Repo.Owner.Login\r\n\trepo := pre.Repo.Name\r\n\tnumber := pre.Number\r\n\tsha := pre.PullRequest.Head.SHA\r\n\tmergeable, err := ghc.IsMergeable(org, repo, number, sha)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tissueLabels, err := ghc.GetIssueLabels(org, repo, number)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\thasLabel := github.HasLabel(labels.NeedsRebase, issueLabels)\r\n\treturn takeAction(log, ghc, org, repo, number, pre.PullRequest.User.Login, hasLabel, mergeable)\r\n}","code-length":274,"reference":"\/\/ HandleEvent handles a GitHub PR event to determine if the \"needs-rebase\"\n\/\/ label needs to be added or removed. It depends on GitHub mergeability check\n\/\/ to decide the need for a rebase.","result":"Handle PR events.","score":[0.0,0.0324]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HandleAll(log *logrus.Entry, ghc githubClient, config *plugins.Configuration) error {\r\n\tlog.Info(\"Checking all PRs.\")\r\n\torgs, repos := config.EnabledReposForExternalPlugin(PluginName)\r\n\tif len(orgs) == 0 && len(repos) == 0 {\r\n\t\tlog.Warnf(\"No repos have been configured for the %s plugin\", PluginName)\r\n\t\treturn nil\r\n\t}\r\n\tvar buf bytes.Buffer\r\n\tfmt.Fprint(&buf, \"is:pr is:open\")\r\n\tfor _, org := range orgs {\r\n\t\tfmt.Fprintf(&buf, \" org:\\\"%s\\\"\", org)\r\n\t}\r\n\tfor _, repo := range repos {\r\n\t\tfmt.Fprintf(&buf, \" repo:\\\"%s\\\"\", repo)\r\n\t}\r\n\tprs, err := search(context.Background(), log, ghc, buf.String())\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tlog.Infof(\"Considering %d PRs.\", len(prs))\r\n\tfor _, pr := range prs {\r\n\t\t\r\n\t\tif pr.Mergeable == githubql.MergeableStateUnknown {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\torg := string(pr.Repository.Owner.Login)\r\n\t\trepo := string(pr.Repository.Name)\r\n\t\tnum := int(pr.Number)\r\n\t\tl := log.WithFields(logrus.Fields{\r\n\t\t\t\"org\":  org,\r\n\t\t\t\"repo\": repo,\r\n\t\t\t\"pr\":   num,\r\n\t\t})\r\n\t\thasLabel := false\r\n\t\tfor _, label := range pr.Labels.Nodes {\r\n\t\t\tif label.Name == labels.NeedsRebase {\r\n\t\t\t\thasLabel = true\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\terr := takeAction(\r\n\t\t\tl,\r\n\t\t\tghc,\r\n\t\t\torg,\r\n\t\t\trepo,\r\n\t\t\tnum,\r\n\t\t\tstring(pr.Author.Login),\r\n\t\t\thasLabel,\r\n\t\t\tpr.Mergeable == githubql.MergeableStateMergeable,\r\n\t\t)\r\n\t\tif err != nil {\r\n\t\t\tl.WithError(err).Error(\"Error handling PR.\")\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":603,"reference":"\/\/ HandleAll checks all orgs and repos that enabled this plugin for open PRs to\n\/\/ determine if the \"needs-rebase\" label needs to be added or removed. It\n\/\/ depends on GitHub's mergeability check to decide the need for a rebase.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDryRunProwJobClient(deckURL string) prowv1.ProwJobInterface {\r\n\treturn &dryRunProwJobClient{\r\n\t\tdeckURL: deckURL,\r\n\t\tclient:  &http.Client{},\r\n\t}\r\n}","code-length":74,"reference":"\/\/ NewDryRunProwJobClient creates a new client that uses deck as a read-only proxy for ProwJob data","result":"Test if the client is created in production.","score":[0.0511,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dryRunProwJobClient) Create(*prowapi.ProwJob) (*prowapi.ProwJob, error) {\r\n\treturn nil, nil\r\n}","code-length":53,"reference":"\/\/ Create does nothing on a dry-run client","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dryRunProwJobClient) Update(*prowapi.ProwJob) (*prowapi.ProwJob, error) {\r\n\treturn nil, nil\r\n}","code-length":53,"reference":"\/\/ Update does nothing on a dry-run client","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dryRunProwJobClient) UpdateStatus(*prowapi.ProwJob) (*prowapi.ProwJob, error) {\r\n\treturn nil, nil\r\n}","code-length":54,"reference":"\/\/ UpdateStatus does nothing on a dry-run client","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dryRunProwJobClient) Delete(name string, options *metav1.DeleteOptions) error {\r\n\treturn nil\r\n}","code-length":44,"reference":"\/\/ Delete does nothing on a dry-run client","result":"Delete the file.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dryRunProwJobClient) DeleteCollection(options *metav1.DeleteOptions, listOptions metav1.ListOptions) error {\r\n\treturn nil\r\n}","code-length":49,"reference":"\/\/ DeleteCollection does nothing on a dry-run client","result":"Delete the entire object.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dryRunProwJobClient) Get(name string, options metav1.GetOptions) (*prowapi.ProwJob, error) {\r\n\treturn nil, nil\r\n}","code-length":55,"reference":"\/\/ Get does nothing on a dry-run client","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dryRunProwJobClient) List(opts metav1.ListOptions) (*prowapi.ProwJobList, error) {\r\n\tvar jl prowapi.ProwJobList\r\n\terr := c.request(\"\/prowjobs.js\", map[string]string{\"labelSelector\": opts.LabelSelector}, &jl)\r\n\treturn &jl, err\r\n}","code-length":102,"reference":"\/\/ List reaches out to `deck` to retrieve the ProwJobs on the cluster via proxy","result":"List all prowjobs in a single file.","score":[0.0515,0.0704]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dryRunProwJobClient) Watch(opts metav1.ListOptions) (watch.Interface, error) {\r\n\treturn nil, nil\r\n}","code-length":46,"reference":"\/\/ Watch does nothing on a dry-run client","result":"Watch for changes to the.","score":[0.1319,0.0649]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dryRunProwJobClient) Patch(name string, pt types.PatchType, data []byte, subresources ...string) (result *prowapi.ProwJob, err error) {\r\n\treturn nil, nil\r\n}","code-length":65,"reference":"\/\/ Patch does nothing on a dry-run client","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *controller) hasSynced() bool {\r\n\tif !c.pjInformer.HasSynced() {\r\n\t\tif c.wait != \"prowjobs\" {\r\n\t\t\tc.wait = \"prowjobs\"\r\n\t\t\tns := c.pjNamespace()\r\n\t\t\tif ns == \"\" {\r\n\t\t\t\tns = \"controllers\"\r\n\t\t\t}\r\n\t\t\tlogrus.Infof(\"Waiting on prowjobs in %s namespace...\", ns)\r\n\t\t}\r\n\t\treturn false\r\n\t}\r\n\tif !c.prowJobsDone {\r\n\t\tc.prowJobsDone = true\r\n\t\tlogrus.Info(\"Synced prow jobs\")\r\n\t}\r\n\tif c.pipelinesDone == nil {\r\n\t\tc.pipelinesDone = map[string]bool{}\r\n\t}\r\n\tfor n, cfg := range c.pipelines {\r\n\t\tif !cfg.informer.Informer().HasSynced() {\r\n\t\t\tif c.wait != n {\r\n\t\t\t\tc.wait = n\r\n\t\t\t\tlogrus.Infof(\"Waiting on %s pipelines...\", n)\r\n\t\t\t}\r\n\t\t\treturn false\r\n\t\t} else if !c.pipelinesDone[n] {\r\n\t\t\tc.pipelinesDone[n] = true\r\n\t\t\tlogrus.Infof(\"Synced %s pipelines\", n)\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":356,"reference":"\/\/ hasSynced returns true when every prowjob and pipeline informer has synced.","result":"Test if the controller hasSynced.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *controller) Run(threads int, stop <-chan struct{}) error {\r\n\tdefer runtime.HandleCrash()\r\n\tdefer c.workqueue.ShutDown()\r\n\tlogrus.Info(\"Starting Pipeline controller\")\r\n\tlogrus.Info(\"Waiting for informer caches to sync\")\r\n\tif ok := cache.WaitForCacheSync(stop, c.hasSynced); !ok {\r\n\t\treturn fmt.Errorf(\"failed to wait for caches to sync\")\r\n\t}\r\n\tlogrus.Info(\"Starting workers\")\r\n\tfor i := 0; i < threads; i++ {\r\n\t\tgo wait.Until(c.runWorker, time.Second, stop)\r\n\t}\r\n\tlogrus.Info(\"Started workers\")\r\n\t<-stop\r\n\tlogrus.Info(\"Shutting down workers\")\r\n\treturn nil\r\n}","code-length":209,"reference":"\/\/ Run starts threads workers, returning after receiving a stop signal.","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *controller) runWorker() {\r\n\tfor {\r\n\t\tkey, shutdown := c.workqueue.Get()\r\n\t\tif shutdown {\r\n\t\t\treturn\r\n\t\t}\r\n\t\tfunc() {\r\n\t\t\tdefer c.workqueue.Done(key)\r\n\t\t\tif err := reconcile(c, key.(string)); err != nil {\r\n\t\t\t\truntime.HandleError(fmt.Errorf(\"failed to reconcile %s: %v\", key, err))\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tc.workqueue.Forget(key)\r\n\t\t}()\r\n\t}\r\n}","code-length":160,"reference":"\/\/ runWorker dequeues to reconcile, until the queue has closed.","result":"Run the worker .","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc fromKey(key string) (string, string, string, error) {\r\n\tparts := strings.Split(key, \"\/\")\r\n\tif len(parts) != 3 {\r\n\t\treturn \"\", \"\", \"\", fmt.Errorf(\"bad key: %q\", key)\r\n\t}\r\n\treturn parts[0], parts[1], parts[2], nil\r\n}","code-length":94,"reference":"\/\/ fromKey converts toKey back into its parts","result":"Create a new key.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *controller) enqueueKey(ctx string, obj interface{}) {\r\n\tswitch o := obj.(type) {\r\n\tcase *prowjobv1.ProwJob:\r\n\t\tns := o.Spec.Namespace\r\n\t\tif ns == \"\" {\r\n\t\t\tns = o.Namespace\r\n\t\t}\r\n\t\tc.workqueue.AddRateLimited(toKey(ctx, ns, o.Name))\r\n\tcase *pipelinev1alpha1.PipelineRun:\r\n\t\tc.workqueue.AddRateLimited(toKey(ctx, o.Namespace, o.Name))\r\n\tdefault:\r\n\t\tlogrus.Warnf(\"cannot enqueue unknown type %T: %v\", o, obj)\r\n\t\treturn\r\n\t}\r\n}","code-length":192,"reference":"\/\/ enqueueKey schedules an item for reconciliation","result":"Register the key to the workqueue.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc finalState(status prowjobv1.ProwJobState) bool {\r\n\tswitch status {\r\n\tcase \"\", prowjobv1.PendingState, prowjobv1.TriggeredState:\r\n\t\treturn false\r\n\t}\r\n\treturn true\r\n}","code-length":75,"reference":"\/\/ finalState returns true if the prowjob has already finished","result":"Check if the final state is valid.","score":[0.1488,0.1933]}
{"code":"\/*is used to<extra_id_0>\r\nfunc description(cond duckv1alpha1.Condition, fallback string) string {\r\n\tswitch {\r\n\tcase cond.Message != \"\":\r\n\t\treturn cond.Message\r\n\tcase cond.Reason != \"\":\r\n\t\treturn cond.Reason\r\n\t}\r\n\treturn fallback\r\n}","code-length":80,"reference":"\/\/ description computes the ProwJobStatus description for this condition or falling back to a default if none is provided.","result":"Generate the description.","score":[0.002,0.0287]}
{"code":"\/*is used to<extra_id_0>\r\nfunc prowJobStatus(ps pipelinev1alpha1.PipelineRunStatus) (prowjobv1.ProwJobState, string) {\r\n\tstarted := ps.StartTime\r\n\tfinished := ps.CompletionTime\r\n\tpcond := ps.GetCondition(duckv1alpha1.ConditionSucceeded)\r\n\tif pcond == nil {\r\n\t\tif !finished.IsZero() {\r\n\t\t\treturn prowjobv1.ErrorState, descMissingCondition\r\n\t\t}\r\n\t\treturn prowjobv1.TriggeredState, descScheduling\r\n\t}\r\n\tcond := *pcond\r\n\tswitch {\r\n\tcase cond.Status == untypedcorev1.ConditionTrue:\r\n\t\treturn prowjobv1.SuccessState, description(cond, descSucceeded)\r\n\tcase cond.Status == untypedcorev1.ConditionFalse:\r\n\t\treturn prowjobv1.FailureState, description(cond, descFailed)\r\n\tcase started.IsZero():\r\n\t\treturn prowjobv1.TriggeredState, description(cond, descInitializing)\r\n\tcase cond.Status == untypedcorev1.ConditionUnknown, finished.IsZero():\r\n\t\treturn prowjobv1.PendingState, description(cond, descRunning)\r\n\t}\r\n\tlogrus.Warnf(\"Unknown condition %#v\", cond)\r\n\treturn prowjobv1.ErrorState, description(cond, descUnknown)\r\n}","code-length":346,"reference":"\/\/ prowJobStatus returns the desired state and description based on the pipeline status","result":"Generate the prow job status .","score":[0.0715,0.0813]}
{"code":"\/*is used to<extra_id_0>\r\nfunc pipelineMeta(pj prowjobv1.ProwJob) metav1.ObjectMeta {\r\n\tlabels, annotations := decorate.LabelsAndAnnotationsForJob(pj)\r\n\treturn metav1.ObjectMeta{\r\n\t\tAnnotations: annotations,\r\n\t\tName:        pj.Name,\r\n\t\tNamespace:   pj.Spec.Namespace,\r\n\t\tLabels:      labels,\r\n\t}\r\n}","code-length":109,"reference":"\/\/ pipelineMeta builds the pipeline metadata from prow job definition","result":"Generate the pipeline meta .","score":[0.125,0.1974]}
{"code":"\/*is used to<extra_id_0>\r\nfunc sourceURL(pj prowjobv1.ProwJob) string {\r\n\tif pj.Spec.Refs == nil {\r\n\t\treturn \"\"\r\n\t}\r\n\tsourceURL := pj.Spec.Refs.CloneURI\r\n\tif sourceURL == \"\" {\r\n\t\tsourceURL = fmt.Sprintf(\"%s.git\", pj.Spec.Refs.RepoLink)\r\n\t}\r\n\treturn sourceURL\r\n}","code-length":113,"reference":"\/\/ sourceURL returns the source URL from prow jobs repository reference","result":"Generate the sourceURL function.","score":[0.066,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc makePipelineGitResource(pj prowjobv1.ProwJob) *pipelinev1alpha1.PipelineResource {\r\n\tvar revision string\r\n\tif pj.Spec.Refs != nil {\r\n\t\tif len(pj.Spec.Refs.Pulls) > 0 {\r\n\t\t\trevision = pj.Spec.Refs.Pulls[0].SHA\r\n\t\t} else {\r\n\t\t\trevision = pj.Spec.Refs.BaseSHA\r\n\t\t}\r\n\t}\r\n\tpr := pipelinev1alpha1.PipelineResource{\r\n\t\tObjectMeta: pipelineMeta(pj),\r\n\t\tSpec: pipelinev1alpha1.PipelineResourceSpec{\r\n\t\t\tType: pipelinev1alpha1.PipelineResourceTypeGit,\r\n\t\t\tParams: []pipelinev1alpha1.Param{\r\n\t\t\t\t{\r\n\t\t\t\t\tName:  \"url\",\r\n\t\t\t\t\tValue: sourceURL(pj),\r\n\t\t\t\t},\r\n\t\t\t\t{\r\n\t\t\t\t\tName:  \"revision\",\r\n\t\t\t\t\tValue: revision,\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n\treturn &pr\r\n}","code-length":283,"reference":"\/\/ makePipelineGitResource creates a pipeline git resource from prow job","result":"Create a pipeline resource for a git repository.","score":[0.1819,0.2551]}
{"code":"\/*is used to<extra_id_0>\r\nfunc makePipelineRun(pj prowjobv1.ProwJob, pr *pipelinev1alpha1.PipelineResource) (*pipelinev1alpha1.PipelineRun, error) {\r\n\tif pj.Spec.PipelineRunSpec == nil {\r\n\t\treturn nil, errors.New(\"no PipelineSpec defined\")\r\n\t}\r\n\tp := pipelinev1alpha1.PipelineRun{\r\n\t\tObjectMeta: pipelineMeta(pj),\r\n\t\tSpec:       *pj.Spec.PipelineRunSpec.DeepCopy(),\r\n\t}\r\n\tbuildID := pj.Status.BuildID\r\n\tif buildID == \"\" {\r\n\t\treturn nil, errors.New(\"empty BuildID in status\")\r\n\t}\r\n\tp.Spec.Params = append(p.Spec.Params, pipelinev1alpha1.Param{\r\n\t\tName:  \"build_id\",\r\n\t\tValue: buildID,\r\n\t})\r\n\trb := pipelinev1alpha1.PipelineResourceBinding{\r\n\t\tName: pr.Name,\r\n\t\tResourceRef: pipelinev1alpha1.PipelineResourceRef{\r\n\t\t\tName:       pr.Name,\r\n\t\t\tAPIVersion: pr.APIVersion,\r\n\t\t},\r\n\t}\r\n\tp.Spec.Resources = append(p.Spec.Resources, rb)\r\n\treturn &p, nil\r\n}","code-length":333,"reference":"\/\/ makePipeline creates a PipelineRun from a prow job using the PipelineRunSpec defined in the prow job","result":"Create a pipeline run .","score":[0.0218,0.0633]}
{"code":"\/*is used to<extra_id_0>\r\nfunc matchingConfigs(org, repo, branch, label string, allConfigs []plugins.RequireMatchingLabel) []plugins.RequireMatchingLabel {\r\n\tvar filtered []plugins.RequireMatchingLabel\r\n\tfor _, cfg := range allConfigs {\r\n\t\t\r\n\t\tif (branch == \"\" && !cfg.Issues) || (branch != \"\" && !cfg.PRs) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tif org != cfg.Org ||\r\n\t\t\t(cfg.Repo != \"\" && cfg.Repo != repo) ||\r\n\t\t\t(cfg.Branch != \"\" && branch != \"\" && cfg.Branch != branch) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tif label != \"\" && !cfg.Re.MatchString(label) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tfiltered = append(filtered, cfg)\r\n\t}\r\n\treturn filtered\r\n}","code-length":223,"reference":"\/\/ matchingConfigs filters irrelevant RequireMtchingLabel configs from\n\/\/ the list of all configs.\n\/\/ `branch` should be empty for Issues and non-empty for PRs.\n\/\/ `label` should be omitted in the case of 'open' and 'reopen' actions.","result":"Filter the list of allConfigs to only return matching configs.","score":[0.0161,0.0729]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SuggestCodeChange(p lint.Problem) string {\r\n\tvar suggestion = \"\"\r\n\tfor regex, handler := range lintHandlersMap {\r\n\t\tmatches := regex.FindStringSubmatch(p.Text)\r\n\t\tsuggestion = handler(p, matches)\r\n\t\tif suggestion != \"\" && suggestion != p.LineText {\r\n\t\t\treturn formatSuggestion(suggestion)\r\n\t\t}\r\n\t}\r\n\treturn \"\"\r\n}","code-length":115,"reference":"\/\/ SuggestCodeChange returns code suggestions for a given lint.Problem\n\/\/ Returns empty string if no suggestion can be given","result":"Suggest code change.","score":[0.002,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ServeExternalPluginHelp(mux *http.ServeMux, log *logrus.Entry, provider ExternalPluginHelpProvider) {\r\n\tmux.HandleFunc(\r\n\t\t\"\/help\",\r\n\t\tfunc(w http.ResponseWriter, r *http.Request) {\r\n\t\t\tw.Header().Set(\"Cache-Control\", \"no-cache\")\r\n\t\t\tserverError := func(action string, err error) {\r\n\t\t\t\tlog.WithError(err).Errorf(\"Error %s.\", action)\r\n\t\t\t\tmsg := fmt.Sprintf(\"500 Internal server error %s: %v\", action, err)\r\n\t\t\t\thttp.Error(w, msg, http.StatusInternalServerError)\r\n\t\t\t}\r\n\t\t\tif r.Method != http.MethodPost {\r\n\t\t\t\tlog.Errorf(\"Invalid request method: %v.\", r.Method)\r\n\t\t\t\thttp.Error(w, \"405 Method not allowed\", http.StatusMethodNotAllowed)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tb, err := ioutil.ReadAll(r.Body)\r\n\t\t\tif err != nil {\r\n\t\t\t\tserverError(\"reading request body\", err)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tvar enabledRepos []string\r\n\t\t\tif err := json.Unmarshal(b, &enabledRepos); err != nil {\r\n\t\t\t\tserverError(\"unmarshaling request body\", err)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tif provider == nil {\r\n\t\t\t\tserverError(\"generating plugin help\", errors.New(\"help provider is nil\"))\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\thelp, err := provider(enabledRepos)\r\n\t\t\tif err != nil {\r\n\t\t\t\tserverError(\"generating plugin help\", err)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tb, err = json.Marshal(help)\r\n\t\t\tif err != nil {\r\n\t\t\t\tserverError(\"marshaling plugin help\", err)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tfmt.Fprint(w, string(b))\r\n\t\t},\r\n\t)\r\n}","code-length":506,"reference":"\/\/ ServeExternalPluginHelp returns a HandlerFunc that serves plugin help information that is\n\/\/ provided by the specified ExternalPluginHelpProvider.","result":"Serve external plugin help.","score":[0.0096,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *protector) protect() {\r\n\tbp := p.cfg.BranchProtection\r\n\t\r\n\tfor orgName := range bp.Orgs {\r\n\t\torg := bp.GetOrg(orgName)\r\n\t\tif err := p.UpdateOrg(orgName, *org); err != nil {\r\n\t\t\tp.errors.add(fmt.Errorf(\"update %s: %v\", orgName, err))\r\n\t\t}\r\n\t}\r\n\t\r\n\tif !bp.ProtectTested {\r\n\t\treturn\r\n\t}\r\n\t\r\n\tfor repo := range p.cfg.Presubmits {\r\n\t\tif p.completedRepos[repo] == true {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tparts := strings.Split(repo, \"\/\")\r\n\t\tif len(parts) != 2 {\r\n\t\t\tp.errors.add(fmt.Errorf(\"bad presubmit repo: %s\", repo))\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\torgName := parts[0]\r\n\t\trepoName := parts[1]\r\n\t\trepo := bp.GetOrg(orgName).GetRepo(repoName)\r\n\t\tif err := p.UpdateRepo(orgName, repoName, *repo); err != nil {\r\n\t\t\tp.errors.add(fmt.Errorf(\"update %s\/%s: %v\", orgName, repoName, err))\r\n\t\t}\r\n\t}\r\n}","code-length":354,"reference":"\/\/ protect protects branches specified in the presubmit and branch-protection config sections.","result":"Protect branch.","score":[0,0.0455]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *protector) UpdateOrg(orgName string, org config.Org) error {\r\n\tvar repos []string\r\n\tif org.Protect != nil {\r\n\t\t\r\n\t\trs, err := p.client.GetRepos(orgName, false)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"list repos: %v\", err)\r\n\t\t}\r\n\t\tfor _, r := range rs {\r\n\t\t\tif !r.Archived {\r\n\t\t\t\trepos = append(repos, r.Name)\r\n\t\t\t}\r\n\t\t}\r\n\t} else {\r\n\t\t\r\n\t\tfor r := range org.Repos {\r\n\t\t\trepos = append(repos, r)\r\n\t\t}\r\n\t}\r\n\tfor _, repoName := range repos {\r\n\t\trepo := org.GetRepo(repoName)\r\n\t\tif err := p.UpdateRepo(orgName, repoName, *repo); err != nil {\r\n\t\t\treturn fmt.Errorf(\"update %s: %v\", repoName, err)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":279,"reference":"\/\/ UpdateOrg updates all repos in the org with the specified defaults","result":"Update org config.","score":[0.0203,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *protector) UpdateRepo(orgName string, repoName string, repo config.Repo) error {\r\n\tp.completedRepos[orgName+\"\/\"+repoName] = true\r\n\tgithubRepo, err := p.client.GetRepo(orgName, repoName)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"could not get repo to check for archival: %v\", err)\r\n\t}\r\n\tif githubRepo.Archived {\r\n\t\t\r\n\t\treturn nil\r\n\t}\r\n\tbranches := map[string]github.Branch{}\r\n\tfor _, onlyProtected := range []bool{false, true} {\r\n\t\tbs, err := p.client.GetBranches(orgName, repoName, onlyProtected)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"list branches: %v\", err)\r\n\t\t}\r\n\t\tfor _, b := range bs {\r\n\t\t\tbranches[b.Name] = b\r\n\t\t}\r\n\t}\r\n\tfor bn, githubBranch := range branches {\r\n\t\tif branch, err := repo.GetBranch(bn); err != nil {\r\n\t\t\treturn fmt.Errorf(\"get %s: %v\", bn, err)\r\n\t\t} else if err = p.UpdateBranch(orgName, repoName, bn, *branch, githubBranch.Protected); err != nil {\r\n\t\t\treturn fmt.Errorf(\"update %s from protected=%t: %v\", bn, githubBranch.Protected, err)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":383,"reference":"\/\/ UpdateRepo updates all branches in the repo with the specified defaults","result":"Protect the repo.","score":[0.0203,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *protector) UpdateBranch(orgName, repo string, branchName string, branch config.Branch, protected bool) error {\r\n\tbp, err := p.cfg.GetPolicy(orgName, repo, branchName, branch)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"get policy: %v\", err)\r\n\t}\r\n\tif bp == nil || bp.Protect == nil {\r\n\t\treturn nil\r\n\t}\r\n\tif !protected && !*bp.Protect {\r\n\t\tlogrus.Infof(\"%s\/%s=%s: already unprotected\", orgName, repo, branchName)\r\n\t\treturn nil\r\n\t}\r\n\tvar req *github.BranchProtectionRequest\r\n\tif *bp.Protect {\r\n\t\tr := makeRequest(*bp)\r\n\t\treq = &r\r\n\t}\r\n\tp.updates <- requirements{\r\n\t\tOrg:     orgName,\r\n\t\tRepo:    repo,\r\n\t\tBranch:  branchName,\r\n\t\tRequest: req,\r\n\t}\r\n\treturn nil\r\n}","code-length":263,"reference":"\/\/ UpdateBranch updates the branch with the specified configuration","result":"BranchConfig config.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *Options) LoadConfig(config string) error {\r\n\treturn json.Unmarshal([]byte(config), o)\r\n}","code-length":41,"reference":"\/\/ LoadConfig loads options from serialized config","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *Options) Run() error {\r\n\tclusterConfig, err := loadClusterConfig()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to load cluster config: %v\", err)\r\n\t}\r\n\tclient, err := kubernetes.NewForConfig(clusterConfig)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tprowJobClient, err := kube.NewClientInCluster(o.ProwJobNamespace)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tcontroller := artifact_uploader.NewController(client.CoreV1(), prowJobClient, o.Options)\r\n\tstop := make(chan struct{})\r\n\tdefer close(stop)\r\n\tgo controller.Run(o.NumWorkers, stop)\r\n\t\r\n\tselect {}\r\n}","code-length":210,"reference":"\/\/ Run uploads artifacts with the specified options forever.\n\/\/\n\/\/ Sends a stop message to the artifact uploader when it is interrupted.","result":"Run the controller.","score":[0.0006,0.0476]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Agent) Start(paths []string) error {\r\n\tsecretsMap, err := LoadSecrets(paths)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ta.secretsMap = secretsMap\r\n\t\r\n\tfor secretPath := range secretsMap {\r\n\t\tgo a.reloadSecret(secretPath)\r\n\t}\r\n\treturn nil\r\n}","code-length":105,"reference":"\/\/ Start creates goroutines to monitor the files that contain the secret value.","result":"Start the agent.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Agent) reloadSecret(secretPath string) {\r\n\tvar lastModTime time.Time\r\n\tlogger := logrus.NewEntry(logrus.StandardLogger())\r\n\tskips := 0\r\n\tfor range time.Tick(1 * time.Second) {\r\n\t\tif skips < 600 {\r\n\t\t\t\r\n\t\t\tsecretStat, err := os.Stat(secretPath)\r\n\t\t\tif err != nil {\r\n\t\t\t\tlogger.WithField(\"secret-path\", secretPath).\r\n\t\t\t\t\tWithError(err).Error(\"Error loading secret file.\")\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\trecentModTime := secretStat.ModTime()\r\n\t\t\tif !recentModTime.After(lastModTime) {\r\n\t\t\t\tskips++\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tlastModTime = recentModTime\r\n\t\t}\r\n\t\tif secretValue, err := LoadSingleSecret(secretPath); err != nil {\r\n\t\t\tlogger.WithField(\"secret-path: \", secretPath).\r\n\t\t\t\tWithError(err).Error(\"Error loading secret.\")\r\n\t\t} else {\r\n\t\t\ta.setSecret(secretPath, secretValue)\r\n\t\t\tskips = 0\r\n\t\t}\r\n\t}\r\n}","code-length":310,"reference":"\/\/ reloadSecret will begin polling the secret file at the path. If the first load\n\/\/ fails, Start with return the error and abort. Future load failures will log\n\/\/ the failure message but continue attempting to load.","result":"Reload secret from file.","score":[0.0001,0.0145]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Agent) GetSecret(secretPath string) []byte {\r\n\ta.RLock()\r\n\tdefer a.RUnlock()\r\n\treturn a.secretsMap[secretPath]\r\n}","code-length":58,"reference":"\/\/ GetSecret returns the value of a secret stored in a map.","result":"Generate the generated code.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Agent) setSecret(secretPath string, secretValue []byte) {\r\n\ta.Lock()\r\n\tdefer a.Unlock()\r\n\ta.secretsMap[secretPath] = secretValue\r\n}","code-length":61,"reference":"\/\/ setSecret sets a value in a map of secrets.","result":"Set secret in the agent.","score":[0.0884,0.1053]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Agent) GetTokenGenerator(secretPath string) func() []byte {\r\n\treturn func() []byte {\r\n\t\treturn a.GetSecret(secretPath)\r\n\t}\r\n}","code-length":57,"reference":"\/\/ GetTokenGenerator returns a function that gets the value of a given secret.","result":"Generate tokens.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(maxRecordsPerKey int, opener io.Opener, path string) (*History, error) {\r\n\thist := &History{\r\n\t\tlogs:         map[string]*recordLog{},\r\n\t\tlogSizeLimit: maxRecordsPerKey,\r\n\t\topener:       opener,\r\n\t\tpath:         path,\r\n\t}\r\n\tif path != \"\" {\r\n\t\t\r\n\t\tvar err error\r\n\t\tstart := time.Now()\r\n\t\thist.logs, err = readHistory(maxRecordsPerKey, hist.opener, hist.path)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tlogrus.WithFields(logrus.Fields{\r\n\t\t\t\"duration\": time.Since(start).String(),\r\n\t\t\t\"path\":     hist.path,\r\n\t\t}).Debugf(\"Successfully read action history for %d pools.\", len(hist.logs))\r\n\t}\r\n\treturn hist, nil\r\n}","code-length":248,"reference":"\/\/ New creates a new History struct with the specificed recordLog size limit.","result":"Create a new history object.","score":[0.0686,0.3253]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *History) Record(poolKey, action, baseSHA, err string, targets []prowapi.Pull) {\r\n\tt := now()\r\n\tsort.Sort(ByNum(targets))\r\n\th.addRecord(\r\n\t\tpoolKey,\r\n\t\t&Record{\r\n\t\t\tTime:    t,\r\n\t\t\tAction:  action,\r\n\t\t\tBaseSHA: baseSHA,\r\n\t\t\tTarget:  targets,\r\n\t\t\tErr:     err,\r\n\t\t},\r\n\t)\r\n}","code-length":136,"reference":"\/\/ Record appends an entry to the recordlog specified by the poolKey.","result":"Record the state of a pool.","score":[0.0845,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *History) ServeHTTP(w http.ResponseWriter, r *http.Request) {\r\n\tb, err := json.Marshal(h.AllRecords())\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Error(\"Encoding JSON history.\")\r\n\t\tb = []byte(\"{}\")\r\n\t}\r\n\tif _, err = w.Write(b); err != nil {\r\n\t\tlogrus.WithError(err).Error(\"Writing JSON history response.\")\r\n\t}\r\n}","code-length":131,"reference":"\/\/ ServeHTTP serves a JSON mapping from pool key -> sorted records for the pool.","result":"Serve the history request.","score":[0.0204,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *History) Flush() {\r\n\tif h.path == \"\" {\r\n\t\treturn\r\n\t}\r\n\trecords := h.AllRecords()\r\n\tstart := time.Now()\r\n\terr := writeHistory(h.opener, h.path, records)\r\n\tlog := logrus.WithFields(logrus.Fields{\r\n\t\t\"duration\": time.Since(start).String(),\r\n\t\t\"path\":     h.path,\r\n\t})\r\n\tif err != nil {\r\n\t\tlog.WithError(err).Error(\"Error flushing action history to GCS.\")\r\n\t} else {\r\n\t\tlog.Debugf(\"Successfully flushed action history for %d pools.\", len(h.logs))\r\n\t}\r\n}","code-length":185,"reference":"\/\/ Flush writes the action history to persistent storage if configured to do so.","result":"Flush the action history to GCS.","score":[0.1684,0.3379]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *History) AllRecords() map[string][]*Record {\r\n\th.Lock()\r\n\tdefer h.Unlock()\r\n\tres := make(map[string][]*Record, len(h.logs))\r\n\tfor key, log := range h.logs {\r\n\t\tres[key] = log.toSlice()\r\n\t}\r\n\treturn res\r\n}","code-length":99,"reference":"\/\/ AllRecords generates a map from pool key -> sorted records for the pool.","result":"Return all records in the history.","score":[0.0605,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MakeCommand() *cobra.Command {\r\n\tflags := &flags{}\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"download [bucket] [prowjob]\",\r\n\t\tShort: \"Finds and downloads the coverage profile file from the latest healthy build\",\r\n\t\tLong: `Finds and downloads the coverage profile file from the latest healthy build \r\nstored in given gcs directory.`,\r\n\t\tRun: func(cmd *cobra.Command, args []string) {\r\n\t\t\trun(flags, cmd, args)\r\n\t\t},\r\n\t}\r\n\tcmd.Flags().StringVarP(&flags.outputFile, \"output\", \"o\", \"-\", \"output file\")\r\n\tcmd.Flags().StringVarP(&flags.artifactsDirName, \"artifactsDir\", \"a\", \"artifacts\", \"artifact directory name in GCS\")\r\n\tcmd.Flags().StringVarP(&flags.profileName, \"profile\", \"p\", \"coverage-profile\", \"code coverage profile file name in GCS\")\r\n\treturn cmd\r\n}","code-length":256,"reference":"\/\/ MakeCommand returns a `download` command.","result":"Generate code coverage profile file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *CommentCounterPlugin) CheckFlags() error {\r\n\tfor _, pattern := range c.pattern {\r\n\t\tmatcher, err := regexp.Compile(pattern)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tc.matcher = append(c.matcher, matcher)\r\n\t}\r\n\treturn nil\r\n}","code-length":97,"reference":"\/\/ CheckFlags looks for comments matching regexes","result":"Generate a comment counter.","score":[0,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *CommentCounterPlugin) ReceiveComment(comment sql.Comment) []Point {\r\n\tpoints := []Point{}\r\n\tfor _, matcher := range c.matcher {\r\n\t\tif matcher.MatchString(comment.Body) {\r\n\t\t\tpoints = append(points, Point{\r\n\t\t\t\tValues: map[string]interface{}{\r\n\t\t\t\t\t\"comment\": 1,\r\n\t\t\t\t},\r\n\t\t\t\tDate: comment.CommentCreatedAt,\r\n\t\t\t})\r\n\t\t}\r\n\t}\r\n\treturn points\r\n}","code-length":136,"reference":"\/\/ ReceiveComment adds matching comments to InfluxDB","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewController(\r\n\tpjclientset clientset.Interface,\r\n\tqueue workqueue.RateLimitingInterface,\r\n\tinformer pjinformers.ProwJobInformer,\r\n\treporter reportClient,\r\n\tnumWorkers int,\r\n\twg *sync.WaitGroup) *Controller {\r\n\treturn &Controller{\r\n\t\tpjclientset: pjclientset,\r\n\t\tqueue:       queue,\r\n\t\tinformer:    informer,\r\n\t\treporter:    reporter,\r\n\t\tnumWorkers:  numWorkers,\r\n\t\twg:          wg,\r\n\t}\r\n}","code-length":157,"reference":"\/\/ NewController constructs a new instance of the crier controller.","result":"Create a new controller.","score":[0.1116,0.2719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) Run(stopCh <-chan struct{}) {\r\n\t\r\n\tdefer utilruntime.HandleCrash()\r\n\t\r\n\t\r\n\tdefer c.queue.ShutDown()\r\n\tlogrus.Info(\"Initiating controller\")\r\n\tc.informer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{\r\n\t\tAddFunc: func(obj interface{}) {\r\n\t\t\tkey, err := cache.MetaNamespaceKeyFunc(obj)\r\n\t\t\tlogrus.WithField(\"prowjob\", key).Infof(\"Add prowjob\")\r\n\t\t\tif err != nil {\r\n\t\t\t\tlogrus.WithError(err).Error(\"Cannot get key from object meta\")\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tc.queue.AddRateLimited(key)\r\n\t\t},\r\n\t\tUpdateFunc: func(oldObj, newObj interface{}) {\r\n\t\t\tkey, err := cache.MetaNamespaceKeyFunc(newObj)\r\n\t\t\tlogrus.WithField(\"prowjob\", key).Infof(\"Update prowjob\")\r\n\t\t\tif err != nil {\r\n\t\t\t\tlogrus.WithError(err).Error(\"Cannot get key from object meta\")\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tc.queue.AddRateLimited(key)\r\n\t\t},\r\n\t})\r\n\t\r\n\tgo c.informer.Informer().Run(stopCh)\r\n\t\r\n\tif !cache.WaitForCacheSync(stopCh, c.HasSynced) {\r\n\t\tutilruntime.HandleError(fmt.Errorf(\"Error syncing cache\"))\r\n\t\treturn\r\n\t}\r\n\tlogrus.Info(\"Controller.Run: cache sync complete\")\r\n\t\r\n\tfor i := 0; i < c.numWorkers; i++ {\r\n\t\tgo wait.Until(c.runWorker, time.Second, stopCh)\r\n\t}\r\n\tlogrus.Infof(\"Started %d workers\", c.numWorkers)\r\n\t<-stopCh\r\n\tlogrus.Info(\"Shutting down workers\")\r\n}","code-length":495,"reference":"\/\/ Run is the main path of execution for the controller loop.","result":"Run the controller .","score":[0.0677,0.2282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) runWorker() {\r\n\tc.wg.Add(1)\r\n\tfor c.processNextItem() {\r\n\t}\r\n\tc.wg.Done()\r\n}","code-length":57,"reference":"\/\/ runWorker executes the loop to process new items added to the queue.","result":"Run the worker.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New() (*LocalGit, *git.Client, error) {\r\n\tg, err := exec.LookPath(\"git\")\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\tt, err := ioutil.TempDir(\"\", \"localgit\")\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\tc, err := git.NewClient()\r\n\tif err != nil {\r\n\t\tos.RemoveAll(t)\r\n\t\treturn nil, nil, err\r\n\t}\r\n\tgetSecret := func() []byte {\r\n\t\treturn []byte(\"\")\r\n\t}\r\n\tc.SetCredentials(\"\", getSecret)\r\n\tc.SetRemote(t)\r\n\treturn &LocalGit{\r\n\t\tDir: t,\r\n\t\tGit: g,\r\n\t}, c, nil\r\n}","code-length":223,"reference":"\/\/ New creates a LocalGit and a git.Client pointing at it.","result":"Create a new instance of the local git repository.","score":[0.0976,0.1389]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lg *LocalGit) MakeFakeRepo(org, repo string) error {\r\n\trdir := filepath.Join(lg.Dir, org, repo)\r\n\tif err := os.MkdirAll(rdir, os.ModePerm); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := runCmd(lg.Git, rdir, \"init\"); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := runCmd(lg.Git, rdir, \"config\", \"user.email\", \"test@test.test\"); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := runCmd(lg.Git, rdir, \"config\", \"user.name\", \"test test\"); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := runCmd(lg.Git, rdir, \"config\", \"commit.gpgsign\", \"false\"); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := lg.AddCommit(org, repo, map[string][]byte{\"initial\": {}}); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":290,"reference":"\/\/ MakeFakeRepo creates the given repo and makes an initial commit.","result":"Generate the code.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lg *LocalGit) AddCommit(org, repo string, files map[string][]byte) error {\r\n\trdir := filepath.Join(lg.Dir, org, repo)\r\n\tfor f, b := range files {\r\n\t\tpath := filepath.Join(rdir, f)\r\n\t\tif err := os.MkdirAll(filepath.Dir(path), os.ModePerm); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif err := ioutil.WriteFile(path, b, os.ModePerm); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif err := runCmd(lg.Git, rdir, \"add\", f); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn runCmd(lg.Git, rdir, \"commit\", \"-m\", \"wow\")\r\n}","code-length":221,"reference":"\/\/ AddCommit adds the files to a new commit in the repo.","result":"Add files to a commit.","score":[0.122,0.3319]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lg *LocalGit) CheckoutNewBranch(org, repo, branch string) error {\r\n\trdir := filepath.Join(lg.Dir, org, repo)\r\n\treturn runCmd(lg.Git, rdir, \"checkout\", \"-b\", branch)\r\n}","code-length":72,"reference":"\/\/ CheckoutNewBranch does git checkout -b.","result":"Create a new branch.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lg *LocalGit) Checkout(org, repo, commitlike string) error {\r\n\trdir := filepath.Join(lg.Dir, org, repo)\r\n\treturn runCmd(lg.Git, rdir, \"checkout\", commitlike)\r\n}","code-length":69,"reference":"\/\/ Checkout does git checkout.","result":"Create a local git repository.","score":[0.2403,0.1]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lg *LocalGit) RevParse(org, repo, commitlike string) (string, error) {\r\n\trdir := filepath.Join(lg.Dir, org, repo)\r\n\treturn runCmdOutput(lg.Git, rdir, \"rev-parse\", commitlike)\r\n}","code-length":77,"reference":"\/\/ RevParse does git rev-parse.","result":"Generate the rev.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CleanAll(sess *session.Session, region string) error {\r\n\tacct, err := account.GetAccount(sess, regions.Default)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Failed to retrieve account\")\r\n\t}\r\n\tklog.V(1).Infof(\"Account: %s\", acct)\r\n\tvar regionList []string\r\n\tif region == \"\" {\r\n\t\tregionList, err = regions.GetAll(sess)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Couldn't retrieve list of regions\")\r\n\t\t}\r\n\t} else {\r\n\t\tregionList = []string{region}\r\n\t}\r\n\tklog.Infof(\"Regions: %+v\", regionList)\r\n\tfor _, r := range regionList {\r\n\t\tfor _, typ := range RegionalTypeList {\r\n\t\t\tset, err := typ.ListAll(sess, acct, r)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn errors.Wrapf(err, \"Failed to list resources of type %T\", typ)\r\n\t\t\t}\r\n\t\t\tif err := typ.MarkAndSweep(sess, acct, r, set); err != nil {\r\n\t\t\t\treturn errors.Wrapf(err, \"Couldn't sweep resources of type %T\", typ)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tfor _, typ := range GlobalTypeList {\r\n\t\tset, err := typ.ListAll(sess, acct, regions.Default)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"Failed to list resources of type %T\", typ)\r\n\t\t}\r\n\t\tif err := typ.MarkAndSweep(sess, acct, regions.Default, set); err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"Couldn't sweep resources of type %T\", typ)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":485,"reference":"\/\/ CleanAll cleans all of the resources for all of the regions visible to\n\/\/ the provided AWS session.","result":"Clean all resources in a region.","score":[0.0263,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc optionsForRepo(config *plugins.Configuration, org, repo string) *plugins.Lgtm {\r\n\tfullName := fmt.Sprintf(\"%s\/%s\", org, repo)\r\n\tfor i := range config.Lgtm {\r\n\t\tif !strInSlice(org, config.Lgtm[i].Repos) && !strInSlice(fullName, config.Lgtm[i].Repos) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\treturn &config.Lgtm[i]\r\n\t}\r\n\treturn &plugins.Lgtm{}\r\n}","code-length":148,"reference":"\/\/ optionsForRepo gets the plugins.Lgtm struct that is applicable to the indicated repo.","result":"Get options for a specific repo.","score":[0.0601,0.0813]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getChangedFiles(gc githubClient, org, repo string, number int) ([]string, error) {\r\n\tchanges, err := gc.GetPullRequestChanges(org, repo, number)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"cannot get PR changes for %s\/%s#%d\", org, repo, number)\r\n\t}\r\n\tvar filenames []string\r\n\tfor _, change := range changes {\r\n\t\tfilenames = append(filenames, change.Filename)\r\n\t}\r\n\treturn filenames, nil\r\n}","code-length":140,"reference":"\/\/ getChangedFiles returns all the changed files for the provided pull request.","result":"Get the changed files from the github API.","score":[0.1864,0.3233]}
{"code":"\/*is used to<extra_id_0>\r\nfunc loadReviewers(ro repoowners.RepoOwner, filenames []string) sets.String {\r\n\treviewers := sets.String{}\r\n\tfor _, filename := range filenames {\r\n\t\treviewers = reviewers.Union(ro.Approvers(filename)).Union(ro.Reviewers(filename))\r\n\t}\r\n\treturn reviewers\r\n}","code-length":93,"reference":"\/\/ loadReviewers returns all reviewers and approvers from all OWNERS files that\n\/\/ cover the provided filenames.","result":"Load reviewers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewController(lastSyncFallback, cookiefilePath string, projects map[string][]string, kc *kube.Client, cfg config.Getter) (*Controller, error) {\r\n\tif lastSyncFallback == \"\" {\r\n\t\treturn nil, errors.New(\"empty lastSyncFallback\")\r\n\t}\r\n\tvar lastUpdate time.Time\r\n\tif buf, err := ioutil.ReadFile(lastSyncFallback); err == nil {\r\n\t\tunix, err := strconv.ParseInt(string(buf), 10, 64)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tlastUpdate = time.Unix(unix, 0)\r\n\t} else if err != nil && !os.IsNotExist(err) {\r\n\t\treturn nil, fmt.Errorf(\"failed to read lastSyncFallback: %v\", err)\r\n\t} else {\r\n\t\tlogrus.Warnf(\"lastSyncFallback not found: %s\", lastSyncFallback)\r\n\t\tlastUpdate = time.Now()\r\n\t}\r\n\tc, err := client.NewClient(projects)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tc.Start(cookiefilePath)\r\n\treturn &Controller{\r\n\t\tkc:               kc,\r\n\t\tconfig:           cfg,\r\n\t\tgc:               c,\r\n\t\tlastUpdate:       lastUpdate,\r\n\t\tlastSyncFallback: lastSyncFallback,\r\n\t}, nil\r\n}","code-length":361,"reference":"\/\/ NewController returns a new gerrit controller client","result":"Create a new controller.","score":[0.1662,0.2467]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) SaveLastSync(lastSync time.Time) error {\r\n\tif c.lastSyncFallback == \"\" {\r\n\t\treturn nil\r\n\t}\r\n\tlastSyncUnix := strconv.FormatInt(lastSync.Unix(), 10)\r\n\tlogrus.Infof(\"Writing last sync: %s\", lastSyncUnix)\r\n\ttempFile, err := ioutil.TempFile(filepath.Dir(c.lastSyncFallback), \"temp\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer os.Remove(tempFile.Name())\r\n\terr = ioutil.WriteFile(tempFile.Name(), []byte(lastSyncUnix), 0644)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = os.Rename(tempFile.Name(), c.lastSyncFallback)\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Info(\"Rename failed, fallback to copyfile\")\r\n\t\treturn copyFile(tempFile.Name(), c.lastSyncFallback)\r\n\t}\r\n\treturn nil\r\n}","code-length":264,"reference":"\/\/ SaveLastSync saves last sync time in Unix to a volume","result":"Save the last sync time.","score":[0.1023,0.2457]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) Sync() error {\r\n\tsyncTime := c.lastUpdate\r\n\tfor instance, changes := range c.gc.QueryChanges(c.lastUpdate, c.config().Gerrit.RateLimit) {\r\n\t\tfor _, change := range changes {\r\n\t\t\tif err := c.ProcessChange(instance, change); err != nil {\r\n\t\t\t\tlogrus.WithError(err).Errorf(\"Failed process change %v\", change.CurrentRevision)\r\n\t\t\t}\r\n\t\t\tif syncTime.Before(change.Updated.Time) {\r\n\t\t\t\tsyncTime = change.Updated.Time\r\n\t\t\t}\r\n\t\t}\r\n\t\tlogrus.Infof(\"Processed %d changes for instance %s\", len(changes), instance)\r\n\t}\r\n\tc.lastUpdate = syncTime\r\n\tif err := c.SaveLastSync(syncTime); err != nil {\r\n\t\tlogrus.WithError(err).Errorf(\"last sync %v, cannot save to path %v\", syncTime, c.lastSyncFallback)\r\n\t}\r\n\treturn nil\r\n}","code-length":264,"reference":"\/\/ Sync looks for newly made gerrit changes\n\/\/ and creates prowjobs according to specs","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *EventCounterPlugin) AddFlags(cmd *cobra.Command) {\r\n\tcmd.Flags().StringVar(&e.desc, \"event\", \"\", \"Match event (eg: `opened`)\")\r\n}","code-length":62,"reference":"\/\/ AddFlags adds \"event\" to the command help","result":"Add flags to the command.","score":[0.1865,0.3319]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *EventCounterPlugin) CheckFlags() error {\r\n\te.matcher = NewEventMatcher(e.desc)\r\n\treturn nil\r\n}","code-length":45,"reference":"\/\/ CheckFlags is delegated to EventMatcher","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *EventCounterPlugin) ReceiveIssueEvent(event sql.IssueEvent) []Point {\r\n\tvar label string\r\n\tif event.Label != nil {\r\n\t\tlabel = *event.Label\r\n\t}\r\n\tif !e.matcher.Match(event.Event, label) {\r\n\t\treturn nil\r\n\t}\r\n\treturn []Point{\r\n\t\t{\r\n\t\t\tValues: map[string]interface{}{\"event\": 1},\r\n\t\t\tDate:   event.EventCreatedAt,\r\n\t\t},\r\n\t}\r\n}","code-length":141,"reference":"\/\/ ReceiveIssueEvent adds issue events to InfluxDB","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Upload(bucket *storage.BucketHandle, uploadTargets map[string]UploadFunc) error {\r\n\terrCh := make(chan error, len(uploadTargets))\r\n\tgroup := &sync.WaitGroup{}\r\n\tgroup.Add(len(uploadTargets))\r\n\tfor dest, upload := range uploadTargets {\r\n\t\tobj := bucket.Object(dest)\r\n\t\tlogrus.WithField(\"dest\", dest).Info(\"Queued for upload\")\r\n\t\tgo func(f UploadFunc, obj *storage.ObjectHandle, name string) {\r\n\t\t\tdefer group.Done()\r\n\t\t\tif err := f(obj); err != nil {\r\n\t\t\t\terrCh <- err\r\n\t\t\t}\r\n\t\t\tlogrus.WithField(\"dest\", name).Info(\"Finished upload\")\r\n\t\t}(upload, obj, dest)\r\n\t}\r\n\tgroup.Wait()\r\n\tclose(errCh)\r\n\tif len(errCh) != 0 {\r\n\t\tvar uploadErrors []error\r\n\t\tfor err := range errCh {\r\n\t\t\tuploadErrors = append(uploadErrors, err)\r\n\t\t}\r\n\t\treturn fmt.Errorf(\"encountered errors during upload: %v\", uploadErrors)\r\n\t}\r\n\treturn nil\r\n}","code-length":305,"reference":"\/\/ Upload uploads all of the data in the\n\/\/ uploadTargets map to GCS in parallel. The map is\n\/\/ keyed on GCS path under the bucket","result":"Upload objects.","score":[0.0,0.0204]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FileUploadWithMetadata(file string, metadata map[string]string) UploadFunc {\r\n\treturn func(obj *storage.ObjectHandle) error {\r\n\t\treader, err := os.Open(file)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tuploadErr := DataUploadWithMetadata(reader, metadata)(obj)\r\n\t\tcloseErr := reader.Close()\r\n\t\treturn errorutil.NewAggregate(uploadErr, closeErr)\r\n\t}\r\n}","code-length":130,"reference":"\/\/ FileUploadWithMetadata returns an UploadFunc which copies all\n\/\/ data from the file on disk into GCS object and also sets the provided\n\/\/ metadata fields on the object.","result":"Upload a file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DataUploadWithMetadata(src io.Reader, metadata map[string]string) UploadFunc {\r\n\treturn func(obj *storage.ObjectHandle) error {\r\n\t\twriter := obj.NewWriter(context.Background())\r\n\t\twriter.Metadata = metadata\r\n\t\t_, copyErr := io.Copy(writer, src)\r\n\t\tcloseErr := writer.Close()\r\n\t\treturn errorutil.NewAggregate(copyErr, closeErr)\r\n\t}\r\n}","code-length":121,"reference":"\/\/ DataUploadWithMetadata returns an UploadFunc which copies all\n\/\/ data from src reader into GCS and also sets the provided metadata\n\/\/ fields onto the object.","result":"Upload data.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HasLabel(label string, issueLabels []Label) bool {\r\n\tfor _, l := range issueLabels {\r\n\t\tif strings.ToLower(l.Name) == strings.ToLower(label) {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":81,"reference":"\/\/ HasLabel checks if label is in the label set \"issueLabels\".","result":"Check if label exists in issueLabels.","score":[0.1313,0.3006]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ImageTooBig(url string) (bool, error) {\r\n\t\r\n\tlimit := 10000000\r\n\t\r\n\tresp, err := http.Head(url)\r\n\tif err != nil {\r\n\t\treturn true, fmt.Errorf(\"HEAD error: %v\", err)\r\n\t}\r\n\tif sc := resp.StatusCode; sc != http.StatusOK {\r\n\t\treturn true, fmt.Errorf(\"failing %d response\", sc)\r\n\t}\r\n\tsize, _ := strconv.Atoi(resp.Header.Get(\"Content-Length\"))\r\n\tif size > limit {\r\n\t\treturn true, nil\r\n\t}\r\n\treturn false, nil\r\n}","code-length":173,"reference":"\/\/ ImageTooBig checks if image is bigger than github limits","result":"Check if the image is too big.","score":[0.1647,0.3866]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LevelFromPermissions(permissions RepoPermissions) RepoPermissionLevel {\r\n\tif permissions.Admin {\r\n\t\treturn Admin\r\n\t} else if permissions.Push {\r\n\t\treturn Write\r\n\t} else if permissions.Pull {\r\n\t\treturn Read\r\n\t} else {\r\n\t\treturn None\r\n\t}\r\n}","code-length":87,"reference":"\/\/ LevelFromPermissions adapts a repo permissions struct to the\n\/\/ appropriate permission level used elsewhere","result":"Get the level from the permissions.","score":[0.0512,0.0709]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PermissionsFromLevel(permission RepoPermissionLevel) RepoPermissions {\r\n\tswitch permission {\r\n\tcase None:\r\n\t\treturn RepoPermissions{}\r\n\tcase Read:\r\n\t\treturn RepoPermissions{Pull: true}\r\n\tcase Write:\r\n\t\treturn RepoPermissions{Pull: true, Push: true}\r\n\tcase Admin:\r\n\t\treturn RepoPermissions{Pull: true, Push: true, Admin: true}\r\n\tdefault:\r\n\t\treturn RepoPermissions{}\r\n\t}\r\n}","code-length":128,"reference":"\/\/ PermissionsFromLevel adapts a repo permission level to the\n\/\/ appropriate permissions struct used elsewhere","result":"Generate the code.","score":[0.0075,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newProwJobs(c *ProwV1Client, namespace string) *prowJobs {\r\n\treturn &prowJobs{\r\n\t\tclient: c.RESTClient(),\r\n\t\tns:     namespace,\r\n\t}\r\n}","code-length":67,"reference":"\/\/ newProwJobs returns a ProwJobs","result":"Create new ProwJobs objects.","score":[0.2488,0.102]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b Blockers) GetApplicable(org, repo, branch string) []Blocker {\r\n\tvar res []Blocker\r\n\tres = append(res, b.Repo[orgRepo{org: org, repo: repo}]...)\r\n\tres = append(res, b.Branch[orgRepoBranch{org: org, repo: repo, branch: branch}]...)\r\n\tsort.Slice(res, func(i, j int) bool {\r\n\t\treturn res[i].Number < res[j].Number\r\n\t})\r\n\treturn res\r\n}","code-length":138,"reference":"\/\/ GetApplicable returns the subset of blockers applicable to the specified branch.","result":"Get the list of applicable blockers.","score":[0.0935,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc serve(jc *jenkins.Client) {\r\n\thttp.Handle(\"\/\", gziphandler.GzipHandler(handleLog(jc)))\r\n\thttp.Handle(\"\/metrics\", promhttp.Handler())\r\n\tlogrus.WithError(http.ListenAndServe(\":8080\", nil)).Fatal(\"ListenAndServe returned.\")\r\n}","code-length":87,"reference":"\/\/ serve starts a http server and serves Jenkins logs\n\/\/ and prometheus metrics. Meant to be called inside\n\/\/ a goroutine.","result":"Serve the logs.","score":[0,0.0249]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCountPlugin(runner func(Plugin) error) *cobra.Command {\r\n\tstateCounter := &StatePlugin{}\r\n\teventCounter := &EventCounterPlugin{}\r\n\tcommentsAsEvents := NewFakeCommentPluginWrapper(eventCounter)\r\n\tcommentCounter := &CommentCounterPlugin{}\r\n\tauthorLoggable := NewMultiplexerPluginWrapper(\r\n\t\tcommentsAsEvents,\r\n\t\tcommentCounter,\r\n\t)\r\n\tauthorLogged := NewAuthorLoggerPluginWrapper(authorLoggable)\r\n\tfullMultiplex := NewMultiplexerPluginWrapper(authorLogged, stateCounter)\r\n\tfakeOpen := NewFakeOpenPluginWrapper(fullMultiplex)\r\n\ttypeFilter := NewTypeFilterWrapperPlugin(fakeOpen)\r\n\tauthorFilter := NewAuthorFilterPluginWrapper(typeFilter)\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"count\",\r\n\t\tShort: \"Count events and number of issues in given state, and for how long\",\r\n\t\tRunE: func(cmd *cobra.Command, args []string) error {\r\n\t\t\tif err := eventCounter.CheckFlags(); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif err := stateCounter.CheckFlags(); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif err := typeFilter.CheckFlags(); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif err := commentCounter.CheckFlags(); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\treturn runner(authorFilter)\r\n\t\t},\r\n\t}\r\n\teventCounter.AddFlags(cmd)\r\n\tstateCounter.AddFlags(cmd)\r\n\tcommentCounter.AddFlags(cmd)\r\n\ttypeFilter.AddFlags(cmd)\r\n\tauthorFilter.AddFlags(cmd)\r\n\tauthorLogged.AddFlags(cmd)\r\n\treturn cmd\r\n}","code-length":463,"reference":"\/\/ NewCountPlugin counts events and number of issues in given state, and for how long.","result":"Create a plugin for counting events and issues.","score":[0.0906,0.2207]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *FakeCommentPluginWrapper) ReceiveComment(comment sql.Comment) []Point {\r\n\t\r\n\tfakeEvent := sql.IssueEvent{\r\n\t\tIssueID:        comment.IssueID,\r\n\t\tEvent:          \"commented\",\r\n\t\tEventCreatedAt: comment.CommentCreatedAt,\r\n\t\tActor:          &comment.User,\r\n\t}\r\n\treturn append(\r\n\t\to.plugin.ReceiveComment(comment),\r\n\t\to.plugin.ReceiveIssueEvent(fakeEvent)...,\r\n\t)\r\n}","code-length":138,"reference":"\/\/ ReceiveComment creates a fake \"commented\" event","result":"Test if the comment plugin is not used.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc updateMetrics(interval time.Duration, diskRoot string) {\r\n\tlogger := logrus.WithField(\"sync-loop\", \"updateMetrics\")\r\n\tticker := time.NewTicker(interval)\r\n\tfor ; true; <-ticker.C {\r\n\t\tlogger.Info(\"tick\")\r\n\t\t_, bytesFree, bytesUsed, err := diskutil.GetDiskUsage(diskRoot)\r\n\t\tif err != nil {\r\n\t\t\tlogger.WithError(err).Error(\"Failed to get disk metrics\")\r\n\t\t} else {\r\n\t\t\tpromMetrics.DiskFree.Set(float64(bytesFree) \/ 1e9)\r\n\t\t\tpromMetrics.DiskUsed.Set(float64(bytesUsed) \/ 1e9)\r\n\t\t\tpromMetrics.DiskTotal.Set(float64(bytesFree+bytesUsed) \/ 1e9)\r\n\t\t}\r\n\t}\r\n}","code-length":219,"reference":"\/\/ helper to update disk metrics","result":"Update metrics in sync.","score":[0.1938,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Ranch) LogStatus() {\r\n\tresources, err := r.Storage.GetResources()\r\n\tif err != nil {\r\n\t\treturn\r\n\t}\r\n\tresJSON, err := json.Marshal(resources)\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Errorf(\"Fail to marshal Resources. %v\", resources)\r\n\t}\r\n\tlogrus.Infof(\"Current Resources : %v\", string(resJSON))\r\n}","code-length":124,"reference":"\/\/ LogStatus outputs current status of all resources","result":"Log the status of the resource.","score":[0.1956,0.2404]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Ranch) SyncConfig(config string) error {\r\n\tresources, err := ParseConfig(config)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := r.Storage.SyncResources(resources); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":92,"reference":"\/\/ SyncConfig updates resource list from a file","result":"Sync config.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Ranch) Metric(rtype string) (common.Metric, error) {\r\n\tmetric := common.Metric{\r\n\t\tType:    rtype,\r\n\t\tCurrent: map[string]int{},\r\n\t\tOwners:  map[string]int{},\r\n\t}\r\n\tresources, err := r.Storage.GetResources()\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Error(\"cannot find resources\")\r\n\t\treturn metric, &ResourceNotFound{rtype}\r\n\t}\r\n\tfor _, res := range resources {\r\n\t\tif res.Type != rtype {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif _, ok := metric.Current[res.State]; !ok {\r\n\t\t\tmetric.Current[res.State] = 0\r\n\t\t}\r\n\t\tif _, ok := metric.Owners[res.Owner]; !ok {\r\n\t\t\tmetric.Owners[res.Owner] = 0\r\n\t\t}\r\n\t\tmetric.Current[res.State]++\r\n\t\tmetric.Owners[res.Owner]++\r\n\t}\r\n\tif len(metric.Current) == 0 && len(metric.Owners) == 0 {\r\n\t\treturn metric, &ResourceNotFound{rtype}\r\n\t}\r\n\treturn metric, nil\r\n}","code-length":332,"reference":"\/\/ Metric returns a metric object with metrics filled in","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FormatURL(dogURL string) (string, error) {\r\n\tif dogURL == \"\" {\r\n\t\treturn \"\", errors.New(\"empty url\")\r\n\t}\r\n\tsrc, err := url.ParseRequestURI(dogURL)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"invalid url %s: %v\", dogURL, err)\r\n\t}\r\n\treturn fmt.Sprintf(\"[![dog image](%s)](%s)\", src, src), nil\r\n}","code-length":132,"reference":"\/\/ FormatURL will return the GH markdown to show the image for a specific dogURL.","result":"Format the dog image url.","score":[0.0387,0.0714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc runAndSkipJobs(c Client, pr *github.PullRequest, requestedJobs []config.Presubmit, skippedJobs []config.Presubmit, eventGUID string, elideSkippedContexts bool) error {\r\n\tif err := validateContextOverlap(requestedJobs, skippedJobs); err != nil {\r\n\t\tc.Logger.WithError(err).Warn(\"Could not run or skip requested jobs, overlapping contexts.\")\r\n\t\treturn err\r\n\t}\r\n\trunErr := RunRequested(c, pr, requestedJobs, eventGUID)\r\n\tvar skipErr error\r\n\tif !elideSkippedContexts {\r\n\t\tskipErr = skipRequested(c, pr, skippedJobs)\r\n\t}\r\n\treturn errorutil.NewAggregate(runErr, skipErr)\r\n}","code-length":186,"reference":"\/\/ runAndSkipJobs executes the config.Presubmits that are requested and posts skipped statuses\n\/\/ for the reporting jobs that are skipped","result":"Run jobs and skip them.","score":[0.0142,0.0811]}
{"code":"\/*is used to<extra_id_0>\r\nfunc validateContextOverlap(toRun, toSkip []config.Presubmit) error {\r\n\trequestedContexts := sets.NewString()\r\n\tfor _, job := range toRun {\r\n\t\trequestedContexts.Insert(job.Context)\r\n\t}\r\n\tskippedContexts := sets.NewString()\r\n\tfor _, job := range toSkip {\r\n\t\tskippedContexts.Insert(job.Context)\r\n\t}\r\n\tif overlap := requestedContexts.Intersection(skippedContexts).List(); len(overlap) > 0 {\r\n\t\treturn fmt.Errorf(\"the following contexts are both triggered and skipped: %s\", strings.Join(overlap, \", \"))\r\n\t}\r\n\treturn nil\r\n}","code-length":173,"reference":"\/\/ validateContextOverlap ensures that there will be no overlap in contexts between a set of jobs running and a set to skip","result":"Validate the context overlap.","score":[0,0.0248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RunRequested(c Client, pr *github.PullRequest, requestedJobs []config.Presubmit, eventGUID string) error {\r\n\tbaseSHA, err := c.GitHubClient.GetRef(pr.Base.Repo.Owner.Login, pr.Base.Repo.Name, \"heads\/\"+pr.Base.Ref)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tvar errors []error\r\n\tfor _, job := range requestedJobs {\r\n\t\tc.Logger.Infof(\"Starting %s build.\", job.Name)\r\n\t\tpj := pjutil.NewPresubmit(*pr, baseSHA, job, eventGUID)\r\n\t\tc.Logger.WithFields(pjutil.ProwJobFields(&pj)).Info(\"Creating a new prowjob.\")\r\n\t\tif _, err := c.ProwJobClient.Create(&pj); err != nil {\r\n\t\t\tc.Logger.WithError(err).Error(\"Failed to create prowjob.\")\r\n\t\t\terrors = append(errors, err)\r\n\t\t}\r\n\t}\r\n\treturn errorutil.NewAggregate(errors...)\r\n}","code-length":284,"reference":"\/\/ RunRequested executes the config.Presubmits that are requested","result":"Run the build .","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc skipRequested(c Client, pr *github.PullRequest, skippedJobs []config.Presubmit) error {\r\n\tvar errors []error\r\n\tfor _, job := range skippedJobs {\r\n\t\tif job.SkipReport {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tc.Logger.Infof(\"Skipping %s build.\", job.Name)\r\n\t\tif err := c.GitHubClient.CreateStatus(pr.Base.Repo.Owner.Login, pr.Base.Repo.Name, pr.Head.SHA, skippedStatusFor(job.Context)); err != nil {\r\n\t\t\terrors = append(errors, err)\r\n\t\t}\r\n\t}\r\n\treturn errorutil.NewAggregate(errors...)\r\n}","code-length":180,"reference":"\/\/ skipRequested posts skipped statuses for the config.Presubmits that are requested","result":"Skip the build.","score":[0.0284,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l LabelEvent) Match(eventName, label string) bool {\r\n\treturn eventName == \"labeled\" && label == l.Label\r\n}","code-length":44,"reference":"\/\/ Match is \"labeled\" with label","result":"Match labels.","score":[0.0677,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u UnlabelEvent) Match(eventName, label string) bool {\r\n\treturn eventName == \"unlabeled\" && label == u.Label\r\n}","code-length":46,"reference":"\/\/ Match is \"unlabeled\"","result":"Match UnlabelEvent.","score":[0.1839,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *GitHubOptions) AddFlags(fs *flag.FlagSet) {\r\n\to.addFlags(true, fs)\r\n}","code-length":42,"reference":"\/\/ AddFlags injects GitHub options into the given FlagSet.","result":"Generate the code.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *GitHubOptions) AddFlagsWithoutDefaultGitHubTokenPath(fs *flag.FlagSet) {\r\n\to.addFlags(false, fs)\r\n}","code-length":47,"reference":"\/\/ AddFlagsWithoutDefaultGitHubTokenPath injects GitHub options into the given\n\/\/ Flagset without setting a default for for the githubTokenPath, allowing to\n\/\/ use an anonymous GitHub client","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *GitHubOptions) Validate(dryRun bool) error {\r\n\tfor _, uri := range o.endpoint.Strings() {\r\n\t\tif uri == \"\" {\r\n\t\t\turi = github.DefaultAPIEndpoint\r\n\t\t} else if _, err := url.ParseRequestURI(uri); err != nil {\r\n\t\t\treturn fmt.Errorf(\"invalid -github-endpoint URI: %q\", uri)\r\n\t\t}\r\n\t}\r\n\tif o.graphqlEndpoint == \"\" {\r\n\t\to.graphqlEndpoint = github.DefaultGraphQLEndpoint\r\n\t} else if _, err := url.Parse(o.graphqlEndpoint); err != nil {\r\n\t\treturn fmt.Errorf(\"invalid -github-graphql-endpoint URI: %q\", o.graphqlEndpoint)\r\n\t}\r\n\tif o.deprecatedTokenFile != \"\" {\r\n\t\to.TokenPath = o.deprecatedTokenFile\r\n\t\tlogrus.Error(\"-github-token-file is deprecated and may be removed anytime after 2019-01-01.  Use -github-token-path instead.\")\r\n\t}\r\n\tif o.TokenPath == \"\" {\r\n\t\tlogrus.Warn(\"empty -github-token-path, will use anonymous github client\")\r\n\t}\r\n\treturn nil\r\n}","code-length":314,"reference":"\/\/ Validate validates GitHub options.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *GitHubOptions) GitHubClientWithLogFields(secretAgent *secret.Agent, dryRun bool, fields logrus.Fields) (client *github.Client, err error) {\r\n\tvar generator *func() []byte\r\n\tif o.TokenPath == \"\" {\r\n\t\tgeneratorFunc := func() []byte {\r\n\t\t\treturn []byte{}\r\n\t\t}\r\n\t\tgenerator = &generatorFunc\r\n\t} else {\r\n\t\tif secretAgent == nil {\r\n\t\t\treturn nil, fmt.Errorf(\"cannot store token from %q without a secret agent\", o.TokenPath)\r\n\t\t}\r\n\t\tgeneratorFunc := secretAgent.GetTokenGenerator(o.TokenPath)\r\n\t\tgenerator = &generatorFunc\r\n\t}\r\n\tif dryRun {\r\n\t\treturn github.NewDryRunClientWithFields(fields, *generator, o.graphqlEndpoint, o.endpoint.Strings()...), nil\r\n\t}\r\n\treturn github.NewClientWithFields(fields, *generator, o.graphqlEndpoint, o.endpoint.Strings()...), nil\r\n}","code-length":259,"reference":"\/\/ GitHubClientWithLogFields returns a GitHub client with extra logging fields","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *GitHubOptions) GitHubClient(secretAgent *secret.Agent, dryRun bool) (client *github.Client, err error) {\r\n\treturn o.GitHubClientWithLogFields(secretAgent, dryRun, logrus.Fields{})\r\n}","code-length":65,"reference":"\/\/ GitHubClient returns a GitHub client.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *GitHubOptions) GitClient(secretAgent *secret.Agent, dryRun bool) (client *git.Client, err error) {\r\n\tclient, err = git.NewClient()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tdefer func(client *git.Client) {\r\n\t\tif err != nil {\r\n\t\t\tclient.Clean()\r\n\t\t}\r\n\t}(client)\r\n\t\r\n\tgithubClient, err := o.GitHubClient(secretAgent, dryRun)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error getting GitHub client: %v\", err)\r\n\t}\r\n\tbotName, err := githubClient.BotName()\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error getting bot name: %v\", err)\r\n\t}\r\n\tclient.SetCredentials(botName, secretAgent.GetTokenGenerator(o.TokenPath))\r\n\treturn client, nil\r\n}","code-length":256,"reference":"\/\/ GitClient returns a Git client.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc toMap(g *calculation.CoverageList) map[string]calculation.Coverage {\r\n\tm := make(map[string]calculation.Coverage)\r\n\tfor _, cov := range g.Group {\r\n\t\tm[cov.Name] = cov\r\n\t}\r\n\treturn m\r\n}","code-length":79,"reference":"\/\/ toMap returns maps the file name to its coverage for faster retrieval\n\/\/ & membership check","result":"Generate the map to return.","score":[0.0259,0.0949]}
{"code":"\/*is used to<extra_id_0>\r\nfunc findChanges(baseList *calculation.CoverageList, newList *calculation.CoverageList) []*coverageChange {\r\n\tvar changes []*coverageChange\r\n\tbaseFilesMap := toMap(baseList)\r\n\tfor _, newCov := range newList.Group {\r\n\t\tbaseCov, ok := baseFilesMap[newCov.Name]\r\n\t\tvar baseRatio float32\r\n\t\tif !ok {\r\n\t\t\tbaseRatio = -1\r\n\t\t} else {\r\n\t\t\tbaseRatio = baseCov.Ratio()\r\n\t\t}\r\n\t\tnewRatio := newCov.Ratio()\r\n\t\tif isChangeSignificant(baseRatio, newRatio) {\r\n\t\t\tchanges = append(changes, &coverageChange{\r\n\t\t\t\tname:      newCov.Name,\r\n\t\t\t\tbaseRatio: baseRatio,\r\n\t\t\t\tnewRatio:  newRatio,\r\n\t\t\t})\r\n\t\t}\r\n\t}\r\n\treturn changes\r\n}","code-length":239,"reference":"\/\/ findChanges compares the newList of coverage against the base list and returns the result","result":"Find changes in the coverage list.","score":[0.0512,0.0709]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (config *MySQLConfig) CreateDatabase() (*gorm.DB, error) {\r\n\tdb, err := gorm.Open(\"mysql\", config.getDSN(\"\"))\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdb.Exec(fmt.Sprintf(\"CREATE DATABASE IF NOT EXISTS %v;\", config.Db))\r\n\tdb.Close()\r\n\tdb, err = gorm.Open(\"mysql\", config.getDSN(config.Db))\r\n\terr = db.AutoMigrate(&Assignee{}, &Issue{}, &IssueEvent{}, &Label{}, &Comment{}).Error\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn db, nil\r\n}","code-length":188,"reference":"\/\/ CreateDatabase for the MySQLConfig","result":"Create a new database.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) ShouldReport(pj *v1.ProwJob) bool {\r\n\tif !pj.Spec.Report {\r\n\t\t\r\n\t\treturn false\r\n\t}\r\n\tif pj.Spec.Type != v1.PresubmitJob && pj.Spec.Type != v1.PostsubmitJob {\r\n\t\t\r\n\t\treturn false\r\n\t}\r\n\tif c.reportAgent != \"\" && pj.Spec.Agent != c.reportAgent {\r\n\t\t\r\n\t\treturn false\r\n\t}\r\n\treturn true\r\n}","code-length":145,"reference":"\/\/ ShouldReport returns if this prowjob should be reported by the github reporter","result":"Generate code for the generated code.","score":[0.0601,0.0407]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Report(pj *v1.ProwJob) ([]*v1.ProwJob, error) {\r\n\t\r\n\treturn []*v1.ProwJob{pj}, report.Report(c.gc, c.config().Plank.ReportTemplate, *pj, c.config().GitHubReporter.JobTypesToReport)\r\n}","code-length":95,"reference":"\/\/ Report will report via reportlib","result":"Report the plank.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Set) MarkComplete() int {\r\n\tvar gone []string\r\n\tfor key := range s.firstSeen {\r\n\t\tif !s.marked[key] {\r\n\t\t\tgone = append(gone, key)\r\n\t\t}\r\n\t}\r\n\tfor _, key := range gone {\r\n\t\tklog.V(1).Infof(\"%s: deleted since last run\", key)\r\n\t\tdelete(s.firstSeen, key)\r\n\t}\r\n\tif len(s.swept) > 0 {\r\n\t\tklog.Errorf(\"%d resources swept: %v\", len(s.swept), s.swept)\r\n\t}\r\n\treturn len(s.swept)\r\n}","code-length":193,"reference":"\/\/ MarkComplete figures out which ARNs were in previous passes but not\n\/\/ this one, and eliminates them. It should only be run after all\n\/\/ resources have been marked.","result":"Mark all resources as complete.","score":[0.0019,0.0364]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewJobAgent(kc serviceClusterClient, plClients map[string]PodLogClient, cfg config.Getter) *JobAgent {\r\n\treturn &JobAgent{\r\n\t\tkc:     kc,\r\n\t\tpkcs:   plClients,\r\n\t\tconfig: cfg,\r\n\t}\r\n}","code-length":83,"reference":"\/\/ NewJobAgent is a JobAgent constructor.","result":"Pkcs map[string]PodLogClient.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ja *JobAgent) Start() {\r\n\tja.tryUpdate()\r\n\tgo func() {\r\n\t\tt := time.Tick(period)\r\n\t\tfor range t {\r\n\t\t\tja.tryUpdate()\r\n\t\t}\r\n\t}()\r\n}","code-length":76,"reference":"\/\/ Start will start the job and periodically update it.","result":"Start the job agent.","score":[0.1116,0.3132]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ja *JobAgent) Jobs() []Job {\r\n\tja.mut.Lock()\r\n\tdefer ja.mut.Unlock()\r\n\tres := make([]Job, len(ja.jobs))\r\n\tcopy(res, ja.jobs)\r\n\treturn res\r\n}","code-length":75,"reference":"\/\/ Jobs returns a thread-safe snapshot of the current job state.","result":"Get the list of jobs in the agent.","score":[0.1135,0.1402]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ja *JobAgent) ProwJobs() []prowapi.ProwJob {\r\n\tja.mut.Lock()\r\n\tdefer ja.mut.Unlock()\r\n\tres := make([]prowapi.ProwJob, len(ja.prowJobs))\r\n\tcopy(res, ja.prowJobs)\r\n\treturn res\r\n}","code-length":93,"reference":"\/\/ ProwJobs returns a thread-safe snapshot of the current prow jobs.","result":"Collect the job.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ja *JobAgent) GetProwJob(job, id string) (prowapi.ProwJob, error) {\r\n\tif ja == nil {\r\n\t\treturn prowapi.ProwJob{}, fmt.Errorf(\"Prow job agent doesn't exist (are you running locally?)\")\r\n\t}\r\n\tvar j prowapi.ProwJob\r\n\tja.mut.Lock()\r\n\tidMap, ok := ja.jobsIDMap[job]\r\n\tif ok {\r\n\t\tj, ok = idMap[id]\r\n\t}\r\n\tja.mut.Unlock()\r\n\tif !ok {\r\n\t\treturn prowapi.ProwJob{}, errProwjobNotFound\r\n\t}\r\n\treturn j, nil\r\n}","code-length":192,"reference":"\/\/ GetProwJob finds the corresponding Prowjob resource from the provided job name and build ID","result":"Get the job from the job agent.","score":[0.0866,0.3141]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ja *JobAgent) GetJobLog(job, id string) ([]byte, error) {\r\n\tj, err := ja.GetProwJob(job, id)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error getting prowjob: %v\", err)\r\n\t}\r\n\tif j.Spec.Agent == prowapi.KubernetesAgent {\r\n\t\tclient, ok := ja.pkcs[j.ClusterAlias()]\r\n\t\tif !ok {\r\n\t\t\treturn nil, fmt.Errorf(\"cannot get logs for prowjob %q with agent %q: unknown cluster alias %q\", j.ObjectMeta.Name, j.Spec.Agent, j.ClusterAlias())\r\n\t\t}\r\n\t\treturn client.GetLogs(j.Status.PodName, &coreapi.PodLogOptions{Container: kube.TestContainerName})\r\n\t}\r\n\tfor _, agentToTmpl := range ja.config().Deck.ExternalAgentLogs {\r\n\t\tif agentToTmpl.Agent != string(j.Spec.Agent) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif !agentToTmpl.Selector.Matches(labels.Set(j.ObjectMeta.Labels)) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvar b bytes.Buffer\r\n\t\tif err := agentToTmpl.URLTemplate.Execute(&b, &j); err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"cannot execute URL template for prowjob %q with agent %q: %v\", j.ObjectMeta.Name, j.Spec.Agent, err)\r\n\t\t}\r\n\t\tresp, err := http.Get(b.String())\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tdefer resp.Body.Close()\r\n\t\treturn ioutil.ReadAll(resp.Body)\r\n\t}\r\n\treturn nil, fmt.Errorf(\"cannot get logs for prowjob %q with agent %q: the agent is missing from the prow config file\", j.ObjectMeta.Name, j.Spec.Agent)\r\n}","code-length":514,"reference":"\/\/ GetJobLog returns the job logs, works for both kubernetes and jenkins agent types.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc unionStrings(parent, child []string) []string {\r\n\tif child == nil {\r\n\t\treturn parent\r\n\t}\r\n\tif parent == nil {\r\n\t\treturn child\r\n\t}\r\n\ts := sets.NewString(parent...)\r\n\ts.Insert(child...)\r\n\treturn s.List()\r\n}","code-length":90,"reference":"\/\/ unionStrings merges the parent and child items together","result":"Create a union of two sets of strings.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p Policy) Apply(child Policy) Policy {\r\n\treturn Policy{\r\n\t\tProtect:                    selectBool(p.Protect, child.Protect),\r\n\t\tRequiredStatusChecks:       mergeContextPolicy(p.RequiredStatusChecks, child.RequiredStatusChecks),\r\n\t\tAdmins:                     selectBool(p.Admins, child.Admins),\r\n\t\tRestrictions:               mergeRestrictions(p.Restrictions, child.Restrictions),\r\n\t\tRequiredPullRequestReviews: mergeReviewPolicy(p.RequiredPullRequestReviews, child.RequiredPullRequestReviews),\r\n\t}\r\n}","code-length":143,"reference":"\/\/ Apply returns a policy that merges the child into the parent","result":"Apply a policy to a child policy.","score":[0.133,0.1739]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (bp BranchProtection) GetOrg(name string) *Org {\r\n\to, ok := bp.Orgs[name]\r\n\tif ok {\r\n\t\to.Policy = bp.Apply(o.Policy)\r\n\t} else {\r\n\t\to.Policy = bp.Policy\r\n\t}\r\n\treturn &o\r\n}","code-length":90,"reference":"\/\/ GetOrg returns the org config after merging in any global policies.","result":"Get the org from the branch protection.","score":[0.1118,0.087]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Org) GetRepo(name string) *Repo {\r\n\tr, ok := o.Repos[name]\r\n\tif ok {\r\n\t\tr.Policy = o.Apply(r.Policy)\r\n\t} else {\r\n\t\tr.Policy = o.Policy\r\n\t}\r\n\treturn &r\r\n}","code-length":88,"reference":"\/\/ GetRepo returns the repo config after merging in any org policies.","result":"Get the repo from the org.","score":[0.1004,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r Repo) GetBranch(name string) (*Branch, error) {\r\n\tb, ok := r.Branches[name]\r\n\tif ok {\r\n\t\tb.Policy = r.Apply(b.Policy)\r\n\t\tif b.Protect == nil {\r\n\t\t\treturn nil, errors.New(\"defined branch policies must set protect\")\r\n\t\t}\r\n\t} else {\r\n\t\tb.Policy = r.Policy\r\n\t}\r\n\treturn &b, nil\r\n}","code-length":128,"reference":"\/\/ GetBranch returns the branch config after merging in any repo policies.","result":"Get the branch.","score":[0.0203,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) GetPolicy(org, repo, branch string, b Branch) (*Policy, error) {\r\n\tpolicy := b.Policy\r\n\t\r\n\tif prowContexts, _, _ := BranchRequirements(org, repo, branch, c.Presubmits); len(prowContexts) > 0 {\r\n\t\t\r\n\t\tif policy.Protect != nil && !*policy.Protect {\r\n\t\t\treturn nil, fmt.Errorf(\"required prow jobs require branch protection\")\r\n\t\t}\r\n\t\tps := Policy{\r\n\t\t\tRequiredStatusChecks: &ContextPolicy{\r\n\t\t\t\tContexts: prowContexts,\r\n\t\t\t},\r\n\t\t}\r\n\t\t\r\n\t\tif c.BranchProtection.ProtectTested {\r\n\t\t\tyes := true\r\n\t\t\tps.Protect = &yes\r\n\t\t}\r\n\t\tpolicy = policy.Apply(ps)\r\n\t}\r\n\tif policy.Protect != nil && !*policy.Protect {\r\n\t\t\r\n\t\tvar old *bool\r\n\t\told, policy.Protect = policy.Protect, old\r\n\t\tswitch {\r\n\t\tcase policy.defined() && c.BranchProtection.AllowDisabledPolicies:\r\n\t\t\tlogrus.Warnf(\"%s\/%s=%s defines a policy but has protect: false\", org, repo, branch)\r\n\t\t\tpolicy = Policy{\r\n\t\t\t\tProtect: policy.Protect,\r\n\t\t\t}\r\n\t\tcase policy.defined():\r\n\t\t\treturn nil, fmt.Errorf(\"%s\/%s=%s defines a policy, which requires protect: true\", org, repo, branch)\r\n\t\t}\r\n\t\tpolicy.Protect = old\r\n\t}\r\n\tif !policy.defined() {\r\n\t\treturn nil, nil\r\n\t}\r\n\treturn &policy, nil\r\n}","code-length":433,"reference":"\/\/ GetPolicy returns the protection policy for the branch, after merging in presubmits.","result":"Get the policy for a branch.","score":[0.0941,0.2078]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UpdateIssueEvents(issueID int, db *gorm.DB, client ClientInterface) {\r\n\tlatest, err := findLatestEvent(issueID, db, client.RepositoryName())\r\n\tif err != nil {\r\n\t\tglog.Error(\"Failed to find last event: \", err)\r\n\t\treturn\r\n\t}\r\n\tc := make(chan *github.IssueEvent, 500)\r\n\tgo client.FetchIssueEvents(issueID, latest, c)\r\n\tfor event := range c {\r\n\t\teventOrm, err := NewIssueEvent(event, issueID, client.RepositoryName())\r\n\t\tif err != nil {\r\n\t\t\tglog.Error(\"Failed to create issue-event\", err)\r\n\t\t}\r\n\t\tdb.Create(eventOrm)\r\n\t}\r\n}","code-length":201,"reference":"\/\/ UpdateIssueEvents fetches all events until we find the most recent we\n\/\/ have in db, and saves everything in database","result":"Update the issue events in the database.","score":[0.0288,0.0765]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *controller) enqueueKey(ctx string, obj interface{}) {\r\n\tswitch o := obj.(type) {\r\n\tcase *prowjobv1.ProwJob:\r\n\t\tc.workqueue.AddRateLimited(toKey(ctx, o.Spec.Namespace, o.Name))\r\n\tcase *buildv1alpha1.Build:\r\n\t\tc.workqueue.AddRateLimited(toKey(ctx, o.Namespace, o.Name))\r\n\tdefault:\r\n\t\tlogrus.Warnf(\"cannot enqueue unknown type %T: %v\", o, obj)\r\n\t\treturn\r\n\t}\r\n}","code-length":161,"reference":"\/\/ enqueueKey schedules an item for reconciliation.","result":"Queue work for all objects.","score":[0.1611,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc prowJobStatus(bs buildv1alpha1.BuildStatus) (prowjobv1.ProwJobState, string) {\r\n\tstarted := bs.StartTime\r\n\tfinished := bs.CompletionTime\r\n\tpcond := bs.GetCondition(buildv1alpha1.BuildSucceeded)\r\n\tif pcond == nil {\r\n\t\tif !finished.IsZero() {\r\n\t\t\treturn prowjobv1.ErrorState, descMissingCondition\r\n\t\t}\r\n\t\treturn prowjobv1.TriggeredState, descScheduling\r\n\t}\r\n\tcond := *pcond\r\n\tswitch {\r\n\tcase cond.Status == coreapi.ConditionTrue:\r\n\t\treturn prowjobv1.SuccessState, description(cond, descSucceeded)\r\n\tcase cond.Status == coreapi.ConditionFalse:\r\n\t\treturn prowjobv1.FailureState, description(cond, descFailed)\r\n\tcase started.IsZero():\r\n\t\treturn prowjobv1.TriggeredState, description(cond, descInitializing)\r\n\tcase cond.Status == coreapi.ConditionUnknown, finished.IsZero():\r\n\t\treturn prowjobv1.PendingState, description(cond, descRunning)\r\n\t}\r\n\tlogrus.Warnf(\"Unknown condition %#v\", cond)\r\n\treturn prowjobv1.ErrorState, description(cond, descUnknown)\r\n}","code-length":337,"reference":"\/\/ prowJobStatus returns the desired state and description based on the build status.","result":"Determine the state of the prow job .","score":[0.0978,0.12]}
{"code":"\/*is used to<extra_id_0>\r\nfunc buildEnv(pj prowjobv1.ProwJob, buildID string) (map[string]string, error) {\r\n\treturn downwardapi.EnvForSpec(downwardapi.NewJobSpec(pj.Spec, buildID, pj.Name))\r\n}","code-length":75,"reference":"\/\/ buildEnv constructs the environment map for the job","result":"Build the environment.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc defaultArguments(t *buildv1alpha1.TemplateInstantiationSpec, rawEnv map[string]string) {\r\n\tkeys := sets.String{}\r\n\tfor _, arg := range t.Arguments {\r\n\t\tkeys.Insert(arg.Name)\r\n\t}\r\n\tfor _, k := range sets.StringKeySet(rawEnv).List() {\r\n\t\tif keys.Has(k) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tt.Arguments = append(t.Arguments, buildv1alpha1.ArgumentSpec{Name: k, Value: rawEnv[k]})\r\n\t}\r\n}","code-length":157,"reference":"\/\/ defaultArguments will append each arg to the template, except where the argument name is already defined.","result":"Set default arguments.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc defaultEnv(c *coreapi.Container, rawEnv map[string]string) {\r\n\tkeys := sets.String{}\r\n\tfor _, arg := range c.Env {\r\n\t\tkeys.Insert(arg.Name)\r\n\t}\r\n\tfor _, k := range sets.StringKeySet(rawEnv).List() {\r\n\t\tif keys.Has(k) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tc.Env = append(c.Env, coreapi.EnvVar{Name: k, Value: rawEnv[k]})\r\n\t}\r\n}","code-length":149,"reference":"\/\/ defaultEnv adds the map of environment variables to the container, except keys already defined.","result":"Set the default environment variables.","score":[0.0387,0.0714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc injectSource(b *buildv1alpha1.Build, pj prowjobv1.ProwJob) (bool, error) {\r\n\tif b.Spec.Source != nil {\r\n\t\treturn false, nil\r\n\t}\r\n\tsrcContainer, refs, cloneVolumes, err := decorate.CloneRefs(pj, codeMount, logMount)\r\n\tif err != nil {\r\n\t\treturn false, fmt.Errorf(\"clone source error: %v\", err)\r\n\t}\r\n\tif srcContainer == nil {\r\n\t\treturn false, nil\r\n\t} else {\r\n\t\tsrcContainer.Name = \"\"\r\n\t}\r\n\tb.Spec.Source = &buildv1alpha1.SourceSpec{\r\n\t\tCustom: srcContainer,\r\n\t}\r\n\tb.Spec.Volumes = append(b.Spec.Volumes, cloneVolumes...)\r\n\twd := workDir(refs[0])\r\n\t\r\n\tfor i := range b.Spec.Steps {\r\n\t\tif b.Spec.Steps[i].WorkingDir != \"\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tb.Spec.Steps[i].WorkingDir = wd.Value\r\n\t}\r\n\tif b.Spec.Template != nil {\r\n\t\t\r\n\t\tb.Spec.Template.Arguments = append(b.Spec.Template.Arguments, wd)\r\n\t}\r\n\treturn true, nil\r\n}","code-length":344,"reference":"\/\/ injectSource adds the custom source container to call clonerefs correctly.\n\/\/\n\/\/ Returns true if it added this container\n\/\/\n\/\/ Does nothing if the build spec predefines Source","result":"Inject source into build.","score":[0.0005,0.0182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc injectedSteps(encodedJobSpec string, dc prowjobv1.DecorationConfig, injectedSource bool, toolsMount coreapi.VolumeMount, entries []wrapper.Options) ([]coreapi.Container, *coreapi.Container, *coreapi.Volume, error) {\r\n\tgcsVol, gcsMount, gcsOptions := decorate.GCSOptions(dc)\r\n\tsidecar, err := decorate.Sidecar(dc.UtilityImages.Sidecar, gcsOptions, gcsMount, logMount, encodedJobSpec, decorate.RequirePassingEntries, entries...)\r\n\tif err != nil {\r\n\t\treturn nil, nil, nil, fmt.Errorf(\"inject sidecar: %v\", err)\r\n\t}\r\n\tvar cloneLogMount *coreapi.VolumeMount\r\n\tif injectedSource {\r\n\t\tcloneLogMount = &logMount\r\n\t}\r\n\tinitUpload, err := decorate.InitUpload(dc.UtilityImages.InitUpload, gcsOptions, gcsMount, cloneLogMount, encodedJobSpec)\r\n\tif err != nil {\r\n\t\treturn nil, nil, nil, fmt.Errorf(\"inject initupload: %v\", err)\r\n\t}\r\n\tplacer := decorate.PlaceEntrypoint(dc.UtilityImages.Entrypoint, toolsMount)\r\n\treturn []coreapi.Container{placer, *initUpload}, sidecar, &gcsVol, nil\r\n}","code-length":327,"reference":"\/\/ injectedSteps returns initial containers, a final container and an additional volume.","result":"Generate the steps to be injected.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc determineTimeout(spec *buildv1alpha1.BuildSpec, dc *prowjobv1.DecorationConfig, defaultTimeout time.Duration) time.Duration {\r\n\tswitch {\r\n\tcase spec.Timeout != nil:\r\n\t\treturn spec.Timeout.Duration\r\n\tcase dc != nil && dc.Timeout.Duration > 0:\r\n\t\treturn dc.Timeout.Duration\r\n\tdefault:\r\n\t\treturn defaultTimeout\r\n\t}\r\n}","code-length":116,"reference":"\/\/ determineTimeout decides the timeout value used for build","result":"Determine the timeout of the build.","score":[0.1656,0.1149]}
{"code":"\/*is used to<extra_id_0>\r\nfunc makeBuild(pj prowjobv1.ProwJob, defaultTimeout time.Duration) (*buildv1alpha1.Build, error) {\r\n\tif pj.Spec.BuildSpec == nil {\r\n\t\treturn nil, errors.New(\"nil BuildSpec in spec\")\r\n\t}\r\n\tbuildID := pj.Status.BuildID\r\n\tif buildID == \"\" {\r\n\t\treturn nil, errors.New(\"empty BuildID in status\")\r\n\t}\r\n\tb := buildv1alpha1.Build{\r\n\t\tObjectMeta: buildMeta(pj),\r\n\t\tSpec:       *pj.Spec.BuildSpec.DeepCopy(),\r\n\t}\r\n\trawEnv, err := buildEnv(pj, buildID)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"environment error: %v\", err)\r\n\t}\r\n\tinjectEnvironment(&b, rawEnv)\r\n\tinjectedSource, err := injectSource(&b, pj)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"inject source: %v\", err)\r\n\t}\r\n\tinjectTimeout(&b.Spec, pj.Spec.DecorationConfig, defaultTimeout)\r\n\tif pj.Spec.DecorationConfig != nil {\r\n\t\tencodedJobSpec := rawEnv[downwardapi.JobSpecEnv]\r\n\t\terr = decorateBuild(&b.Spec, encodedJobSpec, *pj.Spec.DecorationConfig, injectedSource)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"decorate build: %v\", err)\r\n\t\t}\r\n\t}\r\n\treturn &b, nil\r\n}","code-length":415,"reference":"\/\/ makeBuild creates a build from the prowjob, using the prowjob's buildspec.","result":"Create a new build .","score":[0.0705,0.2262]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newLabels(issueID int, gLabels []github.Label, repository string) ([]sql.Label, error) {\r\n\tlabels := []sql.Label{}\r\n\trepository = strings.ToLower(repository)\r\n\tfor _, label := range gLabels {\r\n\t\tif label.Name == nil {\r\n\t\t\treturn nil, fmt.Errorf(\"Label is missing name field\")\r\n\t\t}\r\n\t\tlabels = append(labels, sql.Label{\r\n\t\t\tIssueID:    strconv.Itoa(issueID),\r\n\t\t\tName:       *label.Name,\r\n\t\t\tRepository: repository,\r\n\t\t})\r\n\t}\r\n\treturn labels, nil\r\n}","code-length":172,"reference":"\/\/ newLabels creates a new Label for each label in the issue","result":"Create labels in the database.","score":[0.0838,0.3319]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newAssignees(issueID int, gAssignees []*github.User, repository string) ([]sql.Assignee, error) {\r\n\tassignees := []sql.Assignee{}\r\n\trepository = strings.ToLower(repository)\r\n\tfor _, assignee := range gAssignees {\r\n\t\tif assignee != nil && assignee.Login == nil {\r\n\t\t\treturn nil, fmt.Errorf(\"Assignee is missing Login field\")\r\n\t\t}\r\n\t\tassignees = append(assignees, sql.Assignee{\r\n\t\t\tIssueID:    strconv.Itoa(issueID),\r\n\t\t\tName:       *assignee.Login,\r\n\t\t\tRepository: repository,\r\n\t\t})\r\n\t}\r\n\treturn assignees, nil\r\n}","code-length":192,"reference":"\/\/ newAssignees creates a new Label for each label in the issue","result":"Create a new assignee .","score":[0.0838,0.2606]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewIssueComment(issueID int, gComment *github.IssueComment, repository string) (*sql.Comment, error) {\r\n\tif gComment.ID == nil ||\r\n\t\tgComment.Body == nil ||\r\n\t\tgComment.CreatedAt == nil ||\r\n\t\tgComment.UpdatedAt == nil {\r\n\t\treturn nil, fmt.Errorf(\"IssueComment is missing mandatory field: %s\", gComment)\r\n\t}\r\n\tvar login string\r\n\tif gComment.User != nil && gComment.User.Login != nil {\r\n\t\tlogin = *gComment.User.Login\r\n\t}\r\n\treturn &sql.Comment{\r\n\t\tID:               itoa(*gComment.ID),\r\n\t\tIssueID:          strconv.Itoa(issueID),\r\n\t\tBody:             *gComment.Body,\r\n\t\tUser:             login,\r\n\t\tCommentCreatedAt: *gComment.CreatedAt,\r\n\t\tCommentUpdatedAt: *gComment.UpdatedAt,\r\n\t\tPullRequest:      false,\r\n\t\tRepository:       strings.ToLower(repository),\r\n\t}, nil\r\n}","code-length":272,"reference":"\/\/ NewIssueComment creates a Comment from a github.IssueComment","result":"Create a new comment in the database.","score":[0.14,0.1899]}
{"code":"\/*is used to<extra_id_0>\r\nfunc messageFilter(lastUpdate time.Time, change client.ChangeInfo, presubmits []config.Presubmit) (pjutil.Filter, error) {\r\n\tvar filters []pjutil.Filter\r\n\tcurrentRevision := change.Revisions[change.CurrentRevision].Number\r\n\tfor _, message := range change.Messages {\r\n\t\tmessageTime := message.Date.Time\r\n\t\tif message.RevisionNumber != currentRevision || !messageTime.After(lastUpdate) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif !pjutil.TestAllRe.MatchString(message.Message) {\r\n\t\t\tfor _, presubmit := range presubmits {\r\n\t\t\t\tif presubmit.TriggerMatches(message.Message) {\r\n\t\t\t\t\tlogrus.Infof(\"Change %d: Comment %s matches triggering regex, for %s.\", change.Number, message.Message, presubmit.Name)\r\n\t\t\t\t\tfilters = append(filters, pjutil.CommandFilter(message.Message))\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\tfilters = append(filters, pjutil.TestAllFilter())\r\n\t\t}\r\n\t}\r\n\treturn pjutil.AggregateFilter(filters), nil\r\n}","code-length":307,"reference":"\/\/ messageFilter builds a filter for jobs based on the messageBody matching the trigger regex of the jobs.","result":"Filter messages by command.","score":[0,0.0301]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (jb *Build) IsSuccess() bool {\r\n\treturn jb.Result != nil && *jb.Result == success\r\n}","code-length":39,"reference":"\/\/ IsSuccess means the job passed","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (jb *Build) IsFailure() bool {\r\n\treturn jb.Result != nil && (*jb.Result == failure || *jb.Result == unstable)\r\n}","code-length":49,"reference":"\/\/ IsFailure means the job completed with problems.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (jb *Build) IsAborted() bool {\r\n\treturn jb.Result != nil && *jb.Result == aborted\r\n}","code-length":39,"reference":"\/\/ IsAborted means something stopped the job before it could finish.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (jb *Build) ProwJobID() string {\r\n\tfor _, action := range jb.Actions {\r\n\t\tfor _, p := range action.Parameters {\r\n\t\t\tif p.Name == prowJobID {\r\n\t\t\t\tvalue, ok := p.Value.(string)\r\n\t\t\t\tif !ok {\r\n\t\t\t\t\tlogrus.Errorf(\"Cannot determine %s value for %#v\", p.Name, jb)\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\treturn value\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn \"\"\r\n}","code-length":149,"reference":"\/\/ ProwJobID extracts the ProwJob identifier for the\n\/\/ Jenkins build in order to correlate the build with\n\/\/ a ProwJob. If the build has an empty PROW_JOB_ID\n\/\/ it didn't start by prow.","result":"Generate the code.","score":[0.0,0.0162]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (jb *Build) BuildID() string {\r\n\tvar buildID string\r\n\thasProwJobID := false\r\n\tfor _, action := range jb.Actions {\r\n\t\tfor _, p := range action.Parameters {\r\n\t\t\thasProwJobID = hasProwJobID || p.Name == prowJobID\r\n\t\t\tif p.Name == statusBuildID {\r\n\t\t\t\tvalue, ok := p.Value.(string)\r\n\t\t\t\tif !ok {\r\n\t\t\t\t\tlogrus.Errorf(\"Cannot determine %s value for %#v\", p.Name, jb)\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\tbuildID = value\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif !hasProwJobID {\r\n\t\treturn \"\"\r\n\t}\r\n\treturn buildID\r\n}","code-length":211,"reference":"\/\/ BuildID extracts the build identifier used for\n\/\/ placing and discovering build artifacts.\n\/\/ This identifier can either originate from tot\n\/\/ or the snowflake library, depending on how the\n\/\/ Jenkins operator is configured to run.\n\/\/ We return an empty string if we are dealing with\n\/\/ a build that does not have the ProwJobID set\n\/\/ explicitly, as in that case the Jenkins build has\n\/\/ not started by prow.","result":"Determine the build ID of.","score":[0.0,0.0149]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) CrumbRequest() error {\r\n\tif c.authConfig.csrfToken != \"\" && c.authConfig.csrfRequestField != \"\" {\r\n\t\treturn nil\r\n\t}\r\n\tc.logger.Debug(\"CrumbRequest\")\r\n\tdata, err := c.GetSkipMetrics(\"\/crumbIssuer\/api\/json\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tcrumbResp := struct {\r\n\t\tCrumb             string `json:\"crumb\"`\r\n\t\tCrumbRequestField string `json:\"crumbRequestField\"`\r\n\t}{}\r\n\tif err := json.Unmarshal(data, &crumbResp); err != nil {\r\n\t\treturn fmt.Errorf(\"cannot unmarshal crumb response: %v\", err)\r\n\t}\r\n\tc.authConfig.csrfToken = crumbResp.Crumb\r\n\tc.authConfig.csrfRequestField = crumbResp.CrumbRequestField\r\n\treturn nil\r\n}","code-length":241,"reference":"\/\/ CrumbRequest requests a CSRF protection token from Jenkins to\n\/\/ use it in subsequent requests. Required for Jenkins masters that\n\/\/ prevent cross site request forgery exploits.","result":"Generate code for the generated code.","score":[0.0049,0.0194]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) measure(method, path string, code int, start time.Time) {\r\n\tif c.metrics == nil {\r\n\t\treturn\r\n\t}\r\n\tc.metrics.RequestLatency.WithLabelValues(method, path).Observe(time.Since(start).Seconds())\r\n\tc.metrics.Requests.WithLabelValues(method, path, fmt.Sprintf(\"%d\", code)).Inc()\r\n}","code-length":111,"reference":"\/\/ measure records metrics about the provided method, path, and code.\n\/\/ start needs to be recorded before doing the request.","result":"Measure the request latency.","score":[0.0046,0.0518]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) GetSkipMetrics(path string) ([]byte, error) {\r\n\tresp, err := c.request(http.MethodGet, path, nil, false)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn readResp(resp)\r\n}","code-length":83,"reference":"\/\/ GetSkipMetrics fetches the data found in the provided path. It returns the\n\/\/ content of the response or any errors that occurred during the request or\n\/\/ http errors. Metrics will not be gathered for this request.","result":"Get skip metrics.","score":[0,0.0145]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Get(path string) ([]byte, error) {\r\n\tresp, err := c.request(http.MethodGet, path, nil, true)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn readResp(resp)\r\n}","code-length":81,"reference":"\/\/ Get fetches the data found in the provided path. It returns the\n\/\/ content of the response or any errors that occurred during the\n\/\/ request or http errors.","result":"Call the Get method.","score":[0.0006,0.0365]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) request(method, path string, params url.Values, measure bool) (*http.Response, error) {\r\n\tvar resp *http.Response\r\n\tvar err error\r\n\tbackoff := retryDelay\r\n\turlPath := fmt.Sprintf(\"%s%s\", c.baseURL, path)\r\n\tif params != nil {\r\n\t\turlPath = fmt.Sprintf(\"%s?%s\", urlPath, params.Encode())\r\n\t}\r\n\tstart := time.Now()\r\n\tfor retries := 0; retries < maxRetries; retries++ {\r\n\t\tresp, err = c.doRequest(method, urlPath)\r\n\t\tif err == nil && resp.StatusCode < 500 {\r\n\t\t\tbreak\r\n\t\t} else if err == nil && retries+1 < maxRetries {\r\n\t\t\tresp.Body.Close()\r\n\t\t}\r\n\t\t\r\n\t\tif measure && c.metrics != nil {\r\n\t\t\tc.metrics.RequestRetries.Inc()\r\n\t\t}\r\n\t\ttime.Sleep(backoff)\r\n\t\tbackoff *= 2\r\n\t}\r\n\tif measure && resp != nil {\r\n\t\tc.measure(method, path, resp.StatusCode, start)\r\n\t}\r\n\treturn resp, err\r\n}","code-length":311,"reference":"\/\/ request executes a request with the provided method and path.\n\/\/ It retries on transport failures and 500s. measure is provided\n\/\/ to enable or disable gathering metrics for specific requests\n\/\/ to avoid high-cardinality metrics.","result":"Create a new client.","score":[0.0001,0.0148]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) doRequest(method, path string) (*http.Response, error) {\r\n\treq, err := http.NewRequest(method, path, nil)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif c.authConfig != nil {\r\n\t\tif c.authConfig.Basic != nil {\r\n\t\t\treq.SetBasicAuth(c.authConfig.Basic.User, string(c.authConfig.Basic.GetToken()))\r\n\t\t}\r\n\t\tif c.authConfig.BearerToken != nil {\r\n\t\t\treq.Header.Set(\"Authorization\", fmt.Sprintf(\"Bearer %s\", c.authConfig.BearerToken.GetToken()))\r\n\t\t}\r\n\t\tif c.authConfig.CSRFProtect && c.authConfig.csrfRequestField != \"\" && c.authConfig.csrfToken != \"\" {\r\n\t\t\treq.Header.Set(c.authConfig.csrfRequestField, c.authConfig.csrfToken)\r\n\t\t}\r\n\t}\r\n\treturn c.client.Do(req)\r\n}","code-length":269,"reference":"\/\/ doRequest executes a request with the provided method and path\n\/\/ exactly once. It sets up authentication if the jenkins client\n\/\/ is configured accordingly. It's up to callers of this function\n\/\/ to build retries and error handling.","result":"Generate the code for the client .","score":[0.0019,0.0409]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getJobName(spec *prowapi.ProwJobSpec) string {\r\n\tif spec.JenkinsSpec != nil && spec.JenkinsSpec.GitHubBranchSourceJob && spec.Refs != nil {\r\n\t\tif len(spec.Refs.Pulls) > 0 {\r\n\t\t\treturn fmt.Sprintf(\"%s\/view\/change-requests\/job\/PR-%d\", spec.Job, spec.Refs.Pulls[0].Number)\r\n\t\t}\r\n\t\treturn fmt.Sprintf(\"%s\/job\/%s\", spec.Job, spec.Refs.BaseRef)\r\n\t}\r\n\treturn spec.Job\r\n}","code-length":157,"reference":"\/\/ getJobName generates the correct job name for this job type","result":"Generate the job name.","score":[0.066,0.2481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getBuildPath(spec *prowapi.ProwJobSpec) string {\r\n\tjenkinsJobName := getJobName(spec)\r\n\tjenkinsPath := fmt.Sprintf(\"\/job\/%s\/build\", jenkinsJobName)\r\n\treturn jenkinsPath\r\n}","code-length":71,"reference":"\/\/ getBuildPath builds a path to trigger a regular build for this job","result":"Generate the build path.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) GetJobInfo(spec *prowapi.ProwJobSpec) (*JobInfo, error) {\r\n\tpath := getJobInfoPath(spec)\r\n\tc.logger.Debugf(\"getJobInfoPath: %s\", path)\r\n\tdata, err := c.Get(path)\r\n\tif err != nil {\r\n\t\tc.logger.Errorf(\"Failed to get job info: %v\", err)\r\n\t\treturn nil, err\r\n\t}\r\n\tvar jobInfo JobInfo\r\n\tif err := json.Unmarshal(data, &jobInfo); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"Cannot unmarshal job info from API: %v\", err)\r\n\t}\r\n\tc.logger.Tracef(\"JobInfo: %+v\", jobInfo)\r\n\treturn &jobInfo, nil\r\n}","code-length":209,"reference":"\/\/ GetJobInfo retrieves Jenkins job information","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) JobParameterized(jobInfo *JobInfo) bool {\r\n\tfor _, prop := range jobInfo.Property {\r\n\t\tif prop.ParameterDefinitions != nil && len(prop.ParameterDefinitions) > 0 {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":85,"reference":"\/\/ JobParameterized tells us if the Jenkins job for this ProwJob is parameterized","result":"Generate the code.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) EnsureBuildableJob(spec *prowapi.ProwJobSpec) error {\r\n\tvar jobInfo *JobInfo\r\n\t\r\n\tgetJobInfoBackoff := wait.Backoff{\r\n\t\tDuration: time.Duration(10) * time.Second,\r\n\t\tFactor:   1,\r\n\t\tJitter:   0,\r\n\t\tSteps:    2,\r\n\t}\r\n\tgetJobErr := wait.ExponentialBackoff(getJobInfoBackoff, func() (bool, error) {\r\n\t\tvar jobErr error\r\n\t\tjobInfo, jobErr = c.GetJobInfo(spec)\r\n\t\tif jobErr != nil && !strings.Contains(strings.ToLower(jobErr.Error()), \"404 not found\") {\r\n\t\t\treturn false, jobErr\r\n\t\t}\r\n\t\treturn jobInfo != nil, nil\r\n\t})\r\n\tif getJobErr != nil {\r\n\t\treturn fmt.Errorf(\"Job %v does not exist\", spec.Job)\r\n\t}\r\n\tisParameterized := c.JobParameterized(jobInfo)\r\n\tc.logger.Tracef(\"JobHasParameters: %v\", isParameterized)\r\n\tif isParameterized || len(jobInfo.Builds) > 0 {\r\n\t\treturn nil\r\n\t}\r\n\tbuildErr := c.LaunchBuild(spec, nil)\r\n\tif buildErr != nil {\r\n\t\treturn buildErr\r\n\t}\r\n\tbackoff := wait.Backoff{\r\n\t\tDuration: time.Duration(5) * time.Second,\r\n\t\tFactor:   1,\r\n\t\tJitter:   1,\r\n\t\tSteps:    10,\r\n\t}\r\n\treturn wait.ExponentialBackoff(backoff, func() (bool, error) {\r\n\t\tc.logger.Debugf(\"Waiting for job %v to become parameterized\", spec.Job)\r\n\t\tjobInfo, _ := c.GetJobInfo(spec)\r\n\t\tisParameterized := false\r\n\t\tif jobInfo != nil {\r\n\t\t\tisParameterized = c.JobParameterized(jobInfo)\r\n\t\t\tif isParameterized && jobInfo.LastBuild != nil {\r\n\t\t\t\tc.logger.Debugf(\"Job %v is now parameterized, aborting the build\", spec.Job)\r\n\t\t\t\terr := c.Abort(getJobName(spec), jobInfo.LastBuild)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tc.logger.Infof(\"Couldn't abort build #%v for job %v: %v\", jobInfo.LastBuild.Number, spec.Job, err)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\treturn isParameterized, nil\r\n\t})\r\n}","code-length":646,"reference":"\/\/ EnsureBuildableJob attempts to detect a job that hasn't yet ran and populated\n\/\/ its parameters. If detected, it tries to run a build until the job parameters\n\/\/ are processed, then it aborts the build.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) LaunchBuild(spec *prowapi.ProwJobSpec, params url.Values) error {\r\n\tvar path string\r\n\tif params != nil {\r\n\t\tpath = getBuildWithParametersPath(spec)\r\n\t} else {\r\n\t\tpath = getBuildPath(spec)\r\n\t}\r\n\tc.logger.Debugf(\"getBuildPath\/getBuildWithParametersPath: %s\", path)\r\n\tresp, err := c.request(http.MethodPost, path, params, true)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\tif resp.StatusCode != 201 {\r\n\t\treturn fmt.Errorf(\"response not 201: %s\", resp.Status)\r\n\t}\r\n\treturn nil\r\n}","code-length":200,"reference":"\/\/ LaunchBuild launches a regular or parameterized Jenkins build, depending on\n\/\/ whether or not we have `params` to POST","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Build(pj *prowapi.ProwJob, buildID string) error {\r\n\tc.logger.WithFields(pjutil.ProwJobFields(pj)).Info(\"Build\")\r\n\treturn c.BuildFromSpec(&pj.Spec, buildID, pj.ObjectMeta.Name)\r\n}","code-length":91,"reference":"\/\/ Build triggers a Jenkins build for the provided ProwJob. The name of\n\/\/ the ProwJob is going to be used as the Prow Job ID parameter that will\n\/\/ help us track the build before it's scheduled by Jenkins.","result":"Build the pj.","score":[0.0,0.0275]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) BuildFromSpec(spec *prowapi.ProwJobSpec, buildID, prowJobID string) error {\r\n\tif c.dryRun {\r\n\t\treturn nil\r\n\t}\r\n\tenv, err := downwardapi.EnvForSpec(downwardapi.NewJobSpec(*spec, buildID, prowJobID))\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tparams := url.Values{}\r\n\tfor key, value := range env {\r\n\t\tparams.Set(key, value)\r\n\t}\r\n\tif err := c.EnsureBuildableJob(spec); err != nil {\r\n\t\treturn fmt.Errorf(\"Job %v cannot be build: %v\", spec.Job, err)\r\n\t}\r\n\treturn c.LaunchBuild(spec, params)\r\n}","code-length":211,"reference":"\/\/ BuildFromSpec triggers a Jenkins build for the provided ProwJobSpec.\n\/\/ prowJobID helps us track the build before it's scheduled by Jenkins.","result":"Generate the generated code.","score":[0.0035,0.0248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) GetEnqueuedBuilds(jobs []BuildQueryParams) (map[string]Build, error) {\r\n\tc.logger.Debug(\"GetEnqueuedBuilds\")\r\n\tdata, err := c.Get(\"\/queue\/api\/json?tree=items[task[name],actions[parameters[name,value]]]\")\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"cannot list builds from the queue: %v\", err)\r\n\t}\r\n\tpage := struct {\r\n\t\tQueuedBuilds []Build `json:\"items\"`\r\n\t}{}\r\n\tif err := json.Unmarshal(data, &page); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"cannot unmarshal builds from the queue: %v\", err)\r\n\t}\r\n\tjenkinsBuilds := make(map[string]Build)\r\n\tfor _, jb := range page.QueuedBuilds {\r\n\t\tprowJobID := jb.ProwJobID()\r\n\t\t\r\n\t\tif prowJobID == \"\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tvar exists bool\r\n\t\tfor _, job := range jobs {\r\n\t\t\tif prowJobID == job.ProwJobID {\r\n\t\t\t\texists = true\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif !exists {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tjb.enqueued = true\r\n\t\tjenkinsBuilds[prowJobID] = jb\r\n\t}\r\n\treturn jenkinsBuilds, nil\r\n}","code-length":381,"reference":"\/\/ GetEnqueuedBuilds lists all enqueued builds for the provided jobs.","result":"Get the build jobs from the queue.","score":[0.1052,0.1031]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Abort(job string, build *Build) error {\r\n\tc.logger.Debugf(\"Abort(%v %v)\", job, build.Number)\r\n\tif c.dryRun {\r\n\t\treturn nil\r\n\t}\r\n\tresp, err := c.request(http.MethodPost, fmt.Sprintf(\"\/job\/%s\/%d\/stop\", job, build.Number), nil, false)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\tif resp.StatusCode < 200 || resp.StatusCode >= 300 {\r\n\t\treturn fmt.Errorf(\"response not 2XX: %s\", resp.Status)\r\n\t}\r\n\treturn nil\r\n}","code-length":184,"reference":"\/\/ Abort aborts the provided Jenkins build for job.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PresubmitToJobSpec(pre config.Presubmit) *downwardapi.JobSpec {\r\n\treturn &downwardapi.JobSpec{\r\n\t\tType: prowapi.PresubmitJob,\r\n\t\tJob:  pre.Name,\r\n\t}\r\n}","code-length":77,"reference":"\/\/ PresubmitToJobSpec generates a downwardapi.JobSpec out of a Presubmit.\n\/\/ Useful for figuring out GCS paths when parsing jobs out\n\/\/ of a prow config.","result":"Generate the job spec.","score":[0,0.0437]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PostsubmitToJobSpec(post config.Postsubmit) *downwardapi.JobSpec {\r\n\treturn &downwardapi.JobSpec{\r\n\t\tType: prowapi.PostsubmitJob,\r\n\t\tJob:  post.Name,\r\n\t}\r\n}","code-length":74,"reference":"\/\/ PostsubmitToJobSpec generates a downwardapi.JobSpec out of a Postsubmit.\n\/\/ Useful for figuring out GCS paths when parsing jobs out\n\/\/ of a prow config.","result":"Convert postsubmit config to job spec.","score":[0,0.0216]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PeriodicToJobSpec(periodic config.Periodic) *downwardapi.JobSpec {\r\n\treturn &downwardapi.JobSpec{\r\n\t\tType: prowapi.PeriodicJob,\r\n\t\tJob:  periodic.Name,\r\n\t}\r\n}","code-length":73,"reference":"\/\/ PeriodicToJobSpec generates a downwardapi.JobSpec out of a Periodic.\n\/\/ Useful for figuring out GCS paths when parsing jobs out\n\/\/ of a prow config.","result":"Generate the job spec.","score":[0,0.0437]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetBuildID(name, totURL string) (string, error) {\r\n\tif totURL == \"\" {\r\n\t\treturn node.Generate().String(), nil\r\n\t}\r\n\tvar err error\r\n\turl, err := url.Parse(totURL)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"invalid tot url: %v\", err)\r\n\t}\r\n\turl.Path = path.Join(url.Path, \"vend\", name)\r\n\tsleepDuration := 100 * time.Millisecond\r\n\tfor retries := 0; retries < 10; retries++ {\r\n\t\tif retries > 0 {\r\n\t\t\tsleep(sleepDuration)\r\n\t\t\tsleepDuration = sleepDuration * 2\r\n\t\t}\r\n\t\tvar resp *http.Response\r\n\t\tresp, err = http.Get(url.String())\r\n\t\tif err != nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tdefer resp.Body.Close()\r\n\t\tif resp.StatusCode != 200 {\r\n\t\t\terr = fmt.Errorf(\"got unexpected response from tot: %v\", resp.Status)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvar buf []byte\r\n\t\tbuf, err = ioutil.ReadAll(resp.Body)\r\n\t\tif err == nil {\r\n\t\t\treturn string(buf), nil\r\n\t\t}\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn \"\", err\r\n}","code-length":354,"reference":"\/\/ GetBuildID calls out to `tot` in order\n\/\/ to vend build identifier for the job","result":"Generate a unique build ID.","score":[0.0266,0.0336]}
{"code":"\/*is used to<extra_id_0>\r\nfunc listGcsObjects(ctx context.Context, client *storage.Client, bucketName, prefix, delim string) (\r\n\t[]string, error) {\r\n\tvar objects []string\r\n\tit := client.Bucket(bucketName).Objects(ctx, &storage.Query{\r\n\t\tPrefix:    prefix,\r\n\t\tDelimiter: delim,\r\n\t})\r\n\tfor {\r\n\t\tattrs, err := it.Next()\r\n\t\tif err == iterator.Done {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn objects, fmt.Errorf(\"error iterating: %v\", err)\r\n\t\t}\r\n\t\tif attrs.Prefix != \"\" {\r\n\t\t\tobjects = append(objects, path.Base(attrs.Prefix))\r\n\t\t}\r\n\t}\r\n\tlogrus.Info(\"end of listGcsObjects(...)\")\r\n\treturn objects, nil\r\n}","code-length":227,"reference":"\/\/listGcsObjects get the slice of gcs objects under a given path","result":"List GCS objects.","score":[0,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FindBaseProfile(ctx context.Context, client *storage.Client, bucket, prowJobName, artifactsDirName,\r\n\tcovProfileName string) ([]byte, error) {\r\n\tdirOfJob := path.Join(\"logs\", prowJobName)\r\n\tstrBuilds, err := listGcsObjects(ctx, client, bucket, dirOfJob+\"\/\", \"\/\")\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error listing gcs objects: %v\", err)\r\n\t}\r\n\tbuilds := sortBuilds(strBuilds)\r\n\tprofilePath := \"\"\r\n\tfor _, build := range builds {\r\n\t\tbuildDirPath := path.Join(dirOfJob, strconv.Itoa(build))\r\n\t\tdirOfStatusJSON := path.Join(buildDirPath, statusJSON)\r\n\t\tstatusText, err := readGcsObject(ctx, client, bucket, dirOfStatusJSON)\r\n\t\tif err != nil {\r\n\t\t\tlogrus.Infof(\"Cannot read finished.json (%s) in bucket '%s'\", dirOfStatusJSON, bucket)\r\n\t\t} else if isBuildSucceeded(statusText) {\r\n\t\t\tartifactsDirPath := path.Join(buildDirPath, artifactsDirName)\r\n\t\t\tprofilePath = path.Join(artifactsDirPath, covProfileName)\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif profilePath == \"\" {\r\n\t\treturn nil, fmt.Errorf(\"no healthy build found for job '%s' in bucket '%s'; total # builds = %v\", dirOfJob, bucket, len(builds))\r\n\t}\r\n\treturn readGcsObject(ctx, client, bucket, profilePath)\r\n}","code-length":401,"reference":"\/\/ FindBaseProfile finds the coverage profile file from the latest healthy build\n\/\/ stored in given gcs directory","result":"Find the base profile for a given job.","score":[0.0524,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc sortBuilds(strBuilds []string) []int {\r\n\tvar res []int\r\n\tfor _, buildStr := range strBuilds {\r\n\t\tnum, err := strconv.Atoi(buildStr)\r\n\t\tif err != nil {\r\n\t\t\tlogrus.Infof(\"Non-int build number found: '%s'\", buildStr)\r\n\t\t} else {\r\n\t\t\tres = append(res, num)\r\n\t\t}\r\n\t}\r\n\tsort.Sort(sort.Reverse(sort.IntSlice(res)))\r\n\treturn res\r\n}","code-length":144,"reference":"\/\/ sortBuilds converts all build from str to int and sorts all builds in descending order and\n\/\/ returns the sorted slice","result":"Sort the builds in the build list.","score":[0.0319,0.1815]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetAll(sess *session.Session) ([]string, error) {\r\n\tvar regions []string\r\n\tsvc := ec2.New(sess, &aws.Config{Region: aws.String(Default)})\r\n\tresp, err := svc.DescribeRegions(nil)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tfor _, region := range resp.Regions {\r\n\t\tregions = append(regions, *region.RegionName)\r\n\t}\r\n\treturn regions, nil\r\n}","code-length":135,"reference":"\/\/ GetAll retrieves all regions from the AWS API","result":"Get all the available regions.","score":[0.1284,0.1163]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewEventClient(ghc githubClient, log *logrus.Entry, org, repo string, number int) *EventClient {\r\n\treturn &EventClient{\r\n\t\torg:    org,\r\n\t\trepo:   repo,\r\n\t\tnumber: number,\r\n\t\tghc: ghc,\r\n\t\tlog: log,\r\n\t}\r\n}","code-length":97,"reference":"\/\/ NewEventClient creates an EventClient struct. This should be used once per webhook event.","result":"Create a new event client.","score":[0,0.0382]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *EventClient) PruneComments(shouldPrune func(github.IssueComment) bool) {\r\n\tc.once.Do(func() {\r\n\t\tbotName, err := c.ghc.BotName()\r\n\t\tif err != nil {\r\n\t\t\tc.log.WithError(err).Error(\"failed to get the bot's name. Pruning will consider all comments.\")\r\n\t\t}\r\n\t\tcomments, err := c.ghc.ListIssueComments(c.org, c.repo, c.number)\r\n\t\tif err != nil {\r\n\t\t\tc.log.WithError(err).Errorf(\"failed to list comments for %s\/%s#%d\", c.org, c.repo, c.number)\r\n\t\t}\r\n\t\tif botName != \"\" {\r\n\t\t\tfor _, comment := range comments {\r\n\t\t\t\tif comment.User.Login == botName {\r\n\t\t\t\t\tc.comments = append(c.comments, comment)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t})\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tvar remaining []github.IssueComment\r\n\tfor _, comment := range c.comments {\r\n\t\tremoved := false\r\n\t\tif shouldPrune(comment) {\r\n\t\t\tif err := c.ghc.DeleteComment(c.org, c.repo, comment.ID); err != nil {\r\n\t\t\t\tc.log.WithError(err).Errorf(\"failed to delete stale comment with ID '%d'\", comment.ID)\r\n\t\t\t} else {\r\n\t\t\t\tremoved = true\r\n\t\t\t}\r\n\t\t}\r\n\t\tif !removed {\r\n\t\t\tremaining = append(remaining, comment)\r\n\t\t}\r\n\t}\r\n\tc.comments = remaining\r\n}","code-length":442,"reference":"\/\/ PruneComments fetches issue comments if they have not yet been fetched for this webhook event\n\/\/ and then deletes any bot comments indicated by the func 'shouldPrune'.","result":"Prune comments from github events.","score":[0.0024,0.0195]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FormatResponse(to, message, reason string) string {\r\n\tformat := `@%s: %s\r\n<details>\r\n%s\r\n%s\r\n<\/details>`\r\n\treturn fmt.Sprintf(format, to, message, reason, AboutThisBotWithoutCommands)\r\n}","code-length":79,"reference":"\/\/ FormatResponse nicely formats a response to a generic reason.","result":"Format the response.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FormatSimpleResponse(to, message string) string {\r\n\tformat := `@%s: %s\r\n<details>\r\n%s\r\n<\/details>`\r\n\treturn fmt.Sprintf(format, to, message, AboutThisBotWithoutCommands)\r\n}","code-length":72,"reference":"\/\/ FormatSimpleResponse formats a response that does not warrant additional explanation in the\n\/\/ details section.","result":"Format the response.","score":[0.0054,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FormatICResponse(ic github.IssueComment, s string) string {\r\n\treturn FormatResponseRaw(ic.Body, ic.HTMLURL, ic.User.Login, s)\r\n}","code-length":53,"reference":"\/\/ FormatICResponse nicely formats a response to an issue comment.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FormatResponseRaw(body, bodyURL, login, reply string) string {\r\n\tformat := `In response to [this](%s):\r\n%s\r\n`\r\n\t\r\n\tvar quoted []string\r\n\tfor _, l := range strings.Split(body, \"\\n\") {\r\n\t\tquoted = append(quoted, \">\"+l)\r\n\t}\r\n\treturn FormatResponse(login, reply, fmt.Sprintf(format, bodyURL, strings.Join(quoted, \"\\n\")))\r\n}","code-length":129,"reference":"\/\/ FormatResponseRaw nicely formats a response for one does not have an issue comment","result":"Format the response.","score":[0,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *Options) Validate() error {\r\n\tif o.gcsPath.String() != \"\" {\r\n\t\to.Bucket = o.gcsPath.Bucket()\r\n\t\to.PathPrefix = o.gcsPath.Object()\r\n\t}\r\n\tif !o.DryRun {\r\n\t\tif o.Bucket == \"\" {\r\n\t\t\treturn errors.New(\"GCS upload was requested no GCS bucket was provided\")\r\n\t\t}\r\n\t\tif o.GcsCredentialsFile == \"\" {\r\n\t\t\treturn errors.New(\"GCS upload was requested but no GCS credentials file was provided\")\r\n\t\t}\r\n\t}\r\n\treturn o.GCSConfiguration.Validate()\r\n}","code-length":175,"reference":"\/\/ Validate ensures that the set of options are\n\/\/ self-consistent and valid.","result":"Validate the options.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Encode(options Options) (string, error) {\r\n\tencoded, err := json.Marshal(options)\r\n\treturn string(encoded), err\r\n}","code-length":46,"reference":"\/\/ Encode will encode the set of options in the format that\n\/\/ is expected for the configuration environment variable.","result":"Encode json.","score":[0.0001,0.0275]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterIssueHandler(name string, fn IssueHandler, help HelpProvider) {\r\n\tpluginHelp[name] = help\r\n\tissueHandlers[name] = fn\r\n}","code-length":49,"reference":"\/\/ RegisterIssueHandler registers a plugin's github.IssueEvent handler.","result":"Register issue handlers.","score":[0,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterIssueCommentHandler(name string, fn IssueCommentHandler, help HelpProvider) {\r\n\tpluginHelp[name] = help\r\n\tissueCommentHandlers[name] = fn\r\n}","code-length":52,"reference":"\/\/ RegisterIssueCommentHandler registers a plugin's github.IssueCommentEvent handler.","result":"Register a comment handler.","score":[0.1795,0.3814]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterPullRequestHandler(name string, fn PullRequestHandler, help HelpProvider) {\r\n\tpluginHelp[name] = help\r\n\tpullRequestHandlers[name] = fn\r\n}","code-length":50,"reference":"\/\/ RegisterPullRequestHandler registers a plugin's github.PullRequestEvent handler.","result":"Register plugins.","score":[0,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterStatusEventHandler(name string, fn StatusEventHandler, help HelpProvider) {\r\n\tpluginHelp[name] = help\r\n\tstatusEventHandlers[name] = fn\r\n}","code-length":50,"reference":"\/\/ RegisterStatusEventHandler registers a plugin's github.StatusEvent handler.","result":"Register plugin status event handlers.","score":[0,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterPushEventHandler(name string, fn PushEventHandler, help HelpProvider) {\r\n\tpluginHelp[name] = help\r\n\tpushEventHandlers[name] = fn\r\n}","code-length":50,"reference":"\/\/ RegisterPushEventHandler registers a plugin's github.PushEvent handler.","result":"Register push event handlers.","score":[0,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterReviewEventHandler(name string, fn ReviewEventHandler, help HelpProvider) {\r\n\tpluginHelp[name] = help\r\n\treviewEventHandlers[name] = fn\r\n}","code-length":50,"reference":"\/\/ RegisterReviewEventHandler registers a plugin's github.ReviewEvent handler.","result":"RegisterReviewEventHandler.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterReviewCommentEventHandler(name string, fn ReviewCommentEventHandler, help HelpProvider) {\r\n\tpluginHelp[name] = help\r\n\treviewCommentEventHandlers[name] = fn\r\n}","code-length":53,"reference":"\/\/ RegisterReviewCommentEventHandler registers a plugin's github.ReviewCommentEvent handler.","result":"Register events on review comments.","score":[0,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterGenericCommentHandler(name string, fn GenericCommentHandler, help HelpProvider) {\r\n\tpluginHelp[name] = help\r\n\tgenericCommentHandlers[name] = fn\r\n}","code-length":52,"reference":"\/\/ RegisterGenericCommentHandler registers a plugin's github.GenericCommentEvent handler.","result":"Register generic comment handlers.","score":[0,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewAgent(configAgent *config.Agent, pluginConfigAgent *ConfigAgent, clientAgent *ClientAgent, logger *logrus.Entry) Agent {\r\n\tprowConfig := configAgent.Config()\r\n\tpluginConfig := pluginConfigAgent.Config()\r\n\treturn Agent{\r\n\t\tGitHubClient:     clientAgent.GitHubClient,\r\n\t\tKubernetesClient: clientAgent.KubernetesClient,\r\n\t\tProwJobClient:    clientAgent.ProwJobClient,\r\n\t\tGitClient:        clientAgent.GitClient,\r\n\t\tSlackClient:      clientAgent.SlackClient,\r\n\t\tOwnersClient:     clientAgent.OwnersClient,\r\n\t\tConfig:           prowConfig,\r\n\t\tPluginConfig:     pluginConfig,\r\n\t\tLogger:           logger,\r\n\t}\r\n}","code-length":203,"reference":"\/\/ NewAgent bootstraps a new config.Agent struct from the passed dependencies.","result":"Create a new agent.","score":[0.0785,0.182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Agent) InitializeCommentPruner(org, repo string, pr int) {\r\n\ta.commentPruner = commentpruner.NewEventClient(\r\n\t\ta.GitHubClient, a.Logger.WithField(\"client\", \"commentpruner\"),\r\n\t\torg, repo, pr,\r\n\t)\r\n}","code-length":87,"reference":"\/\/ InitializeCommentPruner attaches a commentpruner.EventClient to the agent to handle\n\/\/ pruning comments.","result":"Initialize comment pruner.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Agent) CommentPruner() (*commentpruner.EventClient, error) {\r\n\tif a.commentPruner == nil {\r\n\t\treturn nil, errors.New(\"comment pruner client never initialized\")\r\n\t}\r\n\treturn a.commentPruner, nil\r\n}","code-length":79,"reference":"\/\/ CommentPruner will return the commentpruner.EventClient attached to the agent or an error\n\/\/ if one is not attached.","result":"Start comment pruner.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) Load(path string) error {\r\n\tb, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tnp := &Configuration{}\r\n\tif err := yaml.Unmarshal(b, np); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := np.Validate(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tpa.Set(np)\r\n\treturn nil\r\n}","code-length":132,"reference":"\/\/ Load attempts to load config from the path. It returns an error if either\n\/\/ the file can't be read or the configuration is invalid.","result":"Load the configuration file.","score":[0.002,0.1074]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) Config() *Configuration {\r\n\tpa.mut.Lock()\r\n\tdefer pa.mut.Unlock()\r\n\treturn pa.configuration\r\n}","code-length":50,"reference":"\/\/ Config returns the agent current Configuration.","result":"Generate the config file.","score":[0.1509,0.1493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) Set(pc *Configuration) {\r\n\tpa.mut.Lock()\r\n\tdefer pa.mut.Unlock()\r\n\tpa.configuration = pc\r\n}","code-length":53,"reference":"\/\/ Set attempts to set the plugins that are enabled on repos. Plugins are listed\n\/\/ as a map from repositories to the list of plugins that are enabled on them.\n\/\/ Specifying simply an org name will also work, and will enable the plugin on\n\/\/ all repos in the org.","result":"Set the configuration.","score":[0.0,0.0212]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) Start(path string) error {\r\n\tif err := pa.Load(path); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tticker := time.Tick(1 * time.Minute)\r\n\tgo func() {\r\n\t\tfor range ticker {\r\n\t\t\tif err := pa.Load(path); err != nil {\r\n\t\t\t\tlogrus.WithField(\"path\", path).WithError(err).Error(\"Error loading plugin config.\")\r\n\t\t\t}\r\n\t\t}\r\n\t}()\r\n\treturn nil\r\n}","code-length":146,"reference":"\/\/ Start starts polling path for plugin config. If the first attempt fails,\n\/\/ then start returns the error. Future errors will halt updates but not stop.","result":"Start the agent.","score":[0.0002,0.0407]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) GenericCommentHandlers(owner, repo string) map[string]GenericCommentHandler {\r\n\tpa.mut.Lock()\r\n\tdefer pa.mut.Unlock()\r\n\ths := map[string]GenericCommentHandler{}\r\n\tfor _, p := range pa.getPlugins(owner, repo) {\r\n\t\tif h, ok := genericCommentHandlers[p]; ok {\r\n\t\t\ths[p] = h\r\n\t\t}\r\n\t}\r\n\treturn hs\r\n}","code-length":128,"reference":"\/\/ GenericCommentHandlers returns a map of plugin names to handlers for the repo.","result":"Generate the code.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) IssueHandlers(owner, repo string) map[string]IssueHandler {\r\n\tpa.mut.Lock()\r\n\tdefer pa.mut.Unlock()\r\n\ths := map[string]IssueHandler{}\r\n\tfor _, p := range pa.getPlugins(owner, repo) {\r\n\t\tif h, ok := issueHandlers[p]; ok {\r\n\t\t\ths[p] = h\r\n\t\t}\r\n\t}\r\n\treturn hs\r\n}","code-length":124,"reference":"\/\/ IssueHandlers returns a map of plugin names to handlers for the repo.","result":"Generate the code.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) IssueCommentHandlers(owner, repo string) map[string]IssueCommentHandler {\r\n\tpa.mut.Lock()\r\n\tdefer pa.mut.Unlock()\r\n\ths := map[string]IssueCommentHandler{}\r\n\tfor _, p := range pa.getPlugins(owner, repo) {\r\n\t\tif h, ok := issueCommentHandlers[p]; ok {\r\n\t\t\ths[p] = h\r\n\t\t}\r\n\t}\r\n\treturn hs\r\n}","code-length":128,"reference":"\/\/ IssueCommentHandlers returns a map of plugin names to handlers for the repo.","result":"Register issue comment handlers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) PullRequestHandlers(owner, repo string) map[string]PullRequestHandler {\r\n\tpa.mut.Lock()\r\n\tdefer pa.mut.Unlock()\r\n\ths := map[string]PullRequestHandler{}\r\n\tfor _, p := range pa.getPlugins(owner, repo) {\r\n\t\tif h, ok := pullRequestHandlers[p]; ok {\r\n\t\t\ths[p] = h\r\n\t\t}\r\n\t}\r\n\treturn hs\r\n}","code-length":125,"reference":"\/\/ PullRequestHandlers returns a map of plugin names to handlers for the repo.","result":"Get the list of pull.","score":[0.0577,0.123]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) ReviewEventHandlers(owner, repo string) map[string]ReviewEventHandler {\r\n\tpa.mut.Lock()\r\n\tdefer pa.mut.Unlock()\r\n\ths := map[string]ReviewEventHandler{}\r\n\tfor _, p := range pa.getPlugins(owner, repo) {\r\n\t\tif h, ok := reviewEventHandlers[p]; ok {\r\n\t\t\ths[p] = h\r\n\t\t}\r\n\t}\r\n\treturn hs\r\n}","code-length":126,"reference":"\/\/ ReviewEventHandlers returns a map of plugin names to handlers for the repo.","result":"Get the map of review.","score":[0.0759,0.2095]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) ReviewCommentEventHandlers(owner, repo string) map[string]ReviewCommentEventHandler {\r\n\tpa.mut.Lock()\r\n\tdefer pa.mut.Unlock()\r\n\ths := map[string]ReviewCommentEventHandler{}\r\n\tfor _, p := range pa.getPlugins(owner, repo) {\r\n\t\tif h, ok := reviewCommentEventHandlers[p]; ok {\r\n\t\t\ths[p] = h\r\n\t\t}\r\n\t}\r\n\treturn hs\r\n}","code-length":130,"reference":"\/\/ ReviewCommentEventHandlers returns a map of plugin names to handlers for the repo.","result":"Register event handlers for plugins.","score":[0.0686,0.1537]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) StatusEventHandlers(owner, repo string) map[string]StatusEventHandler {\r\n\tpa.mut.Lock()\r\n\tdefer pa.mut.Unlock()\r\n\ths := map[string]StatusEventHandler{}\r\n\tfor _, p := range pa.getPlugins(owner, repo) {\r\n\t\tif h, ok := statusEventHandlers[p]; ok {\r\n\t\t\ths[p] = h\r\n\t\t}\r\n\t}\r\n\treturn hs\r\n}","code-length":126,"reference":"\/\/ StatusEventHandlers returns a map of plugin names to handlers for the repo.","result":"Get the status event handlers.","score":[0.0485,0.041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) PushEventHandlers(owner, repo string) map[string]PushEventHandler {\r\n\tpa.mut.Lock()\r\n\tdefer pa.mut.Unlock()\r\n\ths := map[string]PushEventHandler{}\r\n\tfor _, p := range pa.getPlugins(owner, repo) {\r\n\t\tif h, ok := pushEventHandlers[p]; ok {\r\n\t\t\ths[p] = h\r\n\t\t}\r\n\t}\r\n\treturn hs\r\n}","code-length":126,"reference":"\/\/ PushEventHandlers returns a map of plugin names to handlers for the repo.","result":"Get push event handlers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EventsForPlugin(name string) []string {\r\n\tvar events []string\r\n\tif _, ok := issueHandlers[name]; ok {\r\n\t\tevents = append(events, \"issue\")\r\n\t}\r\n\tif _, ok := issueCommentHandlers[name]; ok {\r\n\t\tevents = append(events, \"issue_comment\")\r\n\t}\r\n\tif _, ok := pullRequestHandlers[name]; ok {\r\n\t\tevents = append(events, \"pull_request\")\r\n\t}\r\n\tif _, ok := pushEventHandlers[name]; ok {\r\n\t\tevents = append(events, \"push\")\r\n\t}\r\n\tif _, ok := reviewEventHandlers[name]; ok {\r\n\t\tevents = append(events, \"pull_request_review\")\r\n\t}\r\n\tif _, ok := reviewCommentEventHandlers[name]; ok {\r\n\t\tevents = append(events, \"pull_request_review_comment\")\r\n\t}\r\n\tif _, ok := statusEventHandlers[name]; ok {\r\n\t\tevents = append(events, \"status\")\r\n\t}\r\n\tif _, ok := genericCommentHandlers[name]; ok {\r\n\t\tevents = append(events, \"GenericCommentEvent (any event for user text)\")\r\n\t}\r\n\treturn events\r\n}","code-length":322,"reference":"\/\/ EventsForPlugin returns the registered events for the passed plugin.","result":"Generate the events for plugins.","score":[0.1383,0.269]}
{"code":"\/*is used to<extra_id_0>\r\nfunc insertLink(started *gcs.Started, viewURL string) (bool, error) {\r\n\tif started.Metadata == nil {\r\n\t\tstarted.Metadata = metadata.Metadata{}\r\n\t}\r\n\tmeta := started.Metadata\r\n\tvar changed bool\r\n\ttop, present := meta.String(resultstoreKey)\r\n\tif !present || top == nil || *top != viewURL {\r\n\t\tchanged = true\r\n\t\tmeta[resultstoreKey] = viewURL\r\n\t}\r\n\tlinks, present := meta.Meta(linksKey)\r\n\tif present && links == nil {\r\n\t\treturn false, fmt.Errorf(\"metadata.links is not a Metadata value: %v\", meta[linksKey])\r\n\t}\r\n\tif links == nil {\r\n\t\tlinks = &metadata.Metadata{}\r\n\t\tchanged = true\r\n\t}\r\n\tresultstoreMeta, present := links.Meta(resultstoreKey)\r\n\tif present && resultstoreMeta == nil {\r\n\t\treturn false, fmt.Errorf(\"metadata.links.resultstore is not a Metadata value: %v\", (*links)[resultstoreKey])\r\n\t}\r\n\tif resultstoreMeta == nil {\r\n\t\tresultstoreMeta = &metadata.Metadata{}\r\n\t\tchanged = true\r\n\t}\r\n\tval, present := resultstoreMeta.String(urlKey)\r\n\tif present && val == nil {\r\n\t\treturn false, fmt.Errorf(\"metadata.links.resultstore.url is not a string value: %v\", (*resultstoreMeta)[urlKey])\r\n\t}\r\n\tif !changed && val != nil && *val == viewURL {\r\n\t\treturn false, nil\r\n\t}\r\n\t(*resultstoreMeta)[urlKey] = viewURL\r\n\t(*links)[resultstoreKey] = *resultstoreMeta\r\n\tmeta[linksKey] = *links\r\n\treturn true, nil\r\n}","code-length":459,"reference":"\/\/ insertLink attempts to set metadata.links.resultstore.url to viewURL.\n\/\/\n\/\/ returns true if started metadata was updated.","result":"Insert a link to a started object.","score":[0.046,0.0625]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HelpProvider(enabledRepos []string) (*pluginhelp.PluginHelp, error) {\r\n\tpluginHelp := &pluginhelp.PluginHelp{\r\n\t\tDescription: `The cherrypick plugin is used for cherrypicking PRs across branches. For every successful cherrypick invocation a new PR is opened against the target branch and assigned to the requester. If the parent PR contains a release note, it is copied to the cherrypick PR.`,\r\n\t}\r\n\tpluginHelp.AddCommand(pluginhelp.Command{\r\n\t\tUsage:       \"\/cherrypick [branch]\",\r\n\t\tDescription: \"Cherrypick a PR to a different branch. This command works both in merged PRs (the cherrypick PR is opened immediately) and open PRs (the cherrypick PR opens as soon as the original PR merges).\",\r\n\t\tFeatured:    true,\r\n\t\t\r\n\t\tWhoCanUse: \"Members of the trusted organization for the repo.\",\r\n\t\tExamples:  []string{\"\/cherrypick release-3.9\"},\r\n\t})\r\n\treturn pluginHelp, nil\r\n}","code-length":274,"reference":"\/\/ HelpProvider construct the pluginhelp.PluginHelp for this plugin.","result":"Provide help for cherrypicking plugins.","score":[0.1319,0.0649]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Server) getPatch(org, repo, targetBranch string, num int) (string, error) {\r\n\tpatch, err := s.ghc.GetPullRequestPatch(org, repo, num)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tlocalPath := fmt.Sprintf(\"\/tmp\/%s_%s_%d_%s.patch\", org, repo, num, normalize(targetBranch))\r\n\tout, err := os.Create(localPath)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tdefer out.Close()\r\n\tif _, err := io.Copy(out, bytes.NewBuffer(patch)); err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn localPath, nil\r\n}","code-length":198,"reference":"\/\/ getPatch gets the patch for the provided PR and creates a local\n\/\/ copy of it. It returns its location in the filesystem and any\n\/\/ encountered error.","result":"Generate the generated code.","score":[0.0006,0.0189]}
{"code":"\/*is used to<extra_id_0>\r\nfunc releaseNoteFromParentPR(body string) string {\r\n\tpotentialMatch := releaseNoteRe.FindStringSubmatch(body)\r\n\tif potentialMatch == nil {\r\n\t\treturn \"\"\r\n\t}\r\n\treturn fmt.Sprintf(\"```release-note\\n%s\\n```\", strings.TrimSpace(potentialMatch[1]))\r\n}","code-length":92,"reference":"\/\/ releaseNoteNoteFromParentPR gets the release note from the\n\/\/ parent PR and formats it as per the PR template so that\n\/\/ it can be copied to the cherry-pick PR.","result":"Extract release notes from parent PR.","score":[0.005,0.1616]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ValidatePayload(payload []byte, sig string, key []byte) bool {\r\n\tif !strings.HasPrefix(sig, \"sha1=\") {\r\n\t\treturn false\r\n\t}\r\n\tsig = sig[5:]\r\n\tsb, err := hex.DecodeString(sig)\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\tmac := hmac.New(sha1.New, key)\r\n\tmac.Write(payload)\r\n\texpected := mac.Sum(nil)\r\n\treturn hmac.Equal(sb, expected)\r\n}","code-length":146,"reference":"\/\/ ValidatePayload ensures that the request payload signature matches the key.","result":"Validate payload.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PayloadSignature(payload []byte, key []byte) string {\r\n\tmac := hmac.New(sha1.New, key)\r\n\tmac.Write(payload)\r\n\tsum := mac.Sum(nil)\r\n\treturn \"sha1=\" + hex.EncodeToString(sum)\r\n}","code-length":78,"reference":"\/\/ PayloadSignature returns the signature that matches the payload.","result":"Generate the payload signature.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc updateString(have, want *string) bool {\r\n\tswitch {\r\n\tcase have == nil:\r\n\t\tpanic(\"have must be non-nil\")\r\n\tcase want == nil:\r\n\t\treturn false\r\n\tcase *have == *want:\r\n\t\treturn false\r\n\t}\r\n\t*have = *want\r\n\treturn true\r\n}","code-length":98,"reference":"\/\/ updateString will return true and set have to want iff they are set and different.","result":"Update the string field in the string field.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc updateBool(have, want *bool) bool {\r\n\tswitch {\r\n\tcase have == nil:\r\n\t\tpanic(\"have must not be nil\")\r\n\tcase want == nil:\r\n\t\treturn false\r\n\tcase *have == *want:\r\n\t\treturn false\r\n\t}\r\n\t*have = *want\r\n\treturn true\r\n}","code-length":97,"reference":"\/\/ updateBool will return true and set have to want iff they are set and different.","result":"Update a bool.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc configureOrgMeta(client orgMetadataClient, orgName string, want org.Metadata) error {\r\n\tcur, err := client.GetOrg(orgName)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to get %s metadata: %v\", orgName, err)\r\n\t}\r\n\tchange := false\r\n\tchange = updateString(&cur.BillingEmail, want.BillingEmail) || change\r\n\tchange = updateString(&cur.Company, want.Company) || change\r\n\tchange = updateString(&cur.Email, want.Email) || change\r\n\tchange = updateString(&cur.Name, want.Name) || change\r\n\tchange = updateString(&cur.Description, want.Description) || change\r\n\tchange = updateString(&cur.Location, want.Location) || change\r\n\tif want.DefaultRepositoryPermission != nil {\r\n\t\tw := string(*want.DefaultRepositoryPermission)\r\n\t\tchange = updateString(&cur.DefaultRepositoryPermission, &w)\r\n\t}\r\n\tchange = updateBool(&cur.HasOrganizationProjects, want.HasOrganizationProjects) || change\r\n\tchange = updateBool(&cur.HasRepositoryProjects, want.HasRepositoryProjects) || change\r\n\tchange = updateBool(&cur.MembersCanCreateRepositories, want.MembersCanCreateRepositories) || change\r\n\tif change {\r\n\t\tif _, err := client.EditOrg(orgName, *cur); err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to edit %s metadata: %v\", orgName, err)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":394,"reference":"\/\/ configureOrgMeta will update github to have the non-nil wanted metadata values.","result":"Configure org metadata.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc configureTeamRepos(client teamRepoClient, githubTeams map[string]github.Team, name, orgName string, team org.Team) error {\r\n\tgt, ok := githubTeams[name]\r\n\tif !ok {\r\n\t\treturn fmt.Errorf(\"%s not found in id list\", name)\r\n\t}\r\n\twant := team.Repos\r\n\thave := map[string]github.RepoPermissionLevel{}\r\n\trepos, err := client.ListTeamRepos(gt.ID)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to list team %d(%s) repos: %v\", gt.ID, name, err)\r\n\t}\r\n\tfor _, repo := range repos {\r\n\t\thave[repo.Name] = github.LevelFromPermissions(repo.Permissions)\r\n\t}\r\n\tactions := map[string]github.RepoPermissionLevel{}\r\n\tfor wantRepo, wantPermission := range want {\r\n\t\tif havePermission, haveRepo := have[wantRepo]; haveRepo && havePermission == wantPermission {\r\n\t\t\t\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tactions[wantRepo] = wantPermission\r\n\t}\r\n\tfor haveRepo := range have {\r\n\t\tif _, wantRepo := want[haveRepo]; !wantRepo {\r\n\t\t\t\r\n\t\t\tactions[haveRepo] = github.None\r\n\t\t}\r\n\t}\r\n\tvar updateErrors []error\r\n\tfor repo, permission := range actions {\r\n\t\tvar err error\r\n\t\tif permission == github.None {\r\n\t\t\terr = client.RemoveTeamRepo(gt.ID, orgName, repo)\r\n\t\t} else {\r\n\t\t\terr = client.UpdateTeamRepo(gt.ID, orgName, repo, permission)\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\tupdateErrors = append(updateErrors, fmt.Errorf(\"failed to update team %d(%s) permissions on repo %s to %s: %v\", gt.ID, name, repo, permission, err))\r\n\t\t}\r\n\t}\r\n\treturn errorutil.NewAggregate(updateErrors...)\r\n}","code-length":519,"reference":"\/\/ configureTeamRepos updates the list of repos that the team has permissions for when necessary","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) ShouldReport(pj *prowapi.ProwJob) bool {\r\n\tpubSubMap := findLabels(pj, PubSubProjectLabel, PubSubTopicLabel)\r\n\treturn pubSubMap[PubSubProjectLabel] != \"\" && pubSubMap[PubSubTopicLabel] != \"\"\r\n}","code-length":80,"reference":"\/\/ ShouldReport tells if a prowjob should be reported by this reporter","result":"Report the status of the job.","score":[0,0.0439]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Options) Run(spec *downwardapi.JobSpec, extra map[string]gcs.UploadFunc) error {\r\n\tuploadTargets := o.assembleTargets(spec, extra)\r\n\tif !o.DryRun {\r\n\t\tctx := context.Background()\r\n\t\tgcsClient, err := storage.NewClient(ctx, option.WithCredentialsFile(o.GcsCredentialsFile))\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"could not connect to GCS: %v\", err)\r\n\t\t}\r\n\t\tif err := gcs.Upload(gcsClient.Bucket(o.Bucket), uploadTargets); err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to upload to GCS: %v\", err)\r\n\t\t}\r\n\t} else {\r\n\t\tfor destination := range uploadTargets {\r\n\t\t\tlogrus.WithField(\"dest\", destination).Info(\"Would upload\")\r\n\t\t}\r\n\t}\r\n\tlogrus.Info(\"Finished upload to GCS\")\r\n\treturn nil\r\n}","code-length":255,"reference":"\/\/ Run will upload files to GCS as prescribed by\n\/\/ the options. Any extra files can be passed as\n\/\/ a parameter and will have the prefix prepended\n\/\/ to their destination in GCS, so the caller can\n\/\/ operate relative to the base of the GCS dir.","result":"Generate the code.","score":[0.0,0.0113]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DefaultFieldsFormatter) Format(entry *logrus.Entry) ([]byte, error) {\r\n\tdata := make(logrus.Fields, len(entry.Data)+len(d.DefaultFields))\r\n\tfor k, v := range d.DefaultFields {\r\n\t\tdata[k] = v\r\n\t}\r\n\tfor k, v := range entry.Data {\r\n\t\tdata[k] = v\r\n\t}\r\n\treturn d.WrappedFormatter.Format(&logrus.Entry{\r\n\t\tLogger:  entry.Logger,\r\n\t\tData:    data,\r\n\t\tTime:    entry.Time,\r\n\t\tLevel:   entry.Level,\r\n\t\tMessage: entry.Message,\r\n\t})\r\n}","code-length":189,"reference":"\/\/ Format implements logrus.Formatter's Format. We allocate a new Fields\n\/\/ map in order to not modify the caller's Entry, as that is not a thread\n\/\/ safe operation.","result":"Format the log entry .","score":[0.0024,0.0376]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (issue *Issue) FindLabels(regex *regexp.Regexp) []Label {\r\n\tlabels := []Label{}\r\n\tfor _, label := range issue.Labels {\r\n\t\tif regex.MatchString(label.Name) {\r\n\t\t\tlabels = append(labels, label)\r\n\t\t}\r\n\t}\r\n\treturn labels\r\n}","code-length":92,"reference":"\/\/ FindLabels returns the list of labels matching the regex","result":"Find labels in the issue.","score":[0.1051,0.1053]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *Options) AddFlags(flags *flag.FlagSet) {\r\n\tflags.StringVar(&o.Log, \"clone-log\", \"\", \"Path to the clone records log\")\r\n\to.Options.AddFlags(flags)\r\n}","code-length":68,"reference":"\/\/ AddFlags binds flags to options.","result":"Add flags to the options.","score":[0.3079,0.4331]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewAgent(config *config.GitHubOAuthConfig, logger *logrus.Entry) *Agent {\r\n\treturn &Agent{\r\n\t\tgc:     config,\r\n\t\tlogger: logger,\r\n\t}\r\n}","code-length":62,"reference":"\/\/ NewAgent returns a new GitHub OAuth Agent.","result":"Create a new agent.","score":[0.1662,0.3363]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ga *Agent) HandleLogin(client OAuthClient) http.HandlerFunc {\r\n\treturn func(w http.ResponseWriter, r *http.Request) {\r\n\t\tstateToken := xsrftoken.Generate(ga.gc.ClientSecret, \"\", \"\")\r\n\t\tstate := hex.EncodeToString([]byte(stateToken))\r\n\t\toauthSession, err := ga.gc.CookieStore.New(r, oauthSessionCookie)\r\n\t\toauthSession.Options.Secure = true\r\n\t\toauthSession.Options.HttpOnly = true\r\n\t\tif err != nil {\r\n\t\t\tga.serverError(w, \"Creating new OAuth session\", err)\r\n\t\t\treturn\r\n\t\t}\r\n\t\toauthSession.Options.MaxAge = 10 * 60\r\n\t\toauthSession.Values[stateKey] = state\r\n\t\tif err := oauthSession.Save(r, w); err != nil {\r\n\t\t\tga.serverError(w, \"Save oauth session\", err)\r\n\t\t\treturn\r\n\t\t}\r\n\t\tredirectURL := client.AuthCodeURL(state, oauth2.ApprovalForce, oauth2.AccessTypeOnline)\r\n\t\thttp.Redirect(w, r, redirectURL, http.StatusFound)\r\n\t}\r\n}","code-length":306,"reference":"\/\/ HandleLogin handles GitHub login request from front-end. It starts a new git oauth session and\n\/\/ redirect user to GitHub OAuth end-point for authentication.","result":"Log in to the Google Analytics API.","score":[0.0123,0.0216]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ga *Agent) HandleLogout(client OAuthClient) http.HandlerFunc {\r\n\treturn func(w http.ResponseWriter, r *http.Request) {\r\n\t\taccessTokenSession, err := ga.gc.CookieStore.Get(r, tokenSession)\r\n\t\tif err != nil {\r\n\t\t\tga.serverError(w, \"get cookie\", err)\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\taccessTokenSession.Options.MaxAge = -1\r\n\t\tif err := accessTokenSession.Save(r, w); err != nil {\r\n\t\t\tga.serverError(w, \"Save invalidated session on log out\", err)\r\n\t\t\treturn\r\n\t\t}\r\n\t\tloginCookie, err := r.Cookie(loginSession)\r\n\t\tif err == nil {\r\n\t\t\tloginCookie.MaxAge = -1\r\n\t\t\tloginCookie.Expires = time.Now().Add(-time.Hour * 24)\r\n\t\t\thttp.SetCookie(w, loginCookie)\r\n\t\t}\r\n\t\thttp.Redirect(w, r, ga.gc.FinalRedirectURL, http.StatusFound)\r\n\t}\r\n}","code-length":284,"reference":"\/\/ HandleLogout handles GitHub logout request from front-end. It invalidates cookie sessions and\n\/\/ redirect back to the front page.","result":"Handle logout requests.","score":[0.0014,0.0546]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ga *Agent) serverError(w http.ResponseWriter, action string, err error) {\r\n\tga.logger.WithError(err).Errorf(\"Error %s.\", action)\r\n\tmsg := fmt.Sprintf(\"500 Internal server error %s: %v\", action, err)\r\n\thttp.Error(w, msg, http.StatusInternalServerError)\r\n}","code-length":94,"reference":"\/\/ Handles server errors.","result":"Handle errors.","score":[0.1839,0.2632]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ResourcesConfigObject) FromItem(i common.Item) {\r\n\tc, err := common.ItemToResourcesConfig(i)\r\n\tif err == nil {\r\n\t\tin.fromConfig(c)\r\n\t}\r\n}","code-length":68,"reference":"\/\/ FromItem implements the Object interface","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ResourcesConfigCollection) GetItems() []Object {\r\n\tvar items []Object\r\n\tfor _, i := range in.Items {\r\n\t\titems = append(items, i)\r\n\t}\r\n\treturn items\r\n}","code-length":67,"reference":"\/\/ GetItems implements the Collection interface","result":"Generate code that generates the code that is generated by the go.","score":[0.0891,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ResourcesConfigCollection) SetItems(objects []Object) {\r\n\tvar items []*ResourcesConfigObject\r\n\tfor _, b := range objects {\r\n\t\titems = append(items, b.(*ResourcesConfigObject))\r\n\t}\r\n\tin.Items = items\r\n}","code-length":78,"reference":"\/\/ SetItems implements the Collection interface","result":"Set items of an ResourcesConfigCollection.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *RepoPermissionLevel) UnmarshalText(text []byte) error {\r\n\tv := RepoPermissionLevel(text)\r\n\tif _, ok := repoPermissionLevels[v]; !ok {\r\n\t\treturn fmt.Errorf(\"bad repo permission: %s not in %v\", v, repoPermissionLevels)\r\n\t}\r\n\t*l = v\r\n\treturn nil\r\n}","code-length":99,"reference":"\/\/ UnmarshalText validates the text is a valid string","result":"Unmarshal the repo permission level.","score":[0.108,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i Issue) IsAssignee(login string) bool {\r\n\tfor _, assignee := range i.Assignees {\r\n\t\tif NormLogin(login) == NormLogin(assignee.Login) {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":81,"reference":"\/\/ IsAssignee checks if a user is assigned to the issue.","result":"Check if the user is a member of a group.","score":[0.1747,0.4689]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i Issue) IsAuthor(login string) bool {\r\n\treturn NormLogin(i.User.Login) == NormLogin(login)\r\n}","code-length":44,"reference":"\/\/ IsAuthor checks if a user is the author of the issue.","result":"Check if the author is in the issue.","score":[0.1735,0.5471]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i Issue) HasLabel(labelToFind string) bool {\r\n\tfor _, label := range i.Labels {\r\n\t\tif strings.ToLower(label.Name) == strings.ToLower(labelToFind) {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":85,"reference":"\/\/ HasLabel checks if an issue has a given label.","result":"Check if a label exists in the issue.","score":[0.1286,0.2608]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pe PushEvent) Branch() string {\r\n\tref := strings.TrimPrefix(pe.Ref, \"refs\/heads\/\")\r\n\tref = strings.TrimPrefix(ref, \"refs\/tags\/\")\r\n\treturn ref\r\n}","code-length":65,"reference":"\/\/ Branch returns the name of the branch to which the user pushed.","result":"Get the branch of the event.","score":[0.1119,0.2566]}
{"code":"\/*is used to<extra_id_0>\r\nfunc truncate(in string) string {\r\n\tconst (\r\n\t\thalf = (maxLen - len(elide)) \/ 2\r\n\t)\r\n\tif len(in) <= maxLen {\r\n\t\treturn in\r\n\t}\r\n\treturn in[:half] + elide + in[len(in)-half:]\r\n}","code-length":87,"reference":"\/\/ truncate converts \"really long messages\" into \"really ... messages\".","result":"Truncate strings.","score":[0,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc reportStatus(ghc GitHubClient, pj prowapi.ProwJob) error {\r\n\trefs := pj.Spec.Refs\r\n\tif pj.Spec.Report {\r\n\t\tcontextState, err := prowjobStateToGitHubStatus(pj.Status.State)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tsha := refs.BaseSHA\r\n\t\tif len(refs.Pulls) > 0 {\r\n\t\t\tsha = refs.Pulls[0].SHA\r\n\t\t}\r\n\t\tif err := ghc.CreateStatus(refs.Org, refs.Repo, sha, github.Status{\r\n\t\t\tState:       contextState,\r\n\t\t\tDescription: truncate(pj.Status.Description),\r\n\t\t\tContext:     pj.Spec.Context,\r\n\t\t\tTargetURL:   pj.Status.URL,\r\n\t\t}); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":253,"reference":"\/\/ reportStatus should be called on any prowjob status changes","result":"Report status of a prowjob.","score":[0.0884,0.0526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc parseIssueComments(pj prowapi.ProwJob, botName string, ics []github.IssueComment) ([]int, []string, int) {\r\n\tvar delete []int\r\n\tvar previousComments []int\r\n\tvar latestComment int\r\n\tvar entries []string\r\n\t\r\n\tfor _, ic := range ics {\r\n\t\tif ic.User.Login != botName {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tif strings.HasPrefix(ic.Body, pj.Spec.Context) {\r\n\t\t\tdelete = append(delete, ic.ID)\r\n\t\t}\r\n\t\tif !strings.Contains(ic.Body, commentTag) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif latestComment != 0 {\r\n\t\t\tpreviousComments = append(previousComments, latestComment)\r\n\t\t}\r\n\t\tlatestComment = ic.ID\r\n\t\tvar tracking bool\r\n\t\tfor _, line := range strings.Split(ic.Body, \"\\n\") {\r\n\t\t\tline = strings.TrimSpace(line)\r\n\t\t\tif strings.HasPrefix(line, \"---\") {\r\n\t\t\t\ttracking = true\r\n\t\t\t} else if len(line) == 0 {\r\n\t\t\t\ttracking = false\r\n\t\t\t} else if tracking {\r\n\t\t\t\tentries = append(entries, line)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tvar newEntries []string\r\n\t\r\n\tfor i := range entries {\r\n\t\tkeep := true\r\n\t\tf1 := strings.Split(entries[i], \" | \")\r\n\t\tfor j := range entries {\r\n\t\t\tif i == j {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tf2 := strings.Split(entries[j], \" | \")\r\n\t\t\t\r\n\t\t\tif j > i && f2[0] == f1[0] {\r\n\t\t\t\tkeep = false\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tif pj.Spec.Context == f1[0] {\r\n\t\t\tkeep = false\r\n\t\t}\r\n\t\tif keep {\r\n\t\t\tnewEntries = append(newEntries, entries[i])\r\n\t\t}\r\n\t}\r\n\tvar createNewComment bool\r\n\tif string(pj.Status.State) == github.StatusFailure {\r\n\t\tnewEntries = append(newEntries, createEntry(pj))\r\n\t\tcreateNewComment = true\r\n\t}\r\n\tdelete = append(delete, previousComments...)\r\n\tif (createNewComment || len(newEntries) == 0) && latestComment != 0 {\r\n\t\tdelete = append(delete, latestComment)\r\n\t\tlatestComment = 0\r\n\t}\r\n\treturn delete, newEntries, latestComment\r\n}","code-length":679,"reference":"\/\/ parseIssueComments returns a list of comments to delete, a list of table\n\/\/ entries, and the ID of the comment to update. If there are no table entries\n\/\/ then don't make a new comment. Otherwise, if the comment to update is 0,\n\/\/ create a new comment.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc createComment(reportTemplate *template.Template, pj prowapi.ProwJob, entries []string) (string, error) {\r\n\tplural := \"\"\r\n\tif len(entries) > 1 {\r\n\t\tplural = \"s\"\r\n\t}\r\n\tvar b bytes.Buffer\r\n\tif reportTemplate != nil {\r\n\t\tif err := reportTemplate.Execute(&b, &pj); err != nil {\r\n\t\t\treturn \"\", err\r\n\t\t}\r\n\t}\r\n\tlines := []string{\r\n\t\tfmt.Sprintf(\"@%s: The following test%s **failed**, say `\/retest` to rerun them all:\", pj.Spec.Refs.Pulls[0].Author, plural),\r\n\t\t\"\",\r\n\t\t\"Test name | Commit | Details | Rerun command\",\r\n\t\t\"--- | --- | --- | ---\",\r\n\t}\r\n\tlines = append(lines, entries...)\r\n\tif reportTemplate != nil {\r\n\t\tlines = append(lines, \"\", b.String())\r\n\t}\r\n\tlines = append(lines, []string{\r\n\t\t\"\",\r\n\t\t\"<details>\",\r\n\t\t\"\",\r\n\t\tplugins.AboutThisBot,\r\n\t\t\"<\/details>\",\r\n\t\tcommentTag,\r\n\t}...)\r\n\treturn strings.Join(lines, \"\\n\"), nil\r\n}","code-length":345,"reference":"\/\/ createComment take a ProwJob and a list of entries generated with\n\/\/ createEntry and returns a nicely formatted comment. It may fail if template\n\/\/ execution fails.","result":"Create a comment for the prow job.","score":[0.008,0.0193]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lens Lens) Config() lenses.LensConfig {\r\n\treturn lenses.LensConfig{\r\n\t\tName:     name,\r\n\t\tTitle:    title,\r\n\t\tPriority: priority,\r\n\t}\r\n}","code-length":68,"reference":"\/\/ Config returns the lens's configuration.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lens Lens) Callback(artifacts []lenses.Artifact, resourceDir string, data string) string {\r\n\treturn \"\"\r\n}","code-length":41,"reference":"\/\/ Callback does nothing.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FormatRecord(record Record) string {\r\n\toutput := bytes.Buffer{}\r\n\tif record.Failed {\r\n\t\tfmt.Fprintln(&output, \"# FAILED!\")\r\n\t}\r\n\tfmt.Fprintf(&output, \"# Cloning %s\/%s at %s\", record.Refs.Org, record.Refs.Repo, record.Refs.BaseRef)\r\n\tif record.Refs.BaseSHA != \"\" {\r\n\t\tfmt.Fprintf(&output, \"(%s)\", record.Refs.BaseSHA)\r\n\t}\r\n\toutput.WriteString(\"\\n\")\r\n\tif len(record.Refs.Pulls) > 0 {\r\n\t\toutput.WriteString(\"# Checking out pulls:\\n\")\r\n\t\tfor _, pull := range record.Refs.Pulls {\r\n\t\t\tfmt.Fprintf(&output, \"#\\t%d\", pull.Number)\r\n\t\t\tif pull.SHA != \"\" {\r\n\t\t\t\tfmt.Fprintf(&output, \"(%s)\", pull.SHA)\r\n\t\t\t}\r\n\t\t\tfmt.Fprint(&output, \"\\n\")\r\n\t\t}\r\n\t}\r\n\tfor _, command := range record.Commands {\r\n\t\tfmt.Fprintf(&output, \"$ %s\\n\", command.Command)\r\n\t\tfmt.Fprint(&output, command.Output)\r\n\t\tif command.Error != \"\" {\r\n\t\t\tfmt.Fprintf(&output, \"# Error: %s\\n\", command.Error)\r\n\t\t}\r\n\t}\r\n\treturn output.String()\r\n}","code-length":386,"reference":"\/\/ FormatRecord describes the record in a human-readable\n\/\/ manner for inclusion into build logs","result":"Format the record.","score":[0.0075,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Namespace(ns string) *Client {\r\n\tnc := *c\r\n\tnc.namespace = ns\r\n\treturn &nc\r\n}","code-length":47,"reference":"\/\/ Namespace returns a copy of the client pointing at the specified namespace.","result":"Set the namespace.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFakeClient(deckURL string) *Client {\r\n\treturn &Client{\r\n\t\tnamespace: \"default\",\r\n\t\tdeckURL:   deckURL,\r\n\t\tclient:    &http.Client{},\r\n\t\tfake:      true,\r\n\t}\r\n}","code-length":79,"reference":"\/\/ NewFakeClient creates a client that doesn't do anything. If you provide a\n\/\/ deck URL then the client will hit that for the supported calls.","result":"Create a fake client.","score":[0.0013,0.042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClientInCluster(namespace string) (*Client, error) {\r\n\ttokenFile := \"\/var\/run\/secrets\/kubernetes.io\/serviceaccount\/token\"\r\n\ttoken, err := ioutil.ReadFile(tokenFile)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\trootCAFile := \"\/var\/run\/secrets\/kubernetes.io\/serviceaccount\/ca.crt\"\r\n\tcertData, err := ioutil.ReadFile(rootCAFile)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tcp := x509.NewCertPool()\r\n\tcp.AppendCertsFromPEM(certData)\r\n\ttr := &http.Transport{\r\n\t\tTLSClientConfig: &tls.Config{\r\n\t\t\tMinVersion: tls.VersionTLS12,\r\n\t\t\tRootCAs:    cp,\r\n\t\t},\r\n\t}\r\n\treturn &Client{\r\n\t\tlogger:    logrus.WithField(\"client\", \"kube\"),\r\n\t\tbaseURL:   inClusterBaseURL,\r\n\t\tclient:    &http.Client{Transport: tr, Timeout: requestTimeout},\r\n\t\ttoken:     string(token),\r\n\t\tnamespace: namespace,\r\n\t}, nil\r\n}","code-length":313,"reference":"\/\/ NewClientInCluster creates a Client that works from within a pod.","result":"Create a client in cluster.","score":[0.0724,0.1442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClientFromFile(clusterPath, namespace string) (*Client, error) {\r\n\tdata, err := ioutil.ReadFile(clusterPath)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar c Cluster\r\n\tif err := yaml.Unmarshal(data, &c); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn NewClient(&c, namespace)\r\n}","code-length":112,"reference":"\/\/ NewClientFromFile reads a Cluster object at clusterPath and returns an\n\/\/ authenticated client using the keys within.","result":"Create a client from a file.","score":[0.0311,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(c *Cluster, namespace string) (*Client, error) {\r\n\t\r\n\tientKey\r\n\tca := c.ClusterCACertificate\r\n\tcert, err := tls.X509KeyPair(cc, ck)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tcp := x509.NewCertPool()\r\n\tcp.AppendCertsFromPEM(ca)\r\n\ttr := &http.Transport{\r\n\t\tTLSClientConfig: &tls.Config{\r\n\t\t\tMinVersion:   tls.VersionTLS12,\r\n\t\t\tCertificates: []tls.Certificate{cert},\r\n\t\t\tRootCAs:      cp,\r\n\t\t},\r\n\t}\r\n\treturn &Client{\r\n\t\tlogger:    logrus.WithField(\"client\", \"kube\"),\r\n\t\tbaseURL:   c.Endpoint,\r\n\t\tclient:    &http.Client{Transport: tr, Timeout: requestTimeout},\r\n\t\tnamespace: namespace,\r\n\t}, nil\r\n}","code-length":248,"reference":"\/\/ NewClient returns an authenticated Client using the keys in the Cluster.","result":"Create a client for the cluster.","score":[0.071,0.2242]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) ReplaceConfigMap(name string, config ConfigMap) (ConfigMap, error) {\r\n\tc.log(\"ReplaceConfigMap\", name)\r\n\tnamespace := c.namespace\r\n\tif config.Namespace != \"\" {\r\n\t\tnamespace = config.Namespace\r\n\t}\r\n\tvar retConfigMap ConfigMap\r\n\terr := c.request(&request{\r\n\t\tmethod:      http.MethodPut,\r\n\t\tpath:        fmt.Sprintf(\"\/api\/v1\/namespaces\/%s\/configmaps\/%s\", namespace, name),\r\n\t\trequestBody: &config,\r\n\t}, &retConfigMap)\r\n\treturn retConfigMap, err\r\n}","code-length":164,"reference":"\/\/ ReplaceConfigMap puts the configmap into name.\n\/\/\n\/\/ Analogous to kubectl replace configmap\n\/\/\n\/\/ If config.Namespace is empty, the client's specified namespace is used.\n\/\/ Returns the content returned by the apiserver","result":"Replace the configmap in the cluster.","score":[0.0028,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetDiskUsage(path string) (percentBlocksFree float64, bytesFree, bytesUsed uint64, err error) {\r\n\tvar stat syscall.Statfs_t\r\n\terr = syscall.Statfs(path, &stat)\r\n\tif err != nil {\r\n\t\treturn 0, 0, 0, err\r\n\t}\r\n\tpercentBlocksFree = float64(stat.Bfree) \/ float64(stat.Blocks) * 100\r\n\tbytesFree = stat.Bfree * uint64(stat.Bsize)\r\n\tbytesUsed = (stat.Blocks - stat.Bfree) * uint64(stat.Bsize)\r\n\treturn percentBlocksFree, bytesFree, bytesUsed, nil\r\n}","code-length":173,"reference":"\/\/ GetDiskUsage wraps syscall.Statfs for usage in GCing the disk","result":"Get the disk usage.","score":[0.1008,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetATime(path string, defaultTime time.Time) time.Time {\r\n\tat, err := atime.Stat(path)\r\n\tif err != nil {\r\n\t\tlog.WithError(err).Errorf(\"Could not get atime for %s\", path)\r\n\t\treturn defaultTime\r\n\t}\r\n\treturn at\r\n}","code-length":91,"reference":"\/\/ GetATime the atime for a file, logging errors instead of failing\n\/\/ and returning defaultTime instead","result":"Get the atime of a file.","score":[0.0519,0.1985]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterLens(lens Lens) error {\r\n\tconfig := lens.Config()\r\n\t_, ok := lensReg[config.Name]\r\n\tif ok {\r\n\t\treturn fmt.Errorf(\"viewer already registered with name %s\", config.Name)\r\n\t}\r\n\tif config.Title == \"\" {\r\n\t\treturn errors.New(\"empty title field in view metadata\")\r\n\t}\r\n\tif config.Priority < 0 {\r\n\t\treturn errors.New(\"priority must be >=0\")\r\n\t}\r\n\tlensReg[config.Name] = lens\r\n\tlogrus.Infof(\"Spyglass registered viewer %s with title %s.\", config.Name, config.Title)\r\n\treturn nil\r\n}","code-length":184,"reference":"\/\/ RegisterLens registers new viewers","result":"Register viewer with Spyglass.","score":[0,0.2041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetLens(name string) (Lens, error) {\r\n\tlens, ok := lensReg[name]\r\n\tif !ok {\r\n\t\treturn nil, ErrInvalidLensName\r\n\t}\r\n\treturn lens, nil\r\n}","code-length":68,"reference":"\/\/ GetLens returns a Lens by name, if it exists; otherwise it returns an error.","result":"Get the Lens object from the registry.","score":[0.0515,0.0352]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LastNLines(a Artifact, n int64) ([]string, error) {\r\n\t\r\n\treturn LastNLinesChunked(a, n, 300*n+1)\r\n}","code-length":54,"reference":"\/\/ LastNLines reads the last n lines from an artifact.","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(tokenGenerator func() []byte) *Client {\r\n\treturn &Client{\r\n\t\tlogger:         logrus.WithField(\"client\", \"slack\"),\r\n\t\ttokenGenerator: tokenGenerator,\r\n\t}\r\n}","code-length":65,"reference":"\/\/ NewClient creates a slack client with an API token.","result":"Create a client.","score":[0.0396,0.2016]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (sl *Client) WriteMessage(text, channel string) error {\r\n\tsl.log(\"WriteMessage\", text, channel)\r\n\tif sl.fake {\r\n\t\treturn nil\r\n\t}\r\n\tvar uv = sl.urlValues()\r\n\tuv.Add(\"channel\", channel)\r\n\tuv.Add(\"text\", text)\r\n\t_, err := sl.postMessage(chatPostMessage, uv)\r\n\treturn err\r\n}","code-length":116,"reference":"\/\/ WriteMessage adds text to channel","result":"Send messages to a channel.","score":[0.1967,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (NATGateway) MarkAndSweep(sess *session.Session, acct string, region string, set *Set) error {\r\n\tsvc := ec2.New(sess, &aws.Config{Region: aws.String(region)})\r\n\tinp := &ec2.DescribeNatGatewaysInput{}\r\n\tif err := svc.DescribeNatGatewaysPages(inp, func(page *ec2.DescribeNatGatewaysOutput, _ bool) bool {\r\n\t\tfor _, gw := range page.NatGateways {\r\n\t\t\tg := &natGateway{\r\n\t\t\t\tAccount: acct,\r\n\t\t\t\tRegion:  region,\r\n\t\t\t\tID:      *gw.NatGatewayId,\r\n\t\t\t}\r\n\t\t\tif set.Mark(g) {\r\n\t\t\t\tinp := &ec2.DeleteNatGatewayInput{NatGatewayId: gw.NatGatewayId}\r\n\t\t\t\tif _, err := svc.DeleteNatGateway(inp); err != nil {\r\n\t\t\t\t\tklog.Warningf(\"%v: delete failed: %v\", g.ARN(), err)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn true\r\n\t}); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":299,"reference":"\/\/ MarkAndSweep looks at the provided set, and removes resources older than its TTL that have been previously tagged.","result":"Generate code for the generated code.","score":[0.0221,0.0282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (NATGateway) ListAll(sess *session.Session, acct, region string) (*Set, error) {\r\n\tsvc := ec2.New(sess, &aws.Config{Region: aws.String(region)})\r\n\tset := NewSet(0)\r\n\tinp := &ec2.DescribeNatGatewaysInput{}\r\n\terr := svc.DescribeNatGatewaysPages(inp, func(page *ec2.DescribeNatGatewaysOutput, _ bool) bool {\r\n\t\tfor _, gw := range page.NatGateways {\r\n\t\t\tnow := time.Now()\r\n\t\t\tarn := natGateway{\r\n\t\t\t\tAccount: acct,\r\n\t\t\t\tRegion:  region,\r\n\t\t\t\tID:      *gw.NatGatewayId,\r\n\t\t\t}.ARN()\r\n\t\t\tset.firstSeen[arn] = now\r\n\t\t}\r\n\t\treturn true\r\n\t})\r\n\treturn set, errors.Wrapf(err, \"couldn't describe nat gateways for %q in %q\", acct, region)\r\n}","code-length":250,"reference":"\/\/ ListAll populates a set will all available NATGateway resources.","result":"List all NAT gateways in a given account.","score":[0.1286,0.102]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(owner string, url string) *Client {\r\n\tclient := &Client{\r\n\t\turl:     url,\r\n\t\towner:   owner,\r\n\t\tstorage: storage.NewMemoryStorage(),\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tclient.Dialer.RetryCount = 3\r\n\tclient.Dialer.RetrySleep = time.Second * 10\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tialer.KeepAlive = 30 * time.Second\r\n\tclient.Dialer.DualStack = true\r\n\tclient.http.Transport = &http.Transport{\r\n\t\tProxy:                 http.ProxyFromEnvironment,\r\n\t\tDial:                  client.Dialer.Dial,\r\n\t\tDialContext:           client.Dialer.DialContext,\r\n\t\tMaxIdleConns:          100,\r\n\t\tIdleConnTimeout:       90 * time.Second,\r\n\t\tTLSHandshakeTimeout:   10 * time.Second,\r\n\t\tExpectContinueTimeout: 1 * time.Second,\r\n\t}\r\n\treturn client\r\n}","code-length":257,"reference":"\/\/ NewClient creates a Boskos client for the specified URL and resource owner.\n\/\/\n\/\/ Clients created with this function default to retrying failed connection\n\/\/ attempts three times with a ten second pause between each attempt.","result":"Create a new client.","score":[0.0001,0.0297]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Acquire(rtype, state, dest string) (*common.Resource, error) {\r\n\tr, err := c.acquire(rtype, state, dest)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tif r != nil {\r\n\t\tc.storage.Add(*r)\r\n\t}\r\n\treturn r, nil\r\n}","code-length":126,"reference":"\/\/ public method\n\/\/ Acquire asks boskos for a resource of certain type in certain state, and set the resource to dest state.\n\/\/ Returns the resource on success.","result":"Create a new resource.","score":[0.0006,0.0189]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) AcquireWait(ctx context.Context, rtype, state, dest string) (*common.Resource, error) {\r\n\tif ctx == nil {\r\n\t\treturn nil, ErrContextRequired\r\n\t}\r\n\t\r\n\t\r\n\tfor {\r\n\t\tr, err := c.Acquire(rtype, state, dest)\r\n\t\tif err != nil {\r\n\t\t\tif err == ErrAlreadyInUse || err == ErrNotFound {\r\n\t\t\t\tselect {\r\n\t\t\t\tcase <-ctx.Done():\r\n\t\t\t\t\treturn nil, err\r\n\t\t\t\tcase <-time.After(3 * time.Second):\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn r, nil\r\n\t}\r\n}","code-length":198,"reference":"\/\/ AcquireWait blocks until Acquire returns the specified resource or the\n\/\/ provided context is cancelled or its deadline exceeded.","result":"Wait for the resource to become available.","score":[0.03,0.0535]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) AcquireByState(state, dest string, names []string) ([]common.Resource, error) {\r\n\tresources, err := c.acquireByState(state, dest, names)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tfor _, r := range resources {\r\n\t\tc.storage.Add(r)\r\n\t}\r\n\treturn resources, nil\r\n}","code-length":133,"reference":"\/\/ AcquireByState asks boskos for a resources of certain type, and set the resource to dest state.\n\/\/ Returns a list of resources on success.","result":"Create a new resource.","score":[0.0017,0.0218]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) ReleaseAll(dest string) error {\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tresources, err := c.storage.List()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif len(resources) == 0 {\r\n\t\treturn fmt.Errorf(\"no holding resource\")\r\n\t}\r\n\tvar allErrors error\r\n\tfor _, r := range resources {\r\n\t\tc.storage.Delete(r.GetName())\r\n\t\terr := c.release(r.GetName(), dest)\r\n\t\tif err != nil {\r\n\t\t\tallErrors = multierror.Append(allErrors, err)\r\n\t\t}\r\n\t}\r\n\treturn allErrors\r\n}","code-length":194,"reference":"\/\/ ReleaseAll returns all resources hold by the client back to boskos and set them to dest state.","result":"Release all resources.","score":[0.0028,0.0303]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) ReleaseOne(name, dest string) error {\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tif _, err := c.storage.Get(name); err != nil {\r\n\t\treturn fmt.Errorf(\"no resource name %v\", name)\r\n\t}\r\n\tc.storage.Delete(name)\r\n\tif err := c.release(name, dest); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":132,"reference":"\/\/ ReleaseOne returns one of owned resources back to boskos and set it to dest state.","result":"Release a resource.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) UpdateAll(state string) error {\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tresources, err := c.storage.List()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif len(resources) == 0 {\r\n\t\treturn fmt.Errorf(\"no holding resource\")\r\n\t}\r\n\tvar allErrors error\r\n\tfor _, r := range resources {\r\n\t\tif err := c.update(r.GetName(), state, nil); err != nil {\r\n\t\t\tallErrors = multierror.Append(allErrors, err)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif err := c.updateLocalResource(r, state, nil); err != nil {\r\n\t\t\tallErrors = multierror.Append(allErrors, err)\r\n\t\t}\r\n\t}\r\n\treturn allErrors\r\n}","code-length":226,"reference":"\/\/ UpdateAll signals update for all resources hold by the client.","result":"Update all resources in the client.","score":[0.1562,0.4248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) SyncAll() error {\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tresources, err := c.storage.List()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif len(resources) == 0 {\r\n\t\tlogrus.Info(\"no resource to sync\")\r\n\t\treturn nil\r\n\t}\r\n\tvar allErrors error\r\n\tfor _, i := range resources {\r\n\t\tr, err := common.ItemToResource(i)\r\n\t\tif err != nil {\r\n\t\t\tallErrors = multierror.Append(allErrors, err)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif err := c.update(r.Name, r.State, nil); err != nil {\r\n\t\t\tallErrors = multierror.Append(allErrors, err)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif err := c.storage.Update(r); err != nil {\r\n\t\t\tallErrors = multierror.Append(allErrors, err)\r\n\t\t}\r\n\t}\r\n\treturn allErrors\r\n}","code-length":278,"reference":"\/\/ SyncAll signals update for all resources hold by the client.","result":"Sync all resources.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) UpdateOne(name, state string, userData *common.UserData) error {\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tr, err := c.storage.Get(name)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"no resource name %v\", name)\r\n\t}\r\n\tif err := c.update(r.GetName(), state, userData); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn c.updateLocalResource(r, state, userData)\r\n}","code-length":146,"reference":"\/\/ UpdateOne signals update for one of the resources hold by the client.","result":"Update the resource.","score":[0.0146,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Metric(rtype string) (common.Metric, error) {\r\n\treturn c.metric(rtype)\r\n}","code-length":43,"reference":"\/\/ Metric will query current metric for target resource type.\n\/\/ Return a common.Metric object on success.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) HasResource() bool {\r\n\tresources, _ := c.storage.List()\r\n\treturn len(resources) > 0\r\n}","code-length":46,"reference":"\/\/ HasResource tells if current client holds any resources","result":"Check if the resource exists.","score":[0.108,0.1744]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DialerWithRetry) DialContext(ctx context.Context, network, address string) (net.Conn, error) {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tcount := d.RetryCount + 1\r\n\tsleep := d.RetrySleep\r\n\ti := uint(0)\r\n\tfor {\r\n\t\tconn, err := d.Dialer.DialContext(ctx, network, address)\r\n\t\tif err != nil {\r\n\t\t\tif isDialErrorRetriable(err) {\r\n\t\t\t\tif i < count-1 {\r\n\t\t\t\t\tselect {\r\n\t\t\t\t\tcase <-time.After(sleep):\r\n\t\t\t\t\t\ti++\r\n\t\t\t\t\t\tcontinue\r\n\t\t\t\t\tcase <-ctx.Done():\r\n\t\t\t\t\t\treturn nil, err\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn conn, nil\r\n\t}\r\n}","code-length":230,"reference":"\/\/ DialContext connects to the address on the named network using the provided context.","result":"Avoid the need for the following code.","score":[0.0707,0.0752]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDashboardAgent(repos []string, config *config.GitHubOAuthConfig, log *logrus.Entry) *DashboardAgent {\r\n\treturn &DashboardAgent{\r\n\t\trepos: repos,\r\n\t\tgoac:  config,\r\n\t\tlog:   log,\r\n\t}\r\n}","code-length":79,"reference":"\/\/ NewDashboardAgent creates a new user dashboard agent .","result":"Create a new instance of the dashboard agent.","score":[0.1918,0.4213]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (da *DashboardAgent) QueryPullRequests(ctx context.Context, ghc githubClient, query string) ([]PullRequest, error) {\r\n\tvar prs []PullRequest\r\n\tvars := map[string]interface{}{\r\n\t\t\"query\":        (githubql.String)(query),\r\n\t\t\"searchCursor\": (*githubql.String)(nil),\r\n\t}\r\n\tvar totalCost int\r\n\tvar remaining int\r\n\tfor {\r\n\t\tsq := searchQuery{}\r\n\t\tif err := ghc.Query(ctx, &sq, vars); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\ttotalCost += int(sq.RateLimit.Cost)\r\n\t\tremaining = int(sq.RateLimit.Remaining)\r\n\t\tfor _, n := range sq.Search.Nodes {\r\n\t\t\tprs = append(prs, n.PullRequest)\r\n\t\t}\r\n\t\tif !sq.Search.PageInfo.HasNextPage {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tvars[\"searchCursor\"] = githubql.NewString(sq.Search.PageInfo.EndCursor)\r\n\t}\r\n\tda.log.Infof(\"Search for query \\\"%s\\\" cost %d point(s). %d remaining.\", query, totalCost, remaining)\r\n\treturn prs, nil\r\n}","code-length":328,"reference":"\/\/ QueryPullRequests is a query function that returns a list of open pull requests owned by the user whose access token\n\/\/ is consumed by the github client.","result":"Query pull requests.","score":[0.0001,0.0392]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (da *DashboardAgent) GetHeadContexts(ghc githubClient, pr PullRequest) ([]Context, error) {\r\n\torg := string(pr.Repository.Owner.Login)\r\n\trepo := string(pr.Repository.Name)\r\n\tcombined, err := ghc.GetCombinedStatus(org, repo, string(pr.HeadRefOID))\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to get the combined status: %v\", err)\r\n\t}\r\n\tcontexts := make([]Context, 0, len(combined.Statuses))\r\n\tfor _, status := range combined.Statuses {\r\n\t\tcontexts = append(\r\n\t\t\tcontexts,\r\n\t\t\tContext{\r\n\t\t\t\tContext:     status.Context,\r\n\t\t\t\tDescription: status.Description,\r\n\t\t\t\tState:       strings.ToUpper(status.State),\r\n\t\t\t},\r\n\t\t)\r\n\t}\r\n\treturn contexts, nil\r\n}","code-length":236,"reference":"\/\/ GetHeadContexts returns the status checks' contexts of the head commit of the PR.","result":"Generate the code.","score":[0.0104,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (da *DashboardAgent) ConstructSearchQuery(login string) string {\r\n\ttokens := []string{\"is:pr\", \"state:open\", \"author:\" + login}\r\n\tfor i := range da.repos {\r\n\t\ttokens = append(tokens, fmt.Sprintf(\"repo:\\\"%s\\\"\", da.repos[i]))\r\n\t}\r\n\treturn strings.Join(tokens, \" \")\r\n}","code-length":106,"reference":"\/\/ ConstructSearchQuery returns the GitHub search query string for PRs that are open and authored\n\/\/ by the user passed. The search is scoped to repositories that are configured with either Prow or\n\/\/ Tide.","result":"Construct the search query.","score":[0.0002,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewBundledStates(description string) BundledStates {\r\n\treturn BundledStates{\r\n\t\tdescription: description,\r\n\t\tstates:      map[string]State{},\r\n\t}\r\n}","code-length":59,"reference":"\/\/ NewBundledStates is the constructor for BundledStates","result":"Create the bundled states.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b BundledStates) ReceiveEvent(ID string, eventName, label string, t time.Time) bool {\r\n\tstate, ok := b.states[ID]\r\n\tif !ok {\r\n\t\tstate = NewState(b.description)\r\n\t}\r\n\tstate, changed := state.ReceiveEvent(eventName, label, t)\r\n\tb.states[ID] = state\r\n\treturn changed\r\n}","code-length":109,"reference":"\/\/ ReceiveEvent is called when something happens on an issue. The state\n\/\/ for that issue is updated.","result":"Store the state in the bundled states.","score":[0.0336,0.0592]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b BundledStates) ages(t time.Time) map[string]time.Duration {\r\n\tages := map[string]time.Duration{}\r\n\tfor id, state := range b.states {\r\n\t\tif !state.Active() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tages[id] = state.Age(t)\r\n\t}\r\n\treturn ages\r\n}","code-length":107,"reference":"\/\/ ages return the age of each active states","result":"Generate the ages function.","score":[0.1088,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b BundledStates) Percentile(t time.Time, percentile int) time.Duration {\r\n\tif percentile > 100 || percentile <= 0 {\r\n\t\tpanic(fmt.Errorf(\"percentile %d is out of scope\", percentile))\r\n\t}\r\n\tages := []time.Duration{}\r\n\tfor _, age := range b.ages(t) {\r\n\t\tages = append(ages, age)\r\n\t}\r\n\tif len(ages) == 0 {\r\n\t\treturn 0\r\n\t}\r\n\tsort.Sort(ByDuration(ages))\r\n\tindex := int(math.Ceil(float64(percentile)*float64(len(ages))\/100) - 1)\r\n\tif index >= len(ages) {\r\n\t\tpanic(fmt.Errorf(\"Index is out of range: %d\/%d\", index, len(ages)))\r\n\t}\r\n\treturn ages[index]\r\n}","code-length":229,"reference":"\/\/ Percentile returns given percentile for age of all active states at time t","result":"Calculate the percentile of the.","score":[0.0472,0.0763]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMetrics() *Metrics {\r\n\treturn &Metrics{\r\n\t\tClientMetrics: &ClientMetrics{\r\n\t\t\tRequests:       requests,\r\n\t\t\tRequestRetries: requestRetries,\r\n\t\t\tRequestLatency: requestLatency,\r\n\t\t},\r\n\t\tResyncPeriod: resyncPeriod,\r\n\t}\r\n}","code-length":86,"reference":"\/\/ NewMetrics creates a new set of metrics for the Jenkins operator.","result":"Create a new metrics object.","score":[0.0927,0.3319]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDiskCache(delegate http.RoundTripper, cacheDir string, cacheSizeGB, maxConcurrency int) http.RoundTripper {\r\n\treturn NewFromCache(delegate, diskcache.NewWithDiskv(\r\n\t\tdiskv.New(diskv.Options{\r\n\t\t\tBasePath:     path.Join(cacheDir, \"data\"),\r\n\t\t\tTempDir:      path.Join(cacheDir, \"temp\"),\r\n\t\t\tCacheSizeMax: uint64(cacheSizeGB) * uint64(1000000000),\r\n\t\t})),\r\n\t\tmaxConcurrency,\r\n\t)\r\n}","code-length":147,"reference":"\/\/ NewDiskCache creates a GitHub cache RoundTripper that is backed by a disk\n\/\/ cache.","result":"Create a new cache.","score":[0.0243,0.1079]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMemCache(delegate http.RoundTripper, maxConcurrency int) http.RoundTripper {\r\n\treturn NewFromCache(delegate, httpcache.NewMemoryCache(), maxConcurrency)\r\n}","code-length":53,"reference":"\/\/ NewMemCache creates a GitHub cache RoundTripper that is backed by a memory\n\/\/ cache.","result":"Create a new http.","score":[0.0204,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFromCache(delegate http.RoundTripper, cache httpcache.Cache, maxConcurrency int) http.RoundTripper {\r\n\tcacheTransport := httpcache.NewTransport(cache)\r\n\tcacheTransport.Transport = newThrottlingTransport(maxConcurrency, upstreamTransport{delegate: delegate})\r\n\treturn &requestCoalescer{\r\n\t\tkeys:     make(map[string]*responseWaiter),\r\n\t\tdelegate: cacheTransport,\r\n\t}\r\n}","code-length":117,"reference":"\/\/ NewFromCache creates a GitHub cache RoundTripper that is backed by the\n\/\/ specified httpcache.Cache implementation.","result":"Create a new transport from a cache.","score":[0.0446,0.0662]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Clientset) ProwV1() prowv1.ProwV1Interface {\r\n\treturn &fakeprowv1.FakeProwV1{Fake: &c.Fake}\r\n}","code-length":59,"reference":"\/\/ ProwV1 retrieves the ProwV1Client","result":"Generate the code.","score":[0.2096,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Clientset) Prow() prowv1.ProwV1Interface {\r\n\treturn &fakeprowv1.FakeProwV1{Fake: &c.Fake}\r\n}","code-length":57,"reference":"\/\/ Prow retrieves the ProwV1Client","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewOwners(log *logrus.Entry, filenames []string, r Repo, s int64) Owners {\r\n\treturn Owners{filenames: filenames, repo: r, seed: s, log: log}\r\n}","code-length":61,"reference":"\/\/ NewOwners consturcts a new Owners instance. filenames is the slice of files changed.","result":"Create a new owner.","score":[0.0371,0.1442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Owners) GetApprovers() map[string]sets.String {\r\n\townersToApprovers := map[string]sets.String{}\r\n\tfor fn := range o.GetOwnersSet() {\r\n\t\townersToApprovers[fn] = o.repo.Approvers(fn)\r\n\t}\r\n\treturn ownersToApprovers\r\n}","code-length":96,"reference":"\/\/ GetApprovers returns a map from ownersFiles -> people that are approvers in them","result":"Get the approvers of the owners.","score":[0.0509,0.0379]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Owners) GetAllPotentialApprovers() []string {\r\n\tapproversOnly := []string{}\r\n\tfor _, approverList := range o.GetLeafApprovers() {\r\n\t\tfor approver := range approverList {\r\n\t\t\tapproversOnly = append(approversOnly, approver)\r\n\t\t}\r\n\t}\r\n\tsort.Strings(approversOnly)\r\n\tif len(approversOnly) == 0 {\r\n\t\to.log.Debug(\"No potential approvers exist. Does the repo have OWNERS files?\")\r\n\t}\r\n\treturn approversOnly\r\n}","code-length":155,"reference":"\/\/ GetAllPotentialApprovers returns the people from relevant owners files needed to get the PR approved","result":"Return the list of appro.","score":[0.0325,0.0714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Owners) GetReverseMap(approvers map[string]sets.String) map[string]sets.String {\r\n\tapproverOwnersfiles := map[string]sets.String{}\r\n\tfor ownersFile, approvers := range approvers {\r\n\t\tfor approver := range approvers {\r\n\t\t\tif _, ok := approverOwnersfiles[approver]; ok {\r\n\t\t\t\tapproverOwnersfiles[approver].Insert(ownersFile)\r\n\t\t\t} else {\r\n\t\t\t\tapproverOwnersfiles[approver] = sets.NewString(ownersFile)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn approverOwnersfiles\r\n}","code-length":175,"reference":"\/\/ GetReverseMap returns a map from people -> OWNERS files for which they are an approver","result":"Generate the reverse map of approvers.","score":[0.0365,0.0333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Owners) temporaryUnapprovedFiles(approvers sets.String) sets.String {\r\n\tap := NewApprovers(o)\r\n\tfor approver := range approvers {\r\n\t\tap.AddApprover(approver, \"\", false)\r\n\t}\r\n\treturn ap.UnapprovedFiles()\r\n}","code-length":85,"reference":"\/\/ temporaryUnapprovedFiles returns the list of files that wouldn't be\n\/\/ approved by the given set of approvers.","result":"Generate a temporary unapproved files file.","score":[0.0261,0.0298]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Owners) KeepCoveringApprovers(reverseMap map[string]sets.String, knownApprovers sets.String, potentialApprovers []string) sets.String {\r\n\tif len(potentialApprovers) == 0 {\r\n\t\to.log.Debug(\"No potential approvers exist to filter for relevance. Does this repo have OWNERS files?\")\r\n\t}\r\n\tkeptApprovers := sets.NewString()\r\n\tunapproved := o.temporaryUnapprovedFiles(knownApprovers)\r\n\tfor _, suggestedApprover := range o.GetSuggestedApprovers(reverseMap, potentialApprovers).List() {\r\n\t\tif reverseMap[suggestedApprover].Intersection(unapproved).Len() != 0 {\r\n\t\t\tkeptApprovers.Insert(suggestedApprover)\r\n\t\t}\r\n\t}\r\n\treturn keptApprovers\r\n}","code-length":213,"reference":"\/\/ KeepCoveringApprovers finds who we should keep as suggested approvers given a pre-selection\n\/\/ knownApprovers must be a subset of potentialApprovers.","result":"Filter out the approvers that.","score":[0.0098,0.0258]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Owners) GetSuggestedApprovers(reverseMap map[string]sets.String, potentialApprovers []string) sets.String {\r\n\tap := NewApprovers(o)\r\n\tfor !ap.RequirementsMet() {\r\n\t\tnewApprover := findMostCoveringApprover(potentialApprovers, reverseMap, ap.UnapprovedFiles())\r\n\t\tif newApprover == \"\" {\r\n\t\t\to.log.Warnf(\"Couldn't find\/suggest approvers for each files. Unapproved: %q\", ap.UnapprovedFiles().List())\r\n\t\t\treturn ap.GetCurrentApproversSet()\r\n\t\t}\r\n\t\tap.AddApprover(newApprover, \"\", false)\r\n\t}\r\n\treturn ap.GetCurrentApproversSet()\r\n}","code-length":193,"reference":"\/\/ GetSuggestedApprovers solves the exact cover problem, finding an approver capable of\n\/\/ approving every OWNERS file in the PR","result":"Generate the code for the generated code.","score":[0.03,0.0535]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Owners) GetOwnersSet() sets.String {\r\n\towners := sets.NewString()\r\n\tfor _, fn := range o.filenames {\r\n\t\towners.Insert(o.repo.FindApproverOwnersForFile(fn))\r\n\t}\r\n\to.removeSubdirs(owners)\r\n\treturn owners\r\n}","code-length":95,"reference":"\/\/ GetOwnersSet returns a set containing all the Owners files necessary to get the PR approved","result":"Get the set of owners.","score":[0.0317,0.1715]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Owners) GetShuffledApprovers() []string {\r\n\tapproversList := o.GetAllPotentialApprovers()\r\n\torder := rand.New(rand.NewSource(o.seed)).Perm(len(approversList))\r\n\tpeople := make([]string, 0, len(approversList))\r\n\tfor _, i := range order {\r\n\t\tpeople = append(people, approversList[i])\r\n\t}\r\n\treturn people\r\n}","code-length":123,"reference":"\/\/ GetShuffledApprovers shuffles the potential approvers so that we don't\n\/\/ always suggest the same people.","result":"Get shuffled appro.","score":[0,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a Approval) String() string {\r\n\treturn fmt.Sprintf(\r\n\t\t`*<a href=\"%s\" title=\"%s\">%s<\/a>*`,\r\n\t\ta.Reference,\r\n\t\ta.How,\r\n\t\ta.Login,\r\n\t)\r\n}","code-length":83,"reference":"\/\/ String creates a link for the approval. Use `Login` if you just want the name.","result":"Generate the string.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IntersectSetsCase(one, other sets.String) sets.String {\r\n\tlower := sets.NewString()\r\n\tfor item := range other {\r\n\t\tlower.Insert(strings.ToLower(item))\r\n\t}\r\n\tintersection := sets.NewString()\r\n\tfor item := range one {\r\n\t\tif lower.Has(strings.ToLower(item)) {\r\n\t\t\tintersection.Insert(item)\r\n\t\t}\r\n\t}\r\n\treturn intersection\r\n}","code-length":127,"reference":"\/\/ IntersectSetsCase runs the intersection between to sets.String in a\n\/\/ case-insensitive way. It returns the name with the case of \"one\".","result":"Match the case of the sets.","score":[0.0297,0.1547]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewApprovers(owners Owners) Approvers {\r\n\treturn Approvers{\r\n\t\towners:    owners,\r\n\t\tapprovers: map[string]Approval{},\r\n\t\tassignees: sets.NewString(),\r\n\t\tManuallyApproved: func() bool {\r\n\t\t\treturn false\r\n\t\t},\r\n\t}\r\n}","code-length":97,"reference":"\/\/ NewApprovers create a new \"Approvers\" with no approval.","result":"Create a new approvers object.","score":[0.1527,0.3424]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap *Approvers) AddLGTMer(login, reference string, noIssue bool) {\r\n\tif ap.shouldNotOverrideApproval(login, noIssue) {\r\n\t\treturn\r\n\t}\r\n\tap.approvers[strings.ToLower(login)] = Approval{\r\n\t\tLogin:     login,\r\n\t\tHow:       \"LGTM\",\r\n\t\tReference: reference,\r\n\t\tNoIssue:   noIssue,\r\n\t}\r\n}","code-length":125,"reference":"\/\/ AddLGTMer adds a new LGTM Approver","result":"Add LGTMer.","score":[0,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap *Approvers) RemoveApprover(login string) {\r\n\tdelete(ap.approvers, strings.ToLower(login))\r\n}","code-length":44,"reference":"\/\/ RemoveApprover removes an approver from the list.","result":"Remove the approver from the list.","score":[0.433,0.6205]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap *Approvers) AddAssignees(logins ...string) {\r\n\tfor _, login := range logins {\r\n\t\tap.assignees.Insert(strings.ToLower(login))\r\n\t}\r\n}","code-length":63,"reference":"\/\/ AddAssignees adds assignees to the list","result":"Add assignees to approvers.","score":[0.2134,0.4395]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap Approvers) GetCurrentApproversSetCased() sets.String {\r\n\tcurrentApprovers := sets.NewString()\r\n\tfor _, approval := range ap.approvers {\r\n\t\tcurrentApprovers.Insert(approval.Login)\r\n\t}\r\n\treturn currentApprovers\r\n}","code-length":83,"reference":"\/\/ GetCurrentApproversSetCased returns the set of approvers logins with the original cases.","result":"Get current approvers set cased.","score":[0.0705,0.0885]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap Approvers) GetFilesApprovers() map[string]sets.String {\r\n\tfilesApprovers := map[string]sets.String{}\r\n\tcurrentApprovers := ap.GetCurrentApproversSetCased()\r\n\tfor fn, potentialApprovers := range ap.owners.GetApprovers() {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tfilesApprovers[fn] = IntersectSetsCase(currentApprovers, potentialApprovers)\r\n\t}\r\n\treturn filesApprovers\r\n}","code-length":144,"reference":"\/\/ GetFilesApprovers returns a map from files -> list of current approvers.","result":"Get the files approvers.","score":[0.0514,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap Approvers) NoIssueApprovers() map[string]Approval {\r\n\tnia := map[string]Approval{}\r\n\treverseMap := ap.owners.GetReverseMap(ap.owners.GetApprovers())\r\n\tfor login, approver := range ap.approvers {\r\n\t\tif !approver.NoIssue {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif len(reverseMap[login]) == 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tnia[login] = approver\r\n\t}\r\n\treturn nia\r\n}","code-length":150,"reference":"\/\/ NoIssueApprovers returns the list of people who have \"no-issue\"\n\/\/ approved the pull-request. They are included in the list iff they can\n\/\/ approve one of the files.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap Approvers) UnapprovedFiles() sets.String {\r\n\tunapproved := sets.NewString()\r\n\tfor fn, approvers := range ap.GetFilesApprovers() {\r\n\t\tif len(approvers) == 0 {\r\n\t\t\tunapproved.Insert(fn)\r\n\t\t}\r\n\t}\r\n\treturn unapproved\r\n}","code-length":95,"reference":"\/\/ UnapprovedFiles returns owners files that still need approval","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap Approvers) GetFiles(baseURL *url.URL, branch string) []File {\r\n\tallOwnersFiles := []File{}\r\n\tfilesApprovers := ap.GetFilesApprovers()\r\n\tfor _, file := range ap.owners.GetOwnersSet().List() {\r\n\t\tif len(filesApprovers[file]) == 0 {\r\n\t\t\tallOwnersFiles = append(allOwnersFiles, UnapprovedFile{\r\n\t\t\t\tbaseURL:  baseURL,\r\n\t\t\t\tfilepath: file,\r\n\t\t\t\tbranch:   branch,\r\n\t\t\t})\r\n\t\t} else {\r\n\t\t\tallOwnersFiles = append(allOwnersFiles, ApprovedFile{\r\n\t\t\t\tbaseURL:   baseURL,\r\n\t\t\t\tfilepath:  file,\r\n\t\t\t\tapprovers: filesApprovers[file],\r\n\t\t\t\tbranch:    branch,\r\n\t\t\t})\r\n\t\t}\r\n\t}\r\n\treturn allOwnersFiles\r\n}","code-length":241,"reference":"\/\/ GetFiles returns owners files that still need approval.","result":"Get all files from the repository.","score":[0.1171,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap Approvers) IsApproved() bool {\r\n\treqsMet := ap.RequirementsMet()\r\n\tif !reqsMet && ap.ManuallyApproved() {\r\n\t\treturn true\r\n\t}\r\n\treturn reqsMet\r\n}","code-length":66,"reference":"\/\/ IsApproved returns a bool indicating whether the PR is fully approved.\n\/\/ If a human manually added the approved label, this returns true, ignoring normal approval rules.","result":"Check if the user is approved.","score":[0.0065,0.0775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap Approvers) ListApprovals() []Approval {\r\n\tapprovals := []Approval{}\r\n\tfor _, approver := range ap.GetCurrentApproversSet().List() {\r\n\t\tapprovals = append(approvals, ap.approvers[approver])\r\n\t}\r\n\treturn approvals\r\n}","code-length":86,"reference":"\/\/ ListApprovals returns the list of approvals","result":"List all approvals in the current user.","score":[0.1921,0.2143]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap Approvers) ListNoIssueApprovals() []Approval {\r\n\tapprovals := []Approval{}\r\n\tfor _, approver := range ap.GetNoIssueApproversSet().List() {\r\n\t\tapprovals = append(approvals, ap.approvers[approver])\r\n\t}\r\n\treturn approvals\r\n}","code-length":89,"reference":"\/\/ ListNoIssueApprovals returns the list of \"no-issue\" approvals","result":"List all no issue approvals.","score":[0,0.0649]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GenerateTemplate(templ, name string, data interface{}) (string, error) {\r\n\tbuf := bytes.NewBufferString(\"\")\r\n\tif messageTempl, err := template.New(name).Parse(templ); err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"failed to parse template for %s: %v\", name, err)\r\n\t} else if err := messageTempl.Execute(buf, data); err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"failed to execute template for %s: %v\", name, err)\r\n\t}\r\n\treturn buf.String(), nil\r\n}","code-length":150,"reference":"\/\/ GenerateTemplate takes a template, name and data, and generates\n\/\/ the corresponding string.","result":"Generate the template.","score":[0.0104,0.0775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc writeTemplate(templatePath string, outputPath string, data interface{}) error {\r\n\t\r\n\tfuncMap := template.FuncMap{\r\n\t\t\"anchor\": func(input string) string {\r\n\t\t\treturn strings.Replace(input, \":\", \" \", -1)\r\n\t\t},\r\n\t}\r\n\tt, err := template.New(filepath.Base(templatePath)).Funcs(funcMap).ParseFiles(templatePath)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif !pathExists(outputPath) {\r\n\t\t_, err = os.Create(outputPath)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\t\r\n\tf, err := os.OpenFile(outputPath, os.O_RDWR, 0644)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer f.Close()\r\n\tf.Truncate(0)\r\n\t\r\n\terr = t.Execute(f, data)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":287,"reference":"\/\/ Writes the golang text template at templatePath to outputPath using the given data","result":"Write a template to a file.","score":[0.0605,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c Configuration) Labels() []Label {\r\n\tvar labelarrays [][]Label\r\n\tlabelarrays = append(labelarrays, c.Default.Labels)\r\n\tfor _, repo := range c.Repos {\r\n\t\tlabelarrays = append(labelarrays, repo.Labels)\r\n\t}\r\n\tlabelmap := make(map[string]Label)\r\n\tfor _, labels := range labelarrays {\r\n\t\tfor _, l := range labels {\r\n\t\t\tname := strings.ToLower(l.Name)\r\n\t\t\tif _, ok := labelmap[name]; !ok {\r\n\t\t\t\tlabelmap[name] = l\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tvar labels []Label\r\n\tfor _, label := range labelmap {\r\n\t\tlabels = append(labels, label)\r\n\t}\r\n\tsort.Slice(labels, func(i, j int) bool { return labels[i].Name < labels[j].Name })\r\n\treturn labels\r\n}","code-length":248,"reference":"\/\/ Labels returns a sorted list of labels unique by name","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LabelsForTarget(labels []Label, target LabelTarget) (filteredLabels []Label) {\r\n\tfor _, label := range labels {\r\n\t\tif target == label.Target {\r\n\t\t\tfilteredLabels = append(filteredLabels, label)\r\n\t\t}\r\n\t}\r\n\t\r\n\tsort.Slice(filteredLabels, func(i, j int) bool { return filteredLabels[i].Name < filteredLabels[j].Name })\r\n\treturn\r\n}","code-length":119,"reference":"\/\/ LabelsForTarget returns labels that have a given target","result":"Filter out labels for target.","score":[0.108,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadConfig(path string, orgs string) (*Configuration, error) {\r\n\tif path == \"\" {\r\n\t\treturn nil, errors.New(\"empty path\")\r\n\t}\r\n\tvar c Configuration\r\n\tdata, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err = yaml.Unmarshal(data, &c); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err = c.validate(orgs); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &c, nil\r\n}","code-length":163,"reference":"\/\/ LoadConfig reads the yaml config at path","result":"Load configuration file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc loadLabels(gc client, org string, repos []string) (*RepoLabels, error) {\r\n\trepoChan := make(chan string, len(repos))\r\n\tfor _, repo := range repos {\r\n\t\trepoChan <- repo\r\n\t}\r\n\tclose(repoChan)\r\n\twg := sync.WaitGroup{}\r\n\twg.Add(maxConcurrentWorkers)\r\n\tlabels := make(chan RepoLabels, len(repos))\r\n\terrChan := make(chan error, len(repos))\r\n\tfor i := 0; i < maxConcurrentWorkers; i++ {\r\n\t\tgo func(repositories <-chan string) {\r\n\t\t\tdefer wg.Done()\r\n\t\t\tfor repository := range repositories {\r\n\t\t\t\tlogrus.WithField(\"org\", org).WithField(\"repo\", repository).Info(\"Listing labels for repo\")\r\n\t\t\t\trepoLabels, err := gc.GetRepoLabels(org, repository)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tlogrus.WithField(\"org\", org).WithField(\"repo\", repository).Error(\"Failed listing labels for repo\")\r\n\t\t\t\t\terrChan <- err\r\n\t\t\t\t}\r\n\t\t\t\tlabels <- RepoLabels{repository: repoLabels}\r\n\t\t\t}\r\n\t\t}(repoChan)\r\n\t}\r\n\twg.Wait()\r\n\tclose(labels)\r\n\tclose(errChan)\r\n\trl := RepoLabels{}\r\n\tfor data := range labels {\r\n\t\tfor repo, repoLabels := range data {\r\n\t\t\trl[repo] = repoLabels\r\n\t\t}\r\n\t}\r\n\tvar overallErr error\r\n\tif len(errChan) > 0 {\r\n\t\tvar listErrs []error\r\n\t\tfor listErr := range errChan {\r\n\t\t\tlistErrs = append(listErrs, listErr)\r\n\t\t}\r\n\t\toverallErr = fmt.Errorf(\"failed to list labels: %v\", listErrs)\r\n\t}\r\n\treturn &rl, overallErr\r\n}","code-length":476,"reference":"\/\/ loadLabels returns what labels exist in github","result":"Load labels from github.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc kill(repo string, label Label) Update {\r\n\tlogrus.WithField(\"repo\", repo).WithField(\"label\", label.Name).Info(\"kill\")\r\n\treturn Update{Why: \"dead\", Current: &label, repo: repo}\r\n}","code-length":70,"reference":"\/\/ Delete the label","result":"Kill a label.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc create(repo string, label Label) Update {\r\n\tlogrus.WithField(\"repo\", repo).WithField(\"label\", label.Name).Info(\"create\")\r\n\treturn Update{Why: \"missing\", Wanted: &label, repo: repo}\r\n}","code-length":72,"reference":"\/\/ Create the label","result":"Create labels.","score":[0.1839,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc classifyLabels(labels []Label, required, archaic, dead map[string]Label, now time.Time, parent *Label) (map[string]Label, map[string]Label, map[string]Label) {\r\n\tnewRequired := copyLabelMap(required)\r\n\tnewArchaic := copyLabelMap(archaic)\r\n\tnewDead := copyLabelMap(dead)\r\n\tfor i, l := range labels {\r\n\t\tfirst := parent\r\n\t\tif first == nil {\r\n\t\t\tfirst = &labels[i]\r\n\t\t}\r\n\t\tlower := strings.ToLower(l.Name)\r\n\t\tswitch {\r\n\t\tcase parent == nil && l.DeleteAfter == nil:\r\n\t\t\tnewRequired[lower] = l\r\n\t\tcase l.DeleteAfter != nil && now.After(*l.DeleteAfter):\r\n\t\t\tnewDead[lower] = l\r\n\t\tcase parent != nil:\r\n\t\t\tl.parent = parent\r\n\t\t\tnewArchaic[lower] = l\r\n\t\t}\r\n\t\tnewRequired, newArchaic, newDead = classifyLabels(l.Previously, newRequired, newArchaic, newDead, now, first)\r\n\t}\r\n\treturn newRequired, newArchaic, newDead\r\n}","code-length":317,"reference":"\/\/ classifyLabels will put labels into the required, archaic, dead maps as appropriate.","result":"Map[string]Label.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc linkify(text string) string {\r\n\t\r\n\tlink := strings.Replace(text, \" \", \"-\", -1)\r\n\t\r\n\tdiscard, _ := regexp.Compile(\"[,\/]\")\r\n\tlink = discard.ReplaceAllString(link, \"\")\r\n\t\r\n\treturn strings.ToLower(link)\r\n}","code-length":89,"reference":"\/\/ linkify transforms a string into a markdown anchor link\n\/\/ I could not find a proper doc, so rules here a mostly empirical","result":"Linkify the text.","score":[0,0.0228]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCache(diskRoot string) *Cache {\r\n\treturn &Cache{\r\n\t\tdiskRoot: strings.TrimSuffix(diskRoot, string(os.PathListSeparator)),\r\n\t}\r\n}","code-length":58,"reference":"\/\/ NewCache returns a new Cache given the root directory that should be used\n\/\/ on disk for cache storage","result":"Create cache.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cache) KeyToPath(key string) string {\r\n\treturn filepath.Join(c.diskRoot, key)\r\n}","code-length":42,"reference":"\/\/ KeyToPath converts a cache entry key to a path on disk","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ensureDir(dir string) error {\r\n\tif exists(dir) {\r\n\t\treturn nil\r\n\t}\r\n\treturn os.MkdirAll(dir, os.FileMode(0744))\r\n}","code-length":61,"reference":"\/\/ file path helper","result":"Ensure the directory exists.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cache) Put(key string, content io.Reader, contentSHA256 string) error {\r\n\t\r\n\tpath := c.KeyToPath(key)\r\n\tdir := filepath.Dir(path)\r\n\terr := ensureDir(dir)\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Errorf(\"error ensuring directory '%s' exists\", dir)\r\n\t}\r\n\t\r\n\ttemp, err := ioutil.TempFile(dir, \"temp-put\")\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to create cache entry: %v\", err)\r\n\t}\r\n\t\r\n\tif contentSHA256 == \"\" {\r\n\t\t_, err = io.Copy(temp, content)\r\n\t\tif err != nil {\r\n\t\t\tremoveTemp(temp.Name())\r\n\t\t\treturn fmt.Errorf(\"failed to copy into cache entry: %v\", err)\r\n\t\t}\r\n\t} else {\r\n\t\thasher := sha256.New()\r\n\t\t_, err = io.Copy(io.MultiWriter(temp, hasher), content)\r\n\t\tif err != nil {\r\n\t\t\tremoveTemp(temp.Name())\r\n\t\t\treturn fmt.Errorf(\"failed to copy into cache entry: %v\", err)\r\n\t\t}\r\n\t\tactualContentSHA256 := hex.EncodeToString(hasher.Sum(nil))\r\n\t\tif actualContentSHA256 != contentSHA256 {\r\n\t\t\tremoveTemp(temp.Name())\r\n\t\t\treturn fmt.Errorf(\r\n\t\t\t\t\"hashes did not match for '%s', given: '%s' actual: '%s\",\r\n\t\t\t\tkey, contentSHA256, actualContentSHA256)\r\n\t\t}\r\n\t}\r\n\t\r\n\terr = temp.Sync()\r\n\tif err != nil {\r\n\t\tremoveTemp(temp.Name())\r\n\t\treturn fmt.Errorf(\"failed to sync cache entry: %v\", err)\r\n\t}\r\n\ttemp.Close()\r\n\terr = os.Rename(temp.Name(), path)\r\n\tif err != nil {\r\n\t\tremoveTemp(temp.Name())\r\n\t\treturn fmt.Errorf(\"failed to insert contents into cache: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":550,"reference":"\/\/ Put copies the content reader until the end into the cache at key\n\/\/ if contentSHA256 is not \"\" then the contents will only be stored in the\n\/\/ cache if the content's hex string SHA256 matches","result":"Code too long,keep in 512.","score":[0.0003,0.0144]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cache) Get(key string, readHandler ReadHandler) error {\r\n\tpath := c.KeyToPath(key)\r\n\tf, err := os.Open(path)\r\n\tif err != nil {\r\n\t\tif os.IsNotExist(err) {\r\n\t\t\treturn readHandler(false, nil)\r\n\t\t}\r\n\t\treturn fmt.Errorf(\"failed to get key: %v\", err)\r\n\t}\r\n\treturn readHandler(true, f)\r\n}","code-length":128,"reference":"\/\/ Get provides your readHandler with the contents at key","result":"Get the value of a key.","score":[0.1179,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cache) Delete(key string) error {\r\n\treturn os.Remove(c.KeyToPath(key))\r\n}","code-length":41,"reference":"\/\/ Delete deletes the file at key","result":"Delete the cache.","score":[0.128,0.1515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewGCSArtifact(ctx context.Context, handle artifactHandle, link string, path string, sizeLimit int64) *GCSArtifact {\r\n\treturn &GCSArtifact{\r\n\t\thandle:    handle,\r\n\t\tlink:      link,\r\n\t\tpath:      path,\r\n\t\tsizeLimit: sizeLimit,\r\n\t\tctx:       ctx,\r\n\t}\r\n}","code-length":102,"reference":"\/\/ NewGCSArtifact returns a new GCSArtifact with a given handle, canonical link, and path within the job","result":"Create artifact.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *GCSArtifact) Size() (int64, error) {\r\n\tattrs, err := a.handle.Attrs(a.ctx)\r\n\tif err != nil {\r\n\t\treturn 0, fmt.Errorf(\"error getting gcs attributes for artifact: %v\", err)\r\n\t}\r\n\treturn attrs.Size, nil\r\n}","code-length":90,"reference":"\/\/ Size returns the size of the artifact in GCS","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *GCSArtifact) ReadAll() ([]byte, error) {\r\n\tsize, err := a.Size()\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error getting artifact size: %v\", err)\r\n\t}\r\n\tif size > a.sizeLimit {\r\n\t\treturn nil, lenses.ErrFileTooLarge\r\n\t}\r\n\treader, err := a.handle.NewReader(a.ctx)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error getting artifact reader: %v\", err)\r\n\t}\r\n\tdefer reader.Close()\r\n\tp, err := ioutil.ReadAll(reader)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error reading all from artifact: %v\", err)\r\n\t}\r\n\treturn p, nil\r\n}","code-length":216,"reference":"\/\/ ReadAll will either read the entire file or throw an error if file size is too big","result":"Generate code for the generated code.","score":[0.0261,0.0298]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *GCSArtifact) ReadTail(n int64) ([]byte, error) {\r\n\tgzipped, err := a.gzipped()\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error checking artifact for gzip compression: %v\", err)\r\n\t}\r\n\tif gzipped {\r\n\t\treturn nil, lenses.ErrGzipOffsetRead\r\n\t}\r\n\tsize, err := a.Size()\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error getting artifact size: %v\", err)\r\n\t}\r\n\tvar offset int64\r\n\tif n >= size {\r\n\t\toffset = 0\r\n\t} else {\r\n\t\toffset = size - n\r\n\t}\r\n\treader, err := a.handle.NewRangeReader(a.ctx, offset, -1)\r\n\tdefer reader.Close()\r\n\tif err != nil && err != io.EOF {\r\n\t\treturn nil, fmt.Errorf(\"error getting artifact reader: %v\", err)\r\n\t}\r\n\tread, err := ioutil.ReadAll(reader)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error reading all from artiact: %v\", err)\r\n\t}\r\n\treturn read, nil\r\n}","code-length":320,"reference":"\/\/ ReadTail reads the last n bytes from a file in GCS","result":"Read the contents of the artifact .","score":[0.0791,0.087]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *GCSArtifact) gzipped() (bool, error) {\r\n\tattrs, err := a.handle.Attrs(a.ctx)\r\n\tif err != nil {\r\n\t\treturn false, fmt.Errorf(\"error getting gcs attributes for artifact: %v\", err)\r\n\t}\r\n\treturn attrs.ContentEncoding == \"gzip\", nil\r\n}","code-length":94,"reference":"\/\/ gzipped returns whether the file is gzip-encoded in GCS","result":"Determine if the artifact is.","score":[0.0884,0.0526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc optionsForRepo(config *plugins.Configuration, org, repo string) *plugins.Welcome {\r\n\tfullName := fmt.Sprintf(\"%s\/%s\", org, repo)\r\n\t\r\n\tfor _, c := range config.Welcome {\r\n\t\tif !strInSlice(fullName, c.Repos) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\treturn &c\r\n\t}\r\n\t\r\n\tfor _, c := range config.Welcome {\r\n\t\tif !strInSlice(org, c.Repos) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\treturn &c\r\n\t}\r\n\t\r\n\treturn &plugins.Welcome{}\r\n}","code-length":177,"reference":"\/\/ optionsForRepo gets the plugins.Welcome struct that is applicable to the indicated repo.","result":"Generate the options for a repo.","score":[0.0715,0.0813]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *prowJobLister) List(selector labels.Selector) (ret []*v1.ProwJob, err error) {\r\n\terr = cache.ListAll(s.indexer, selector, func(m interface{}) {\r\n\t\tret = append(ret, m.(*v1.ProwJob))\r\n\t})\r\n\treturn ret, err\r\n}","code-length":97,"reference":"\/\/ List lists all ProwJobs in the indexer.","result":"Support nested list operations.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *prowJobLister) ProwJobs(namespace string) ProwJobNamespaceLister {\r\n\treturn prowJobNamespaceLister{indexer: s.indexer, namespace: namespace}\r\n}","code-length":54,"reference":"\/\/ ProwJobs returns an object that can list and get ProwJobs.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s prowJobNamespaceLister) List(selector labels.Selector) (ret []*v1.ProwJob, err error) {\r\n\terr = cache.ListAllByNamespace(s.indexer, s.namespace, selector, func(m interface{}) {\r\n\t\tret = append(ret, m.(*v1.ProwJob))\r\n\t})\r\n\treturn ret, err\r\n}","code-length":103,"reference":"\/\/ List lists all ProwJobs in the indexer for a given namespace.","result":"List prow jobs in a namespace.","score":[0.1004,0.1754]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (br Brancher) RunsAgainstAllBranch() bool {\r\n\treturn len(br.SkipBranches) == 0 && len(br.Branches) == 0\r\n}","code-length":49,"reference":"\/\/ RunsAgainstAllBranch returns true if there are both branches and skip_branches are unset","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (br Brancher) Intersects(other Brancher) bool {\r\n\tif br.RunsAgainstAllBranch() || other.RunsAgainstAllBranch() {\r\n\t\treturn true\r\n\t}\r\n\tif len(br.Branches) > 0 {\r\n\t\tbaseBranches := sets.NewString(br.Branches...)\r\n\t\tif len(other.Branches) > 0 {\r\n\t\t\totherBranches := sets.NewString(other.Branches...)\r\n\t\t\tif baseBranches.Intersection(otherBranches).Len() > 0 {\r\n\t\t\t\treturn true\r\n\t\t\t}\r\n\t\t\treturn false\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tfor _, b := range baseBranches.List() {\r\n\t\t\tif other.ShouldRun(b) {\r\n\t\t\t\treturn true\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn false\r\n\t}\r\n\tif len(other.Branches) == 0 {\r\n\t\t\r\n\t\treturn true\r\n\t}\r\n\treturn other.Intersects(br)\r\n}","code-length":257,"reference":"\/\/ Intersects checks if other Brancher would trigger for the same branch.","result":"Test if two Branchers intersect.","score":[0.0593,0.0885]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cm RegexpChangeMatcher) ShouldRun(changes ChangedFilesProvider) (determined bool, shouldRun bool, err error) {\r\n\tif cm.CouldRun() {\r\n\t\tchangeList, err := changes()\r\n\t\tif err != nil {\r\n\t\t\treturn true, false, err\r\n\t\t}\r\n\t\treturn true, cm.RunsAgainstChanges(changeList), nil\r\n\t}\r\n\treturn false, false, nil\r\n}","code-length":117,"reference":"\/\/ ShouldRun determines if we can know for certain that the job should run. We can either\n\/\/ know for certain that the job should or should not run based on the matcher, or we can\n\/\/ not be able to determine that fact at all.","result":"Match the regexp in the file .","score":[0.0007,0.0238]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cm RegexpChangeMatcher) RunsAgainstChanges(changes []string) bool {\r\n\tfor _, change := range changes {\r\n\t\tif cm.reChanges.MatchString(change) {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":78,"reference":"\/\/ RunsAgainstChanges returns true if any of the changed input paths match the run_if_changed regex.","result":"Match regexp changes.","score":[0,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ps Postsubmit) CouldRun(baseRef string) bool {\r\n\treturn ps.Brancher.ShouldRun(baseRef)\r\n}","code-length":42,"reference":"\/\/ CouldRun determines if the postsubmit could run against a specific\n\/\/ base ref","result":"Generate the code.","score":[0.0104,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ps Postsubmit) ShouldRun(baseRef string, changes ChangedFilesProvider) (bool, error) {\r\n\tif !ps.CouldRun(baseRef) {\r\n\t\treturn false, nil\r\n\t}\r\n\tif determined, shouldRun, err := ps.RegexpChangeMatcher.ShouldRun(changes); err != nil {\r\n\t\treturn false, err\r\n\t} else if determined {\r\n\t\treturn shouldRun, nil\r\n\t}\r\n\t\r\n\treturn true, nil\r\n}","code-length":127,"reference":"\/\/ ShouldRun determines if the postsubmit should run in response to a\n\/\/ set of changes. This is evaluated lazily, if necessary.","result":"Check if the postsubmit should run.","score":[0.042,0.1838]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ps Presubmit) CouldRun(baseRef string) bool {\r\n\treturn ps.Brancher.ShouldRun(baseRef)\r\n}","code-length":43,"reference":"\/\/ CouldRun determines if the presubmit could run against a specific\n\/\/ base ref","result":"Generate the generated code.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ps Presubmit) ShouldRun(baseRef string, changes ChangedFilesProvider, forced, defaults bool) (bool, error) {\r\n\tif !ps.CouldRun(baseRef) {\r\n\t\treturn false, nil\r\n\t}\r\n\tif ps.AlwaysRun {\r\n\t\treturn true, nil\r\n\t}\r\n\tif forced {\r\n\t\treturn true, nil\r\n\t}\r\n\tif determined, shouldRun, err := ps.RegexpChangeMatcher.ShouldRun(changes); err != nil {\r\n\t\treturn false, err\r\n\t} else if determined {\r\n\t\treturn shouldRun, nil\r\n\t}\r\n\treturn defaults, nil\r\n}","code-length":169,"reference":"\/\/ ShouldRun determines if the presubmit should run against a specific\n\/\/ base ref, or in response to a set of changes. The latter mechanism\n\/\/ is evaluated lazily, if necessary.","result":"Generate the code.","score":[0.0,0.0177]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *JobConfig) GetPresubmit(repo, jobName string) *Presubmit {\r\n\tpresubmits := c.AllPresubmits([]string{repo})\r\n\tfor i := range presubmits {\r\n\t\tps := presubmits[i]\r\n\t\tif ps.Name == jobName {\r\n\t\t\treturn &ps\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":108,"reference":"\/\/ GetPresubmit returns the presubmit job for the provided repo and job name.","result":"Get the presubmit.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *JobConfig) SetPresubmits(jobs map[string][]Presubmit) error {\r\n\tnj := map[string][]Presubmit{}\r\n\tfor k, v := range jobs {\r\n\t\tnj[k] = make([]Presubmit, len(v))\r\n\t\tcopy(nj[k], v)\r\n\t\tif err := SetPresubmitRegexes(nj[k]); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tc.Presubmits = nj\r\n\treturn nil\r\n}","code-length":150,"reference":"\/\/ SetPresubmits updates c.Presubmits to jobs, after compiling and validating their regexes.","result":"Set the default value of the function .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *JobConfig) SetPostsubmits(jobs map[string][]Postsubmit) error {\r\n\tnj := map[string][]Postsubmit{}\r\n\tfor k, v := range jobs {\r\n\t\tnj[k] = make([]Postsubmit, len(v))\r\n\t\tcopy(nj[k], v)\r\n\t\tif err := SetPostsubmitRegexes(nj[k]); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tc.Postsubmits = nj\r\n\treturn nil\r\n}","code-length":146,"reference":"\/\/ SetPostsubmits updates c.Postsubmits to jobs, after compiling and validating their regexes.","result":"Set the postsubmits in the job config.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *JobConfig) AllPresubmits(repos []string) []Presubmit {\r\n\tvar res []Presubmit\r\n\tfor repo, v := range c.Presubmits {\r\n\t\tif len(repos) == 0 {\r\n\t\t\tres = append(res, v...)\r\n\t\t} else {\r\n\t\t\tfor _, r := range repos {\r\n\t\t\t\tif r == repo {\r\n\t\t\t\t\tres = append(res, v...)\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn res\r\n}","code-length":150,"reference":"\/\/ AllPresubmits returns all prow presubmit jobs in repos.\n\/\/ if repos is empty, return all presubmits.","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *JobConfig) AllPostsubmits(repos []string) []Postsubmit {\r\n\tvar res []Postsubmit\r\n\tfor repo, v := range c.Postsubmits {\r\n\t\tif len(repos) == 0 {\r\n\t\t\tres = append(res, v...)\r\n\t\t} else {\r\n\t\t\tfor _, r := range repos {\r\n\t\t\t\tif r == repo {\r\n\t\t\t\t\tres = append(res, v...)\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn res\r\n}","code-length":148,"reference":"\/\/ AllPostsubmits returns all prow postsubmit jobs in repos.\n\/\/ if repos is empty, return all postsubmits.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *JobConfig) AllPeriodics() []Periodic {\r\n\tvar listPeriodic func(ps []Periodic) []Periodic\r\n\tlistPeriodic = func(ps []Periodic) []Periodic {\r\n\t\tvar res []Periodic\r\n\t\tfor _, p := range ps {\r\n\t\t\tres = append(res, p)\r\n\t\t}\r\n\t\treturn res\r\n\t}\r\n\treturn listPeriodic(c.Periodics)\r\n}","code-length":114,"reference":"\/\/ AllPeriodics returns all prow periodic jobs.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ClearCompiledRegexes(presubmits []Presubmit) {\r\n\tfor i := range presubmits {\r\n\t\tpresubmits[i].re = nil\r\n\t\tpresubmits[i].Brancher.re = nil\r\n\t\tpresubmits[i].Brancher.reSkip = nil\r\n\t\tpresubmits[i].RegexpChangeMatcher.reChanges = nil\r\n\t}\r\n}","code-length":106,"reference":"\/\/ ClearCompiledRegexes removes compiled regexes from the presubmits,\n\/\/ useful for testing when deep equality is needed between presubmits","result":"Clear compiled regexes.","score":[0.002,0.0287]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *SimpleConfig) Empty() bool {\r\n\treturn len(s.Approvers) == 0 && len(s.Reviewers) == 0 && len(s.RequiredReviewers) == 0 && len(s.Labels) == 0\r\n}","code-length":66,"reference":"\/\/ Empty checks if a SimpleConfig could be considered empty","result":"Create a new function.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(\r\n\tgc *git.Client,\r\n\tghc *github.Client,\r\n\tmdYAMLEnabled func(org, repo string) bool,\r\n\tskipCollaborators func(org, repo string) bool,\r\n\townersDirBlacklist func() prowConf.OwnersDirBlacklist,\r\n) *Client {\r\n\treturn &Client{\r\n\t\tgit:    gc,\r\n\t\tghc:    ghc,\r\n\t\tlogger: logrus.WithField(\"client\", \"repoowners\"),\r\n\t\tcache:  make(map[string]cacheEntry),\r\n\t\tmdYAMLEnabled:      mdYAMLEnabled,\r\n\t\tskipCollaborators:  skipCollaborators,\r\n\t\townersDirBlacklist: ownersDirBlacklist,\r\n\t}\r\n}","code-length":193,"reference":"\/\/ NewClient is the constructor for Client","result":"Create a new client.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a RepoAliases) ExpandAlias(alias string) sets.String {\r\n\tif a == nil {\r\n\t\treturn nil\r\n\t}\r\n\treturn a[github.NormLogin(alias)]\r\n}","code-length":59,"reference":"\/\/ ExpandAlias returns members of an alias","result":"Expand aliases.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a RepoAliases) ExpandAliases(logins sets.String) sets.String {\r\n\tif a == nil {\r\n\t\treturn logins\r\n\t}\r\n\t\r\n\tlogins = logins.Union(nil)\r\n\tfor _, login := range logins.List() {\r\n\t\tif expanded := a.ExpandAlias(login); len(expanded) > 0 {\r\n\t\t\tlogins.Delete(login)\r\n\t\t\tlogins = logins.Union(expanded)\r\n\t\t}\r\n\t}\r\n\treturn logins\r\n}","code-length":142,"reference":"\/\/ ExpandAliases returns members of multiple aliases, duplicates are pruned","result":"Expand aliases in the repo.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseFullConfig(b []byte) (FullConfig, error) {\r\n\tfull := new(FullConfig)\r\n\terr := yaml.Unmarshal(b, full)\r\n\treturn *full, err\r\n}","code-length":59,"reference":"\/\/ ParseFullConfig will unmarshal OWNERS file's content into a FullConfig\n\/\/ Returns an error if the content cannot be unmarshalled","result":"Parse yaml.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseSimpleConfig(b []byte) (SimpleConfig, error) {\r\n\tsimple := new(SimpleConfig)\r\n\terr := yaml.Unmarshal(b, simple)\r\n\treturn *simple, err\r\n}","code-length":59,"reference":"\/\/ ParseSimpleConfig will unmarshal an OWNERS file's content into a SimpleConfig\n\/\/ Returns an error if the content cannot be unmarshalled","result":"Parse yaml.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc decodeOwnersMdConfig(path string, config *SimpleConfig) error {\r\n\tfileBytes, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tmeta := mdStructuredHeaderRegex.FindString(string(fileBytes))\r\n\t\r\n\treturn yaml.Unmarshal([]byte(meta), &config)\r\n}","code-length":102,"reference":"\/\/ decodeOwnersMdConfig will parse the yaml header if it exists and unmarshal it into a singleOwnersConfig.\n\/\/ If no yaml header is found, do nothing\n\/\/ Returns an error if the file cannot be read or the yaml header is found but cannot be unmarshalled.","result":"Decode the metadata file.","score":[0.0,0.0122]}
{"code":"\/*is used to<extra_id_0>\r\nfunc findOwnersForFile(log *logrus.Entry, path string, ownerMap map[string]map[*regexp.Regexp]sets.String) string {\r\n\td := path\r\n\tfor ; d != baseDirConvention; d = canonicalize(filepath.Dir(d)) {\r\n\t\trelative, err := filepath.Rel(d, path)\r\n\t\tif err != nil {\r\n\t\t\tlog.WithError(err).WithField(\"path\", path).Errorf(\"Unable to find relative path between %q and path.\", d)\r\n\t\t\treturn \"\"\r\n\t\t}\r\n\t\tfor re, n := range ownerMap[d] {\r\n\t\t\tif re != nil && !re.MatchString(relative) {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tif len(n) != 0 {\r\n\t\t\t\treturn d\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn \"\"\r\n}","code-length":225,"reference":"\/\/ findOwnersForFile returns the OWNERS file path furthest down the tree for a specified file\n\/\/ using ownerMap to check for entries","result":"Find the owner of a file.","score":[0.016,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *RepoOwners) FindApproverOwnersForFile(path string) string {\r\n\treturn findOwnersForFile(o.log, path, o.approvers)\r\n}","code-length":54,"reference":"\/\/ FindApproverOwnersForFile returns the OWNERS file path furthest down the tree for a specified file\n\/\/ that contains an approvers section","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *RepoOwners) FindReviewersOwnersForFile(path string) string {\r\n\treturn findOwnersForFile(o.log, path, o.reviewers)\r\n}","code-length":54,"reference":"\/\/ FindReviewersOwnersForFile returns the OWNERS file path furthest down the tree for a specified file\n\/\/ that contains a reviewers section","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *RepoOwners) FindLabelsForFile(path string) sets.String {\r\n\treturn o.entriesForFile(path, o.labels, false)\r\n}","code-length":50,"reference":"\/\/ FindLabelsForFile returns a set of labels which should be applied to PRs\n\/\/ modifying files under the given path.","result":"Find labels for files.","score":[0.0059,0.0272]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *RepoOwners) IsNoParentOwners(path string) bool {\r\n\treturn o.options[path].NoParentOwners\r\n}","code-length":45,"reference":"\/\/ IsNoParentOwners checks if an OWNERS file path refers to an OWNERS file with NoParentOwners enabled.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Coverage) Ratio() float32 {\r\n\tif c.NumAllStmts == 0 {\r\n\t\treturn 1\r\n\t}\r\n\treturn float32(c.NumCoveredStmts) \/ float32(c.NumAllStmts)\r\n}","code-length":73,"reference":"\/\/ Ratio returns the percentage of statements that are covered","result":"Calculate the ratio of all statements covered by this function.","score":[0.1535,0.25]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pe *PeriodicProwJobEvent) FromPayload(data []byte) error {\r\n\tif err := json.Unmarshal(data, pe); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":64,"reference":"\/\/ FromPayload set the PeriodicProwJobEvent from the PubSub message payload.","result":"Construct the event payload.","score":[0.0848,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pe *PeriodicProwJobEvent) ToMessage() (*pubsub.Message, error) {\r\n\tdata, err := json.Marshal(pe)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tmessage := pubsub.Message{\r\n\t\tData: data,\r\n\t\tAttributes: map[string]string{\r\n\t\t\tprowEventType: periodicProwJobEvent,\r\n\t\t},\r\n\t}\r\n\treturn &message, nil\r\n}","code-length":128,"reference":"\/\/ ToMessage generates a PubSub Message from a PeriodicProwJobEvent.","result":"Generate the message.","score":[0,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Privacy) UnmarshalText(text []byte) error {\r\n\tv := Privacy(text)\r\n\tif _, ok := privacySettings[v]; !ok {\r\n\t\treturn fmt.Errorf(\"bad privacy setting: %s\", v)\r\n\t}\r\n\t*p = v\r\n\treturn nil\r\n}","code-length":88,"reference":"\/\/ UnmarshalText returns an error if text != secret or closed","result":"Parse the file .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc compileApplicableBlockades(org, repo string, log *logrus.Entry, blockades []plugins.Blockade) []blockade {\r\n\tif len(blockades) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\torgRepo := fmt.Sprintf(\"%s\/%s\", org, repo)\r\n\tvar compiled []blockade\r\n\tfor _, raw := range blockades {\r\n\t\t\r\n\t\tif !stringInSlice(org, raw.Repos) && !stringInSlice(orgRepo, raw.Repos) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tb := blockade{}\r\n\t\tfor _, str := range raw.BlockRegexps {\r\n\t\t\tif reg, err := regexp.Compile(str); err != nil {\r\n\t\t\t\tlog.WithError(err).Errorf(\"Failed to compile the blockade regexp '%s'.\", str)\r\n\t\t\t} else {\r\n\t\t\t\tb.blockRegexps = append(b.blockRegexps, reg)\r\n\t\t\t}\r\n\t\t}\r\n\t\tif len(b.blockRegexps) == 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif raw.Explanation == \"\" {\r\n\t\t\tb.explanation = \"Files are protected\"\r\n\t\t} else {\r\n\t\t\tb.explanation = raw.Explanation\r\n\t\t}\r\n\t\tfor _, str := range raw.ExceptionRegexps {\r\n\t\t\tif reg, err := regexp.Compile(str); err != nil {\r\n\t\t\t\tlog.WithError(err).Errorf(\"Failed to compile the blockade regexp '%s'.\", str)\r\n\t\t\t} else {\r\n\t\t\t\tb.exceptionRegexps = append(b.exceptionRegexps, reg)\r\n\t\t\t}\r\n\t\t}\r\n\t\tcompiled = append(compiled, b)\r\n\t}\r\n\treturn compiled\r\n}","code-length":447,"reference":"\/\/ compileApplicableBlockades filters the specified blockades and compiles those that apply to the repo.","result":"Compile the blockade regexp.","score":[0.0262,0.1154]}
{"code":"\/*is used to<extra_id_0>\r\nfunc calculateBlocks(changes []github.PullRequestChange, blockades []blockade) summary {\r\n\tsum := make(summary)\r\n\tfor _, change := range changes {\r\n\t\tfor _, b := range blockades {\r\n\t\t\tif b.isBlocked(change.Filename) {\r\n\t\t\t\tsum[b.explanation] = append(sum[b.explanation], change)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn sum\r\n}","code-length":121,"reference":"\/\/ calculateBlocks determines if a PR should be blocked and returns the summary describing the block.","result":"Calculate the block summary.","score":[0.0159,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MergeMultipleProfiles(profiles [][]*cover.Profile) ([]*cover.Profile, error) {\r\n\tif len(profiles) < 1 {\r\n\t\treturn nil, errors.New(\"can't merge zero profiles\")\r\n\t}\r\n\tresult := profiles[0]\r\n\tfor _, profile := range profiles[1:] {\r\n\t\tvar err error\r\n\t\tif result, err = MergeProfiles(result, profile); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\treturn result, nil\r\n}","code-length":140,"reference":"\/\/ MergeMultipleProfiles merges more than two profiles together.\n\/\/ MergeMultipleProfiles is equivalent to calling MergeProfiles on pairs of profiles\n\/\/ until only one profile remains.","result":"Merge multiple profiles.","score":[0,0.0219]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *Options) AddFlags(fs *flag.FlagSet) {\r\n\tfs.StringVar(&o.ProcessLog, \"process-log\", \"\", \"path to the log where stdout and stderr are streamed for the process we execute\")\r\n\tfs.StringVar(&o.MarkerFile, \"marker-file\", \"\", \"file we write the return code of the process we execute once it has finished running\")\r\n\tfs.StringVar(&o.MetadataFile, \"metadata-file\", \"\", \"path to the metadata file generated from the job\")\r\n}","code-length":136,"reference":"\/\/ AddFlags adds flags to the FlagSet that populate\n\/\/ the wrapper options struct provided.","result":"Add flags to the options.","score":[0.067,0.2679]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) processNextItem() bool {\r\n\tkey, quit := c.queue.Get()\r\n\tif quit {\r\n\t\treturn false\r\n\t}\r\n\tdefer c.queue.Done(key)\r\n\tworkItem := key.(item)\r\n\tprowJob, err := c.prowJobClient.GetProwJob(workItem.prowJobId)\r\n\tif err != nil {\r\n\t\tc.handleErr(err, workItem)\r\n\t\treturn true\r\n\t}\r\n\tspec := downwardapi.NewJobSpec(prowJob.Spec, prowJob.Status.BuildID, prowJob.Name)\r\n\tresult := c.client.Pods(workItem.namespace).GetLogs(workItem.podName, &api.PodLogOptions{Container: workItem.containerName}).Do()\r\n\tif err := result.Error(); err != nil {\r\n\t\tc.handleErr(err, workItem)\r\n\t\treturn true\r\n\t}\r\n\t\r\n\tlog, _ := result.Raw()\r\n\tvar target string\r\n\tif workItem.podName == workItem.prowJobId {\r\n\t\ttarget = path.Join(ContainerLogDir, fmt.Sprintf(\"%s.txt\", workItem.containerName))\r\n\t} else {\r\n\t\ttarget = path.Join(ContainerLogDir, workItem.podName, fmt.Sprintf(\"%s.txt\", workItem.containerName))\r\n\t}\r\n\tdata := gcs.DataUpload(bytes.NewReader(log))\r\n\tif err := c.gcsConfig.Run(&spec, map[string]gcs.UploadFunc{target: data}); err != nil {\r\n\t\tc.handleErr(err, workItem)\r\n\t\treturn true\r\n\t}\r\n\tc.queue.Forget(key)\r\n\treturn true\r\n}","code-length":455,"reference":"\/\/ processNextItem attempts to upload container logs to GCS","result":"Process the work item.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) handleErr(err error, key item) {\r\n\tif c.queue.NumRequeues(key) < 5 {\r\n\t\tglog.Infof(\"Error uploading logs for container %v in pod %v: %v\", key.containerName, key.podName, err)\r\n\t\tc.queue.AddRateLimited(key)\r\n\t\treturn\r\n\t}\r\n\tc.queue.Forget(key)\r\n\tglog.Infof(\"Giving up on upload of logs for container %v in pod %v: %v\", key.containerName, key.podName, err)\r\n}","code-length":157,"reference":"\/\/ handleErr checks if an error happened and makes sure we will retry later.","result":"Handle errors in the controller.","score":[0,0.0382]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AggregateFilter(filters []Filter) Filter {\r\n\treturn func(presubmit config.Presubmit) (bool, bool, bool) {\r\n\t\tfor _, filter := range filters {\r\n\t\t\tif shouldRun, forced, defaults := filter(presubmit); shouldRun {\r\n\t\t\t\treturn shouldRun, forced, defaults\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn false, false, false\r\n\t}\r\n}","code-length":113,"reference":"\/\/ AggregateFilter builds a filter that evaluates the child filters in order\n\/\/ and returns the first match","result":"Aggregate filters.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FilterPresubmits(filter Filter, changes config.ChangedFilesProvider, branch string, presubmits []config.Presubmit, logger *logrus.Entry) ([]config.Presubmit, []config.Presubmit, error) {\r\n\tvar toTrigger []config.Presubmit\r\n\tvar toSkip []config.Presubmit\r\n\tfor _, presubmit := range presubmits {\r\n\t\tmatches, forced, defaults := filter(presubmit)\r\n\t\tif !matches {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tshouldRun, err := presubmit.ShouldRun(branch, changes, forced, defaults)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, nil, err\r\n\t\t}\r\n\t\tif shouldRun {\r\n\t\t\ttoTrigger = append(toTrigger, presubmit)\r\n\t\t} else {\r\n\t\t\ttoSkip = append(toSkip, presubmit)\r\n\t\t}\r\n\t}\r\n\tlogger.WithFields(logrus.Fields{\"to-trigger\": toTrigger, \"to-skip\": toSkip}).Debugf(\"Filtered %d jobs, found %d to trigger and %d to skip.\", len(presubmits), len(toTrigger), len(toSkip))\r\n\treturn toTrigger, toSkip, nil\r\n}","code-length":318,"reference":"\/\/ FilterPresubmits determines which presubmits should run and which should be skipped\n\/\/ by evaluating the user-provided filter.","result":"Filter the presubmits.","score":[0.0028,0.0303]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MakeCommand() *cobra.Command {\r\n\tflags := &flags{}\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"filter [file]\",\r\n\t\tShort: \"Filters a Go coverage file.\",\r\n\t\tLong:  `Filters a Go coverage file, removing entries that do not match the given flags.`,\r\n\t\tRun: func(cmd *cobra.Command, args []string) {\r\n\t\t\trun(flags, cmd, args)\r\n\t\t},\r\n\t}\r\n\tcmd.Flags().StringVarP(&flags.OutputFile, \"output\", \"o\", \"-\", \"output file\")\r\n\tcmd.Flags().StringSliceVar(&flags.IncludePaths, \"include-path\", nil, \"If specified at least once, only files with paths matching one of these regexes are included.\")\r\n\tcmd.Flags().StringSliceVar(&flags.ExcludePaths, \"exclude-path\", nil, \"Files with paths matching one of these regexes are excluded. Can be used repeatedly.\")\r\n\treturn cmd\r\n}","code-length":257,"reference":"\/\/ MakeCommand returns a `filter` command.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *EventTimeHeap) Push(x interface{}) {\r\n\t*t = append(*t, x.(sql.IssueEvent))\r\n}","code-length":45,"reference":"\/\/ Push adds event to the heap","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *EventTimeHeap) Pop() interface{} {\r\n\told := *t\r\n\tn := len(old)\r\n\tx := old[n-1]\r\n\t*t = old[0 : n-1]\r\n\treturn x\r\n}","code-length":71,"reference":"\/\/ Pop retrieves the last added event","result":"Avoid recursion.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFakeOpenPluginWrapper(plugin Plugin) *FakeOpenPluginWrapper {\r\n\treturn &FakeOpenPluginWrapper{\r\n\t\tplugin:      plugin,\r\n\t\talreadyOpen: map[string]bool{},\r\n\t}\r\n}","code-length":65,"reference":"\/\/ NewFakeOpenPluginWrapper is the constructor for FakeOpenPluginWrapper","result":"Wrap plugin .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *FakeOpenPluginWrapper) ReceiveIssue(issue sql.Issue) []Point {\r\n\tif _, ok := o.alreadyOpen[issue.ID]; !ok {\r\n\t\t\r\n\t\theap.Push(&o.openEvents, sql.IssueEvent{\r\n\t\t\tEvent:          \"opened\",\r\n\t\t\tIssueID:        issue.ID,\r\n\t\t\tActor:          &issue.User,\r\n\t\t\tEventCreatedAt: issue.IssueCreatedAt,\r\n\t\t})\r\n\t\to.alreadyOpen[issue.ID] = true\r\n\t}\r\n\treturn o.plugin.ReceiveIssue(issue)\r\n}","code-length":157,"reference":"\/\/ ReceiveIssue creates a fake \"opened\" event","result":"Test if the file contains a comment.","score":[0.1615,0.0714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *Options) Validate() error {\r\n\tif o.SrcRoot == \"\" {\r\n\t\treturn errors.New(\"no source root specified\")\r\n\t}\r\n\tif o.Log == \"\" {\r\n\t\treturn errors.New(\"no log file specified\")\r\n\t}\r\n\tif len(o.GitRefs) == 0 {\r\n\t\treturn errors.New(\"no refs specified to clone\")\r\n\t}\r\n\tseen := map[string]sets.String{}\r\n\tfor _, ref := range o.GitRefs {\r\n\t\tif _, seenOrg := seen[ref.Org]; seenOrg {\r\n\t\t\tif seen[ref.Org].Has(ref.Repo) {\r\n\t\t\t\treturn errors.New(\"sync config for %s\/%s provided more than once\")\r\n\t\t\t}\r\n\t\t\tseen[ref.Org].Insert(ref.Repo)\r\n\t\t} else {\r\n\t\t\tseen[ref.Org] = sets.NewString(ref.Repo)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":259,"reference":"\/\/ Validate ensures that the configuration options are valid","result":"Validate the options.","score":[0.0657,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *Options) Complete(args []string) {\r\n\to.GitRefs = o.refs.gitRefs\r\n\to.KeyFiles = o.keys.data\r\n\tfor _, ref := range o.GitRefs {\r\n\t\talias, err := o.clonePath.Execute(OrgRepo{Org: ref.Org, Repo: ref.Repo})\r\n\t\tif err != nil {\r\n\t\t\tpanic(err)\r\n\t\t}\r\n\t\tref.PathAlias = alias\r\n\t\talias, err = o.cloneURI.Execute(OrgRepo{Org: ref.Org, Repo: ref.Repo})\r\n\t\tif err != nil {\r\n\t\t\tpanic(err)\r\n\t\t}\r\n\t\tref.CloneURI = alias\r\n\t}\r\n}","code-length":196,"reference":"\/\/ Complete internalizes command line arguments","result":"Complete the command.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *orgRepoFormat) Set(value string) error {\r\n\ttempl, err := template.New(\"format\").Parse(value)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ta.raw = value\r\n\ta.format = templ\r\n\treturn nil\r\n}","code-length":83,"reference":"\/\/ Set parses out overrides from user input","result":"Set the format of the org.","score":[0.1383,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ensure(binary, install string) error {\r\n\tif _, err := exec.LookPath(binary); err != nil {\r\n\t\treturn fmt.Errorf(\"%s: %s\", binary, install)\r\n\t}\r\n\treturn nil\r\n}","code-length":68,"reference":"\/\/ ensure will ensure binary is on path or return an error with install message.","result":"Ensure the binary is installed.","score":[0.046,0.1825]}
{"code":"\/*is used to<extra_id_0>\r\nfunc output(args ...string) (string, error) {\r\n\tcmd := exec.Command(args[0], args[1:]...)\r\n\tcmd.Stderr = os.Stderr\r\n\tcmd.Stdin = os.Stdin\r\n\tb, err := cmd.Output()\r\n\treturn strings.TrimSpace(string(b)), err\r\n}","code-length":91,"reference":"\/\/ output returns the trimmed output of running args, or an err on non-zero exit.","result":"Output to stdout.","score":[0,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc projects(max int) ([]string, error) {\r\n\tout, err := output(\"gcloud\", \"projects\", \"list\", fmt.Sprintf(\"--limit=%d\", max), \"--format=value(project_id)\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn strings.Split(out, \"\\n\"), nil\r\n}","code-length":100,"reference":"\/\/ projects returns the list of accessible gcp projects","result":"Get the list of projects in the cloud provider.","score":[0.2697,0.3507]}
{"code":"\/*is used to<extra_id_0>\r\nfunc selectProject(choice string) (string, error) {\r\n\tfmt.Print(\"Getting active GCP account...\")\r\n\twho, err := currentAccount()\r\n\tif err != nil {\r\n\t\tlogrus.Warn(\"Run gcloud auth login to initialize gcloud\")\r\n\t\treturn \"\", err\r\n\t}\r\n\tfmt.Println(who)\r\n\tvar projs []string\r\n\tif choice == \"\" {\r\n\t\tfmt.Printf(\"Projects available to %s:\", who)\r\n\t\tfmt.Println()\r\n\t\tconst max = 20\r\n\t\tprojs, err = projects(max)\r\n\t\tfor _, proj := range projs {\r\n\t\t\tfmt.Println(\"  *\", proj)\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"list projects: %v\", err)\r\n\t\t}\r\n\t\tif len(projs) == 0 {\r\n\t\t\tfmt.Println(\"Create a project at https:\r\n\t\t\treturn \"\", errors.New(\"no projects\")\r\n\t\t}\r\n\t\tif len(projs) == max {\r\n\t\t\tfmt.Println(\"  ... Wow, that is a lot of projects!\")\r\n\t\t\tfmt.Println(\"Type the name of any project, including ones not in this truncated list\")\r\n\t\t}\r\n\t\tdef, err := currentProject()\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"get current project: %v\", err)\r\n\t\t}\r\n\t\tfmt.Printf(\"Select project [%s]: \", def)\r\n\t\tfmt.Scanln(&choice)\r\n\t\t\r\n\t\tif choice == \"\" {\r\n\t\t\treturn def, nil\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor _, p := range projs {\r\n\t\tif p == choice {\r\n\t\t\treturn choice, nil\r\n\t\t}\r\n\t}\r\n\tfmt.Printf(\"Ensuring %s has access to %s...\", who, choice)\r\n\tfmt.Println()\r\n\t\r\n\tif err = exec.Command(\"gcloud\", \"projects\", \"describe\", choice).Run(); err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"%s cannot describe project: %v\", who, err)\r\n\t}\r\n\treturn choice, nil\r\n}","code-length":572,"reference":"\/\/ selectProject returns the user-selected project, defaulting to the current gcloud one.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc createCluster(proj, choice string) (*cluster, error) {\r\n\tconst def = \"prow\"\r\n\tif choice == \"\" {\r\n\t\tfmt.Printf(\"Cluster name [%s]: \", def)\r\n\t\tfmt.Scanln(&choice)\r\n\t\tif choice == \"\" {\r\n\t\t\tchoice = def\r\n\t\t}\r\n\t}\r\n\tcmd := exec.Command(\"gcloud\", \"container\", \"clusters\", \"create\", choice)\r\n\tcmd.Stdin = os.Stdin\r\n\tcmd.Stdout = os.Stdout\r\n\tcmd.Stderr = os.Stderr\r\n\tif err := cmd.Run(); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"create cluster: %v\", err)\r\n\t}\r\n\tout, err := output(\"gcloud\", \"container\", \"clusters\", \"describe\", choice, \"--format=value(name,zone)\")\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"describe cluster: %v\", err)\r\n\t}\r\n\tparts := strings.Split(out, \"\\t\")\r\n\tif len(parts) != 2 {\r\n\t\treturn nil, fmt.Errorf(\"bad describe cluster output: %s\", out)\r\n\t}\r\n\treturn &cluster{name: parts[0], zone: parts[1], project: proj}, nil\r\n}","code-length":329,"reference":"\/\/ createCluster causes gcloud to create a cluster in project, returning the context name","result":"Create a cluster in the cloud .","score":[0.1315,0.3639]}
{"code":"\/*is used to<extra_id_0>\r\nfunc createContext(co contextOptions) (string, error) {\r\n\tproj, err := selectProject(co.project)\r\n\tif err != nil {\r\n\t\tlogrus.Info(\"Run gcloud auth login to initialize gcloud\")\r\n\t\treturn \"\", fmt.Errorf(\"get current project: %v\", err)\r\n\t}\r\n\tfmt.Printf(\"Existing GKE clusters in %s:\", proj)\r\n\tfmt.Println()\r\n\tclusters, err := currentClusters(proj)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"list %s clusters: %v\", proj, err)\r\n\t}\r\n\tfor name := range clusters {\r\n\t\tfmt.Println(\"  *\", name)\r\n\t}\r\n\tif len(clusters) == 0 {\r\n\t\tfmt.Println(\"  No clusters\")\r\n\t}\r\n\tvar choice string\r\n\tcreate := co.create\r\n\treuse := co.reuse\r\n\tswitch {\r\n\tcase create != \"\" && reuse != \"\":\r\n\t\treturn \"\", errors.New(\"Cannot use both --create and --reuse\")\r\n\tcase create != \"\":\r\n\t\tfmt.Println(\"Creating new \" + create + \" cluster...\")\r\n\t\tchoice = \"new\"\r\n\tcase reuse != \"\":\r\n\t\tfmt.Println(\"Reusing existing \" + reuse + \" cluster...\")\r\n\t\tchoice = reuse\r\n\tdefault:\r\n\t\tfmt.Print(\"Get credentials for existing cluster or [create new]: \")\r\n\t\tfmt.Scanln(&choice)\r\n\t}\r\n\tif choice == \"\" || choice == \"new\" {\r\n\t\tcluster, err := createCluster(proj, create)\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"create cluster in %s: %v\", proj, err)\r\n\t\t}\r\n\t\treturn cluster.context(), nil\r\n\t}\r\n\tcluster, ok := clusters[choice]\r\n\tif !ok {\r\n\t\treturn \"\", fmt.Errorf(\"cluster not found: %s\", choice)\r\n\t}\r\n\tcmd := exec.Command(\"gcloud\", \"container\", \"clusters\", \"get-credentials\", cluster.name, \"--project=\"+cluster.project, \"--zone=\"+cluster.zone)\r\n\tcmd.Stdin = os.Stdin\r\n\tcmd.Stdout = os.Stdout\r\n\tcmd.Stderr = os.Stderr\r\n\tif err := cmd.Run(); err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"get credentials: %v\", err)\r\n\t}\r\n\treturn cluster.context(), nil\r\n}","code-length":630,"reference":"\/\/ createContext has the user create a context.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc contextConfig() (clientcmd.ClientConfigLoader, *clientcmdapi.Config, error) {\r\n\tif err := ensureKubectl(); err != nil {\r\n\t\tfmt.Println(\"Prow's tackler requires kubectl, please install:\")\r\n\t\tfmt.Println(\"  *\", err)\r\n\t\tif gerr := ensureGcloud(); gerr != nil {\r\n\t\t\tfmt.Println(\"  *\", gerr)\r\n\t\t}\r\n\t\treturn nil, nil, errors.New(\"missing kubectl\")\r\n\t}\r\n\tl := clientcmd.NewDefaultClientConfigLoadingRules()\r\n\tc, err := l.Load()\r\n\treturn l, c, err\r\n}","code-length":179,"reference":"\/\/ contextConfig returns the loader and config, which can create a clientconfig.","result":"Create a context config.","score":[0.0432,0.1674]}
{"code":"\/*is used to<extra_id_0>\r\nfunc selectContext(co contextOptions) (string, error) {\r\n\tfmt.Println(\"Existing kubernetes contexts:\")\r\n\t\r\n\t_, cfg, err := contextConfig()\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Fatal(\"Failed to load ~\/.kube\/config from any obvious location\")\r\n\t}\r\n\t\r\n\toptions := map[int]string{}\r\n\tvar ctxs []string\r\n\tfor ctx := range cfg.Contexts {\r\n\t\tctxs = append(ctxs, ctx)\r\n\t}\r\n\tsort.Strings(ctxs)\r\n\tfor idx, ctx := range ctxs {\r\n\t\toptions[idx] = ctx\r\n\t\tif ctx == cfg.CurrentContext {\r\n\t\t\tfmt.Printf(\"* %d: %s (current)\", idx, ctx)\r\n\t\t} else {\r\n\t\t\tfmt.Printf(\"  %d: %s\", idx, ctx)\r\n\t\t}\r\n\t\tfmt.Println()\r\n\t}\r\n\tfmt.Println()\r\n\tchoice := co.context\r\n\tswitch {\r\n\tcase choice != \"\":\r\n\t\tfmt.Println(\"Reuse \" + choice + \" context...\")\r\n\tcase co.create != \"\" || co.reuse != \"\":\r\n\t\tchoice = \"create\"\r\n\t\tfmt.Println(\"Create new context...\")\r\n\tdefault:\r\n\t\tfmt.Print(\"Choose context or [create new]: \")\r\n\t\tfmt.Scanln(&choice)\r\n\t}\r\n\tif choice == \"create\" || choice == \"\" || choice == \"create new\" || choice == \"new\" {\r\n\t\tctx, err := createContext(co)\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"create context: %v\", err)\r\n\t\t}\r\n\t\treturn ctx, nil\r\n\t}\r\n\tif _, ok := cfg.Contexts[choice]; ok {\r\n\t\treturn choice, nil\r\n\t}\r\n\tidx, err := strconv.Atoi(choice)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"invalid context: %q\", choice)\r\n\t}\r\n\tif ctx, ok := options[idx]; ok {\r\n\t\treturn ctx, nil\r\n\t}\r\n\treturn \"\", fmt.Errorf(\"invalid index: %d\", idx)\r\n}","code-length":577,"reference":"\/\/ selectContext allows the user to choose a context\n\/\/ This may involve creating a cluster","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc applyCreate(ctx string, args ...string) error {\r\n\tcreate := exec.Command(\"kubectl\", append([]string{\"--dry-run=true\", \"--output=yaml\", \"create\"}, args...)...)\r\n\tcreate.Stderr = os.Stderr\r\n\tobj, err := create.StdoutPipe()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"rolebinding pipe: %v\", err)\r\n\t}\r\n\tif err := create.Start(); err != nil {\r\n\t\treturn fmt.Errorf(\"start create: %v\", err)\r\n\t}\r\n\tif err := apply(ctx, obj); err != nil {\r\n\t\treturn fmt.Errorf(\"apply: %v\", err)\r\n\t}\r\n\tif err := create.Wait(); err != nil {\r\n\t\treturn fmt.Errorf(\"create: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":224,"reference":"\/\/ applyCreate will dry-run create and then pipe this to kubectl apply.\n\/\/\n\/\/ If we use the create verb it will fail if the secret already exists.\n\/\/ And kubectl will reject the apply verb with a secret.","result":"Apply rolebindings to a rolebinding.","score":[0.0003,0.0421]}
{"code":"\/*is used to<extra_id_0>\r\nfunc determineSkippedPresubmits(toTrigger, toSkipSuperset []config.Presubmit, logger *logrus.Entry) []config.Presubmit {\r\n\ttriggeredContexts := sets.NewString()\r\n\tfor _, presubmit := range toTrigger {\r\n\t\ttriggeredContexts.Insert(presubmit.Context)\r\n\t}\r\n\tvar toSkip []config.Presubmit\r\n\tfor _, presubmit := range toSkipSuperset {\r\n\t\tif triggeredContexts.Has(presubmit.Context) {\r\n\t\t\tlogger.WithFields(logrus.Fields{\"context\": presubmit.Context, \"job\": presubmit.Name}).Debug(\"Not skipping job as context will be created by a triggered job.\")\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\ttoSkip = append(toSkip, presubmit)\r\n\t}\r\n\treturn toSkip\r\n}","code-length":222,"reference":"\/\/ determineSkippedPresubmits identifies the largest set of contexts we can actually\n\/\/ post skipped contexts for, given a set of presubmits we're triggering. We don't\n\/\/ want to skip a job that posts a context that will be written to by a job we just\n\/\/ identified for triggering or the skipped context will override the triggered one","result":"Determine skipped presubmits.","score":[0.0,0.0095]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Dispatch(plugin plugins.Plugin, DB *InfluxDB, issues chan sql.Issue, eventsCommentsChannel chan interface{}) {\r\n\tfor {\r\n\t\tvar points []plugins.Point\r\n\t\tselect {\r\n\t\tcase issue, ok := <-issues:\r\n\t\t\tif !ok {\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tpoints = plugin.ReceiveIssue(issue)\r\n\t\tcase event, ok := <-eventsCommentsChannel:\r\n\t\t\tif !ok {\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tswitch event := event.(type) {\r\n\t\t\tcase sql.IssueEvent:\r\n\t\t\t\tpoints = plugin.ReceiveIssueEvent(event)\r\n\t\t\tcase sql.Comment:\r\n\t\t\t\tpoints = plugin.ReceiveComment(event)\r\n\t\t\tdefault:\r\n\t\t\t\tglog.Fatal(\"Received invalid object: \", event)\r\n\t\t\t}\r\n\t\t}\r\n\t\tfor _, point := range points {\r\n\t\t\tif err := DB.Push(point.Tags, point.Values, point.Date); err != nil {\r\n\t\t\t\tglog.Fatal(\"Failed to push point: \", err)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":297,"reference":"\/\/ Dispatch receives channels to each type of events, and dispatch them to each plugins.","result":"Dispatch events to the InfluxDB .","score":[0.0512,0.0709]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) CreateIssue(org, repo, title, body string, labels, assignees []string) (*github.Issue, error) {\r\n\tglog.Infof(\"CreateIssue(dry=%t) Title:%q, Labels:%q, Assignees:%q\\n\", c.dryRun, title, labels, assignees)\r\n\tif c.dryRun {\r\n\t\treturn nil, nil\r\n\t}\r\n\tissue := &github.IssueRequest{\r\n\t\tTitle: &title,\r\n\t\tBody:  &body,\r\n\t}\r\n\tif len(labels) > 0 {\r\n\t\tissue.Labels = &labels\r\n\t}\r\n\tif len(assignees) > 0 {\r\n\t\tissue.Assignees = &assignees\r\n\t}\r\n\tvar result *github.Issue\r\n\t_, err := c.retry(\r\n\t\tfmt.Sprintf(\"creating issue '%s'\", title),\r\n\t\tfunc() (*github.Response, error) {\r\n\t\t\tvar resp *github.Response\r\n\t\t\tvar err error\r\n\t\t\tresult, resp, err = c.issueService.Create(context.Background(), org, repo, issue)\r\n\t\t\treturn resp, err\r\n\t\t},\r\n\t)\r\n\treturn result, err\r\n}","code-length":317,"reference":"\/\/ CreateIssue tries to create and return a new github issue.","result":"Create a new issue.","score":[0.0869,0.3064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) CreateStatus(owner, repo, ref string, status *github.RepoStatus) (*github.RepoStatus, error) {\r\n\tglog.Infof(\"CreateStatus(dry=%t) ref:%s: %s:%s\", c.dryRun, ref, *status.Context, *status.State)\r\n\tif c.dryRun {\r\n\t\treturn nil, nil\r\n\t}\r\n\tvar result *github.RepoStatus\r\n\tmsg := fmt.Sprintf(\"creating status for ref '%s'\", ref)\r\n\t_, err := c.retry(msg, func() (*github.Response, error) {\r\n\t\tvar resp *github.Response\r\n\t\tvar err error\r\n\t\tresult, resp, err = c.repoService.CreateStatus(context.Background(), owner, repo, ref, status)\r\n\t\treturn resp, err\r\n\t})\r\n\treturn result, err\r\n}","code-length":228,"reference":"\/\/ CreateStatus creates or updates a status context on the indicated reference.","result":"Create a new repo status.","score":[0.0593,0.0885]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) ForEachPR(owner, repo string, opts *github.PullRequestListOptions, continueOnError bool, mungePR PRMungeFunc) error {\r\n\tvar lastPage int\r\n\t\r\n\t\r\n\t\r\n\t_, err := c.depaginate(\r\n\t\t\"processing PRs\",\r\n\t\t&opts.ListOptions,\r\n\t\tfunc() ([]interface{}, *github.Response, error) {\r\n\t\t\tlist, resp, err := c.prService.List(context.Background(), owner, repo, opts)\r\n\t\t\tif err == nil {\r\n\t\t\t\tfor _, pr := range list {\r\n\t\t\t\t\tif pr == nil {\r\n\t\t\t\t\t\tglog.Errorln(\"Received a nil PR from go-github while listing PRs. Skipping...\")\r\n\t\t\t\t\t}\r\n\t\t\t\t\tif mungeErr := mungePR(pr); mungeErr != nil {\r\n\t\t\t\t\t\tif pr.Number == nil {\r\n\t\t\t\t\t\t\tmungeErr = fmt.Errorf(\"error munging pull request with nil Number field: %v\", mungeErr)\r\n\t\t\t\t\t\t} else {\r\n\t\t\t\t\t\t\tmungeErr = fmt.Errorf(\"error munging pull request #%d: %v\", *pr.Number, mungeErr)\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\tif !continueOnError {\r\n\t\t\t\t\t\t\treturn nil, resp, &retryAbort{mungeErr}\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\tglog.Errorf(\"%v\\n\", mungeErr)\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t\tif resp.LastPage > 0 {\r\n\t\t\t\t\tlastPage = resp.LastPage\r\n\t\t\t\t}\r\n\t\t\t\tglog.Infof(\"ForEachPR processed page %d\/%d\\n\", opts.ListOptions.Page, lastPage)\r\n\t\t\t}\r\n\t\t\treturn nil, resp, err\r\n\t\t},\r\n\t)\r\n\treturn err\r\n}","code-length":456,"reference":"\/\/ ForEachPR iterates over all PRs that fit the specified criteria, calling the munge function on every PR.\n\/\/ If the munge function returns a non-nil error, ForEachPR will return immediately with a non-nil\n\/\/ error unless continueOnError is true in which case an error will be logged and the remaining PRs will be munged.","result":"Get the list of pull requests from github.","score":[0.0004,0.0099]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) GetCollaborators(org, repo string) ([]*github.User, error) {\r\n\topts := &github.ListCollaboratorsOptions{}\r\n\tcollaborators, err := c.depaginate(\r\n\t\tfmt.Sprintf(\"getting collaborators for '%s\/%s'\", org, repo),\r\n\t\t&opts.ListOptions,\r\n\t\tfunc() ([]interface{}, *github.Response, error) {\r\n\t\t\tpage, resp, err := c.repoService.ListCollaborators(context.Background(), org, repo, opts)\r\n\t\t\tvar interfaceList []interface{}\r\n\t\t\tif err == nil {\r\n\t\t\t\tinterfaceList = make([]interface{}, 0, len(page))\r\n\t\t\t\tfor _, user := range page {\r\n\t\t\t\t\tinterfaceList = append(interfaceList, user)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn interfaceList, resp, err\r\n\t\t},\r\n\t)\r\n\tresult := make([]*github.User, 0, len(collaborators))\r\n\tfor _, user := range collaborators {\r\n\t\tresult = append(result, user.(*github.User))\r\n\t}\r\n\treturn result, err\r\n}","code-length":299,"reference":"\/\/ GetCollaborators returns all github users who are members or outside collaborators of the repo.","result":"Get the list of collaborators for a given repo.","score":[0.0885,0.1736]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) GetCombinedStatus(owner, repo, ref string) (*github.CombinedStatus, error) {\r\n\tvar result *github.CombinedStatus\r\n\tlistOpts := &github.ListOptions{}\r\n\tstatuses, err := c.depaginate(\r\n\t\tfmt.Sprintf(\"getting combined status for ref '%s'\", ref),\r\n\t\tlistOpts,\r\n\t\tfunc() ([]interface{}, *github.Response, error) {\r\n\t\t\tcombined, resp, err := c.repoService.GetCombinedStatus(\r\n\t\t\t\tcontext.Background(),\r\n\t\t\t\towner,\r\n\t\t\t\trepo,\r\n\t\t\t\tref,\r\n\t\t\t\tlistOpts,\r\n\t\t\t)\r\n\t\t\tif result == nil {\r\n\t\t\t\tresult = combined\r\n\t\t\t}\r\n\t\t\tvar interfaceList []interface{}\r\n\t\t\tif err == nil {\r\n\t\t\t\tinterfaceList = make([]interface{}, 0, len(combined.Statuses))\r\n\t\t\t\tfor _, status := range combined.Statuses {\r\n\t\t\t\t\tinterfaceList = append(interfaceList, status)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn interfaceList, resp, err\r\n\t\t},\r\n\t)\r\n\tif result != nil {\r\n\t\tresult.Statuses = make([]github.RepoStatus, 0, len(statuses))\r\n\t\tfor _, status := range statuses {\r\n\t\t\tresult.Statuses = append(result.Statuses, status.(github.RepoStatus))\r\n\t\t}\r\n\t}\r\n\treturn result, err\r\n}","code-length":376,"reference":"\/\/ GetCombinedStatus retrieves the CombinedStatus for the specified reference.","result":"Get the combined status of a repo.","score":[0.1214,0.0568]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) GetIssues(org, repo string, opts *github.IssueListByRepoOptions) ([]*github.Issue, error) {\r\n\tissues, err := c.depaginate(\r\n\t\tfmt.Sprintf(\"getting issues from '%s\/%s'\", org, repo),\r\n\t\t&opts.ListOptions,\r\n\t\tfunc() ([]interface{}, *github.Response, error) {\r\n\t\t\tpage, resp, err := c.issueService.ListByRepo(context.Background(), org, repo, opts)\r\n\t\t\tvar interfaceList []interface{}\r\n\t\t\tif err == nil {\r\n\t\t\t\tinterfaceList = make([]interface{}, 0, len(page))\r\n\t\t\t\tfor _, issue := range page {\r\n\t\t\t\t\tinterfaceList = append(interfaceList, issue)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn interfaceList, resp, err\r\n\t\t},\r\n\t)\r\n\tresult := make([]*github.Issue, 0, len(issues))\r\n\tfor _, issue := range issues {\r\n\t\tresult = append(result, issue.(*github.Issue))\r\n\t}\r\n\treturn result, err\r\n}","code-length":289,"reference":"\/\/ GetIssues gets all the issues in a repo that meet the list options.","result":"List all issues in a repo.","score":[0.1126,0.3379]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) GetRepoLabels(org, repo string) ([]*github.Label, error) {\r\n\topts := &github.ListOptions{}\r\n\tlabels, err := c.depaginate(\r\n\t\tfmt.Sprintf(\"getting valid labels for '%s\/%s'\", org, repo),\r\n\t\topts,\r\n\t\tfunc() ([]interface{}, *github.Response, error) {\r\n\t\t\tpage, resp, err := c.issueService.ListLabels(context.Background(), org, repo, opts)\r\n\t\t\tvar interfaceList []interface{}\r\n\t\t\tif err == nil {\r\n\t\t\t\tinterfaceList = make([]interface{}, 0, len(page))\r\n\t\t\t\tfor _, label := range page {\r\n\t\t\t\t\tinterfaceList = append(interfaceList, label)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn interfaceList, resp, err\r\n\t\t},\r\n\t)\r\n\tresult := make([]*github.Label, 0, len(labels))\r\n\tfor _, label := range labels {\r\n\t\tresult = append(result, label.(*github.Label))\r\n\t}\r\n\treturn result, err\r\n}","code-length":287,"reference":"\/\/ GetRepoLabels gets all the labels that valid in the specified repo.","result":"Get all labels for a given repository.","score":[0.094,0.2222]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) GetUser(login string) (*github.User, error) {\r\n\tvar result *github.User\r\n\t_, err := c.retry(\r\n\t\tfmt.Sprintf(\"getting user '%s'\", login),\r\n\t\tfunc() (*github.Response, error) {\r\n\t\t\tvar resp *github.Response\r\n\t\t\tvar err error\r\n\t\t\tresult, resp, err = c.userService.Get(context.Background(), login)\r\n\t\t\treturn resp, err\r\n\t\t},\r\n\t)\r\n\treturn result, err\r\n}","code-length":149,"reference":"\/\/ GetUser gets the github user with the specified login or the currently authenticated user.\n\/\/ To get the currently authenticated user specify a login of \"\".","result":"Get the user.","score":[0.0002,0.1039]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkConfigValidity() error {\r\n\tglog.Info(\"Verifying if a valid config has been provided through the flags\")\r\n\tif *nodeName == \"\" {\r\n\t\treturn fmt.Errorf(\"Flag --node-name has its value unspecified\")\r\n\t}\r\n\tif *gcsPath == \"\" {\r\n\t\treturn fmt.Errorf(\"Flag --gcs-path has its value unspecified\")\r\n\t}\r\n\tif _, err := os.Stat(*gcloudAuthFilePath); err != nil {\r\n\t\treturn fmt.Errorf(\"Could not find the gcloud service account file: %v\", err)\r\n\t} else {\r\n\t\tglog.Infof(\"Running gcloud auth activate-service-account --key-file=%s\\n\", *gcloudAuthFilePath)\r\n\t\tcmd := exec.Command(\"gcloud\", \"auth\", \"activate-service-account\", \"--key-file=\"+*gcloudAuthFilePath)\r\n\t\tvar stderr, stdout bytes.Buffer\r\n\t\tcmd.Stderr, cmd.Stdout = &stderr, &stdout\r\n\t\terr = cmd.Run()\r\n\t\tglog.Infof(\"Stdout:\\n%s\\n\", stdout.String())\r\n\t\tglog.Infof(\"Stderr:\\n%s\\n\", stderr.String())\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"Failed to activate gcloud service account: %v\", err)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":355,"reference":"\/\/ Check if the config provided through the flags take valid values.","result":"Check if a config is valid.","score":[0.1112,0.2242]}
{"code":"\/*is used to<extra_id_0>\r\nfunc createSystemdLogfile(service string, outputMode string, outputDir string) error {\r\n\t\r\n\tjournalCmdArgs := []string{fmt.Sprintf(\"--output=%v\", outputMode), \"-D\", *journalPath}\r\n\tif service == \"kern\" {\r\n\t\tjournalCmdArgs = append(journalCmdArgs, \"-k\")\r\n\t} else {\r\n\t\tjournalCmdArgs = append(journalCmdArgs, \"-u\", fmt.Sprintf(\"%v.service\", service))\r\n\t}\r\n\tcmd := exec.Command(\"journalctl\", journalCmdArgs...)\r\n\t\r\n\toutput, err := cmd.Output()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"Journalctl command for '%v' service failed: %v\", service, err)\r\n\t}\r\n\tlogfile := filepath.Join(outputDir, service+\".log\")\r\n\tif err := ioutil.WriteFile(logfile, output, 0444); err != nil {\r\n\t\treturn fmt.Errorf(\"Writing to file of journalctl logs for '%v' service failed: %v\", service, err)\r\n\t}\r\n\treturn nil\r\n}","code-length":277,"reference":"\/\/ Create logfile for systemd service in outputDir with the given journalctl outputMode.","result":"Create a log file for systemd.","score":[0.0715,0.0813]}
{"code":"\/*is used to<extra_id_0>\r\nfunc createFullSystemdLogfile(outputDir string) error {\r\n\tcmd := exec.Command(\"journalctl\", \"--output=short-precise\", \"-D\", *journalPath)\r\n\t\r\n\toutput, err := cmd.Output()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"Journalctl command failed: %v\", err)\r\n\t}\r\n\tlogfile := filepath.Join(outputDir, \"systemd.log\")\r\n\tif err := ioutil.WriteFile(logfile, output, 0444); err != nil {\r\n\t\treturn fmt.Errorf(\"Writing full journalctl logs to file failed: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":171,"reference":"\/\/ createFullSystemdLogfile creates logfile for full systemd journal in the outputDir.","result":"Create a log file for systemd.","score":[0.0839,0.0952]}
{"code":"\/*is used to<extra_id_0>\r\nfunc createSystemdLogfiles(outputDir string) {\r\n\tservices := append(systemdServices, nodeSystemdServices...)\r\n\tfor _, service := range services {\r\n\t\tif err := createSystemdLogfile(service, \"cat\", outputDir); err != nil {\r\n\t\t\tglog.Warningf(\"Failed to record journalctl logs: %v\", err)\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor _, service := range systemdSetupServices {\r\n\t\tif err := createSystemdLogfile(service, \"short-precise\", outputDir); err != nil {\r\n\t\t\tglog.Warningf(\"Failed to record journalctl logs: %v\", err)\r\n\t\t}\r\n\t}\r\n\tif *dumpSystemdJournal {\r\n\t\tif err := createFullSystemdLogfile(outputDir); err != nil {\r\n\t\t\tglog.Warningf(\"Failed to record journalctl logs: %v\", err)\r\n\t\t}\r\n\t}\r\n}","code-length":242,"reference":"\/\/ Create logfiles for systemd services in outputDir.","result":"Create systemd logfiles.","score":[0.0917,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc prepareLogfiles(logDir string) {\r\n\tglog.Info(\"Preparing logfiles relevant to this node\")\r\n\tlogfiles := nodeLogs[:]\r\n\tswitch *cloudProvider {\r\n\tcase \"gce\", \"gke\":\r\n\t\tlogfiles = append(logfiles, gceLogs...)\r\n\tcase \"aws\":\r\n\t\tlogfiles = append(logfiles, awsLogs...)\r\n\tdefault:\r\n\t\tglog.Errorf(\"Unknown cloud provider '%v' provided, skipping any provider specific logs\", *cloudProvider)\r\n\t}\r\n\t\r\n\tif *enableHollowNodeLogs {\r\n\t\tlogfiles = append(logfiles, kubemarkLogs...)\r\n\t}\r\n\t\r\n\tif _, err := os.Stat(\"\/workspace\/etc\/systemd\/journald.conf\"); err == nil {\r\n\t\tglog.Info(\"Journalctl found on host. Collecting systemd logs\")\r\n\t\tcreateSystemdLogfiles(logDir)\r\n\t} else {\r\n\t\tglog.Infof(\"Journalctl not found on host (%v). Collecting supervisord logs instead\", err)\r\n\t\tlogfiles = append(logfiles, kernelLog)\r\n\t\tlogfiles = append(logfiles, initdLogs...)\r\n\t\tlogfiles = append(logfiles, supervisordLogs...)\r\n\t}\r\n\t\r\n\tfor _, logfile := range logfiles {\r\n\t\tlogfileFullPath := filepath.Join(localLogPath, logfile+\".log*\")\r\n\t\tcmd := exec.Command(\"\/bin\/sh\", \"-c\", fmt.Sprintf(\"cp %v %v\", logfileFullPath, logDir))\r\n\t\tif err := cmd.Run(); err != nil {\r\n\t\t\tglog.Warningf(\"Failed to copy any logfiles with pattern '%v': %v\", logfileFullPath, err)\r\n\t\t}\r\n\t}\r\n}","code-length":452,"reference":"\/\/ Copy logfiles specific to this node based on the cloud-provider, system services, etc\n\/\/ to a temporary directory. Also create logfiles for systemd services if journalctl is present.\n\/\/ We do not expect this function to see an error.","result":"Collect logfiles relevant to this node.","score":[0.001,0.041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc writeSuccessMarkerFile() error {\r\n\tmarkerFilePath := *gcsPath + \"\/logexported-nodes-registry\/\" + *nodeName + \".txt\"\r\n\tcmd := exec.Command(\"gsutil\", \"-q\", \"cp\", \"-a\", \"public-read\", \"-\", markerFilePath)\r\n\tstdin, err := cmd.StdinPipe()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"Failed to get stdin pipe to write marker file: %v\", err)\r\n\t}\r\n\tio.WriteString(stdin, \"\")\r\n\tstdin.Close()\r\n\tif err = cmd.Run(); err != nil {\r\n\t\treturn fmt.Errorf(\"Failed to write marker file to GCS: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":192,"reference":"\/\/ Write a marker file to GCS named after this node to indicate logexporter's success.\n\/\/ The directory to which we write this file can then be used as a registry to quickly\n\/\/ fetch the list of nodes on which logexporter succeeded.","result":"Write the success marker file to GCS.","score":[0.0022,0.0635]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MakeCommand() *cobra.Command {\r\n\tflags := &flags{}\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"junit [profile]\",\r\n\t\tShort: \"Summarize coverage profile and produce the result in junit xml format.\",\r\n\t\tLong: `Summarize coverage profile and produce the result in junit xml format.\r\nSummary done at per-file and per-package level. Any coverage below coverage-threshold will be marked\r\nwith a <failure> tag in the xml produced.`,\r\n\t\tRun: func(cmd *cobra.Command, args []string) {\r\n\t\t\trun(flags, cmd, args)\r\n\t\t},\r\n\t}\r\n\tcmd.Flags().StringVarP(&flags.outputFile, \"output\", \"o\", \"-\", \"output file\")\r\n\tcmd.Flags().Float32VarP(&flags.threshold, \"threshold\", \"t\", .8, \"code coverage threshold\")\r\n\treturn cmd\r\n}","code-length":244,"reference":"\/\/ MakeCommand returns a `junit` command.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc warnDeprecated(last *time.Time, freq time.Duration, msg string) {\r\n\t\r\n\twarnLock.RLock()\r\n\tfresh := time.Now().Sub(*last) <= freq\r\n\twarnLock.RUnlock()\r\n\tif fresh {\r\n\t\treturn\r\n\t}\r\n\t\r\n\twarnLock.Lock()\r\n\tdefer warnLock.Unlock()\r\n\tnow := time.Now()\r\n\tif now.Sub(*last) <= freq {\r\n\t\treturn\r\n\t}\r\n\t*last = now\r\n\tlogrus.Warn(msg)\r\n}","code-length":151,"reference":"\/\/ warnDeprecated prints a deprecation warning for a particular configuration\n\/\/ option.","result":"Warn deprecated functions.","score":[0,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r RequireMatchingLabel) Describe() string {\r\n\tstr := &strings.Builder{}\r\n\tfmt.Fprintf(str, \"Applies the '%s' label \", r.MissingLabel)\r\n\tif r.MissingComment == \"\" {\r\n\t\tfmt.Fprint(str, \"to \")\r\n\t} else {\r\n\t\tfmt.Fprint(str, \"and comments on \")\r\n\t}\r\n\tif r.Issues {\r\n\t\tfmt.Fprint(str, \"Issues \")\r\n\t\tif r.PRs {\r\n\t\t\tfmt.Fprint(str, \"and \")\r\n\t\t}\r\n\t}\r\n\tif r.PRs {\r\n\t\tif r.Branch != \"\" {\r\n\t\t\tfmt.Fprintf(str, \"'%s' branch \", r.Branch)\r\n\t\t}\r\n\t\tfmt.Fprint(str, \"PRs \")\r\n\t}\r\n\tif r.Repo == \"\" {\r\n\t\tfmt.Fprintf(str, \"in the '%s' GitHub org \", r.Org)\r\n\t} else {\r\n\t\tfmt.Fprintf(str, \"in the '%s\/%s' GitHub repo \", r.Org, r.Repo)\r\n\t}\r\n\tfmt.Fprintf(str, \"that have no labels matching the regular expression '%s'.\", r.Regexp)\r\n\treturn str.String()\r\n}","code-length":335,"reference":"\/\/ Describe generates a human readable description of the behavior that this\n\/\/ configuration specifies.","result":"Describe the required label.","score":[0.0243,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Configuration) TriggerFor(org, repo string) Trigger {\r\n\tfor _, tr := range c.Triggers {\r\n\t\tfor _, r := range tr.Repos {\r\n\t\t\tif r == org || r == fmt.Sprintf(\"%s\/%s\", org, repo) {\r\n\t\t\t\treturn tr\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn Trigger{}\r\n}","code-length":106,"reference":"\/\/ TriggerFor finds the Trigger for a repo, if one exists\n\/\/ a trigger can be listed for the repo itself or for the\n\/\/ owning organization","result":"Generate the code.","score":[0.0001,0.0203]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Configuration) EnabledReposForPlugin(plugin string) (orgs, repos []string) {\r\n\tfor repo, plugins := range c.Plugins {\r\n\t\tfound := false\r\n\t\tfor _, candidate := range plugins {\r\n\t\t\tif candidate == plugin {\r\n\t\t\t\tfound = true\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif found {\r\n\t\t\tif strings.Contains(repo, \"\/\") {\r\n\t\t\t\trepos = append(repos, repo)\r\n\t\t\t} else {\r\n\t\t\t\torgs = append(orgs, repo)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn\r\n}","code-length":170,"reference":"\/\/ EnabledReposForPlugin returns the orgs and repos that have enabled the passed plugin.","result":"Find enabled repos for a.","score":[0.0577,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Configuration) EnabledReposForExternalPlugin(plugin string) (orgs, repos []string) {\r\n\tfor repo, plugins := range c.ExternalPlugins {\r\n\t\tfound := false\r\n\t\tfor _, candidate := range plugins {\r\n\t\t\tif candidate.Name == plugin {\r\n\t\t\t\tfound = true\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif found {\r\n\t\t\tif strings.Contains(repo, \"\/\") {\r\n\t\t\t\trepos = append(repos, repo)\r\n\t\t\t} else {\r\n\t\t\t\torgs = append(orgs, repo)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn\r\n}","code-length":174,"reference":"\/\/ EnabledReposForExternalPlugin returns the orgs and repos that have enabled the passed\n\/\/ external plugin.","result":"Determine the enabled repos for.","score":[0.0428,0.1071]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ConfigUpdater) SetDefaults() {\r\n\tif len(c.Maps) == 0 {\r\n\t\tcf := c.ConfigFile\r\n\t\tif cf == \"\" {\r\n\t\t\tcf = \"prow\/config.yaml\"\r\n\t\t} else {\r\n\t\t\tlogrus.Warnf(`config_file is deprecated, please switch to \"maps\": {\"%s\": \"config\"} before July 2018`, cf)\r\n\t\t}\r\n\t\tpf := c.PluginFile\r\n\t\tif pf == \"\" {\r\n\t\t\tpf = \"prow\/plugins.yaml\"\r\n\t\t} else {\r\n\t\t\tlogrus.Warnf(`plugin_file is deprecated, please switch to \"maps\": {\"%s\": \"plugins\"} before July 2018`, pf)\r\n\t\t}\r\n\t\tc.Maps = map[string]ConfigMapSpec{\r\n\t\t\tcf: {\r\n\t\t\t\tName: \"config\",\r\n\t\t\t},\r\n\t\t\tpf: {\r\n\t\t\t\tName: \"plugins\",\r\n\t\t\t},\r\n\t\t}\r\n\t}\r\n\tfor name, spec := range c.Maps {\r\n\t\tspec.Namespaces = append([]string{spec.Namespace}, spec.AdditionalNamespaces...)\r\n\t\tc.Maps[name] = spec\r\n\t}\r\n}","code-length":320,"reference":"\/\/ SetDefaults sets default options for config updating","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc validatePlugins(plugins map[string][]string) error {\r\n\tvar errors []string\r\n\tfor _, configuration := range plugins {\r\n\t\tfor _, plugin := range configuration {\r\n\t\t\tif _, ok := pluginHelp[plugin]; !ok {\r\n\t\t\t\terrors = append(errors, fmt.Sprintf(\"unknown plugin: %s\", plugin))\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tfor repo, repoConfig := range plugins {\r\n\t\tif strings.Contains(repo, \"\/\") {\r\n\t\t\torg := strings.Split(repo, \"\/\")[0]\r\n\t\t\tif dupes := findDuplicatedPluginConfig(repoConfig, plugins[org]); len(dupes) > 0 {\r\n\t\t\t\terrors = append(errors, fmt.Sprintf(\"plugins %v are duplicated for %s and %s\", dupes, repo, org))\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif len(errors) > 0 {\r\n\t\treturn fmt.Errorf(\"invalid plugin configuration:\\n\\t%v\", strings.Join(errors, \"\\n\\t\"))\r\n\t}\r\n\treturn nil\r\n}","code-length":280,"reference":"\/\/ validatePlugins will return error if\n\/\/ there are unknown or duplicated plugins.","result":"Validate plugins configuration.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) ShouldReport(pj *v1.ProwJob) bool {\r\n\tif pj.Status.State == v1.TriggeredState || pj.Status.State == v1.PendingState {\r\n\t\t\r\n\t\tlogrus.WithField(\"prowjob\", pj.ObjectMeta.Name).Info(\"PJ not finished\")\r\n\t\treturn false\r\n\t}\r\n\tif pj.Status.State == v1.AbortedState {\r\n\t\t\r\n\t\tlogrus.WithField(\"prowjob\", pj.ObjectMeta.Name).Info(\"PJ aborted\")\r\n\t\treturn false\r\n\t}\r\n\t\r\n\tif pj.ObjectMeta.Annotations[client.GerritID] == \"\" ||\r\n\t\tpj.ObjectMeta.Annotations[client.GerritInstance] == \"\" ||\r\n\t\tpj.ObjectMeta.Labels[client.GerritRevision] == \"\" {\r\n\t\tlogrus.WithField(\"prowjob\", pj.ObjectMeta.Name).Info(\"Not a gerrit job\")\r\n\t\treturn false\r\n\t}\r\n\t\r\n\tselector := labels.Set{\r\n\t\tclient.GerritRevision: pj.ObjectMeta.Labels[client.GerritRevision],\r\n\t\tkube.ProwJobTypeLabel: pj.ObjectMeta.Labels[kube.ProwJobTypeLabel],\r\n\t}\r\n\tif pj.ObjectMeta.Labels[client.GerritReportLabel] == \"\" {\r\n\t\t\r\n\t\tlogrus.Errorf(\"Gerrit report label not set for job %s\", pj.Spec.Job)\r\n\t} else {\r\n\t\tselector[client.GerritReportLabel] = pj.ObjectMeta.Labels[client.GerritReportLabel]\r\n\t}\r\n\tpjs, err := c.lister.List(selector.AsSelector())\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Errorf(\"Cannot list prowjob with selector %v\", selector)\r\n\t\treturn false\r\n\t}\r\n\tfor _, pjob := range pjs {\r\n\t\tif pjob.Status.State == v1.TriggeredState || pjob.Status.State == v1.PendingState {\r\n\t\t\t\r\n\t\t\tlogrus.WithField(\"prowjob\", pjob.ObjectMeta.Name).Info(\"Other jobs with same label are still running on this revision\")\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":598,"reference":"\/\/ ShouldReport returns if this prowjob should be reported by the gerrit reporter","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Run(refs prowapi.Refs, dir, gitUserName, gitUserEmail, cookiePath string, env []string) Record {\r\n\tlogrus.WithFields(logrus.Fields{\"refs\": refs}).Info(\"Cloning refs\")\r\n\trecord := Record{Refs: refs}\r\n\t\r\n\t\r\n\trunCommands := func(commands []cloneCommand) error {\r\n\t\tfor _, command := range commands {\r\n\t\t\tformattedCommand, output, err := command.run()\r\n\t\t\tlogrus.WithFields(logrus.Fields{\"command\": formattedCommand, \"output\": output, \"error\": err}).Info(\"Ran command\")\r\n\t\t\tmessage := \"\"\r\n\t\t\tif err != nil {\r\n\t\t\t\tmessage = err.Error()\r\n\t\t\t\trecord.Failed = true\r\n\t\t\t}\r\n\t\t\trecord.Commands = append(record.Commands, Command{Command: formattedCommand, Output: output, Error: message})\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\tg := gitCtxForRefs(refs, dir, env)\r\n\tif err := runCommands(g.commandsForBaseRef(refs, gitUserName, gitUserEmail, cookiePath)); err != nil {\r\n\t\treturn record\r\n\t}\r\n\ttimestamp, err := g.gitHeadTimestamp()\r\n\tif err != nil {\r\n\t\ttimestamp = int(time.Now().Unix())\r\n\t}\r\n\tif err := runCommands(g.commandsForPullRefs(refs, timestamp)); err != nil {\r\n\t\treturn record\r\n\t}\r\n\tfinalSHA, err := g.gitRevParse()\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Warnf(\"Cannot resolve finalSHA for ref %#v\", refs)\r\n\t} else {\r\n\t\trecord.FinalSHA = finalSHA\r\n\t}\r\n\treturn record\r\n}","code-length":471,"reference":"\/\/ Run clones the refs under the prescribed directory and optionally\n\/\/ configures the git username and email in the repository as well.","result":"Run a git command.","score":[0.0033,0.0474]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PathForRefs(baseDir string, refs prowapi.Refs) string {\r\n\tvar clonePath string\r\n\tif refs.PathAlias != \"\" {\r\n\t\tclonePath = refs.PathAlias\r\n\t} else {\r\n\t\tclonePath = fmt.Sprintf(\"github.com\/%s\/%s\", refs.Org, refs.Repo)\r\n\t}\r\n\treturn fmt.Sprintf(\"%s\/src\/%s\", baseDir, clonePath)\r\n}","code-length":117,"reference":"\/\/ PathForRefs determines the full path to where\n\/\/ refs should be cloned","result":"Generate the path for the refs.","score":[0.0715,0.0813]}
{"code":"\/*is used to<extra_id_0>\r\nfunc gitCtxForRefs(refs prowapi.Refs, baseDir string, env []string) gitCtx {\r\n\tg := gitCtx{\r\n\t\tcloneDir:      PathForRefs(baseDir, refs),\r\n\t\tenv:           env,\r\n\t\trepositoryURI: fmt.Sprintf(\"https:\r\n\t}\r\n\tif refs.CloneURI != \"\" {\r\n\t\tg.repositoryURI = refs.CloneURI\r\n\t}\r\n\treturn g\r\n}","code-length":120,"reference":"\/\/ gitCtxForRefs creates a gitCtx based on the provide refs and baseDir.","result":"Create a new git context.","score":[0.0593,0.1659]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *gitCtx) commandsForBaseRef(refs prowapi.Refs, gitUserName, gitUserEmail, cookiePath string) []cloneCommand {\r\n\tcommands := []cloneCommand{{dir: \"\/\", env: g.env, command: \"mkdir\", args: []string{\"-p\", g.cloneDir}}}\r\n\tcommands = append(commands, g.gitCommand(\"init\"))\r\n\tif gitUserName != \"\" {\r\n\t\tcommands = append(commands, g.gitCommand(\"config\", \"user.name\", gitUserName))\r\n\t}\r\n\tif gitUserEmail != \"\" {\r\n\t\tcommands = append(commands, g.gitCommand(\"config\", \"user.email\", gitUserEmail))\r\n\t}\r\n\tif cookiePath != \"\" {\r\n\t\tcommands = append(commands, g.gitCommand(\"config\", \"http.cookiefile\", cookiePath))\r\n\t}\r\n\tcommands = append(commands, g.gitCommand(\"fetch\", g.repositoryURI, \"--tags\", \"--prune\"))\r\n\tcommands = append(commands, g.gitCommand(\"fetch\", g.repositoryURI, refs.BaseRef))\r\n\tvar target string\r\n\tif refs.BaseSHA != \"\" {\r\n\t\ttarget = refs.BaseSHA\r\n\t} else {\r\n\t\ttarget = \"FETCH_HEAD\"\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tcommands = append(commands, g.gitCommand(\"checkout\", target))\r\n\tcommands = append(commands, g.gitCommand(\"branch\", \"--force\", refs.BaseRef, target))\r\n\tcommands = append(commands, g.gitCommand(\"checkout\", refs.BaseRef))\r\n\treturn commands\r\n}","code-length":408,"reference":"\/\/ commandsForBaseRef returns the list of commands needed to initialize and\n\/\/ configure a local git directory, as well as fetch and check out the provided\n\/\/ base ref.","result":"Create a new git repository.","score":[0.0024,0.0376]}
{"code":"\/*is used to<extra_id_0>\r\nfunc gitTimestampEnvs(timestamp int) []string {\r\n\treturn []string{\r\n\t\tfmt.Sprintf(\"GIT_AUTHOR_DATE=%d\", timestamp),\r\n\t\tfmt.Sprintf(\"GIT_COMMITTER_DATE=%d\", timestamp),\r\n\t}\r\n}","code-length":77,"reference":"\/\/ gitTimestampEnvs returns the list of environment variables needed to override\n\/\/ git's author and commit timestamps when creating new commits.","result":"Set git timestamp env vars.","score":[0,0.0258]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *gitCtx) gitRevParse() (string, error) {\r\n\tgitRevParseCommand := g.gitCommand(\"rev-parse\", \"HEAD\")\r\n\t_, commit, err := gitRevParseCommand.run()\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Error(\"git rev-parse HEAD failed!\")\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn strings.TrimSpace(commit), nil\r\n}","code-length":117,"reference":"\/\/ gitRevParse returns current commit from HEAD in a git tree","result":"Get the current commit.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *gitCtx) commandsForPullRefs(refs prowapi.Refs, fakeTimestamp int) []cloneCommand {\r\n\tvar commands []cloneCommand\r\n\tfor _, prRef := range refs.Pulls {\r\n\t\tref := fmt.Sprintf(\"pull\/%d\/head\", prRef.Number)\r\n\t\tif prRef.Ref != \"\" {\r\n\t\t\tref = prRef.Ref\r\n\t\t}\r\n\t\tcommands = append(commands, g.gitCommand(\"fetch\", g.repositoryURI, ref))\r\n\t\tvar prCheckout string\r\n\t\tif prRef.SHA != \"\" {\r\n\t\t\tprCheckout = prRef.SHA\r\n\t\t} else {\r\n\t\t\tprCheckout = \"FETCH_HEAD\"\r\n\t\t}\r\n\t\tfakeTimestamp++\r\n\t\tgitMergeCommand := g.gitCommand(\"merge\", \"--no-ff\", prCheckout)\r\n\t\tgitMergeCommand.env = append(gitMergeCommand.env, gitTimestampEnvs(fakeTimestamp)...)\r\n\t\tcommands = append(commands, gitMergeCommand)\r\n\t}\r\n\t\r\n\tif !refs.SkipSubmodules {\r\n\t\tcommands = append(commands, g.gitCommand(\"submodule\", \"update\", \"--init\", \"--recursive\"))\r\n\t}\r\n\treturn commands\r\n}","code-length":316,"reference":"\/\/ commandsForPullRefs returns the list of commands needed to fetch and\n\/\/ merge any pull refs as well as submodules. These commands should be run only\n\/\/ after the commands provided by commandsForBaseRef have been run\n\/\/ successfully.\n\/\/ Each merge commit will be created at sequential seconds after fakeTimestamp.\n\/\/ It's recommended that fakeTimestamp be set to the timestamp of the base ref.\n\/\/ This enables reproducible timestamps and git tree digests every time the same\n\/\/ set of base and pull refs are used.","result":"Avoid the need for the following code.","score":[0.0,0.0256]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ProduceCovList(profiles []*cover.Profile) *CoverageList {\r\n\tcovList := newCoverageList(\"summary\")\r\n\tfor _, prof := range profiles {\r\n\t\tcovList.Group = append(covList.Group, summarizeBlocks(prof))\r\n\t}\r\n\treturn covList\r\n}","code-length":83,"reference":"\/\/ ProduceCovList summarizes profiles and returns the result","result":"Produce the coverage list.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc popRandom(set sets.String) string {\r\n\tlist := set.List()\r\n\tsort.Strings(list)\r\n\tsel := list[rand.Intn(len(list))]\r\n\tset.Delete(sel)\r\n\treturn sel\r\n}","code-length":72,"reference":"\/\/ popRandom randomly selects an element of 'set' and pops it.","result":"Pop a random string from a set.","score":[0,0.0472]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *ExperimentalKubernetesOptions) resolve(dryRun bool) (err error) {\r\n\tif o.resolved {\r\n\t\treturn nil\r\n\t}\r\n\to.dryRun = dryRun\r\n\tif dryRun {\r\n\t\treturn nil\r\n\t}\r\n\tclusterConfigs, err := kube.LoadClusterConfigs(o.kubeconfig, o.buildCluster)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"load --kubeconfig=%q --build-cluster=%q configs: %v\", o.kubeconfig, o.buildCluster, err)\r\n\t}\r\n\tclients := map[string]kubernetes.Interface{}\r\n\tfor context, config := range clusterConfigs {\r\n\t\tclient, err := kubernetes.NewForConfig(&config)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"create %s kubernetes client: %v\", context, err)\r\n\t\t}\r\n\t\tclients[context] = client\r\n\t}\r\n\tlocalCfg := clusterConfigs[kube.InClusterContext]\r\n\tpjClient, err := prow.NewForConfig(&localCfg)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\to.prowJobClientset = pjClient\r\n\to.kubernetesClientsByContext = clients\r\n\to.resolved = true\r\n\treturn nil\r\n}","code-length":334,"reference":"\/\/ resolve loads all of the clients we need and caches them for future calls.","result":"Resolve the kubernetes client.","score":[0.0204,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *ExperimentalKubernetesOptions) ProwJobClientset(namespace string, dryRun bool) (prowJobClientset prow.Interface, err error) {\r\n\tif err := o.resolve(dryRun); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif o.dryRun {\r\n\t\treturn nil, errors.New(\"no dry-run prowjob clientset is supported in dry-run mode\")\r\n\t}\r\n\treturn o.prowJobClientset, nil\r\n}","code-length":132,"reference":"\/\/ ProwJobClientset returns a ProwJob clientset for use in informer factories.","result":"Create prowjob client.","score":[0,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *ExperimentalKubernetesOptions) ProwJobClient(namespace string, dryRun bool) (prowJobClient prowv1.ProwJobInterface, err error) {\r\n\tif err := o.resolve(dryRun); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif o.dryRun {\r\n\t\treturn kube.NewDryRunProwJobClient(o.DeckURI), nil\r\n\t}\r\n\treturn o.prowJobClientset.ProwV1().ProwJobs(namespace), nil\r\n}","code-length":138,"reference":"\/\/ ProwJobClient returns a ProwJob client.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *ExperimentalKubernetesOptions) InfrastructureClusterClient(dryRun bool) (kubernetesClient kubernetes.Interface, err error) {\r\n\tif err := o.resolve(dryRun); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif o.dryRun {\r\n\t\treturn nil, errors.New(\"no dry-run kubernetes client is supported in dry-run mode\")\r\n\t}\r\n\treturn o.kubernetesClientsByContext[kube.InClusterContext], nil\r\n}","code-length":130,"reference":"\/\/ InfrastructureClusterClient returns a Kubernetes client for the infrastructure cluster.","result":"Generate code for generated code.","score":[0.0884,0.0526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *ExperimentalKubernetesOptions) BuildClusterClients(namespace string, dryRun bool) (buildClusterClients map[string]corev1.PodInterface, err error) {\r\n\tif err := o.resolve(dryRun); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif o.dryRun {\r\n\t\treturn nil, errors.New(\"no dry-run pod client is supported for build clusters in dry-run mode\")\r\n\t}\r\n\tbuildClients := map[string]corev1.PodInterface{}\r\n\tfor context, client := range o.kubernetesClientsByContext {\r\n\t\tbuildClients[context] = client.CoreV1().Pods(namespace)\r\n\t}\r\n\treturn buildClients, nil\r\n}","code-length":187,"reference":"\/\/ BuildClusterClients returns Pod clients for build clusters.","result":"Build the cluster client for the cluster.","score":[0.14,0.3235]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *ActiveState) Age(t time.Time) time.Duration {\r\n\treturn t.Sub(a.startTime)\r\n}","code-length":44,"reference":"\/\/ Age gives the time since the state has been activated.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *ActiveState) ReceiveEvent(eventName, label string, t time.Time) (State, bool) {\r\n\tif a.exit.Match(eventName, label) {\r\n\t\treturn &InactiveState{\r\n\t\t\tentry: a.exit.Opposite(),\r\n\t\t}, true\r\n\t}\r\n\treturn a, false\r\n}","code-length":94,"reference":"\/\/ ReceiveEvent checks if the event matches the exit criteria.\n\/\/ Returns a new InactiveState or self, and true if it changed.","result":"Receive events from the active state.","score":[0.0134,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InactiveState) ReceiveEvent(eventName, label string, t time.Time) (State, bool) {\r\n\tif i.entry.Match(eventName, label) {\r\n\t\treturn &ActiveState{\r\n\t\t\tstartTime: t,\r\n\t\t\texit:      i.entry.Opposite(),\r\n\t\t}, true\r\n\t}\r\n\treturn i, false\r\n}","code-length":104,"reference":"\/\/ ReceiveEvent checks if the event matches the entry criteria\n\/\/ Returns a new ActiveState or self, and true if it changed.","result":"Receive events from an inactive state.","score":[0,0.0245]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *MultiState) Active() bool {\r\n\tfor _, state := range m.states {\r\n\t\tif !state.Active() {\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":67,"reference":"\/\/ Active is true if all the states are active.","result":"Check if the state is active.","score":[0.1402,0.3875]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *MultiState) Age(t time.Time) time.Duration {\r\n\tminAge := time.Duration(1<<63 - 1)\r\n\tfor _, state := range m.states {\r\n\t\tstateAge := state.Age(t)\r\n\t\tif stateAge < minAge {\r\n\t\t\tminAge = stateAge\r\n\t\t}\r\n\t}\r\n\treturn minAge\r\n}","code-length":108,"reference":"\/\/ Age returns the time since all states have been activated.\n\/\/ It will panic if any of the state is not active.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *MultiState) ReceiveEvent(eventName, label string, t time.Time) (State, bool) {\r\n\toneChanged := false\r\n\tfor i := range m.states {\r\n\t\tstate, changed := m.states[i].ReceiveEvent(eventName, label, t)\r\n\t\tif changed {\r\n\t\t\toneChanged = true\r\n\t\t}\r\n\t\tm.states[i] = state\r\n\t}\r\n\treturn m, oneChanged\r\n}","code-length":125,"reference":"\/\/ ReceiveEvent will send the event to each individual state, and update\n\/\/ them if they change.","result":"Receive events from multiple states.","score":[0,0.0316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v *version) ProwJobs() ProwJobInformer {\r\n\treturn &prowJobInformer{factory: v.factory, namespace: v.namespace, tweakListOptions: v.tweakListOptions}\r\n}","code-length":58,"reference":"\/\/ ProwJobs returns a ProwJobInformer.","result":"Test the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ItemToResourcesConfig(i Item) (ResourcesConfig, error) {\r\n\tconf, ok := i.(ResourcesConfig)\r\n\tif !ok {\r\n\t\treturn ResourcesConfig{}, fmt.Errorf(\"cannot construct Resource from received object %v\", i)\r\n\t}\r\n\treturn conf, nil\r\n}","code-length":83,"reference":"\/\/ ItemToResourcesConfig casts an Item object to a ResourcesConfig","result":"Convert the item to a resource config.","score":[0.1716,0.2904]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t TypeToResources) Copy() TypeToResources {\r\n\tn := TypeToResources{}\r\n\tfor k, v := range t {\r\n\t\tn[k] = v\r\n\t}\r\n\treturn n\r\n}","code-length":64,"reference":"\/\/ Copy returns a copy of the TypeToResources","result":"Copy the typeToResources.","score":[0.0917,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MakeCommand() *cobra.Command {\r\n\tflags := &flags{}\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"aggregate [files...]\",\r\n\t\tShort: \"Aggregates multiple Go coverage files.\",\r\n\t\tLong: `Given multiple Go coverage files from identical binaries recorded in\r\n\"count\" or \"atomic\" mode, produces a new Go coverage file in the same mode\r\nthat counts how many of those coverage profiles hit a block at least once.`,\r\n\t\tRun: func(cmd *cobra.Command, args []string) {\r\n\t\t\trun(flags, cmd, args)\r\n\t\t},\r\n\t}\r\n\tcmd.Flags().StringVarP(&flags.OutputFile, \"output\", \"o\", \"-\", \"output file\")\r\n\treturn cmd\r\n}","code-length":204,"reference":"\/\/ MakeCommand returns an `aggregate` command.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) incrementNumPendingJobs(job string) {\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tc.pendingJobs[job]++\r\n}","code-length":57,"reference":"\/\/ incrementNumPendingJobs increments the amount of\n\/\/ pending ProwJobs for the given job identifier","result":"Increment the number of pending.","score":[0.0472,0.2409]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) setPreviousReportState(pj prowapi.ProwJob) error {\r\n\t\r\n\tlatestPJ, err := c.kc.GetProwJob(pj.ObjectMeta.Name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif latestPJ.Status.PrevReportStates == nil {\r\n\t\tlatestPJ.Status.PrevReportStates = map[string]prowapi.ProwJobState{}\r\n\t}\r\n\tlatestPJ.Status.PrevReportStates[reporter.GitHubReporterName] = latestPJ.Status.State\r\n\t_, err = c.kc.ReplaceProwJob(latestPJ.ObjectMeta.Name, latestPJ)\r\n\treturn err\r\n}","code-length":193,"reference":"\/\/ setPreviousReportState sets the github key for PrevReportStates\n\/\/ to current state. This is a work-around for plank -> crier\n\/\/ migration to become seamless.","result":"Set the previous report state.","score":[0.0052,0.1111]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) SyncMetrics() {\r\n\tc.pjLock.RLock()\r\n\tdefer c.pjLock.RUnlock()\r\n\tkube.GatherProwJobMetrics(c.pjs)\r\n}","code-length":64,"reference":"\/\/ SyncMetrics records metrics for the cached prowjobs.","result":"Sync metrics.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DumpProfile(profiles []*cover.Profile, writer io.Writer) error {\r\n\tif len(profiles) == 0 {\r\n\t\treturn errors.New(\"can't write an empty profile\")\r\n\t}\r\n\tif _, err := io.WriteString(writer, \"mode: \"+profiles[0].Mode+\"\\n\"); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfor _, profile := range profiles {\r\n\t\tfor _, block := range profile.Blocks {\r\n\t\t\tif _, err := fmt.Fprintf(writer, \"%s:%d.%d,%d.%d %d %d\\n\", profile.FileName, block.StartLine, block.StartCol, block.EndLine, block.EndCol, block.NumStmt, block.Count); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":223,"reference":"\/\/ DumpProfile dumps the profiles given to writer in go coverage format.","result":"Dump the profile to a file.","score":[0.0845,0.3289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc blocksEqual(a cover.ProfileBlock, b cover.ProfileBlock) bool {\r\n\treturn a.StartCol == b.StartCol && a.StartLine == b.StartLine &&\r\n\t\ta.EndCol == b.EndCol && a.EndLine == b.EndLine && a.NumStmt == b.NumStmt\r\n}","code-length":87,"reference":"\/\/ blocksEqual returns true if the blocks refer to the same code, otherwise false.\n\/\/ It does not care about Count.","result":"Compare profile blocks.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewProwJobInformer(client versioned.Interface, namespace string, resyncPeriod time.Duration, indexers cache.Indexers) cache.SharedIndexInformer {\r\n\treturn NewFilteredProwJobInformer(client, namespace, resyncPeriod, indexers, nil)\r\n}","code-length":67,"reference":"\/\/ NewProwJobInformer constructs a new informer for ProwJob type.\n\/\/ Always prefer using an informer factory to get a shared informer instead of getting an independent\n\/\/ one. This reduces memory footprint and number of connections to the server.","result":"ResyncPeriod time.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFilteredProwJobInformer(client versioned.Interface, namespace string, resyncPeriod time.Duration, indexers cache.Indexers, tweakListOptions internalinterfaces.TweakListOptionsFunc) cache.SharedIndexInformer {\r\n\treturn cache.NewSharedIndexInformer(\r\n\t\t&cache.ListWatch{\r\n\t\t\tListFunc: func(options metav1.ListOptions) (runtime.Object, error) {\r\n\t\t\t\tif tweakListOptions != nil {\r\n\t\t\t\t\ttweakListOptions(&options)\r\n\t\t\t\t}\r\n\t\t\t\treturn client.ProwV1().ProwJobs(namespace).List(options)\r\n\t\t\t},\r\n\t\t\tWatchFunc: func(options metav1.ListOptions) (watch.Interface, error) {\r\n\t\t\t\tif tweakListOptions != nil {\r\n\t\t\t\t\ttweakListOptions(&options)\r\n\t\t\t\t}\r\n\t\t\t\treturn client.ProwV1().ProwJobs(namespace).Watch(options)\r\n\t\t\t},\r\n\t\t},\r\n\t\t&prowjobsv1.ProwJob{},\r\n\t\tresyncPeriod,\r\n\t\tindexers,\r\n\t)\r\n}","code-length":269,"reference":"\/\/ NewFilteredProwJobInformer constructs a new informer for ProwJob type.\n\/\/ Always prefer using an informer factory to get a shared informer instead of getting an independent\n\/\/ one. This reduces memory footprint and number of connections to the server.","result":"Test if the informer is used to test if the informer is not nil.","score":[0.0179,0.0685]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(ja *jobs.JobAgent, cfg config.Getter, c *storage.Client, ctx context.Context) *Spyglass {\r\n\treturn &Spyglass{\r\n\t\tJobAgent:              ja,\r\n\t\tconfig:                cfg,\r\n\t\tPodLogArtifactFetcher: NewPodLogArtifactFetcher(ja),\r\n\t\tGCSArtifactFetcher:    NewGCSArtifactFetcher(c),\r\n\t\ttestgrid: &TestGrid{\r\n\t\t\tconf:   cfg,\r\n\t\t\tclient: c,\r\n\t\t\tctx:    ctx,\r\n\t\t},\r\n\t}\r\n}","code-length":154,"reference":"\/\/ New constructs a Spyglass object from a JobAgent, a config.Agent, and a storage Client.","result":"Create the Spyglass.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Spyglass) Lenses(matchCache map[string][]string) []lenses.Lens {\r\n\tls := []lenses.Lens{}\r\n\tfor lensName, matches := range matchCache {\r\n\t\tif len(matches) == 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tlens, err := lenses.GetLens(lensName)\r\n\t\tif err != nil {\r\n\t\t\tlogrus.WithField(\"lensName\", lens).WithError(err).Error(\"Could not find artifact lens\")\r\n\t\t} else {\r\n\t\t\tls = append(ls, lens)\r\n\t\t}\r\n\t}\r\n\t\r\n\tsort.Slice(ls, func(i, j int) bool {\r\n\t\ticonf := ls[i].Config()\r\n\t\tjconf := ls[j].Config()\r\n\t\tiname := iconf.Name\r\n\t\tjname := jconf.Name\r\n\t\tpi := iconf.Priority\r\n\t\tpj := jconf.Priority\r\n\t\tif pi == pj {\r\n\t\t\treturn iname < jname\r\n\t\t}\r\n\t\treturn pi < pj\r\n\t})\r\n\treturn ls\r\n}","code-length":302,"reference":"\/\/ Lenses gets all views of all artifact files matching each regexp with a registered lens","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Spyglass) JobPath(src string) (string, error) {\r\n\tsrc = strings.TrimSuffix(src, \"\/\")\r\n\tkeyType, key, err := splitSrc(src)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error parsing src: %v\", src)\r\n\t}\r\n\tsplit := strings.Split(key, \"\/\")\r\n\tswitch keyType {\r\n\tcase gcsKeyType:\r\n\t\tif len(split) < 4 {\r\n\t\t\treturn \"\", fmt.Errorf(\"invalid key %s: expected <bucket-name>\/<log-type>\/...\/<job-name>\/<build-id>\", key)\r\n\t\t}\r\n\t\t split[len(split)-2]\r\n\t\tif logType == gcs.NonPRLogs {\r\n\t\t\treturn path.Dir(key), nil\r\n\t\t} else if logType == gcs.PRLogs {\r\n\t\t\treturn path.Join(bktName, gcs.PRLogs, \"directory\", jobName), nil\r\n\t\t}\r\n\t\treturn \"\", fmt.Errorf(\"unrecognized GCS key: %s\", key)\r\n\tcase prowKeyType:\r\n\t\tif len(split) < 2 {\r\n\t\t\treturn \"\", fmt.Errorf(\"invalid key %s: expected <job-name>\/<build-id>\", key)\r\n\t\t}\r\n\t\tjobName := split[0]\r\n\t\tbuildID := split[1]\r\n\t\tjob, err := s.jobAgent.GetProwJob(jobName, buildID)\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"failed to get prow job from src %q: %v\", key, err)\r\n\t\t}\r\n\t\tif job.Spec.DecorationConfig == nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"failed to locate GCS upload bucket for %s: job is undecorated\", jobName)\r\n\t\t}\r\n\t\tif job.Spec.DecorationConfig.GCSConfiguration == nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"failed to locate GCS upload bucket for %s: missing GCS configuration\", jobName)\r\n\t\t}\r\n\t\tbktName := job.Spec.DecorationConfig.GCSConfiguration.Bucket\r\n\t\tif job.Spec.Type == prowapi.PresubmitJob {\r\n\t\t\treturn path.Join(bktName, gcs.PRLogs, \"directory\", jobName), nil\r\n\t\t}\r\n\t\treturn path.Join(bktName, gcs.NonPRLogs, jobName), nil\r\n\tdefault:\r\n\t\treturn \"\", fmt.Errorf(\"unrecognized key type for src: %v\", src)\r\n\t}\r\n}","code-length":640,"reference":"\/\/ JobPath returns a link to the GCS directory for the job specified in src","result":"Code too long,keep in 512.","score":[0.0325,0.0357]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Spyglass) RunPath(src string) (string, error) {\r\n\tsrc = strings.TrimSuffix(src, \"\/\")\r\n\tkeyType, key, err := splitSrc(src)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error parsing src: %v\", src)\r\n\t}\r\n\tswitch keyType {\r\n\tcase gcsKeyType:\r\n\t\treturn key, nil\r\n\tcase prowKeyType:\r\n\t\treturn s.prowToGCS(key)\r\n\tdefault:\r\n\t\treturn \"\", fmt.Errorf(\"unrecognized key type for src: %v\", src)\r\n\t}\r\n}","code-length":168,"reference":"\/\/ RunPath returns the path to the GCS directory for the job run specified in src.","result":"Run the code .","score":[0.0159,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (sg *Spyglass) ExtraLinks(src string) ([]ExtraLink, error) {\r\n\tartifacts, err := sg.FetchArtifacts(src, \"\", 1000000, []string{\"started.json\"})\r\n\t\r\n\tif err != nil || len(artifacts) == 0 {\r\n\t\tlogrus.WithError(err).Debugf(\"Failed to find started.json while looking for extra links.\")\r\n\t\treturn nil, nil\r\n\t}\r\n\t\r\n\tcontent, err := artifacts[0].ReadAll()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tstarted := metadata.Started{}\r\n\tif err := json.Unmarshal(content, &started); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tlinks, ok := started.Metadata.Meta(\"links\")\r\n\tif !ok {\r\n\t\treturn nil, nil\r\n\t}\r\n\textraLinks := make([]ExtraLink, 0, len(*links))\r\n\tfor _, name := range links.Keys() {\r\n\t\tm, ok := links.Meta(name)\r\n\t\tif !ok {\r\n\t\t\t\r\n\t\t\tlogrus.Debugf(\"Got bad link key %q from %s, but that should be impossible.\", name, artifacts[0].CanonicalLink())\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\ts := m.Strings()\r\n\t\tlink := ExtraLink{\r\n\t\t\tName:        name,\r\n\t\t\tURL:         s[\"url\"],\r\n\t\t\tDescription: s[\"description\"],\r\n\t\t}\r\n\t\tif link.URL == \"\" || link.Name == \"\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\textraLinks = append(extraLinks, link)\r\n\t}\r\n\treturn extraLinks, nil\r\n}","code-length":444,"reference":"\/\/ ExtraLinks fetches started.json and extracts links from metadata.links.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Server) needDemux(eventType, srcRepo string) []plugins.ExternalPlugin {\r\n\tvar matching []plugins.ExternalPlugin\r\n\tsrcOrg := strings.Split(srcRepo, \"\/\")[0]\r\n\tfor repo, plugins := range s.Plugins.Config().ExternalPlugins {\r\n\t\t\r\n\t\tif repo != srcRepo && repo != srcOrg {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tfor _, p := range plugins {\r\n\t\t\tif len(p.Events) == 0 {\r\n\t\t\t\tmatching = append(matching, p)\r\n\t\t\t} else {\r\n\t\t\t\tfor _, et := range p.Events {\r\n\t\t\t\t\tif et != eventType {\r\n\t\t\t\t\t\tcontinue\r\n\t\t\t\t\t}\r\n\t\t\t\t\tmatching = append(matching, p)\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn matching\r\n}","code-length":230,"reference":"\/\/ needDemux returns whether there are any external plugins that need to\n\/\/ get the present event.","result":"Generate the generated code.","score":[0.0124,0.0318]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Server) demuxExternal(l *logrus.Entry, externalPlugins []plugins.ExternalPlugin, payload []byte, h http.Header) {\r\n\th.Set(\"User-Agent\", \"ProwHook\")\r\n\tfor _, p := range externalPlugins {\r\n\t\ts.wg.Add(1)\r\n\t\tgo func(p plugins.ExternalPlugin) {\r\n\t\t\tdefer s.wg.Done()\r\n\t\t\tif err := s.dispatch(p.Endpoint, payload, h); err != nil {\r\n\t\t\t\tl.WithError(err).WithField(\"external-plugin\", p.Name).Error(\"Error dispatching event to external plugin.\")\r\n\t\t\t} else {\r\n\t\t\t\tl.WithField(\"external-plugin\", p.Name).Info(\"Dispatched event to external plugin\")\r\n\t\t\t}\r\n\t\t}(p)\r\n\t}\r\n}","code-length":217,"reference":"\/\/ demuxExternal dispatches the provided payload to the external plugins.","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Server) dispatch(endpoint string, payload []byte, h http.Header) error {\r\n\treq, err := http.NewRequest(http.MethodPost, endpoint, bytes.NewBuffer(payload))\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treq.Header = h\r\n\tresp, err := s.do(req)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\trb, err := ioutil.ReadAll(resp.Body)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif resp.StatusCode < 200 || resp.StatusCode > 299 {\r\n\t\treturn fmt.Errorf(\"response has status %q and body %q\", resp.Status, string(rb))\r\n\t}\r\n\treturn nil\r\n}","code-length":213,"reference":"\/\/ dispatch creates a new request using the provided payload and headers\n\/\/ and dispatches the request to the provided endpoint.","result":"Dispatch requests to the endpoint.","score":[0.0153,0.2299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *StatePlugin) AddFlags(cmd *cobra.Command) {\r\n\tcmd.Flags().StringVar(&s.desc, \"state\", \"\", \"Description of the state (eg: `opened,!merged,labeled:cool`)\")\r\n\tcmd.Flags().IntSliceVar(&s.percentiles, \"percentiles\", []int{}, \"Age percentiles for state\")\r\n}","code-length":104,"reference":"\/\/ AddFlags adds \"state\" and \"percentiles\" to the command help","result":"Generate the state description.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *StatePlugin) CheckFlags() error {\r\n\ts.states = NewBundledStates(s.desc)\r\n\treturn nil\r\n}","code-length":45,"reference":"\/\/ CheckFlags configures which states to monitor","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *StatePlugin) ReceiveIssueEvent(event sql.IssueEvent) []Point {\r\n\tlabel := \"\"\r\n\tif event.Label != nil {\r\n\t\tlabel = *event.Label\r\n\t}\r\n\tif !s.states.ReceiveEvent(event.IssueID, event.Event, label, event.EventCreatedAt) {\r\n\t\treturn nil\r\n\t}\r\n\ttotal, sum := s.states.Total(event.EventCreatedAt)\r\n\tvalues := map[string]interface{}{\r\n\t\t\"count\": total,\r\n\t\t\"sum\":   int(sum),\r\n\t}\r\n\tfor _, percentile := range s.percentiles {\r\n\t\tvalues[fmt.Sprintf(\"%d%%\", percentile)] = int(s.states.Percentile(event.EventCreatedAt, percentile))\r\n\t}\r\n\treturn []Point{\r\n\t\t{\r\n\t\t\tValues: values,\r\n\t\t\tDate:   event.EventCreatedAt,\r\n\t\t},\r\n\t}\r\n}","code-length":248,"reference":"\/\/ ReceiveIssueEvent computes age percentiles and saves them to InfluxDB","result":"Receive issue events .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Load(prowConfig, jobConfig string) (c *Config, err error) {\r\n\t\r\n\tdefer func() {\r\n\t\tif r := recover(); r != nil {\r\n\t\t\tc, err = nil, fmt.Errorf(\"panic loading config: %v\", r)\r\n\t\t}\r\n\t}()\r\n\tc, err = loadConfig(prowConfig, jobConfig)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err := c.finalizeJobConfig(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err := c.validateComponentConfig(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err := c.validateJobConfig(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn c, nil\r\n}","code-length":216,"reference":"\/\/ Load loads and parses the config at path.","result":"Load the config file .","score":[0.169,0.2972]}
{"code":"\/*is used to<extra_id_0>\r\nfunc loadConfig(prowConfig, jobConfig string) (*Config, error) {\r\n\tstat, err := os.Stat(prowConfig)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif stat.IsDir() {\r\n\t\treturn nil, fmt.Errorf(\"prowConfig cannot be a dir - %s\", prowConfig)\r\n\t}\r\n\tvar nc Config\r\n\tif err := yamlToConfig(prowConfig, &nc); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err := parseProwConfig(&nc); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\t\r\n\tif jobConfig == \"\" {\r\n\t\treturn &nc, nil\r\n\t}\r\n\tstat, err = os.Stat(jobConfig)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif !stat.IsDir() {\r\n\t\t\r\n\t\tvar jc JobConfig\r\n\t\tif err := yamlToConfig(jobConfig, &jc); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tif err := nc.mergeJobConfig(jc); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn &nc, nil\r\n\t}\r\n\t\r\n\t\r\n\tuniqueBasenames := sets.String{}\r\n\terr = filepath.Walk(jobConfig, func(path string, info os.FileInfo, err error) error {\r\n\t\tif err != nil {\r\n\t\t\tlogrus.WithError(err).Errorf(\"walking path %q.\", path)\r\n\t\t\t\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tif strings.HasPrefix(info.Name(), \"..\") {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tif info.IsDir() {\r\n\t\t\t\treturn filepath.SkipDir\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tif filepath.Ext(path) != \".yaml\" && filepath.Ext(path) != \".yml\" {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tif info.IsDir() {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tbase := filepath.Base(path)\r\n\t\tif uniqueBasenames.Has(base) {\r\n\t\t\treturn fmt.Errorf(\"duplicated basename is not allowed: %s\", base)\r\n\t\t}\r\n\t\tuniqueBasenames.Insert(base)\r\n\t\tvar subConfig JobConfig\r\n\t\tif err := yamlToConfig(path, &subConfig); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn nc.mergeJobConfig(subConfig)\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &nc, nil\r\n}","code-length":699,"reference":"\/\/ loadConfig loads one or multiple config files and returns a config object.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc yamlToConfig(path string, nc interface{}) error {\r\n\tb, err := ReadFileMaybeGZIP(path)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"error reading %s: %v\", path, err)\r\n\t}\r\n\tif err := yaml.Unmarshal(b, nc); err != nil {\r\n\t\treturn fmt.Errorf(\"error unmarshaling %s: %v\", path, err)\r\n\t}\r\n\tvar jc *JobConfig\r\n\tswitch v := nc.(type) {\r\n\tcase *JobConfig:\r\n\t\tjc = v\r\n\tcase *Config:\r\n\t\tjc = &v.JobConfig\r\n\t}\r\n\tfor rep := range jc.Presubmits {\r\n\t\tvar fix func(*Presubmit)\r\n\t\tfix = func(job *Presubmit) {\r\n\t\t\tjob.SourcePath = path\r\n\t\t}\r\n\t\tfor i := range jc.Presubmits[rep] {\r\n\t\t\tfix(&jc.Presubmits[rep][i])\r\n\t\t}\r\n\t}\r\n\tfor rep := range jc.Postsubmits {\r\n\t\tvar fix func(*Postsubmit)\r\n\t\tfix = func(job *Postsubmit) {\r\n\t\t\tjob.SourcePath = path\r\n\t\t}\r\n\t\tfor i := range jc.Postsubmits[rep] {\r\n\t\t\tfix(&jc.Postsubmits[rep][i])\r\n\t\t}\r\n\t}\r\n\tvar fix func(*Periodic)\r\n\tfix = func(job *Periodic) {\r\n\t\tjob.SourcePath = path\r\n\t}\r\n\tfor i := range jc.Periodics {\r\n\t\tfix(&jc.Periodics[i])\r\n\t}\r\n\treturn nil\r\n}","code-length":443,"reference":"\/\/ yamlToConfig converts a yaml file into a Config object","result":"Convert yaml to config.","score":[0.0713,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReadFileMaybeGZIP(path string) ([]byte, error) {\r\n\tb, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tyte(\"\\x1F\\x8B\")) {\r\n\t\t\r\n\t\treturn b, nil\r\n\t}\r\n\t\r\n\tgzipReader, err := gzip.NewReader(bytes.NewBuffer(b))\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn ioutil.ReadAll(gzipReader)\r\n}","code-length":147,"reference":"\/\/ ReadFileMaybeGZIP wraps ioutil.ReadFile, returning the decompressed contents\n\/\/ if the file is gzipped, or otherwise the raw contents","result":"Read a file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) finalizeJobConfig() error {\r\n\tif c.decorationRequested() {\r\n\t\tif c.Plank.DefaultDecorationConfig == nil {\r\n\t\t\treturn errors.New(\"no default decoration config provided for plank\")\r\n\t\t}\r\n\t\tif c.Plank.DefaultDecorationConfig.UtilityImages == nil {\r\n\t\t\treturn errors.New(\"no default decoration image pull specs provided for plank\")\r\n\t\t}\r\n\t\tif c.Plank.DefaultDecorationConfig.GCSConfiguration == nil {\r\n\t\t\treturn errors.New(\"no default GCS decoration config provided for plank\")\r\n\t\t}\r\n\t\tif c.Plank.DefaultDecorationConfig.GCSCredentialsSecret == \"\" {\r\n\t\t\treturn errors.New(\"no default GCS credentials secret provided for plank\")\r\n\t\t}\r\n\t\tfor _, vs := range c.Presubmits {\r\n\t\t\tfor i := range vs {\r\n\t\t\t\tsetPresubmitDecorationDefaults(c, &vs[i])\r\n\t\t\t}\r\n\t\t}\r\n\t\tfor _, js := range c.Postsubmits {\r\n\t\t\tfor i := range js {\r\n\t\t\t\tsetPostsubmitDecorationDefaults(c, &js[i])\r\n\t\t\t}\r\n\t\t}\r\n\t\tfor i := range c.Periodics {\r\n\t\t\tsetPeriodicDecorationDefaults(c, &c.Periodics[i])\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor _, vs := range c.Presubmits {\r\n\t\tc.defaultPresubmitFields(vs)\r\n\t\tif err := SetPresubmitRegexes(vs); err != nil {\r\n\t\t\treturn fmt.Errorf(\"could not set regex: %v\", err)\r\n\t\t}\r\n\t}\r\n\tfor _, js := range c.Postsubmits {\r\n\t\tc.defaultPostsubmitFields(js)\r\n\t\tif err := SetPostsubmitRegexes(js); err != nil {\r\n\t\t\treturn fmt.Errorf(\"could not set regex: %v\", err)\r\n\t\t}\r\n\t}\r\n\tc.defaultPeriodicFields(c.Periodics)\r\n\tfor _, v := range c.AllPresubmits(nil) {\r\n\t\tif err := resolvePresets(v.Name, v.Labels, v.Spec, v.BuildSpec, c.Presets); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tfor _, v := range c.AllPostsubmits(nil) {\r\n\t\tif err := resolvePresets(v.Name, v.Labels, v.Spec, v.BuildSpec, c.Presets); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tfor _, v := range c.AllPeriodics() {\r\n\t\tif err := resolvePresets(v.Name, v.Labels, v.Spec, v.BuildSpec, c.Presets); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":740,"reference":"\/\/ finalizeJobConfig mutates and fixes entries for jobspecs","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) validateComponentConfig() error {\r\n\tif c.Plank.JobURLPrefix != \"\" && c.Plank.JobURLPrefixConfig[\"*\"] != \"\" {\r\n\t\treturn errors.New(`Planks job_url_prefix must be unset when job_url_prefix_config[\"*\"] is set. The former is deprecated, use the latter`)\r\n\t}\r\n\tfor k, v := range c.Plank.JobURLPrefixConfig {\r\n\t\tif _, err := url.Parse(v); err != nil {\r\n\t\t\treturn fmt.Errorf(`Invalid value for Planks job_url_prefix_config[\"%s\"]: %v`, k, err)\r\n\t\t}\r\n\t}\r\n\tif c.SlackReporter != nil {\r\n\t\tif err := c.SlackReporter.DefaultAndValidate(); err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to validate slackreporter config: %v\", err)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":251,"reference":"\/\/ validateComponentConfig validates the infrastructure component configuration","result":"Generate the generated code.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ConfigPath(value string) string {\r\n\tif value != \"\" {\r\n\t\treturn value\r\n\t}\r\n\tlogrus.Warningf(\"defaulting to %s until 15 July 2019, please migrate\", DefaultConfigPath)\r\n\treturn DefaultConfigPath\r\n}","code-length":72,"reference":"\/\/ ConfigPath returns the value for the component's configPath if provided\n\/\/ explicitly or default otherwise.","result":"Generate the config path.","score":[0.0159,0.0338]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ValidateController(c *Controller) error {\r\n\turlTmpl, err := template.New(\"JobURL\").Parse(c.JobURLTemplateString)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"parsing template: %v\", err)\r\n\t}\r\n\tc.JobURLTemplate = urlTmpl\r\n\treportTmpl, err := template.New(\"Report\").Parse(c.ReportTemplateString)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"parsing template: %v\", err)\r\n\t}\r\n\tc.ReportTemplate = reportTmpl\r\n\tif c.MaxConcurrency < 0 {\r\n\t\treturn fmt.Errorf(\"controller has invalid max_concurrency (%d), it needs to be a non-negative number\", c.MaxConcurrency)\r\n\t}\r\n\tif c.MaxGoroutines == 0 {\r\n\t\tc.MaxGoroutines = 20\r\n\t}\r\n\tif c.MaxGoroutines <= 0 {\r\n\t\treturn fmt.Errorf(\"controller has invalid max_goroutines (%d), it needs to be a positive number\", c.MaxGoroutines)\r\n\t}\r\n\treturn nil\r\n}","code-length":285,"reference":"\/\/ ValidateController validates the provided controller config.","result":"Validate the controller configuration.","score":[0.1795,0.3814]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ProwConfig) defaultJobBase(base *JobBase) {\r\n\tif base.Agent == \"\" {\r\n\t\tbase.Agent = string(prowapi.KubernetesAgent)\r\n\t}\r\n\tif base.Namespace == nil || *base.Namespace == \"\" {\r\n\t\ts := c.PodNamespace\r\n\t\tbase.Namespace = &s\r\n\t}\r\n\tif base.Cluster == \"\" {\r\n\t\tbase.Cluster = kube.DefaultClusterAlias\r\n\t}\r\n}","code-length":130,"reference":"\/\/ defaultJobBase configures common parameters, currently Agent and Namespace.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetPresubmitRegexes(js []Presubmit) error {\r\n\tfor i, j := range js {\r\n\t\tif re, err := regexp.Compile(j.Trigger); err == nil {\r\n\t\t\tjs[i].re = re\r\n\t\t} else {\r\n\t\t\treturn fmt.Errorf(\"could not compile trigger regex for %s: %v\", j.Name, err)\r\n\t\t}\r\n\t\tif !js[i].re.MatchString(j.RerunCommand) {\r\n\t\t\treturn fmt.Errorf(\"for job %s, rerun command \\\"%s\\\" does not match trigger \\\"%s\\\"\", j.Name, j.RerunCommand, j.Trigger)\r\n\t\t}\r\n\t\tb, err := setBrancherRegexes(j.Brancher)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"could not set branch regexes for %s: %v\", j.Name, err)\r\n\t\t}\r\n\t\tjs[i].Brancher = b\r\n\t\tc, err := setChangeRegexes(j.RegexpChangeMatcher)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"could not set change regexes for %s: %v\", j.Name, err)\r\n\t\t}\r\n\t\tjs[i].RegexpChangeMatcher = c\r\n\t}\r\n\treturn nil\r\n}","code-length":333,"reference":"\/\/ SetPresubmitRegexes compiles and validates all the regular expressions for\n\/\/ the provided presubmits.","result":"Set the regexps for the presubmit regexps.","score":[0.0782,0.1128]}
{"code":"\/*is used to<extra_id_0>\r\nfunc setBrancherRegexes(br Brancher) (Brancher, error) {\r\n\tif len(br.Branches) > 0 {\r\n\t\tif re, err := regexp.Compile(strings.Join(br.Branches, `|`)); err == nil {\r\n\t\t\tbr.re = re\r\n\t\t} else {\r\n\t\t\treturn br, fmt.Errorf(\"could not compile positive branch regex: %v\", err)\r\n\t\t}\r\n\t}\r\n\tif len(br.SkipBranches) > 0 {\r\n\t\tif re, err := regexp.Compile(strings.Join(br.SkipBranches, `|`)); err == nil {\r\n\t\t\tbr.reSkip = re\r\n\t\t} else {\r\n\t\t\treturn br, fmt.Errorf(\"could not compile negative branch regex: %v\", err)\r\n\t\t}\r\n\t}\r\n\treturn br, nil\r\n}","code-length":220,"reference":"\/\/ setBrancherRegexes compiles and validates all the regular expressions for\n\/\/ the provided branch specifiers.","result":"Set the brancher regexes.","score":[0.0204,0.036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetPostsubmitRegexes(ps []Postsubmit) error {\r\n\tfor i, j := range ps {\r\n\t\tb, err := setBrancherRegexes(j.Brancher)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"could not set branch regexes for %s: %v\", j.Name, err)\r\n\t\t}\r\n\t\tps[i].Brancher = b\r\n\t\tc, err := setChangeRegexes(j.RegexpChangeMatcher)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"could not set change regexes for %s: %v\", j.Name, err)\r\n\t\t}\r\n\t\tps[i].RegexpChangeMatcher = c\r\n\t}\r\n\treturn nil\r\n}","code-length":191,"reference":"\/\/ SetPostsubmitRegexes compiles and validates all the regular expressions for\n\/\/ the provided postsubmits.","result":"Set the postsubmit regexes.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lens Lens) Body(artifacts []lenses.Artifact, resourceDir string, data string) string {\r\n\tvar buf bytes.Buffer\r\n\ttype MetadataViewData struct {\r\n\t\tStatus       string\r\n\t\tStartTime    time.Time\r\n\t\tFinishedTime time.Time\r\n\t\tElapsed      time.Duration\r\n\t\tMetadata     map[string]string\r\n\t}\r\n\tmetadataViewData := MetadataViewData{Status: \"Pending\"}\r\n\tstarted := gcs.Started{}\r\n\tfinished := gcs.Finished{}\r\n\tfor _, a := range artifacts {\r\n\t\tread, err := a.ReadAll()\r\n\t\tif err != nil {\r\n\t\t\tlogrus.WithError(err).Error(\"Failed reading from artifact.\")\r\n\t\t}\r\n\t\tif a.JobPath() == \"started.json\" {\r\n\t\t\tif err = json.Unmarshal(read, &started); err != nil {\r\n\t\t\t\tlogrus.WithError(err).Error(\"Error unmarshaling started.json\")\r\n\t\t\t}\r\n\t\t\tmetadataViewData.StartTime = time.Unix(started.Timestamp, 0)\r\n\t\t} else if a.JobPath() == \"finished.json\" {\r\n\t\t\tif err = json.Unmarshal(read, &finished); err != nil {\r\n\t\t\t\tlogrus.WithError(err).Error(\"Error unmarshaling finished.json\")\r\n\t\t\t}\r\n\t\t\tif finished.Timestamp != nil {\r\n\t\t\t\tmetadataViewData.FinishedTime = time.Unix(*finished.Timestamp, 0)\r\n\t\t\t}\r\n\t\t\tmetadataViewData.Status = finished.Result\r\n\t\t}\r\n\t}\r\n\tif !metadataViewData.StartTime.IsZero() {\r\n\t\tif metadataViewData.FinishedTime.IsZero() {\r\n\t\t\tmetadataViewData.Elapsed = time.Now().Sub(metadataViewData.StartTime)\r\n\t\t} else {\r\n\t\t\tmetadataViewData.Elapsed =\r\n\t\t\t\tmetadataViewData.FinishedTime.Sub(metadataViewData.StartTime)\r\n\t\t}\r\n\t\tmetadataViewData.Elapsed = metadataViewData.Elapsed.Round(time.Second)\r\n\t}\r\n\tmetadataViewData.Metadata = map[string]string{\"node\": started.Node}\r\n\tmetadatas := []metadata.Metadata{started.Metadata, finished.Metadata}\r\n\tfor _, m := range metadatas {\r\n\t\tfor k, v := range m {\r\n\t\t\tif s, ok := v.(string); ok && v != \"\" {\r\n\t\t\t\tmetadataViewData.Metadata[k] = s\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tmetadataTemplate, err := template.ParseFiles(filepath.Join(resourceDir, \"template.html\"))\r\n\tif err != nil {\r\n\t\treturn fmt.Sprintf(\"Failed to load template: %v\", err)\r\n\t}\r\n\tif err := metadataTemplate.ExecuteTemplate(&buf, \"body\", metadataViewData); err != nil {\r\n\t\tlogrus.WithError(err).Error(\"Error executing template.\")\r\n\t}\r\n\treturn buf.String()\r\n}","code-length":727,"reference":"\/\/ Body creates a view for prow job metadata.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewBoskosHandler(r *ranch.Ranch) *http.ServeMux {\r\n\tmux := http.NewServeMux()\r\n\tmux.Handle(\"\/\", handleDefault(r))\r\n\tmux.Handle(\"\/acquire\", handleAcquire(r))\r\n\tmux.Handle(\"\/acquirebystate\", handleAcquireByState(r))\r\n\tmux.Handle(\"\/release\", handleRelease(r))\r\n\tmux.Handle(\"\/reset\", handleReset(r))\r\n\tmux.Handle(\"\/update\", handleUpdate(r))\r\n\tmux.Handle(\"\/metric\", handleMetric(r))\r\n\treturn mux\r\n}","code-length":169,"reference":"\/\/NewBoskosHandler constructs the boskos handler.","result":"Create a handler for boskos.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ErrorToStatus(err error) int {\r\n\tswitch err.(type) {\r\n\tdefault:\r\n\t\treturn http.StatusInternalServerError\r\n\tcase *ranch.OwnerNotMatch:\r\n\t\treturn http.StatusUnauthorized\r\n\tcase *ranch.ResourceNotFound:\r\n\t\treturn http.StatusNotFound\r\n\tcase *ranch.ResourceTypeNotFound:\r\n\t\treturn http.StatusNotFound\r\n\tcase *ranch.StateNotMatch:\r\n\t\treturn http.StatusConflict\r\n\t}\r\n}","code-length":128,"reference":"\/\/ ErrorToStatus translates error into http code","result":"Convert error to status.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DumpProfile(destination string, profile []*cover.Profile) error {\r\n\tvar output io.Writer\r\n\tif destination == \"-\" {\r\n\t\toutput = os.Stdout\r\n\t} else {\r\n\t\tf, err := os.Create(destination)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to open %s: %v\", destination, err)\r\n\t\t}\r\n\t\tdefer f.Close()\r\n\t\toutput = f\r\n\t}\r\n\terr := cov.DumpProfile(profile, output)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to dump profile: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":179,"reference":"\/\/ DumpProfile dumps the profile to the given file destination.\n\/\/ If the destination is \"-\", it instead writes to stdout.","result":"Dump profile to stdout.","score":[0.0079,0.1635]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadProfile(origin string) ([]*cover.Profile, error) {\r\n\tfilename := origin\r\n\tif origin == \"-\" {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\ttf, err := ioutil.TempFile(\"\", \"\")\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"failed to create temp file: %v\", err)\r\n\t\t}\r\n\t\tdefer tf.Close()\r\n\t\tdefer os.Remove(tf.Name())\r\n\t\tif _, err := io.Copy(tf, os.Stdin); err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"failed to copy stdin to temp file: %v\", err)\r\n\t\t}\r\n\t\tfilename = tf.Name()\r\n\t}\r\n\treturn cover.ParseProfiles(filename)\r\n}","code-length":202,"reference":"\/\/ LoadProfile loads a profile from the given filename.\n\/\/ If the filename is \"-\", it instead reads from stdin.","result":"Load a profile from a file.","score":[0.0386,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient() (*Client, error) {\r\n\tg, err := exec.LookPath(\"git\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tt, err := ioutil.TempDir(\"\", \"git\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &Client{\r\n\t\tlogger:    logrus.WithField(\"client\", \"git\"),\r\n\t\tdir:       t,\r\n\t\tgit:       g,\r\n\t\tbase:      fmt.Sprintf(\"https:\r\n\t\trepoLocks: make(map[string]*sync.Mutex),\r\n\t}, nil\r\n}","code-length":171,"reference":"\/\/ NewClient returns a client that talks to GitHub. It will fail if git is not\n\/\/ in the PATH.","result":"Create a new client.","score":[0.0059,0.0272]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) SetCredentials(user string, tokenGenerator func() []byte) {\r\n\tc.credLock.Lock()\r\n\tdefer c.credLock.Unlock()\r\n\tc.user = user\r\n\tc.tokenGenerator = tokenGenerator\r\n}","code-length":71,"reference":"\/\/ SetCredentials sets credentials in the client to be used for pushing to\n\/\/ or pulling from remote repositories.","result":"Set credentials.","score":[0,0.0289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Repo) Checkout(commitlike string) error {\r\n\tr.logger.Infof(\"Checkout %s.\", commitlike)\r\n\tco := r.gitCommand(\"checkout\", commitlike)\r\n\tif b, err := co.CombinedOutput(); err != nil {\r\n\t\treturn fmt.Errorf(\"error checking out %s: %v. output: %s\", commitlike, err, string(b))\r\n\t}\r\n\treturn nil\r\n}","code-length":117,"reference":"\/\/ Checkout runs git checkout.","result":"Create a new function to create a new repository.","score":[0,0.0926]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Repo) CheckoutNewBranch(branch string) error {\r\n\tr.logger.Infof(\"Create and checkout %s.\", branch)\r\n\tco := r.gitCommand(\"checkout\", \"-b\", branch)\r\n\tif b, err := co.CombinedOutput(); err != nil {\r\n\t\treturn fmt.Errorf(\"error checking out %s: %v. output: %s\", branch, err, string(b))\r\n\t}\r\n\treturn nil\r\n}","code-length":120,"reference":"\/\/ CheckoutNewBranch creates a new branch and checks it out.","result":"Create a new branch.","score":[0.1008,0.3132]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Repo) Merge(commitlike string) (bool, error) {\r\n\tr.logger.Infof(\"Merging %s.\", commitlike)\r\n\tco := r.gitCommand(\"merge\", \"--no-ff\", \"--no-stat\", \"-m merge\", commitlike)\r\n\tb, err := co.CombinedOutput()\r\n\tif err == nil {\r\n\t\treturn true, nil\r\n\t}\r\n\tr.logger.WithError(err).Infof(\"Merge failed with output: %s\", string(b))\r\n\tif b, err := r.gitCommand(\"merge\", \"--abort\").CombinedOutput(); err != nil {\r\n\t\treturn false, fmt.Errorf(\"error aborting merge for commitlike %s: %v. output: %s\", commitlike, err, string(b))\r\n\t}\r\n\treturn false, nil\r\n}","code-length":210,"reference":"\/\/ Merge attempts to merge commitlike into the current branch. It returns true\n\/\/ if the merge completes. It returns an error if the abort fails.","result":"Generate code for the generated code.","score":[0.0069,0.0208]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Repo) CheckoutPullRequest(number int) error {\r\n\tr.logger.Infof(\"Fetching and checking out %s#%d.\", r.repo, number)\r\n\tif b, err := retryCmd(r.logger, r.Dir, r.git, \"fetch\", r.base+\"\/\"+r.repo, fmt.Sprintf(\"pull\/%d\/head:pull%d\", number, number)); err != nil {\r\n\t\treturn fmt.Errorf(\"git fetch failed for PR %d: %v. output: %s\", number, err, string(b))\r\n\t}\r\n\tco := r.gitCommand(\"checkout\", fmt.Sprintf(\"pull%d\", number))\r\n\tif b, err := co.CombinedOutput(); err != nil {\r\n\t\treturn fmt.Errorf(\"git checkout failed for PR %d: %v. output: %s\", number, err, string(b))\r\n\t}\r\n\treturn nil\r\n}","code-length":231,"reference":"\/\/ CheckoutPullRequest does exactly that.","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Repo) Config(key, value string) error {\r\n\tr.logger.Infof(\"Running git config %s %s\", key, value)\r\n\tif b, err := r.gitCommand(\"config\", key, value).CombinedOutput(); err != nil {\r\n\t\treturn fmt.Errorf(\"git config %s %s failed: %v. output: %s\", key, value, err, string(b))\r\n\t}\r\n\treturn nil\r\n}","code-length":119,"reference":"\/\/ Config runs git config.","result":"Set the config value of a repo.","score":[0,0.0962]}
{"code":"\/*is used to<extra_id_0>\r\nfunc retryCmd(l *logrus.Entry, dir, cmd string, arg ...string) ([]byte, error) {\r\n\tvar b []byte\r\n\tvar err error\r\n\tsleepyTime := time.Second\r\n\tfor i := 0; i < 3; i++ {\r\n\t\tc := exec.Command(cmd, arg...)\r\n\t\tc.Dir = dir\r\n\t\tb, err = c.CombinedOutput()\r\n\t\tif err != nil {\r\n\t\t\tl.Warningf(\"Running %s %v returned error %v with output %s.\", cmd, arg, err, string(b))\r\n\t\t\ttime.Sleep(sleepyTime)\r\n\t\t\tsleepyTime *= 2\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tbreak\r\n\t}\r\n\treturn b, err\r\n}","code-length":203,"reference":"\/\/ retryCmd will retry the command a few times with backoff. Use this for any\n\/\/ commands that will be talking to GitHub, such as clones or fetches.","result":"Retry commands.","score":[0,0.0197]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LabelsAndAnnotationsForSpec(spec prowapi.ProwJobSpec, extraLabels, extraAnnotations map[string]string) (map[string]string, map[string]string) {\r\n\tjobNameForLabel := spec.Job\r\n\tif len(jobNameForLabel) > validation.LabelValueMaxLength {\r\n\t\t\r\n\t\tjobNameForLabel = strings.TrimRight(spec.Job[:validation.LabelValueMaxLength], \".-\")\r\n\t\tlogrus.WithFields(logrus.Fields{\r\n\t\t\t\"job\":       spec.Job,\r\n\t\t\t\"key\":       kube.ProwJobAnnotation,\r\n\t\t\t\"value\":     spec.Job,\r\n\t\t\t\"truncated\": jobNameForLabel,\r\n\t\t}).Info(\"Cannot use full job name, will truncate.\")\r\n\t}\r\n\tlabels := map[string]string{\r\n\t\tkube.CreatedByProw:     \"true\",\r\n\t\tkube.ProwJobTypeLabel:  string(spec.Type),\r\n\t\tkube.ProwJobAnnotation: jobNameForLabel,\r\n\t}\r\n\tif spec.Type != prowapi.PeriodicJob && spec.Refs != nil {\r\n\t\tlabels[kube.OrgLabel] = spec.Refs.Org\r\n\t\tlabels[kube.RepoLabel] = spec.Refs.Repo\r\n\t\tif len(spec.Refs.Pulls) > 0 {\r\n\t\t\tlabels[kube.PullLabel] = strconv.Itoa(spec.Refs.Pulls[0].Number)\r\n\t\t}\r\n\t}\r\n\tfor k, v := range extraLabels {\r\n\t\tlabels[k] = v\r\n\t}\r\n\t\r\n\tfor key, value := range labels {\r\n\t\tif errs := validation.IsValidLabelValue(value); len(errs) > 0 {\r\n\t\t\t\tbase := filepath.Base(value)\r\n\t\t\tif errs := validation.IsValidLabelValue(base); len(errs) == 0 {\r\n\t\t\t\tlabels[key] = base\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tlogrus.WithFields(logrus.Fields{\r\n\t\t\t\t\"key\":    key,\r\n\t\t\t\t\"value\":  value,\r\n\t\t\t\t\"errors\": errs,\r\n\t\t\t}).Warn(\"Removing invalid label\")\r\n\t\t\tdelete(labels, key)\r\n\t\t}\r\n\t}\r\n\tannotations := map[string]string{\r\n\t\tkube.ProwJobAnnotation: spec.Job,\r\n\t}\r\n\tfor k, v := range extraAnnotations {\r\n\t\tannotations[k] = v\r\n\t}\r\n\treturn labels, annotations\r\n}","code-length":637,"reference":"\/\/ LabelsAndAnnotationsForSpec returns a minimal set of labels to add to prowjobs or its owned resources.\n\/\/\n\/\/ User-provided extraLabels and extraAnnotations values will take precedence over auto-provided values.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ProwJobToPod(pj prowapi.ProwJob, buildID string) (*coreapi.Pod, error) {\r\n\tif pj.Spec.PodSpec == nil {\r\n\t\treturn nil, fmt.Errorf(\"prowjob %q lacks a pod spec\", pj.Name)\r\n\t}\r\n\trawEnv, err := downwardapi.EnvForSpec(downwardapi.NewJobSpec(pj.Spec, buildID, pj.Name))\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tspec := pj.Spec.PodSpec.DeepCopy()\r\n\tspec.RestartPolicy = \"Never\"\r\n\tspec.Containers[0].Name = kube.TestContainerName\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif spec.AutomountServiceAccountToken == nil && spec.ServiceAccountName == \"\" {\r\n\t\tmyFalse := false\r\n\t\tspec.AutomountServiceAccountToken = &myFalse\r\n\t}\r\n\tif pj.Spec.DecorationConfig == nil {\r\n\t\tspec.Containers[0].Env = append(spec.Containers[0].Env, kubeEnv(rawEnv)...)\r\n\t} else {\r\n\t\tif err := decorate(spec, &pj, rawEnv); err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"error decorating podspec: %v\", err)\r\n\t\t}\r\n\t}\r\n\tpodLabels, annotations := LabelsAndAnnotationsForJob(pj)\r\n\treturn &coreapi.Pod{\r\n\t\tObjectMeta: metav1.ObjectMeta{\r\n\t\t\tName:        pj.ObjectMeta.Name,\r\n\t\t\tLabels:      podLabels,\r\n\t\t\tAnnotations: annotations,\r\n\t\t},\r\n\t\tSpec: *spec,\r\n\t}, nil\r\n}","code-length":441,"reference":"\/\/ ProwJobToPod converts a ProwJob to a Pod that will run the tests.","result":"Convert ProwJob to pod.","score":[0.0476,0.2112]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CloneLogPath(logMount coreapi.VolumeMount) string {\r\n\treturn filepath.Join(logMount.MountPath, cloneLogPath)\r\n}","code-length":45,"reference":"\/\/ CloneLogPath returns the path to the clone log file in the volume mount.\n\/\/ CloneLogPath returns the path to the clone log file in the volume mount.","result":"Generate the generated code.","score":[0.0008,0.0195]}
{"code":"\/*is used to<extra_id_0>\r\nfunc cloneEnv(opt clonerefs.Options) ([]coreapi.EnvVar, error) {\r\n\t\r\n\tcloneConfigEnv, err := clonerefs.Encode(opt)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn kubeEnv(map[string]string{clonerefs.JSONConfigEnvVar: cloneConfigEnv}), nil\r\n}","code-length":105,"reference":"\/\/ cloneEnv encodes clonerefs Options into json and puts it into an environment variable","result":"Clone the environment.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc sshVolume(secret string) (coreapi.Volume, coreapi.VolumeMount) {\r\n\tvar sshKeyMode int32 = 0400\r\n\tname := strings.Join([]string{\"ssh-keys\", secret}, \"-\")\r\n\tmountPath := path.Join(\"\/secrets\/ssh\", secret)\r\n\tv := coreapi.Volume{\r\n\t\tName: name,\r\n\t\tVolumeSource: coreapi.VolumeSource{\r\n\t\t\tSecret: &coreapi.SecretVolumeSource{\r\n\t\t\t\tSecretName:  secret,\r\n\t\t\t\tDefaultMode: &sshKeyMode,\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n\tvm := coreapi.VolumeMount{\r\n\t\tName:      name,\r\n\t\tMountPath: mountPath,\r\n\t\tReadOnly:  true,\r\n\t}\r\n\treturn v, vm\r\n}","code-length":210,"reference":"\/\/ sshVolume converts a secret holding ssh keys into the corresponding volume and mount.\n\/\/\n\/\/ This is used by CloneRefs to attach the mount to the clonerefs container.","result":"Mount a secret to a volume.","score":[0.0065,0.0749]}
{"code":"\/*is used to<extra_id_0>\r\nfunc InjectEntrypoint(c *coreapi.Container, timeout, gracePeriod time.Duration, prefix, previousMarker string, exitZero bool, log, tools coreapi.VolumeMount) (*wrapper.Options, error) {\r\n\twrapperOptions := &wrapper.Options{\r\n\t\tArgs:         append(c.Command, c.Args...),\r\n\t\tProcessLog:   processLog(log, prefix),\r\n\t\tMarkerFile:   markerFile(log, prefix),\r\n\t\tMetadataFile: metadataFile(log, prefix),\r\n\t}\r\n\t\r\n\tentrypointConfigEnv, err := entrypoint.Encode(entrypoint.Options{\r\n\t\tArtifactDir:    artifactsDir(log),\r\n\t\tGracePeriod:    gracePeriod,\r\n\t\tOptions:        wrapperOptions,\r\n\t\tTimeout:        timeout,\r\n\t\tAlwaysZero:     exitZero,\r\n\t\tPreviousMarker: previousMarker,\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tc.Command = []string{entrypointLocation(tools)}\r\n\tc.Args = nil\r\n\tc.Env = append(c.Env, kubeEnv(map[string]string{entrypoint.JSONConfigEnvVar: entrypointConfigEnv})...)\r\n\tc.VolumeMounts = append(c.VolumeMounts, log, tools)\r\n\treturn wrapperOptions, nil\r\n}","code-length":333,"reference":"\/\/ InjectEntrypoint will make the entrypoint binary in the tools volume the container's entrypoint, which will output to the log volume.","result":"Inject the entrypoint.","score":[0.001,0.026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PlaceEntrypoint(image string, toolsMount coreapi.VolumeMount) coreapi.Container {\r\n\treturn coreapi.Container{\r\n\t\tName:         \"place-entrypoint\",\r\n\t\tImage:        image,\r\n\t\tCommand:      []string{\"\/bin\/cp\"},\r\n\t\tArgs:         []string{\"\/entrypoint\", entrypointLocation(toolsMount)},\r\n\t\tVolumeMounts: []coreapi.VolumeMount{toolsMount},\r\n\t}\r\n}","code-length":122,"reference":"\/\/ PlaceEntrypoint will copy entrypoint from the entrypoint image to the tools volume","result":"Place the entrypoint.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc kubeEnv(environment map[string]string) []coreapi.EnvVar {\r\n\tvar keys []string\r\n\tfor key := range environment {\r\n\t\tkeys = append(keys, key)\r\n\t}\r\n\tsort.Strings(keys)\r\n\tvar kubeEnvironment []coreapi.EnvVar\r\n\tfor _, key := range keys {\r\n\t\tkubeEnvironment = append(kubeEnvironment, coreapi.EnvVar{\r\n\t\t\tName:  key,\r\n\t\t\tValue: environment[key],\r\n\t\t})\r\n\t}\r\n\treturn kubeEnvironment\r\n}","code-length":148,"reference":"\/\/ kubeEnv transforms a mapping of environment variables\n\/\/ into their serialized form for a PodSpec, sorting by\n\/\/ the name of the env vars","result":"Generate the kubeEnv function.","score":[0.002,0.0437]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *KubernetesOptions) Client(namespace string, dryRun bool) (*kube.Client, error) {\r\n\tif dryRun {\r\n\t\treturn kube.NewFakeClient(o.DeckURI), nil\r\n\t}\r\n\tif o.cluster == \"\" {\r\n\t\treturn kube.NewClientInCluster(namespace)\r\n\t}\r\n\treturn kube.NewClientFromFile(o.cluster, namespace)\r\n}","code-length":108,"reference":"\/\/ Client returns a Kubernetes client.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc handle(gc githubClient, le *logrus.Entry, e *event) error {\r\n\tneedsLabel := e.draft || titleRegex.MatchString(e.title)\r\n\tif needsLabel && !e.hasLabel {\r\n\t\tif err := gc.AddLabel(e.org, e.repo, e.number, labels.WorkInProgress); err != nil {\r\n\t\t\tle.Warnf(\"error while adding Label %q: %v\", labels.WorkInProgress, err)\r\n\t\t\treturn err\r\n\t\t}\r\n\t} else if !needsLabel && e.hasLabel {\r\n\t\tif err := gc.RemoveLabel(e.org, e.repo, e.number, labels.WorkInProgress); err != nil {\r\n\t\t\tle.Warnf(\"error while removing Label %q: %v\", labels.WorkInProgress, err)\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":229,"reference":"\/\/ handle interacts with GitHub to drive the pull request to the\n\/\/ proper state by adding and removing comments and labels. If a\n\/\/ PR has a WIP prefix, it needs an explanatory comment and label.\n\/\/ Otherwise, neither should be present.","result":"Handle events in github.","score":[0,0.0128]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SendHook(address, eventType string, payload, hmac []byte) error {\r\n\treq, err := http.NewRequest(http.MethodPost, address, bytes.NewBuffer(payload))\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treq.Header.Set(\"X-GitHub-Event\", eventType)\r\n\treq.Header.Set(\"X-GitHub-Delivery\", \"GUID\")\r\n\treq.Header.Set(\"X-Hub-Signature\", github.PayloadSignature(payload, hmac))\r\n\treq.Header.Set(\"content-type\", \"application\/json\")\r\n\tc := &http.Client{}\r\n\tresp, err := c.Do(req)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\trb, err := ioutil.ReadAll(resp.Body)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif resp.StatusCode != 200 {\r\n\t\treturn fmt.Errorf(\"response from hook has status %d and body %s\", resp.StatusCode, string(bytes.TrimSpace(rb)))\r\n\t}\r\n\treturn nil\r\n}","code-length":288,"reference":"\/\/ SendHook sends a GitHub event of type eventType to the provided address.","result":"Send a hook to a GitHub address.","score":[0.1153,0.3]}
{"code":"\/*is used to<extra_id_0>\r\nfunc janitorClean(resource *common.Resource, flags []string) error {\r\n\targs := append([]string{fmt.Sprintf(\"--%s=%s\", format(resource.Type), resource.Name)}, flags...)\r\n\tlogrus.Infof(\"executing janitor: %s %s\", *janitorPath, strings.Join(args, \" \"))\r\n\tcmd := exec.Command(*janitorPath, args...)\r\n\tb, err := cmd.CombinedOutput()\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Errorf(\"failed to clean up project %s, error info: %s\", resource.Name, string(b))\r\n\t} else {\r\n\t\tlogrus.Tracef(\"output from janitor: %s\", string(b))\r\n\t\tlogrus.Infof(\"successfully cleaned up resource %s\", resource.Name)\r\n\t}\r\n\treturn err\r\n}","code-length":230,"reference":"\/\/ Clean by janitor script","result":"Clean up project .","score":[0.2488,0.102]}
{"code":"\/*is used to<extra_id_0>\r\nfunc janitor(c boskosClient, buffer <-chan *common.Resource, fn clean, flags []string) {\r\n\tfor {\r\n\t\tresource := <-buffer\r\n\t\tdest := common.Free\r\n\t\tif err := fn(resource, flags); err != nil {\r\n\t\t\tlogrus.WithError(err).Errorf(\"%s failed!\", *janitorPath)\r\n\t\t\tdest = common.Dirty\r\n\t\t}\r\n\t\tif err := c.ReleaseOne(resource.Name, dest); err != nil {\r\n\t\t\tlogrus.WithError(err).Error(\"boskos release failed!\")\r\n\t\t}\r\n\t}\r\n}","code-length":167,"reference":"\/\/ async janitor goroutine","result":"Avoid the need for the janitor .","score":[0.1615,0.1163]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *PullServer) Run(ctx context.Context) error {\r\n\tconfigEvent := make(chan config.Delta, 2)\r\n\ts.Subscriber.ConfigAgent.Subscribe(configEvent)\r\n\tvar err error\r\n\tdefer func() {\r\n\t\tif err != nil {\r\n\t\t\tlogrus.WithError(ctx.Err()).Error(\"Pull server shutting down\")\r\n\t\t}\r\n\t\tlogrus.Warn(\"Pull server shutting down\")\r\n\t}()\r\n\tcurrentConfig := s.Subscriber.ConfigAgent.Config().PubSubSubscriptions\r\n\terrGroup, derivedCtx, err := s.handlePulls(ctx, currentConfig)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfor {\r\n\t\tselect {\r\n\t\t\r\n\t\tcase <-ctx.Done():\r\n\t\t\treturn ctx.Err()\r\n\t\t\r\n\t\tcase <-derivedCtx.Done():\r\n\t\t\terr = errGroup.Wait()\r\n\t\t\treturn err\r\n\t\t\r\n\t\tcase event := <-configEvent:\r\n\t\t\tnewConfig := event.After.PubSubSubscriptions\r\n\t\t\tlogrus.Info(\"Received new config\")\r\n\t\t\tif !reflect.DeepEqual(currentConfig, newConfig) {\r\n\t\t\t\tlogrus.Warn(\"New config found, reloading pull Server\")\r\n\t\t\t\t\r\n\t\t\t\terrGroup.Wait()\r\n\t\t\t\t\r\n\t\t\t\terrGroup, derivedCtx, err = s.handlePulls(ctx, newConfig)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t\tcurrentConfig = newConfig\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":402,"reference":"\/\/ Run will block listening to all subscriptions and return once the context is cancelled\n\/\/ or one of the subscription has a unrecoverable error.","result":"Run the server.","score":[0.0003,0.0439]}
{"code":"\/*is used to<extra_id_0>\r\nfunc specToStarted(spec *downwardapi.JobSpec, mainRefSHA string) gcs.Started {\r\n\tstarted := gcs.Started{\r\n\t\tTimestamp:   time.Now().Unix(),\r\n\t\tRepoVersion: downwardapi.GetRevisionFromSpec(spec),\r\n\t}\r\n\tif mainRefSHA != \"\" {\r\n\t\tstarted.RepoVersion = mainRefSHA\r\n\t}\r\n\t\r\n\tif spec.Refs != nil && len(spec.Refs.Pulls) > 0 {\r\n\t\tstarted.Pull = strconv.Itoa(spec.Refs.Pulls[0].Number)\r\n\t}\r\n\tstarted.Repos = map[string]string{}\r\n\tif spec.Refs != nil {\r\n\t\tstarted.Repos[spec.Refs.Org+\"\/\"+spec.Refs.Repo] = spec.Refs.String()\r\n\t}\r\n\tfor _, ref := range spec.ExtraRefs {\r\n\t\tstarted.Repos[ref.Org+\"\/\"+ref.Repo] = ref.String()\r\n\t}\r\n\treturn started\r\n}","code-length":260,"reference":"\/\/ specToStarted translate a jobspec into a started struct\n\/\/ optionally overwrite RepoVersion with provided mainRefSHA","result":"Convert spec to started object.","score":[0.0266,0.0336]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Options) Run() error {\r\n\tspec, err := downwardapi.ResolveSpecFromEnv()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"could not resolve job spec: %v\", err)\r\n\t}\r\n\tuploadTargets := map[string]gcs.UploadFunc{}\r\n\tvar failed bool\r\n\tvar mainRefSHA string\r\n\tif o.Log != \"\" {\r\n\t\tif failed, mainRefSHA, err = processCloneLog(o.Log, uploadTargets); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tstarted := specToStarted(spec, mainRefSHA)\r\n\tstartedData, err := json.Marshal(&started)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"could not marshal starting data: %v\", err)\r\n\t}\r\n\tuploadTargets[\"started.json\"] = gcs.DataUpload(bytes.NewReader(startedData))\r\n\tif err := o.Options.Run(spec, uploadTargets); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to upload to GCS: %v\", err)\r\n\t}\r\n\tif failed {\r\n\t\treturn errors.New(\"cloning the appropriate refs failed\")\r\n\t}\r\n\treturn nil\r\n}","code-length":314,"reference":"\/\/ Run will start the initupload job to upload the artifacts, logs and clone status.","result":"Clone the appropriate refs.","score":[0.0204,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc hasPRChanged(pr github.PullRequestEvent) bool {\r\n\tswitch pr.Action {\r\n\tcase github.PullRequestActionOpened:\r\n\t\treturn true\r\n\tcase github.PullRequestActionReopened:\r\n\t\treturn true\r\n\tcase github.PullRequestActionSynchronize:\r\n\t\treturn true\r\n\tdefault:\r\n\t\treturn false\r\n\t}\r\n}","code-length":98,"reference":"\/\/ hasPRChanged indicates that the code diff may have changed.","result":"Check if PR has changed.","score":[0.0884,0.0526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UpdateIssues(db *gorm.DB, client ClientInterface) {\r\n\tlatest, err := findLatestIssueUpdate(db, client.RepositoryName())\r\n\tif err != nil {\r\n\t\tglog.Error(\"Failed to find last issue update: \", err)\r\n\t\treturn\r\n\t}\r\n\tc := make(chan *github.Issue, 200)\r\n\tgo client.FetchIssues(latest, c)\r\n\tfor issue := range c {\r\n\t\tissueOrm, err := NewIssue(issue, client.RepositoryName())\r\n\t\tif err != nil {\r\n\t\t\tglog.Error(\"Can't create issue:\", err)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif db.Create(issueOrm).Error != nil {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tdb.Delete(sql.Label{},\r\n\t\t\t\t\"issue_id = ? AND repository = ?\",\r\n\t\t\t\tissueOrm.ID, client.RepositoryName())\r\n\t\t\tdb.Delete(sql.Assignee{},\r\n\t\t\t\t\"issue_id = ? AND repository = ?\",\r\n\t\t\t\tissueOrm.ID, client.RepositoryName())\r\n\t\t\tif err := db.Save(issueOrm).Error; err != nil {\r\n\t\t\t\tglog.Error(\"Failed to update database issue: \", err)\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tUpdateComments(*issue.Number, issueOrm.IsPR, db, client)\r\n\t\t\r\n\t\tUpdateIssueEvents(*issue.Number, db, client)\r\n\t}\r\n}","code-length":383,"reference":"\/\/ UpdateIssues downloads new issues and saves in database","result":"Update issues in the database.","score":[0.1284,0.1163]}
{"code":"\/*is used to<extra_id_0>\r\nfunc handleReviewEvent(pc plugins.Agent, re github.ReviewEvent) error {\r\n\treturn handleReview(\r\n\t\tpc.Logger,\r\n\t\tpc.GitHubClient,\r\n\t\tpc.OwnersClient,\r\n\t\tpc.Config.GitHubOptions,\r\n\t\tpc.PluginConfig,\r\n\t\t&re,\r\n\t)\r\n}","code-length":95,"reference":"\/\/ handleReviewEvent should only handle reviews that have no approval command.\n\/\/ Reviews with approval commands will be handled by handleGenericCommentEvent.","result":"Handle review events.","score":[0,0.0521]}
{"code":"\/*is used to<extra_id_0>\r\nfunc findAssociatedIssue(body, org string) (int, error) {\r\n\tassociatedIssueRegex, err := regexp.Compile(fmt.Sprintf(associatedIssueRegexFormat, org))\r\n\tif err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\tmatch := associatedIssueRegex.FindStringSubmatch(body)\r\n\tif len(match) == 0 {\r\n\t\treturn 0, nil\r\n\t}\r\n\tv, err := strconv.Atoi(match[1])\r\n\tif err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\treturn v, nil\r\n}","code-length":154,"reference":"\/\/ Returns associated issue, or 0 if it can't find any.\n\/\/ This is really simple, and could be improved later.","result":"Find associated issues in a body.","score":[0.0158,0.0513]}
{"code":"\/*is used to<extra_id_0>\r\nfunc optionsForRepo(config *plugins.Configuration, org, repo string) *plugins.Approve {\r\n\tfullName := fmt.Sprintf(\"%s\/%s\", org, repo)\r\n\ta := func() *plugins.Approve {\r\n\t\t\r\n\t\tfor _, c := range config.Approve {\r\n\t\t\tif !strInSlice(fullName, c.Repos) {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\treturn &c\r\n\t\t}\r\n\t\t\r\n\t\tfor _, c := range config.Approve {\r\n\t\t\tif !strInSlice(org, c.Repos) {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\treturn &c\r\n\t\t}\r\n\t\t\r\n\t\treturn &plugins.Approve{}\r\n\t}()\r\n\tif a.DeprecatedImplicitSelfApprove == nil && a.RequireSelfApproval == nil && config.UseDeprecatedSelfApprove {\r\n\t\tno := false\r\n\t\ta.DeprecatedImplicitSelfApprove = &no\r\n\t}\r\n\tif a.DeprecatedReviewActsAsApprove == nil && a.IgnoreReviewState == nil && config.UseDeprecatedReviewApprove {\r\n\t\tno := false\r\n\t\ta.DeprecatedReviewActsAsApprove = &no\r\n\t}\r\n\treturn a\r\n}","code-length":319,"reference":"\/\/ optionsForRepo gets the plugins.Approve struct that is applicable to the indicated repo.","result":"Generate the options for a repo.","score":[0.0715,0.0813]}
{"code":"\/*is used to<extra_id_0>\r\nfunc localOnlyMain(cfg config.Getter, o options, mux *http.ServeMux) *http.ServeMux {\r\n\tmux.Handle(\"\/github-login\", gziphandler.GzipHandler(handleSimpleTemplate(o, cfg, \"github-login.html\", nil)))\r\n\tif o.spyglass {\r\n\t\tinitSpyglass(cfg, o, mux, nil)\r\n\t}\r\n\treturn mux\r\n}","code-length":111,"reference":"\/\/ localOnlyMain contains logic used only when running locally, and is mutually exclusive with\n\/\/ prodOnlyMain.","result":"Run local only main.","score":[0.0159,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (covList *CoverageList) summarize() {\r\n\tcovList.NumCoveredStmts = 0\r\n\tcovList.NumAllStmts = 0\r\n\tfor _, item := range covList.Group {\r\n\t\tcovList.NumCoveredStmts += item.NumCoveredStmts\r\n\t\tcovList.NumAllStmts += item.NumAllStmts\r\n\t}\r\n}","code-length":104,"reference":"\/\/ summarize summarizes all items in the Group and stores the result","result":"Summarize the coverage list.","score":[0.0432,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (covList *CoverageList) Subset(prefix string) *CoverageList {\r\n\ts := newCoverageList(\"Filtered Summary\")\r\n\tfor _, c := range covList.Group {\r\n\t\tif strings.HasPrefix(c.Name, prefix) {\r\n\t\t\tcovList.Group = append(covList.Group, c)\r\n\t\t}\r\n\t}\r\n\treturn s\r\n}","code-length":105,"reference":"\/\/ Subset returns the subset obtained through applying filter","result":"Filter the summary.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (covList CoverageList) ListDirectories() []string {\r\n\tdirSet := map[string]bool{}\r\n\tfor _, cov := range covList.Group {\r\n\t\tdirSet[path.Dir(cov.Name)] = true\r\n\t}\r\n\tvar result []string\r\n\tfor key := range dirSet {\r\n\t\tresult = append(result, key)\r\n\t}\r\n\treturn result\r\n}","code-length":110,"reference":"\/\/ ListDirectories gets a list a sub-directories that contains source code.","result":"List the directories in the list of directories.","score":[0.0955,0.0467]}
{"code":"\/*is used to<extra_id_0>\r\nfunc readRequest(r io.Reader, contentType string) (*admissionapi.AdmissionRequest, error) {\r\n\tif contentType != contentTypeJSON {\r\n\t\treturn nil, fmt.Errorf(\"Content-Type=%s, expected %s\", contentType, contentTypeJSON)\r\n\t}\r\n\t\r\n\tif r == nil {\r\n\t\treturn nil, fmt.Errorf(\"no body\")\r\n\t}\r\n\tbody, err := ioutil.ReadAll(r)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"read body: %v\", err)\r\n\t}\r\n\t\r\n\tvar ar admissionapi.AdmissionReview\r\n\tdeserializer := codecs.UniversalDeserializer()\r\n\tif _, _, err := deserializer.Decode(body, nil, &ar); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"decode body: %v\", err)\r\n\t}\r\n\treturn ar.Request, nil\r\n}","code-length":233,"reference":"\/\/ readRequest extracts the request from the AdmissionReview reader","result":"Read the request from the body.","score":[0.3665,0.4562]}
{"code":"\/*is used to<extra_id_0>\r\nfunc handle(w http.ResponseWriter, r *http.Request) {\r\n\treq, err := readRequest(r.Body, r.Header.Get(\"Content-Type\"))\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Error(\"read\")\r\n\t}\r\n\tif err := writeResponse(*req, w, onlyUpdateStatus); err != nil {\r\n\t\tlogrus.WithError(err).Error(\"write\")\r\n\t}\r\n}","code-length":120,"reference":"\/\/ handle reads the request and writes the response","result":"Handle requests.","score":[0,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc writeResponse(ar admissionapi.AdmissionRequest, w io.Writer, decide decider) error {\r\n\tresponse, err := decide(ar)\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Error(\"failed decision\")\r\n\t\tresponse = &admissionapi.AdmissionResponse{\r\n\t\t\tResult: &meta.Status{\r\n\t\t\t\tMessage: err.Error(),\r\n\t\t\t},\r\n\t\t}\r\n\t}\r\n\tvar result admissionapi.AdmissionReview\r\n\tresult.Response = response\r\n\tresult.Response.UID = ar.UID\r\n\tout, err := json.Marshal(result)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"encode response: %v\", err)\r\n\t}\r\n\tif _, err := w.Write(out); err != nil {\r\n\t\treturn fmt.Errorf(\"write response: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":237,"reference":"\/\/ writeResponse gets the response from onlyUpdateStatus and writes it to w.","result":"Write the response to the writer.","score":[0.1112,0.1754]}
{"code":"\/*is used to<extra_id_0>\r\nfunc onlyUpdateStatus(req admissionapi.AdmissionRequest) (*admissionapi.AdmissionResponse, error) {\r\n\tlogger := logrus.WithFields(logrus.Fields{\r\n\t\t\"resource\":    req.Resource,\r\n\t\t\"subresource\": req.SubResource,\r\n\t\t\"name\":        req.Name,\r\n\t\t\"namespace\":   req.Namespace,\r\n\t\t\"operation\":   req.Operation,\r\n\t})\r\n\t\r\n\tif req.SubResource == \"status\" {\r\n\t\tlogrus.Info(\"accept status update\")\r\n\t\treturn &allow, nil\r\n\t}\r\n\t\r\n\tvar new prowjobv1.ProwJob\r\n\tif _, _, err := codecs.UniversalDeserializer().Decode(req.Object.Raw, nil, &new); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"decode new: %v\", err)\r\n\t}\r\n\tvar old prowjobv1.ProwJob\r\n\tif _, _, err := codecs.UniversalDeserializer().Decode(req.OldObject.Raw, nil, &old); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"decode old: %v\", err)\r\n\t}\r\n\tif equality.Semantic.DeepEqual(old.Spec, new.Spec) {\r\n\t\tlogrus.Info(\"accept update with equivalent spec\")\r\n\t\treturn &allow, nil\r\n\t}\r\n\tlogger.Info(\"reject\")\r\n\treturn &reject, nil\r\n}","code-length":370,"reference":"\/\/ onlyUpdateStatus returns the response to the request","result":"Check if the status is updated.","score":[0.1383,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc convertSuiteMeta(suiteMeta gcs.SuitesMeta) resultstore.Suite {\r\n\tout := resultstore.Suite{\r\n\t\tName: path.Base(suiteMeta.Path),\r\n\t\tFiles: []resultstore.File{\r\n\t\t\t{\r\n\t\t\t\tContentType: \"text\/xml\",\r\n\t\t\t\tID:          resultstore.UUID(),\r\n\t\t\t\tURL:         suiteMeta.Path,\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n\tfor _, suite := range suiteMeta.Suites.Suites {\r\n\t\tchild := resultstore.Suite{\r\n\t\t\tName:     suite.Name,\r\n\t\t\tDuration: dur(suite.Time),\r\n\t\t}\r\n\t\tswitch {\r\n\t\tcase suite.Failures > 0 && suite.Tests >= suite.Failures:\r\n\t\t\tchild.Failures = append(child.Failures, resultstore.Failure{\r\n\t\t\t\tMessage: fmt.Sprintf(\"%d out of %d tests failed (%.1f%% passing)\", suite.Failures, suite.Tests, float64(suite.Tests-suite.Failures)*100.0\/float64(suite.Tests)),\r\n\t\t\t})\r\n\t\tcase suite.Failures > 0:\r\n\t\t\tchild.Failures = append(child.Failures, resultstore.Failure{\r\n\t\t\t\tMessage: fmt.Sprintf(\"%d tests failed\", suite.Failures),\r\n\t\t\t})\r\n\t\t}\r\n\t\tfor _, result := range suite.Results {\r\n\t\t\tname, tags := stripTags(result.Name)\r\n\t\t\tclass := result.ClassName\r\n\t\t\tif class == \"\" {\r\n\t\t\t\tclass = strings.Join(tags, \" \")\r\n\t\t\t} else {\r\n\t\t\t\tclass += \" \" + strings.Join(tags, \" \")\r\n\t\t\t}\r\n\t\t\tc := resultstore.Case{\r\n\t\t\t\tName:     name,\r\n\t\t\t\tClass:    class,\r\n\t\t\t\tDuration: dur(result.Time),\r\n\t\t\t\tResult:   resultstore.Completed,\r\n\t\t\t}\r\n\t\t\tconst max = 5000\r\n\t\t\tmsg := result.Message(max)\r\n\t\t\tswitch {\r\n\t\t\tcase result.Failure != nil:\r\n\t\t\t\t\r\n\t\t\t\tif msg == \"\" {\r\n\t\t\t\t\tmsg = \"unknown failure\"\r\n\t\t\t\t}\r\n\t\t\t\tc.Failures = append(c.Failures, resultstore.Failure{\r\n\t\t\t\t\tMessage: msg,\r\n\t\t\t\t})\r\n\t\t\tcase result.Skipped != nil:\r\n\t\t\t\tc.Result = resultstore.Skipped\r\n\t\t\t\tif msg != \"\" {\r\n\t\t\t\t\tc.Errors = append(c.Errors, resultstore.Error{\r\n\t\t\t\t\t\tMessage: msg,\r\n\t\t\t\t\t})\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tchild.Cases = append(child.Cases, c)\r\n\t\t\tif c.Duration > child.Duration {\r\n\t\t\t\tchild.Duration = c.Duration\r\n\t\t\t}\r\n\t\t}\r\n\t\tif child.Duration > out.Duration {\r\n\t\t\t\r\n\t\t\tout.Duration = child.Duration\r\n\t\t}\r\n\t\tout.Suites = append(out.Suites, child)\r\n\t}\r\n\treturn out\r\n}","code-length":765,"reference":"\/\/ convertSuiteMeta converts a junit result in gcs to a ResultStore Suite.","result":"Code too long,keep in 512.","score":[0.0593,0.0442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewHealth() *Health {\r\n\thealthMux := http.NewServeMux()\r\n\thealthMux.HandleFunc(\"\/healthz\", func(w http.ResponseWriter, r *http.Request) { fmt.Fprint(w, \"OK\") })\r\n\tgo func() {\r\n\t\tlogrus.WithError(http.ListenAndServe(\":\"+strconv.Itoa(healthPort), healthMux)).Fatal(\"ListenAndServe returned.\")\r\n\t}()\r\n\treturn &Health{\r\n\t\thealthMux: healthMux,\r\n\t}\r\n}","code-length":140,"reference":"\/\/ NewHealth creates a new health request multiplexer and starts serving the liveness endpoint\n\/\/ on the given port","result":"Create a new health object.","score":[0.0301,0.2255]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *Health) ServeReady() {\r\n\th.healthMux.HandleFunc(\"\/healthz\/ready\", func(w http.ResponseWriter, r *http.Request) { fmt.Fprint(w, \"OK\") })\r\n}","code-length":66,"reference":"\/\/ ServeReady starts serving the readiness endpoint","result":"Serve the ready event.","score":[0.1509,0.4395]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewController(ghcSync, ghcStatus *github.Client, prowJobClient prowv1.ProwJobInterface, cfg config.Getter, gc *git.Client, maxRecordsPerPool int, opener io.Opener, historyURI, statusURI string, logger *logrus.Entry) (*Controller, error) {\r\n\tif logger == nil {\r\n\t\tlogger = logrus.NewEntry(logrus.StandardLogger())\r\n\t}\r\n\thist, err := history.New(maxRecordsPerPool, opener, historyURI)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error initializing history client from %q: %v\", historyURI, err)\r\n\t}\r\n\tsc := &statusController{\r\n\t\tlogger:         logger.WithField(\"controller\", \"status-update\"),\r\n\t\tghc:            ghcStatus,\r\n\t\tconfig:         cfg,\r\n\t\tnewPoolPending: make(chan bool, 1),\r\n\t\tshutDown:       make(chan bool),\r\n\t\topener:         opener,\r\n\t\tpath:           statusURI,\r\n\t}\r\n\tgo sc.run()\r\n\treturn &Controller{\r\n\t\tlogger:        logger.WithField(\"controller\", \"sync\"),\r\n\t\tghc:           ghcSync,\r\n\t\tprowJobClient: prowJobClient,\r\n\t\tconfig:        cfg,\r\n\t\tgc:            gc,\r\n\t\tsc:            sc,\r\n\t\tchangedFiles: &changedFilesAgent{\r\n\t\t\tghc:             ghcSync,\r\n\t\t\tnextChangeCache: make(map[changeCacheKey][]string),\r\n\t\t},\r\n\t\tHistory: hist,\r\n\t}, nil\r\n}","code-length":422,"reference":"\/\/ NewController makes a Controller out of the given clients.","result":"Create a new controller.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newExpectedContext(c string) Context {\r\n\treturn Context{\r\n\t\tContext:     githubql.String(c),\r\n\t\tState:       githubql.StatusStateExpected,\r\n\t\tDescription: githubql.String(\"\"),\r\n\t}\r\n}","code-length":73,"reference":"\/\/ newExpectedContext creates a Context with Expected state.","result":"Create a new context.","score":[0.1175,0.2467]}
{"code":"\/*is used to<extra_id_0>\r\nfunc contextsToStrings(contexts []Context) []string {\r\n\tvar names []string\r\n\tfor _, c := range contexts {\r\n\t\tnames = append(names, string(c.Context))\r\n\t}\r\n\treturn names\r\n}","code-length":67,"reference":"\/\/ contextsToStrings converts a list Context to a list of string","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) filterSubpools(goroutines int, raw map[string]*subpool) map[string]*subpool {\r\n\tfiltered := make(map[string]*subpool)\r\n\tvar lock sync.Mutex\r\n\tsubpoolsInParallel(\r\n\t\tgoroutines,\r\n\t\traw,\r\n\t\tfunc(sp *subpool) {\r\n\t\t\tif err := c.initSubpoolData(sp); err != nil {\r\n\t\t\t\tsp.log.WithError(err).Error(\"Error initializing subpool.\")\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tkey := poolKey(sp.org, sp.repo, sp.branch)\r\n\t\t\tif spFiltered := filterSubpool(c.ghc, sp); spFiltered != nil {\r\n\t\t\t\tsp.log.WithField(\"key\", key).WithField(\"pool\", spFiltered).Debug(\"filtered sub-pool\")\r\n\t\t\t\tlock.Lock()\r\n\t\t\t\tfiltered[key] = spFiltered\r\n\t\t\t\tlock.Unlock()\r\n\t\t\t} else {\r\n\t\t\t\tsp.log.WithField(\"key\", key).WithField(\"pool\", spFiltered).Debug(\"filtering sub-pool removed all PRs\")\r\n\t\t\t}\r\n\t\t},\r\n\t)\r\n\treturn filtered\r\n}","code-length":309,"reference":"\/\/ filterSubpools filters non-pool PRs out of the initially identified subpools,\n\/\/ deleting any pools that become empty.\n\/\/ See filterSubpool for filtering details.","result":"Filter subpools .","score":[0,0.0228]}
{"code":"\/*is used to<extra_id_0>\r\nfunc filterSubpool(ghc githubClient, sp *subpool) *subpool {\r\n\tvar toKeep []PullRequest\r\n\tfor _, pr := range sp.prs {\r\n\t\tif !filterPR(ghc, sp, &pr) {\r\n\t\t\ttoKeep = append(toKeep, pr)\r\n\t\t}\r\n\t}\r\n\tif len(toKeep) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\tsp.prs = toKeep\r\n\treturn sp\r\n}","code-length":131,"reference":"\/\/ filterSubpool filters PRs from an initially identified subpool, returning the\n\/\/ filtered subpool.\n\/\/ If the subpool becomes empty 'nil' is returned to indicate that the subpool\n\/\/ should be deleted.","result":"Filter subpool.","score":[0.0,0.0647]}
{"code":"\/*is used to<extra_id_0>\r\nfunc poolPRMap(subpoolMap map[string]*subpool) map[string]PullRequest {\r\n\tprs := make(map[string]PullRequest)\r\n\tfor _, sp := range subpoolMap {\r\n\t\tfor _, pr := range sp.prs {\r\n\t\t\tprs[prKey(&pr)] = pr\r\n\t\t}\r\n\t}\r\n\treturn prs\r\n}","code-length":105,"reference":"\/\/ poolPRMap collects all subpool PRs into a map containing all pooled PRs.","result":"Generate the PR map.","score":[0,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc unsuccessfulContexts(contexts []Context, cc contextChecker, log *logrus.Entry) []Context {\r\n\tvar failed []Context\r\n\tfor _, ctx := range contexts {\r\n\t\tif string(ctx.Context) == statusContext {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif cc.IsOptional(string(ctx.Context)) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif ctx.State != githubql.StatusStateSuccess {\r\n\t\t\tfailed = append(failed, ctx)\r\n\t\t}\r\n\t}\r\n\tfor _, c := range cc.MissingRequiredContexts(contextsToStrings(contexts)) {\r\n\t\tfailed = append(failed, newExpectedContext(c))\r\n\t}\r\n\tlog.Debugf(\"from %d total contexts (%v) found %d failing contexts: %v\", len(contexts), contextsToStrings(contexts), len(failed), contextsToStrings(failed))\r\n\treturn failed\r\n}","code-length":232,"reference":"\/\/ unsuccessfulContexts determines which contexts from the list that we care about are\n\/\/ failed. For instance, we do not care about our own context.\n\/\/ If the branchProtection is set to only check for required checks, we will skip\n\/\/ all non-required tests. If required tests are missing from the list, they will be\n\/\/ added to the list of failed contexts.","result":"Check for missing required contexts.","score":[0.0,0.065]}
{"code":"\/*is used to<extra_id_0>\r\nfunc accumulate(presubmits map[int][]config.Presubmit, prs []PullRequest, pjs []prowapi.ProwJob, log *logrus.Entry) (successes, pendings, nones []PullRequest) {\r\n\tfor _, pr := range prs {\r\n\t\t\r\n\t\tpsStates := make(map[string]simpleState)\r\n\t\tfor _, pj := range pjs {\r\n\t\t\tif pj.Spec.Type != prowapi.PresubmitJob {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tif pj.Spec.Refs.Pulls[0].Number != int(pr.Number) {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tif pj.Spec.Refs.Pulls[0].SHA != string(pr.HeadRefOID) {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tname := pj.Spec.Context\r\n\t\t\toldState := psStates[name]\r\n\t\t\tnewState := toSimpleState(pj.Status.State)\r\n\t\t\tif oldState == failureState || oldState == \"\" {\r\n\t\t\t\tpsStates[name] = newState\r\n\t\t\t} else if oldState == pendingState && newState == successState {\r\n\t\t\t\tpsStates[name] = successState\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\toverallState := successState\r\n\t\tfor _, ps := range presubmits[int(pr.Number)] {\r\n\t\t\tif s, ok := psStates[ps.Context]; !ok {\r\n\t\t\t\toverallState = failureState\r\n\t\t\t\tlog.WithFields(pr.logFields()).Debugf(\"missing presubmit %s\", ps.Context)\r\n\t\t\t\tbreak\r\n\t\t\t} else if s == failureState {\r\n\t\t\t\toverallState = failureState\r\n\t\t\t\tlog.WithFields(pr.logFields()).Debugf(\"presubmit %s not passing\", ps.Context)\r\n\t\t\t\tbreak\r\n\t\t\t} else if s == pendingState {\r\n\t\t\t\tlog.WithFields(pr.logFields()).Debugf(\"presubmit %s pending\", ps.Context)\r\n\t\t\t\toverallState = pendingState\r\n\t\t\t}\r\n\t\t}\r\n\t\tif overallState == successState {\r\n\t\t\tsuccesses = append(successes, pr)\r\n\t\t} else if overallState == pendingState {\r\n\t\t\tpendings = append(pendings, pr)\r\n\t\t} else {\r\n\t\t\tnones = append(nones, pr)\r\n\t\t}\r\n\t}\r\n\treturn\r\n}","code-length":615,"reference":"\/\/ accumulate returns the supplied PRs sorted into three buckets based on their\n\/\/ accumulated state across the presubmits.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc tryMerge(mergeFunc func() error) (bool, error) {\r\n\tvar err error\r\n\tconst maxRetries = 3\r\n\tbackoff := time.Second * 4\r\n\tfor retry := 0; retry < maxRetries; retry++ {\r\n\t\tif err = mergeFunc(); err == nil {\r\n\t\t\t\r\n\t\t\treturn true, nil\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tok {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\treturn true, fmt.Errorf(\"PR was modified: %v\", err)\r\n\t\t} else if _, ok = err.(github.UnmergablePRBaseChangedError); ok {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tmodified: %v\", err)\r\n\t\t\tif retry+1 < maxRetries {\r\n\t\t\t\tsleep(backoff)\r\n\t\t\t\tbackoff *= 2\r\n\t\t\t}\r\n\t\t} else if _, ok = err.(github.UnauthorizedToPushError); ok {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\treturn false, fmt.Errorf(\"branch needs to be configured to allow this robot to push: %v\", err)\r\n\t\t} else if _, ok = err.(github.MergeCommitsForbiddenError); ok {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\treturn false, fmt.Errorf(\"Tide needs to be configured to use the 'rebase' merge method for this repo or the repo needs to allow merge commits: %v\", err)\r\n\t\t} else if _, ok = err.(github.UnmergablePRError); ok {\r\n\t\t\treturn true, fmt.Errorf(\"PR is unmergable. Do the Tide merge requirements match the GitHub settings for the repo? %v\", err)\r\n\t\t} else {\r\n\t\t\treturn true, err\r\n\t\t}\r\n\t}\r\n\t\r\n\treturn true, err\r\n}","code-length":479,"reference":"\/\/ tryMerge attempts 1 merge and returns a bool indicating if we should try\n\/\/ to merge the remaining PRs and possibly an error.","result":"Try to merge the PRs.","score":[0.0111,0.1697]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *changedFilesAgent) prChanges(pr *PullRequest) config.ChangedFilesProvider {\r\n\treturn func() ([]string, error) {\r\n\t\tcacheKey := changeCacheKey{\r\n\t\t\torg:    string(pr.Repository.Owner.Login),\r\n\t\t\trepo:   string(pr.Repository.Name),\r\n\t\t\tnumber: int(pr.Number),\r\n\t\t\tsha:    string(pr.HeadRefOID),\r\n\t\t}\r\n\t\tc.RLock()\r\n\t\tchangedFiles, ok := c.changeCache[cacheKey]\r\n\t\tif ok {\r\n\t\t\tc.RUnlock()\r\n\t\t\tc.Lock()\r\n\t\t\tc.nextChangeCache[cacheKey] = changedFiles\r\n\t\t\tc.Unlock()\r\n\t\t\treturn changedFiles, nil\r\n\t\t}\r\n\t\tif changedFiles, ok = c.nextChangeCache[cacheKey]; ok {\r\n\t\t\tc.RUnlock()\r\n\t\t\treturn changedFiles, nil\r\n\t\t}\r\n\t\tc.RUnlock()\r\n\t\t\r\n\t\tchanges, err := c.ghc.GetPullRequestChanges(\r\n\t\t\tstring(pr.Repository.Owner.Login),\r\n\t\t\tstring(pr.Repository.Name),\r\n\t\t\tint(pr.Number),\r\n\t\t)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"error getting PR changes for #%d: %v\", int(pr.Number), err)\r\n\t\t}\r\n\t\tchangedFiles = make([]string, 0, len(changes))\r\n\t\tfor _, change := range changes {\r\n\t\t\tchangedFiles = append(changedFiles, change.Filename)\r\n\t\t}\r\n\t\tc.Lock()\r\n\t\tc.nextChangeCache[cacheKey] = changedFiles\r\n\t\tc.Unlock()\r\n\t\treturn changedFiles, nil\r\n\t}\r\n}","code-length":462,"reference":"\/\/ prChanges gets the files changed by the PR, either from the cache or by\n\/\/ querying GitHub.","result":"Get the PR changes.","score":[0.0096,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *changedFilesAgent) prune() {\r\n\tc.Lock()\r\n\tdefer c.Unlock()\r\n\tc.changeCache = c.nextChangeCache\r\n\tc.nextChangeCache = make(map[changeCacheKey][]string)\r\n}","code-length":70,"reference":"\/\/ prune removes any cached file changes that were not used since the last prune.","result":"Prune the changed files cache.","score":[0.0325,0.1429]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) dividePool(pool map[string]PullRequest, pjs []prowapi.ProwJob) (map[string]*subpool, error) {\r\n\tsps := make(map[string]*subpool)\r\n\tfor _, pr := range pool {\r\n\t\torg := string(pr.Repository.Owner.Login)\r\n\t\trepo := string(pr.Repository.Name)\r\n\t\tbranch := string(pr.BaseRef.Name)\r\n\t\tbranchRef := string(pr.BaseRef.Prefix) + string(pr.BaseRef.Name)\r\n\t\tfn := poolKey(org, repo, branch)\r\n\t\tif sps[fn] == nil {\r\n\t\t\tsha, err := c.ghc.GetRef(org, repo, strings.TrimPrefix(branchRef, \"refs\/\"))\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\tsps[fn] = &subpool{\r\n\t\t\t\tlog: c.logger.WithFields(logrus.Fields{\r\n\t\t\t\t\t\"org\":      org,\r\n\t\t\t\t\t\"repo\":     repo,\r\n\t\t\t\t\t\"branch\":   branch,\r\n\t\t\t\t\t\"base-sha\": sha,\r\n\t\t\t\t}),\r\n\t\t\t\torg:    org,\r\n\t\t\t\trepo:   repo,\r\n\t\t\t\tbranch: branch,\r\n\t\t\t\tsha:    sha,\r\n\t\t\t}\r\n\t\t}\r\n\t\tsps[fn].prs = append(sps[fn].prs, pr)\r\n\t}\r\n\tfor _, pj := range pjs {\r\n\t\tif pj.Spec.Type != prowapi.PresubmitJob && pj.Spec.Type != prowapi.BatchJob {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tfn := poolKey(pj.Spec.Refs.Org, pj.Spec.Refs.Repo, pj.Spec.Refs.BaseRef)\r\n\t\tif sps[fn] == nil || pj.Spec.Refs.BaseSHA != sps[fn].sha {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tsps[fn].pjs = append(sps[fn].pjs, pj)\r\n\t}\r\n\treturn sps, nil\r\n}","code-length":553,"reference":"\/\/ dividePool splits up the list of pull requests and prow jobs into a group\n\/\/ per repo and branch. It only keeps ProwJobs that match the latest branch.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AggregateProfiles(profiles [][]*cover.Profile) ([]*cover.Profile, error) {\r\n\tsetProfiles := make([][]*cover.Profile, 0, len(profiles))\r\n\tfor _, p := range profiles {\r\n\t\tc := countToBoolean(p)\r\n\t\tsetProfiles = append(setProfiles, c)\r\n\t}\r\n\taggregateProfiles, err := MergeMultipleProfiles(setProfiles)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn aggregateProfiles, nil\r\n}","code-length":137,"reference":"\/\/ AggregateProfiles takes multiple coverage profiles and produces a new\n\/\/ coverage profile that counts the number of profiles that hit a block at least\n\/\/ once.","result":"Aggregate multiple profiles.","score":[0.0001,0.0203]}
{"code":"\/*is used to<extra_id_0>\r\nfunc countToBoolean(profile []*cover.Profile) []*cover.Profile {\r\n\tsetProfile := make([]*cover.Profile, 0, len(profile))\r\n\tfor _, p := range profile {\r\n\t\tpc := deepCopyProfile(*p)\r\n\t\tfor i := range pc.Blocks {\r\n\t\t\tif pc.Blocks[i].Count > 0 {\r\n\t\t\t\tpc.Blocks[i].Count = 1\r\n\t\t\t}\r\n\t\t}\r\n\t\tsetProfile = append(setProfile, &pc)\r\n\t}\r\n\treturn setProfile\r\n}","code-length":146,"reference":"\/\/ countToBoolean converts a profile containing hit counts to instead contain\n\/\/ only 1s or 0s.","result":"Convert the count to boolean.","score":[0.0266,0.1715]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewStorage(r storage.PersistenceLayer, storage string) (*Storage, error) {\r\n\ts := &Storage{\r\n\t\tresources: r,\r\n\t}\r\n\tif storage != \"\" {\r\n\t\tvar data struct {\r\n\t\t\tResources []common.Resource\r\n\t\t}\r\n\t\tbuf, err := ioutil.ReadFile(storage)\r\n\t\tif err == nil {\r\n\t\t\tlogrus.Infof(\"Current state: %s.\", string(buf))\r\n\t\t\terr = json.Unmarshal(buf, &data)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t} else if !os.IsNotExist(err) {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tlogrus.Info(\"Before adding resource loop\")\r\n\t\tfor _, res := range data.Resources {\r\n\t\t\tif err := s.AddResource(res); err != nil {\r\n\t\t\t\tlogrus.WithError(err).Errorf(\"Failed Adding Resources: %s - %s.\", res.Name, res.State)\r\n\t\t\t}\r\n\t\t\tlogrus.Infof(\"Successfully Added Resources: %s - %s.\", res.Name, res.State)\r\n\t\t}\r\n\t}\r\n\treturn s, nil\r\n}","code-length":321,"reference":"\/\/ NewStorage instantiates a new Storage with a PersistenceLayer implementation\n\/\/ If storage string is not empty, it will read resource data from the file","result":"Create a new storage object.","score":[0.0069,0.0652]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) AddResource(resource common.Resource) error {\r\n\treturn s.resources.Add(resource)\r\n}","code-length":40,"reference":"\/\/ AddResource adds a new resource","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) DeleteResource(name string) error {\r\n\treturn s.resources.Delete(name)\r\n}","code-length":38,"reference":"\/\/ DeleteResource deletes a resource if it exists, errors otherwise","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) UpdateResource(resource common.Resource) error {\r\n\treturn s.resources.Update(resource)\r\n}","code-length":40,"reference":"\/\/ UpdateResource updates a resource if it exists, errors otherwise","result":"Store the file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) GetResource(name string) (common.Resource, error) {\r\n\ti, err := s.resources.Get(name)\r\n\tif err != nil {\r\n\t\treturn common.Resource{}, err\r\n\t}\r\n\tvar res common.Resource\r\n\tres, err = common.ItemToResource(i)\r\n\tif err != nil {\r\n\t\treturn common.Resource{}, err\r\n\t}\r\n\treturn res, nil\r\n}","code-length":122,"reference":"\/\/ GetResource gets an existing resource, errors otherwise","result":"Retrieve the resource from storage.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) GetResources() ([]common.Resource, error) {\r\n\tvar resources []common.Resource\r\n\titems, err := s.resources.List()\r\n\tif err != nil {\r\n\t\treturn resources, err\r\n\t}\r\n\tfor _, i := range items {\r\n\t\tvar res common.Resource\r\n\t\tres, err = common.ItemToResource(i)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tresources = append(resources, res)\r\n\t}\r\n\tsort.Stable(common.ResourceByUpdateTime(resources))\r\n\treturn resources, nil\r\n}","code-length":169,"reference":"\/\/ GetResources list all resources","result":"Get the list of resources in the storage.","score":[0.1652,0.1887]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) SyncResources(data []common.Resource) error {\r\n\ts.resourcesLock.Lock()\r\n\tdefer s.resourcesLock.Unlock()\r\n\tresources, err := s.GetResources()\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Error(\"cannot find resources\")\r\n\t\treturn err\r\n\t}\r\n\tvar finalError error\r\n\t\r\n\tvalid := 0\r\n\tfor _, res := range resources {\r\n\t\t\r\n\t\tif res.Owner != \"\" {\r\n\t\t\tresources[valid] = res\r\n\t\t\tvalid++\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\ttoDelete := true\r\n\t\tfor _, newRes := range data {\r\n\t\t\tif res.Name == newRes.Name {\r\n\t\t\t\tresources[valid] = res\r\n\t\t\t\tvalid++\r\n\t\t\t\ttoDelete = false\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif toDelete {\r\n\t\t\tlogrus.Infof(\"Deleting resource %s\", res.Name)\r\n\t\t\tif err := s.DeleteResource(res.Name); err != nil {\r\n\t\t\t\tfinalError = multierror.Append(finalError, err)\r\n\t\t\t\tlogrus.WithError(err).Errorf(\"unable to delete resource %s\", res.Name)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tresources = resources[:valid]\r\n\t\r\n\tfor _, p := range data {\r\n\t\tfound := false\r\n\t\tfor idx := range resources {\r\n\t\t\texist := resources[idx]\r\n\t\t\tif p.Name == exist.Name {\r\n\t\t\t\tfound = true\r\n\t\t\t\tlogrus.Infof(\"Keeping resource %s\", p.Name)\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif !found {\r\n\t\t\tif p.State == \"\" {\r\n\t\t\t\tp.State = common.Free\r\n\t\t\t}\r\n\t\t\tlogrus.Infof(\"Adding resource %s\", p.Name)\r\n\t\t\tresources = append(resources, p)\r\n\t\t\tif err := s.AddResource(p); err != nil {\r\n\t\t\t\tlogrus.WithError(err).Errorf(\"unable to add resource %s\", p.Name)\r\n\t\t\t\tfinalError = multierror.Append(finalError, err)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn finalError\r\n}","code-length":588,"reference":"\/\/ SyncResources will update resources every 10 mins.\n\/\/ It will append newly added resources to ranch.Resources,\n\/\/ And try to remove newly deleted resources from ranch.Resources.\n\/\/ If the newly deleted resource is currently held by a user, the deletion will\n\/\/ yield to next update cycle.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseConfig(configPath string) ([]common.Resource, error) {\r\n\tfile, err := ioutil.ReadFile(configPath)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar data common.BoskosConfig\r\n\terr = yaml.Unmarshal(file, &data)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar resources []common.Resource\r\n\tfor _, entry := range data.Resources {\r\n\t\tresources = append(resources, common.NewResourcesFromConfig(entry)...)\r\n\t}\r\n\treturn resources, nil\r\n}","code-length":162,"reference":"\/\/ ParseConfig reads in configPath and returns a list of resource objects\n\/\/ on success.","result":"Parse the config file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc problemsInFiles(r *git.Repo, files map[string]string) (map[string][]string, error) {\r\n\tproblems := make(map[string][]string)\r\n\tfor f := range files {\r\n\t\tsrc, err := ioutil.ReadFile(filepath.Join(r.Dir, f))\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\t\r\n\t\trrorf(\"parsing as Bazel file %v\", err)\r\n\t\t}\r\n\t\tbeforeRewrite := build.Format(content)\r\n\t\tvar info build.RewriteInfo\r\n\t\tbuild.Rewrite(content, &info)\r\n\t\tndata := build.Format(content)\r\n\t\tif !bytes.Equal(src, ndata) && !bytes.Equal(src, beforeRewrite) {\r\n\t\t\t\r\n\t\t\tproblems[f] = uniqProblems(info.Log)\r\n\t\t}\r\n\t}\r\n\treturn problems, nil\r\n}","code-length":246,"reference":"\/\/ problemsInFiles runs buildifier on the files. It returns a map from the file to\n\/\/ a list of problems with that file.","result":"Detect problems in files.","score":[0.0033,0.0474]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPodLogArtifact(jobName string, buildID string, sizeLimit int64, ja jobAgent) (*PodLogArtifact, error) {\r\n\tif jobName == \"\" {\r\n\t\treturn nil, errInsufficientJobInfo\r\n\t}\r\n\tif buildID == \"\" {\r\n\t\treturn nil, errInsufficientJobInfo\r\n\t}\r\n\tif sizeLimit < 0 {\r\n\t\treturn nil, errInvalidSizeLimit\r\n\t}\r\n\treturn &PodLogArtifact{\r\n\t\tname:      jobName,\r\n\t\tbuildID:   buildID,\r\n\t\tsizeLimit: sizeLimit,\r\n\t\tjobAgent:  ja,\r\n\t}, nil\r\n}","code-length":170,"reference":"\/\/ NewPodLogArtifact creates a new PodLogArtifact","result":"Create a new artifact.","score":[0.274,0.5077]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *PodLogArtifact) CanonicalLink() string {\r\n\tq := url.Values{\r\n\t\t\"job\": []string{a.name},\r\n\t\t\"id\":  []string{a.buildID},\r\n\t}\r\n\tu := url.URL{\r\n\t\tPath:     \"\/log\",\r\n\t\tRawQuery: q.Encode(),\r\n\t}\r\n\treturn u.String()\r\n}","code-length":110,"reference":"\/\/ CanonicalLink returns a link to where pod logs are streamed","result":"Generate the canonical link.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *PodLogArtifact) ReadAt(p []byte, off int64) (n int, err error) {\r\n\tlogs, err := a.jobAgent.GetJobLog(a.name, a.buildID)\r\n\tif err != nil {\r\n\t\treturn 0, fmt.Errorf(\"error getting pod log: %v\", err)\r\n\t}\r\n\tr := bytes.NewReader(logs)\r\n\treadBytes, err := r.ReadAt(p, off)\r\n\tif err == io.EOF {\r\n\t\treturn readBytes, io.EOF\r\n\t}\r\n\tif err != nil {\r\n\t\treturn 0, fmt.Errorf(\"error reading pod logs: %v\", err)\r\n\t}\r\n\treturn readBytes, nil\r\n}","code-length":190,"reference":"\/\/ ReadAt implements reading a range of bytes from the pod logs endpoint","result":"Read the pod log file.","score":[0.0686,0.3074]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *PodLogArtifact) ReadAll() ([]byte, error) {\r\n\tsize, err := a.Size()\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error getting pod log size: %v\", err)\r\n\t}\r\n\tif size > a.sizeLimit {\r\n\t\treturn nil, lenses.ErrFileTooLarge\r\n\t}\r\n\tlogs, err := a.jobAgent.GetJobLog(a.name, a.buildID)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error getting pod log: %v\", err)\r\n\t}\r\n\treturn logs, nil\r\n}","code-length":168,"reference":"\/\/ ReadAll reads all available pod logs, failing if they are too large","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *PodLogArtifact) ReadAtMost(n int64) ([]byte, error) {\r\n\tlogs, err := a.jobAgent.GetJobLog(a.name, a.buildID)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error getting pod log: %v\", err)\r\n\t}\r\n\treader := bytes.NewReader(logs)\r\n\tvar byteCount int64\r\n\tvar p []byte\r\n\tfor byteCount < n {\r\n\t\tb, err := reader.ReadByte()\r\n\t\tif err == io.EOF {\r\n\t\t\treturn p, io.EOF\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"error reading pod log: %v\", err)\r\n\t\t}\r\n\t\tp = append(p, b)\r\n\t\tbyteCount++\r\n\t}\r\n\treturn p, nil\r\n}","code-length":231,"reference":"\/\/ ReadAtMost reads at most n bytes","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *PodLogArtifact) ReadTail(n int64) ([]byte, error) {\r\n\tlogs, err := a.jobAgent.GetJobLog(a.name, a.buildID)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error getting pod log tail: %v\", err)\r\n\t}\r\n\tsize := int64(len(logs))\r\n\tvar off int64\r\n\tif n > size {\r\n\t\toff = 0\r\n\t} else {\r\n\t\toff = size - n\r\n\t}\r\n\tp := make([]byte, n)\r\n\treadBytes, err := bytes.NewReader(logs).ReadAt(p, off)\r\n\tif err != nil && err != io.EOF {\r\n\t\treturn nil, fmt.Errorf(\"error reading pod log tail: %v\", err)\r\n\t}\r\n\treturn p[:readBytes], nil\r\n}","code-length":230,"reference":"\/\/ ReadTail reads the last n bytes of the pod log","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newProblems(cs []github.ReviewComment, ps map[string]map[int]lint.Problem) map[string]map[int]lint.Problem {\r\n\t\r\n\tres := make(map[string]map[int]lint.Problem)\r\n\tfor f, ls := range ps {\r\n\t\tres[f] = make(map[int]lint.Problem)\r\n\t\tfor l, p := range ls {\r\n\t\t\tres[f][l] = p\r\n\t\t}\r\n\t}\r\n\tfor _, c := range cs {\r\n\t\tif c.Position == nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif !strings.Contains(c.Body, commentTag) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tdelete(res[c.Path], *c.Position)\r\n\t}\r\n\treturn res\r\n}","code-length":220,"reference":"\/\/ newProblems compares the list of problems with the list of past comments on\n\/\/ the PR to decide which are new.","result":"Map[string]map[int]lint.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc problemsInFiles(r *git.Repo, files map[string]string) (map[string]map[int]lint.Problem, []github.DraftReviewComment) {\r\n\tproblems := make(map[string]map[int]lint.Problem)\r\n\tvar lintErrorComments []github.DraftReviewComment\r\n\tl := new(lint.Linter)\r\n\tfor f, patch := range files {\r\n\t\tproblems[f] = make(map[int]lint.Problem)\r\n\t\tsrc, err := ioutil.ReadFile(filepath.Join(r.Dir, f))\r\n\t\tif err != nil {\r\n\t\t\tlintErrorComments = append(lintErrorComments, github.DraftReviewComment{\r\n\t\t\t\tPath: f,\r\n\t\t\t\tBody: fmt.Sprintf(\"%v\", err),\r\n\t\t\t})\r\n\t\t}\r\n\t\tps, err := l.Lint(f, src)\r\n\t\tif err != nil {\r\n\t\t\t\r\n\t\t\terrLineIndexStart := strings.LastIndex(err.Error(), f) + len(f)\r\n\t\t\treNumber := regexp.MustCompile(`:([0-9]+):`)\r\n\t\t\tmatches := reNumber.FindStringSubmatch(err.Error()[errLineIndexStart:])\r\n\t\t\tnewComment := github.DraftReviewComment{\r\n\t\t\t\tPath: f,\r\n\t\t\t\tBody: err.Error(),\r\n\t\t\t}\r\n\t\t\tif len(matches) > 1 {\r\n\t\t\t\terrLineString := matches[1]\r\n\t\t\t\terrLine, errAtoi := strconv.Atoi(errLineString)\r\n\t\t\t\tif errAtoi == nil {\r\n\t\t\t\t\tnewComment.Position = errLine\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\treTrimError := regexp.MustCompile(`(:[0-9]+:[0-9]+: )`)\r\n\t\t\t\tmatches = reTrimError.FindStringSubmatch(err.Error())\r\n\t\t\t\tif len(matches) > 0 {\r\n\t\t\t\t\tnewComment.Body = err.Error()[len(matches[0])+errLineIndexStart:]\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tlintErrorComments = append(lintErrorComments, newComment)\r\n\t\t}\r\n\t\tal, err := AddedLines(patch)\r\n\t\tif err != nil {\r\n\t\t\tlintErrorComments = append(lintErrorComments,\r\n\t\t\t\tgithub.DraftReviewComment{\r\n\t\t\t\t\tPath: f,\r\n\t\t\t\t\tBody: fmt.Sprintf(\"computing added lines in %s: %v\", f, err),\r\n\t\t\t\t})\r\n\t\t}\r\n\t\tfor _, p := range ps {\r\n\t\t\tif pl, ok := al[p.Position.Line]; ok {\r\n\t\t\t\tproblems[f][pl] = p\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn problems, lintErrorComments\r\n}","code-length":689,"reference":"\/\/ problemsInFiles runs golint on the files. It returns a map from the file to\n\/\/ a map from the line in the patch to the problem.","result":"Code too long,keep in 512.","score":[0.003,0.0202]}
{"code":"\/*is used to<extra_id_0>\r\nfunc undoPreset(preset *config.Preset, labels map[string]string, pod *coreapi.PodSpec) {\r\n\t\r\n\tfor l, v := range preset.Labels {\r\n\t\tif v2, ok := labels[l]; !ok || v2 != v {\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n\t\r\n\tremoveEnvNames := sets.NewString()\r\n\tfor _, e1 := range preset.Env {\r\n\t\tremoveEnvNames.Insert(e1.Name)\r\n\t}\r\n\tremoveVolumeNames := sets.NewString()\r\n\tfor _, volume := range preset.Volumes {\r\n\t\tremoveVolumeNames.Insert(volume.Name)\r\n\t}\r\n\tremoveVolumeMountNames := sets.NewString()\r\n\tfor _, volumeMount := range preset.VolumeMounts {\r\n\t\tremoveVolumeMountNames.Insert(volumeMount.Name)\r\n\t}\r\n\t\r\n\tfilteredVolumes := []coreapi.Volume{}\r\n\tfor _, volume := range pod.Volumes {\r\n\t\tif !removeVolumeNames.Has(volume.Name) {\r\n\t\t\tfilteredVolumes = append(filteredVolumes, volume)\r\n\t\t}\r\n\t}\r\n\tpod.Volumes = filteredVolumes\r\n\t\r\n\tfor i := range pod.Containers {\r\n\t\tfilteredEnv := []coreapi.EnvVar{}\r\n\t\tfor _, env := range pod.Containers[i].Env {\r\n\t\t\tif !removeEnvNames.Has(env.Name) {\r\n\t\t\t\tfilteredEnv = append(filteredEnv, env)\r\n\t\t\t}\r\n\t\t}\r\n\t\tpod.Containers[i].Env = filteredEnv\r\n\t\tfilteredVolumeMounts := []coreapi.VolumeMount{}\r\n\t\tfor _, mount := range pod.Containers[i].VolumeMounts {\r\n\t\t\tif !removeVolumeMountNames.Has(mount.Name) {\r\n\t\t\t\tfilteredVolumeMounts = append(filteredVolumeMounts, mount)\r\n\t\t\t}\r\n\t\t}\r\n\t\tpod.Containers[i].VolumeMounts = filteredVolumeMounts\r\n\t}\r\n}","code-length":505,"reference":"\/\/ remove merged presets from a podspec","result":"UndoPreset is used to undo the preset.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc undoPresubmitPresets(presets []config.Preset, presubmit *config.Presubmit) {\r\n\tif presubmit.Spec == nil {\r\n\t\treturn\r\n\t}\r\n\tfor _, preset := range presets {\r\n\t\tundoPreset(&preset, presubmit.Labels, presubmit.Spec)\r\n\t}\r\n}","code-length":95,"reference":"\/\/ undo merged presets from loaded presubmit and its children","result":"Undo presubmit presets.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc yamlBytesStripNulls(yamlBytes []byte) []byte {\r\n\tnullRE := regexp.MustCompile(\"(?m)[\\n]+^[^\\n]+: null$\")\r\n\treturn nullRE.ReplaceAll(yamlBytes, []byte{})\r\n}","code-length":68,"reference":"\/\/ these are unnecessary, and make the config larger so we strip them out","result":"Strip nulls from yamlBytes.","score":[0,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc monitorDiskAndEvict(\r\n\tc *diskcache.Cache,\r\n\tinterval time.Duration,\r\n\tminPercentBlocksFree, evictUntilPercentBlocksFree float64,\r\n) {\r\n\tdiskRoot := c.DiskRoot()\r\n\t\r\n\tticker := time.NewTicker(interval)\r\n\tfor ; true; <-ticker.C {\r\n\t\tblocksFree, _, _, err := diskutil.GetDiskUsage(diskRoot)\r\n\t\tif err != nil {\r\n\t\t\tlogrus.WithError(err).Error(\"Failed to get disk usage!\")\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tlogger := logrus.WithFields(logrus.Fields{\r\n\t\t\t\"sync-loop\":   \"MonitorDiskAndEvict\",\r\n\t\t\t\"blocks-free\": blocksFree,\r\n\t\t})\r\n\t\tlogger.Info(\"tick\")\r\n\t\t\r\n\t\tif blocksFree < minPercentBlocksFree {\r\n\t\t\tlogger.Warn(\"Eviction triggered\")\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfiles := c.GetEntries()\r\n\t\t\tsort.Slice(files, func(i, j int) bool {\r\n\t\t\t\treturn files[i].LastAccess.Before(files[j].LastAccess)\r\n\t\t\t})\r\n\t\t\t\r\n\t\t\tfor blocksFree < evictUntilPercentBlocksFree {\r\n\t\t\t\tif len(files) < 1 {\r\n\t\t\t\t\tlogger.Fatal(\"Failed to find entries to evict!\")\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\tvar entry diskcache.EntryInfo\r\n\t\t\t\tentry, files = files[0], files[1:]\r\n\t\t\t\terr = c.Delete(c.PathToKey(entry.Path))\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tlogger.WithError(err).Errorf(\"Error deleting entry at path: %v\", entry.Path)\r\n\t\t\t\t} else {\r\n\t\t\t\t\tpromMetrics.FilesEvicted.Inc()\r\n\t\t\t\t\tpromMetrics.LastEvictedAccessAge.Set(time.Now().Sub(entry.LastAccess).Hours())\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\tblocksFree, _, _, err = diskutil.GetDiskUsage(diskRoot)\r\n\t\t\t\tlogger = logrus.WithFields(logrus.Fields{\r\n\t\t\t\t\t\"sync-loop\":   \"MonitorDiskAndEvict\",\r\n\t\t\t\t\t\"blocks-free\": blocksFree,\r\n\t\t\t\t})\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tlogrus.WithError(err).Error(\"Failed to get disk usage!\")\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tlogger.Info(\"Done evicting\")\r\n\t\t}\r\n\t}\r\n}","code-length":634,"reference":"\/\/ monitorDiskAndEvict loops monitoring the disk, evicting cache entries\n\/\/ when the disk passes either minPercentBlocksFree until the disk is above\n\/\/ evictUntilPercentBlocksFree","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *orgRepoConfig) difference(c2 *orgRepoConfig) *orgRepoConfig {\r\n\tres := &orgRepoConfig{\r\n\t\torgExceptions: make(map[string]sets.String),\r\n\t\trepos:         sets.NewString().Union(c.repos),\r\n\t}\r\n\tfor org, excepts1 := range c.orgExceptions {\r\n\t\tif excepts2, ok := c2.orgExceptions[org]; ok {\r\n\t\t\tres.repos.Insert(excepts2.Difference(excepts1).UnsortedList()...)\r\n\t\t} else {\r\n\t\t\texcepts := sets.NewString().Union(excepts1)\r\n\t\t\t\r\n\t\t\tfor _, repo := range c2.repos.UnsortedList() {\r\n\t\t\t\tif parts := strings.SplitN(repo, \"\/\", 2); len(parts) == 2 && parts[0] == org {\r\n\t\t\t\t\texcepts.Insert(repo)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tres.orgExceptions[org] = excepts\r\n\t\t}\r\n\t}\r\n\tres.repos = res.repos.Difference(c2.repos)\r\n\tfor _, repo := range res.repos.UnsortedList() {\r\n\t\tif parts := strings.SplitN(repo, \"\/\", 2); len(parts) == 2 {\r\n\t\t\tif excepts2, ok := c2.orgExceptions[parts[0]]; ok && !excepts2.Has(repo) {\r\n\t\t\t\tres.repos.Delete(repo)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn res\r\n}","code-length":395,"reference":"\/\/ difference returns a new orgRepoConfig that represents the set difference of\n\/\/ the repos specified by the receiver and the parameter orgRepoConfigs.","result":"Create a new config file to be merged into one.","score":[0.0418,0.0864]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *orgRepoConfig) union(c2 *orgRepoConfig) *orgRepoConfig {\r\n\tres := &orgRepoConfig{\r\n\t\torgExceptions: make(map[string]sets.String),\r\n\t\trepos:         sets.NewString(),\r\n\t}\r\n\tfor org, excepts1 := range c.orgExceptions {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tpruned := excepts1.Difference(c2.repos)\r\n\t\tif excepts2, ok := c2.orgExceptions[org]; ok {\r\n\t\t\tres.orgExceptions[org] = pruned.Intersection(excepts2.Difference(c.repos))\r\n\t\t} else {\r\n\t\t\tres.orgExceptions[org] = pruned\r\n\t\t}\r\n\t}\r\n\tfor org, excepts2 := range c2.orgExceptions {\r\n\t\t\r\n\t\tif _, exists := res.orgExceptions[org]; !exists {\r\n\t\t\tres.orgExceptions[org] = excepts2.Difference(c.repos)\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tfor _, repo := range c.repos.Union(c2.repos).UnsortedList() {\r\n\t\tparts := strings.SplitN(repo, \"\/\", 2)\r\n\t\tif len(parts) != 2 {\r\n\t\t\tlogrus.Warnf(\"org\/repo %q is formatted incorrectly\", repo)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif _, exists := res.orgExceptions[parts[0]]; !exists {\r\n\t\t\tres.repos.Insert(repo)\r\n\t\t}\r\n\t}\r\n\treturn res\r\n}","code-length":411,"reference":"\/\/ union returns a new orgRepoConfig that represents the set union of the\n\/\/ repos specified by the receiver and the parameter orgRepoConfigs","result":"Merge two configs.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc clearStaleComments(gc githubClient, log *logrus.Entry, pr *github.PullRequestEvent, prLabels sets.String, comments []github.IssueComment) error {\r\n\t\r\n\tif prMustFollowRelNoteProcess(gc, log, pr, prLabels, false) && !releaseNoteAlreadyAdded(prLabels) {\r\n\t\treturn nil\r\n\t}\r\n\tbotName, err := gc.BotName()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn gc.DeleteStaleComments(\r\n\t\tpr.Repo.Owner.Login,\r\n\t\tpr.Repo.Name,\r\n\t\tpr.Number,\r\n\t\tcomments,\r\n\t\tfunc(c github.IssueComment) bool {\r\n\t\t\treturn c.User.Login == botName &&\r\n\t\t\t\t(strings.Contains(c.Body, releaseNoteBody) ||\r\n\t\t\t\t\tstrings.Contains(c.Body, parentReleaseNoteBody))\r\n\t\t},\r\n\t)\r\n}","code-length":245,"reference":"\/\/ clearStaleComments deletes old comments that are no longer applicable.","result":"Clear stale comments.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc determineReleaseNoteLabel(body string) string {\r\n\tcomposedReleaseNote := strings.ToLower(strings.TrimSpace(getReleaseNote(body)))\r\n\tif composedReleaseNote == \"\" {\r\n\t\treturn ReleaseNoteLabelNeeded\r\n\t}\r\n\tif noneRe.MatchString(composedReleaseNote) {\r\n\t\treturn releaseNoteNone\r\n\t}\r\n\tif strings.Contains(composedReleaseNote, actionRequiredNote) {\r\n\t\treturn releaseNoteActionRequired\r\n\t}\r\n\treturn releaseNote\r\n}","code-length":135,"reference":"\/\/ determineReleaseNoteLabel returns the label to be added based on the contents of the 'release-note'\n\/\/ section of a PR's body text.","result":"Determine the release note label.","score":[0.008,0.0246]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getReleaseNote(body string) string {\r\n\tpotentialMatch := noteMatcherRE.FindStringSubmatch(body)\r\n\tif potentialMatch == nil {\r\n\t\treturn \"\"\r\n\t}\r\n\treturn strings.TrimSpace(potentialMatch[1])\r\n}","code-length":71,"reference":"\/\/ getReleaseNote returns the release note from a PR body\n\/\/ assumes that the PR body followed the PR template","result":"Generate the release notes.","score":[0.0083,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(boskosClient boskosClient) *Client {\r\n\treturn &Client{\r\n\t\tbasic:     boskosClient,\r\n\t\tresources: map[string]common.Resource{},\r\n\t}\r\n}","code-length":66,"reference":"\/\/ NewClient creates a new client from a boskosClient interface","result":"Create a client.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Acquire(rtype, state, dest string) (*common.Resource, error) {\r\n\tvar resourcesToRelease []common.Resource\r\n\treleaseOnFailure := func() {\r\n\t\tfor _, r := range resourcesToRelease {\r\n\t\t\tif err := c.basic.ReleaseOne(r.Name, common.Dirty); err != nil {\r\n\t\t\t\tlogrus.WithError(err).Warningf(\"failed to release resource %s\", r.Name)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tres, err := c.basic.Acquire(rtype, state, dest)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar leasedResources common.LeasedResources\r\n\tif err = res.UserData.Extract(LeasedResources, &leasedResources); err != nil {\r\n\t\tif _, ok := err.(*common.UserDataNotFound); !ok {\r\n\t\t\tlogrus.WithError(err).Errorf(\"cannot parse %s from User Data\", LeasedResources)\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\tresourcesToRelease = append(resourcesToRelease, *res)\r\n\tresources, err := c.basic.AcquireByState(res.Name, dest, leasedResources)\r\n\tif err != nil {\r\n\t\treleaseOnFailure()\r\n\t\treturn nil, err\r\n\t}\r\n\tresourcesToRelease = append(resourcesToRelease, resources...)\r\n\tc.updateResource(*res)\r\n\treturn res, nil\r\n}","code-length":377,"reference":"\/\/ Acquire gets a resource with associated leased resources","result":"Create a new resource.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) ReleaseOne(name, dest string) (allErrors error) {\r\n\tres, err := c.getResource(name)\r\n\tif err != nil {\r\n\t\tallErrors = err\r\n\t\treturn\r\n\t}\r\n\tresourceNames := []string{name}\r\n\tvar leasedResources common.LeasedResources\r\n\tif err := res.UserData.Extract(LeasedResources, &leasedResources); err != nil {\r\n\t\tif _, ok := err.(*common.UserDataNotFound); !ok {\r\n\t\t\tlogrus.WithError(err).Errorf(\"cannot parse %s from User Data\", LeasedResources)\r\n\t\t\tallErrors = multierror.Append(allErrors, err)\r\n\t\t\tif err := c.basic.ReleaseOne(name, dest); err != nil {\r\n\t\t\t\tlogrus.WithError(err).Warningf(\"failed to release resource %s\", name)\r\n\t\t\t\tallErrors = multierror.Append(allErrors, err)\r\n\t\t\t}\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n\tresourceNames = append(resourceNames, leasedResources...)\r\n\tfor _, n := range resourceNames {\r\n\t\tif err := c.basic.ReleaseOne(n, dest); err != nil {\r\n\t\t\tlogrus.WithError(err).Warningf(\"failed to release resource %s\", n)\r\n\t\t\tallErrors = multierror.Append(allErrors, err)\r\n\t\t}\r\n\t}\r\n\tc.deleteResource(name)\r\n\treturn\r\n}","code-length":371,"reference":"\/\/ ReleaseOne will release a resource as well as leased resources associated to it","result":"Release a resource.","score":[0.0104,0.1453]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) UpdateAll(state string) error {\r\n\treturn c.basic.UpdateAll(state)\r\n}","code-length":39,"reference":"\/\/ UpdateAll updates all the acquired resources with a given state","result":"Generate the code.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetGitHubClient(token string) *github.Client {\r\n\treturn github.NewClient(\r\n\t\toauth2.NewClient(\r\n\t\t\toauth2.NoContext,\r\n\t\t\toauth2.StaticTokenSource(&oauth2.Token{AccessToken: token}),\r\n\t\t),\r\n\t)\r\n}","code-length":83,"reference":"\/\/ GetGitHubClient creates a client for each token","result":"Get the github client.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetUsername(client *github.Client) (string, error) {\r\n\tuser, _, err := client.Users.Get(context.Background(), \"\")\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tif user.Login == nil {\r\n\t\treturn \"\", errors.New(\"Users.Get(\\\"\\\") returned empty login\")\r\n\t}\r\n\treturn *user.Login, nil\r\n}","code-length":112,"reference":"\/\/ GetUsername finds the login for each token","result":"Get the username of the user.","score":[0.1383,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CreateTokenHandler(tokenStream io.Reader, influxdb *InfluxDB) (*TokenHandler, error) {\r\n\ttoken, err := ioutil.ReadAll(tokenStream)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tclient := GetGitHubClient(strings.TrimSpace(string(token)))\r\n\tlogin, err := GetUsername(client)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &TokenHandler{\r\n\t\tgClient:  client,\r\n\t\tlogin:    login,\r\n\t\tinfluxdb: influxdb,\r\n\t}, nil\r\n}","code-length":163,"reference":"\/\/ CreateTokenHandler parses the token and create a handler","result":"Create a token handler.","score":[0.1088,0.3007]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CreateTokenHandlers(tokenFiles []string, influxdb *InfluxDB) ([]TokenHandler, error) {\r\n\ttokens := []TokenHandler{}\r\n\tfor _, tokenFile := range tokenFiles {\r\n\t\tf, err := os.Open(tokenFile)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"Can't open token-file (%s): %s\", tokenFile, err)\r\n\t\t}\r\n\t\ttoken, err := CreateTokenHandler(f, influxdb)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"Failed to create token (%s): %s\", tokenFile, err)\r\n\t\t}\r\n\t\ttokens = append(tokens, *token)\r\n\t}\r\n\treturn tokens, nil\r\n}","code-length":195,"reference":"\/\/ CreateTokenHandlers goes through the list of token files, and create handlers","result":"Create the token handlers.","score":[0.0514,0.1339]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *jobIndentifier) String() string {\r\n\treturn fmt.Sprintf(\"%s %s\/%s#%d\", i.job, i.organization, i.repository, i.pullRequest)\r\n}","code-length":59,"reference":"\/\/ String returns the string representation of a prow job identifier","result":"Generate the job name.","score":[0.066,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc TerminateOlderPresubmitJobs(pjc prowClient, log *logrus.Entry, pjs []prowapi.ProwJob,\r\n\tcleanup ProwJobResourcesCleanup) error {\r\n\tdupes := map[jobIndentifier]int{}\r\n\tfor i, pj := range pjs {\r\n\t\tif pj.Complete() || pj.Spec.Type != prowapi.PresubmitJob {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tji := jobIndentifier{\r\n\t\t\tjob:          pj.Spec.Job,\r\n\t\t\torganization: pj.Spec.Refs.Org,\r\n\t\t\trepository:   pj.Spec.Refs.Repo,\r\n\t\t\tpullRequest:  pj.Spec.Refs.Pulls[0].Number,\r\n\t\t}\r\n\t\tprev, ok := dupes[ji]\r\n\t\tif !ok {\r\n\t\t\tdupes[ji] = i\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tcancelIndex := i\r\n\t\tif (&pjs[prev].Status.StartTime).Before(&pj.Status.StartTime) {\r\n\t\t\tcancelIndex = prev\r\n\t\t\tdupes[ji] = i\r\n\t\t}\r\n\t\ttoCancel := pjs[cancelIndex]\r\n\t\t\r\n\t\t\r\n\t\tWithFields(ProwJobFields(&toCancel)).Warn(\"Cannot clean up job resources\")\r\n\t\t}\r\n\t\ttoCancel.SetComplete()\r\n\t\tprevState := toCancel.Status.State\r\n\t\ttoCancel.Status.State = prowapi.AbortedState\r\n\t\tlog.WithFields(ProwJobFields(&toCancel)).\r\n\t\t\tWithField(\"from\", prevState).\r\n\t\t\tWithField(\"to\", toCancel.Status.State).Info(\"Transitioning states\")\r\n\t\tnpj, err := pjc.ReplaceProwJob(toCancel.ObjectMeta.Name, toCancel)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tpjs[cancelIndex] = npj\r\n\t}\r\n\treturn nil\r\n}","code-length":519,"reference":"\/\/ TerminateOlderPresubmitJobs aborts all presubmit jobs from the given list that have a newer version. It calls\n\/\/ the cleanup callback for each job before updating its status as aborted.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PushMetrics(component, endpoint string, interval time.Duration) {\r\n\tsig := make(chan os.Signal, 1)\r\n\tsignal.Notify(sig, os.Interrupt, syscall.SIGTERM)\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase <-time.Tick(interval):\r\n\t\t\tif err := push.FromGatherer(component, push.HostnameGroupingKey(), endpoint, prometheus.DefaultGatherer); err != nil {\r\n\t\t\t\tlogrus.WithField(\"component\", component).WithError(err).Error(\"Failed to push metrics.\")\r\n\t\t\t}\r\n\t\tcase <-sig:\r\n\t\t\tlogrus.WithField(\"component\", component).Infof(\"Metrics pusher shutting down...\")\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":192,"reference":"\/\/ PushMetrics is meant to run in a goroutine and continuously push\n\/\/ metrics to the provided endpoint.","result":"Push metrics to the metrics server.","score":[0.0538,0.1879]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RateLimiter(controllerName string) workqueue.RateLimitingInterface {\r\n\trl := workqueue.NewMaxOfRateLimiter(\r\n\t\tworkqueue.NewItemExponentialFailureRateLimiter(5*time.Millisecond, 120*time.Second),\r\n\t\t&workqueue.BucketRateLimiter{Limiter: rate.NewLimiter(rate.Limit(1000), 50000)},\r\n\t)\r\n\treturn workqueue.NewNamedRateLimitingQueue(rl, controllerName)\r\n}","code-length":120,"reference":"\/\/ RateLimiter creates a ratelimiting queue for a given prow controller.","result":"Generate the controller name.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkExistingStatus(gc gitHubClient, l *logrus.Entry, org, repo, sha string) (string, error) {\r\n\tstatuses, err := gc.ListStatuses(org, repo, sha)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error listing pull request statuses: %v\", err)\r\n\t}\r\n\texistingStatus := \"\"\r\n\tfor _, status := range statuses {\r\n\t\tif status.Context != dcoContextName {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\texistingStatus = status.State\r\n\t\tbreak\r\n\t}\r\n\tl.Debugf(\"Existing DCO status context status is %q\", existingStatus)\r\n\treturn existingStatus, nil\r\n}","code-length":182,"reference":"\/\/ checkExistingStatus will retrieve the current status of the DCO context for\n\/\/ the provided SHA.","result":"Check if the existing status context status is already set.","score":[0.0784,0.0974]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkExistingLabels(gc gitHubClient, l *logrus.Entry, org, repo string, number int) (hasYesLabel, hasNoLabel bool, err error) {\r\n\tlabels, err := gc.GetIssueLabels(org, repo, number)\r\n\tif err != nil {\r\n\t\treturn false, false, fmt.Errorf(\"error getting pull request labels: %v\", err)\r\n\t}\r\n\tfor _, l := range labels {\r\n\t\tif l.Name == dcoYesLabel {\r\n\t\t\thasYesLabel = true\r\n\t\t}\r\n\t\tif l.Name == dcoNoLabel {\r\n\t\t\thasNoLabel = true\r\n\t\t}\r\n\t}\r\n\treturn hasYesLabel, hasNoLabel, nil\r\n}","code-length":190,"reference":"\/\/ checkExistingLabels will check the provided PR for the dco sign off labels,\n\/\/ returning bool's indicating whether the 'yes' and the 'no' label are present.","result":"Check existing labels.","score":[0,0.0211]}
{"code":"\/*is used to<extra_id_0>\r\nfunc handle(gc gitHubClient, cp commentPruner, log *logrus.Entry, org, repo string, pr github.PullRequest, addComment bool) error {\r\n\tl := log.WithField(\"pr\", pr.Number)\r\n\tcommitsMissingDCO, err := checkCommitMessages(gc, l, org, repo, pr.Number)\r\n\tif err != nil {\r\n\t\tl.WithError(err).Infof(\"Error running DCO check against commits in PR\")\r\n\t\treturn err\r\n\t}\r\n\texistingStatus, err := checkExistingStatus(gc, l, org, repo, pr.Head.SHA)\r\n\tif err != nil {\r\n\t\tl.WithError(err).Infof(\"Error checking existing PR status\")\r\n\t\treturn err\r\n\t}\r\n\thasYesLabel, hasNoLabel, err := checkExistingLabels(gc, l, org, repo, pr.Number)\r\n\tif err != nil {\r\n\t\tl.WithError(err).Infof(\"Error checking existing PR labels\")\r\n\t\treturn err\r\n\t}\r\n\treturn takeAction(gc, cp, l, org, repo, pr, commitsMissingDCO, existingStatus, hasYesLabel, hasNoLabel, addComment)\r\n}","code-length":298,"reference":"\/\/ 1. Check commit messages in the pull request for the sign-off string\n\/\/ 2. Check the existing status context value\n\/\/ 3. Check the existing PR labels\n\/\/ 4. If signed off, apply appropriate labels and status context.\n\/\/ 5. If not signed off, apply appropriate labels and status context and add a comment.","result":"Handle PRs with DCO.","score":[0,0.01]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MarkdownSHAList(org, repo string, list []github.GitCommit) string {\r\n\tlines := make([]string, len(list))\r\n\tlineFmt := \"- [%s](https:\r\n\tfor i, commit := range list {\r\n\t\tif commit.SHA == \"\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tshortSHA := commit.SHA\r\n\t\tif len(shortSHA) > 7 {\r\n\t\t\tshortSHA = shortSHA[:7]\r\n\t\t}\r\n\t\t\r\n\t\tmessage := strings.Split(commit.Message, \"\\n\")[0]\r\n\t\tlines[i] = fmt.Sprintf(lineFmt, shortSHA, org, repo, commit.SHA, message)\r\n\t}\r\n\treturn strings.Join(lines, \"\\n\")\r\n}","code-length":205,"reference":"\/\/ MardkownSHAList prints the list of commits in a markdown-friendly way.","result":"Generate the markdown.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PathForSpec(spec *downwardapi.JobSpec, pathSegment RepoPathBuilder) string {\r\n\tswitch spec.Type {\r\n\tcase prowapi.PeriodicJob, prowapi.PostsubmitJob:\r\n\t\treturn path.Join(NonPRLogs, spec.Job, spec.BuildID)\r\n\tcase prowapi.PresubmitJob:\r\n\t\treturn path.Join(PRLogs, \"pull\", pathSegment(spec.Refs.Org, spec.Refs.Repo), strconv.Itoa(spec.Refs.Pulls[0].Number), spec.Job, spec.BuildID)\r\n\tcase prowapi.BatchJob:\r\n\t\treturn path.Join(PRLogs, \"pull\", \"batch\", spec.Job, spec.BuildID)\r\n\tdefault:\r\n\t\tlogrus.Fatalf(\"unknown job spec type: %v\", spec.Type)\r\n\t}\r\n\treturn \"\"\r\n}","code-length":225,"reference":"\/\/ PathForSpec determines the GCS path prefix for files uploaded\n\/\/ for a specific job spec","result":"Generate the path for the job spec.","score":[0.0631,0.1325]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AliasForSpec(spec *downwardapi.JobSpec) string {\r\n\tswitch spec.Type {\r\n\tcase prowapi.PeriodicJob, prowapi.PostsubmitJob, prowapi.BatchJob:\r\n\t\treturn \"\"\r\n\tcase prowapi.PresubmitJob:\r\n\t\treturn path.Join(PRLogs, \"directory\", spec.Job, fmt.Sprintf(\"%s.txt\", spec.BuildID))\r\n\tdefault:\r\n\t\tlogrus.Fatalf(\"unknown job spec type: %v\", spec.Type)\r\n\t}\r\n\treturn \"\"\r\n}","code-length":150,"reference":"\/\/ AliasForSpec determines the GCS path aliases for a job spec","result":"Generate the alias for the job spec.","score":[0.12,0.1415]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RootForSpec(spec *downwardapi.JobSpec) string {\r\n\tswitch spec.Type {\r\n\tcase prowapi.PeriodicJob, prowapi.PostsubmitJob:\r\n\t\treturn path.Join(NonPRLogs, spec.Job)\r\n\tcase prowapi.PresubmitJob, prowapi.BatchJob:\r\n\t\treturn path.Join(PRLogs, \"directory\", spec.Job)\r\n\tdefault:\r\n\t\tlogrus.Errorf(\"unknown job spec type: %v\", spec.Type)\r\n\t}\r\n\treturn \"\"\r\n}","code-length":146,"reference":"\/\/ RootForSpec determines the root GCS path for storing artifacts about\n\/\/ the provided job.","result":"Generate the root for the job.","score":[0.0766,0.2638]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSingleDefaultRepoPathBuilder(defaultOrg, defaultRepo string) RepoPathBuilder {\r\n\treturn func(org, repo string) string {\r\n\t\tif org == defaultOrg && repo == defaultRepo {\r\n\t\t\treturn \"\"\r\n\t\t}\r\n\t\t\r\n\t\trepo = strings.Replace(repo, \"\/\", \"_\", -1)\r\n\t\treturn fmt.Sprintf(\"%s_%s\", org, repo)\r\n\t}\r\n}","code-length":114,"reference":"\/\/ NewSingleDefaultRepoPathBuilder returns a builder that handles the legacy path\n\/\/ encoding where a path will contain org and repo for all but one default repo","result":"Create a single default repo path builder.","score":[0.018,0.131]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewExplicitRepoPathBuilder() RepoPathBuilder {\r\n\treturn func(org, repo string) string {\r\n\t\t\r\n\t\trepo = strings.Replace(repo, \"\/\", \"_\", -1)\r\n\t\treturn fmt.Sprintf(\"%s_%s\", org, repo)\r\n\t}\r\n}","code-length":80,"reference":"\/\/ NewExplicitRepoPathBuilder returns a builder that handles the path encoding\n\/\/ where a path will always have an explicit \"org_repo\" path segment","result":"Create a new RepoPathBuilder.","score":[0.0035,0.0248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterSourceOrDie(name string, src IssueSource) {\r\n\tif _, ok := sources[name]; ok {\r\n\t\tglog.Fatalf(\"Cannot register an IssueSource with name %q, already exists!\", name)\r\n\t}\r\n\tsources[name] = src\r\n\tglog.Infof(\"Registered issue source '%s'.\", name)\r\n}","code-length":96,"reference":"\/\/ RegisterSourceOrDie registers a source of auto-filed issues.","result":"Register a source.","score":[0.0771,0.25]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *IssueCreator) CreateAndSync() {\r\n\tvar err error\r\n\tif err = c.initialize(); err != nil {\r\n\t\tglog.Fatalf(\"Error initializing IssueCreator: %v.\", err)\r\n\t}\r\n\tglog.Info(\"IssueCreator initialization complete.\")\r\n\tfor srcName, src := range sources {\r\n\t\tglog.Infof(\"Generating issues from source: %s.\", srcName)\r\n\t\tvar issues []Issue\r\n\t\tif issues, err = src.Issues(c); err != nil {\r\n\t\t\tglog.Errorf(\"Error generating issues. Source: %s Msg: %v.\", srcName, err)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tglog.Infof(\"Syncing issues from source: %s.\", srcName)\r\n\t\tcreated := 0\r\n\t\tfor _, issue := range issues {\r\n\t\t\tif c.sync(issue) {\r\n\t\t\t\tcreated++\r\n\t\t\t}\r\n\t\t}\r\n\t\tglog.Infof(\r\n\t\t\t\"Created issues for %d of the %d issues synced from source: %s.\",\r\n\t\t\tcreated,\r\n\t\t\tlen(issues),\r\n\t\t\tsrcName,\r\n\t\t)\r\n\t}\r\n}","code-length":327,"reference":"\/\/ CreateAndSync is the main workhorse function of IssueCreator. It initializes the IssueCreator,\n\/\/ asks each source for its issues to sync, and syncs the issues.","result":"Generate code for the generated code.","score":[0.0082,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *IssueCreator) loadCache() error {\r\n\tuser, err := c.client.GetUser(\"\")\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to fetch the User struct for the current authenticated user. errmsg: %v\", err)\r\n\t}\r\n\tif user == nil {\r\n\t\treturn fmt.Errorf(\"received a nil User struct pointer when trying to look up the currently authenticated user\")\r\n\t}\r\n\tif user.Login == nil {\r\n\t\treturn fmt.Errorf(\"the user struct for the currently authenticated user does not specify a login\")\r\n\t}\r\n\tc.authorName = *user.Login\r\n\t\r\n\tif validLabels, err := c.client.GetRepoLabels(c.org, c.project); err != nil {\r\n\t\tc.validLabels = nil\r\n\t\tglog.Errorf(\"Failed to retrieve the list of valid labels for repo '%s\/%s'. Allowing all labels. errmsg: %v\\n\", c.org, c.project, err)\r\n\t} else {\r\n\t\tc.validLabels = make([]string, 0, len(validLabels))\r\n\t\tfor _, label := range validLabels {\r\n\t\t\tif label.Name != nil && *label.Name != \"\" {\r\n\t\t\t\tc.validLabels = append(c.validLabels, *label.Name)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\tif collaborators, err := c.client.GetCollaborators(c.org, c.project); err != nil {\r\n\t\tc.Collaborators = nil\r\n\t\tglog.Errorf(\"Failed to retrieve the list of valid collaborators for repo '%s\/%s'. Allowing all assignees. errmsg: %v\\n\", c.org, c.project, err)\r\n\t} else {\r\n\t\tc.Collaborators = make([]string, 0, len(collaborators))\r\n\t\tfor _, user := range collaborators {\r\n\t\t\tif user.Login != nil && *user.Login != \"\" {\r\n\t\t\t\tc.Collaborators = append(c.Collaborators, strings.ToLower(*user.Login))\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\tissues, err := c.client.GetIssues(\r\n\t\tc.org,\r\n\t\tc.project,\r\n\t\t&github.IssueListByRepoOptions{\r\n\t\t\tState:   \"all\",\r\n\t\t\tCreator: c.authorName,\r\n\t\t},\r\n\t)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to refresh the list of all issues created by %s in repo '%s\/%s'. errmsg: %v\", c.authorName, c.org, c.project, err)\r\n\t}\r\n\tif len(issues) == 0 {\r\n\t\tglog.Warningf(\"IssueCreator found no issues in the repo '%s\/%s' authored by '%s'.\\n\", c.org, c.project, c.authorName)\r\n\t}\r\n\tc.allIssues = make(map[int]*github.Issue)\r\n\tfor _, i := range issues {\r\n\t\tc.allIssues[*i.Number] = i\r\n\t}\r\n\treturn nil\r\n}","code-length":784,"reference":"\/\/ loadCache loads the valid labels for the repo, the currently authenticated user, and the issue cache from github.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc setIntersect(a, b []string) (filtered, removed []string) {\r\n\tfor _, elemA := range a {\r\n\t\tfound := false\r\n\t\tfor _, elemB := range b {\r\n\t\t\tif elemA == elemB {\r\n\t\t\t\tfound = true\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif found {\r\n\t\t\tfiltered = append(filtered, elemA)\r\n\t\t} else {\r\n\t\t\tremoved = append(removed, elemA)\r\n\t\t}\r\n\t}\r\n\treturn\r\n}","code-length":148,"reference":"\/\/ setIntersect removes any elements from the first list that are not in the second, returning the\n\/\/ new set and the removed elements.","result":"Set the intersection of two sets.","score":[0.0096,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *IssueCreator) sync(issue Issue) bool {\r\n\t\r\n\tid := issue.ID()\r\n\tvar closedIssues []*github.Issue\r\n\tfor _, i := range c.allIssues {\r\n\t\tif strings.Contains(*i.Body, id) {\r\n\t\t\tswitch *i.State {\r\n\t\t\tcase \"open\":\r\n\t\t\t\t\r\n\t\t\t\treturn false\r\n\t\t\tcase \"closed\":\r\n\t\t\t\tclosedIssues = append(closedIssues, i)\r\n\t\t\tdefault:\r\n\t\t\t\tglog.Errorf(\"Unrecognized issue state '%s' for issue #%d. Ignoring this issue.\\n\", *i.State, *i.Number)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\tbody := issue.Body(closedIssues)\r\n\tif body == \"\" {\r\n\t\t\r\n\t\tglog.Infof(\"Issue aborted sync by providing \\\"\\\" (empty) body. ID: %s.\", id)\r\n\t\treturn false\r\n\t}\r\n\tif !strings.Contains(body, id) {\r\n\t\tglog.Fatalf(\"Programmer error: The following body text does not contain id '%s'.\\n%s\\n\", id, body)\r\n\t}\r\n\ttitle := issue.Title()\r\n\towners := issue.Owners()\r\n\tif c.Collaborators != nil {\r\n\t\tvar removedOwners []string\r\n\t\towners, removedOwners = setIntersect(owners, c.Collaborators)\r\n\t\tif len(removedOwners) > 0 {\r\n\t\t\tglog.Errorf(\"Filtered the following invalid assignees from issue %q: %q.\", title, removedOwners)\r\n\t\t}\r\n\t}\r\n\tlabels := issue.Labels()\r\n\tif prio, ok := issue.Priority(); ok {\r\n\t\tlabels = append(labels, \"priority\/\"+prio)\r\n\t}\r\n\tif c.validLabels != nil {\r\n\t\tvar removedLabels []string\r\n\t\tlabels, removedLabels = setIntersect(labels, c.validLabels)\r\n\t\tif len(removedLabels) > 0 {\r\n\t\t\tglog.Errorf(\"Filtered the following invalid labels from issue %q: %q.\", title, removedLabels)\r\n\t\t}\r\n\t}\r\n\tglog.Infof(\"Create Issue: %q Assigned to: %q\\n\", title, owners)\r\n\tif c.dryRun {\r\n\t\treturn true\r\n\t}\r\n\tcreated, err := c.client.CreateIssue(c.org, c.project, title, body, labels, owners)\r\n\tif err != nil {\r\n\t\tglog.Errorf(\"Failed to create a new github issue for issue ID '%s'.\\n\", id)\r\n\t\treturn false\r\n\t}\r\n\tc.allIssues[*created.Number] = created\r\n\treturn true\r\n}","code-length":696,"reference":"\/\/ sync checks to see if an issue is already on github and tries to create a new issue for it if it is not.\n\/\/ True is returned iff a new issue is created.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetAWSCreds(r *common.Resource) (credentials.Value, error) {\r\n\tval := credentials.Value{}\r\n\tif r.Type != ResourceType {\r\n\t\treturn val, fmt.Errorf(\"Wanted resource of type %q, got %q\", ResourceType, r.Type)\r\n\t}\r\n\taccessKey, ok := r.UserData.Map.Load(UserDataAccessIDKey)\r\n\tif !ok {\r\n\t\treturn val, errors.New(\"No Access Key ID in UserData\")\r\n\t}\r\n\tsecretKey, ok := r.UserData.Map.Load(UserDataSecretAccessKey)\r\n\tif !ok {\r\n\t\treturn val, errors.New(\"No Secret Access Key in UserData\")\r\n\t}\r\n\tval.AccessKeyID = accessKey.(string)\r\n\tval.SecretAccessKey = secretKey.(string)\r\n\treturn val, nil\r\n}","code-length":217,"reference":"\/\/ GetAWSCreds tries to fetch AWS credentials from a resource","result":"Get the AWS credentials from the service provider.","score":[0.2228,0.3827]}
{"code":"\/*is used to<extra_id_0>\r\nfunc stopper() chan struct{} {\r\n\tstop := make(chan struct{})\r\n\tc := make(chan os.Signal, 2)\r\n\tsignal.Notify(c, os.Interrupt, syscall.SIGTERM)\r\n\tgo func() {\r\n\t\t<-c\r\n\t\tlogrus.Warn(\"Interrupt received, attempting clean shutdown...\")\r\n\t\tclose(stop)\r\n\t\t<-c\r\n\t\tlogrus.Error(\"Second interrupt received, force exiting...\")\r\n\t\tos.Exit(1)\r\n\t}()\r\n\treturn stop\r\n}","code-length":146,"reference":"\/\/ stopper returns a channel that remains open until an interrupt is received.","result":"Stop the server.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newPipelineConfig(cfg rest.Config, stop chan struct{}) (*pipelineConfig, error) {\r\n\tbc, err := pipelineset.NewForConfig(&cfg)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\t\r\n\tif _, err := bc.TektonV1alpha1().PipelineRuns(\"\").List(metav1.ListOptions{Limit: 1}); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tbif := pipelineinfo.NewSharedInformerFactory(bc, 30*time.Minute)\r\n\tbif.Tekton().V1alpha1().PipelineRuns().Lister()\r\n\tgo bif.Start(stop)\r\n\treturn &pipelineConfig{\r\n\t\tclient:   bc,\r\n\t\tinformer: bif.Tekton().V1alpha1().PipelineRuns(),\r\n\t}, nil\r\n}","code-length":227,"reference":"\/\/ newPipelineConfig returns a client and informer capable of mutating and monitoring the specified config.","result":"Create a new pipeline config.","score":[0.0387,0.0714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *KubernetesClientOptions) KubeClient() (kubernetes.Interface, error) {\r\n\treturn kube.GetKubernetesClient(o.masterURL, o.kubeConfig)\r\n}","code-length":55,"reference":"\/\/ KubeClient returns a Kubernetes client.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *KubernetesClientOptions) ProwJobClient() (versioned.Interface, error) {\r\n\treturn kube.GetProwJobClient(o.masterURL, o.kubeConfig)\r\n}","code-length":57,"reference":"\/\/ ProwJobClient returns a Kubernetes client.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (bucket gcsBucket) resolveSymLink(symLink string) (string, error) {\r\n\tdata, err := bucket.readObject(symLink)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"failed to read %s: %v\", symLink, err)\r\n\t}\r\n\tplaceAllString(u, \"\"), nil\r\n}","code-length":94,"reference":"\/\/ resolve sym links into the actual log directory for a particular test run","result":"Resolve the symlink.","score":[0.0104,0.0775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc readJSON(bucket storageBucket, key string, data interface{}) error {\r\n\trawData, err := bucket.readObject(key)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to read %s: %v\", key, err)\r\n\t}\r\n\terr = json.Unmarshal(rawData, &data)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to parse %s: %v\", key, err)\r\n\t}\r\n\treturn nil\r\n}","code-length":132,"reference":"\/\/ reads specified JSON file in to `data`","result":"Read a JSON object.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (bucket gcsBucket) listSubDirs(prefix string) ([]string, error) {\r\n\tif !strings.HasSuffix(prefix, \"\/\") {\r\n\t\tprefix += \"\/\"\r\n\t}\r\n\tdirs := []string{}\r\n\tit := bucket.Objects(context.Background(), &storage.Query{\r\n\t\tPrefix:    prefix,\r\n\t\tDelimiter: \"\/\",\r\n\t})\r\n\tfor {\r\n\t\tattrs, err := it.Next()\r\n\t\tif err == iterator.Done {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn dirs, err\r\n\t\t}\r\n\t\tif attrs.Prefix != \"\" {\r\n\t\t\tdirs = append(dirs, attrs.Prefix)\r\n\t\t}\r\n\t}\r\n\treturn dirs, nil\r\n}","code-length":206,"reference":"\/\/ Lists the GCS \"directory paths\" immediately under prefix.","result":"List subdirectories in a bucket.","score":[0,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (bucket gcsBucket) listAll(prefix string) ([]string, error) {\r\n\tkeys := []string{}\r\n\tit := bucket.Objects(context.Background(), &storage.Query{\r\n\t\tPrefix: prefix,\r\n\t})\r\n\tfor {\r\n\t\tattrs, err := it.Next()\r\n\t\tif err == iterator.Done {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn keys, err\r\n\t\t}\r\n\t\tkeys = append(keys, attrs.Name)\r\n\t}\r\n\treturn keys, nil\r\n}","code-length":153,"reference":"\/\/ Lists all GCS keys with given prefix.","result":"List all objects in a bucket.","score":[0.1383,0.2404]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (bucket gcsBucket) listBuildIDs(root string) ([]int64, error) {\r\n\tids := []int64{}\r\n\tif strings.HasPrefix(root, logsPrefix) {\r\n\t\tdirs, err := bucket.listSubDirs(root)\r\n\t\tif err != nil {\r\n\t\t\treturn ids, fmt.Errorf(\"failed to list GCS directories: %v\", err)\r\n\t\t}\r\n\t\tfor _, dir := range dirs {\r\n\t\t\ti, err := strconv.ParseInt(path.Base(dir), 10, 64)\r\n\t\t\tif err == nil {\r\n\t\t\t\tids = append(ids, i)\r\n\t\t\t} else {\r\n\t\t\t\tlogrus.Warningf(\"unrecognized directory name (expected int64): %s\", dir)\r\n\t\t\t}\r\n\t\t}\r\n\t} else {\r\n\t\tkeys, err := bucket.listAll(root)\r\n\t\tif err != nil {\r\n\t\t\treturn ids, fmt.Errorf(\"failed to list GCS keys: %v\", err)\r\n\t\t}\r\n\t\tfor _, key := range keys {\r\n\t\t\tmatches := linkRe.FindStringSubmatch(key)\r\n\t\t\tif len(matches) == 2 {\r\n\t\t\t\ti, err := strconv.ParseInt(matches[1], 10, 64)\r\n\t\t\t\tif err == nil {\r\n\t\t\t\t\tids = append(ids, i)\r\n\t\t\t\t} else {\r\n\t\t\t\t\tlogrus.Warningf(\"unrecognized file name (expected <int64>.txt): %s\", key)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn ids, nil\r\n}","code-length":404,"reference":"\/\/ Gets all build ids for a job.","result":"List build IDs in the bucket.","score":[0.1383,0.2404]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FilterProfilePaths(profile []*cover.Profile, paths []string, include bool) ([]*cover.Profile, error) {\r\n\tparenPaths := make([]string, len(paths))\r\n\tfor i, path := range paths {\r\n\t\tparenPaths[i] = \"(\" + path + \")\"\r\n\t}\r\n\tjoined := strings.Join(parenPaths, \"|\")\r\n\tre, err := regexp.Compile(joined)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tresult := make([]*cover.Profile, 0, len(profile))\r\n\tfor _, p := range profile {\r\n\t\tif re.MatchString(p.FileName) == include {\r\n\t\t\tresult = append(result, p)\r\n\t\t}\r\n\t}\r\n\treturn result, nil\r\n}","code-length":208,"reference":"\/\/ FilterProfilePaths produces a new profile that removes either everything matching or everything\n\/\/ not matching the provided paths, depending on the value of include.\n\/\/ Paths are interpreted as regular expressions.\n\/\/ If include is true, paths is treated as a whitelist; otherwise it is treated as a blacklist.","result":"Filter profile by path.","score":[0.0,0.011]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadSecrets(paths []string) (map[string][]byte, error) {\r\n\tsecretsMap := make(map[string][]byte, len(paths))\r\n\tfor _, path := range paths {\r\n\t\tsecretValue, err := LoadSingleSecret(path)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tsecretsMap[path] = secretValue\r\n\t}\r\n\treturn secretsMap, nil\r\n}","code-length":124,"reference":"\/\/ LoadSecrets loads multiple paths of secrets and add them in a map.","result":"Load secrets.","score":[0,0.042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadSingleSecret(path string) ([]byte, error) {\r\n\tb, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error reading %s: %v\", path, err)\r\n\t}\r\n\treturn bytes.TrimSpace(b), nil\r\n}","code-length":88,"reference":"\/\/ LoadSingleSecret reads and returns the value of a single file.","result":"Load a single secret.","score":[0.0785,0.182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Bool) Set(s string) error {\r\n\tv, err := strconv.ParseBool(s)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tb.Explicit = true\r\n\tb.Value = v\r\n\treturn nil\r\n}","code-length":78,"reference":"\/\/ Set the bool according to the string.","result":"Set the value of the field.","score":[0.2165,0.3276]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewOpener(ctx context.Context, creds string) (Opener, error) {\r\n\tvar options []option.ClientOption\r\n\tif creds != \"\" {\r\n\t\toptions = append(options, option.WithCredentialsFile(creds))\r\n\t}\r\n\tclient, err := storage.NewClient(ctx, options...)\r\n\tif err != nil {\r\n\t\tif creds != \"\" {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tlogrus.WithError(err).Debug(\"Cannot load application default gcp credentials\")\r\n\t\tclient = nil\r\n\t}\r\n\treturn opener{gcs: client}, nil\r\n}","code-length":161,"reference":"\/\/ NewOpener returns an opener that can read GCS and local paths.","result":"Create a new opener.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsNotExist(err error) bool {\r\n\treturn os.IsNotExist(err) || err == storage.ErrObjectNotExist\r\n}","code-length":39,"reference":"\/\/ IsNotExist will return true if the error is because the object does not exist.","result":"Detect the error type.","score":[0.0289,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LogClose(c io.Closer) {\r\n\tif err := c.Close(); err != nil {\r\n\t\tlogrus.WithError(err).Error(\"Failed to close\")\r\n\t}\r\n}","code-length":57,"reference":"\/\/ LogClose will attempt a close an log any error","result":"Log the close of a file.","score":[0.1179,0.1562]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o opener) Writer(ctx context.Context, path string) (io.WriteCloser, error) {\r\n\tg, err := o.openGCS(path)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"bad gcs path: %v\", err)\r\n\t}\r\n\tif g == nil {\r\n\t\treturn os.Create(path)\r\n\t}\r\n\treturn g.NewWriter(ctx), nil\r\n}","code-length":118,"reference":"\/\/ Writer returns a writer that overwrites the path.","result":"Create a file.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gac *GitHubOAuthConfig) InitGitHubOAuthConfig(cookie *sessions.CookieStore) {\r\n\tgob.Register(&oauth2.Token{})\r\n\tgac.CookieStore = cookie\r\n}","code-length":59,"reference":"\/\/ InitGitHubOAuthConfig creates an OAuthClient using GitHubOAuth config and a Cookie Store\n\/\/ to retain user credentials.","result":"Initialize github oauth config.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc deltaDisplayed(change *coverageChange) string {\r\n\tif change.baseRatio < 0 {\r\n\t\treturn \"\"\r\n\t}\r\n\treturn fmt.Sprintf(\"%.1f\", (change.newRatio-change.baseRatio)*100)\r\n}","code-length":71,"reference":"\/\/ deltaDisplayed converts a coverage ratio delta into a string value to be displayed by coverage robot","result":"Calculate the delta displayed.","score":[0.0124,0.0318]}
{"code":"\/*is used to<extra_id_0>\r\nfunc makeTable(baseCovList, newCovList *calculation.CoverageList, coverageThreshold float32) (string, bool) {\r\n\tvar rows []string\r\n\tisCoverageLow := false\r\n\tfor _, change := range findChanges(baseCovList, newCovList) {\r\n\t\tfilePath := change.name\r\n\t\trows = append(rows, fmt.Sprintf(\"%s | %s | %s | %s\",\r\n\t\t\tfilePath,\r\n\t\t\tformatPercentage(change.baseRatio),\r\n\t\t\tformatPercentage(change.newRatio),\r\n\t\t\tdeltaDisplayed(change)))\r\n\t\tif change.newRatio < coverageThreshold {\r\n\t\t\tisCoverageLow = true\r\n\t\t}\r\n\t}\r\n\treturn strings.Join(rows, \"\\n\"), isCoverageLow\r\n}","code-length":203,"reference":"\/\/ makeTable checks each coverage change and produce the table content for coverage bot post\n\/\/ It also report on whether any coverage fells below the given threshold","result":"Generate the table .","score":[0.0011,0.0391]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ContentForGitHubPost(baseProfiles, newProfiles []*cover.Profile, jobName string, coverageThreshold float32) (\r\n\tstring, bool) {\r\n\trows := []string{\r\n\t\t\"The following is the code coverage report\",\r\n\t\tfmt.Sprintf(\"Say `\/test %s` to re-run this coverage report\", jobName),\r\n\t\t\"\",\r\n\t\t\"File | Old Coverage | New Coverage | Delta\",\r\n\t\t\"---- |:------------:|:------------:|:-----:\",\r\n\t}\r\n\ttable, isCoverageLow := makeTable(calculation.ProduceCovList(baseProfiles), calculation.ProduceCovList(newProfiles), coverageThreshold)\r\n\tif table == \"\" {\r\n\t\treturn \"\", false\r\n\t}\r\n\trows = append(rows, table)\r\n\trows = append(rows, \"\")\r\n\treturn strings.Join(rows, \"\\n\"), isCoverageLow\r\n}","code-length":231,"reference":"\/\/ ContentForGitHubPost constructs the message covbot posts","result":"Generate the code coverage report.","score":[0.1611,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (client *Client) AddFlags(cmd *cobra.Command) {\r\n\tcmd.PersistentFlags().StringVar(&client.Token, \"token\", \"\",\r\n\t\t\"The OAuth Token to use for requests.\")\r\n\tcmd.PersistentFlags().StringVar(&client.TokenFile, \"token-file\", \"\",\r\n\t\t\"The file containing the OAuth Token to use for requests.\")\r\n\tcmd.PersistentFlags().StringVar(&client.Org, \"organization\", \"\",\r\n\t\t\"The github organization to scan\")\r\n\tcmd.PersistentFlags().StringVar(&client.Project, \"project\", \"\",\r\n\t\t\"The github project to scan\")\r\n}","code-length":166,"reference":"\/\/ AddFlags parses options for github client","result":"Add flags to a command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (client *Client) CheckFlags() error {\r\n\tif client.Org == \"\" {\r\n\t\treturn fmt.Errorf(\"organization flag must be set\")\r\n\t}\r\n\tclient.Org = strings.ToLower(client.Org)\r\n\tif client.Project == \"\" {\r\n\t\treturn fmt.Errorf(\"project flag must be set\")\r\n\t}\r\n\tclient.Project = strings.ToLower(client.Project)\r\n\treturn nil\r\n}","code-length":118,"reference":"\/\/ CheckFlags looks for organization and project flags to configure the client","result":"Check flags.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (client *Client) getGitHubClient() (*github.Client, error) {\r\n\tif client.githubClient != nil {\r\n\t\treturn client.githubClient, nil\r\n\t}\r\n\ttoken := client.Token\r\n\tif len(token) == 0 && len(client.TokenFile) != 0 {\r\n\t\tdata, err := ioutil.ReadFile(client.TokenFile)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\ttoken = strings.TrimSpace(string(data))\r\n\t}\r\n\tif len(token) > 0 {\r\n\t\tts := oauth2.StaticTokenSource(&oauth2.Token{AccessToken: token})\r\n\t\ttc := oauth2.NewClient(oauth2.NoContext, ts)\r\n\t\tclient.githubClient = github.NewClient(tc)\r\n\t} else {\r\n\t\tclient.githubClient = github.NewClient(nil)\r\n\t}\r\n\treturn client.githubClient, nil\r\n}","code-length":249,"reference":"\/\/ getGitHubClient create the github client that we use to communicate with github","result":"Create a github client.","score":[0.0337,0.0826]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (client *Client) limitsCheckAndWait() {\r\n\tvar sleep time.Duration\r\n\tgithubClient, err := client.getGitHubClient()\r\n\tif err != nil {\r\n\t\tglog.Error(\"Failed to get RateLimits: \", err)\r\n\t\tsleep = time.Minute\r\n\t} else {\r\n\t\tlimits, _, err := githubClient.RateLimits(context.Background())\r\n\t\tif err != nil {\r\n\t\t\tglog.Error(\"Failed to get RateLimits:\", err)\r\n\t\t\tsleep = time.Minute\r\n\t\t}\r\n\t\tif limits != nil && limits.Core != nil && limits.Core.Remaining < tokenLimit {\r\n\t\t\tsleep = limits.Core.Reset.Sub(time.Now())\r\n\t\t\tglog.Warning(\"RateLimits: reached. Sleeping for \", sleep)\r\n\t\t}\r\n\t}\r\n\ttime.Sleep(sleep)\r\n}","code-length":228,"reference":"\/\/ limitsCheckAndWait make sure we have not reached the limit or wait","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (client *Client) FetchIssues(latest time.Time, c chan *github.Issue) {\r\n\topt := &github.IssueListByRepoOptions{Since: latest, Sort: \"updated\", State: \"all\", Direction: \"asc\"}\r\n\tgithubClient, err := client.getGitHubClient()\r\n\tif err != nil {\r\n\t\tclose(c)\r\n\t\tglog.Error(err)\r\n\t\treturn\r\n\t}\r\n\tcount := 0\r\n\tfor {\r\n\t\tclient.limitsCheckAndWait()\r\n\t\tissues, resp, err := githubClient.Issues.ListByRepo(\r\n\t\t\tcontext.Background(),\r\n\t\t\tclient.Org,\r\n\t\t\tclient.Project,\r\n\t\t\topt,\r\n\t\t)\r\n\t\tif err != nil {\r\n\t\t\tclose(c)\r\n\t\t\tglog.Error(err)\r\n\t\t\treturn\r\n\t\t}\r\n\t\tfor _, issue := range issues {\r\n\t\t\tc <- issue\r\n\t\t\tcount++\r\n\t\t}\r\n\t\tif resp.NextPage == 0 {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\topt.ListOptions.Page = resp.NextPage\r\n\t}\r\n\tglog.Infof(\"Fetched %d issues updated issue since %v.\", count, latest)\r\n\tclose(c)\r\n}","code-length":331,"reference":"\/\/ FetchIssues from GitHub, until 'latest' time","result":"Fetch issues updated issue since the last.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc hasID(events []*github.IssueEvent, id int) bool {\r\n\tfor _, event := range events {\r\n\t\tif *event.ID == int64(id) {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":76,"reference":"\/\/ hasID look for a specific id in a list of events","result":"Check if an issue event has an ID.","score":[0,0.0431]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (client *Client) FetchIssueEvents(issueID int, latest *int, c chan *github.IssueEvent) {\r\n\topt := &github.ListOptions{PerPage: 100}\r\n\tgithubClient, err := client.getGitHubClient()\r\n\tif err != nil {\r\n\t\tclose(c)\r\n\t\tglog.Error(err)\r\n\t\treturn\r\n\t}\r\n\tcount := 0\r\n\tfor {\r\n\t\tclient.limitsCheckAndWait()\r\n\t\tevents, resp, err := githubClient.Issues.ListIssueEvents(\r\n\t\t\tcontext.Background(),\r\n\t\t\tclient.Org,\r\n\t\t\tclient.Project,\r\n\t\t\tissueID,\r\n\t\t\topt,\r\n\t\t)\r\n\t\tif err != nil {\r\n\t\t\tglog.Errorf(\"ListIssueEvents failed: %s. Retrying...\", err)\r\n\t\t\ttime.Sleep(time.Second)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tfor _, event := range events {\r\n\t\t\tc <- event\r\n\t\t\tcount++\r\n\t\t}\r\n\t\tif resp.NextPage == 0 || (latest != nil && hasID(events, *latest)) {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\topt.Page = resp.NextPage\r\n\t}\r\n\tglog.Infof(\"Fetched %d events.\", count)\r\n\tclose(c)\r\n}","code-length":344,"reference":"\/\/ FetchIssueEvents from github and return the full list, until it matches 'latest'\n\/\/ The entire last page will be included so you can have redundancy.","result":"Fetch events from github.","score":[0.0013,0.021]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isPRChanged(pe github.PullRequestEvent) bool {\r\n\tswitch pe.Action {\r\n\tcase github.PullRequestActionOpened:\r\n\t\treturn true\r\n\tcase github.PullRequestActionReopened:\r\n\t\treturn true\r\n\tcase github.PullRequestActionSynchronize:\r\n\t\treturn true\r\n\tcase github.PullRequestActionEdited:\r\n\t\treturn true\r\n\tdefault:\r\n\t\treturn false\r\n\t}\r\n}","code-length":115,"reference":"\/\/ These are the only actions indicating the code diffs may have changed.","result":"Detect PR changes.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFetcher(repository string) *Fetcher {\r\n\treturn &Fetcher{\r\n\t\tIssuesChannel:         make(chan sql.Issue, 100),\r\n\t\tEventsCommentsChannel: make(chan interface{}, 100),\r\n\t\trepository:            repository,\r\n\t}\r\n}","code-length":75,"reference":"\/\/ NewFetcher creates a new Fetcher and initializes the output channels","result":"Create a fetcher.","score":[0.0284,0.1838]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *Fetcher) fetchRecentIssues(db *gorm.DB) error {\r\n\tglog.Infof(\"Fetching issues updated after %s\", f.lastIssue)\r\n\tvar issues []sql.Issue\r\n\tquery := db.\r\n\t\tWhere(\"issue_updated_at >= ?\", f.lastIssue).\r\n\t\tWhere(\"repository = ?\", f.repository).\r\n\t\tOrder(\"issue_updated_at\").\r\n\t\tPreload(\"Labels\").\r\n\t\tFind(&issues)\r\n\tif query.Error != nil {\r\n\t\treturn query.Error\r\n\t}\r\n\tcount := len(issues)\r\n\tfor _, issue := range issues {\r\n\t\tf.IssuesChannel <- issue\r\n\t\tf.lastIssue = issue.IssueUpdatedAt\r\n\t}\r\n\tglog.Infof(\"Found and pushed %d updated\/new issues\", count)\r\n\treturn nil\r\n}","code-length":226,"reference":"\/\/ fetchRecentIssues retrieves issues from DB, but only fetches issues modified since last call","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *Fetcher) fetchRecentEventsAndComments(db *gorm.DB) error {\r\n\tglog.Infof(\"Fetching issue-events with id bigger than %s\", f.lastEvent)\r\n\tglog.Infof(\"Fetching comments with id bigger than %s\", f.lastComment)\r\n\teventRows, err := db.\r\n\t\tModel(sql.IssueEvent{}).\r\n\t\tWhere(\"repository = ?\", f.repository).\r\n\t\tWhere(\"event_created_at > ?\", f.lastEvent).\r\n\t\tOrder(\"event_created_at asc\").\r\n\t\tRows()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"Failed to query events from database: %s\", err)\r\n\t}\r\n\tcommentRows, err := db.\r\n\t\tModel(sql.Comment{}).\r\n\t\tWhere(\"repository = ?\", f.repository).\r\n\t\tWhere(\"comment_created_at > ?\", f.lastComment).\r\n\t\tOrder(\"comment_created_at asc\").\r\n\t\tRows()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"Failed to query comments from database: %s\", err)\r\n\t}\r\n\tcount := 0\r\n\tcomment := &sql.Comment{}\r\n\tif commentRows.Next() {\r\n\t\tdb.ScanRows(commentRows, comment)\r\n\t} else {\r\n\t\tcomment = nil\r\n\t}\r\n\tevent := &sql.IssueEvent{}\r\n\tif eventRows.Next() {\r\n\t\tdb.ScanRows(eventRows, event)\r\n\t} else {\r\n\t\tevent = nil\r\n\t}\r\n\tfor event != nil || comment != nil {\r\n\t\tif event == nil || (comment != nil && comment.CommentCreatedAt.Before(event.EventCreatedAt)) {\r\n\t\t\tf.EventsCommentsChannel <- *comment\r\n\t\t\tf.lastComment = comment.CommentCreatedAt\r\n\t\t\tif commentRows.Next() {\r\n\t\t\t\tdb.ScanRows(commentRows, comment)\r\n\t\t\t} else {\r\n\t\t\t\tcomment = nil\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\tf.EventsCommentsChannel <- *event\r\n\t\t\tf.lastEvent = event.EventCreatedAt\r\n\t\t\tif eventRows.Next() {\r\n\t\t\t\tdb.ScanRows(eventRows, event)\r\n\t\t\t} else {\r\n\t\t\t\tevent = nil\r\n\t\t\t}\r\n\t\t}\r\n\t\tcount++\r\n\t}\r\n\tglog.Infof(\"Found and pushed %d new events\/comments\", count)\r\n\treturn nil\r\n}","code-length":628,"reference":"\/\/ fetchRecentEventsAndComments retrieves events from DB, but only fetches events created since last call","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *Fetcher) Fetch(db *gorm.DB) error {\r\n\tif err := f.fetchRecentIssues(db); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := f.fetchRecentEventsAndComments(db); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":92,"reference":"\/\/ Fetch retrieves all types of events, and push them to output channels","result":"Fetch the content.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (fjr *FlakyJobReporter) Issues(c *creator.IssueCreator) ([]creator.Issue, error) {\r\n\tfjr.creator = c\r\n\tjson, err := ReadHTTP(fjr.flakyJobDataURL)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tflakyJobs, err := fjr.parseFlakyJobs(json)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tcount := fjr.syncCount\r\n\tif len(flakyJobs) < count {\r\n\t\tcount = len(flakyJobs)\r\n\t}\r\n\tissues := make([]creator.Issue, 0, count)\r\n\tfor _, fj := range flakyJobs[0:count] {\r\n\t\tissues = append(issues, fj)\r\n\t}\r\n\treturn issues, nil\r\n}","code-length":231,"reference":"\/\/ Issues is the main work method of FlakyJobReporter. It fetches and parses flaky job data,\n\/\/ then syncs the top issues to github with the IssueCreator.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (fj *FlakyJob) Title() string {\r\n\treturn fmt.Sprintf(\"%s flaked %d times in the past week\", fj.Name, *fj.FlakeCount)\r\n}","code-length":58,"reference":"\/\/ Title yields the initial title text of the github issue.","result":"Generate title.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (fj *FlakyJob) Labels() []string {\r\n\tlabels := []string{\"kind\/flake\"}\r\n\t\r\n\tfor sig := range fj.reporter.creator.TestsSIGs(fj.TestsSorted()) {\r\n\t\tlabels = append(labels, \"sig\/\"+sig)\r\n\t}\r\n\treturn labels\r\n}","code-length":93,"reference":"\/\/ Labels returns the labels to apply to the issue created for this flaky job on github.","result":"Get the labels of the flaky job.","score":[0.0651,0.1973]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReadHTTP(url string) ([]byte, error) {\r\n\tvar err error\r\n\tretryDelay := time.Duration(2) * time.Second\r\n\tfor retryCount := 0; retryCount < 5; retryCount++ {\r\n\t\tif retryCount > 0 {\r\n\t\t\ttime.Sleep(retryDelay)\r\n\t\t\tretryDelay *= time.Duration(2)\r\n\t\t}\r\n\t\tresp, err := http.Get(url)\r\n\t\tif resp != nil && resp.StatusCode >= 500 {\r\n\t\t\t\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tdefer resp.Body.Close()\r\n\t\tbody, err := ioutil.ReadAll(resp.Body)\r\n\t\tif err != nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\treturn body, nil\r\n\t}\r\n\treturn nil, fmt.Errorf(\"ran out of retries reading from '%s'. Last error was %v\", url, err)\r\n}","code-length":253,"reference":"\/\/ ReadHTTP fetches file contents from a URL with retries.","result":"Read a file from a URL .","score":[0.2329,0.3866]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l linesByTimestamp) String() string {\r\n\tsort.Sort(l)\r\n\tvar log string\r\n\tfor i, line := range l {\r\n\t\tswitch i {\r\n\t\tcase len(l) - 1:\r\n\t\t\tlog += string(line.actual)\r\n\t\tdefault:\r\n\t\t\t\r\n\t\t\tlog += fmt.Sprintf(\"%s,\\n\", strings.TrimSuffix(string(line.actual), \"\\n\"))\r\n\t\t}\r\n\t}\r\n\treturn fmt.Sprintf(\"[%s]\", log)\r\n}","code-length":143,"reference":"\/\/ Return valid json.","result":"Print log lines by timestamp.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewJobSpec(spec prowapi.ProwJobSpec, buildID, prowJobID string) JobSpec {\r\n\treturn JobSpec{\r\n\t\tType:      spec.Type,\r\n\t\tJob:       spec.Job,\r\n\t\tBuildID:   buildID,\r\n\t\tProwJobID: prowJobID,\r\n\t\tRefs:      spec.Refs,\r\n\t\tExtraRefs: spec.ExtraRefs,\r\n\t\tagent:     spec.Agent,\r\n\t}\r\n}","code-length":131,"reference":"\/\/ NewJobSpec converts a prowapi.ProwJobSpec invocation into a JobSpec","result":"Create a new job spec.","score":[0.108,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ResolveSpecFromEnv() (*JobSpec, error) {\r\n\tspecEnv, ok := os.LookupEnv(JobSpecEnv)\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"$%s unset\", JobSpecEnv)\r\n\t}\r\n\tspec := &JobSpec{}\r\n\tif err := json.Unmarshal([]byte(specEnv), spec); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"malformed $%s: %v\", JobSpecEnv, err)\r\n\t}\r\n\treturn spec, nil\r\n}","code-length":142,"reference":"\/\/ ResolveSpecFromEnv will determine the Refs being\n\/\/ tested in by parsing Prow environment variable contents","result":"Resolve job spec from environment variables.","score":[0.0365,0.0333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EnvForSpec(spec JobSpec) (map[string]string, error) {\r\n\tenv := map[string]string{\r\n\t\tjobNameEnv:   spec.Job,\r\n\t\tbuildIDEnv:   spec.BuildID,\r\n\t\tprowJobIDEnv: spec.ProwJobID,\r\n\t\tjobTypeEnv:   string(spec.Type),\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tif spec.agent == prowapi.KubernetesAgent {\r\n\t\tenv[prowBuildIDEnv] = spec.BuildID\r\n\t}\r\n\traw, err := json.Marshal(spec)\r\n\tif err != nil {\r\n\t\treturn env, fmt.Errorf(\"failed to marshal job spec: %v\", err)\r\n\t}\r\n\tenv[JobSpecEnv] = string(raw)\r\n\tif spec.Type == prowapi.PeriodicJob {\r\n\t\treturn env, nil\r\n\t}\r\n\tenv[repoOwnerEnv] = spec.Refs.Org\r\n\tenv[repoNameEnv] = spec.Refs.Repo\r\n\tenv[pullBaseRefEnv] = spec.Refs.BaseRef\r\n\tenv[pullBaseShaEnv] = spec.Refs.BaseSHA\r\n\tenv[pullRefsEnv] = spec.Refs.String()\r\n\tif spec.Type == prowapi.PostsubmitJob || spec.Type == prowapi.BatchJob {\r\n\t\treturn env, nil\r\n\t}\r\n\tenv[pullNumberEnv] = strconv.Itoa(spec.Refs.Pulls[0].Number)\r\n\tenv[pullPullShaEnv] = spec.Refs.Pulls[0].SHA\r\n\treturn env, nil\r\n}","code-length":412,"reference":"\/\/ EnvForSpec returns a mapping of environment variables\n\/\/ to their values that should be available for a job spec","result":"Generate the job env .","score":[0.012,0.027]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EnvForType(jobType prowapi.ProwJobType) []string {\r\n\tbaseEnv := []string{jobNameEnv, JobSpecEnv, jobTypeEnv, prowJobIDEnv, buildIDEnv, prowBuildIDEnv}\r\n\trefsEnv := []string{repoOwnerEnv, repoNameEnv, pullBaseRefEnv, pullBaseShaEnv, pullRefsEnv}\r\n\tpullEnv := []string{pullNumberEnv, pullPullShaEnv}\r\n\tswitch jobType {\r\n\tcase prowapi.PeriodicJob:\r\n\t\treturn baseEnv\r\n\tcase prowapi.PostsubmitJob, prowapi.BatchJob:\r\n\t\treturn append(baseEnv, refsEnv...)\r\n\tcase prowapi.PresubmitJob:\r\n\t\treturn append(append(baseEnv, refsEnv...), pullEnv...)\r\n\tdefault:\r\n\t\treturn []string{}\r\n\t}\r\n}","code-length":222,"reference":"\/\/ EnvForType returns the slice of environment variables to export for jobType","result":"Generate the environment variables for the job.","score":[0.133,0.2745]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getRevisionFromRef(refs *prowapi.Refs) string {\r\n\tif len(refs.Pulls) > 0 {\r\n\t\treturn refs.Pulls[0].SHA\r\n\t}\r\n\tif refs.BaseSHA != \"\" {\r\n\t\treturn refs.BaseSHA\r\n\t}\r\n\treturn refs.BaseRef\r\n}","code-length":90,"reference":"\/\/ getRevisionFromRef returns a ref or sha from a refs object","result":"Generate the revision from ref.","score":[0.0724,0.0481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetRevisionFromSpec(spec *JobSpec) string {\r\n\tif spec.Refs != nil {\r\n\t\treturn getRevisionFromRef(spec.Refs)\r\n\t} else if len(spec.ExtraRefs) > 0 {\r\n\t\treturn getRevisionFromRef(&spec.ExtraRefs[0])\r\n\t}\r\n\treturn \"\"\r\n}","code-length":90,"reference":"\/\/ GetRevisionFromSpec returns a main ref or sha from a spec object","result":"Generate the revision string for the job.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc helpProvider(config *plugins.Configuration, enabledRepos []string) (*pluginhelp.PluginHelp, error) {\r\n\t\r\n\treturn &pluginhelp.PluginHelp{\r\n\t\tDescription: fmt.Sprintf(\"The merge commit blocker plugin adds the %s label to pull requests that contain merge commits\", labels.MergeCommits),\r\n\t}, nil\r\n}","code-length":92,"reference":"\/\/ helpProvider provides information on the plugin","result":"Provide the help for the plugin.","score":[0.1634,0.1449]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Group) load(r io.Reader) ([]string, error) {\r\n\tvar repoPaths []string\r\n\ts := bufio.NewScanner(r)\r\n\tfor s.Scan() {\r\n\t\tl := strings.TrimSpace(s.Text())\r\n\t\tif l == \"\" || l[0] == '#' {\r\n\t\t\t\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tfs := strings.Fields(l)\r\n\t\tif len(fs) != 2 {\r\n\t\t\treturn repoPaths, &ParseError{line: l}\r\n\t\t}\r\n\t\tswitch fs[0] {\r\n\t\tcase \"prefix\", \"path-prefix\":\r\n\t\t\tg.PathPrefixes[fs[1]] = true\r\n\t\tcase \"file-prefix\":\r\n\t\t\tg.FilePrefixes[fs[1]] = true\r\n\t\tcase \"file-name\":\r\n\t\t\tg.FileNames[fs[1]] = true\r\n\t\tcase \"path\":\r\n\t\t\tg.FileNames[fs[1]] = true\r\n\t\tcase \"paths-from-repo\":\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\trepoPaths = append(repoPaths, fs[1])\r\n\t\tdefault:\r\n\t\t\treturn repoPaths, &ParseError{line: l}\r\n\t\t}\r\n\t}\r\n\tif err := s.Err(); err != nil {\r\n\t\treturn repoPaths, err\r\n\t}\r\n\treturn repoPaths, nil\r\n}","code-length":362,"reference":"\/\/ Use load to read a generated files config file, and populate g with the commands.\n\/\/ \"paths-from-repo\" commands are aggregated into repoPaths. It is the caller's\n\/\/ responsibility to fetch these and load them via g.loadPaths.","result":"Load the file.","score":[0.0,0.0298]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Group) loadPaths(r io.Reader) error {\r\n\ts := bufio.NewScanner(r)\r\n\tfor s.Scan() {\r\n\t\tl := strings.TrimSpace(s.Text())\r\n\t\tif l == \"\" || l[0] == '#' {\r\n\t\t\t\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tg.Paths[l] = true\r\n\t}\r\n\tif err := s.Err(); err != nil {\r\n\t\treturn fmt.Errorf(\"scan error: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":149,"reference":"\/\/ Use loadPaths to load a file of new-line delimited paths, such as\n\/\/ resolving file data referenced in a \"paths-from-repo\" command.","result":"Load paths in the file.","score":[0.008,0.0493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Group) Match(path string) bool {\r\n\tif g.Paths[path] {\r\n\t\treturn true\r\n\t}\r\n\tfor prefix := range g.PathPrefixes {\r\n\t\tif strings.HasPrefix(path, prefix) {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\tbase := filepath.Base(path)\r\n\tif g.FileNames[base] {\r\n\t\treturn true\r\n\t}\r\n\tfor prefix := range g.FilePrefixes {\r\n\t\tif strings.HasPrefix(base, prefix) {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":168,"reference":"\/\/ Match determines whether a file, given here by its full path\n\/\/ is included in the generated files group.","result":"Match the path.","score":[0.0017,0.0546]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (config *InfluxConfig) CreateDatabase(tags map[string]string, measurement string) (*InfluxDB, error) {\r\n\tclient, err := influxdb.NewHTTPClient(influxdb.HTTPConfig{\r\n\t\tAddr:     config.Host,\r\n\t\tUsername: config.User,\r\n\t\tPassword: config.Password,\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\terr = dropSeries(client, measurement, config.DB, tags)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tbp, err := influxdb.NewBatchPoints(influxdb.BatchPointsConfig{\r\n\t\tDatabase:  config.DB,\r\n\t\tPrecision: \"s\",\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &InfluxDB{\r\n\t\tclient:      client,\r\n\t\tdatabase:    config.DB,\r\n\t\tbatch:       bp,\r\n\t\ttags:        tags,\r\n\t\tmeasurement: measurement,\r\n\t}, err\r\n}","code-length":277,"reference":"\/\/ CreateDatabase creates and connects a new instance of an InfluxDB\n\/\/ It is created based on the fields set in the configuration.","result":"Create a new database.","score":[0.0039,0.1211]}
{"code":"\/*is used to<extra_id_0>\r\nfunc mergeTags(defaultTags, extraTags map[string]string) map[string]string {\r\n\tnewTags := map[string]string{}\r\n\tfor k, v := range defaultTags {\r\n\t\tnewTags[k] = v\r\n\t}\r\n\tfor k, v := range extraTags {\r\n\t\tnewTags[k] = v\r\n\t}\r\n\treturn newTags\r\n}","code-length":105,"reference":"\/\/ mergeTags merges the default tags with the exta tags. Default will be overridden if it conflicts.","result":"Merge default and extra tags.","score":[0.0259,0.0949]}
{"code":"\/*is used to<extra_id_0>\r\nfunc tagsToWhere(tags map[string]string) string {\r\n\tif len(tags) == 0 {\r\n\t\treturn \"\"\r\n\t}\r\n\tsortedKeys := []string{}\r\n\tfor k := range tags {\r\n\t\tsortedKeys = append(sortedKeys, k)\r\n\t}\r\n\tsort.Strings(sortedKeys)\r\n\tconditions := []string{}\r\n\tfor _, key := range sortedKeys {\r\n\t\tconditions = append(conditions, fmt.Sprintf(`\"%s\" = '%v'`, key, tags[key]))\r\n\t}\r\n\treturn \"WHERE \" + strings.Join(conditions, \" AND \")\r\n}","code-length":164,"reference":"\/\/ tagsToWhere creates a where query to match tags element","result":"Generate the tagsToWhere function.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InfluxDB) Push(tags map[string]string, fields map[string]interface{}, date time.Time) error {\r\n\tpt, err := influxdb.NewPoint(i.measurement, mergeTags(i.tags, tags), fields, date)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ti.batch.AddPoint(pt)\r\n\ti.batchSize++\r\n\treturn nil\r\n}","code-length":116,"reference":"\/\/ Push a point to the database. This appends to current batchpoint","result":"Push metrics to the influxdb.","score":[0.0927,0.1327]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (af *PodLogArtifactFetcher) artifact(jobName, buildID string, sizeLimit int64) (lenses.Artifact, error) {\r\n\tpodLog, err := NewPodLogArtifact(jobName, buildID, sizeLimit, af.jobAgent)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"Error accessing pod log from given source: %v\", err)\r\n\t}\r\n\treturn podLog, nil\r\n}","code-length":115,"reference":"\/\/ artifact constructs an artifact handle for the given job build","result":"Fetch the pod log artifact from given source.","score":[0.1256,0.1402]}
{"code":"\/*is used to<extra_id_0>\r\nfunc serve() {\r\n\thttp.Handle(\"\/metrics\", promhttp.Handler())\r\n\tlogrus.WithError(http.ListenAndServe(\":8080\", nil)).Fatal(\"ListenAndServe returned.\")\r\n}","code-length":58,"reference":"\/\/ serve starts a http server and serves prometheus metrics.\n\/\/ Meant to be called inside a goroutine.","result":"Serve the metrics.","score":[0.0028,0.0606]}
{"code":"\/*is used to<extra_id_0>\r\nfunc gather(c *plank.Controller) {\r\n\ttick := time.Tick(30 * time.Second)\r\n\tsig := make(chan os.Signal, 1)\r\n\tsignal.Notify(sig, os.Interrupt, syscall.SIGTERM)\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase <-tick:\r\n\t\t\tstart := time.Now()\r\n\t\t\tc.SyncMetrics()\r\n\t\t\tlogrus.WithField(\"metrics-duration\", fmt.Sprintf(\"%v\", time.Since(start))).Debug(\"Metrics synced\")\r\n\t\tcase <-sig:\r\n\t\t\tlogrus.Debug(\"Plank gatherer is shutting down...\")\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":181,"reference":"\/\/ gather metrics from plank.\n\/\/ Meant to be called inside a goroutine.","result":"Gather metrics from the plank controller.","score":[0.085,0.2394]}
{"code":"\/*is used to<extra_id_0>\r\nfunc makeRequest(policy branchprotection.Policy) github.BranchProtectionRequest {\r\n\treturn github.BranchProtectionRequest{\r\n\t\tEnforceAdmins:              makeAdmins(policy.Admins),\r\n\t\tRequiredPullRequestReviews: makeReviews(policy.RequiredPullRequestReviews),\r\n\t\tRequiredStatusChecks:       makeChecks(policy.RequiredStatusChecks),\r\n\t\tRestrictions:               makeRestrictions(policy.Restrictions),\r\n\t}\r\n}","code-length":113,"reference":"\/\/ makeRequest renders a branch protection policy into the corresponding GitHub api request.","result":"Create a branch protection request.","score":[0.1074,0.3074]}
{"code":"\/*is used to<extra_id_0>\r\nfunc makeReviews(rp *branchprotection.ReviewPolicy) *github.RequiredPullRequestReviews {\r\n\tswitch {\r\n\tcase rp == nil:\r\n\t\treturn nil\r\n\tcase rp.Approvals == nil:\r\n\t\tlogrus.Warn(\"WARNING: required_pull_request_reviews policy does not specify required_approving_review_count, disabling\")\r\n\t\treturn nil\r\n\tcase *rp.Approvals == 0:\r\n\t\treturn nil\r\n\t}\r\n\trprr := github.RequiredPullRequestReviews{\r\n\t\tDismissStaleReviews:          makeBool(rp.DismissStale),\r\n\t\tRequireCodeOwnerReviews:      makeBool(rp.RequireOwners),\r\n\t\tRequiredApprovingReviewCount: *rp.Approvals,\r\n\t}\r\n\tif rp.DismissalRestrictions != nil {\r\n\t\trprr.DismissalRestrictions = *makeRestrictions(rp.DismissalRestrictions)\r\n\t}\r\n\treturn &rprr\r\n}","code-length":247,"reference":"\/\/ makeReviews renders review policy into the corresponding GitHub api object.\n\/\/\n\/\/ Returns nil if the policy is nil, or approvals is nil or 0.","result":"Create reviews for a.","score":[0,0.021]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lens Lens) Header(artifacts []lenses.Artifact, resourceDir string) string {\r\n\treturn executeTemplate(resourceDir, \"header\", BuildLogsView{})\r\n}","code-length":51,"reference":"\/\/ Header executes the \"header\" section of the template.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lens Lens) Callback(artifacts []lenses.Artifact, resourceDir string, data string) string {\r\n\tvar request LineRequest\r\n\terr := json.Unmarshal([]byte(data), &request)\r\n\tif err != nil {\r\n\t\treturn \"failed to unmarshal request\"\r\n\t}\r\n\tartifact, ok := artifactByName(artifacts, request.Artifact)\r\n\tif !ok {\r\n\t\treturn \"no artifact named \" + request.Artifact\r\n\t}\r\n\tvar lines []string\r\n\tif request.Offset == 0 && request.Length == -1 {\r\n\t\tlines, err = logLinesAll(artifact)\r\n\t} else {\r\n\t\tlines, err = logLines(artifact, request.Offset, request.Length)\r\n\t}\r\n\tif err != nil {\r\n\t\treturn fmt.Sprintf(\"failed to retrieve log lines: %v\", err)\r\n\t}\r\n\tlogLines := highlightLines(lines, request.StartLine)\r\n\treturn executeTemplate(resourceDir, \"line group\", logLines)\r\n}","code-length":259,"reference":"\/\/ Callback is used to retrieve new log segments","result":"Retrieve log lines.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc logLinesAll(artifact lenses.Artifact) ([]string, error) {\r\n\tread, err := artifact.ReadAll()\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to read log %q: %v\", artifact.JobPath(), err)\r\n\t}\r\n\tlogLines := strings.Split(string(read), \"\\n\")\r\n\treturn logLines, nil\r\n}","code-length":107,"reference":"\/\/ logLinesAll reads all of an artifact and splits it into lines.","result":"Read log lines from a artifact.","score":[0,0.0439]}
{"code":"\/*is used to<extra_id_0>\r\nfunc executeTemplate(resourceDir, templateName string, data interface{}) string {\r\n\tt := template.New(\"template.html\")\r\n\t_, err := t.ParseFiles(filepath.Join(resourceDir, \"template.html\"))\r\n\tif err != nil {\r\n\t\treturn fmt.Sprintf(\"Failed to load template: %v\", err)\r\n\t}\r\n\tvar buf bytes.Buffer\r\n\tif err := t.ExecuteTemplate(&buf, templateName, data); err != nil {\r\n\t\tlogrus.WithError(err).Error(\"Error executing template.\")\r\n\t}\r\n\treturn buf.String()\r\n}","code-length":158,"reference":"\/\/ LogViewTemplate executes the log viewer template ready for rendering","result":"Execute a template.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ResourceObject) DeepCopyObject() runtime.Object {\r\n\tif c := in.deepCopy(); c != nil {\r\n\t\treturn c\r\n\t}\r\n\treturn nil\r\n}","code-length":56,"reference":"\/\/ DeepCopyObject implements runtime.Object interface","result":"Avoid deep copy.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ResourceObject) FromItem(i common.Item) {\r\n\tr, err := common.ItemToResource(i)\r\n\tif err == nil {\r\n\t\tin.fromResource(r)\r\n\t}\r\n}","code-length":66,"reference":"\/\/ FromItem implements Object interface","result":"Construct the resource object.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ResourceCollection) SetItems(objects []Object) {\r\n\tvar items []*ResourceObject\r\n\tfor _, b := range objects {\r\n\t\titems = append(items, b.(*ResourceObject))\r\n\t}\r\n\tin.Items = items\r\n}","code-length":75,"reference":"\/\/ SetItems implements Collection interface","result":"Set items of a resource collection.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ResourceCollection) DeepCopyObject() runtime.Object {\r\n\tif c := in.deepCopy(); c != nil {\r\n\t\treturn c\r\n\t}\r\n\treturn nil\r\n}","code-length":56,"reference":"\/\/ DeepCopyObject implements Collection interface","result":"Avoid deep copy.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc useContext(o options, ctx string) error {\r\n\t_, cmd := command(\"kubectl\", \"config\", \"use-context\", ctx)\r\n\treturn cmd.Run()\r\n}","code-length":55,"reference":"\/\/ useContext calls kubectl config use-context ctx","result":"Set the context in the config file.","score":[0.1615,0.0714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc currentContext(o options) (string, error) {\r\n\t_, cmd := command(\"kubectl\", \"config\", \"current-context\")\r\n\tb, err := cmd.Output()\r\n\treturn strings.TrimSpace(string(b)), err\r\n}","code-length":71,"reference":"\/\/ currentContext returns kubectl config current-context","result":"Get the current context from the current context.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc command(bin string, args ...string) ([]string, *exec.Cmd) {\r\n\tcmd := exec.Command(bin, args...)\r\n\tcmd.Stderr = os.Stderr\r\n\treturn append([]string{bin}, args...), cmd\r\n}","code-length":70,"reference":"\/\/ command creates an exec.Cmd with Stderr piped to os.Stderr and returns the args","result":"Execute commands.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc describeCluster(o options) (*describe, error) {\r\n\tif o.account != \"\" {\r\n\t\tact, err := getAccount()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"get current account: %v\", err)\r\n\t\t}\r\n\t\tdefer setAccount(act)\r\n\t\tif err = setAccount(o.account); err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"set account %s: %v\", o.account, err)\r\n\t\t}\r\n\t}\r\n\targs, cmd := command(\r\n\t\t\"gcloud\", \"container\", \"clusters\", \"describe\", o.cluster,\r\n\t\t\"--project\", o.project,\r\n\t\t\"--zone\", o.zone,\r\n\t\t\"--format=yaml\",\r\n\t)\r\n\tdata, err := cmd.Output()\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"%s: %v\", strings.Join(args, \" \"), err)\r\n\t}\r\n\tvar d describe\r\n\tif yaml.Unmarshal(data, &d); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"unmarshal gcloud: %v\", err)\r\n\t}\r\n\tif d.Endpoint == \"\" {\r\n\t\treturn nil, errors.New(\"empty endpoint\")\r\n\t}\r\n\tif len(d.Auth.ClusterCACertificate) == 0 {\r\n\t\treturn nil, errors.New(\"empty clusterCaCertificate\")\r\n\t}\r\n\tif len(d.Auth.ClientKey) == 0 {\r\n\t\treturn nil, errors.New(\"empty clientKey, consider running with --get-client-cert\")\r\n\t}\r\n\tif len(d.Auth.ClientCertificate) == 0 {\r\n\t\treturn nil, errors.New(\"empty clientCertificate, consider running with --get-client-cert\")\r\n\t}\r\n\treturn &d, nil\r\n}","code-length":471,"reference":"\/\/ describeCluster returns details from gcloud container clusters describe.","result":"Describe cluster.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ss *strslice) Set(value string) error {\r\n\t*ss = append(*ss, value)\r\n\treturn nil\r\n}","code-length":43,"reference":"\/\/ Set appends a value onto the strslice.","result":"Set the slice values.","score":[0.1398,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc parseXML(body []byte, object string) (*gcsDir, error) {\r\n\tdir := new(gcsDir)\r\n\tif err := xml.Unmarshal(body, &dir); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\t\r\n\tisDir := object == \"\/\" || len(dir.Contents)+len(dir.CommonPrefixes) > 0\r\n\tselfIndex := -1\r\n\tfor i := range dir.Contents {\r\n\t\trec := &dir.Contents[i]\r\n\t\tname := strings.TrimPrefix(rec.Name, object)\r\n\t\tif name == \"\" {\r\n\t\t\tselfIndex = i\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\trec.Name = name\r\n\t\tif strings.HasSuffix(name, \"\/\") {\r\n\t\t\trec.isDir = true\r\n\t\t}\r\n\t}\r\n\tfor i := range dir.CommonPrefixes {\r\n\t\tcp := &dir.CommonPrefixes[i]\r\n\t\tcp.Prefix = strings.TrimPrefix(cp.Prefix, object)\r\n\t}\r\n\tif !isDir {\r\n\t\treturn nil, nil\r\n\t}\r\n\tif selfIndex >= 0 {\r\n\t\t\r\n\t\tdir.Contents = append(dir.Contents[:selfIndex], dir.Contents[selfIndex+1:]...)\r\n\t}\r\n\treturn dir, nil\r\n}","code-length":343,"reference":"\/\/ parseXML extracts a gcsDir object from XML.  If this returns a nil gcsDir,\n\/\/ the XML indicated that this was not a directory at all.","result":"Parse XML file.","score":[0.0002,0.0211]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (dir *gcsDir) Render(out http.ResponseWriter, inPath string) {\r\n\thtmlPageHeader(out, dir.Name)\r\n\tif !strings.HasSuffix(inPath, \"\/\") {\r\n\t\tinPath += \"\/\"\r\n\t}\r\n\thtmlContentHeader(out, dir.Name, inPath)\r\n\tif dir.NextMarker != \"\" {\r\n\t\thtmlNextButton(out, gcsPath+inPath, dir.NextMarker)\r\n\t}\r\n\thtmlGridHeader(out)\r\n\tif parent := dirname(inPath); parent != \"\" {\r\n\t\turl := gcsPath + parent\r\n\t\thtmlGridItem(out, iconBack, url, \"..\", \"-\", \"-\")\r\n\t}\r\n\tfor i := range dir.CommonPrefixes {\r\n\t\tdir.CommonPrefixes[i].Render(out, inPath)\r\n\t}\r\n\tfor i := range dir.Contents {\r\n\t\tdir.Contents[i].Render(out, inPath)\r\n\t}\r\n\tif dir.NextMarker != \"\" {\r\n\t\thtmlNextButton(out, gcsPath+inPath, dir.NextMarker)\r\n\t}\r\n\thtmlContentFooter(out)\r\n\thtmlPageFooter(out)\r\n}","code-length":306,"reference":"\/\/ Render writes HTML representing this gcsDir to the provided output.","result":"Render the directory.","score":[0.0337,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rec *Record) Render(out http.ResponseWriter, inPath string) {\r\n\tmtime := \"<unknown>\"\r\n\tts, err := time.Parse(time.RFC3339, rec.MTime)\r\n\tif err == nil {\r\n\t\tmtime = ts.Format(\"02 Jan 2006 15:04:05\")\r\n\t}\r\n\tvar url, size string\r\n\tif rec.isDir {\r\n\t\turl = gcsPath + inPath + rec.Name\r\n\t\tsize = \"-\"\r\n\t} else {\r\n\t\turl = gcsBaseURL + inPath + rec.Name\r\n\t\tsize = fmt.Sprintf(\"%v\", rec.Size)\r\n\t}\r\n\thtmlGridItem(out, iconFile, url, rec.Name, size, mtime)\r\n}","code-length":194,"reference":"\/\/ Render writes HTML representing this Record to the provided output.","result":"Render the record.","score":[0.0337,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pfx *Prefix) Render(out http.ResponseWriter, inPath string) {\r\n\turl := gcsPath + inPath + pfx.Prefix\r\n\thtmlGridItem(out, iconDir, url, pfx.Prefix, \"-\", \"-\")\r\n}","code-length":68,"reference":"\/\/ Render writes HTML representing this Prefix to the provided output.","result":"Render the prefix.","score":[0.0337,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tl txnLogger) Printf(fmt string, args ...interface{}) {\r\n\targs = append([]interface{}{tl.nonce}, args...)\r\n\tlog.Printf(\"[txn-%s] \"+fmt, args...)\r\n}","code-length":63,"reference":"\/\/ Printf logs a formatted line to the logging output.","result":"Print to the console.","score":[0.1008,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(instances map[string][]string) (*Client, error) {\r\n\tc := &Client{\r\n\t\thandlers: map[string]*gerritInstanceHandler{},\r\n\t}\r\n\tfor instance := range instances {\r\n\t\tgc, err := gerrit.NewClient(instance, nil)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tc.handlers[instance] = &gerritInstanceHandler{\r\n\t\t\tinstance:       instance,\r\n\t\t\tprojects:       instances[instance],\r\n\t\t\tauthService:    gc.Authentication,\r\n\t\t\taccountService: gc.Accounts,\r\n\t\t\tchangeService:  gc.Changes,\r\n\t\t\tprojectService: gc.Projects,\r\n\t\t}\r\n\t}\r\n\treturn c, nil\r\n}","code-length":205,"reference":"\/\/ NewClient returns a new gerrit client","result":"Create a new client .","score":[0.2521,0.3758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) SetReview(instance, id, revision, message string, labels map[string]string) error {\r\n\th, ok := c.handlers[instance]\r\n\tif !ok {\r\n\t\treturn fmt.Errorf(\"not activated gerrit instance: %s\", instance)\r\n\t}\r\n\tif _, _, err := h.changeService.SetReview(id, revision, &gerrit.ReviewInput{\r\n\t\tMessage: message,\r\n\t\tLabels:  labels,\r\n\t}); err != nil {\r\n\t\treturn fmt.Errorf(\"cannot comment to gerrit: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":166,"reference":"\/\/ SetReview writes a review comment base on the change id + revision","result":"Comment to gerrit instance.","score":[0,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) GetBranchRevision(instance, project, branch string) (string, error) {\r\n\th, ok := c.handlers[instance]\r\n\tif !ok {\r\n\t\treturn \"\", fmt.Errorf(\"not activated gerrit instance: %s\", instance)\r\n\t}\r\n\tres, _, err := h.projectService.GetBranch(project, branch)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn res.Revision, nil\r\n}","code-length":129,"reference":"\/\/ GetBranchRevision returns SHA of HEAD of a branch","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *gerritInstanceHandler) queryAllChanges(lastUpdate time.Time, rateLimit int) []gerrit.ChangeInfo {\r\n\tresult := []gerrit.ChangeInfo{}\r\n\tfor _, project := range h.projects {\r\n\t\tchanges, err := h.queryChangesForProject(project, lastUpdate, rateLimit)\r\n\t\tif err != nil {\r\n\t\t\t\r\n\t\t\tlogrus.WithError(err).Errorf(\"fail to query changes for project %s\", project)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tresult = append(result, changes...)\r\n\t}\r\n\treturn result\r\n}","code-length":157,"reference":"\/\/ private handler implementation details","result":"Query all changes for all projects.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTypeFilterWrapperPlugin(plugin Plugin) *TypeFilterWrapperPlugin {\r\n\treturn &TypeFilterWrapperPlugin{\r\n\t\tplugin: plugin,\r\n\t\tpass:   map[string]bool{},\r\n\t}\r\n}","code-length":64,"reference":"\/\/ NewTypeFilterWrapperPlugin is the constructor of TypeFilterWrapperPlugin","result":"Wrap plugin types.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *TypeFilterWrapperPlugin) AddFlags(cmd *cobra.Command) {\r\n\tcmd.Flags().BoolVar(&t.pullRequests, \"no-pull-requests\", false, \"Ignore pull-requests\")\r\n\tcmd.Flags().BoolVar(&t.issues, \"no-issues\", false, \"Ignore issues\")\r\n}","code-length":90,"reference":"\/\/ AddFlags adds \"no-pull-requests\" and \"no-issues\" to the command help","result":"Add flags.","score":[0,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *TypeFilterWrapperPlugin) CheckFlags() error {\r\n\tif t.pullRequests && t.issues {\r\n\t\treturn fmt.Errorf(\r\n\t\t\t\"you can't ignore both pull-requests and issues\")\r\n\t}\r\n\treturn nil\r\n}","code-length":73,"reference":"\/\/ CheckFlags makes sure not both PR and issues are ignored","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *KubernetesClientOptions) AddFlags(fs *flag.FlagSet) {\r\n\tfs.StringVar(&o.namespace, \"namespace\", v1.NamespaceDefault, \"namespace to install on\")\r\n\tfs.StringVar(&o.kubeConfig, \"kubeconfig\", \"\", \"absolute path to the kubeConfig file\")\r\n\tfs.BoolVar(&o.inMemory, \"in_memory\", false, \"Use in memory client instead of CRD\")\r\n}","code-length":120,"reference":"\/\/ AddFlags adds kube client flags to existing FlagSet.","result":"Add flags to the client.","score":[0.1527,0.2972]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *KubernetesClientOptions) Validate() error {\r\n\tif o.kubeConfig != \"\" {\r\n\t\tif _, err := os.Stat(o.kubeConfig); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":80,"reference":"\/\/ Validate validates Kubernetes client options.","result":"Validate the generated code.","score":[0.1938,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *KubernetesClientOptions) Client(t Type) (ClientInterface, error) {\r\n\tif o.inMemory {\r\n\t\treturn newDummyClient(t), nil\r\n\t}\r\n\treturn o.newCRDClient(t)\r\n}","code-length":71,"reference":"\/\/ Client returns a ClientInterface based on the flags provided.","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *KubernetesClientOptions) newCRDClient(t Type) (*Client, error) {\r\n\tconfig, scheme, err := createRESTConfig(o.kubeConfig, t)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err = registerResource(config, t); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tvar restClient *rest.RESTClient\r\n\trestClient, err = rest.RESTClientFor(config)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\trc := Client{cl: restClient, ns: o.namespace, t: t,\r\n\t\tcodec: runtime.NewParameterCodec(scheme)}\r\n\treturn &rc, nil\r\n}","code-length":198,"reference":"\/\/ newClientFromFlags creates a CRD rest client from provided flags.","result":"Create a new CRDClient.","score":[0.0713,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc createRESTConfig(kubeconfig string, t Type) (config *rest.Config, types *runtime.Scheme, err error) {\r\n\tif kubeconfig == \"\" {\r\n\t\tconfig, err = rest.InClusterConfig()\r\n\t} else {\r\n\t\tconfig, err = clientcmd.BuildConfigFromFlags(\"\", kubeconfig)\r\n\t}\r\n\tif err != nil {\r\n\t\treturn\r\n\t}\r\n\tversion := schema.GroupVersion{\r\n\t\tGroup:   group,\r\n\t\tVersion: version,\r\n\t}\r\n\tconfig.GroupVersion = &version\r\n\tconfig.APIPath = \"\/apis\"\r\n\tconfig.ContentType = runtime.ContentTypeJSON\r\n\ttypes = runtime.NewScheme()\r\n\tschemeBuilder := runtime.NewSchemeBuilder(\r\n\t\tfunc(scheme *runtime.Scheme) error {\r\n\t\t\tscheme.AddKnownTypes(version, t.Object, t.Collection)\r\n\t\t\tv1.AddToGroupVersion(scheme, version)\r\n\t\t\treturn nil\r\n\t\t})\r\n\terr = schemeBuilder.AddToScheme(types)\r\n\tconfig.NegotiatedSerializer = serializer.DirectCodecFactory{CodecFactory: serializer.NewCodecFactory(types)}\r\n\treturn\r\n}","code-length":295,"reference":"\/\/ createRESTConfig for cluster API server, pass empty config file for in-cluster","result":"Create a new rest config.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc registerResource(config *rest.Config, t Type) error {\r\n\tc, err := apiextensionsclient.NewForConfig(config)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tcrd := &apiextensionsv1beta1.CustomResourceDefinition{\r\n\t\tObjectMeta: v1.ObjectMeta{\r\n\t\t\tName: fmt.Sprintf(\"%s.%s\", t.Plural, group),\r\n\t\t},\r\n\t\tSpec: apiextensionsv1beta1.CustomResourceDefinitionSpec{\r\n\t\t\tGroup:   group,\r\n\t\t\tVersion: version,\r\n\t\t\tScope:   apiextensionsv1beta1.NamespaceScoped,\r\n\t\t\tNames: apiextensionsv1beta1.CustomResourceDefinitionNames{\r\n\t\t\t\tSingular: t.Singular,\r\n\t\t\t\tPlural:   t.Plural,\r\n\t\t\t\tKind:     t.Kind,\r\n\t\t\t\tListKind: t.ListKind,\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n\tif _, err := c.ApiextensionsV1beta1().CustomResourceDefinitions().Create(crd); err != nil && !apierrors.IsAlreadyExists(err) {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":299,"reference":"\/\/ registerResource sends a request to create CRDs and waits for them to initialize","result":"Register a resource.","score":[0.0104,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newDummyClient(t Type) *dummyClient {\r\n\tc := &dummyClient{\r\n\t\tt:       t,\r\n\t\tobjects: make(map[string]Object),\r\n\t}\r\n\treturn c\r\n}","code-length":65,"reference":"\/\/ newDummyClient creates a in memory client representation for testing, such that we do not need to use a kubernetes API Server.","result":"Create a new client.","score":[0.0035,0.0495]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dummyClient) Update(obj Object) (Object, error) {\r\n\t_, ok := c.objects[obj.GetName()]\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"cannot find object %s\", obj.GetName())\r\n\t}\r\n\tc.objects[obj.GetName()] = obj\r\n\treturn obj, nil\r\n}","code-length":102,"reference":"\/\/ Update implements ClientInterface","result":"Update the object in the client.","score":[0.193,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc TrustedPullRequest(ghc githubClient, trigger plugins.Trigger, author, org, repo string, num int, l []github.Label) ([]github.Label, bool, error) {\r\n\t\r\n\tif orgMember, err := TrustedUser(ghc, trigger, author, org, repo); err != nil {\r\n\t\treturn l, false, fmt.Errorf(\"error checking %s for trust: %v\", author, err)\r\n\t} else if orgMember {\r\n\t\treturn l, true, nil\r\n\t}\r\n\t\r\n\tif l == nil {\r\n\t\tvar err error\r\n\t\tl, err = ghc.GetIssueLabels(org, repo, num)\r\n\t\tif err != nil {\r\n\t\t\treturn l, false, err\r\n\t\t}\r\n\t}\r\n\treturn l, github.HasLabel(labels.OkToTest, l), nil\r\n}","code-length":220,"reference":"\/\/ TrustedPullRequest returns whether or not the given PR should be tested.\n\/\/ It first checks if the author is in the org, then looks for \"ok-to-test\" label.","result":"Check if the PR is already trusted.","score":[0.0135,0.1436]}
{"code":"\/*is used to<extra_id_0>\r\nfunc buildAll(c Client, pr *github.PullRequest, eventGUID string, elideSkippedContexts bool) error {\r\n\torg, repo, number, branch := pr.Base.Repo.Owner.Login, pr.Base.Repo.Name, pr.Number, pr.Base.Ref\r\n\tchanges := config.NewGitHubDeferredChangedFilesProvider(c.GitHubClient, org, repo, number)\r\n\ttoTest, toSkipSuperset, err := pjutil.FilterPresubmits(pjutil.TestAllFilter(), changes, branch, c.Config.Presubmits[pr.Base.Repo.FullName], c.Logger)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ttoSkip := determineSkippedPresubmits(toTest, toSkipSuperset, c.Logger)\r\n\treturn runAndSkipJobs(c, pr, toTest, toSkip, eventGUID, elideSkippedContexts)\r\n}","code-length":223,"reference":"\/\/ buildAll ensures that all builds that should run and will be required are built","result":"Build all jobs.","score":[0.0075,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Options) Run(ctx context.Context) (int, error) {\r\n\tspec, err := downwardapi.ResolveSpecFromEnv()\r\n\tif err != nil {\r\n\t\treturn 0, fmt.Errorf(\"could not resolve job spec: %v\", err)\r\n\t}\r\n\tctx, cancel := context.WithCancel(ctx)\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tinterrupt := make(chan os.Signal)\r\n\tsignal.Notify(interrupt, os.Interrupt, syscall.SIGTERM)\r\n\tgo func() {\r\n\t\tselect {\r\n\t\tcase s := <-interrupt:\r\n\t\t\tlogrus.Errorf(\"Received an interrupt: %s, cancelling...\", s)\r\n\t\t\tcancel()\r\n\t\tcase <-ctx.Done():\r\n\t\t}\r\n\t}()\r\n\tif o.DeprecatedWrapperOptions != nil {\r\n\t\t\r\n\t\tlogrus.Warnf(\"Using deprecated wrapper_options instead of entries. Please update prow\/pod-utils\/decorate before June 2019\")\r\n\t}\r\n\tentries := o.entries()\r\n\tpassed, aborted, failures := wait(ctx, entries)\r\n\tcancel()\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tsignal.Ignore(os.Interrupt, syscall.SIGTERM)\r\n\tbuildLog := logReader(entries)\r\n\tmetadata := combineMetadata(entries)\r\n\treturn failures, o.doUpload(spec, passed, aborted, metadata, buildLog)\r\n}","code-length":371,"reference":"\/\/ Run will watch for the process being wrapped to exit\n\/\/ and then post the status of that process and any artifacts\n\/\/ to cloud storage.","result":"Run the job .","score":[0.0012,0.0405]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) AddConfig(conf common.ResourcesConfig) error {\r\n\treturn s.configs.Add(conf)\r\n}","code-length":41,"reference":"\/\/ AddConfig adds a new config","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) DeleteConfig(name string) error {\r\n\treturn s.configs.Delete(name)\r\n}","code-length":38,"reference":"\/\/ DeleteConfig deletes an existing config if it exists or fail otherwise","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) UpdateConfig(conf common.ResourcesConfig) error {\r\n\treturn s.configs.Update(conf)\r\n}","code-length":41,"reference":"\/\/ UpdateConfig updates a given if it exists or fail otherwise","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) GetConfig(name string) (common.ResourcesConfig, error) {\r\n\ti, err := s.configs.Get(name)\r\n\tif err != nil {\r\n\t\treturn common.ResourcesConfig{}, err\r\n\t}\r\n\tvar conf common.ResourcesConfig\r\n\tconf, err = common.ItemToResourcesConfig(i)\r\n\tif err != nil {\r\n\t\treturn common.ResourcesConfig{}, err\r\n\t}\r\n\treturn conf, nil\r\n}","code-length":127,"reference":"\/\/ GetConfig returns an existing if it exists errors out otherwise","result":"Avoid the need for the function to be executed.","score":[0,0.0463]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) GetConfigs() ([]common.ResourcesConfig, error) {\r\n\tvar configs []common.ResourcesConfig\r\n\titems, err := s.configs.List()\r\n\tif err != nil {\r\n\t\treturn configs, err\r\n\t}\r\n\tfor _, i := range items {\r\n\t\tvar conf common.ResourcesConfig\r\n\t\tconf, err = common.ItemToResourcesConfig(i)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tconfigs = append(configs, conf)\r\n\t}\r\n\treturn configs, nil\r\n}","code-length":157,"reference":"\/\/ GetConfigs returns all configs","result":"Get all the configs from the storage.","score":[0.1921,0.1923]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) SyncConfigs(newConfigs []common.ResourcesConfig) error {\r\n\ts.configsLock.Lock()\r\n\tdefer s.configsLock.Unlock()\r\n\tcurrentConfigs, err := s.GetConfigs()\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Error(\"cannot find configs\")\r\n\t\treturn err\r\n\t}\r\n\tcurrentSet := mapset.NewSet()\r\n\tnewSet := mapset.NewSet()\r\n\ttoUpdate := mapset.NewSet()\r\n\tconfigs := map[string]common.ResourcesConfig{}\r\n\tfor _, c := range currentConfigs {\r\n\t\tcurrentSet.Add(c.Name)\r\n\t\tconfigs[c.Name] = c\r\n\t}\r\n\tfor _, c := range newConfigs {\r\n\t\tnewSet.Add(c.Name)\r\n\t\tif old, exists := configs[c.Name]; exists {\r\n\t\t\tif !reflect.DeepEqual(old, c) {\r\n\t\t\t\ttoUpdate.Add(c.Name)\r\n\t\t\t\tconfigs[c.Name] = c\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\tconfigs[c.Name] = c\r\n\t\t}\r\n\t}\r\n\tvar finalError error\r\n\ttoDelete := currentSet.Difference(newSet)\r\n\ttoAdd := newSet.Difference(currentSet)\r\n\tfor _, n := range toDelete.ToSlice() {\r\n\t\tlogrus.Infof(\"Deleting config %s\", n.(string))\r\n\t\tif err := s.DeleteConfig(n.(string)); err != nil {\r\n\t\t\tlogrus.WithError(err).Errorf(\"failed to delete config %s\", n)\r\n\t\t\tfinalError = multierror.Append(finalError, err)\r\n\t\t}\r\n\t}\r\n\tfor _, n := range toAdd.ToSlice() {\r\n\t\trc := configs[n.(string)]\r\n\t\tlogrus.Infof(\"Adding config %s\", n.(string))\r\n\t\tif err := s.AddConfig(rc); err != nil {\r\n\t\t\tlogrus.WithError(err).Errorf(\"failed to create resources %s\", n)\r\n\t\t\tfinalError = multierror.Append(finalError, err)\r\n\t\t}\r\n\t}\r\n\tfor _, n := range toUpdate.ToSlice() {\r\n\t\trc := configs[n.(string)]\r\n\t\tlogrus.Infof(\"Updating config %s\", n.(string))\r\n\t\tif err := s.UpdateConfig(rc); err != nil {\r\n\t\t\tlogrus.WithError(err).Errorf(\"failed to update resources %s\", n)\r\n\t\t\tfinalError = multierror.Append(finalError, err)\r\n\t\t}\r\n\t}\r\n\treturn finalError\r\n}","code-length":680,"reference":"\/\/ SyncConfigs syncs new configs","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc addKnownTypes(scheme *runtime.Scheme) error {\r\n\tscheme.AddKnownTypes(SchemeGroupVersion,\r\n\t\t&ProwJob{},\r\n\t\t&ProwJobList{},\r\n\t)\r\n\tmetav1.AddToGroupVersion(scheme, SchemeGroupVersion)\r\n\treturn nil\r\n}","code-length":83,"reference":"\/\/ Adds the list of known types to the Scheme.","result":"Add custom types to the scheme.","score":[0.2042,0.5042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewController(continueOnError bool, addedPresubmitBlacklist sets.String, prowJobClient prowv1.ProwJobInterface, githubClient *github.Client, configAgent *config.Agent, pluginAgent *plugins.ConfigAgent) *Controller {\r\n\treturn &Controller{\r\n\t\tcontinueOnError:         continueOnError,\r\n\t\taddedPresubmitBlacklist: addedPresubmitBlacklist,\r\n\t\tprowJobTriggerer: &kubeProwJobTriggerer{\r\n\t\t\tprowJobClient: prowJobClient,\r\n\t\t\tgithubClient:  githubClient,\r\n\t\t\tconfigAgent:   configAgent,\r\n\t\t},\r\n\t\tgithubClient: githubClient,\r\n\t\tstatusMigrator: &gitHubMigrator{\r\n\t\t\tgithubClient:    githubClient,\r\n\t\t\tcontinueOnError: continueOnError,\r\n\t\t},\r\n\t\ttrustedChecker: &githubTrustedChecker{\r\n\t\t\tgithubClient: githubClient,\r\n\t\t\tpluginAgent:  pluginAgent,\r\n\t\t},\r\n\t}\r\n}","code-length":253,"reference":"\/\/ NewController constructs a new controller to reconcile stauses on config change","result":"Create a new controller.","score":[0.0611,0.1674]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) Run(stop <-chan os.Signal, changes <-chan config.Delta) {\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase change := <-changes:\r\n\t\t\tstart := time.Now()\r\n\t\t\tif err := c.reconcile(change); err != nil {\r\n\t\t\t\tlogrus.WithError(err).Error(\"Error reconciling statuses.\")\r\n\t\t\t}\r\n\t\t\tlogrus.WithField(\"duration\", fmt.Sprintf(\"%v\", time.Since(start))).Info(\"Statuses reconciled\")\r\n\t\tcase <-stop:\r\n\t\t\tlogrus.Info(\"status-reconciler is shutting down...\")\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":182,"reference":"\/\/ Run monitors the incoming configuration changes to determine when statuses need to be\n\/\/ reconciled on PRs in flight when blocking presubmits change","result":"Generate code for the generated code.","score":[0.0096,0.0225]}
{"code":"\/*is used to<extra_id_0>\r\nfunc addedBlockingPresubmits(old, new map[string][]config.Presubmit) map[string][]config.Presubmit {\r\n\tadded := map[string][]config.Presubmit{}\r\n\tfor repo, oldPresubmits := range old {\r\n\t\tadded[repo] = []config.Presubmit{}\r\n\t\tfor _, newPresubmit := range new[repo] {\r\n\t\t\tif !newPresubmit.ContextRequired() || newPresubmit.NeedsExplicitTrigger() {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tvar found bool\r\n\t\t\tfor _, oldPresubmit := range oldPresubmits {\r\n\t\t\t\tif oldPresubmit.Name == newPresubmit.Name {\r\n\t\t\t\t\tif oldPresubmit.SkipReport && !newPresubmit.SkipReport {\r\n\t\t\t\t\t\tadded[repo] = append(added[repo], newPresubmit)\r\n\t\t\t\t\t\tlogrus.WithFields(logrus.Fields{\r\n\t\t\t\t\t\t\t\"repo\": repo,\r\n\t\t\t\t\t\t\t\"name\": oldPresubmit.Name,\r\n\t\t\t\t\t\t}).Debug(\"Identified a newly-reporting blocking presubmit.\")\r\n\t\t\t\t\t}\r\n\t\t\t\t\tif oldPresubmit.RunIfChanged != newPresubmit.RunIfChanged {\r\n\t\t\t\t\t\tadded[repo] = append(added[repo], newPresubmit)\r\n\t\t\t\t\t\tlogrus.WithFields(logrus.Fields{\r\n\t\t\t\t\t\t\t\"repo\": repo,\r\n\t\t\t\t\t\t\t\"name\": oldPresubmit.Name,\r\n\t\t\t\t\t\t}).Debug(\"Identified a blocking presubmit running over a different set of files.\")\r\n\t\t\t\t\t}\r\n\t\t\t\t\tfound = true\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tif !found {\r\n\t\t\t\tadded[repo] = append(added[repo], newPresubmit)\r\n\t\t\t\tlogrus.WithFields(logrus.Fields{\r\n\t\t\t\t\t\"repo\": repo,\r\n\t\t\t\t\t\"name\": newPresubmit.Name,\r\n\t\t\t\t}).Debug(\"Identified an added blocking presubmit.\")\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tvar numAdded int\r\n\tfor _, presubmits := range added {\r\n\t\tnumAdded += len(presubmits)\r\n\t}\r\n\tlogrus.Infof(\"Identified %d added blocking presubmits.\", numAdded)\r\n\treturn added\r\n}","code-length":591,"reference":"\/\/ addedBlockingPresubmits determines new blocking presubmits based on a\n\/\/ config update. New blocking presubmits are either brand-new presubmits\n\/\/ or extant presubmits that are now reporting. Previous presubmits that\n\/\/ reported but were optional that are no longer optional require no action\n\/\/ as their contexts will already exist on PRs.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc removedBlockingPresubmits(old, new map[string][]config.Presubmit) map[string][]config.Presubmit {\r\n\tremoved := map[string][]config.Presubmit{}\r\n\tfor repo, oldPresubmits := range old {\r\n\t\tremoved[repo] = []config.Presubmit{}\r\n\t\tfor _, oldPresubmit := range oldPresubmits {\r\n\t\t\tif !oldPresubmit.ContextRequired() {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tvar found bool\r\n\t\t\tfor _, newPresubmit := range new[repo] {\r\n\t\t\t\tif oldPresubmit.Name == newPresubmit.Name {\r\n\t\t\t\t\tfound = true\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tif !found {\r\n\t\t\t\tremoved[repo] = append(removed[repo], oldPresubmit)\r\n\t\t\t\tlogrus.WithFields(logrus.Fields{\r\n\t\t\t\t\t\"repo\": repo,\r\n\t\t\t\t\t\"name\": oldPresubmit.Name,\r\n\t\t\t\t}).Debug(\"Identified a removed blocking presubmit.\")\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tvar numRemoved int\r\n\tfor _, presubmits := range removed {\r\n\t\tnumRemoved += len(presubmits)\r\n\t}\r\n\tlogrus.Infof(\"Identified %d removed blocking presubmits.\", numRemoved)\r\n\treturn removed\r\n}","code-length":362,"reference":"\/\/ removedBlockingPresubmits determines stale blocking presubmits based on a\n\/\/ config update. Presubmits that are no longer blocking due to no longer\n\/\/ reporting or being optional require no action as Tide will honor those\n\/\/ statuses correctly.","result":"Identify removed blocking presubmits.","score":[0.0001,0.0145]}
{"code":"\/*is used to<extra_id_0>\r\nfunc migratedBlockingPresubmits(old, new map[string][]config.Presubmit) map[string][]presubmitMigration {\r\n\tmigrated := map[string][]presubmitMigration{}\r\n\tfor repo, oldPresubmits := range old {\r\n\t\tmigrated[repo] = []presubmitMigration{}\r\n\t\tfor _, newPresubmit := range new[repo] {\r\n\t\t\tif !newPresubmit.ContextRequired() {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tfor _, oldPresubmit := range oldPresubmits {\r\n\t\t\t\tif oldPresubmit.Context != newPresubmit.Context && oldPresubmit.Name == newPresubmit.Name {\r\n\t\t\t\t\tmigrated[repo] = append(migrated[repo], presubmitMigration{from: oldPresubmit, to: newPresubmit})\r\n\t\t\t\t\tlogrus.WithFields(logrus.Fields{\r\n\t\t\t\t\t\t\"repo\": repo,\r\n\t\t\t\t\t\t\"name\": oldPresubmit.Name,\r\n\t\t\t\t\t\t\"from\": oldPresubmit.Context,\r\n\t\t\t\t\t\t\"to\":   newPresubmit.Context,\r\n\t\t\t\t\t}).Debug(\"Identified a migrated blocking presubmit.\")\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tvar numMigrated int\r\n\tfor _, presubmits := range migrated {\r\n\t\tnumMigrated += len(presubmits)\r\n\t}\r\n\tlogrus.Infof(\"Identified %d migrated blocking presubmits.\", numMigrated)\r\n\treturn migrated\r\n}","code-length":395,"reference":"\/\/ migratedBlockingPresubmits determines blocking presubmits that have had\n\/\/ their status contexts migrated. This is a best-effort evaluation as we\n\/\/ can only track a presubmit between configuration versions by its name.\n\/\/ A presubmit \"migration\" that had its underlying job and context changed\n\/\/ will be treated as a deletion and creation.","result":"Identify the migrated blocking presubmits.","score":[0.0,0.0104]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Load(loader OptionLoader) error {\r\n\tif jsonConfig, provided := os.LookupEnv(loader.ConfigVar()); provided {\r\n\t\tif err := loader.LoadConfig(jsonConfig); err != nil {\r\n\t\t\treturn fmt.Errorf(\"could not load config from JSON var %s: %v\", loader.ConfigVar(), err)\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\tfs := flag.NewFlagSet(os.Args[0], flag.ExitOnError)\r\n\tloader.AddFlags(fs)\r\n\tfs.Parse(os.Args[1:])\r\n\tloader.Complete(fs.Args())\r\n\treturn nil\r\n}","code-length":167,"reference":"\/\/ Load loads the set of options, preferring to use\n\/\/ JSON config from an env var, but falling back to\n\/\/ command line flags if not possible.","result":"Load options from JSON env vars.","score":[0.007,0.0775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) canExecuteConcurrently(pj *prowapi.ProwJob) bool {\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tif max := c.config().MaxConcurrency; max > 0 {\r\n\t\tvar running int\r\n\t\tfor _, num := range c.pendingJobs {\r\n\t\t\trunning += num\r\n\t\t}\r\n\t\tif running >= max {\r\n\t\t\tc.log.WithFields(pjutil.ProwJobFields(pj)).Debugf(\"Not starting another job, already %d running.\", running)\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\tif pj.Spec.MaxConcurrency == 0 {\r\n\t\tc.pendingJobs[pj.Spec.Job]++\r\n\t\treturn true\r\n\t}\r\n\tnumPending := c.pendingJobs[pj.Spec.Job]\r\n\tif numPending >= pj.Spec.MaxConcurrency {\r\n\t\tc.log.WithFields(pjutil.ProwJobFields(pj)).Debugf(\"Not starting another instance of %s, already %d running.\", pj.Spec.Job, numPending)\r\n\t\treturn false\r\n\t}\r\n\tc.pendingJobs[pj.Spec.Job]++\r\n\treturn true\r\n}","code-length":324,"reference":"\/\/ canExecuteConcurrently checks whether the provided ProwJob can\n\/\/ be executed concurrently.","result":"Prevent infinite loops.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getJenkinsJobs(pjs []prowapi.ProwJob) []BuildQueryParams {\r\n\tjenkinsJobs := []BuildQueryParams{}\r\n\tfor _, pj := range pjs {\r\n\t\tif pj.Complete() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tjenkinsJobs = append(jenkinsJobs, BuildQueryParams{\r\n\t\t\tJobName:   getJobName(&pj.Spec),\r\n\t\t\tProwJobID: pj.Name,\r\n\t\t})\r\n\t}\r\n\treturn jenkinsJobs\r\n}","code-length":140,"reference":"\/\/ getJenkinsJobs returns all the Jenkins jobs for all active\n\/\/ prowjobs from the provided list. It handles deduplication.","result":"Get the Jenkins jobs from the API.","score":[0.0731,0.2719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) terminateDupes(pjs []prowapi.ProwJob, jbs map[string]Build) error {\r\n\t\r\n\tdupes := make(map[string]int)\r\n\tfor i, pj := range pjs {\r\n\t\tif pj.Complete() || pj.Spec.Type != prowapi.PresubmitJob {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tn := fmt.Sprintf(\"%s %s\/%s#%d\", pj.Spec.Job, pj.Spec.Refs.Org, pj.Spec.Refs.Repo, pj.Spec.Refs.Pulls[0].Number)\r\n\t\tprev, ok := dupes[n]\r\n\t\tif !ok {\r\n\t\t\tdupes[n] = i\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tcancelIndex := i\r\n\t\tif (&pjs[prev].Status.StartTime).Before(&pj.Status.StartTime) {\r\n\t\t\tcancelIndex = prev\r\n\t\t\tdupes[n] = i\r\n\t\t}\r\n\t\ttoCancel := pjs[cancelIndex]\r\n\t\t\r\n\t\t\r\n\t\tif c.config().AllowCancellations {\r\n\t\t\tbuild, buildExists := jbs[toCancel.ObjectMeta.Name]\r\n\t\t\t\r\n\t\t\tif buildExists && build.IsEnqueued() {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif buildExists {\r\n\t\t\t\tif err := c.jc.Abort(getJobName(&toCancel.Spec), &build); err != nil {\r\n\t\t\t\t\tc.log.WithError(err).WithFields(pjutil.ProwJobFields(&toCancel)).Warn(\"Cannot cancel Jenkins build\")\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\ttoCancel.SetComplete()\r\n\t\tprevState := toCancel.Status.State\r\n\t\ttoCancel.Status.State = prowapi.AbortedState\r\n\t\tc.log.WithFields(pjutil.ProwJobFields(&toCancel)).\r\n\t\t\tWithField(\"from\", prevState).\r\n\t\t\tWithField(\"to\", toCancel.Status.State).Info(\"Transitioning states.\")\r\n\t\tnpj, err := c.prowJobClient.Update(&toCancel)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tpjs[cancelIndex] = *npj\r\n\t}\r\n\treturn nil\r\n}","code-length":608,"reference":"\/\/ terminateDupes aborts presubmits that have a newer version. It modifies pjs\n\/\/ in-place when it aborts.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Throttle(hourlyTokens, burst int) {\r\n\tc.log(\"Throttle\", hourlyTokens, burst)\r\n\tc.throttle.lock.Lock()\r\n\tdefer c.throttle.lock.Unlock()\r\n\tpreviouslyThrottled := c.throttle.ticker != nil\r\n\tif hourlyTokens <= 0 || burst <= 0 {\r\n\t\tif previouslyThrottled {\r\n\t\t\tc.client = c.throttle.http\r\n\t\t\tc.gqlc = c.throttle.graph\r\n\t\t\tc.throttle.ticker.Stop()\r\n\t\t\tc.throttle.ticker = nil\r\n\t\t}\r\n\t\treturn\r\n\t}\r\n\trate := time.Hour \/ time.Duration(hourlyTokens)\r\n\tticker := time.NewTicker(rate)\r\n\tthrottle := make(chan time.Time, burst)\r\n\tfor i := 0; i < burst; i++ {\r\n\t\tthrottle <- time.Now()\r\n\t}\r\n\tgo func() {\r\n\t\t\r\n\t\tfor t := range ticker.C {\r\n\t\t\tselect {\r\n\t\t\tcase throttle <- t:\r\n\t\t\tdefault:\r\n\t\t\t}\r\n\t\t}\r\n\t}()\r\n\tif !previouslyThrottled {\r\n\t\tc.throttle.http = c.client\r\n\t\tc.throttle.graph = c.gqlc\r\n\t\tc.client = &c.throttle\r\n\t\tc.gqlc = &c.throttle\r\n\t}\r\n\tc.throttle.ticker = ticker\r\n\tc.throttle.throttle = throttle\r\n}","code-length":407,"reference":"\/\/ Throttle client to a rate of at most hourlyTokens requests per hour,\n\/\/ allowing burst tokens.","result":"Set up the throttle function.","score":[0,0.0316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClientWithFields(fields logrus.Fields, getToken func() []byte, graphqlEndpoint string, bases ...string) *Client {\r\n\treturn &Client{\r\n\t\tlogger: logrus.WithFields(fields).WithField(\"client\", \"github\"),\r\n\t\ttime:   &standardTime{},\r\n\t\tgqlc: githubql.NewEnterpriseClient(\r\n\t\t\tgraphqlEndpoint,\r\n\t\t\t&http.Client{\r\n\t\t\t\tTimeout:   maxRequestTime,\r\n\t\t\t\tTransport: &oauth2.Transport{Source: newReloadingTokenSource(getToken)},\r\n\t\t\t}),\r\n\t\tclient:   &http.Client{Timeout: maxRequestTime},\r\n\t\tbases:    bases,\r\n\t\tgetToken: getToken,\r\n\t\tdry:      false,\r\n\t}\r\n}","code-length":202,"reference":"\/\/ NewClientWithFields creates a new fully operational GitHub client. With\n\/\/ added logging fields.\n\/\/ 'getToken' is a generator for the GitHub access token to use.\n\/\/ 'bases' is a variadic slice of endpoints to use in order of preference.\n\/\/   An endpoint is used when all preceding endpoints have returned a conn err.\n\/\/   This should be used when using the ghproxy GitHub proxy cache to allow\n\/\/   this client to bypass the cache if it is temporarily unavailable.","result":"Create a new client with fields.","score":[0.0,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(getToken func() []byte, graphqlEndpoint string, bases ...string) *Client {\r\n\treturn NewClientWithFields(logrus.Fields{}, getToken, graphqlEndpoint, bases...)\r\n}","code-length":54,"reference":"\/\/ NewClient creates a new fully operational GitHub client.","result":"Generate the client code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDryRunClient(getToken func() []byte, graphqlEndpoint string, bases ...string) *Client {\r\n\treturn NewDryRunClientWithFields(logrus.Fields{}, getToken, graphqlEndpoint, bases...)\r\n}","code-length":58,"reference":"\/\/ NewDryRunClient creates a new client that will not perform mutating actions\n\/\/ such as setting statuses or commenting, but it will still query GitHub and\n\/\/ use up API tokens.\n\/\/ 'getToken' is a generator the GitHub access token to use.\n\/\/ 'bases' is a variadic slice of endpoints to use in order of preference.\n\/\/   An endpoint is used when all preceding endpoints have returned a conn err.\n\/\/   This should be used when using the ghproxy GitHub proxy cache to allow\n\/\/   this client to bypass the cache if it is temporarily unavailable.","result":"GraphqlEndpoint string.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFakeClient() *Client {\r\n\treturn &Client{\r\n\t\tlogger: logrus.WithField(\"client\", \"github\"),\r\n\t\ttime:   &standardTime{},\r\n\t\tfake:   true,\r\n\t\tdry:    true,\r\n\t}\r\n}","code-length":78,"reference":"\/\/ NewFakeClient creates a new client that will not perform any actions at all.","result":"Create a new client.","score":[0.0371,0.2265]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) request(r *request, ret interface{}) (int, error) {\r\n\tstatusCode, b, err := c.requestRaw(r)\r\n\tif err != nil {\r\n\t\treturn statusCode, err\r\n\t}\r\n\tif ret != nil {\r\n\t\tif err := json.Unmarshal(b, ret); err != nil {\r\n\t\t\treturn statusCode, err\r\n\t\t}\r\n\t}\r\n\treturn statusCode, nil\r\n}","code-length":121,"reference":"\/\/ Make a request with retries. If ret is not nil, unmarshal the response body\n\/\/ into it. Returns an error if the exit code is not one of the provided codes.","result":"Call the client to send a request.","score":[0.0054,0.0339]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) requestRaw(r *request) (int, []byte, error) {\r\n\tif c.fake || (c.dry && r.method != http.MethodGet) {\r\n\t\treturn r.exitCodes[0], nil, nil\r\n\t}\r\n\tresp, err := c.requestRetry(r.method, r.path, r.accept, r.requestBody)\r\n\tif err != nil {\r\n\t\treturn 0, nil, err\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\tb, err := ioutil.ReadAll(resp.Body)\r\n\tif err != nil {\r\n\t\treturn 0, nil, err\r\n\t}\r\n\tvar okCode bool\r\n\tfor _, code := range r.exitCodes {\r\n\t\tif code == resp.StatusCode {\r\n\t\t\tokCode = true\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif !okCode {\r\n\t\tclientError := unmarshalClientError(b)\r\n\t\terr = requestError{\r\n\t\t\tClientError: clientError,\r\n\t\t\tErrorString: fmt.Sprintf(\"status code %d not one of %v, body: %s\", resp.StatusCode, r.exitCodes, string(b)),\r\n\t\t}\r\n\t}\r\n\treturn resp.StatusCode, b, err\r\n}","code-length":330,"reference":"\/\/ requestRaw makes a request with retries and returns the response body.\n\/\/ Returns an error if the exit code is not one of the provided codes.","result":"Generate the code.","score":[0.0001,0.0203]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) getUserData() error {\r\n\tc.log(\"User\")\r\n\tvar u User\r\n\t_, err := c.request(&request{\r\n\t\tmethod:    http.MethodGet,\r\n\t\tpath:      \"\/user\",\r\n\t\texitCodes: []int{200},\r\n\t}, &u)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tc.botName = u.Login\r\n\t\r\n\t\r\n\t","code-length":128,"reference":"\/\/ Not thread-safe - callers need to hold c.mut.","result":"Get user data from bot.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) readPaginatedResultsWithValues(path string, values url.Values, accept string, newObj func() interface{}, accumulate func(interface{})) error {\r\n\tpagedPath := path\r\n\tif len(values) > 0 {\r\n\t\tpagedPath += \"?\" + values.Encode()\r\n\t}\r\n\tfor {\r\n\t\tresp, err := c.requestRetry(http.MethodGet, pagedPath, accept, nil)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdefer resp.Body.Close()\r\n\t\tif resp.StatusCode < 200 || resp.StatusCode > 299 {\r\n\t\t\treturn fmt.Errorf(\"return code not 2XX: %s\", resp.Status)\r\n\t\t}\r\n\t\tb, err := ioutil.ReadAll(resp.Body)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tobj := newObj()\r\n\t\tif err := json.Unmarshal(b, obj); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\taccumulate(obj)\r\n\t\tlink := parseLinks(resp.Header.Get(\"Link\"))[\"next\"]\r\n\t\tif link == \"\" {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tu, err := url.Parse(link)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to parse 'next' link: %v\", err)\r\n\t\t}\r\n\t\tpagedPath = u.RequestURI()\r\n\t}\r\n\treturn nil\r\n}","code-length":389,"reference":"\/\/ readPaginatedResultsWithValues is an override that allows control over the query string.","result":"Return paginated results.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) UpdatePullRequest(org, repo string, number int, title, body *string, open *bool, branch *string, canModify *bool) error {\r\n\tc.log(\"UpdatePullRequest\", org, repo, title)\r\n\tdata := struct {\r\n\t\tState *string `json:\"state,omitempty\"`\r\n\t\tTitle *string `json:\"title,omitempty\"`\r\n\t\tBody  *string `json:\"body,omitempty\"`\r\n\t\tBase  *string `json:\"base,omitempty\"`\r\n\t\t\r\n\t\t\r\n\t\tMaintainerCanModify *bool `json:\"maintainer_can_modify,omitempty\"`\r\n\t}{\r\n\t\tTitle:               title,\r\n\t\tBody:                body,\r\n\t\tBase:                branch,\r\n\t\tMaintainerCanModify: canModify,\r\n\t}\r\n\tif open != nil && *open {\r\n\t\top := \"open\"\r\n\t\tdata.State = &op\r\n\t} else if open != nil {\r\n\t\tcl := \"clossed\"\r\n\t\tdata.State = &cl\r\n\t}\r\n\t_, err := c.request(&request{\r\n\t\t\r\n\t\tatch,\r\n\t\tpath:        fmt.Sprintf(\"\/repos\/%s\/%s\/pulls\/%d\", org, repo, number),\r\n\t\trequestBody: &data,\r\n\t\texitCodes:   []int{200},\r\n\t}, nil)\r\n\treturn err\r\n}","code-length":361,"reference":"\/\/ UpdatePullRequest modifies the title, body, open state","result":"Update a pull request.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) getLabels(path string) ([]Label, error) {\r\n\tvar labels []Label\r\n\tif c.fake {\r\n\t\treturn labels, nil\r\n\t}\r\n\terr := c.readPaginatedResults(\r\n\t\tpath,\r\n\t\t\"application\/vnd.github.symmetra-preview+json\",\r\n\t\t\tlabels = append(labels, *(obj.(*[]Label))...)\r\n\t\t},\r\n\t)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn labels, nil\r\n}","code-length":150,"reference":"\/\/ getLabels is a helper function that retrieves a paginated list of labels from a github URI path.","result":"Fetch labels.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc stateCannotBeChangedOrOriginalError(err error) error {\r\n\trequestErr, ok := err.(requestError)\r\n\tif ok {\r\n\t\tfor _, errorMsg := range requestErr.ErrorMessages() {\r\n\t\t\tif strings.Contains(errorMsg, stateCannotBeChangedMessagePrefix) {\r\n\t\t\t\treturn StateCannotBeChanged{\r\n\t\t\t\t\tMessage: errorMsg,\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn err\r\n}","code-length":125,"reference":"\/\/ convert to a StateCannotBeChanged if appropriate or else return the original error","result":"Detect state cannot be changed or original error.","score":[0.0884,0.08]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) IsMergeable(org, repo string, number int, SHA string) (bool, error) {\r\n\tbackoff := time.Second * 3\r\n\tmaxTries := 3\r\n\tfor try := 0; try < maxTries; try++ {\r\n\t\tpr, err := c.GetPullRequest(org, repo, number)\r\n\t\tif err != nil {\r\n\t\t\treturn false, err\r\n\t\t}\r\n\t\tif pr.Head.SHA != SHA {\r\n\t\t\treturn false, fmt.Errorf(\"pull request head changed while checking mergeability (%s -> %s)\", SHA, pr.Head.SHA)\r\n\t\t}\r\n\t\tif pr.Merged {\r\n\t\t\treturn false, errors.New(\"pull request was merged while checking mergeability\")\r\n\t\t}\r\n\t\tif pr.Mergable != nil {\r\n\t\t\treturn *pr.Mergable, nil\r\n\t\t}\r\n\t\tif try+1 < maxTries {\r\n\t\t\tc.time.Sleep(backoff)\r\n\t\t\tbackoff *= 2\r\n\t\t}\r\n\t}\r\n\treturn false, fmt.Errorf(\"reached maximum number of retries (%d) checking mergeability\", maxTries)\r\n}","code-length":297,"reference":"\/\/ IsMergeable determines if a PR can be merged.\n\/\/ Mergeability is calculated by a background job on GitHub and is not immediately available when\n\/\/ new commits are added so the PR must be polled until the background job completes.","result":"Check if a file is merged.","score":[0.001,0.0533]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *reloadingTokenSource) Token() (*oauth2.Token, error) {\r\n\treturn &oauth2.Token{\r\n\t\tAccessToken: string(s.getToken()),\r\n\t}, nil\r\n}","code-length":62,"reference":"\/\/ Token is an implementation for oauth2.TokenSource interface.","result":"Reload token.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Spyglass) ListArtifacts(src string) ([]string, error) {\r\n\tkeyType, key, err := splitSrc(src)\r\n\tif err != nil {\r\n\t\treturn []string{}, fmt.Errorf(\"error parsing src: %v\", err)\r\n\t}\r\n\tgcsKey := \"\"\r\n\tswitch keyType {\r\n\tcase gcsKeyType:\r\n\t\tgcsKey = key\r\n\tcase prowKeyType:\r\n\t\tif gcsKey, err = s.prowToGCS(key); err != nil {\r\n\t\t\tlogrus.Warningf(\"Failed to get gcs source for prow job: %v\", err)\r\n\t\t}\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"Unrecognized key type for src: %v\", src)\r\n\t}\r\n\tartifactNames, err := s.GCSArtifactFetcher.artifacts(gcsKey)\r\n\tlogFound := false\r\n\tfor _, name := range artifactNames {\r\n\t\tif name == \"build-log.txt\" {\r\n\t\t\tlogFound = true\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif err != nil || !logFound {\r\n\t\tartifactNames = append(artifactNames, \"build-log.txt\")\r\n\t}\r\n\treturn artifactNames, nil\r\n}","code-length":326,"reference":"\/\/ ListArtifacts gets the names of all artifacts available from the given source","result":"List all the artifacts in the package.","score":[0.0969,0.2016]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (*Spyglass) KeyToJob(src string) (jobName string, buildID string, err error) {\r\n\tsrc = strings.Trim(src, \"\/\")\r\n\tparsed := strings.Split(src, \"\/\")\r\n\tif len(parsed) < 2 {\r\n\t\treturn \"\", \"\", fmt.Errorf(\"expected at least two path components in %q\", src)\r\n\t}\r\n\tjobName = parsed[len(parsed)-2]\r\n\tbuildID = parsed[len(parsed)-1]\r\n\treturn jobName, buildID, nil\r\n}","code-length":142,"reference":"\/\/ KeyToJob takes a spyglass URL and returns the jobName and buildID.","result":"Convert a string to a job name.","score":[0.0791,0.0435]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Spyglass) prowToGCS(prowKey string) (string, error) {\r\n\tjobName, buildID, err := s.KeyToJob(prowKey)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"could not get GCS src: %v\", err)\r\n\t}\r\n\tjob, err := s.jobAgent.GetProwJob(jobName, buildID)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"Failed to get prow job from src %q: %v\", prowKey, err)\r\n\t}\r\n\turl := job.Status.URL\r\n\tprefix := s.config().Plank.GetJobURLPrefix(job.Spec.Refs)\r\n\tif !strings.HasPrefix(url, prefix) {\r\n\t\treturn \"\", fmt.Errorf(\"unexpected job URL %q when finding GCS path: expected something starting with %q\", url, prefix)\r\n\t}\r\n\treturn url[len(prefix):], nil\r\n}","code-length":252,"reference":"\/\/ prowToGCS returns the GCS key corresponding to the given prow key","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Spyglass) FetchArtifacts(src string, podName string, sizeLimit int64, artifactNames []string) ([]lenses.Artifact, error) {\r\n\tartStart := time.Now()\r\n\tarts := []lenses.Artifact{}\r\n\tkeyType, key, err := splitSrc(src)\r\n\tif err != nil {\r\n\t\treturn arts, fmt.Errorf(\"error parsing src: %v\", err)\r\n\t}\r\n\tjobName, buildID, err := s.KeyToJob(src)\r\n\tif err != nil {\r\n\t\treturn arts, fmt.Errorf(\"could not derive job: %v\", err)\r\n\t}\r\n\tgcsKey := \"\"\r\n\tswitch keyType {\r\n\tcase gcsKeyType:\r\n\t\tgcsKey = strings.TrimSuffix(key, \"\/\")\r\n\tcase prowKeyType:\r\n\t\tif gcsKey, err = s.prowToGCS(key); err != nil {\r\n\t\t\tlogrus.Warningln(err)\r\n\t\t}\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"invalid src: %v\", src)\r\n\t}\r\n\tpodLogNeeded := false\r\n\tfor _, name := range artifactNames {\r\n\t\tart, err := s.GCSArtifactFetcher.artifact(gcsKey, name, sizeLimit)\r\n\t\tif err == nil {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t_, err = art.Size()\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\tif name == \"build-log.txt\" {\r\n\t\t\t\tpodLogNeeded = true\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tarts = append(arts, art)\r\n\t}\r\n\tif podLogNeeded {\r\n\t\tart, err := s.PodLogArtifactFetcher.artifact(jobName, buildID, sizeLimit)\r\n\t\tif err != nil {\r\n\t\t\tlogrus.Errorf(\"Failed to fetch pod log: %v\", err)\r\n\t\t} else {\r\n\t\t\tarts = append(arts, art)\r\n\t\t}\r\n\t}\r\n\tlogrus.WithField(\"duration\", time.Since(artStart)).Infof(\"Retrieved artifacts for %v\", src)\r\n\treturn arts, nil\r\n}","code-length":568,"reference":"\/\/ FetchArtifacts constructs and returns Artifact objects for each artifact name in the list.\n\/\/ This includes getting any handles needed for read write operations, direct artifact links, etc.","result":"Code too long,keep in 512.","score":[0.002,0.0188]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *DecorationConfig) DeepCopy() *DecorationConfig {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(DecorationConfig)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":70,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new DecorationConfig.","result":"Avoid deep copy.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *GCSConfiguration) DeepCopy() *GCSConfiguration {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(GCSConfiguration)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":70,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new GCSConfiguration.","result":"Create a deep copy of the objects.","score":[0.0707,0.2373]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *JenkinsSpec) DeepCopy() *JenkinsSpec {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(JenkinsSpec)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":70,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new JenkinsSpec.","result":"Create a deep copy of the same object.","score":[0.078,0.2355]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ProwJob) DeepCopy() *ProwJob {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(ProwJob)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":70,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new ProwJob.","result":"Avoid deep copy.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ProwJobList) DeepCopy() *ProwJobList {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(ProwJobList)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":73,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new ProwJobList.","result":"Avoid deep copy.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ProwJobSpec) DeepCopy() *ProwJobSpec {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(ProwJobSpec)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":73,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new ProwJobSpec.","result":"Create a deep copy of the same object.","score":[0.078,0.2355]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ProwJobStatus) DeepCopy() *ProwJobStatus {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(ProwJobStatus)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":70,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new ProwJobStatus.","result":"Create a deep copy of the same object.","score":[0.078,0.2355]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *Pull) DeepCopy() *Pull {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(Pull)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":64,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new Pull.","result":"Avoid deep copy.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *Refs) DeepCopy() *Refs {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(Refs)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":64,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new Refs.","result":"Avoid deep copy.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *UtilityImages) DeepCopy() *UtilityImages {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(UtilityImages)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":67,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new UtilityImages.","result":"Copy library functions.","score":[0,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc upload(rsClient *resultstore.Client, inv resultstore.Invocation, target resultstore.Target, test resultstore.Test) (string, error) {\r\n\ttargetID := test.Name\r\n\tconst configID = resultstore.Default\r\n\tinvName, err := rsClient.Invocations().Create(inv)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"create invocation: %v\", err)\r\n\t}\r\n\ttargetName, err := rsClient.Targets(invName).Create(targetID, target)\r\n\tif err != nil {\r\n\t\treturn resultstore.URL(invName), fmt.Errorf(\"create target: %v\", err)\r\n\t}\r\n\turl := resultstore.URL(targetName)\r\n\t_, err = rsClient.Configurations(invName).Create(configID)\r\n\tif err != nil {\r\n\t\treturn url, fmt.Errorf(\"create configuration: %v\", err)\r\n\t}\r\n\tctName, err := rsClient.ConfiguredTargets(targetName, configID).Create(test.Action)\r\n\tif err != nil {\r\n\t\treturn url, fmt.Errorf(\"create configured target: %v\", err)\r\n\t}\r\n\t_, err = rsClient.Actions(ctName).Create(\"primary\", test)\r\n\tif err != nil {\r\n\t\treturn url, fmt.Errorf(\"create action: %v\", err)\r\n\t}\r\n\treturn url, nil\r\n}","code-length":356,"reference":"\/\/ upload the result downloaded from path into project.","result":"Upload result to resultstore.","score":[0.0915,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DecorationConfig) ApplyDefault(def *DecorationConfig) *DecorationConfig {\r\n\tif d == nil && def == nil {\r\n\t\treturn nil\r\n\t}\r\n\tvar merged DecorationConfig\r\n\tif d != nil {\r\n\t\tmerged = *d\r\n\t} else {\r\n\t\tmerged = *def\r\n\t}\r\n\tif d == nil || def == nil {\r\n\t\treturn &merged\r\n\t}\r\n\tmerged.UtilityImages = merged.UtilityImages.ApplyDefault(def.UtilityImages)\r\n\tmerged.GCSConfiguration = merged.GCSConfiguration.ApplyDefault(def.GCSConfiguration)\r\n\tif merged.Timeout.Duration == 0 {\r\n\t\tmerged.Timeout = def.Timeout\r\n\t}\r\n\tif merged.GracePeriod.Duration == 0 {\r\n\t\tmerged.GracePeriod = def.GracePeriod\r\n\t}\r\n\tif merged.GCSCredentialsSecret == \"\" {\r\n\t\tmerged.GCSCredentialsSecret = def.GCSCredentialsSecret\r\n\t}\r\n\tif len(merged.SSHKeySecrets) == 0 {\r\n\t\tmerged.SSHKeySecrets = def.SSHKeySecrets\r\n\t}\r\n\tif len(merged.SSHHostFingerprints) == 0 {\r\n\t\tmerged.SSHHostFingerprints = def.SSHHostFingerprints\r\n\t}\r\n\tif merged.SkipCloning == nil {\r\n\t\tmerged.SkipCloning = def.SkipCloning\r\n\t}\r\n\tif merged.CookiefileSecret == \"\" {\r\n\t\tmerged.CookiefileSecret = def.CookiefileSecret\r\n\t}\r\n\treturn &merged\r\n}","code-length":396,"reference":"\/\/ ApplyDefault applies the defaults for the ProwJob decoration. If a field has a zero value, it\n\/\/ replaces that with the value set in def.","result":"Apply default values to the decorated images.","score":[0.0107,0.083]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DecorationConfig) Validate() error {\r\n\tif d.UtilityImages == nil {\r\n\t\treturn errors.New(\"utility image config is not specified\")\r\n\t}\r\n\tvar missing []string\r\n\tif d.UtilityImages.CloneRefs == \"\" {\r\n\t\tmissing = append(missing, \"clonerefs\")\r\n\t}\r\n\tif d.UtilityImages.InitUpload == \"\" {\r\n\t\tmissing = append(missing, \"initupload\")\r\n\t}\r\n\tif d.UtilityImages.Entrypoint == \"\" {\r\n\t\tmissing = append(missing, \"entrypoint\")\r\n\t}\r\n\tif d.UtilityImages.Sidecar == \"\" {\r\n\t\tmissing = append(missing, \"sidecar\")\r\n\t}\r\n\tif len(missing) > 0 {\r\n\t\treturn fmt.Errorf(\"the following utility images are not specified: %q\", missing)\r\n\t}\r\n\tif d.GCSConfiguration == nil {\r\n\t\treturn errors.New(\"GCS upload configuration is not specified\")\r\n\t}\r\n\tif d.GCSCredentialsSecret == \"\" {\r\n\t\treturn errors.New(\"GCS upload credential secret is not specified\")\r\n\t}\r\n\tif err := d.GCSConfiguration.Validate(); err != nil {\r\n\t\treturn fmt.Errorf(\"GCS configuration is invalid: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":345,"reference":"\/\/ Validate ensures all the values set in the DecorationConfig are valid.","result":"Validate the code.","score":[0.0242,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *UtilityImages) ApplyDefault(def *UtilityImages) *UtilityImages {\r\n\tif u == nil {\r\n\t\treturn def\r\n\t} else if def == nil {\r\n\t\treturn u\r\n\t}\r\n\tmerged := *u\r\n\tif merged.CloneRefs == \"\" {\r\n\t\tmerged.CloneRefs = def.CloneRefs\r\n\t}\r\n\tif merged.InitUpload == \"\" {\r\n\t\tmerged.InitUpload = def.InitUpload\r\n\t}\r\n\tif merged.Entrypoint == \"\" {\r\n\t\tmerged.Entrypoint = def.Entrypoint\r\n\t}\r\n\tif merged.Sidecar == \"\" {\r\n\t\tmerged.Sidecar = def.Sidecar\r\n\t}\r\n\treturn &merged\r\n}","code-length":190,"reference":"\/\/ ApplyDefault applies the defaults for the UtilityImages decorations. If a field has a zero value,\n\/\/ it replaces that with the value set in def.","result":"Apply default values.","score":[0,0.0422]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *GCSConfiguration) ApplyDefault(def *GCSConfiguration) *GCSConfiguration {\r\n\tif g == nil && def == nil {\r\n\t\treturn nil\r\n\t}\r\n\tvar merged GCSConfiguration\r\n\tif g != nil {\r\n\t\tmerged = *g\r\n\t} else {\r\n\t\tmerged = *def\r\n\t}\r\n\tif g == nil || def == nil {\r\n\t\treturn &merged\r\n\t}\r\n\tif merged.Bucket == \"\" {\r\n\t\tmerged.Bucket = def.Bucket\r\n\t}\r\n\tif merged.PathPrefix == \"\" {\r\n\t\tmerged.PathPrefix = def.PathPrefix\r\n\t}\r\n\tif merged.PathStrategy == \"\" {\r\n\t\tmerged.PathStrategy = def.PathStrategy\r\n\t}\r\n\tif merged.DefaultOrg == \"\" {\r\n\t\tmerged.DefaultOrg = def.DefaultOrg\r\n\t}\r\n\tif merged.DefaultRepo == \"\" {\r\n\t\tmerged.DefaultRepo = def.DefaultRepo\r\n\t}\r\n\treturn &merged\r\n}","code-length":260,"reference":"\/\/ ApplyDefault applies the defaults for GCSConfiguration decorations. If a field has a zero value,\n\/\/ it replaces that with the value set in def.","result":"Apply default values to GCSConfiguration objects.","score":[0.0081,0.0866]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *GCSConfiguration) Validate() error {\r\n\tif g.PathStrategy != PathStrategyLegacy && g.PathStrategy != PathStrategyExplicit && g.PathStrategy != PathStrategySingle {\r\n\t\treturn fmt.Errorf(\"gcs_path_strategy must be one of %q, %q, or %q\", PathStrategyLegacy, PathStrategyExplicit, PathStrategySingle)\r\n\t}\r\n\tif g.PathStrategy != PathStrategyExplicit && (g.DefaultOrg == \"\" || g.DefaultRepo == \"\") {\r\n\t\treturn fmt.Errorf(\"default org and repo must be provided for GCS strategy %q\", g.PathStrategy)\r\n\t}\r\n\treturn nil\r\n}","code-length":165,"reference":"\/\/ Validate ensures all the values set in the GCSConfiguration are valid.","result":"Validate the configuration .","score":[0.0514,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (j *ProwJob) ClusterAlias() string {\r\n\tif j.Spec.Cluster == \"\" {\r\n\t\treturn DefaultClusterAlias\r\n\t}\r\n\treturn j.Spec.Cluster\r\n}","code-length":58,"reference":"\/\/ ClusterAlias specifies the key in the clusters map to use.\n\/\/\n\/\/ This allows scheduling a prow job somewhere aside from the default build cluster.","result":"Generate the generated code.","score":[0.0013,0.021]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewResource(name, rtype, state, owner string, t time.Time) Resource {\r\n\treturn Resource{\r\n\t\tName:       name,\r\n\t\tType:       rtype,\r\n\t\tState:      state,\r\n\t\tOwner:      owner,\r\n\t\tLastUpdate: t,\r\n\t\tUserData:   &UserData{},\r\n\t}\r\n}","code-length":98,"reference":"\/\/ NewResource creates a new Boskos Resource.","result":"Create a new resource.","score":[0.2134,0.5597]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewResourcesFromConfig(e ResourceEntry) []Resource {\r\n\tvar resources []Resource\r\n\tfor _, name := range e.Names {\r\n\t\tresources = append(resources, NewResource(name, e.Type, e.State, \"\", time.Time{}))\r\n\t}\r\n\treturn resources\r\n}","code-length":82,"reference":"\/\/ NewResourcesFromConfig parse the a ResourceEntry into a list of resources","result":"Create a new resource.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UserDataFromMap(m UserDataMap) *UserData {\r\n\tud := &UserData{}\r\n\tfor k, v := range m {\r\n\t\tud.Store(k, v)\r\n\t}\r\n\treturn ud\r\n}","code-length":63,"reference":"\/\/ UserDataFromMap returns a UserData from a map","result":"Create a user data object.","score":[0.1319,0.0649]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *CommaSeparatedStrings) Set(value string) error {\r\n\tif len(*r) > 0 {\r\n\t\treturn errors.New(\"resTypes flag already set\")\r\n\t}\r\n\tfor _, rtype := range strings.Split(value, \",\") {\r\n\t\t*r = append(*r, rtype)\r\n\t}\r\n\treturn nil\r\n}","code-length":97,"reference":"\/\/ Set parses the flag value into a CommaSeparatedStrings","result":"Set the resTypes flag.","score":[0.1088,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ud *UserData) UnmarshalJSON(data []byte) error {\r\n\ttmpMap := UserDataMap{}\r\n\tif err := json.Unmarshal(data, &tmpMap); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tud.FromMap(tmpMap)\r\n\treturn nil\r\n}","code-length":80,"reference":"\/\/ UnmarshalJSON implements JSON Unmarshaler interface","result":"Unmarshal JSON.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ud *UserData) Extract(id string, out interface{}) error {\r\n\tcontent, ok := ud.Load(id)\r\n\tif !ok {\r\n\t\treturn &UserDataNotFound{id}\r\n\t}\r\n\treturn yaml.Unmarshal([]byte(content.(string)), out)\r\n}","code-length":83,"reference":"\/\/ Extract unmarshalls a string a given struct if it exists","result":"Extract data from a user data.","score":[0.0998,0.0952]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ud *UserData) Set(id string, in interface{}) error {\r\n\tb, err := yaml.Marshal(in)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tud.Store(id, string(b))\r\n\treturn nil\r\n}","code-length":78,"reference":"\/\/ User Data are used to store custom information mainly by Mason and Masonable implementation.\n\/\/ Mason used a LeasedResource keys to store information about other resources that used to\n\/\/ create the given resource.\n\/\/ Set marshalls a struct to a string into the UserData","result":"Set the value of a user data.","score":[0.0008,0.0475]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ud *UserData) Update(new *UserData) {\r\n\tif new == nil {\r\n\t\treturn\r\n\t}\r\n\tnew.Range(func(key, value interface{}) bool {\r\n\t\tif value.(string) != \"\" {\r\n\t\t\tud.Store(key, value)\r\n\t\t} else {\r\n\t\t\tud.Delete(key)\r\n\t\t}\r\n\t\treturn true\r\n\t})\r\n}","code-length":116,"reference":"\/\/ Update updates existing UserData with new UserData.\n\/\/ If a key as an empty string, the key will be deleted","result":"Update the user data.","score":[0.0054,0.0518]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ud *UserData) ToMap() UserDataMap {\r\n\tm := UserDataMap{}\r\n\tud.Range(func(key, value interface{}) bool {\r\n\t\tm[key.(string)] = value.(string)\r\n\t\treturn true\r\n\t})\r\n\treturn m\r\n}","code-length":81,"reference":"\/\/ ToMap converts a UserData to UserDataMap","result":"Convert UserData to UserDataMap.","score":[0.2134,0.3814]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ud *UserData) FromMap(m UserDataMap) {\r\n\tfor key, value := range m {\r\n\t\tud.Store(key, value)\r\n\t}\r\n}","code-length":53,"reference":"\/\/ FromMap feels updates user data from a map","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ItemToResource(i Item) (Resource, error) {\r\n\tres, ok := i.(Resource)\r\n\tif !ok {\r\n\t\treturn Resource{}, fmt.Errorf(\"cannot construct Resource from received object %v\", i)\r\n\t}\r\n\treturn res, nil\r\n}","code-length":79,"reference":"\/\/ ItemToResource casts a Item back to a Resource","result":"Convert Item to Resource.","score":[0.1088,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Options) Run() error {\r\n\tvar env []string\r\n\tif len(o.KeyFiles) > 0 {\r\n\t\tvar err error\r\n\t\tenv, err = addSSHKeys(o.KeyFiles)\r\n\t\tif err != nil {\r\n\t\t\tlogrus.WithError(err).Error(\"Failed to add SSH keys.\")\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t}\r\n\t}\r\n\tif len(o.HostFingerprints) > 0 {\r\n\t\tif err := addHostFingerprints(o.HostFingerprints); err != nil {\r\n\t\t\tlogrus.WithError(err).Error(\"failed to add host fingerprints\")\r\n\t\t}\r\n\t}\r\n\tvar numWorkers int\r\n\tif o.MaxParallelWorkers != 0 {\r\n\t\tnumWorkers = o.MaxParallelWorkers\r\n\t} else {\r\n\t\tnumWorkers = len(o.GitRefs)\r\n\t}\r\n\twg := &sync.WaitGroup{}\r\n\twg.Add(numWorkers)\r\n\tinput := make(chan prowapi.Refs)\r\n\toutput := make(chan clone.Record, len(o.GitRefs))\r\n\tfor i := 0; i < numWorkers; i++ {\r\n\t\tgo func() {\r\n\t\t\tdefer wg.Done()\r\n\t\t\tfor ref := range input {\r\n\t\t\t\toutput <- cloneFunc(ref, o.SrcRoot, o.GitUserName, o.GitUserEmail, o.CookiePath, env)\r\n\t\t\t}\r\n\t\t}()\r\n\t}\r\n\tfor _, ref := range o.GitRefs {\r\n\t\tinput <- ref\r\n\t}\r\n\tclose(input)\r\n\twg.Wait()\r\n\tclose(output)\r\n\tvar results []clone.Record\r\n\tfor record := range output {\r\n\t\tresults = append(results, record)\r\n\t}\r\n\tlogData, err := json.Marshal(results)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to marshal clone records: %v\", err)\r\n\t}\r\n\tif err := ioutil.WriteFile(o.Log, logData, 0755); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to write clone records: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":562,"reference":"\/\/ Run clones the configured refs","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc addSSHKeys(paths []string) ([]string, error) {\r\n\tvars, err := exec.Command(\"ssh-agent\").CombinedOutput()\r\n\tif err != nil {\r\n\t\treturn []string{}, fmt.Errorf(\"failed to start ssh-agent: %v\", err)\r\n\t}\r\n\tlogrus.Info(\"Started SSH agent\")\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tparts := strings.Split(string(vars), \";\")\r\n\tenv := []string{strings.TrimSpace(parts[0]), strings.TrimSpace(parts[2])}\r\n\tfor _, keyPath := range paths {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif err := filepath.Walk(keyPath, func(path string, info os.FileInfo, err error) error {\r\n\t\t\tif strings.HasPrefix(info.Name(), \"..\") {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tif info.IsDir() {\r\n\t\t\t\t\treturn filepath.SkipDir\r\n\t\t\t\t}\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\tif info.IsDir() {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\tcmd := exec.Command(\"ssh-add\", path)\r\n\t\t\tcmd.Env = append(cmd.Env, env...)\r\n\t\t\tif output, err := cmd.CombinedOutput(); err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"failed to add ssh key at %s: %v: %s\", path, err, output)\r\n\t\t\t}\r\n\t\t\tlogrus.Infof(\"Added SSH key at %s\", path)\r\n\t\t\treturn nil\r\n\t\t}); err != nil {\r\n\t\t\treturn env, fmt.Errorf(\"error walking path %q: %v\", keyPath, err)\r\n\t\t}\r\n\t}\r\n\treturn env, nil\r\n}","code-length":444,"reference":"\/\/ addSSHKeys will start the ssh-agent and add all the specified\n\/\/ keys, returning the ssh-agent environment variables for reuse","result":"Add ssh keys to the host.","score":[0.0187,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *TriageFiler) Issues(c *creator.IssueCreator) ([]creator.Issue, error) {\r\n\tf.creator = c\r\n\trawjson, err := ReadHTTP(clusterDataURL)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tclusters, err := f.loadClusters(rawjson)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\ttopclusters := topClusters(clusters, f.topClustersCount)\r\n\tissues := make([]creator.Issue, 0, len(topclusters))\r\n\tfor _, clust := range topclusters {\r\n\t\tissues = append(issues, clust)\r\n\t}\r\n\treturn issues, nil\r\n}","code-length":191,"reference":"\/\/ Issues is the main work function of the TriageFiler.  It fetches and parses cluster data,\n\/\/ then syncs the top issues to github with the IssueCreator.","result":"Generate issue.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *TriageFiler) loadClusters(jsonIn []byte) ([]*Cluster, error) {\r\n\tvar err error\r\n\tf.data, err = parseTriageData(jsonIn)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err = f.filterAndValidate(f.windowDays); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tfor _, clust := range f.data.Clustered {\r\n\t\tclust.filer = f\r\n\t\tclust.jobs = make(map[string][]int)\r\n\t\tfor _, test := range clust.Tests {\r\n\t\t\tfor _, job := range test.Jobs {\r\n\t\t\t\tfor _, buildnum := range job.Builds {\r\n\t\t\t\t\tfound := false\r\n\t\t\t\t\tfor _, oldBuild := range clust.jobs[job.Name] {\r\n\t\t\t\t\t\tif oldBuild == buildnum {\r\n\t\t\t\t\t\t\tfound = true\r\n\t\t\t\t\t\t\tbreak\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t}\r\n\t\t\t\t\tif !found {\r\n\t\t\t\t\t\tclust.jobs[job.Name] = append(clust.jobs[job.Name], buildnum)\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\tclust.totalJobs = len(clust.jobs)\r\n\t\tclust.totalTests = len(clust.Tests)\r\n\t\tclust.totalBuilds = 0\r\n\t\tfor _, builds := range clust.jobs {\r\n\t\t\tclust.totalBuilds += len(builds)\r\n\t\t}\r\n\t}\r\n\treturn f.data.Clustered, nil\r\n}","code-length":418,"reference":"\/\/ loadClusters parses and filters the json data, then populates every Cluster struct with\n\/\/ aggregated job data and totals. The job data specifies all jobs that failed in a cluster and the\n\/\/ builds that failed for each job, independent of which tests the jobs or builds failed.","result":"Load the cluster data.","score":[0.0,0.0225]}
{"code":"\/*is used to<extra_id_0>\r\nfunc parseTriageData(jsonIn []byte) (*triageData, error) {\r\n\tvar data triageData\r\n\tif err := json.Unmarshal(jsonIn, &data); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif data.Builds.Cols.Started == nil {\r\n\t\treturn nil, fmt.Errorf(\"triage data json is missing the builds.cols.started key\")\r\n\t}\r\n\tif data.Builds.JobsRaw == nil {\r\n\t\treturn nil, fmt.Errorf(\"triage data is missing the builds.jobs key\")\r\n\t}\r\n\tif data.Builds.JobPaths == nil {\r\n\t\treturn nil, fmt.Errorf(\"triage data is missing the builds.job_paths key\")\r\n\t}\r\n\tif data.Clustered == nil {\r\n\t\treturn nil, fmt.Errorf(\"triage data is missing the clustered key\")\r\n\t}\r\n\t\r\n\tdata.Builds.Jobs = make(map[string]BuildIndexer)\r\n\tfor jobID, mapper := range data.Builds.JobsRaw {\r\n\t\tswitch mapper := mapper.(type) {\r\n\t\tcase []interface{}:\r\n\t\t\t\r\n\t\t\tdata.Builds.Jobs[jobID] = ContigIndexer{\r\n\t\t\t\tstartBuild: int(mapper[0].(float64)),\r\n\t\t\t\tcount:      int(mapper[1].(float64)),\r\n\t\t\t\tstartRow:   int(mapper[2].(float64)),\r\n\t\t\t}\r\n\t\tcase map[string]interface{}:\r\n\t\t\t\r\n\t\t\tdata.Builds.Jobs[jobID] = DictIndexer(mapper)\r\n\t\tdefault:\r\n\t\t\treturn nil, fmt.Errorf(\"the build number to row index mapping for job '%s' is not an accepted type. Type is: %v\", jobID, reflect.TypeOf(mapper))\r\n\t\t}\r\n\t}\r\n\treturn &data, nil\r\n}","code-length":472,"reference":"\/\/ parseTriageData unmarshals raw json data into a triageData struct and creates a BuildIndexer for\n\/\/ every job.","result":"Parse the triage data json.","score":[0.0178,0.0299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc topClusters(clusters []*Cluster, count int) []*Cluster {\r\n\tless := func(i, j int) bool { return clusters[i].totalBuilds > clusters[j].totalBuilds }\r\n\tsort.SliceStable(clusters, less)\r\n\tif len(clusters) < count {\r\n\t\tcount = len(clusters)\r\n\t}\r\n\treturn clusters[0:count]\r\n}","code-length":104,"reference":"\/\/ topClusters gets the 'count' most important clusters from a slice of clusters based on number of build failures.","result":"Generate the code.","score":[0.002,0.0287]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) topJobsFailed(count int) []*Job {\r\n\tslice := make([]*Job, len(c.jobs))\r\n\ti := 0\r\n\tfor jobName, builds := range c.jobs {\r\n\t\tslice[i] = &Job{Name: jobName, Builds: builds}\r\n\t\ti++\r\n\t}\r\n\tless := func(i, j int) bool { return len(slice[i].Builds) > len(slice[j].Builds) }\r\n\tsort.SliceStable(slice, less)\r\n\tif len(slice) < count {\r\n\t\tcount = len(slice)\r\n\t}\r\n\treturn slice[0:count]\r\n}","code-length":175,"reference":"\/\/ topJobsFailed returns the top 'count' job names sorted by number of failing builds.","result":"Get the list of failed jobs.","score":[0.0605,0.2841]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) Title() string {\r\n\treturn fmt.Sprintf(\"Failure cluster [%s...] failed %d builds, %d jobs, and %d tests over %d days\",\r\n\t\tc.Identifier[0:6],\r\n\t\tc.totalBuilds,\r\n\t\tc.totalJobs,\r\n\t\tc.totalTests,\r\n\t\tc.filer.windowDays,\r\n\t)\r\n}","code-length":109,"reference":"\/\/ Title is the string to use as the github issue title.","result":"Generate the title.","score":[0.0242,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) Labels() []string {\r\n\tlabels := []string{\"kind\/flake\"}\r\n\ttopTests := make([]string, len(c.Tests))\r\n\tfor i, test := range c.topTestsFailed(len(c.Tests)) {\r\n\t\ttopTests[i] = test.Name\r\n\t}\r\n\tfor sig := range c.filer.creator.TestsSIGs(topTests) {\r\n\t\tlabels = append(labels, \"sig\/\"+sig)\r\n\t}\r\n\treturn labels\r\n}","code-length":138,"reference":"\/\/ Labels returns the labels to apply to the issue created for this cluster on github.","result":"Get labels from the cluster.","score":[0.0317,0.0671]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New() *Cron {\r\n\treturn &Cron{\r\n\t\tcronAgent: cron.New(),\r\n\t\tjobs:      map[string]*jobStatus{},\r\n\t\tlogger:    logrus.WithField(\"client\", \"cron\"),\r\n\t}\r\n}","code-length":73,"reference":"\/\/ New makes a new Cron object","result":"Create a new cron agent.","score":[0.2278,0.433]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cron) QueuedJobs() []string {\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tres := []string{}\r\n\tfor k, v := range c.jobs {\r\n\t\tif v.triggered {\r\n\t\t\tres = append(res, k)\r\n\t\t}\r\n\t\tc.jobs[k].triggered = false\r\n\t}\r\n\treturn res\r\n}","code-length":115,"reference":"\/\/ QueuedJobs returns a list of jobs that need to be triggered\n\/\/ and reset trigger in jobStatus","result":"Get the list of queued jobs.","score":[0.0369,0.1116]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cron) HasJob(name string) bool {\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\t_, ok := c.jobs[name]\r\n\treturn ok\r\n}","code-length":63,"reference":"\/\/ HasJob returns if a job has been scheduled in cronAgent or not","result":"Check if the job exists in the cron .","score":[0.1028,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cron) addJob(name, cron string) error {\r\n\tid, err := c.cronAgent.AddFunc(\"TZ=UTC \"+cron, func() {\r\n\t\tc.lock.Lock()\r\n\t\tdefer c.lock.Unlock()\r\n\t\tc.jobs[name].triggered = true\r\n\t\tc.logger.Infof(\"Triggering cron job %s.\", name)\r\n\t})\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"cronAgent fails to add job %s with cron %s: %v\", name, cron, err)\r\n\t}\r\n\tc.jobs[name] = &jobStatus{\r\n\t\tentryID: id,\r\n\t\tcronStr: cron,\r\n\t\t\r\n\t\ttriggered: strings.HasPrefix(cron, \"@every\"),\r\n\t}\r\n\tc.logger.Infof(\"Added new cron job %s with trigger %s.\", name, cron)\r\n\treturn nil\r\n}","code-length":243,"reference":"\/\/ addJob adds a cron entry for a job to cronAgent","result":"Add a new cron job.","score":[0.0861,0.1442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cron) removeJob(name string) error {\r\n\tjob, ok := c.jobs[name]\r\n\tif !ok {\r\n\t\treturn fmt.Errorf(\"job %s has not been added to cronAgent yet\", name)\r\n\t}\r\n\tc.cronAgent.Remove(job.entryID)\r\n\tdelete(c.jobs, name)\r\n\tc.logger.Infof(\"Removed previous cron job %s.\", name)\r\n\treturn nil\r\n}","code-length":124,"reference":"\/\/ removeJob removes the job from cronAgent","result":"Remove a job from the cron agent.","score":[0.2528,0.4509]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UpdateComments(issueID int, pullRequest bool, db *gorm.DB, client ClientInterface) {\r\n\tlatest := findLatestCommentUpdate(issueID, db, client.RepositoryName())\r\n\tupdateIssueComments(issueID, latest, db, client)\r\n\tif pullRequest {\r\n\t\tupdatePullComments(issueID, latest, db, client)\r\n\t}\r\n}","code-length":100,"reference":"\/\/ UpdateComments downloads issue and pull-request comments and save in DB","result":"Update comments.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GatherProwJobMetrics(pjs []prowapi.ProwJob) {\r\n\t\r\n\tmetricMap := make(map[string]map[string]map[string]float64)\r\n\tfor _, pj := range pjs {\r\n\t\tif metricMap[pj.Spec.Job] == nil {\r\n\t\t\tmetricMap[pj.Spec.Job] = make(map[string]map[string]float64)\r\n\t\t}\r\n\t\tif metricMap[pj.Spec.Job][string(pj.Spec.Type)] == nil {\r\n\t\t\tmetricMap[pj.Spec.Job][string(pj.Spec.Type)] = make(map[string]float64)\r\n\t\t}\r\n\t\tmetricMap[pj.Spec.Job][string(pj.Spec.Type)][string(pj.Status.State)]++\r\n\t}\r\n\t\r\n\t\r\n\tprowJobs.Reset()\r\n\tfor job, jobMap := range metricMap {\r\n\t\tfor jobType, typeMap := range jobMap {\r\n\t\t\tfor state, count := range typeMap {\r\n\t\t\t\tprowJobs.WithLabelValues(job, jobType, state).Set(count)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":316,"reference":"\/\/ GatherProwJobMetrics gathers prometheus metrics for prowjobs.","result":"Gather metrics for all ProwJobs.","score":[0.2278,0.4642]}
{"code":"\/*is used to<extra_id_0>\r\nfunc optionOrDefault(option, defaultValue time.Duration) time.Duration {\r\n\tif option == 0 {\r\n\t\treturn defaultValue\r\n\t}\r\n\treturn option\r\n}","code-length":50,"reference":"\/\/ optionOrDefault defaults to a value if option\n\/\/ is the zero value","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newGCSJobSource(src string) (*gcsJobSource, error) {\r\n\tgcsURL, err := url.Parse(fmt.Sprintf(\"gs:\r\n\tif err != nil {\r\n\t\treturn &gcsJobSource{}, ErrCannotParseSource\r\n\t}\r\n\tgcsPath := &gcs.Path{}\r\n\terr = gcsPath.SetURL(gcsURL)\r\n\tif err != nil {\r\n\t\treturn &gcsJobSource{}, ErrCannotParseSource\r\n\t}\r\n\ttokens := strings.FieldsFunc(gcsPath.Object(), func(c rune) bool { return c == '\/' })\r\n\tif len(tokens) < 2 {\r\n\t\treturn &gcsJobSource{}, ErrCannotParseSource\r\n\t}\r\n\tbuildID := tokens[len(tokens)-1]\r\n\tname := tokens[len(tokens)-2]\r\n\treturn &gcsJobSource{\r\n\t\tsource:     src,\r\n\t\tlinkPrefix: \"gs:\r\n\t\tbucket:     gcsPath.Bucket(),\r\n\t\tjobPrefix:  path.Clean(gcsPath.Object()) + \"\/\",\r\n\t\tjobName:    name,\r\n\t\tbuildID:    buildID,\r\n\t}, nil\r\n}","code-length":311,"reference":"\/\/ newGCSJobSource creates a new gcsJobSource from a given bucket and jobPrefix","result":"Create a job source.","score":[0.0432,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (af *GCSArtifactFetcher) artifacts(key string) ([]string, error) {\r\n\tsrc, err := newGCSJobSource(key)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"Failed to get GCS job source from %s: %v\", key, err)\r\n\t}\r\n\tlistStart := time.Now()\r\n\tbucketName, prefix := extractBucketPrefixPair(src.jobPath())\r\n\tartifacts := []string{}\r\n\tbkt := af.client.Bucket(bucketName)\r\n\tq := storage.Query{\r\n\t\tPrefix:   prefix,\r\n\t\tVersions: false,\r\n\t}\r\n\tobjIter := bkt.Objects(context.Background(), &q)\r\n\twait := []time.Duration{16, 32, 64, 128, 256, 256, 512, 512}\r\n\tfor i := 0; ; {\r\n\t\toAttrs, err := objIter.Next()\r\n\t\tif err == iterator.Done {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\tlogrus.WithFields(fieldsForJob(src)).WithError(err).Error(\"Error accessing GCS artifact.\")\r\n\t\t\tif i >= len(wait) {\r\n\t\t\t\treturn artifacts, fmt.Errorf(\"timed out: error accessing GCS artifact: %v\", err)\r\n\t\t\t}\r\n\t\t\ttime.Sleep((wait[i] + time.Duration(rand.Intn(10))) * time.Millisecond)\r\n\t\t\ti++\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tartifacts = append(artifacts, strings.TrimPrefix(oAttrs.Name, prefix))\r\n\t\ti = 0\r\n\t}\r\n\tlistElapsed := time.Since(listStart)\r\n\tlogrus.WithField(\"duration\", listElapsed).Infof(\"Listed %d artifacts.\", len(artifacts))\r\n\treturn artifacts, nil\r\n}","code-length":465,"reference":"\/\/ Artifacts lists all artifacts available for the given job source","result":"Fetch artifacts from GCS.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (src *gcsJobSource) canonicalLink() string {\r\n\treturn path.Join(src.linkPrefix, src.bucket, src.jobPrefix)\r\n}","code-length":48,"reference":"\/\/ CanonicalLink gets a link to the location of job-specific artifacts in GCS","result":"Generate the generated code.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (src *gcsJobSource) jobPath() string {\r\n\treturn fmt.Sprintf(\"%s\/%s\", src.bucket, src.jobPrefix)\r\n}","code-length":48,"reference":"\/\/ JobPath gets the prefix to all artifacts in GCS in the job","result":"Generate the job path.","score":[0.0476,0.155]}
{"code":"\/*is used to<extra_id_0>\r\nfunc targetURL(c config.Getter, pr *PullRequest, log *logrus.Entry) string {\r\n\tvar link string\r\n\tif tideURL := c().Tide.TargetURL; tideURL != \"\" {\r\n\t\tlink = tideURL\r\n\t} else if baseURL := c().Tide.PRStatusBaseURL; baseURL != \"\" {\r\n\t\tparseURL, err := url.Parse(baseURL)\r\n\t\tif err != nil {\r\n\t\t\tlog.WithError(err).Error(\"Failed to parse PR status base URL\")\r\n\t\t} else {\r\n\t\t\tprQuery := fmt.Sprintf(\"is:pr repo:%s author:%s head:%s\", pr.Repository.NameWithOwner, pr.Author.Login, pr.HeadRefName)\r\n\t\t\tvalues := parseURL.Query()\r\n\t\t\tvalues.Set(\"query\", prQuery)\r\n\t\t\tparseURL.RawQuery = values.Encode()\r\n\t\t\tlink = parseURL.String()\r\n\t\t}\r\n\t}\r\n\treturn link\r\n}","code-length":252,"reference":"\/\/ targetURL determines the URL used for more details in the status\n\/\/ context on GitHub. If no PR dashboard is configured, we will use\n\/\/ the administrative Prow overview.","result":"Generate the target URL.","score":[0.0005,0.0182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newBuildConfig(cfg rest.Config, stop chan struct{}) (*buildConfig, error) {\r\n\tbc, err := buildset.NewForConfig(&cfg)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\t\r\n\t_, err = bc.BuildV1alpha1().Builds(\"\").List(metav1.ListOptions{Limit: 1})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tbif := buildinfo.NewSharedInformerFactory(bc, 30*time.Minute)\r\n\tbif.Build().V1alpha1().Builds().Lister()\r\n\tgo bif.Start(stop)\r\n\treturn &buildConfig{\r\n\t\tclient:   bc,\r\n\t\tinformer: bif.Build().V1alpha1().Builds(),\r\n\t}, nil\r\n}","code-length":221,"reference":"\/\/ newBuildConfig returns a client and informer capable of mutating and monitoring the specified config.","result":"Create a new build config.","score":[0.0387,0.0714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(token string, dryRun bool) *Client {\r\n\thttpClient := &http.Client{\r\n\t\tTransport: &oauth2.Transport{\r\n\t\t\tBase:   http.DefaultTransport,\r\n\t\t\tSource: oauth2.ReuseTokenSource(nil, oauth2.StaticTokenSource(&oauth2.Token{AccessToken: token})),\r\n\t\t},\r\n\t}\r\n\tclient := github.NewClient(httpClient)\r\n\treturn &Client{\r\n\t\tissueService:        client.Issues,\r\n\t\tprService:           client.PullRequests,\r\n\t\trepoService:         client.Repositories,\r\n\t\tuserService:         client.Users,\r\n\t\tretries:             5,\r\n\t\tretryInitialBackoff: time.Second,\r\n\t\ttokenReserve:        50,\r\n\t\tdryRun:              dryRun,\r\n\t}\r\n}","code-length":215,"reference":"\/\/ NewClient makes a new Client with the specified token and dry-run status.","result":"Create a new client.","score":[0.0476,0.155]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) retry(action string, call func() (*github.Response, error)) (*github.Response, error) {\r\n\tvar err error\r\n\tvar resp *github.Response\r\n\tfor retryCount := 0; retryCount <= c.retries; retryCount++ {\r\n\t\tif resp, err = call(); err == nil {\r\n\t\t\tc.limitRate(&resp.Rate)\r\n\t\t\treturn resp, nil\r\n\t\t}\r\n\t\tswitch err := err.(type) {\r\n\t\tcase *github.RateLimitError:\r\n\t\t\tc.limitRate(&err.Rate)\r\n\t\tcase *github.TwoFactorAuthError:\r\n\t\t\treturn resp, err\r\n\t\tcase *retryAbort:\r\n\t\t\treturn resp, err\r\n\t\t}\r\n\t\tif retryCount == c.retries {\r\n\t\t\treturn resp, err\r\n\t\t}\r\n\t\tglog.Errorf(\"error %s: %v. Will retry.\\n\", action, err)\r\n\t\tc.sleepForAttempt(retryCount)\r\n\t}\r\n\treturn resp, err\r\n}","code-length":271,"reference":"\/\/ retry handles rate limiting and retry logic for a github API call.","result":"Avoid the need for the function to be called multiple times.","score":[0.0816,0.0391]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) depaginate(action string, opts *github.ListOptions, call func() ([]interface{}, *github.Response, error)) ([]interface{}, error) {\r\n\tvar allItems []interface{}\r\n\twrapper := func() (*github.Response, error) {\r\n\t\titems, resp, err := call()\r\n\t\tif err == nil {\r\n\t\t\tallItems = append(allItems, items...)\r\n\t\t}\r\n\t\treturn resp, err\r\n\t}\r\n\topts.Page = 1\r\n\topts.PerPage = 100\r\n\tlastPage := 1\r\n\tfor ; opts.Page <= lastPage; opts.Page++ {\r\n\t\tresp, err := c.retry(action, wrapper)\r\n\t\tif err != nil {\r\n\t\t\treturn allItems, fmt.Errorf(\"error while depaginating page %d\/%d: %v\", opts.Page, lastPage, err)\r\n\t\t}\r\n\t\tif resp.LastPage > 0 {\r\n\t\t\tlastPage = resp.LastPage\r\n\t\t}\r\n\t}\r\n\treturn allItems, nil\r\n}","code-length":275,"reference":"\/\/ depaginate adds depagination on top of the retry and rate limiting logic provided by retry.","result":"Avoid the need for the function to be executed.","score":[0.056,0.0327]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewHelpAgent(pa pluginAgent, ghc githubClient) *HelpAgent {\r\n\tl := logrus.WithField(\"client\", \"plugin-help\")\r\n\treturn &HelpAgent{\r\n\t\tlog: l,\r\n\t\tpa:  pa,\r\n\t\toa:  newOrgAgent(l, ghc, newRepoDetectionLimit),\r\n\t}\r\n}","code-length":97,"reference":"\/\/ NewHelpAgent constructs a new HelpAgent.","result":"Create a new help agent.","score":[0.2782,0.3178]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ha *HelpAgent) GeneratePluginHelp() *pluginhelp.Help {\r\n\tconfig := ha.pa.Config()\r\n\torgToRepos := ha.oa.orgToReposMap(config)\r\n\tnormalRevMap, externalRevMap := reversePluginMaps(config, orgToRepos)\r\n\tallPlugins, pluginHelp := ha.generateNormalPluginHelp(config, normalRevMap)\r\n\tallExternalPlugins, externalPluginHelp := ha.generateExternalPluginHelp(config, externalRevMap)\r\n\t\r\n\trepoPlugins := map[string][]string{\r\n\t\t\"\": allPlugins,\r\n\t}\r\n\tfor repo, plugins := range config.Plugins {\r\n\t\trepoPlugins[repo] = plugins\r\n\t}\r\n\trepoExternalPlugins := map[string][]string{\r\n\t\t\"\": allExternalPlugins,\r\n\t}\r\n\tfor repo, exts := range config.ExternalPlugins {\r\n\t\tfor _, ext := range exts {\r\n\t\t\trepoExternalPlugins[repo] = append(repoExternalPlugins[repo], ext.Name)\r\n\t\t}\r\n\t}\r\n\treturn &pluginhelp.Help{\r\n\t\tAllRepos:            allRepos(config, orgToRepos),\r\n\t\tRepoPlugins:         repoPlugins,\r\n\t\tRepoExternalPlugins: repoExternalPlugins,\r\n\t\tPluginHelp:          pluginHelp,\r\n\t\tExternalPluginHelp:  externalPluginHelp,\r\n\t}\r\n}","code-length":346,"reference":"\/\/ GeneratePluginHelp compiles and returns the help information for all plugins.","result":"Generate plugin help.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getPullCommitHash(pull string) (string, error) {\r\n\tmatch := pullCommitRe.FindStringSubmatch(pull)\r\n\tif len(match) != 2 {\r\n\t\texpected := \"branch:hash,pullNumber:hash\"\r\n\t\treturn \"\", fmt.Errorf(\"unable to parse pull %q (expected %q)\", pull, expected)\r\n\t}\r\n\treturn match[1], nil\r\n}","code-length":108,"reference":"\/\/ gets the pull commit hash from metadata","result":"Parse the pull commit hash.","score":[0.2716,0.3824]}
{"code":"\/*is used to<extra_id_0>\r\nfunc listJobBuilds(bucket storageBucket, jobPrefixes []string) []jobBuilds {\r\n\tjobch := make(chan jobBuilds)\r\n\tdefer close(jobch)\r\n\tfor i, jobPrefix := range jobPrefixes {\r\n\t\tgo func(i int, jobPrefix string) {\r\n\t\t\tbuildPrefixes, err := bucket.listSubDirs(jobPrefix)\r\n\t\t\tif err != nil {\r\n\t\t\t\tlogrus.WithError(err).Warningf(\"Error getting builds for job %s\", jobPrefix)\r\n\t\t\t}\r\n\t\t\tjobch <- jobBuilds{\r\n\t\t\t\tname:          path.Base(jobPrefix),\r\n\t\t\t\tbuildPrefixes: buildPrefixes,\r\n\t\t\t}\r\n\t\t}(i, jobPrefix)\r\n\t}\r\n\tjobs := []jobBuilds{}\r\n\tfor range jobPrefixes {\r\n\t\tjob := <-jobch\r\n\t\tjobs = append(jobs, job)\r\n\t}\r\n\treturn jobs\r\n}","code-length":237,"reference":"\/\/ listJobBuilds concurrently lists builds for the given job prefixes that have been run on a PR","result":"List job builds in storage.","score":[0.0259,0.0949]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getPRBuildData(bucket storageBucket, jobs []jobBuilds) []buildData {\r\n\tbuildch := make(chan buildData)\r\n\tdefer close(buildch)\r\n\texpected := 0\r\n\tfor _, job := range jobs {\r\n\t\tfor j, buildPrefix := range job.buildPrefixes {\r\n\t\t\tgo func(j int, jobName, buildPrefix string) {\r\n\t\t\t\tbuild, err := getBuildData(bucket, buildPrefix)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tlogrus.WithError(err).Warningf(\"build %s information incomplete\", buildPrefix)\r\n\t\t\t\t}\r\n\t\t\t\tsplit := strings.Split(strings.TrimSuffix(buildPrefix, \"\/\"), \"\/\")\r\n\t\t\t\tbuild.SpyglassLink = path.Join(spyglassPrefix, bucket.getName(), buildPrefix)\r\n\t\t\t\tbuild.ID = split[len(split)-1]\r\n\t\t\t\tbuild.jobName = jobName\r\n\t\t\t\tbuild.prefix = buildPrefix\r\n\t\t\t\tbuild.index = j\r\n\t\t\t\tbuildch <- build\r\n\t\t\t}(j, job.name, buildPrefix)\r\n\t\t\texpected++\r\n\t\t}\r\n\t}\r\n\tbuilds := []buildData{}\r\n\tfor k := 0; k < expected; k++ {\r\n\t\tbuild := <-buildch\r\n\t\tbuilds = append(builds, build)\r\n\t}\r\n\treturn builds\r\n}","code-length":341,"reference":"\/\/ getPRBuildData concurrently fetches metadata on each build of each job run on a PR","result":"Fetch build data from the PR.","score":[0.0431,0.0709]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getGCSDirsForPR(config *config.Config, org, repo string, pr int) (map[string]sets.String, error) {\r\n\ttoSearch := make(map[string]sets.String)\r\n\tfullRepo := org + \"\/\" + repo\r\n\tpresubmits, ok := config.Presubmits[fullRepo]\r\n\tif !ok {\r\n\t\treturn toSearch, fmt.Errorf(\"couldn't find presubmits for %q in config\", fullRepo)\r\n\t}\r\n\tfor _, presubmit := range presubmits {\r\n\t\tvar gcsConfig *v1.GCSConfiguration\r\n\t\tif presubmit.DecorationConfig != nil && presubmit.DecorationConfig.GCSConfiguration != nil {\r\n\t\t\tgcsConfig = presubmit.DecorationConfig.GCSConfiguration\r\n\t\t} else {\r\n\t\t\t\r\n\t\t\tgcsConfig = config.Plank.DefaultDecorationConfig.GCSConfiguration\r\n\t\t}\r\n\t\tgcsPath, _, _ := gcsupload.PathsForJob(gcsConfig, &downwardapi.JobSpec{\r\n\t\t\tType: v1.PresubmitJob,\r\n\t\t\tJob:  presubmit.Name,\r\n\t\t\tRefs: &v1.Refs{\r\n\t\t\t\tRepo: repo,\r\n\t\t\t\tOrg:  org,\r\n\t\t\t\tPulls: []v1.Pull{\r\n\t\t\t\t\t{Number: pr},\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t}, \"\")\r\n\t\tgcsPath, _ = path.Split(path.Clean(gcsPath))\r\n\t\tif _, ok := toSearch[gcsConfig.Bucket]; !ok {\r\n\t\t\ttoSearch[gcsConfig.Bucket] = sets.String{}\r\n\t\t}\r\n\t\ttoSearch[gcsConfig.Bucket].Insert(gcsPath)\r\n\t}\r\n\treturn toSearch, nil\r\n}","code-length":465,"reference":"\/\/ getGCSDirsForPR returns a map from bucket names -> set of \"directories\" containing presubmit data","result":"Generate the gcs upload paths for a PR.","score":[0.0579,0.035]}
{"code":"\/*is used to<extra_id_0>\r\nfunc imageDeleteFromDisk(fingerprint string) {\r\n\t\r\n\tfname := shared.VarPath(\"images\", fingerprint)\r\n\tif shared.PathExists(fname) {\r\n\t\terr := os.Remove(fname)\r\n\t\tif err != nil && !os.IsNotExist(err) {\r\n\t\t\tlogger.Errorf(\"Error deleting image file %s: %s\", fname, err)\r\n\t\t}\r\n\t}\r\n\t\r\n\tfname = shared.VarPath(\"images\", fingerprint) + \".rootfs\"\r\n\tif shared.PathExists(fname) {\r\n\t\terr := os.Remove(fname)\r\n\t\tif err != nil && !os.IsNotExist(err) {\r\n\t\t\tlogger.Errorf(\"Error deleting image file %s: %s\", fname, err)\r\n\t\t}\r\n\t}\r\n}","code-length":207,"reference":"\/\/ Helper to delete an image file from the local images directory.","result":"Delete image from disk.","score":[0.0514,0.1339]}
{"code":"\/*is used to<extra_id_0>\r\nfunc doNetworksCreate(d *Daemon, req api.NetworksPost, withDatabase bool) error {\r\n\t\r\n\tn, err := networkLoadByName(d.State(), req.Name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = n.Start()\r\n\tif err != nil {\r\n\t\tn.Delete(withDatabase)\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":116,"reference":"\/\/ Create the network on the system. The withDatabase flag is used to decide\n\/\/ whether to cleanup the database if an error occurs.","result":"Create a new network.","score":[0.0022,0.0227]}
{"code":"\/*is used to<extra_id_0>\r\nfunc networkLoadByName(s *state.State, name string) (*network, error) {\r\n\tid, dbInfo, err := s.Cluster.NetworkGet(name)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tn := network{state: s, id: id, name: name, description: dbInfo.Description, config: dbInfo.Config}\r\n\treturn &n, nil\r\n}","code-length":113,"reference":"\/\/ The network structs and functions","result":"Load the network by name.","score":[0.1967,0.3178]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *Node) Transaction(f func(*NodeTx) error) error {\r\n\tnodeTx := &NodeTx{}\r\n\treturn query.Transaction(n.db, func(tx *sql.Tx) error {\r\n\t\tnodeTx.tx = tx\r\n\t\treturn f(nodeTx)\r\n\t})\r\n}","code-length":86,"reference":"\/\/ Transaction creates a new NodeTx object and transactionally executes the\n\/\/ node-level database interactions invoked by the given function. If the\n\/\/ function returns no error, all database changes are committed to the\n\/\/ node-level database, otherwise they are rolled back.","result":"Transaction the node.","score":[0.0,0.0262]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ForLocalInspectionWithPreparedStmts(db *sql.DB) (*Cluster, error) {\r\n\tc := ForLocalInspection(db)\r\n\tstmts, err := cluster.PrepareStmts(c.db)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Prepare database statements\")\r\n\t}\r\n\tc.stmts = stmts\r\n\treturn c, nil\r\n}","code-length":107,"reference":"\/\/ ForLocalInspectionWithPreparedStmts is the same as ForLocalInspection but it\n\/\/ also prepares the statements used in auto-generated database code.","result":"Create a cluster.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) SetDefaultTimeout(timeout time.Duration) {\r\n\tdriver := c.db.Driver().(*dqlite.Driver)\r\n\tdriver.SetContextTimeout(timeout)\r\n}","code-length":57,"reference":"\/\/ SetDefaultTimeout sets the default go-dqlite driver timeout.","result":"Set the default timeout.","score":[0.1839,0.4934]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) Transaction(f func(*ClusterTx) error) error {\r\n\tc.mu.RLock()\r\n\tdefer c.mu.RUnlock()\r\n\treturn c.transaction(f)\r\n}","code-length":61,"reference":"\/\/ Transaction creates a new ClusterTx object and transactionally executes the\n\/\/ cluster database interactions invoked by the given function. If the function\n\/\/ returns no error, all database changes are committed to the cluster database\n\/\/ database, otherwise they are rolled back.\n\/\/\n\/\/ If EnterExclusive has been called before, calling Transaction will block\n\/\/ until ExitExclusive has been called as well to release the lock.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) EnterExclusive() error {\r\n\tlogger.Debug(\"Acquiring exclusive lock on cluster db\")\r\n\tch := make(chan struct{})\r\n\tgo func() {\r\n\t\tc.mu.Lock()\r\n\t\tch <- struct{}{}\r\n\t}()\r\n\ttimeout := 20 * time.Second\r\n\tselect {\r\n\tcase <-ch:\r\n\t\treturn nil\r\n\tcase <-time.After(timeout):\r\n\t\treturn fmt.Errorf(\"timeout (%s)\", timeout)\r\n\t}\r\n}","code-length":140,"reference":"\/\/ EnterExclusive acquires a lock on the cluster db, so any successive call to\n\/\/ Transaction will block until ExitExclusive has been called.","result":"Enter exclusive lock on cluster db.","score":[0.0178,0.12]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ExitExclusive(f func(*ClusterTx) error) error {\r\n\tlogger.Debug(\"Releasing exclusive lock on cluster db\")\r\n\tdefer c.mu.Unlock()\r\n\treturn c.transaction(f)\r\n}","code-length":66,"reference":"\/\/ ExitExclusive runs the given transaction and then releases the lock acquired\n\/\/ with EnterExclusive.","result":"Avoid recursive call to the function.","score":[0.0431,0.0355]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) Close() error {\r\n\tfor _, stmt := range c.stmts {\r\n\t\tstmt.Close()\r\n\t}\r\n\treturn c.db.Close()\r\n}","code-length":57,"reference":"\/\/ Close the database facade.","result":"Close the cluster.","score":[0.2964,0.3906]}
{"code":"\/*is used to<extra_id_0>\r\nfunc TxCommit(tx *sql.Tx) error {\r\n\terr := tx.Commit()\r\n\tif err == nil || err == sql.ErrTxDone {\r\n\t\treturn nil\r\n\t}\r\n\treturn err\r\n}","code-length":64,"reference":"\/\/ TxCommit commits the given transaction.","result":"Commit the transaction.","score":[0.1786,0.4483]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) ParseRemote(raw string) (string, string, error) {\r\n\tresult := strings.SplitN(raw, \":\", 2)\r\n\tif len(result) == 1 {\r\n\t\treturn c.DefaultRemote, raw, nil\r\n\t}\r\n\t_, ok := c.Remotes[result[0]]\r\n\tif !ok {\r\n\t\t\r\n\t\tif shared.IsSnapshot(raw) && shared.IsSnapshot(result[0]) {\r\n\t\t\treturn c.DefaultRemote, raw, nil\r\n\t\t}\r\n\t\treturn \"\", \"\", fmt.Errorf(\"The remote \\\"%s\\\" doesn't exist\", result[0])\r\n\t}\r\n\treturn result[0], result[1], nil\r\n}","code-length":184,"reference":"\/\/ ParseRemote splits remote and object","result":"Parse the remote name and the remote.","score":[0.1921,0.1639]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) GetContainerServer(name string) (lxd.ContainerServer, error) {\r\n\t\r\n\tremote, ok := c.Remotes[name]\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"The remote \\\"%s\\\" doesn't exist\", name)\r\n\t}\r\n\t\r\n\tif remote.Public || remote.Protocol == \"simplestreams\" {\r\n\t\treturn nil, fmt.Errorf(\"The remote isn't a private LXD server\")\r\n\t}\r\n\t\r\n\targs, err := c.getConnectionArgs(name)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tif strings.HasPrefix(remote.Addr, \"unix:\") {\r\n\t\td, err := lxd.ConnectLXDUnix(strings.TrimPrefix(strings.TrimPrefix(remote.Addr, \"unix:\"), \"\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tif remote.Project != \"\" && remote.Project != \"default\" {\r\n\t\t\td = d.UseProject(remote.Project)\r\n\t\t}\r\n\t\tif c.ProjectOverride != \"\" {\r\n\t\t\td = d.UseProject(c.ProjectOverride)\r\n\t\t}\r\n\t\treturn d, nil\r\n\t}\r\n\t\r\n\tif remote.AuthType != \"candid\" && (args.TLSClientCert == \"\" || args.TLSClientKey == \"\") {\r\n\t\treturn nil, fmt.Errorf(\"Missing TLS client certificate and key\")\r\n\t}\r\n\td, err := lxd.ConnectLXD(remote.Addr, args)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif remote.Project != \"\" && remote.Project != \"default\" {\r\n\t\td = d.UseProject(remote.Project)\r\n\t}\r\n\tif c.ProjectOverride != \"\" {\r\n\t\td = d.UseProject(c.ProjectOverride)\r\n\t}\r\n\treturn d, nil\r\n}","code-length":504,"reference":"\/\/ GetContainerServer returns a ContainerServer struct for the remote","result":"Get the container server from the config.","score":[0.1214,0.0568]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) GetImageServer(name string) (lxd.ImageServer, error) {\r\n\t\r\n\tremote, ok := c.Remotes[name]\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"The remote \\\"%s\\\" doesn't exist\", name)\r\n\t}\r\n\t\r\n\targs, err := c.getConnectionArgs(name)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tif strings.HasPrefix(remote.Addr, \"unix:\") {\r\n\t\td, err := lxd.ConnectLXDUnix(strings.TrimPrefix(strings.TrimPrefix(remote.Addr, \"unix:\"), \"\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tif remote.Project != \"\" && remote.Project != \"default\" {\r\n\t\t\td = d.UseProject(remote.Project)\r\n\t\t}\r\n\t\tif c.ProjectOverride != \"\" {\r\n\t\t\td = d.UseProject(c.ProjectOverride)\r\n\t\t}\r\n\t\treturn d, nil\r\n\t}\r\n\t\r\n\tif remote.Protocol == \"simplestreams\" {\r\n\t\td, err := lxd.ConnectSimpleStreams(remote.Addr, args)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn d, nil\r\n\t}\r\n\t\r\n\tif remote.Public {\r\n\t\td, err := lxd.ConnectPublicLXD(remote.Addr, args)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn d, nil\r\n\t}\r\n\t\r\n\td, err := lxd.ConnectLXD(remote.Addr, args)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif remote.Project != \"\" && remote.Project != \"default\" {\r\n\t\td = d.UseProject(remote.Project)\r\n\t}\r\n\tif c.ProjectOverride != \"\" {\r\n\t\td = d.UseProject(c.ProjectOverride)\r\n\t}\r\n\treturn d, nil\r\n}","code-length":543,"reference":"\/\/ GetImageServer returns a ImageServer struct for the remote","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *OS) initAppArmor() {\r\n\t\r\n\t_, err := exec.LookPath(\"apparmor_parser\")\r\n\tif os.Getenv(\"LXD_SECURITY_APPARMOR\") == \"false\" {\r\n\t\tlogger.Warnf(\"AppArmor support has been manually disabled\")\r\n\t} else if !shared.IsDir(\"\/sys\/kernel\/security\/apparmor\") {\r\n\t\tlogger.Warnf(\"AppArmor support has been disabled because of lack of kernel support\")\r\n\t} else if err != nil {\r\n\t\tlogger.Warnf(\"AppArmor support has been disabled because 'apparmor_parser' couldn't be found\")\r\n\t} else {\r\n\t\ts.AppArmorAvailable = true\r\n\t}\r\n\t\r\n\ts.AppArmorStacking = appArmorCanStack()\r\n\t\r\n\tif shared.PathExists(\"\/sys\/kernel\/security\/apparmor\/.ns_stacked\") {\r\n\t\tcontentBytes, err := ioutil.ReadFile(\"\/sys\/kernel\/security\/apparmor\/.ns_stacked\")\r\n\t\tif err == nil && string(contentBytes) == \"yes\\n\" {\r\n\t\t\ts.AppArmorStacked = true\r\n\t\t}\r\n\t}\r\n\t\r\n\tif !haveMacAdmin() {\r\n\t\tif s.AppArmorAvailable {\r\n\t\t\tlogger.Warnf(\"Per-container AppArmor profiles are disabled because the mac_admin capability is missing\")\r\n\t\t}\r\n\t} else if s.RunningInUserNS && !s.AppArmorStacked {\r\n\t\tif s.AppArmorAvailable {\r\n\t\t\tlogger.Warnf(\"Per-container AppArmor profiles are disabled because LXD is running in an unprivileged container without stacking\")\r\n\t\t}\r\n\t} else {\r\n\t\ts.AppArmorAdmin = true\r\n\t}\r\n\t\r\n\tprofile := util.AppArmorProfile()\r\n\tif profile != \"unconfined\" && profile != \"\" {\r\n\t\tif s.AppArmorAvailable {\r\n\t\t\tlogger.Warnf(\"Per-container AppArmor profiles are disabled because LXD is already protected by AppArmor\")\r\n\t\t}\r\n\t\ts.AppArmorConfined = true\r\n\t}\r\n}","code-length":569,"reference":"\/\/ Initialize AppArmor-specific attributes.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc appArmorCanStack() bool {\r\n\tcontentBytes, err := ioutil.ReadFile(\"\/sys\/kernel\/security\/apparmor\/features\/domain\/stack\")\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\tif string(contentBytes) != \"yes\\n\" {\r\n\t\treturn false\r\n\t}\r\n\tcontentBytes, err = ioutil.ReadFile(\"\/sys\/kernel\/security\/apparmor\/features\/domain\/version\")\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\tcontent := string(contentBytes)\r\n\tparts := strings.Split(strings.TrimSpace(content), \".\")\r\n\tif len(parts) == 0 {\r\n\t\tlogger.Warn(\"Unknown apparmor domain version\", log.Ctx{\"version\": content})\r\n\t\treturn false\r\n\t}\r\n\tmajor, err := strconv.Atoi(parts[0])\r\n\tif err != nil {\r\n\t\tlogger.Warn(\"Unknown apparmor domain version\", log.Ctx{\"version\": content})\r\n\t\treturn false\r\n\t}\r\n\tminor := 0\r\n\tif len(parts) == 2 {\r\n\t\tminor, err = strconv.Atoi(parts[1])\r\n\t\tif err != nil {\r\n\t\t\tlogger.Warn(\"Unknown apparmor domain version\", log.Ctx{\"version\": content})\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\treturn major >= 1 && minor >= 2\r\n}","code-length":366,"reference":"\/\/ Returns true if AppArmor stacking support is available.","result":"Check if the domain can stack .","score":[0.1214,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc containerDeviceAdd(client lxd.ContainerServer, name string, devName string, dev map[string]string) error {\r\n\t\r\n\tcontainer, etag, err := client.GetContainer(name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t_, ok := container.Devices[devName]\r\n\tif ok {\r\n\t\treturn fmt.Errorf(i18n.G(\"Device already exists: %s\"), devName)\r\n\t}\r\n\tcontainer.Devices[devName] = dev\r\n\top, err := client.UpdateContainer(name, container.Writable(), etag)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn op.Wait()\r\n}","code-length":188,"reference":"\/\/ Add a device to a container","result":"Add a new device to a container.","score":[0.4061,0.6914]}
{"code":"\/*is used to<extra_id_0>\r\nfunc profileDeviceAdd(client lxd.ContainerServer, name string, devName string, dev map[string]string) error {\r\n\t\r\n\tprofile, profileEtag, err := client.GetProfile(name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t_, ok := profile.Devices[devName]\r\n\tif ok {\r\n\t\treturn fmt.Errorf(i18n.G(\"Device already exists: %s\"), devName)\r\n\t}\r\n\t\r\n\tprofile.Devices[devName] = dev\r\n\terr = client.UpdateProfile(name, profile.Writable(), profileEtag)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":190,"reference":"\/\/ Add a device to a profile","result":"Add a new profile device.","score":[0.2521,0.2206]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ensureImageAliases(client lxd.ContainerServer, aliases []api.ImageAlias, fingerprint string) error {\r\n\tif len(aliases) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\tnames := make([]string, len(aliases))\r\n\tfor i, alias := range aliases {\r\n\t\tnames[i] = alias.Name\r\n\t}\r\n\tsort.Strings(names)\r\n\tresp, err := client.GetImageAliases()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tfor _, alias := range GetExistingAliases(names, resp) {\r\n\t\terr := client.DeleteImageAlias(alias.Name)\r\n\t\tif err != nil {\r\n\t\t\tfmt.Println(fmt.Sprintf(i18n.G(\"Failed to remove alias %s\"), alias.Name))\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor _, alias := range aliases {\r\n\t\taliasPost := api.ImageAliasesPost{}\r\n\t\taliasPost.Name = alias.Name\r\n\t\taliasPost.Target = fingerprint\r\n\t\terr := client.CreateImageAlias(aliasPost)\r\n\t\tif err != nil {\r\n\t\t\tfmt.Println(fmt.Sprintf(i18n.G(\"Failed to create alias %s\"), alias.Name))\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":344,"reference":"\/\/ Create the specified image alises, updating those that already exist","result":"Ensure that the image alias fingerprint is valid.","score":[0.1256,0.1869]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetExistingAliases(aliases []string, allAliases []api.ImageAliasesEntry) []api.ImageAliasesEntry {\r\n\texisting := []api.ImageAliasesEntry{}\r\n\tfor _, alias := range allAliases {\r\n\t\tname := alias.Name\r\n\t\tpos := sort.SearchStrings(aliases, name)\r\n\t\tif pos < len(aliases) && aliases[pos] == name {\r\n\t\t\texisting = append(existing, alias)\r\n\t\t}\r\n\t}\r\n\treturn existing\r\n}","code-length":130,"reference":"\/\/ GetExistingAliases returns the intersection between a list of aliases and all the existing ones.","result":"Filter the aliases.","score":[0.0075,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o StatusCode) String() string {\r\n\treturn map[StatusCode]string{\r\n\t\tOperationCreated: \"Operation created\",\r\n\t\tStarted:          \"Started\",\r\n\t\tStopped:          \"Stopped\",\r\n\t\tRunning:          \"Running\",\r\n\t\tCancelling:       \"Cancelling\",\r\n\t\tPending:          \"Pending\",\r\n\t\tSuccess:          \"Success\",\r\n\t\tFailure:          \"Failure\",\r\n\t\tCancelled:        \"Cancelled\",\r\n\t\tStarting:         \"Starting\",\r\n\t\tStopping:         \"Stopping\",\r\n\t\tAborting:         \"Aborting\",\r\n\t\tFreezing:         \"Freezing\",\r\n\t\tFrozen:           \"Frozen\",\r\n\t\tThawed:           \"Thawed\",\r\n\t\tError:            \"Error\",\r\n\t}[o]\r\n}","code-length":214,"reference":"\/\/ String returns a suitable string representation for the status code","result":"Operation created.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImagesGetExpired(expiry int64) ([]string, error) {\r\n\tq := `SELECT fingerprint, last_use_date, upload_date FROM images WHERE cached=1`\r\n\tvar fpStr string\r\n\tvar useStr string\r\n\tvar uploadStr string\r\n\tinargs := []interface{}{}\r\n\toutfmt := []interface{}{fpStr, useStr, uploadStr}\r\n\tdbResults, err := queryScan(c.db, q, inargs, outfmt)\r\n\tif err != nil {\r\n\t\treturn []string{}, err\r\n\t}\r\n\tresults := []string{}\r\n\tfor _, r := range dbResults {\r\n\t\t\r\n\t\ttimestamp := r[2]\r\n\t\tif r[1] != \"\" {\r\n\t\t\ttimestamp = r[1]\r\n\t\t}\r\n\t\tvar imageExpiry time.Time\r\n\t\terr = imageExpiry.UnmarshalText([]byte(timestamp.(string)))\r\n\t\tif err != nil {\r\n\t\t\treturn []string{}, err\r\n\t\t}\r\n\t\timageExpiry = imageExpiry.Add(time.Duration(expiry*24) * time.Hour)\r\n\t\t\r\n\t\tif imageExpiry.After(time.Now()) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tresults = append(results, r[0].(string))\r\n\t}\r\n\treturn results, nil\r\n}","code-length":348,"reference":"\/\/ ImagesGetExpired returns the names of all images that have expired since the\n\/\/ given time.","result":"Generate the generated code.","score":[0.0159,0.0338]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageSourceInsert(id int, server string, protocol string, certificate string, alias string) error {\r\n\tstmt := `INSERT INTO images_source (image_id, server, protocol, certificate, alias) values (?, ?, ?, ?, ?)`\r\n\tprotocolInt := -1\r\n\tfor protoInt, protoString := range ImageSourceProtocol {\r\n\t\tif protoString == protocol {\r\n\t\t\tprotocolInt = protoInt\r\n\t\t}\r\n\t}\r\n\tif protocolInt == -1 {\r\n\t\treturn fmt.Errorf(\"Invalid protocol: %s\", protocol)\r\n\t}\r\n\terr := exec(c.db, stmt, id, server, protocolInt, certificate, alias)\r\n\treturn err\r\n}","code-length":182,"reference":"\/\/ ImageSourceInsert inserts a new image source.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageSourceGet(imageID int) (int, api.ImageSource, error) {\r\n\tq := `SELECT id, server, protocol, certificate, alias FROM images_source WHERE image_id=?`\r\n\tid := 0\r\n\tprotocolInt := -1\r\n\tresult := api.ImageSource{}\r\n\targ1 := []interface{}{imageID}\r\n\targ2 := []interface{}{&id, &result.Server, &protocolInt, &result.Certificate, &result.Alias}\r\n\terr := dbQueryRowScan(c.db, q, arg1, arg2)\r\n\tif err != nil {\r\n\t\tif err == sql.ErrNoRows {\r\n\t\t\treturn -1, api.ImageSource{}, ErrNoSuchObject\r\n\t\t}\r\n\t\treturn -1, api.ImageSource{}, err\r\n\t}\r\n\tprotocol, found := ImageSourceProtocol[protocolInt]\r\n\tif !found {\r\n\t\treturn -1, api.ImageSource{}, fmt.Errorf(\"Invalid protocol: %d\", protocolInt)\r\n\t}\r\n\tresult.Protocol = protocol\r\n\treturn id, result, nil\r\n}","code-length":285,"reference":"\/\/ ImageSourceGet returns the image source with the given ID.","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageExists(project string, fingerprint string) (bool, error) {\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tenabled, err := tx.ProjectHasImages(project)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Check if project has images\")\r\n\t\t}\r\n\t\tif !enabled {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\tvar exists bool\r\n\tquery := `\r\nSELECT COUNT(*) > 0\r\n  FROM images\r\n  JOIN projects ON projects.id = images.project_id\r\n WHERE projects.name = ? AND fingerprint=?\r\n`\r\n\tinargs := []interface{}{project, fingerprint}\r\n\toutargs := []interface{}{&exists}\r\n\terr = dbQueryRowScan(c.db, query, inargs, outargs)\r\n\tif err == sql.ErrNoRows {\r\n\t\treturn exists, ErrNoSuchObject\r\n\t}\r\n\treturn exists, err\r\n}","code-length":286,"reference":"\/\/ ImageExists returns whether an image with the given fingerprint exists.","result":"Check if an image exists in the project .","score":[0.1527,0.2366]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageGet(project, fingerprint string, public bool, strictMatching bool) (int, *api.Image, error) {\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tenabled, err := tx.ProjectHasImages(project)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Check if project has images\")\r\n\t\t}\r\n\t\tif !enabled {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn -1, nil, err\r\n\t}\r\n\tvar create, expire, used, upload *time.Time\r\n\t\r\n\timage := api.Image{}\r\n\tid := -1\r\n\tarch := -1\r\n\t\r\n\toutfmt := []interface{}{&id, &image.Fingerprint, &image.Filename,\r\n\t\t&image.Size, &image.Cached, &image.Public, &image.AutoUpdate, &arch,\r\n\t\t&create, &expire, &used, &upload}\r\n\tinargs := []interface{}{project}\r\n\tquery := `\r\n        SELECT\r\n            images.id, fingerprint, filename, size, cached, public, auto_update, architecture,\r\n            creation_date, expiry_date, last_use_date, upload_date\r\n        FROM images\r\n        JOIN projects ON projects.id = images.project_id\r\n       WHERE projects.name = ?`\r\n\tif strictMatching {\r\n\t\tinargs = append(inargs, fingerprint)\r\n\t\tquery += \" AND fingerprint = ?\"\r\n\t} else {\r\n\t\tinargs = append(inargs, fingerprint+\"%\")\r\n\t\tquery += \" AND fingerprint LIKE ?\"\r\n\t}\r\n\tif public {\r\n\t\tquery += \" AND public=1\"\r\n\t}\r\n\terr = dbQueryRowScan(c.db, query, inargs, outfmt)\r\n\tif err != nil {\r\n\t\tif err == sql.ErrNoRows {\r\n\t\t\treturn -1, nil, ErrNoSuchObject\r\n\t\t}\r\n\t\treturn -1, nil, err\r\n\t}\r\n\t\r\n\tif !strictMatching {\r\n\t\tquery = `\r\nSELECT COUNT(images.id)\r\n  FROM images\r\n  JOIN projects ON projects.id = images.project_id\r\n WHERE projects.name = ?\r\n   AND fingerprint LIKE ?\r\n`\r\n\t\tcount := 0\r\n\t\toutfmt := []interface{}{&count}\r\n\t\terr = dbQueryRowScan(c.db, query, inargs, outfmt)\r\n\t\tif err != nil {\r\n\t\t\treturn -1, nil, err\r\n\t\t}\r\n\t\tif count > 1 {\r\n\t\t\treturn -1, nil, fmt.Errorf(\"Partial fingerprint matches more than one image\")\r\n\t\t}\r\n\t}\r\n\terr = c.imageFill(id, &image, create, expire, used, upload, arch)\r\n\tif err != nil {\r\n\t\treturn -1, nil, errors.Wrapf(err, \"Fill image details\")\r\n\t}\r\n\treturn id, &image, nil\r\n}","code-length":781,"reference":"\/\/ ImageGet gets an Image object from the database.\n\/\/ If strictMatching is false, The fingerprint argument will be queried with a LIKE query, means you can\n\/\/ pass a shortform and will get the full fingerprint.\n\/\/ There can never be more than one image with a given fingerprint, as it is\n\/\/ enforced by a UNIQUE constraint in the schema.","result":"Code too long,keep in 512.","score":[0.0,0.0089]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageGetFromAnyProject(fingerprint string) (int, *api.Image, error) {\r\n\tvar create, expire, used, upload *time.Time\r\n\t\r\n\timage := api.Image{}\r\n\tid := -1\r\n\tarch := -1\r\n\t\r\n\toutfmt := []interface{}{&id, &image.Fingerprint, &image.Filename,\r\n\t\t&image.Size, &image.Cached, &image.Public, &image.AutoUpdate, &arch,\r\n\t\t&create, &expire, &used, &upload}\r\n\tinargs := []interface{}{fingerprint}\r\n\tquery := `\r\n        SELECT\r\n            images.id, fingerprint, filename, size, cached, public, auto_update, architecture,\r\n            creation_date, expiry_date, last_use_date, upload_date\r\n        FROM images\r\n        WHERE fingerprint = ?\r\n        LIMIT 1`\r\n\terr := dbQueryRowScan(c.db, query, inargs, outfmt)\r\n\tif err != nil {\r\n\t\tif err == sql.ErrNoRows {\r\n\t\t\treturn -1, nil, ErrNoSuchObject\r\n\t\t}\r\n\t\treturn -1, nil, err\r\n\t}\r\n\terr = c.imageFill(id, &image, create, expire, used, upload, arch)\r\n\tif err != nil {\r\n\t\treturn -1, nil, errors.Wrapf(err, \"Fill image details\")\r\n\t}\r\n\treturn id, &image, nil\r\n}","code-length":377,"reference":"\/\/ ImageGetFromAnyProject returns an image matching the given fingerprint, if\n\/\/ it exists in any project.","result":"Fetch image details from cluster.","score":[0.0266,0.0336]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) imageFill(id int, image *api.Image, create, expire, used, upload *time.Time, arch int) error {\r\n\t\r\n\tif create != nil {\r\n\t\timage.CreatedAt = *create\r\n\t} else {\r\n\t\timage.CreatedAt = time.Time{}\r\n\t}\r\n\tif expire != nil {\r\n\t\timage.ExpiresAt = *expire\r\n\t} else {\r\n\t\timage.ExpiresAt = time.Time{}\r\n\t}\r\n\tif used != nil {\r\n\t\timage.LastUsedAt = *used\r\n\t} else {\r\n\t\timage.LastUsedAt = time.Time{}\r\n\t}\r\n\timage.Architecture, _ = osarch.ArchitectureName(arch)\r\n\t\r\n\timage.UploadedAt = *upload\r\n\t\r\n\tq := \"SELECT key, value FROM images_properties where image_id=?\"\r\n\tvar key, value, name, desc string\r\n\tinargs := []interface{}{id}\r\n\toutfmt := []interface{}{key, value}\r\n\tresults, err := queryScan(c.db, q, inargs, outfmt)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tproperties := map[string]string{}\r\n\tfor _, r := range results {\r\n\t\tkey = r[0].(string)\r\n\t\tvalue = r[1].(string)\r\n\t\tproperties[key] = value\r\n\t}\r\n\timage.Properties = properties\r\n\t\r\n\tq = \"SELECT name, description FROM images_aliases WHERE image_id=?\"\r\n\tinargs = []interface{}{id}\r\n\toutfmt = []interface{}{name, desc}\r\n\tresults, err = queryScan(c.db, q, inargs, outfmt)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\taliases := []api.ImageAlias{}\r\n\tfor _, r := range results {\r\n\t\tname = r[0].(string)\r\n\t\tdesc = r[1].(string)\r\n\t\ta := api.ImageAlias{Name: name, Description: desc}\r\n\t\taliases = append(aliases, a)\r\n\t}\r\n\timage.Aliases = aliases\r\n\t_, source, err := c.ImageSourceGet(id)\r\n\tif err == nil {\r\n\t\timage.UpdateSource = &source\r\n\t}\r\n\treturn nil\r\n}","code-length":602,"reference":"\/\/ Fill extra image fields such as properties and alias. This is called after\n\/\/ fetching a single row from the images table.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageLocate(fingerprint string) (string, error) {\r\n\tstmt := `\r\nSELECT nodes.address FROM nodes\r\n  LEFT JOIN images_nodes ON images_nodes.node_id = nodes.id\r\n  LEFT JOIN images ON images_nodes.image_id = images.id\r\nWHERE images.fingerprint = ?\r\n`\r\n\tvar localAddress string\r\n\tvar addresses []string\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tofflineThreshold, err := tx.NodeOfflineThreshold()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tlocalAddress, err = tx.NodeAddress()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tallAddresses, err := query.SelectStrings(tx.tx, stmt, fingerprint)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tfor _, address := range allAddresses {\r\n\t\t\tnode, err := tx.NodeByAddress(address)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif address != localAddress && node.IsOffline(offlineThreshold) {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\taddresses = append(addresses, address)\r\n\t\t}\r\n\t\treturn err\r\n\t})\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tif len(addresses) == 0 {\r\n\t\treturn \"\", fmt.Errorf(\"image not available on any online node\")\r\n\t}\r\n\tfor _, address := range addresses {\r\n\t\tif address == localAddress {\r\n\t\t\treturn \"\", nil\r\n\t\t}\r\n\t}\r\n\treturn addresses[0], nil\r\n}","code-length":440,"reference":"\/\/ ImageLocate returns the address of an online node that has a local copy of\n\/\/ the given image, or an empty string if the image is already available on this\n\/\/ node.\n\/\/\n\/\/ If the image is not available on any online node, an error is returned.","result":"Fetch the image from the database.","score":[0.0002,0.0336]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageAssociateNode(project, fingerprint string) error {\r\n\timageID, _, err := c.ImageGet(project, fingerprint, false, true)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = c.Transaction(func(tx *ClusterTx) error {\r\n\t\t_, err := tx.tx.Exec(\"INSERT INTO images_nodes(image_id, node_id) VALUES(?, ?)\", imageID, c.nodeID)\r\n\t\treturn err\r\n\t})\r\n\treturn err\r\n}","code-length":145,"reference":"\/\/ ImageAssociateNode creates a new entry in the images_nodes table for\n\/\/ tracking that the current node has the given image.","result":"Create a new node in the cluster.","score":[0.043,0.2608]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageDelete(id int) error {\r\n\terr := exec(c.db, \"DELETE FROM images WHERE id=?\", id)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":70,"reference":"\/\/ ImageDelete deletes the image with the given ID.","result":"Delete the image from.","score":[0.1294,0.1765]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageAliasesGet(project string) ([]string, error) {\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tenabled, err := tx.ProjectHasImages(project)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Check if project has images\")\r\n\t\t}\r\n\t\tif !enabled {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tq := `\r\nSELECT images_aliases.name\r\n  FROM images_aliases\r\n  JOIN projects ON projects.id=images_aliases.project_id\r\n WHERE projects.name=?\r\n`\r\n\tvar name string\r\n\tinargs := []interface{}{project}\r\n\toutfmt := []interface{}{name}\r\n\tresults, err := queryScan(c.db, q, inargs, outfmt)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tnames := []string{}\r\n\tfor _, res := range results {\r\n\t\tnames = append(names, res[0].(string))\r\n\t}\r\n\treturn names, nil\r\n}","code-length":317,"reference":"\/\/ ImageAliasesGet returns the names of the aliases of all images.","result":"Generate the generated code.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageAliasGet(project, name string, isTrustedClient bool) (int, api.ImageAliasesEntry, error) {\r\n\tid := -1\r\n\tentry := api.ImageAliasesEntry{}\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tenabled, err := tx.ProjectHasImages(project)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Check if project has images\")\r\n\t\t}\r\n\t\tif !enabled {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn id, entry, err\r\n\t}\r\n\tq := `SELECT images_aliases.id, images.fingerprint, images_aliases.description\r\n\t\t\t FROM images_aliases\r\n\t\t\t INNER JOIN images\r\n\t\t\t ON images_aliases.image_id=images.id\r\n                         INNER JOIN projects\r\n                         ON images_aliases.project_id=projects.id\r\n\t\t\t WHERE projects.name=? AND images_aliases.name=?`\r\n\tif !isTrustedClient {\r\n\t\tq = q + ` AND images.public=1`\r\n\t}\r\n\tvar fingerprint, description string\r\n\targ1 := []interface{}{project, name}\r\n\targ2 := []interface{}{&id, &fingerprint, &description}\r\n\terr = dbQueryRowScan(c.db, q, arg1, arg2)\r\n\tif err != nil {\r\n\t\tif err == sql.ErrNoRows {\r\n\t\t\treturn -1, entry, ErrNoSuchObject\r\n\t\t}\r\n\t\treturn -1, entry, err\r\n\t}\r\n\tentry.Name = name\r\n\tentry.Target = fingerprint\r\n\tentry.Description = description\r\n\treturn id, entry, nil\r\n}","code-length":448,"reference":"\/\/ ImageAliasGet returns the alias with the given name in the given project.","result":"Fetch the image alias information.","score":[0.0577,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageAliasRename(id int, name string) error {\r\n\terr := exec(c.db, \"UPDATE images_aliases SET name=? WHERE id=?\", name, id)\r\n\treturn err\r\n}","code-length":62,"reference":"\/\/ ImageAliasRename renames the alias with the given ID.","result":"Rename alias in cluster.","score":[0.0915,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageAliasDelete(project, name string) error {\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tenabled, err := tx.ProjectHasImages(project)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Check if project has images\")\r\n\t\t}\r\n\t\tif !enabled {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = exec(c.db, `\r\nDELETE\r\n  FROM images_aliases\r\n WHERE project_id = (SELECT id FROM projects WHERE name = ?) AND name = ?\r\n`, project, name)\r\n\treturn err\r\n}","code-length":200,"reference":"\/\/ ImageAliasDelete deletes the alias with the given name.","result":"Delete the image alias.","score":[0.0915,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageAliasesMove(source int, destination int) error {\r\n\terr := exec(c.db, \"UPDATE images_aliases SET image_id=? WHERE image_id=?\", destination, source)\r\n\treturn err\r\n}","code-length":66,"reference":"\/\/ ImageAliasesMove changes the image ID associated with an alias.","result":"Move images aliases.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageAliasAdd(project, name string, imageID int, desc string) error {\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tenabled, err := tx.ProjectHasImages(project)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Check if project has images\")\r\n\t\t}\r\n\t\tif !enabled {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tstmt := `\r\nINSERT INTO images_aliases (name, image_id, description, project_id)\r\n     VALUES (?, ?, ?, (SELECT id FROM projects WHERE name = ?))\r\n`\r\n\terr = exec(c.db, stmt, name, imageID, desc, project)\r\n\treturn err\r\n}","code-length":226,"reference":"\/\/ ImageAliasAdd inserts an alias ento the database.","result":"Add an image alias to a project.","score":[0.1665,0.1266]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageAliasUpdate(id int, imageID int, desc string) error {\r\n\tstmt := `UPDATE images_aliases SET image_id=?, description=? WHERE id=?`\r\n\terr := exec(c.db, stmt, imageID, desc, id)\r\n\treturn err\r\n}","code-length":81,"reference":"\/\/ ImageAliasUpdate updates the alias with the given ID.","result":"Update the image alias in cluster.","score":[0.1392,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageLastAccessUpdate(fingerprint string, date time.Time) error {\r\n\tstmt := `UPDATE images SET last_use_date=? WHERE fingerprint=?`\r\n\terr := exec(c.db, stmt, date, fingerprint)\r\n\treturn err\r\n}","code-length":74,"reference":"\/\/ ImageLastAccessUpdate updates the last_use_date field of the image with the\n\/\/ given fingerprint.","result":"Update image last.","score":[0.0104,0.0775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageLastAccessInit(fingerprint string) error {\r\n\tstmt := `UPDATE images SET cached=1, last_use_date=strftime(\"%s\") WHERE fingerprint=?`\r\n\terr := exec(c.db, stmt, fingerprint)\r\n\treturn err\r\n}","code-length":76,"reference":"\/\/ImageLastAccessInit inits the last_use_date field of the image with the given fingerprint.","result":"Initialize image last access.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageUpdate(id int, fname string, sz int64, public bool, autoUpdate bool, architecture string, createdAt time.Time, expiresAt time.Time, properties map[string]string) error {\r\n\tarch, err := osarch.ArchitectureId(architecture)\r\n\tif err != nil {\r\n\t\tarch = 0\r\n\t}\r\n\terr = c.Transaction(func(tx *ClusterTx) error {\r\n\t\tpublicInt := 0\r\n\t\tif public {\r\n\t\t\tpublicInt = 1\r\n\t\t}\r\n\t\tautoUpdateInt := 0\r\n\t\tif autoUpdate {\r\n\t\t\tautoUpdateInt = 1\r\n\t\t}\r\n\t\tstmt, err := tx.tx.Prepare(`UPDATE images SET filename=?, size=?, public=?, auto_update=?, architecture=?, creation_date=?, expiry_date=? WHERE id=?`)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdefer stmt.Close()\r\n\t\t_, err = stmt.Exec(fname, sz, publicInt, autoUpdateInt, arch, createdAt, expiresAt, id)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t_, err = tx.tx.Exec(`DELETE FROM images_properties WHERE image_id=?`, id)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tstmt2, err := tx.tx.Prepare(`INSERT INTO images_properties (image_id, type, key, value) VALUES (?, ?, ?, ?)`)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdefer stmt2.Close()\r\n\t\tfor key, value := range properties {\r\n\t\t\t_, err = stmt2.Exec(id, 0, key, value)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\treturn err\r\n}","code-length":494,"reference":"\/\/ ImageUpdate updates the image with the given ID.","result":"Update the properties of an image.","score":[0.1171,0.1149]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageInsert(project, fp string, fname string, sz int64, public bool, autoUpdate bool, architecture string, createdAt time.Time, expiresAt time.Time, properties map[string]string) error {\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tenabled, err := tx.ProjectHasImages(project)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Check if project has images\")\r\n\t\t}\r\n\t\tif !enabled {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tarch, err := osarch.ArchitectureId(architecture)\r\n\tif err != nil {\r\n\t\tarch = 0\r\n\t}\r\n\terr = c.Transaction(func(tx *ClusterTx) error {\r\n\t\tpublicInt := 0\r\n\t\tif public {\r\n\t\t\tpublicInt = 1\r\n\t\t}\r\n\t\tautoUpdateInt := 0\r\n\t\tif autoUpdate {\r\n\t\t\tautoUpdateInt = 1\r\n\t\t}\r\n\t\tstmt, err := tx.tx.Prepare(`INSERT INTO images (project_id, fingerprint, filename, size, public, auto_update, architecture, creation_date, expiry_date, upload_date) VALUES ((SELECT id FROM projects WHERE name = ?), ?, ?, ?, ?, ?, ?, ?, ?, ?)`)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdefer stmt.Close()\r\n\t\tresult, err := stmt.Exec(project, fp, fname, sz, publicInt, autoUpdateInt, arch, createdAt, expiresAt, time.Now().UTC())\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tid64, err := result.LastInsertId()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tid := int(id64)\r\n\t\tif len(properties) > 0 {\r\n\t\t\tpstmt, err := tx.tx.Prepare(`INSERT INTO images_properties (image_id, type, key, value) VALUES (?, 0, ?, ?)`)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tdefer pstmt.Close()\r\n\t\t\tfor k, v := range properties {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t_, err = pstmt.Exec(id, k, v)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\t_, err = tx.tx.Exec(\"INSERT INTO images_nodes(image_id, node_id) VALUES(?, ?)\", id, c.nodeID)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\treturn err\r\n}","code-length":723,"reference":"\/\/ ImageInsert inserts a new image.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageGetPools(imageFingerprint string) ([]int64, error) {\r\n\tpoolID := int64(-1)\r\n\tquery := \"SELECT storage_pool_id FROM storage_volumes WHERE node_id=? AND name=? AND type=?\"\r\n\tinargs := []interface{}{c.nodeID, imageFingerprint, StoragePoolVolumeTypeImage}\r\n\toutargs := []interface{}{poolID}\r\n\tresult, err := queryScan(c.db, query, inargs, outargs)\r\n\tif err != nil {\r\n\t\treturn []int64{}, err\r\n\t}\r\n\tpoolIDs := []int64{}\r\n\tfor _, r := range result {\r\n\t\tpoolIDs = append(poolIDs, r[0].(int64))\r\n\t}\r\n\treturn poolIDs, nil\r\n}","code-length":207,"reference":"\/\/ ImageGetPools get the names of all storage pools on which a given image exists.","result":"Get the image pools from the storage.","score":[0.0678,0.1408]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageGetPoolNamesFromIDs(poolIDs []int64) ([]string, error) {\r\n\tvar poolName string\r\n\tquery := \"SELECT name FROM storage_pools WHERE id=?\"\r\n\tpoolNames := []string{}\r\n\tfor _, poolID := range poolIDs {\r\n\t\tinargs := []interface{}{poolID}\r\n\t\toutargs := []interface{}{poolName}\r\n\t\tresult, err := queryScan(c.db, query, inargs, outargs)\r\n\t\tif err != nil {\r\n\t\t\treturn []string{}, err\r\n\t\t}\r\n\t\tfor _, r := range result {\r\n\t\t\tpoolNames = append(poolNames, r[0].(string))\r\n\t\t}\r\n\t}\r\n\treturn poolNames, nil\r\n}","code-length":204,"reference":"\/\/ ImageGetPoolNamesFromIDs get the names of all storage pools on which a given image exists.","result":"Get pool names from image.","score":[0.0325,0.1071]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageUploadedAt(id int, uploadedAt time.Time) error {\r\n\terr := exec(c.db, \"UPDATE images SET upload_date=? WHERE id=?\", uploadedAt, id)\r\n\treturn err\r\n}","code-length":66,"reference":"\/\/ ImageUploadedAt updates the upload_date column and an image row.","result":"Update images uploaded.","score":[0,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImagesGetOnCurrentNode() (map[string][]string, error) {\r\n\treturn c.ImagesGetByNodeID(c.nodeID)\r\n}","code-length":51,"reference":"\/\/ ImagesGetOnCurrentNode returns all images that the current LXD node instance has.","result":"Generate the generated code.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImagesGetByNodeID(id int64) (map[string][]string, error) {\r\n\timages := make(map[string][]string)\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tstmt := `\r\n    SELECT images.fingerprint, projects.name FROM images\r\n      LEFT JOIN images_nodes ON images.id = images_nodes.image_id\r\n\t\t\tLEFT JOIN nodes ON images_nodes.node_id = nodes.id\r\n\t\t\tLEFT JOIN projects ON images.project_id = projects.id\r\n    WHERE nodes.id = ?\r\n\t\t`\r\n\t\trows, err := tx.tx.Query(stmt, id)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tvar fingerprint string\r\n\t\tvar projectName string\r\n\t\tfor rows.Next() {\r\n\t\t\terr := rows.Scan(&fingerprint, &projectName)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\timages[fingerprint] = append(images[fingerprint], projectName)\r\n\t\t}\r\n\t\treturn rows.Err()\r\n\t})\r\n\treturn images, err\r\n}","code-length":301,"reference":"\/\/ ImagesGetByNodeID returns all images that the LXD node instance has with the given node id.","result":"Fetch images by node id.","score":[0.0417,0.1715]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageGetNodesWithImage(fingerprint string) ([]string, error) {\r\n\tq := `\r\nSELECT DISTINCT nodes.address FROM nodes\r\n  LEFT JOIN images_nodes ON images_nodes.node_id = nodes.id\r\n  LEFT JOIN images ON images_nodes.image_id = images.id\r\nWHERE images.fingerprint = ?\r\n\t`\r\n\treturn c.getNodesByImageFingerprint(q, fingerprint)\r\n}","code-length":115,"reference":"\/\/ ImageGetNodesWithImage returns the addresses of online nodes which already have the image.","result":"Fetch nodes with image .","score":[0.0485,0.041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageGetNodesWithoutImage(fingerprint string) ([]string, error) {\r\n\tq := `\r\nSELECT DISTINCT nodes.address FROM nodes WHERE nodes.address NOT IN (\r\n  SELECT DISTINCT nodes.address FROM nodes\r\n    LEFT JOIN images_nodes ON images_nodes.node_id = nodes.id\r\n    LEFT JOIN images ON images_nodes.image_id = images.id\r\n  WHERE images.fingerprint = ?)\r\n`\r\n\treturn c.getNodesByImageFingerprint(q, fingerprint)\r\n}","code-length":133,"reference":"\/\/ ImageGetNodesWithoutImage returns the addresses of online nodes which don't have the image.","result":"Fetch nodes without image.","score":[0.04,0.0826]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Group) Add(f Func, schedule Schedule) *Task {\r\n\ti := len(g.tasks)\r\n\tg.tasks = append(g.tasks, Task{\r\n\t\tf:        f,\r\n\t\tschedule: schedule,\r\n\t\treset:    make(chan struct{}, 16),\r\n\t})\r\n\treturn &g.tasks[i]\r\n}","code-length":102,"reference":"\/\/ Add a new task to the group, returning its index.","result":"Create a new task.","score":[0.0785,0.182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Group) Start() {\r\n\tctx := context.Background()\r\n\tctx, g.cancel = context.WithCancel(ctx)\r\n\tg.wg.Add(len(g.tasks))\r\n\tg.mu.Lock()\r\n\tif g.running == nil {\r\n\t\tg.running = make(map[int]bool)\r\n\t}\r\n\tg.mu.Unlock()\r\n\tfor i := range g.tasks {\r\n\t\tg.mu.Lock()\r\n\t\tif g.running[i] {\r\n\t\t\tg.mu.Unlock()\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tg.running[i] = true\r\n\t\ttask := g.tasks[i]\r\n\t\tg.mu.Unlock()\r\n\t\tgo func(i int) {\r\n\t\t\ttask.loop(ctx)\r\n\t\t\tg.wg.Done()\r\n\t\t\tg.mu.Lock()\r\n\t\t\tg.running[i] = false\r\n\t\t\tg.mu.Unlock()\r\n\t\t}(i)\r\n\t}\r\n}","code-length":271,"reference":"\/\/ Start all the tasks in the group.","result":"Start the group.","score":[0.1207,0.3407]}
{"code":"\/*is used to<extra_id_0>\r\nfunc zfsIsEnabled() bool {\r\n\tout, err := exec.LookPath(\"zfs\")\r\n\tif err != nil || len(out) == 0 {\r\n\t\treturn false\r\n\t}\r\n\treturn true\r\n}","code-length":65,"reference":"\/\/ zfsIsEnabled returns whether zfs backend is supported.","result":"Detect if zfs is enabled.","score":[0.1568,0.1299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc zfsToolVersionGet() (string, error) {\r\n\t\r\n\t\r\n\tout, err := shared.RunCommand(\"dpkg-query\", \"--showformat=${Version}\", \"--show\", \"zfsutils-linux\")\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn strings.TrimSpace(string(out)), nil\r\n}","code-length":100,"reference":"\/\/ zfsToolVersionGet returns the ZFS tools version","result":"Get the version of zfsutils.","score":[0.1915,0.1471]}
{"code":"\/*is used to<extra_id_0>\r\nfunc zfsModuleVersionGet() (string, error) {\r\n\tvar zfsVersion string\r\n\tif shared.PathExists(\"\/sys\/module\/zfs\/version\") {\r\n\t\tout, err := ioutil.ReadFile(\"\/sys\/module\/zfs\/version\")\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"Could not determine ZFS module version\")\r\n\t\t}\r\n\t\tzfsVersion = string(out)\r\n\t} else {\r\n\t\tout, err := shared.RunCommand(\"modinfo\", \"-F\", \"version\", \"zfs\")\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"Could not determine ZFS module version\")\r\n\t\t}\r\n\t\tzfsVersion = out\r\n\t}\r\n\treturn strings.TrimSpace(zfsVersion), nil\r\n}","code-length":211,"reference":"\/\/ zfsModuleVersionGet returns the ZFS module version","result":"Get the version of the zfs module.","score":[0.1921,0.3651]}
{"code":"\/*is used to<extra_id_0>\r\nfunc zfsPoolVolumeCreate(dataset string, properties ...string) (string, error) {\r\n\tcmd := []string{\"zfs\", \"create\"}\r\n\tfor _, prop := range properties {\r\n\t\tcmd = append(cmd, []string{\"-o\", prop}...)\r\n\t}\r\n\tcmd = append(cmd, []string{\"-p\", dataset}...)\r\n\treturn shared.RunCommand(cmd[0], cmd[1:]...)\r\n}","code-length":117,"reference":"\/\/ zfsPoolVolumeCreate creates a ZFS dataset with a set of given properties.","result":"Create a ZFS volume.","score":[0.0611,0.1339]}
{"code":"\/*is used to<extra_id_0>\r\nfunc zfsPoolVolumeExists(dataset string) (bool, error) {\r\n\toutput, err := shared.RunCommand(\r\n\t\t\"zfs\", \"list\", \"-Ho\", \"name\")\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\tfor _, name := range strings.Split(output, \"\\n\") {\r\n\t\tif name == dataset {\r\n\t\t\treturn true, nil\r\n\t\t}\r\n\t}\r\n\treturn false, nil\r\n}","code-length":130,"reference":"\/\/ zfsPoolVolumeExists verifies if a specific ZFS pool or volume exists.","result":"Check if a zfs volume exists.","score":[0.1562,0.4248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NetworkIDsNotPending() (map[string]int64, error) {\r\n\tnetworks := []struct {\r\n\t\tid   int64\r\n\t\tname string\r\n\t}{}\r\n\tdest := func(i int) []interface{} {\r\n\t\tnetworks = append(networks, struct {\r\n\t\t\tid   int64\r\n\t\t\tname string\r\n\t\t}{})\r\n\t\treturn []interface{}{&networks[i].id, &networks[i].name}\r\n\t}\r\n\tstmt, err := c.tx.Prepare(\"SELECT id, name FROM networks WHERE NOT state=?\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer stmt.Close()\r\n\terr = query.SelectObjects(stmt, dest, networkPending)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tids := map[string]int64{}\r\n\tfor _, network := range networks {\r\n\t\tids[network.name] = network.id\r\n\t}\r\n\treturn ids, nil\r\n}","code-length":273,"reference":"\/\/ NetworkIDsNotPending returns a map associating each network name to its ID.\n\/\/\n\/\/ Pending networks are skipped.","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NetworkConfigAdd(networkID, nodeID int64, config map[string]string) error {\r\n\treturn networkConfigAdd(c.tx, networkID, nodeID, config)\r\n}","code-length":58,"reference":"\/\/ NetworkConfigAdd adds a new entry in the networks_config table","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NetworkNodeJoin(networkID, nodeID int64) error {\r\n\tcolumns := []string{\"network_id\", \"node_id\"}\r\n\tvalues := []interface{}{networkID, nodeID}\r\n\t_, err := query.UpsertObject(c.tx, \"networks_nodes\", columns, values)\r\n\treturn err\r\n}","code-length":94,"reference":"\/\/ NetworkNodeJoin adds a new entry in the networks_nodes table.\n\/\/\n\/\/ It should only be used when a new node joins the cluster, when it's safe to\n\/\/ assume that the relevant network has already been created on the joining node,\n\/\/ and we just need to track it.","result":"Join a node in a cluster.","score":[0.0002,0.0548]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NetworkCreatePending(node, name string, conf map[string]string) error {\r\n\t\r\n\t\r\n\tnetwork := struct {\r\n\t\tid    int64\r\n\t\tstate int\r\n\t}{}\r\n\tvar errConsistency error\r\n\tdest := func(i int) []interface{} {\r\n\t\t\r\n\t\tif i != 0 {\r\n\t\t\terrConsistency = fmt.Errorf(\"more than one network exists with the given name\")\r\n\t\t}\r\n\t\treturn []interface{}{&network.id, &network.state}\r\n\t}\r\n\tstmt, err := c.tx.Prepare(\"SELECT id, state FROM networks WHERE name=?\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer stmt.Close()\r\n\terr = query.SelectObjects(stmt, dest, name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif errConsistency != nil {\r\n\t\treturn errConsistency\r\n\t}\r\n\tvar networkID = network.id\r\n\tif networkID == 0 {\r\n\t\t\r\n\t\t\r\n\t\tcolumns := []string{\"name\"}\r\n\t\tvalues := []interface{}{name}\r\n\t\tnetworkID, err = query.UpsertObject(c.tx, \"networks\", columns, values)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t} else {\r\n\t\t\r\n\t\tif network.state != networkPending {\r\n\t\t\treturn fmt.Errorf(\"network is not in pending state\")\r\n\t\t}\r\n\t}\r\n\t\r\n\tnodeInfo, err := c.NodeByName(node)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tcount, err := query.Count(\r\n\t\tc.tx, \"networks_nodes\", \"network_id=? AND node_id=?\", networkID, nodeInfo.ID)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif count != 0 {\r\n\t\treturn ErrAlreadyDefined\r\n\t}\r\n\t\r\n\tcolumns := []string{\"network_id\", \"node_id\"}\r\n\tvalues := []interface{}{networkID, nodeInfo.ID}\r\n\t_, err = query.UpsertObject(c.tx, \"networks_nodes\", columns, values)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = c.NetworkConfigAdd(networkID, nodeInfo.ID, conf)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":636,"reference":"\/\/ NetworkCreatePending creates a new pending network on the node with\n\/\/ the given name.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NetworkCreated(name string) error {\r\n\treturn c.networkState(name, networkCreated)\r\n}","code-length":41,"reference":"\/\/ NetworkCreated sets the state of the given network to \"Created\".","result":"Generate the code.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NetworkErrored(name string) error {\r\n\treturn c.networkState(name, networkErrored)\r\n}","code-length":43,"reference":"\/\/ NetworkErrored sets the state of the given network to \"Errored\".","result":"Generate the code.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) NetworkGet(name string) (int64, *api.Network, error) {\r\n\tdescription := sql.NullString{}\r\n\tid := int64(-1)\r\n\tstate := 0\r\n\tq := \"SELECT id, description, state FROM networks WHERE name=?\"\r\n\targ1 := []interface{}{name}\r\n\targ2 := []interface{}{&id, &description, &state}\r\n\terr := dbQueryRowScan(c.db, q, arg1, arg2)\r\n\tif err != nil {\r\n\t\tif err == sql.ErrNoRows {\r\n\t\t\treturn -1, nil, ErrNoSuchObject\r\n\t\t}\r\n\t\treturn -1, nil, err\r\n\t}\r\n\tconfig, err := c.NetworkConfigGet(id)\r\n\tif err != nil {\r\n\t\treturn -1, nil, err\r\n\t}\r\n\tnetwork := api.Network{\r\n\t\tName:    name,\r\n\t\tManaged: true,\r\n\t\tType:    \"bridge\",\r\n\t}\r\n\tnetwork.Description = description.String\r\n\tnetwork.Config = config\r\n\tswitch state {\r\n\tcase networkPending:\r\n\t\tnetwork.Status = \"Pending\"\r\n\tcase networkCreated:\r\n\t\tnetwork.Status = \"Created\"\r\n\tdefault:\r\n\t\tnetwork.Status = \"Unknown\"\r\n\t}\r\n\tnodes, err := c.networkNodes(id)\r\n\tif err != nil {\r\n\t\treturn -1, nil, err\r\n\t}\r\n\tnetwork.Locations = nodes\r\n\treturn id, &network, nil\r\n}","code-length":399,"reference":"\/\/ NetworkGet returns the network with the given name.","result":"Get the network configuration.","score":[0.1294,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) networkNodes(networkID int64) ([]string, error) {\r\n\tstmt := `\r\nSELECT nodes.name FROM nodes\r\n  JOIN networks_nodes ON networks_nodes.node_id = nodes.id\r\n  WHERE networks_nodes.network_id = ?\r\n`\r\n\tvar nodes []string\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tvar err error\r\n\t\tnodes, err = query.SelectStrings(tx.tx, stmt, networkID)\r\n\t\treturn err\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn nodes, nil\r\n}","code-length":173,"reference":"\/\/ Return the names of the nodes the given network is defined on.","result":"Fetch the nodes from the database.","score":[0.0941,0.2078]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) NetworkGetInterface(devName string) (int64, *api.Network, error) {\r\n\tid := int64(-1)\r\n\tname := \"\"\r\n\tvalue := \"\"\r\n\tq := \"SELECT networks.id, networks.name, networks_config.value FROM networks LEFT JOIN networks_config ON networks.id=networks_config.network_id WHERE networks_config.key=\\\"bridge.external_interfaces\\\" AND networks_config.node_id=?\"\r\n\targ1 := []interface{}{c.nodeID}\r\n\targ2 := []interface{}{id, name, value}\r\n\tresult, err := queryScan(c.db, q, arg1, arg2)\r\n\tif err != nil {\r\n\t\treturn -1, nil, err\r\n\t}\r\n\tfor _, r := range result {\r\n\t\tfor _, entry := range strings.Split(r[2].(string), \",\") {\r\n\t\t\tentry = strings.TrimSpace(entry)\r\n\t\t\tif entry == devName {\r\n\t\t\t\tid = r[0].(int64)\r\n\t\t\t\tname = r[1].(string)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif id == -1 {\r\n\t\treturn -1, nil, fmt.Errorf(\"No network found for interface: %s\", devName)\r\n\t}\r\n\tconfig, err := c.NetworkConfigGet(id)\r\n\tif err != nil {\r\n\t\treturn -1, nil, err\r\n\t}\r\n\tnetwork := api.Network{\r\n\t\tName:    name,\r\n\t\tManaged: true,\r\n\t\tType:    \"bridge\",\r\n\t}\r\n\tnetwork.Config = config\r\n\treturn id, &network, nil\r\n}","code-length":431,"reference":"\/\/ NetworkGetInterface returns the network associated with the interface with\n\/\/ the given name.","result":"Get the network config from the cluster.","score":[0.093,0.1128]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) NetworkConfigGet(id int64) (map[string]string, error) {\r\n\tvar key, value string\r\n\tquery := `\r\n        SELECT\r\n            key, value\r\n        FROM networks_config\r\n\t\tWHERE network_id=?\r\n                AND (node_id=? OR node_id IS NULL)`\r\n\tinargs := []interface{}{id, c.nodeID}\r\n\toutfmt := []interface{}{key, value}\r\n\tresults, err := queryScan(c.db, query, inargs, outfmt)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"Failed to get network '%d'\", id)\r\n\t}\r\n\tif len(results) == 0 {\r\n\t\t\r\n\t\tquery := \"SELECT id FROM networks WHERE id=?\"\r\n\t\tvar r int\r\n\t\tresults, err := queryScan(c.db, query, []interface{}{id}, []interface{}{r})\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tif len(results) == 0 {\r\n\t\t\treturn nil, ErrNoSuchObject\r\n\t\t}\r\n\t}\r\n\tconfig := map[string]string{}\r\n\tfor _, r := range results {\r\n\t\tkey = r[0].(string)\r\n\t\tvalue = r[1].(string)\r\n\t\tconfig[key] = value\r\n\t}\r\n\treturn config, nil\r\n}","code-length":364,"reference":"\/\/ NetworkConfigGet returns the config map of the network with the given ID.","result":"Get the network configuration from the database.","score":[0.1073,0.2061]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) NetworkCreate(name, description string, config map[string]string) (int64, error) {\r\n\tvar id int64\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tresult, err := tx.tx.Exec(\"INSERT INTO networks (name, description, state) VALUES (?, ?, ?)\", name, description, networkCreated)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tid, err := result.LastInsertId()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\tcolumns := []string{\"network_id\", \"node_id\"}\r\n\t\tvalues := []interface{}{id, c.nodeID}\r\n\t\t_, err = query.UpsertObject(tx.tx, \"networks_nodes\", columns, values)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\terr = networkConfigAdd(tx.tx, id, c.nodeID, config)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\tid = -1\r\n\t}\r\n\treturn id, err\r\n}","code-length":321,"reference":"\/\/ NetworkCreate creates a new network.","result":"Create a new network.","score":[0.3991,0.6843]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) NetworkUpdate(name, description string, config map[string]string) error {\r\n\tid, _, err := c.NetworkGet(name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = c.Transaction(func(tx *ClusterTx) error {\r\n\t\terr = NetworkUpdateDescription(tx.tx, id, description)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\terr = NetworkConfigClear(tx.tx, id, c.nodeID)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\terr = networkConfigAdd(tx.tx, id, c.nodeID, config)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\treturn err\r\n}","code-length":224,"reference":"\/\/ NetworkUpdate updates the network with the given name.","result":"Update the network configuration.","score":[0.1294,0.1765]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NetworkUpdateDescription(tx *sql.Tx, id int64, description string) error {\r\n\t_, err := tx.Exec(\"UPDATE networks SET description=? WHERE id=?\", description, id)\r\n\treturn err\r\n}","code-length":61,"reference":"\/\/ NetworkUpdateDescription updates the description of the network with the\n\/\/ given ID.","result":"Update the description of a network.","score":[0.1238,0.2566]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NetworkConfigClear(tx *sql.Tx, networkID, nodeID int64) error {\r\n\t_, err := tx.Exec(\r\n\t\t\"DELETE FROM networks_config WHERE network_id=? AND (node_id=? OR node_id IS NULL)\",\r\n\t\tnetworkID, nodeID)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":104,"reference":"\/\/ NetworkConfigClear resets the config of the network with the given ID\n\/\/ associated with the node with the given ID.","result":"Clear the network config.","score":[0.0064,0.0518]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) NetworkDelete(name string) error {\r\n\tid, _, err := c.NetworkGet(name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = exec(c.db, \"DELETE FROM networks WHERE id=?\", id)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":104,"reference":"\/\/ NetworkDelete deletes the network with the given name.","result":"Delete a network.","score":[0,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) NetworkRename(oldName string, newName string) error {\r\n\tid, _, err := c.NetworkGet(oldName)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = c.Transaction(func(tx *ClusterTx) error {\r\n\t\t_, err = tx.tx.Exec(\"UPDATE networks SET name=? WHERE id=?\", newName, id)\r\n\t\treturn err\r\n\t})\r\n\treturn err\r\n}","code-length":125,"reference":"\/\/ NetworkRename renames a network.","result":"Replace the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainers() ([]api.Container, error) {\r\n\tcontainers := []api.Container{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", \"\/containers?recursion=1\", nil, \"\", &containers)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn containers, nil\r\n}","code-length":99,"reference":"\/\/ GetContainers returns a list of containers","result":"Get the list of containers.","score":[0.2278,0.2757]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainersFull() ([]api.ContainerFull, error) {\r\n\tcontainers := []api.ContainerFull{}\r\n\tif !r.HasExtension(\"container_full\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"container_full\\\" API extension\")\r\n\t}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", \"\/containers?recursion=2\", nil, \"\", &containers)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn containers, nil\r\n}","code-length":146,"reference":"\/\/ GetContainersFull returns a list of containers including snapshots, backups and state","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainer(name string) (*api.Container, string, error) {\r\n\tcontainer := api.Container{}\r\n\t\r\n\tetag, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/containers\/%s\", url.QueryEscape(name)), nil, \"\", &container)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\treturn &container, etag, nil\r\n}","code-length":118,"reference":"\/\/ GetContainer returns the container entry for the provided name","result":"Get the container.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) CreateContainerFromBackup(args ContainerBackupArgs) (Operation, error) {\r\n\tif !r.HasExtension(\"container_backup\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"container_backup\\\" API extension\")\r\n\t}\r\n\tif args.PoolName == \"\" {\r\n\t\t\r\n\t\top, _, err := r.queryOperation(\"POST\", \"\/containers\", args.BackupFile, \"\")\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn op, nil\r\n\t}\r\n\tif !r.HasExtension(\"container_backup_override_pool\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"container_backup_override_pool\\\" API extension\")\r\n\t}\r\n\t\r\n\treqURL, err := r.setQueryAttributes(fmt.Sprintf(\"%s\/1.0\/containers\", r.httpHost))\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treq, err := http.NewRequest(\"POST\", reqURL, args.BackupFile)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treq.Header.Set(\"Content-Type\", \"application\/octet-stream\")\r\n\treq.Header.Set(\"X-LXD-pool\", args.PoolName)\r\n\t\r\n\tif r.httpUserAgent != \"\" {\r\n\t\treq.Header.Set(\"User-Agent\", r.httpUserAgent)\r\n\t}\r\n\t\r\n\tresp, err := r.do(req)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\t\r\n\tresponse, _, err := lxdParseResponse(resp)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\trespOperation, err := response.MetadataAsOperation()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\top := operation{\r\n\t\tOperation: *respOperation,\r\n\t\tr:         r,\r\n\t\tchActive:  make(chan bool),\r\n\t}\r\n\treturn &op, nil\r\n}","code-length":558,"reference":"\/\/ CreateContainerFromBackup is a convenience function to make it easier to\n\/\/ create a container from a backup","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) CreateContainer(container api.ContainersPost) (Operation, error) {\r\n\tif container.Source.ContainerOnly {\r\n\t\tif !r.HasExtension(\"container_only_migration\") {\r\n\t\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"container_only_migration\\\" API extension\")\r\n\t\t}\r\n\t}\r\n\t\r\n\top, _, err := r.queryOperation(\"POST\", \"\/containers\", container, \"\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":153,"reference":"\/\/ CreateContainer requests that LXD creates a new container","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) CreateContainerFromImage(source ImageServer, image api.Image, req api.ContainersPost) (RemoteOperation, error) {\r\n\t\r\n\treq.Source.Type = \"image\"\r\n\t\r\n\tif r == source {\r\n\t\t\r\n\t\treq.Source.Fingerprint = image.Fingerprint\r\n\t\treq.Source.Alias = \"\"\r\n\t\top, err := r.CreateContainer(req)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\trop := remoteOperation{\r\n\t\t\ttargetOp: op,\r\n\t\t\tchDone:   make(chan bool),\r\n\t\t}\r\n\t\t\r\n\t\tgo func() {\r\n\t\t\trop.err = rop.targetOp.Wait()\r\n\t\t\tclose(rop.chDone)\r\n\t\t}()\r\n\t\treturn &rop, nil\r\n\t}\r\n\t\r\n\treq.Source.Mode = \"pull\"\r\n\t\r\n\tif req.Source.Alias != \"\" && image.Public {\r\n\t\treq.Source.Fingerprint = \"\"\r\n\t} else {\r\n\t\treq.Source.Fingerprint = image.Fingerprint\r\n\t\treq.Source.Alias = \"\"\r\n\t}\r\n\t\r\n\tinfo, err := source.GetConnectionInfo()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treq.Source.Protocol = info.Protocol\r\n\treq.Source.Certificate = info.Certificate\r\n\t\r\n\tif !image.Public {\r\n\t\tsecret, err := source.GetImageSecret(image.Fingerprint)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treq.Source.Secret = secret\r\n\t}\r\n\treturn r.tryCreateContainer(req, info.Addresses)\r\n}","code-length":452,"reference":"\/\/ CreateContainerFromImage is a convenience function to make it easier to create a container from an existing image","result":"Create a container from an image.","score":[0.0818,0.2964]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) UpdateContainer(name string, container api.ContainerPut, ETag string) (Operation, error) {\r\n\t\r\n\top, _, err := r.queryOperation(\"PUT\", fmt.Sprintf(\"\/containers\/%s\", url.QueryEscape(name)), container, ETag)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":109,"reference":"\/\/ UpdateContainer updates the container definition","result":"Update the container.","score":[0.1502,0.3289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) RenameContainer(name string, container api.ContainerPost) (Operation, error) {\r\n\t\r\n\tif container.Migration {\r\n\t\treturn nil, fmt.Errorf(\"Can't ask for a migration through RenameContainer\")\r\n\t}\r\n\t\r\n\top, _, err := r.queryOperation(\"POST\", fmt.Sprintf(\"\/containers\/%s\", url.QueryEscape(name)), container, \"\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":142,"reference":"\/\/ RenameContainer requests that LXD renames the container","result":"Rename the container.","score":[0.0771,0.25]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) ExecContainer(containerName string, exec api.ContainerExecPost, args *ContainerExecArgs) (Operation, error) {\r\n\tif exec.RecordOutput {\r\n\t\tif !r.HasExtension(\"container_exec_recording\") {\r\n\t\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"container_exec_recording\\\" API extension\")\r\n\t\t}\r\n\t}\r\n\t\r\n\top, _, err := r.queryOperation(\"POST\", fmt.Sprintf(\"\/containers\/%s\/exec\", url.QueryEscape(containerName)), exec, \"\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\topAPI := op.Get()\r\n\t\r\n\tif args != nil {\r\n\t\t\r\n\t\tfds := map[string]string{}\r\n\t\tvalue, ok := opAPI.Metadata[\"fds\"]\r\n\t\tif ok {\r\n\t\t\tvalues := value.(map[string]interface{})\r\n\t\t\tfor k, v := range values {\r\n\t\t\t\tfds[k] = v.(string)\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tif args.Control != nil && fds[\"control\"] != \"\" {\r\n\t\t\tconn, err := r.GetOperationWebsocket(opAPI.ID, fds[\"control\"])\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\tgo args.Control(conn)\r\n\t\t}\r\n\t\tif exec.Interactive {\r\n\t\t\t\r\n\t\t\tif args.Stdin != nil && args.Stdout != nil {\r\n\t\t\t\t\r\n\t\t\t\tconn, err := r.GetOperationWebsocket(opAPI.ID, fds[\"0\"])\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn nil, err\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\tgo func() {\r\n\t\t\t\t\tshared.WebsocketSendStream(conn, args.Stdin, -1)\r\n\t\t\t\t\t<-shared.WebsocketRecvStream(args.Stdout, conn)\r\n\t\t\t\t\tconn.Close()\r\n\t\t\t\t\tif args.DataDone != nil {\r\n\t\t\t\t\t\tclose(args.DataDone)\r\n\t\t\t\t\t}\r\n\t\t\t\t}()\r\n\t\t\t} else {\r\n\t\t\t\tif args.DataDone != nil {\r\n\t\t\t\t\tclose(args.DataDone)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\t\r\n\t\t\tdones := map[int]chan bool{}\r\n\t\t\tconns := []*websocket.Conn{}\r\n\t\t\t\r\n\t\t\tif fds[\"0\"] != \"\" {\r\n\t\t\t\tconn, err := r.GetOperationWebsocket(opAPI.ID, fds[\"0\"])\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn nil, err\r\n\t\t\t\t}\r\n\t\t\t\tconns = append(conns, conn)\r\n\t\t\t\tdones[0] = shared.WebsocketSendStream(conn, args.Stdin, -1)\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif fds[\"1\"] != \"\" {\r\n\t\t\t\tconn, err := r.GetOperationWebsocket(opAPI.ID, fds[\"1\"])\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn nil, err\r\n\t\t\t\t}\r\n\t\t\t\tconns = append(conns, conn)\r\n\t\t\t\tdones[1] = shared.WebsocketRecvStream(args.Stdout, conn)\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif fds[\"2\"] != \"\" {\r\n\t\t\t\tconn, err := r.GetOperationWebsocket(opAPI.ID, fds[\"2\"])\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn nil, err\r\n\t\t\t\t}\r\n\t\t\t\tconns = append(conns, conn)\r\n\t\t\t\tdones[2] = shared.WebsocketRecvStream(args.Stderr, conn)\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tgo func() {\r\n\t\t\t\tfor i, chDone := range dones {\r\n\t\t\t\t\t\r\n\t\t\t\t\tif i == 0 {\r\n\t\t\t\t\t\tcontinue\r\n\t\t\t\t\t}\r\n\t\t\t\t\t<-chDone\r\n\t\t\t\t}\r\n\t\t\t\tif fds[\"0\"] != \"\" {\r\n\t\t\t\t\tif args.Stdin != nil {\r\n\t\t\t\t\t\targs.Stdin.Close()\r\n\t\t\t\t\t}\r\n\t\t\t\t\t\r\n\t\t\t\t\t\r\n\t\t\t\t\tgo func() {\r\n\t\t\t\t\t\t<-dones[0]\r\n\t\t\t\t\t}()\r\n\t\t\t\t}\r\n\t\t\t\tfor _, conn := range conns {\r\n\t\t\t\t\tconn.Close()\r\n\t\t\t\t}\r\n\t\t\t\tif args.DataDone != nil {\r\n\t\t\t\t\tclose(args.DataDone)\r\n\t\t\t\t}\r\n\t\t\t}()\r\n\t\t}\r\n\t}\r\n\treturn op, nil\r\n}","code-length":1149,"reference":"\/\/ ExecContainer requests that LXD spawns a command inside the container","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainerFile(containerName string, path string) (io.ReadCloser, *ContainerFileResponse, error) {\r\n\t\r\n\trequestURL, err := shared.URLEncode(\r\n\t\tfmt.Sprintf(\"%s\/1.0\/containers\/%s\/files\", r.httpHost, url.QueryEscape(containerName)),\r\n\t\tmap[string]string{\"path\": path})\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\trequestURL, err = r.setQueryAttributes(requestURL)\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\treq, err := http.NewRequest(\"GET\", requestURL, nil)\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\t\r\n\tif r.httpUserAgent != \"\" {\r\n\t\treq.Header.Set(\"User-Agent\", r.httpUserAgent)\r\n\t}\r\n\t\r\n\tresp, err := r.do(req)\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\t\r\n\tif resp.StatusCode != http.StatusOK {\r\n\t\t_, _, err := lxdParseResponse(resp)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, nil, err\r\n\t\t}\r\n\t}\r\n\t\r\n\tuid, gid, mode, fileType, _ := shared.ParseLXDFileHeaders(resp.Header)\r\n\tfileResp := ContainerFileResponse{\r\n\t\tUID:  uid,\r\n\t\tGID:  gid,\r\n\t\tMode: mode,\r\n\t\tType: fileType,\r\n\t}\r\n\tif fileResp.Type == \"directory\" {\r\n\t\t\r\n\t\tresponse := api.Response{}\r\n\t\tdecoder := json.NewDecoder(resp.Body)\r\n\t\terr = decoder.Decode(&response)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, nil, err\r\n\t\t}\r\n\t\t\r\n\t\tentries := []string{}\r\n\t\terr = response.MetadataAsStruct(&entries)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, nil, err\r\n\t\t}\r\n\t\tfileResp.Entries = entries\r\n\t\treturn nil, &fileResp, err\r\n\t}\r\n\treturn resp.Body, &fileResp, err\r\n}","code-length":592,"reference":"\/\/ GetContainerFile retrieves the provided path from the container","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) CreateContainerFile(containerName string, path string, args ContainerFileArgs) error {\r\n\tif args.Type == \"directory\" {\r\n\t\tif !r.HasExtension(\"directory_manipulation\") {\r\n\t\t\treturn fmt.Errorf(\"The server is missing the required \\\"directory_manipulation\\\" API extension\")\r\n\t\t}\r\n\t}\r\n\tif args.Type == \"symlink\" {\r\n\t\tif !r.HasExtension(\"file_symlinks\") {\r\n\t\t\treturn fmt.Errorf(\"The server is missing the required \\\"file_symlinks\\\" API extension\")\r\n\t\t}\r\n\t}\r\n\tif args.WriteMode == \"append\" {\r\n\t\tif !r.HasExtension(\"file_append\") {\r\n\t\t\treturn fmt.Errorf(\"The server is missing the required \\\"file_append\\\" API extension\")\r\n\t\t}\r\n\t}\r\n\t\r\n\trequestURL := fmt.Sprintf(\"%s\/1.0\/containers\/%s\/files?path=%s\", r.httpHost, url.QueryEscape(containerName), url.QueryEscape(path))\r\n\trequestURL, err := r.setQueryAttributes(requestURL)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treq, err := http.NewRequest(\"POST\", requestURL, args.Content)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif r.httpUserAgent != \"\" {\r\n\t\treq.Header.Set(\"User-Agent\", r.httpUserAgent)\r\n\t}\r\n\t\r\n\tif args.UID > -1 {\r\n\t\treq.Header.Set(\"X-LXD-uid\", fmt.Sprintf(\"%d\", args.UID))\r\n\t}\r\n\tif args.GID > -1 {\r\n\t\treq.Header.Set(\"X-LXD-gid\", fmt.Sprintf(\"%d\", args.GID))\r\n\t}\r\n\tif args.Mode > -1 {\r\n\t\treq.Header.Set(\"X-LXD-mode\", fmt.Sprintf(\"%04o\", args.Mode))\r\n\t}\r\n\tif args.Type != \"\" {\r\n\t\treq.Header.Set(\"X-LXD-type\", args.Type)\r\n\t}\r\n\tif args.WriteMode != \"\" {\r\n\t\treq.Header.Set(\"X-LXD-write\", args.WriteMode)\r\n\t}\r\n\t\r\n\tresp, err := r.do(req)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t_, _, err = lxdParseResponse(resp)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":667,"reference":"\/\/ CreateContainerFile tells LXD to create a file in the container","result":"Code too long,keep in 512.","score":[0.0724,0.0481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) DeleteContainerFile(containerName string, path string) error {\r\n\tif !r.HasExtension(\"file_delete\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"file_delete\\\" API extension\")\r\n\t}\r\n\t\r\n\t_, _, err := r.query(\"DELETE\", fmt.Sprintf(\"\/containers\/%s\/files?path=%s\", url.QueryEscape(containerName), url.QueryEscape(path)), nil, \"\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":152,"reference":"\/\/ DeleteContainerFile deletes a file in the container","result":"Delete a container file.","score":[0.1398,0.3363]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainerSnapshotNames(containerName string) ([]string, error) {\r\n\turls := []string{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/containers\/%s\/snapshots\", url.QueryEscape(containerName)), nil, \"\", &urls)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tnames := []string{}\r\n\tfor _, uri := range urls {\r\n\t\tfields := strings.Split(uri, fmt.Sprintf(\"\/containers\/%s\/snapshots\/\", url.QueryEscape(containerName)))\r\n\t\tnames = append(names, fields[len(fields)-1])\r\n\t}\r\n\treturn names, nil\r\n}","code-length":192,"reference":"\/\/ GetContainerSnapshotNames returns a list of snapshot names for the container","result":"Get the list of snapshots names for a container.","score":[0.201,0.6226]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainerSnapshots(containerName string) ([]api.ContainerSnapshot, error) {\r\n\tsnapshots := []api.ContainerSnapshot{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/containers\/%s\/snapshots?recursion=1\", url.QueryEscape(containerName)), nil, \"\", &snapshots)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn snapshots, nil\r\n}","code-length":124,"reference":"\/\/ GetContainerSnapshots returns a list of snapshots for the container","result":"Get the container snapshots.","score":[0.1008,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainerSnapshot(containerName string, name string) (*api.ContainerSnapshot, string, error) {\r\n\tsnapshot := api.ContainerSnapshot{}\r\n\t\r\n\tetag, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/containers\/%s\/snapshots\/%s\", url.QueryEscape(containerName), url.QueryEscape(name)), nil, \"\", &snapshot)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\treturn &snapshot, etag, nil\r\n}","code-length":137,"reference":"\/\/ GetContainerSnapshot returns a Snapshot struct for the provided container and snapshot names","result":"Get the snapshot from the container.","score":[0.0715,0.0813]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) CreateContainerSnapshot(containerName string, snapshot api.ContainerSnapshotsPost) (Operation, error) {\r\n\t\r\n\tif snapshot.ExpiresAt != nil && !r.HasExtension(\"snapshot_expiry_creation\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"snapshot_expiry_creation\\\" API extension\")\r\n\t}\r\n\t\r\n\top, _, err := r.queryOperation(\"POST\", fmt.Sprintf(\"\/containers\/%s\/snapshots\", url.QueryEscape(containerName)), snapshot, \"\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":170,"reference":"\/\/ CreateContainerSnapshot requests that LXD creates a new snapshot for the container","result":"Generate the generated code.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) MigrateContainerSnapshot(containerName string, name string, container api.ContainerSnapshotPost) (Operation, error) {\r\n\t\r\n\tif !container.Migration {\r\n\t\treturn nil, fmt.Errorf(\"Can't ask for a rename through MigrateContainerSnapshot\")\r\n\t}\r\n\t\r\n\top, _, err := r.queryOperation(\"POST\", fmt.Sprintf(\"\/containers\/%s\/snapshots\/%s\", url.QueryEscape(containerName), url.QueryEscape(name)), container, \"\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":162,"reference":"\/\/ MigrateContainerSnapshot requests that LXD prepares for a snapshot migration","result":"Create a new LXD instance.","score":[0.1051,0.1053]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) UpdateContainerSnapshot(containerName string, name string, container api.ContainerSnapshotPut, ETag string) (Operation, error) {\r\n\tif !r.HasExtension(\"snapshot_expiry\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"snapshot_expiry\\\" API extension\")\r\n\t}\r\n\t\r\n\top, _, err := r.queryOperation(\"PUT\", fmt.Sprintf(\"\/containers\/%s\/snapshots\/%s\",\r\n\t\turl.QueryEscape(containerName), url.QueryEscape(name)), container, ETag)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":175,"reference":"\/\/ UpdateContainerSnapshot requests that LXD updates the container snapshot","result":"Update the snapshot on the server.","score":[0.1392,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainerState(name string) (*api.ContainerState, string, error) {\r\n\tstate := api.ContainerState{}\r\n\t\r\n\tetag, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/containers\/%s\/state\", url.QueryEscape(name)), nil, \"\", &state)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\treturn &state, etag, nil\r\n}","code-length":123,"reference":"\/\/ GetContainerState returns a ContainerState entry for the provided container name","result":"Get the container state.","score":[0.066,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) UpdateContainerState(name string, state api.ContainerStatePut, ETag string) (Operation, error) {\r\n\t\r\n\top, _, err := r.queryOperation(\"PUT\", fmt.Sprintf(\"\/containers\/%s\/state\", url.QueryEscape(name)), state, ETag)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":113,"reference":"\/\/ UpdateContainerState updates the container to match the requested state","result":"Update the container state.","score":[0.1008,0.1596]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainerLogfiles(name string) ([]string, error) {\r\n\turls := []string{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/containers\/%s\/logs\", url.QueryEscape(name)), nil, \"\", &urls)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tlogfiles := []string{}\r\n\tfor _, uri := range logfiles {\r\n\t\tfields := strings.Split(uri, fmt.Sprintf(\"\/containers\/%s\/logs\/\", url.QueryEscape(name)))\r\n\t\tlogfiles = append(logfiles, fields[len(fields)-1])\r\n\t}\r\n\treturn logfiles, nil\r\n}","code-length":194,"reference":"\/\/ GetContainerLogfiles returns a list of logfiles for the container","result":"Get the container logfiles.","score":[0.1008,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainerLogfile(name string, filename string) (io.ReadCloser, error) {\r\n\t\r\n\turl := fmt.Sprintf(\"%s\/1.0\/containers\/%s\/logs\/%s\", r.httpHost, url.QueryEscape(name), url.QueryEscape(filename))\r\n\turl, err := r.setQueryAttributes(url)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treq, err := http.NewRequest(\"GET\", url, nil)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tif r.httpUserAgent != \"\" {\r\n\t\treq.Header.Set(\"User-Agent\", r.httpUserAgent)\r\n\t}\r\n\t\r\n\tresp, err := r.do(req)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tif resp.StatusCode != http.StatusOK {\r\n\t\t_, _, err := lxdParseResponse(resp)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\treturn resp.Body, err\r\n}","code-length":300,"reference":"\/\/ GetContainerLogfile returns the content of the requested logfile\n\/\/\n\/\/ Note that it's the caller's responsibility to close the returned ReadCloser","result":"Avoid the need for the following line.","score":[0.0225,0.0488]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainerMetadata(name string) (*api.ImageMetadata, string, error) {\r\n\tif !r.HasExtension(\"container_edit_metadata\") {\r\n\t\treturn nil, \"\", fmt.Errorf(\"The server is missing the required \\\"container_edit_metadata\\\" API extension\")\r\n\t}\r\n\tmetadata := api.ImageMetadata{}\r\n\turl := fmt.Sprintf(\"\/containers\/%s\/metadata\", url.QueryEscape(name))\r\n\tetag, err := r.queryStruct(\"GET\", url, nil, \"\", &metadata)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\treturn &metadata, etag, err\r\n}","code-length":175,"reference":"\/\/ GetContainerMetadata returns container metadata.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) SetContainerMetadata(name string, metadata api.ImageMetadata, ETag string) error {\r\n\tif !r.HasExtension(\"container_edit_metadata\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"container_edit_metadata\\\" API extension\")\r\n\t}\r\n\turl := fmt.Sprintf(\"\/containers\/%s\/metadata\", url.QueryEscape(name))\r\n\t_, _, err := r.query(\"PUT\", url, metadata, ETag)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":152,"reference":"\/\/ SetContainerMetadata sets the content of the container metadata file.","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainerTemplateFiles(containerName string) ([]string, error) {\r\n\tif !r.HasExtension(\"container_edit_metadata\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"container_edit_metadata\\\" API extension\")\r\n\t}\r\n\ttemplates := []string{}\r\n\turl := fmt.Sprintf(\"\/containers\/%s\/metadata\/templates\", url.QueryEscape(containerName))\r\n\t_, err := r.queryStruct(\"GET\", url, nil, \"\", &templates)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn templates, nil\r\n}","code-length":168,"reference":"\/\/ GetContainerTemplateFiles returns the list of names of template files for a container.","result":"Generate the generated code.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) CreateContainerTemplateFile(containerName string, templateName string, content io.ReadSeeker) error {\r\n\treturn r.setContainerTemplateFile(containerName, templateName, content, \"POST\")\r\n}","code-length":61,"reference":"\/\/ CreateContainerTemplateFile creates an a template for a container.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) DeleteContainerTemplateFile(name string, templateName string) error {\r\n\tif !r.HasExtension(\"container_edit_metadata\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"container_edit_metadata\\\" API extension\")\r\n\t}\r\n\t_, _, err := r.query(\"DELETE\", fmt.Sprintf(\"\/containers\/%s\/metadata\/templates?path=%s\", url.QueryEscape(name), url.QueryEscape(templateName)), nil, \"\")\r\n\treturn err\r\n}","code-length":137,"reference":"\/\/ DeleteContainerTemplateFile deletes a template file for a container.","result":"Delete the container template file.","score":[0.108,0.1163]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) ConsoleContainer(containerName string, console api.ContainerConsolePost, args *ContainerConsoleArgs) (Operation, error) {\r\n\tif !r.HasExtension(\"console\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"console\\\" API extension\")\r\n\t}\r\n\t\r\n\top, _, err := r.queryOperation(\"POST\", fmt.Sprintf(\"\/containers\/%s\/console\", url.QueryEscape(containerName)), console, \"\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\topAPI := op.Get()\r\n\tif args == nil || args.Terminal == nil {\r\n\t\treturn nil, fmt.Errorf(\"A terminal must be set\")\r\n\t}\r\n\tif args.Control == nil {\r\n\t\treturn nil, fmt.Errorf(\"A control channel must be set\")\r\n\t}\r\n\t\r\n\tfds := map[string]string{}\r\n\tvalue, ok := opAPI.Metadata[\"fds\"]\r\n\tif ok {\r\n\t\tvalues := value.(map[string]interface{})\r\n\t\tfor k, v := range values {\r\n\t\t\tfds[k] = v.(string)\r\n\t\t}\r\n\t}\r\n\tvar controlConn *websocket.Conn\r\n\t\r\n\tif fds[\"control\"] == \"\" {\r\n\t\treturn nil, fmt.Errorf(\"Did not receive a file descriptor for the control channel\")\r\n\t}\r\n\tcontrolConn, err = r.GetOperationWebsocket(opAPI.ID, fds[\"control\"])\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tgo args.Control(controlConn)\r\n\t\r\n\tconn, err := r.GetOperationWebsocket(opAPI.ID, fds[\"0\"])\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tgo func(consoleDisconnect <-chan bool) {\r\n\t\t<-consoleDisconnect\r\n\t\tmsg := websocket.FormatCloseMessage(websocket.CloseNormalClosure, \"Detaching from console\")\r\n\t\t\r\n\t\tcontrolConn.WriteMessage(websocket.CloseMessage, msg)\r\n\t\tcontrolConn.Close()\r\n\t}(args.ConsoleDisconnect)\r\n\t\r\n\tgo func() {\r\n\t\tshared.WebsocketSendStream(conn, args.Terminal, -1)\r\n\t\t<-shared.WebsocketRecvStream(args.Terminal, conn)\r\n\t\tconn.Close()\r\n\t}()\r\n\treturn op, nil\r\n}","code-length":623,"reference":"\/\/ ConsoleContainer requests that LXD attaches to the console device of a container.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainerConsoleLog(containerName string, args *ContainerConsoleLogArgs) (io.ReadCloser, error) {\r\n\tif !r.HasExtension(\"console\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"console\\\" API extension\")\r\n\t}\r\n\t\r\n\turl := fmt.Sprintf(\"%s\/1.0\/containers\/%s\/console\", r.httpHost, url.QueryEscape(containerName))\r\n\turl, err := r.setQueryAttributes(url)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treq, err := http.NewRequest(\"GET\", url, nil)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tif r.httpUserAgent != \"\" {\r\n\t\treq.Header.Set(\"User-Agent\", r.httpUserAgent)\r\n\t}\r\n\t\r\n\tresp, err := r.do(req)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tif resp.StatusCode != http.StatusOK {\r\n\t\t_, _, err := lxdParseResponse(resp)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\treturn resp.Body, err\r\n}","code-length":337,"reference":"\/\/ GetContainerConsoleLog requests that LXD attaches to the console device of a container.\n\/\/\n\/\/ Note that it's the caller's responsibility to close the returned ReadCloser","result":"Get the console log for a container.","score":[0.0199,0.131]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) DeleteContainerConsoleLog(containerName string, args *ContainerConsoleLogArgs) error {\r\n\tif !r.HasExtension(\"console\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"console\\\" API extension\")\r\n\t}\r\n\t\r\n\t_, _, err := r.query(\"DELETE\", fmt.Sprintf(\"\/containers\/%s\/console\", url.QueryEscape(containerName)), nil, \"\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":142,"reference":"\/\/ DeleteContainerConsoleLog deletes the requested container's console log","result":"Delete the container console log.","score":[0.1568,0.3319]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainerBackups(containerName string) ([]api.ContainerBackup, error) {\r\n\tif !r.HasExtension(\"container_backup\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"container_backup\\\" API extension\")\r\n\t}\r\n\t\r\n\tbackups := []api.ContainerBackup{}\r\n\t_, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/containers\/%s\/backups?recursion=1\", url.QueryEscape(containerName)), nil, \"\", &backups)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn backups, nil\r\n}","code-length":171,"reference":"\/\/ GetContainerBackups returns a list of backups for the container","result":"Avoid the need for a function to be executed.","score":[0.1435,0.1515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainerBackup(containerName string, name string) (*api.ContainerBackup, string, error) {\r\n\tif !r.HasExtension(\"container_backup\") {\r\n\t\treturn nil, \"\", fmt.Errorf(\"The server is missing the required \\\"container_backup\\\" API extension\")\r\n\t}\r\n\t\r\n\tbackup := api.ContainerBackup{}\r\n\tetag, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/containers\/%s\/backups\/%s\", url.QueryEscape(containerName), url.QueryEscape(name)), nil, \"\", &backup)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\treturn &backup, etag, nil\r\n}","code-length":183,"reference":"\/\/ GetContainerBackup returns a Backup struct for the provided container and backup names","result":"Avoid the need for a function to be called.","score":[0.1028,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) CreateContainerBackup(containerName string, backup api.ContainerBackupsPost) (Operation, error) {\r\n\tif !r.HasExtension(\"container_backup\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"container_backup\\\" API extension\")\r\n\t}\r\n\t\r\n\top, _, err := r.queryOperation(\"POST\", fmt.Sprintf(\"\/containers\/%s\/backups\",\r\n\t\turl.QueryEscape(containerName)), backup, \"\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":161,"reference":"\/\/ CreateContainerBackup requests that LXD creates a new backup for the container","result":"Generate the generated code.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) RenameContainerBackup(containerName string, name string, backup api.ContainerBackupPost) (Operation, error) {\r\n\tif !r.HasExtension(\"container_backup\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"container_backup\\\" API extension\")\r\n\t}\r\n\t\r\n\top, _, err := r.queryOperation(\"POST\", fmt.Sprintf(\"\/containers\/%s\/backups\/%s\",\r\n\t\turl.QueryEscape(containerName), url.QueryEscape(name)), backup, \"\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":173,"reference":"\/\/ RenameContainerBackup requests that LXD renames the backup","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) DeleteContainerBackup(containerName string, name string) (Operation, error) {\r\n\tif !r.HasExtension(\"container_backup\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"container_backup\\\" API extension\")\r\n\t}\r\n\t\r\n\top, _, err := r.queryOperation(\"DELETE\", fmt.Sprintf(\"\/containers\/%s\/backups\/%s\",\r\n\t\turl.QueryEscape(containerName), url.QueryEscape(name)), nil, \"\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":166,"reference":"\/\/ DeleteContainerBackup requests that LXD deletes the container backup","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainerBackupFile(containerName string, name string, req *BackupFileRequest) (*BackupFileResponse, error) {\r\n\tif !r.HasExtension(\"container_backup\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"container_backup\\\" API extension\")\r\n\t}\r\n\t\r\n\turi := fmt.Sprintf(\"%s\/1.0\/containers\/%s\/backups\/%s\/export\", r.httpHost,\r\n\t\turl.QueryEscape(containerName), url.QueryEscape(name))\r\n\tif r.project != \"\" {\r\n\t\turi += fmt.Sprintf(\"?project=%s\", url.QueryEscape(r.project))\r\n\t}\r\n\t\r\n\trequest, err := http.NewRequest(\"GET\", uri, nil)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif r.httpUserAgent != \"\" {\r\n\t\trequest.Header.Set(\"User-Agent\", r.httpUserAgent)\r\n\t}\r\n\t\r\n\tresponse, doneCh, err := cancel.CancelableDownload(req.Canceler, r.http, request)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer response.Body.Close()\r\n\tdefer close(doneCh)\r\n\tif response.StatusCode != http.StatusOK {\r\n\t\t_, _, err := lxdParseResponse(response)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\t\r\n\tbody := response.Body\r\n\tif req.ProgressHandler != nil {\r\n\t\tbody = &ioprogress.ProgressReader{\r\n\t\t\tReadCloser: response.Body,\r\n\t\t\tTracker: &ioprogress.ProgressTracker{\r\n\t\t\t\tLength: response.ContentLength,\r\n\t\t\t\tHandler: func(percent int64, speed int64) {\r\n\t\t\t\t\treq.ProgressHandler(ioprogress.ProgressData{Text: fmt.Sprintf(\"%d%% (%s\/s)\", percent, shared.GetByteSizeString(speed, 2))})\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t}\r\n\t}\r\n\tsize, err := io.Copy(req.BackupFile, body)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tresp := BackupFileResponse{}\r\n\tresp.Size = size\r\n\treturn &resp, nil\r\n}","code-length":603,"reference":"\/\/ GetContainerBackupFile requests the container backup content","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RsyncSend(name string, path string, conn *websocket.Conn, readWrapper func(io.ReadCloser) io.ReadCloser, features []string, bwlimit string, execPath string) error {\r\n\tcmd, dataSocket, stderr, err := rsyncSendSetup(name, path, bwlimit, execPath, features)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif dataSocket != nil {\r\n\t\tdefer dataSocket.Close()\r\n\t}\r\n\treadPipe := io.ReadCloser(dataSocket)\r\n\tif readWrapper != nil {\r\n\t\treadPipe = readWrapper(dataSocket)\r\n\t}\r\n\treadDone, writeDone := shared.WebsocketMirror(conn, dataSocket, readPipe, nil, nil)\r\n\tchError := make(chan error, 1)\r\n\tgo func() {\r\n\t\terr = cmd.Wait()\r\n\t\tif err != nil {\r\n\t\t\tdataSocket.Close()\r\n\t\t\treadPipe.Close()\r\n\t\t}\r\n\t\tchError <- err\r\n\t}()\r\n\toutput, err := ioutil.ReadAll(stderr)\r\n\tif err != nil {\r\n\t\tcmd.Process.Kill()\r\n\t}\r\n\terr = <-chError\r\n\tif err != nil {\r\n\t\tlogger.Errorf(\"Rsync send failed: %s: %s: %s\", path, err, string(output))\r\n\t}\r\n\t<-readDone\r\n\t<-writeDone\r\n\treturn err\r\n}","code-length":373,"reference":"\/\/ RsyncSend sets up the sending half of an rsync, to recursively send the\n\/\/ directory pointed to by path over the websocket.","result":"Send rsync commands.","score":[0,0.0238]}
{"code":"\/*is used to<extra_id_0>\r\nfunc patchesGetNames() []string {\r\n\tnames := make([]string, len(patches))\r\n\tfor i, patch := range patches {\r\n\t\tnames[i] = patch.name\r\n\t}\r\n\treturn names\r\n}","code-length":66,"reference":"\/\/ Return the names of all available patches.","result":"Get the names of the patches.","score":[0.3062,0.4046]}
{"code":"\/*is used to<extra_id_0>\r\nfunc patchRenameCustomVolumeLVs(name string, d *Daemon) error {\r\n\t\r\n\tpools, _ := d.cluster.StoragePools()\r\n\tfor _, poolName := range pools {\r\n\t\tpoolID, pool, err := d.cluster.StoragePoolGet(poolName)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tsType, err := storageStringToType(pool.Driver)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif sType != storageTypeLvm {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvolumes, err := d.cluster.StoragePoolNodeVolumesGetType(storagePoolVolumeTypeCustom, poolID)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tvgName := poolName\r\n\t\tif pool.Config[\"lvm.vg_name\"] != \"\" {\r\n\t\t\tvgName = pool.Config[\"lvm.vg_name\"]\r\n\t\t}\r\n\t\tfor _, volume := range volumes {\r\n\t\t\toldName := fmt.Sprintf(\"%s\/custom_%s\", vgName, volume)\r\n\t\t\tnewName := fmt.Sprintf(\"%s\/custom_%s\", vgName, containerNameToLVName(volume))\r\n\t\t\texists, err := storageLVExists(newName)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif exists || oldName == newName {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\terr = lvmLVRename(vgName, oldName, newName)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tlogger.Info(\"Successfully renamed LV\", log.Ctx{\"old_name\": oldName, \"new_name\": newName})\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":459,"reference":"\/\/ Patches begin here","result":"Patch the storage volume name.","score":[0,0.122]}
{"code":"\/*is used to<extra_id_0>\r\nfunc patchLvmNodeSpecificConfigKeys(name string, d *Daemon) error {\r\n\ttx, err := d.cluster.Begin()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to begin transaction\")\r\n\t}\r\n\t\r\n\tnodeIDs, err := query.SelectIntegers(tx, \"SELECT id FROM nodes\")\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to get IDs of current nodes\")\r\n\t}\r\n\t\r\n\tpoolIDs, err := query.SelectIntegers(tx, \"SELECT id FROM storage_pools WHERE driver='lvm'\")\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to get IDs of current lvm pools\")\r\n\t}\r\n\tfor _, poolID := range poolIDs {\r\n\t\t\r\n\t\t\r\n\t\tconfig, err := query.SelectConfig(\r\n\t\t\ttx, \"storage_pools_config\", \"storage_pool_id=? AND node_id IS NULL\", poolID)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"failed to fetch of lvm pool config\")\r\n\t\t}\r\n\t\tfor _, key := range []string{\"lvm.thinpool_name\", \"lvm.vg_name\"} {\r\n\t\t\tvalue, ok := config[key]\r\n\t\t\tif !ok {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\t_, err = tx.Exec(`\r\nDELETE FROM storage_pools_config WHERE key=? AND storage_pool_id=? AND node_id IS NULL\r\n`, key, poolID)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn errors.Wrapf(err, \"failed to delete %s config\", key)\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tfor _, nodeID := range nodeIDs {\r\n\t\t\t\t_, err := tx.Exec(`\r\nINSERT INTO storage_pools_config(storage_pool_id, node_id, key, value)\r\n  VALUES(?, ?, ?, ?)\r\n`, poolID, nodeID, key, value)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn errors.Wrapf(err, \"failed to create %s node config\", key)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\terr = tx.Commit()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to commit transaction\")\r\n\t}\r\n\treturn err\r\n}","code-length":611,"reference":"\/\/ The lvm.thinpool_name and lvm.vg_name config keys are node-specific and need\n\/\/ to be linked to nodes.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetHTTPClient() (*http.Client, error) {\r\n\tif r.http == nil {\r\n\t\treturn nil, fmt.Errorf(\"HTTP client isn't set, bad connection\")\r\n\t}\r\n\treturn r.http, nil\r\n}","code-length":75,"reference":"\/\/ GetHTTPClient returns the http client used for the connection. This can be used to set custom http options.","result":"Create a new LXD client.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) do(req *http.Request) (*http.Response, error) {\r\n\tif r.bakeryClient != nil {\r\n\t\tr.addMacaroonHeaders(req)\r\n\t\treturn r.bakeryClient.Do(req)\r\n\t}\r\n\treturn r.http.Do(req)\r\n}","code-length":93,"reference":"\/\/ Do performs a Request, using macaroon authentication if set.","result":"Implement the LXD protocol.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) RawQuery(method string, path string, data interface{}, ETag string) (*api.Response, string, error) {\r\n\t\r\n\turl := fmt.Sprintf(\"%s%s\", r.httpHost, path)\r\n\treturn r.rawQuery(method, url, data, ETag)\r\n}","code-length":87,"reference":"\/\/ RawQuery allows directly querying the LXD API\n\/\/\n\/\/ This should only be used by internal LXD tools.","result":"Query LXD.","score":[0,0.0289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) RawWebsocket(path string) (*websocket.Conn, error) {\r\n\treturn r.websocket(path)\r\n}","code-length":45,"reference":"\/\/ RawWebsocket allows directly connection to LXD API websockets\n\/\/\n\/\/ This should only be used by internal LXD tools.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) RawOperation(method string, path string, data interface{}, ETag string) (Operation, string, error) {\r\n\treturn r.queryOperation(method, path, data, ETag)\r\n}","code-length":61,"reference":"\/\/ RawOperation allows direct querying of a LXD API endpoint returning\n\/\/ background operations.","result":"Generate the LXD code.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ProfileToAPI(profile *Profile) *api.Profile {\r\n\tp := &api.Profile{\r\n\t\tName:   profile.Name,\r\n\t\tUsedBy: profile.UsedBy,\r\n\t}\r\n\tp.Description = profile.Description\r\n\tp.Config = profile.Config\r\n\tp.Devices = profile.Devices\r\n\treturn p\r\n}","code-length":98,"reference":"\/\/ ProfileToAPI is a convenience to convert a Profile db struct into\n\/\/ an API profile struct.","result":"Convert profile to api.","score":[0.0147,0.0955]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) Profiles(project string) ([]string, error) {\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tenabled, err := tx.ProjectHasProfiles(project)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Check if project has profiles\")\r\n\t\t}\r\n\t\tif !enabled {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tq := fmt.Sprintf(`\r\nSELECT profiles.name\r\n FROM profiles\r\n JOIN projects ON projects.id = profiles.project_id\r\nWHERE projects.name = ?\r\n`)\r\n\tinargs := []interface{}{project}\r\n\tvar name string\r\n\toutfmt := []interface{}{name}\r\n\tresult, err := queryScan(c.db, q, inargs, outfmt)\r\n\tif err != nil {\r\n\t\treturn []string{}, err\r\n\t}\r\n\tresponse := []string{}\r\n\tfor _, r := range result {\r\n\t\tresponse = append(response, r[0].(string))\r\n\t}\r\n\treturn response, nil\r\n}","code-length":316,"reference":"\/\/ Profiles returns a string list of profiles.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ProfileGet(project, name string) (int64, *api.Profile, error) {\r\n\tvar result *api.Profile\r\n\tvar id int64\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tenabled, err := tx.ProjectHasProfiles(project)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Check if project has profiles\")\r\n\t\t}\r\n\t\tif !enabled {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\tprofile, err := tx.ProfileGet(project, name)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tresult = ProfileToAPI(profile)\r\n\t\tid = int64(profile.ID)\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn -1, nil, err\r\n\t}\r\n\treturn id, result, nil\r\n}","code-length":246,"reference":"\/\/ ProfileGet returns the profile with the given name.","result":"Generate code for the generated code.","score":[0.1171,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ProfilesGet(project string, names []string) ([]api.Profile, error) {\r\n\tprofiles := make([]api.Profile, len(names))\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tenabled, err := tx.ProjectHasProfiles(project)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Check if project has profiles\")\r\n\t\t}\r\n\t\tif !enabled {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\tfor i, name := range names {\r\n\t\t\tprofile, err := tx.ProfileGet(project, name)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn errors.Wrapf(err, \"Load profile %q\", name)\r\n\t\t\t}\r\n\t\t\tprofiles[i] = *ProfileToAPI(profile)\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn profiles, nil\r\n}","code-length":263,"reference":"\/\/ ProfilesGet returns the profiles with the given names in the given project.","result":"Generate code for the generated code.","score":[0.0601,0.0407]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ProfileConfig(project, name string) (map[string]string, error) {\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tenabled, err := tx.ProjectHasProfiles(project)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Check if project has profiles\")\r\n\t\t}\r\n\t\tif !enabled {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar key, value string\r\n\tquery := `\r\n        SELECT\r\n            key, value\r\n        FROM profiles_config\r\n        JOIN profiles ON profiles_config.profile_id=profiles.id\r\n        JOIN projects ON projects.id = profiles.project_id\r\n        WHERE projects.name=? AND profiles.name=?`\r\n\tinargs := []interface{}{project, name}\r\n\toutfmt := []interface{}{key, value}\r\n\tresults, err := queryScan(c.db, query, inargs, outfmt)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrapf(err, \"Failed to get profile '%s'\", name)\r\n\t}\r\n\tif len(results) == 0 {\r\n\t\t\r\n\t\tquery := \"SELECT id FROM profiles WHERE name=?\"\r\n\t\tvar id int\r\n\t\tresults, err := queryScan(c.db, query, []interface{}{name}, []interface{}{id})\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tif len(results) == 0 {\r\n\t\t\treturn nil, ErrNoSuchObject\r\n\t\t}\r\n\t}\r\n\tconfig := map[string]string{}\r\n\tfor _, r := range results {\r\n\t\tkey = r[0].(string)\r\n\t\tvalue = r[1].(string)\r\n\t\tconfig[key] = value\r\n\t}\r\n\treturn config, nil\r\n}","code-length":504,"reference":"\/\/ ProfileConfig gets the profile configuration map from the DB.","result":"Get the profile config from the database.","score":[0.1958,0.499]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ProfileConfigClear(tx *sql.Tx, id int64) error {\r\n\t_, err := tx.Exec(\"DELETE FROM profiles_config WHERE profile_id=?\", id)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t_, err = tx.Exec(`DELETE FROM profiles_devices_config WHERE id IN\r\n\t\t(SELECT profiles_devices_config.id\r\n\t\t FROM profiles_devices_config JOIN profiles_devices\r\n\t\t ON profiles_devices_config.profile_device_id=profiles_devices.id\r\n\t\t WHERE profiles_devices.profile_id=?)`, id)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t_, err = tx.Exec(\"DELETE FROM profiles_devices WHERE profile_id=?\", id)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":221,"reference":"\/\/ ProfileConfigClear resets the config of the profile with the given ID.","result":"Clear the config of a profile.","score":[0.1463,0.2242]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ProfileConfigAdd(tx *sql.Tx, id int64, config map[string]string) error {\r\n\tstr := fmt.Sprintf(\"INSERT INTO profiles_config (profile_id, key, value) VALUES(?, ?, ?)\")\r\n\tstmt, err := tx.Prepare(str)\r\n\tdefer stmt.Close()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfor k, v := range config {\r\n\t\tif v == \"\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t_, err = stmt.Exec(id, k, v)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":183,"reference":"\/\/ ProfileConfigAdd adds a config to the profile with the given ID.","result":"Add a new profile config.","score":[0.0705,0.2262]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ProfileContainersGet(project, profile string) (map[string][]string, error) {\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tenabled, err := tx.ProjectHasProfiles(project)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Check if project has profiles\")\r\n\t\t}\r\n\t\tif !enabled {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tq := `SELECT containers.name, projects.name FROM containers\r\n\t\tJOIN containers_profiles ON containers.id == containers_profiles.container_id\r\n\t\tJOIN projects ON projects.id == containers.project_id\r\n\t\tWHERE containers_profiles.profile_id ==\r\n\t\t  (SELECT profiles.id FROM profiles\r\n\t\t   JOIN projects ON projects.id == profiles.project_id\r\n\t\t   WHERE profiles.name=? AND projects.name=?)\r\n\t\tAND containers.type == 0`\r\n\tresults := map[string][]string{}\r\n\tinargs := []interface{}{profile, project}\r\n\tvar name string\r\n\toutfmt := []interface{}{name, name}\r\n\toutput, err := queryScan(c.db, q, inargs, outfmt)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tfor _, r := range output {\r\n\t\tif results[r[1].(string)] == nil {\r\n\t\t\tresults[r[1].(string)] = []string{}\r\n\t\t}\r\n\t\tresults[r[1].(string)] = append(results[r[1].(string)], r[0].(string))\r\n\t}\r\n\treturn results, nil\r\n}","code-length":456,"reference":"\/\/ ProfileContainersGet gets the names of the containers associated with the\n\/\/ profile with the given name.","result":"Get the profile containers from the database.","score":[0.0547,0.1562]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ProfileCleanupLeftover() error {\r\n\tstmt := `\r\nDELETE FROM profiles_config WHERE profile_id NOT IN (SELECT id FROM profiles);\r\nDELETE FROM profiles_devices WHERE profile_id NOT IN (SELECT id FROM profiles);\r\nDELETE FROM profiles_devices_config WHERE profile_device_id NOT IN (SELECT id FROM profiles_devices);\r\n`\r\n\terr := exec(c.db, stmt)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":134,"reference":"\/\/ ProfileCleanupLeftover removes unreferenced profiles.","result":"Clean up leftover profiles.","score":[0.2488,0.102]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ProfilesExpandConfig(config map[string]string, profiles []api.Profile) map[string]string {\r\n\texpandedConfig := map[string]string{}\r\n\t\r\n\tprofileConfigs := make([]map[string]string, len(profiles))\r\n\tfor i, profile := range profiles {\r\n\t\tprofileConfigs[i] = profile.Config\r\n\t}\r\n\tfor i := range profileConfigs {\r\n\t\tfor k, v := range profileConfigs[i] {\r\n\t\t\texpandedConfig[k] = v\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor k, v := range config {\r\n\t\texpandedConfig[k] = v\r\n\t}\r\n\treturn expandedConfig\r\n}","code-length":180,"reference":"\/\/ ProfilesExpandConfig expands the given container config with the config\n\/\/ values of the given profiles.","result":"Expand the config in the profile.","score":[0.0571,0.2104]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ProfilesExpandDevices(devices types.Devices, profiles []api.Profile) types.Devices {\r\n\texpandedDevices := types.Devices{}\r\n\t\r\n\tprofileDevices := make([]types.Devices, len(profiles))\r\n\tfor i, profile := range profiles {\r\n\t\tprofileDevices[i] = profile.Devices\r\n\t}\r\n\tfor i := range profileDevices {\r\n\t\tfor k, v := range profileDevices[i] {\r\n\t\t\texpandedDevices[k] = v\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor k, v := range devices {\r\n\t\texpandedDevices[k] = v\r\n\t}\r\n\treturn expandedDevices\r\n}","code-length":172,"reference":"\/\/ ProfilesExpandDevices expands the given container devices with the devices\n\/\/ defined in the given profiles.","result":"Expand devices in profiles.","score":[0.0209,0.1351]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetServer() (*api.Server, string, error) {\r\n\tserver := api.Server{}\r\n\t\r\n\tetag, err := r.queryStruct(\"GET\", \"\", nil, \"\", &server)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\t\r\n\tif server.Environment.CertificateFingerprint == \"\" && server.Environment.Certificate != \"\" {\r\n\t\tvar err error\r\n\t\tserver.Environment.CertificateFingerprint, err = shared.CertFingerprintStr(server.Environment.Certificate)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, \"\", err\r\n\t\t}\r\n\t}\r\n\tif !server.Public && len(server.AuthMethods) == 0 {\r\n\t\t\r\n\t\tserver.AuthMethods = []string{\"tls\"}\r\n\t}\r\n\t\r\n\tr.server = &server\r\n\treturn &server, etag, nil\r\n}","code-length":234,"reference":"\/\/ Server handling functions\n\/\/ GetServer returns the server status as a Server struct","result":"Avoid the need for the function to be executed.","score":[0.0699,0.0741]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) UpdateServer(server api.ServerPut, ETag string) error {\r\n\t\r\n\t_, _, err := r.query(\"PUT\", \"\", server, ETag)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":80,"reference":"\/\/ UpdateServer updates the server status to match the provided Server struct","result":"Update the server.","score":[0.0203,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) HasExtension(extension string) bool {\r\n\t\r\n\t\r\n\tif r.server == nil {\r\n\t\treturn true\r\n\t}\r\n\tfor _, entry := range r.server.APIExtensions {\r\n\t\tif entry == extension {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":99,"reference":"\/\/ HasExtension returns true if the server supports a given API extension","result":"Check if the server has an extension.","score":[0.1628,0.256]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetServerResources() (*api.Resources, error) {\r\n\tif !r.HasExtension(\"resources\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"resources\\\" API extension\")\r\n\t}\r\n\tresources := api.Resources{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", \"\/resources\", nil, \"\", &resources)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &resources, nil\r\n}","code-length":136,"reference":"\/\/ GetServerResources returns the resources available to a given LXD server","result":"Generate the generated code.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) UseProject(name string) ContainerServer {\r\n\treturn &ProtocolLXD{\r\n\t\tserver:               r.server,\r\n\t\thttp:                 r.http,\r\n\t\thttpCertificate:      r.httpCertificate,\r\n\t\thttpHost:             r.httpHost,\r\n\t\thttpProtocol:         r.httpProtocol,\r\n\t\thttpUserAgent:        r.httpUserAgent,\r\n\t\tbakeryClient:         r.bakeryClient,\r\n\t\tbakeryInteractor:     r.bakeryInteractor,\r\n\t\trequireAuthenticated: r.requireAuthenticated,\r\n\t\tclusterTarget:        r.clusterTarget,\r\n\t\tproject:              name,\r\n\t}\r\n}","code-length":182,"reference":"\/\/ UseProject returns a client that will use a specific project.","result":"Create a new LXD instance.","score":[0.0724,0.0481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc sqliteOpen(path string) (*sql.DB, error) {\r\n\ttimeout := 5\r\n\t\r\n\t\r\n\topenPath := fmt.Sprintf(\"%s?_busy_timeout=%d&_txlock=exclusive\", path, timeout*1000)\r\n\t\r\n\treturn sql.Open(\"sqlite3_with_fk\", openPath)\r\n}","code-length":94,"reference":"\/\/ Opens the node-level database with the correct parameters for LXD.","result":"Open the database .","score":[0.066,0.1456]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Rebalance(state *state.State, gateway *Gateway) (string, []db.RaftNode, error) {\r\n\t\r\n\t\r\n\tcurrentRaftNodes, err := gateway.currentRaftNodes()\r\n\tif err != nil {\r\n\t\treturn \"\", nil, errors.Wrap(err, \"failed to get current raft nodes\")\r\n\t}\r\n\tif len(currentRaftNodes) >= membershipMaxRaftNodes {\r\n\t\t\r\n\t\treturn \"\", nil, nil\r\n\t}\r\n\tcurrentRaftAddresses := make([]string, len(currentRaftNodes))\r\n\tfor i, node := range currentRaftNodes {\r\n\t\tcurrentRaftAddresses[i] = node.Address\r\n\t}\r\n\t\r\n\taddress := \"\"\r\n\terr = state.Cluster.Transaction(func(tx *db.ClusterTx) error {\r\n\t\tconfig, err := ConfigLoad(tx)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"failed load cluster configuration\")\r\n\t\t}\r\n\t\tnodes, err := tx.Nodes()\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"failed to get cluster nodes\")\r\n\t\t}\r\n\t\t\r\n\t\tfor _, node := range nodes {\r\n\t\t\tif shared.StringInSlice(node.Address, currentRaftAddresses) {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tif node.IsOffline(config.OfflineThreshold()) {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tlogger.Debugf(\r\n\t\t\t\t\"Found spare node %s (%s) to be promoted as database node\", node.Name, node.Address)\r\n\t\t\taddress = node.Address\r\n\t\t\tbreak\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn \"\", nil, err\r\n\t}\r\n\tif address == \"\" {\r\n\t\t\r\n\t\treturn \"\", nil, nil\r\n\t}\r\n\t\r\n\t\r\n\tupdatedRaftNodes := currentRaftNodes\r\n\terr = gateway.db.Transaction(func(tx *db.NodeTx) error {\r\n\t\tid, err := tx.RaftNodeAdd(address)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"failed to add new raft node\")\r\n\t\t}\r\n\t\tupdatedRaftNodes = append(updatedRaftNodes, db.RaftNode{ID: id, Address: address})\r\n\t\terr = tx.RaftNodesReplace(updatedRaftNodes)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"failed to update raft nodes\")\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn \"\", nil, err\r\n\t}\r\n\treturn address, updatedRaftNodes, nil\r\n}","code-length":699,"reference":"\/\/ Rebalance the raft cluster, trying to see if we have a spare online node\n\/\/ that we can promote to database node if we are below membershipMaxRaftNodes.\n\/\/\n\/\/ If there's such spare node, return its address as well as the new list of\n\/\/ raft nodes.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Promote(state *state.State, gateway *Gateway, nodes []db.RaftNode) error {\r\n\tlogger.Info(\"Promote node to database node\")\r\n\t\r\n\tif gateway.IsDatabaseNode() {\r\n\t\treturn fmt.Errorf(\"this node is already a database node\")\r\n\t}\r\n\t\r\n\taddress := \"\"\r\n\terr := state.Cluster.Transaction(func(tx *db.ClusterTx) error {\r\n\t\tvar err error\r\n\t\taddress, err = tx.NodeAddress()\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"failed to fetch the address of this node\")\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif address == \"\" {\r\n\t\treturn fmt.Errorf(\"node is not exposed on the network\")\r\n\t}\r\n\t\r\n\t\r\n\tid := \"\"\r\n\ttarget := \"\"\r\n\tfor _, node := range nodes {\r\n\t\tif node.Address == address {\r\n\t\t\tid = strconv.Itoa(int(node.ID))\r\n\t\t} else {\r\n\t\t\ttarget = node.Address\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\tif id == \"\" {\r\n\t\treturn fmt.Errorf(\"this node is not included in the given list of database nodes\")\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\terr = state.Node.Transaction(func(tx *db.NodeTx) error {\r\n\t\terr = tx.RaftNodesReplace(nodes)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"failed to set raft nodes\")\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t\r\n\terr = state.Cluster.EnterExclusive()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to acquire cluster database lock\")\r\n\t}\r\n\t\r\n\t\r\n\terr = os.RemoveAll(state.OS.GlobalDatabaseDir())\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to remove existing raft data\")\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\terr = gateway.init()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to re-initialize gRPC SQL gateway\")\r\n\t}\r\n\tlogger.Info(\r\n\t\t\"Joining dqlite raft cluster\",\r\n\t\tlog15.Ctx{\"id\": id, \"address\": address, \"target\": target})\r\n\tchanger := gateway.raft.MembershipChanger()\r\n\terr = changer.Join(raft.ServerID(id), raft.ServerAddress(target), 5*time.Second)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t\r\n\terr = state.Cluster.ExitExclusive(func(tx *db.ClusterTx) error {\r\n\t\t_, err := tx.Nodes()\r\n\t\treturn err\r\n\t})\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"cluster database initialization failed\")\r\n\t}\r\n\treturn nil\r\n}","code-length":803,"reference":"\/\/ Promote makes a LXD node which is not a database node, become part of the\n\/\/ raft cluster.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Purge(cluster *db.Cluster, name string) error {\r\n\tlogger.Debugf(\"Remove node %s from the database\", name)\r\n\treturn cluster.Transaction(func(tx *db.ClusterTx) error {\r\n\t\t\r\n\t\tnode, err := tx.NodeByName(name)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"failed to get node %s\", name)\r\n\t\t}\r\n\t\terr = tx.NodeClear(node.ID)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"failed to clear node %s\", name)\r\n\t\t}\r\n\t\terr = tx.NodeRemove(node.ID)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"failed to remove node %s\", name)\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n}","code-length":229,"reference":"\/\/ Purge removes a node entirely from the cluster database.","result":"Remove a node from the database.","score":[0.1951,0.5859]}
{"code":"\/*is used to<extra_id_0>\r\nfunc List(state *state.State) ([]api.ClusterMember, error) {\r\n\taddresses := []string{}\r\n\terr := state.Node.Transaction(func(tx *db.NodeTx) error {\r\n\t\tnodes, err := tx.RaftNodes()\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"failed to fetch current raft nodes\")\r\n\t\t}\r\n\t\tfor _, node := range nodes {\r\n\t\t\taddresses = append(addresses, node.Address)\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar nodes []db.NodeInfo\r\n\tvar offlineThreshold time.Duration\r\n\terr = state.Cluster.Transaction(func(tx *db.ClusterTx) error {\r\n\t\tnodes, err = tx.Nodes()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tofflineThreshold, err = tx.NodeOfflineThreshold()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tresult := make([]api.ClusterMember, len(nodes))\r\n\tnow := time.Now()\r\n\tversion := nodes[0].Version()\r\n\tfor i, node := range nodes {\r\n\t\tresult[i].ServerName = node.Name\r\n\t\tresult[i].URL = fmt.Sprintf(\"https:\r\n\t\tresult[i].Database = shared.StringInSlice(node.Address, addresses)\r\n\t\tif node.IsOffline(offlineThreshold) {\r\n\t\t\tresult[i].Status = \"Offline\"\r\n\t\t\tresult[i].Message = fmt.Sprintf(\r\n\t\t\t\t\"no heartbeat since %s\", now.Sub(node.Heartbeat))\r\n\t\t} else {\r\n\t\t\tresult[i].Status = \"Online\"\r\n\t\t\tresult[i].Message = \"fully operational\"\r\n\t\t}\r\n\t\tn, err := util.CompareVersions(version, node.Version())\r\n\t\tif err != nil {\r\n\t\t\tresult[i].Status = \"Broken\"\r\n\t\t\tresult[i].Message = \"inconsistent version\"\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif n == 1 {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tversion = node.Version()\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\tfor i, node := range nodes {\r\n\t\tif result[i].Status != \"Online\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tn, err := util.CompareVersions(version, node.Version())\r\n\t\tif err != nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif n == 2 {\r\n\t\t\tresult[i].Status = \"Blocked\"\r\n\t\t\tresult[i].Message = \"waiting for other nodes to be upgraded\"\r\n\t\t}\r\n\t}\r\n\treturn result, nil\r\n}","code-length":747,"reference":"\/\/ List the nodes of the cluster.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Count(state *state.State) (int, error) {\r\n\tvar count int\r\n\terr := state.Cluster.Transaction(func(tx *db.ClusterTx) error {\r\n\t\tvar err error\r\n\t\tcount, err = tx.NodesCount()\r\n\t\treturn err\r\n\t})\r\n\treturn count, err\r\n}","code-length":92,"reference":"\/\/ Count is a convenience for checking the current number of nodes in the\n\/\/ cluster.","result":"Count the number of nodes in the cluster.","score":[0.2391,0.4934]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Enabled(node *db.Node) (bool, error) {\r\n\tenabled := false\r\n\terr := node.Transaction(func(tx *db.NodeTx) error {\r\n\t\taddresses, err := tx.RaftNodeAddresses()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tenabled = len(addresses) > 0\r\n\t\treturn nil\r\n\t})\r\n\treturn enabled, err\r\n}","code-length":117,"reference":"\/\/ Enabled is a convenience that returns true if clustering is enabled on this\n\/\/ node.","result":"Check if the node is enabled.","score":[0.0434,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc membershipCheckNodeStateForBootstrapOrJoin(tx *db.NodeTx, address string) error {\r\n\tnodes, err := tx.RaftNodes()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to fetch current raft nodes\")\r\n\t}\r\n\thasClusterAddress := address != \"\"\r\n\thasRaftNodes := len(nodes) > 0\r\n\t\r\n\t\r\n\t\r\n\tif !hasClusterAddress && hasRaftNodes {\r\n\t\treturn fmt.Errorf(\"inconsistent state: found leftover entries in raft_nodes\")\r\n\t}\r\n\tif !hasClusterAddress {\r\n\t\treturn fmt.Errorf(\"no cluster.https_address config is set on this node\")\r\n\t}\r\n\tif hasRaftNodes {\r\n\t\treturn fmt.Errorf(\"the node is already part of a cluster\")\r\n\t}\r\n\treturn nil\r\n}","code-length":221,"reference":"\/\/ Check that node-related preconditions are met for bootstrapping or joining a\n\/\/ cluster.","result":"Check membership of a node for bootstrap or join.","score":[0.0989,0.3304]}
{"code":"\/*is used to<extra_id_0>\r\nfunc membershipCheckClusterStateForBootstrapOrJoin(tx *db.ClusterTx) error {\r\n\tnodes, err := tx.Nodes()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to fetch current cluster nodes\")\r\n\t}\r\n\tif len(nodes) != 1 {\r\n\t\treturn fmt.Errorf(\"inconsistent state: found leftover entries in nodes\")\r\n\t}\r\n\treturn nil\r\n}","code-length":112,"reference":"\/\/ Check that cluster-related preconditions are met for bootstrapping or\n\/\/ joining a cluster.","result":"Check if the cluster is bootstrap or join.","score":[0.078,0.1907]}
{"code":"\/*is used to<extra_id_0>\r\nfunc membershipCheckClusterStateForAccept(tx *db.ClusterTx, name string, address string, schema int, api int) error {\r\n\tnodes, err := tx.Nodes()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to fetch current cluster nodes\")\r\n\t}\r\n\tif len(nodes) == 1 && nodes[0].Address == \"0.0.0.0\" {\r\n\t\treturn fmt.Errorf(\"clustering not enabled\")\r\n\t}\r\n\tfor _, node := range nodes {\r\n\t\tif node.Name == name {\r\n\t\t\treturn fmt.Errorf(\"cluster already has node with name %s\", name)\r\n\t\t}\r\n\t\tif node.Address == address {\r\n\t\t\treturn fmt.Errorf(\"cluster already has node with address %s\", address)\r\n\t\t}\r\n\t\tif node.Schema != schema {\r\n\t\t\treturn fmt.Errorf(\"schema version mismatch: cluster has %d\", node.Schema)\r\n\t\t}\r\n\t\tif node.APIExtensions != api {\r\n\t\t\treturn fmt.Errorf(\"API version mismatch: cluster has %d\", node.APIExtensions)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":298,"reference":"\/\/ Check that cluster-related preconditions are met for accepting a new node.","result":"Check if cluster is in accept state.","score":[0.0791,0.087]}
{"code":"\/*is used to<extra_id_0>\r\nfunc membershipCheckClusterStateForLeave(tx *db.ClusterTx, nodeID int64) error {\r\n\t\r\n\tmessage, err := tx.NodeIsEmpty(nodeID)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif message != \"\" {\r\n\t\treturn fmt.Errorf(message)\r\n\t}\r\n\t\r\n\tnodes, err := tx.Nodes()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif len(nodes) == 1 {\r\n\t\treturn fmt.Errorf(\"node is the only node in the cluster\")\r\n\t}\r\n\treturn nil\r\n}","code-length":163,"reference":"\/\/ Check that cluster-related preconditions are met for leaving a cluster.","result":"Check if the cluster is in the right state.","score":[0.0976,0.0463]}
{"code":"\/*is used to<extra_id_0>\r\nfunc membershipCheckNoLeftoverClusterCert(dir string) error {\r\n\t\r\n\tfor _, basename := range []string{\"cluster.crt\", \"cluster.key\", \"cluster.ca\"} {\r\n\t\tif shared.PathExists(filepath.Join(dir, basename)) {\r\n\t\t\treturn fmt.Errorf(\"inconsistent state: found leftover cluster certificate\")\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":110,"reference":"\/\/ Check that there is no left-over cluster certificate in the LXD var dir of\n\/\/ this node.","result":"Check membership.","score":[0.0002,0.0305]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ConfigLoad(tx *db.NodeTx) (*Config, error) {\r\n\t\r\n\tvalues, err := tx.Config()\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"cannot fetch node config from database: %v\", err)\r\n\t}\r\n\tm, err := config.SafeLoad(ConfigSchema, values)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to load node config: %v\", err)\r\n\t}\r\n\treturn &Config{tx: tx, m: m}, nil\r\n}","code-length":146,"reference":"\/\/ ConfigLoad loads a new Config object with the current node-local configuration\n\/\/ values fetched from the database. An optional list of config value triggers\n\/\/ can be passed, each config key must have at most one trigger.","result":"Load the node config from the database.","score":[0.0045,0.1465]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) Replace(values map[string]interface{}) (map[string]string, error) {\r\n\treturn c.update(values)\r\n}","code-length":48,"reference":"\/\/ Replace the current configuration with the given values.","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) Patch(patch map[string]interface{}) (map[string]string, error) {\r\n\tvalues := c.Dump()\r\n\tfor name, value := range patch {\r\n\t\tvalues[name] = value\r\n\t}\r\n\treturn c.update(values)\r\n}","code-length":82,"reference":"\/\/ Patch changes only the configuration keys in the given map.","result":"Patch the config.","score":[0.0337,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HTTPSAddress(node *db.Node) (string, error) {\r\n\tvar config *Config\r\n\terr := node.Transaction(func(tx *db.NodeTx) error {\r\n\t\tvar err error\r\n\t\tconfig, err = ConfigLoad(tx)\r\n\t\treturn err\r\n\t})\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn config.HTTPSAddress(), nil\r\n}","code-length":114,"reference":"\/\/ HTTPSAddress is a convenience for loading the node configuration and\n\/\/ returning the value of core.https_address.","result":"Retrieve the HTTPS address of the node.","score":[0.0509,0.0938]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) CertificatesGet() (certs []*CertInfo, err error) {\r\n\terr = c.Transaction(func(tx *ClusterTx) error {\r\n\t\trows, err := tx.tx.Query(\r\n\t\t\t\"SELECT id, fingerprint, type, name, certificate FROM certificates\",\r\n\t\t)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdefer rows.Close()\r\n\t\tfor rows.Next() {\r\n\t\t\tcert := new(CertInfo)\r\n\t\t\trows.Scan(\r\n\t\t\t\t&cert.ID,\r\n\t\t\t\t&cert.Fingerprint,\r\n\t\t\t\t&cert.Type,\r\n\t\t\t\t&cert.Name,\r\n\t\t\t\t&cert.Certificate,\r\n\t\t\t)\r\n\t\t\tcerts = append(certs, cert)\r\n\t\t}\r\n\t\treturn rows.Err()\r\n\t})\r\n\tif err != nil {\r\n\t\treturn certs, err\r\n\t}\r\n\treturn certs, nil\r\n}","code-length":252,"reference":"\/\/ CertificatesGet returns all certificates from the DB as CertBaseInfo objects.","result":"Get all certificates in the cluster.","score":[0.1313,0.2434]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) CertificateGet(fingerprint string) (cert *CertInfo, err error) {\r\n\tcert = new(CertInfo)\r\n\tinargs := []interface{}{fingerprint + \"%\"}\r\n\toutfmt := []interface{}{\r\n\t\t&cert.ID,\r\n\t\t&cert.Fingerprint,\r\n\t\t&cert.Type,\r\n\t\t&cert.Name,\r\n\t\t&cert.Certificate,\r\n\t}\r\n\tquery := `\r\n\t\tSELECT\r\n\t\t\tid, fingerprint, type, name, certificate\r\n\t\tFROM\r\n\t\t\tcertificates\r\n\t\tWHERE fingerprint LIKE ?`\r\n\tif err = dbQueryRowScan(c.db, query, inargs, outfmt); err != nil {\r\n\t\tif err == sql.ErrNoRows {\r\n\t\t\treturn nil, ErrNoSuchObject\r\n\t\t}\r\n\t\treturn nil, err\r\n\t}\r\n\treturn cert, err\r\n}","code-length":235,"reference":"\/\/ CertificateGet gets an CertBaseInfo object from the database.\n\/\/ The argument fingerprint will be queried with a LIKE query, means you can\n\/\/ pass a shortform and will get the full fingerprint.\n\/\/ There can never be more than one image with a given fingerprint, as it is\n\/\/ enforced by a UNIQUE constraint in the schema.","result":"Fetch the certificate from the database.","score":[0.0001,0.0705]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) CertSave(cert *CertInfo) error {\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tstmt, err := tx.tx.Prepare(`\r\n\t\t\tINSERT INTO certificates (\r\n\t\t\t\tfingerprint,\r\n\t\t\t\ttype,\r\n\t\t\t\tname,\r\n\t\t\t\tcertificate\r\n\t\t\t) VALUES (?, ?, ?, ?)`,\r\n\t\t)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdefer stmt.Close()\r\n\t\t_, err = stmt.Exec(\r\n\t\t\tcert.Fingerprint,\r\n\t\t\tcert.Type,\r\n\t\t\tcert.Name,\r\n\t\t\tcert.Certificate,\r\n\t\t)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\treturn err\r\n}","code-length":223,"reference":"\/\/ CertSave stores a CertBaseInfo object in the db,\n\/\/ it will ignore the ID field from the CertInfo.","result":"Save the certificate.","score":[0.002,0.0287]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) CertDelete(fingerprint string) error {\r\n\terr := exec(c.db, \"DELETE FROM certificates WHERE fingerprint=?\", fingerprint)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":70,"reference":"\/\/ CertDelete deletes a certificate from the db.","result":"Delete the certificate.","score":[0.0771,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) CertUpdate(fingerprint string, certName string, certType int) error {\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\t_, err := tx.tx.Exec(\"UPDATE certificates SET name=?, type=? WHERE fingerprint=?\", certName, certType, fingerprint)\r\n\t\treturn err\r\n\t})\r\n\treturn err\r\n}","code-length":101,"reference":"\/\/ CertUpdate updates the certificate with the given fingerprint.","result":"Update the certificate in the cluster.","score":[0.1833,0.431]}
{"code":"\/*is used to<extra_id_0>\r\nfunc createDevLxdlListener(dir string) (net.Listener, error) {\r\n\tpath := filepath.Join(dir, \"devlxd\", \"sock\")\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\turn nil, err\r\n\t}\r\n\tlistener, err := socketUnixListen(path)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\terr = socketUnixSetPermissions(path, 0666)\r\n\tif err != nil {\r\n\t\tlistener.Close()\r\n\t\treturn nil, err\r\n\t}\r\n\treturn listener, nil\r\n}","code-length":168,"reference":"\/\/ Create a new net.Listener bound to the unix socket of the devlxd endpoint.","result":"Create a listener for devlxd.","score":[0.0562,0.1431]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *raftInstance) Servers() ([]raft.Server, error) {\r\n\tif i.raft.State() != raft.Leader {\r\n\t\treturn nil, raft.ErrNotLeader\r\n\t}\r\n\tfuture := i.raft.GetConfiguration()\r\n\terr := future.Error()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tconfiguration := future.Configuration()\r\n\treturn configuration.Servers, nil\r\n}","code-length":120,"reference":"\/\/ Servers returns the servers that are currently part of the cluster.\n\/\/\n\/\/ If this raft instance is not the leader, an error is returned.","result":"Get the raft servers.","score":[0.0016,0.042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *raftInstance) Shutdown() error {\r\n\tlogger.Debug(\"Stop raft instance\")\r\n\t\r\n\ttimeout := 10 * time.Second\r\n\terrCh := make(chan error)\r\n\ttimer := time.After(timeout)\r\n\tgo func() {\r\n\t\terrCh <- i.raft.Shutdown().Error()\r\n\t}()\r\n\tselect {\r\n\tcase err := <-errCh:\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"failed to shutdown raft\")\r\n\t\t}\r\n\tcase <-timer:\r\n\t\tlogger.Debug(\"Timeout waiting for raft to shutdown\")\r\n\t\treturn fmt.Errorf(\"raft did not shutdown within %s\", timeout)\r\n\t}\r\n\terr := i.logs.Close()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to close boltdb logs store\")\r\n\t}\r\n\treturn nil\r\n}","code-length":235,"reference":"\/\/ Shutdown raft and any raft-related resource we have instantiated.","result":"Close the logs store.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc raftNetworkTransport(\r\n\tdb *db.Node,\r\n\taddress string,\r\n\tlogger *log.Logger,\r\n\ttimeout time.Duration,\r\n\tdial rafthttp.Dial) (raft.Transport, *rafthttp.Handler, *rafthttp.Layer, error) {\r\n\thandler := rafthttp.NewHandlerWithLogger(logger)\r\n\taddr, err := net.ResolveTCPAddr(\"tcp\", address)\r\n\tif err != nil {\r\n\t\treturn nil, nil, nil, errors.Wrap(err, \"invalid node address\")\r\n\t}\r\n\tlayer := rafthttp.NewLayer(raftEndpoint, addr, handler, dial)\r\n\tconfig := &raft.NetworkTransportConfig{\r\n\t\tLogger:                logger,\r\n\t\tStream:                layer,\r\n\t\tMaxPool:               2,\r\n\t\tTimeout:               timeout,\r\n\t\tServerAddressProvider: &raftAddressProvider{db: db},\r\n\t}\r\n\ttransport := raft.NewNetworkTransportWithConfig(config)\r\n\treturn transport, handler, layer, nil\r\n}","code-length":265,"reference":"\/\/ Create a network raft transport that will handle connections using a\n\/\/ rafthttp.Handler.","result":"Create a new raft network transport.","score":[0.0856,0.1515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc raftConfig(latency float64) *raft.Config {\r\n\tconfig := raft.DefaultConfig()\r\n\tscale := func(duration *time.Duration) {\r\n\t\t*duration = time.Duration((math.Ceil(float64(*duration) * latency)))\r\n\t}\r\n\tdurations := []*time.Duration{\r\n\t\t&config.HeartbeatTimeout,\r\n\t\t&config.ElectionTimeout,\r\n\t\t&config.CommitTimeout,\r\n\t\t&config.LeaderLeaseTimeout,\r\n\t}\r\n\tfor _, duration := range durations {\r\n\t\tscale(duration)\r\n\t}\r\n\tconfig.SnapshotThreshold = 1024\r\n\tconfig.TrailingLogs = 512\r\n\treturn config\r\n}","code-length":182,"reference":"\/\/ Create a base raft configuration tweaked for a network with the given latency measure.","result":"Generate the raft config.","score":[0.0243,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc raftMaybeBootstrap(\r\n\tconf *raft.Config,\r\n\tlogs *raftboltdb.BoltStore,\r\n\tsnaps raft.SnapshotStore,\r\n\ttrans raft.Transport) error {\r\n\t\r\n\thasExistingState, err := raft.HasExistingState(logs, logs, snaps)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to check if raft has existing state\")\r\n\t}\r\n\tif hasExistingState {\r\n\t\treturn nil\r\n\t}\r\n\tserver := raft.Server{\r\n\t\tID:      conf.LocalID,\r\n\t\tAddress: trans.LocalAddr(),\r\n\t}\r\n\tconfiguration := raft.Configuration{\r\n\t\tServers: []raft.Server{server},\r\n\t}\r\n\treturn raft.BootstrapCluster(conf, logs, logs, snaps, trans, configuration)\r\n}","code-length":220,"reference":"\/\/ Helper to bootstrap the raft cluster if needed.","result":"Ensure raft has existing state.","score":[0.108,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CPUResource() (*api.ResourcesCPU, error) {\r\n\tc := api.ResourcesCPU{}\r\n\tthreads, err := getThreads()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar cur *api.ResourcesCPUSocket\r\n\tc.Total = uint64(len(threads))\r\n\tfor _, v := range threads {\r\n\t\tif uint64(len(c.Sockets)) <= v.socketID {\r\n\t\t\tc.Sockets = append(c.Sockets, api.ResourcesCPUSocket{})\r\n\t\t\tcur = &c.Sockets[v.socketID]\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tsocketCores := map[uint64]bool{}\r\n\t\t\tfor _, thread := range threads {\r\n\t\t\t\tif thread.socketID != v.socketID {\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\tsocketCores[thread.coreID] = true\r\n\t\t\t}\r\n\t\t\tcur.Cores = uint64(len(socketCores))\r\n\t\t} else {\r\n\t\t\tcur = &c.Sockets[v.socketID]\r\n\t\t}\r\n\t\tcur.Socket = v.socketID\r\n\t\tcur.NUMANode = v.numaNode\r\n\t\tcur.Threads++\r\n\t\tcur.Name = v.name\r\n\t\tcur.Vendor = v.vendor\r\n\t\tcur.Frequency = v.frequency\r\n\t\tcur.FrequencyTurbo = v.frequencyTurbo\r\n\t}\r\n\treturn &c, nil\r\n}","code-length":383,"reference":"\/\/ CPUResource returns the system CPU information","result":"Get the CPU resource .","score":[0.1915,0.1471]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MemoryResource() (*api.ResourcesMemory, error) {\r\n\tvar buffers uint64\r\n\tvar cached uint64\r\n\tvar free uint64\r\n\tvar total uint64\r\n\tf, err := os.Open(\"\/proc\/meminfo\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer f.Close()\r\n\tcleanLine := func(l string) (string, error) {\r\n\t\tl = strings.TrimSpace(l)\r\n\t\tidx := strings.LastIndex(l, \"kB\")\r\n\t\tif idx < 0 {\r\n\t\t\treturn \"\", fmt.Errorf(`Failed to detect \"kB\" suffix`)\r\n\t\t}\r\n\t\treturn strings.TrimSpace(l[:idx]), nil\r\n\t}\r\n\tmem := api.ResourcesMemory{}\r\n\tscanner := bufio.NewScanner(f)\r\n\tfound := 0\r\n\tfor scanner.Scan() {\r\n\t\tvar err error\r\n\t\tline := scanner.Text()\r\n\t\tif strings.HasPrefix(line, \"MemTotal:\") {\r\n\t\t\tline, err = cleanLine(line[len(\"MemTotal:\"):])\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\ttotal, err = strconv.ParseUint(line, 10, 64)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\tfound++\r\n\t\t} else if strings.HasPrefix(line, \"MemFree:\") {\r\n\t\t\tline, err = cleanLine(line[len(\"MemFree:\"):])\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\tfree, err = strconv.ParseUint(line, 10, 64)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\tfound++\r\n\t\t} else if strings.HasPrefix(line, \"Cached:\") {\r\n\t\t\tline, err = cleanLine(line[len(\"Cached:\"):])\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\tcached, err = strconv.ParseUint(line, 10, 64)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\tfound++\r\n\t\t} else if strings.HasPrefix(line, \"Buffers:\") {\r\n\t\t\tline, err = cleanLine(line[len(\"Buffers:\"):])\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\tbuffers, err = strconv.ParseUint(line, 10, 64)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\tfound++\r\n\t\t}\r\n\t\tif found == 4 {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tmem.Total = total * 1024\r\n\tmem.Used = (total - free - cached - buffers) * 1024\r\n\treturn &mem, err\r\n}","code-length":748,"reference":"\/\/ MemoryResource returns the system memory information","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetOperationUUIDs() ([]string, error) {\r\n\turls := []string{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", \"\/operations\", nil, \"\", &urls)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tuuids := []string{}\r\n\tfor _, url := range urls {\r\n\t\tfields := strings.Split(url, \"\/operations\/\")\r\n\t\tuuids = append(uuids, fields[len(fields)-1])\r\n\t}\r\n\treturn uuids, nil\r\n}","code-length":156,"reference":"\/\/ GetOperationUUIDs returns a list of operation uuids","result":"Get the list of operation UUIDs.","score":[0.2849,0.3775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetOperations() ([]api.Operation, error) {\r\n\tapiOperations := map[string][]api.Operation{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", \"\/operations?recursion=1\", nil, \"\", &apiOperations)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\toperations := []api.Operation{}\r\n\tfor _, v := range apiOperations {\r\n\t\tfor _, operation := range v {\r\n\t\t\toperations = append(operations, operation)\r\n\t\t}\r\n\t}\r\n\treturn operations, nil\r\n}","code-length":163,"reference":"\/\/ GetOperations returns a list of Operation struct","result":"Get the list of operations in the LXD.","score":[0.1964,0.3681]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetOperation(uuid string) (*api.Operation, string, error) {\r\n\top := api.Operation{}\r\n\t\r\n\tetag, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/operations\/%s\", url.QueryEscape(uuid)), nil, \"\", &op)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\treturn &op, etag, nil\r\n}","code-length":118,"reference":"\/\/ GetOperation returns an Operation entry for the provided uuid","result":"Get the operation from the server.","score":[0.0991,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetOperationWebsocket(uuid string, secret string) (*websocket.Conn, error) {\r\n\tpath := fmt.Sprintf(\"\/operations\/%s\/websocket\", url.QueryEscape(uuid))\r\n\tif secret != \"\" {\r\n\t\tpath = fmt.Sprintf(\"%s?secret=%s\", path, url.QueryEscape(secret))\r\n\t}\r\n\treturn r.websocket(path)\r\n}","code-length":111,"reference":"\/\/ GetOperationWebsocket returns a websocket connection for the provided operation","result":"Get the websocket connection for the operation.","score":[0.3293,0.4091]}
{"code":"\/*is used to<extra_id_0>\r\nfunc tryMount(src string, dst string, fs string, flags uintptr, options string) error {\r\n\tvar err error\r\n\tfor i := 0; i < 20; i++ {\r\n\t\terr = syscall.Mount(src, dst, fs, flags, options)\r\n\t\tif err == nil {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\ttime.Sleep(500 * time.Millisecond)\r\n\t}\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":136,"reference":"\/\/ Useful functions for unreliable backends","result":"Detect if a mount is attempted.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc lxdUsesPool(dbObj *db.Cluster, onDiskPoolName string, driver string, onDiskProperty string) (bool, string, error) {\r\n\tpools, err := dbObj.StoragePools()\r\n\tif err != nil && err != db.ErrNoSuchObject {\r\n\t\treturn false, \"\", err\r\n\t}\r\n\tfor _, pool := range pools {\r\n\t\t_, pl, err := dbObj.StoragePoolGet(pool)\r\n\t\tif err != nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif pl.Driver != driver {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif pl.Config[onDiskProperty] == onDiskPoolName {\r\n\t\t\treturn true, pl.Name, nil\r\n\t\t}\r\n\t}\r\n\treturn false, \"\", nil\r\n}","code-length":207,"reference":"\/\/ Detect whether LXD already uses the given storage pool.","result":"Test if the file is not empty.","score":[0.1052,0.0515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ProjectURIs(filter ProjectFilter) ([]string, error) {\r\n\t\r\n\tcriteria := map[string]interface{}{}\r\n\tif filter.Name != \"\" {\r\n\t\tcriteria[\"Name\"] = filter.Name\r\n\t}\r\n\t\r\n\tvar stmt *sql.Stmt\r\n\tvar args []interface{}\r\n\tif criteria[\"Name\"] != nil {\r\n\t\tstmt = c.stmt(projectNamesByName)\r\n\t\targs = []interface{}{\r\n\t\t\tfilter.Name,\r\n\t\t}\r\n\t} else {\r\n\t\tstmt = c.stmt(projectNames)\r\n\t\targs = []interface{}{}\r\n\t}\r\n\tcode := cluster.EntityTypes[\"project\"]\r\n\tformatter := cluster.EntityFormatURIs[code]\r\n\treturn query.SelectURIs(stmt, formatter, args...)\r\n}","code-length":218,"reference":"\/\/ ProjectURIs returns all available project URIs.","result":"Generate the project URI.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ProjectList(filter ProjectFilter) ([]api.Project, error) {\r\n\t\r\n\tobjects := make([]api.Project, 0)\r\n\t\r\n\tcriteria := map[string]interface{}{}\r\n\tif filter.Name != \"\" {\r\n\t\tcriteria[\"Name\"] = filter.Name\r\n\t}\r\n\t\r\n\tvar stmt *sql.Stmt\r\n\tvar args []interface{}\r\n\tif criteria[\"Name\"] != nil {\r\n\t\tstmt = c.stmt(projectObjectsByName)\r\n\t\targs = []interface{}{\r\n\t\t\tfilter.Name,\r\n\t\t}\r\n\t} else {\r\n\t\tstmt = c.stmt(projectObjects)\r\n\t\targs = []interface{}{}\r\n\t}\r\n\t\r\n\tdest := func(i int) []interface{} {\r\n\t\tobjects = append(objects, api.Project{})\r\n\t\treturn []interface{}{\r\n\t\t\t&objects[i].Description,\r\n\t\t\t&objects[i].Name,\r\n\t\t}\r\n\t}\r\n\t\r\n\terr := query.SelectObjects(stmt, dest, args...)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Failed to fetch projects\")\r\n\t}\r\n\t\r\n\tconfigObjects, err := c.ProjectConfigRef(filter)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Failed to fetch field Config\")\r\n\t}\r\n\tfor i := range objects {\r\n\t\tvalue := configObjects[objects[i].Name]\r\n\t\tif value == nil {\r\n\t\t\tvalue = map[string]string{}\r\n\t\t}\r\n\t\tobjects[i].Config = value\r\n\t}\r\n\t\r\n\tusedByObjects, err := c.ProjectUsedByRef(filter)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Failed to fetch field UsedBy\")\r\n\t}\r\n\tfor i := range objects {\r\n\t\tvalue := usedByObjects[objects[i].Name]\r\n\t\tif value == nil {\r\n\t\t\tvalue = []string{}\r\n\t\t}\r\n\t\tobjects[i].UsedBy = value\r\n\t}\r\n\treturn objects, nil\r\n}","code-length":557,"reference":"\/\/ ProjectList returns all available projects.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ProjectGet(name string) (*api.Project, error) {\r\n\tfilter := ProjectFilter{}\r\n\tfilter.Name = name\r\n\tobjects, err := c.ProjectList(filter)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Failed to fetch Project\")\r\n\t}\r\n\tswitch len(objects) {\r\n\tcase 0:\r\n\t\treturn nil, ErrNoSuchObject\r\n\tcase 1:\r\n\t\treturn &objects[0], nil\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"More than one project matches\")\r\n\t}\r\n}","code-length":163,"reference":"\/\/ ProjectGet returns the project with the given key.","result":"Generate code for the generated code.","score":[0.1171,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ProjectExists(name string) (bool, error) {\r\n\t_, err := c.ProjectID(name)\r\n\tif err != nil {\r\n\t\tif err == ErrNoSuchObject {\r\n\t\t\treturn false, nil\r\n\t\t}\r\n\t\treturn false, err\r\n\t}\r\n\treturn true, nil\r\n}","code-length":96,"reference":"\/\/ ProjectExists checks if a project with the given key exists.","result":"Test if the project exists.","score":[0.1023,0.1923]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ProjectCreate(object api.ProjectsPost) (int64, error) {\r\n\t\r\n\texists, err := c.ProjectExists(object.Name)\r\n\tif err != nil {\r\n\t\treturn -1, errors.Wrap(err, \"Failed to check for duplicates\")\r\n\t}\r\n\tif exists {\r\n\t\treturn -1, fmt.Errorf(\"This project already exists\")\r\n\t}\r\n\targs := make([]interface{}, 2)\r\n\t\r\n\targs[0] = object.Description\r\n\targs[1] = object.Name\r\n\t\r\n\tstmt := c.stmt(projectCreate)\r\n\t\r\n\tresult, err := stmt.Exec(args...)\r\n\tif err != nil {\r\n\t\treturn -1, errors.Wrap(err, \"Failed to create project\")\r\n\t}\r\n\tid, err := result.LastInsertId()\r\n\tif err != nil {\r\n\t\treturn -1, errors.Wrap(err, \"Failed to fetch project ID\")\r\n\t}\r\n\t\r\n\tstmt = c.stmt(projectCreateConfigRef)\r\n\tfor key, value := range object.Config {\r\n\t\t_, err := stmt.Exec(id, key, value)\r\n\t\tif err != nil {\r\n\t\t\treturn -1, errors.Wrap(err, \"Insert config for project\")\r\n\t\t}\r\n\t}\r\n\treturn id, nil\r\n}","code-length":353,"reference":"\/\/ ProjectCreate adds a new project to the database.","result":"Create a project in the cluster.","score":[0.1541,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ProjectUsedByRef(filter ProjectFilter) (map[string][]string, error) {\r\n\t\r\n\tobjects := make([]struct {\r\n\t\tName  string\r\n\t\tValue string\r\n\t}, 0)\r\n\t\r\n\tcriteria := map[string]interface{}{}\r\n\tif filter.Name != \"\" {\r\n\t\tcriteria[\"Name\"] = filter.Name\r\n\t}\r\n\t\r\n\tvar stmt *sql.Stmt\r\n\tvar args []interface{}\r\n\tif criteria[\"Name\"] != nil {\r\n\t\tstmt = c.stmt(projectUsedByRefByName)\r\n\t\targs = []interface{}{\r\n\t\t\tfilter.Name,\r\n\t\t}\r\n\t} else {\r\n\t\tstmt = c.stmt(projectUsedByRef)\r\n\t\targs = []interface{}{}\r\n\t}\r\n\t\r\n\tdest := func(i int) []interface{} {\r\n\t\tobjects = append(objects, struct {\r\n\t\t\tName  string\r\n\t\t\tValue string\r\n\t\t}{})\r\n\t\treturn []interface{}{\r\n\t\t\t&objects[i].Name,\r\n\t\t\t&objects[i].Value,\r\n\t\t}\r\n\t}\r\n\t\r\n\terr := query.SelectObjects(stmt, dest, args...)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Failed to fetch string ref for projects\")\r\n\t}\r\n\t\r\n\tindex := map[string][]string{}\r\n\tfor _, object := range objects {\r\n\t\titem, ok := index[object.Name]\r\n\t\tif !ok {\r\n\t\t\titem = []string{}\r\n\t\t}\r\n\t\tindex[object.Name] = append(item, object.Value)\r\n\t}\r\n\treturn index, nil\r\n}","code-length":451,"reference":"\/\/ ProjectUsedByRef returns entities used by projects.","result":"Fetch project references.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ProjectRename(name string, to string) error {\r\n\tstmt := c.stmt(projectRename)\r\n\tresult, err := stmt.Exec(to, name)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Rename project\")\r\n\t}\r\n\tn, err := result.RowsAffected()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Fetch affected rows\")\r\n\t}\r\n\tif n != 1 {\r\n\t\treturn fmt.Errorf(\"Query affected %d rows instead of 1\", n)\r\n\t}\r\n\treturn nil\r\n}","code-length":161,"reference":"\/\/ ProjectRename renames the project matching the given key parameters.","result":"Rename a project.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ProjectDelete(name string) error {\r\n\tstmt := c.stmt(projectDelete)\r\n\tresult, err := stmt.Exec(name)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Delete project\")\r\n\t}\r\n\tn, err := result.RowsAffected()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Fetch affected rows\")\r\n\t}\r\n\tif n != 1 {\r\n\t\treturn fmt.Errorf(\"Query deleted %d rows instead of 1\", n)\r\n\t}\r\n\treturn nil\r\n}","code-length":156,"reference":"\/\/ ProjectDelete deletes the project matching the given key parameters.","result":"Delete project.","score":[0,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PasswordCheck(secret string, password string) error {\r\n\t\r\n\tif secret == \"\" {\r\n\t\treturn fmt.Errorf(\"No password is set\")\r\n\t}\r\n\t\r\n\tbuff, err := hex.DecodeString(secret)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tsalt := buff[0:32]\r\n\thash, err := scrypt.Key([]byte(password), salt, 1<<14, 8, 1, 64)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif !bytes.Equal(hash, buff[32:]) {\r\n\t\treturn fmt.Errorf(\"Bad password provided\")\r\n\t}\r\n\treturn nil\r\n}","code-length":185,"reference":"\/\/ PasswordCheck validates the provided password against the encoded secret","result":"Check the password.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadCert(dir string) (*shared.CertInfo, error) {\r\n\tprefix := \"server\"\r\n\tif shared.PathExists(filepath.Join(dir, \"cluster.crt\")) {\r\n\t\tprefix = \"cluster\"\r\n\t}\r\n\tcert, err := shared.KeyPairAndCA(dir, prefix, shared.CertServer)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"failed to load TLS certificate\")\r\n\t}\r\n\treturn cert, nil\r\n}","code-length":134,"reference":"\/\/ LoadCert reads the LXD server certificate from the given var dir.\n\/\/\n\/\/ If a cluster certificate is found it will be loaded instead.","result":"Load the TLS certificate.","score":[0.0017,0.0437]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WriteCert(dir, prefix string, cert, key, ca []byte) error {\r\n\terr := ioutil.WriteFile(filepath.Join(dir, prefix+\".crt\"), cert, 0644)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = ioutil.WriteFile(filepath.Join(dir, prefix+\".key\"), key, 0600)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif ca != nil {\r\n\t\terr = ioutil.WriteFile(filepath.Join(dir, prefix+\".ca\"), ca, 0644)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":185,"reference":"\/\/ WriteCert writes the given material to the appropriate certificate files in\n\/\/ the given LXD var directory.","result":"Write the certificate to a file.","score":[0.0344,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDaemon(config *DaemonConfig, os *sys.OS) *Daemon {\r\n\treturn &Daemon{\r\n\t\tconfig:       config,\r\n\t\tos:           os,\r\n\t\tsetupChan:    make(chan struct{}),\r\n\t\treadyChan:    make(chan struct{}),\r\n\t\tshutdownChan: make(chan struct{}),\r\n\t}\r\n}","code-length":100,"reference":"\/\/ NewDaemon returns a new Daemon object with the given configuration.","result":"Create a new daemon.","score":[0.0785,0.182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DefaultDaemon() *Daemon {\r\n\tconfig := DefaultDaemonConfig()\r\n\tos := sys.DefaultOS()\r\n\treturn NewDaemon(config, os)\r\n}","code-length":49,"reference":"\/\/ DefaultDaemon returns a new, un-initialized Daemon object with default values.","result":"Create a default daemon.","score":[0.066,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AllowProjectPermission(feature string, permission string) func(d *Daemon, r *http.Request) Response {\r\n\treturn func(d *Daemon, r *http.Request) Response {\r\n\t\t\r\n\t\tif d.userIsAdmin(r) {\r\n\t\t\treturn EmptySyncResponse\r\n\t\t}\r\n\t\t\r\n\t\tproject := projectParam(r)\r\n\t\t\r\n\t\tif !d.userHasPermission(r, project, permission) {\r\n\t\t\treturn Forbidden(nil)\r\n\t\t}\r\n\t\treturn EmptySyncResponse\r\n\t}\r\n}","code-length":147,"reference":"\/\/ AllowProjectPermission is a wrapper to check access against the project, its features and RBAC permission","result":"Allow project permissions.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *Daemon) checkTrustedClient(r *http.Request) error {\r\n\ttrusted, _, _, err := d.Authenticate(r)\r\n\tif !trusted || err != nil {\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn fmt.Errorf(\"Not authorized\")\r\n\t}\r\n\treturn nil\r\n}","code-length":99,"reference":"\/\/ Convenience function around Authenticate","result":"Check if the client is trusted.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *Daemon) Authenticate(r *http.Request) (bool, string, string, error) {\r\n\t\r\n\tif r.TLS != nil {\r\n\t\tcert, _ := x509.ParseCertificate(d.endpoints.NetworkCert().KeyPair().Certificate[0])\r\n\t\tclusterCerts := map[string]x509.Certificate{\"0\": *cert}\r\n\t\tfor i := range r.TLS.PeerCertificates {\r\n\t\t\ttrusted, _ := util.CheckTrustState(*r.TLS.PeerCertificates[i], clusterCerts)\r\n\t\t\tif trusted {\r\n\t\t\t\treturn true, \"\", \"cluster\", nil\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\tif r.RemoteAddr == \"@\" {\r\n\t\treturn true, \"\", \"unix\", nil\r\n\t}\r\n\t\r\n\tif r.RemoteAddr == \"@devlxd\" {\r\n\t\treturn false, \"\", \"\", fmt.Errorf(\"Main API query can't come from \/dev\/lxd socket\")\r\n\t}\r\n\t\r\n\tif isClusterNotification(r) {\r\n\t\treturn false, \"\", \"\", fmt.Errorf(\"Cluster notification isn't using cluster certificate\")\r\n\t}\r\n\t\r\n\tif r.TLS == nil {\r\n\t\treturn false, \"\", \"\", fmt.Errorf(\"Bad\/missing TLS on network query\")\r\n\t}\r\n\tif d.externalAuth != nil && r.Header.Get(httpbakery.BakeryProtocolHeader) != \"\" {\r\n\t\t\r\n\t\tctx := httpbakery.ContextWithRequest(context.TODO(), r)\r\n\t\tauthChecker := d.externalAuth.bakery.Checker.Auth(httpbakery.RequestMacaroons(r)...)\r\n\t\tops := []bakery.Op{{\r\n\t\t\tEntity: r.URL.Path,\r\n\t\t\tAction: r.Method,\r\n\t\t}}\r\n\t\tinfo, err := authChecker.Allow(ctx, ops...)\r\n\t\tif err != nil {\r\n\t\t\t\r\n\t\t\treturn false, \"\", \"\", err\r\n\t\t}\r\n\t\tif info != nil && info.Identity != nil {\r\n\t\t\t\r\n\t\t\treturn true, info.Identity.Id(), \"candid\", nil\r\n\t\t}\r\n\t\t\r\n\t\treturn true, \"\", \"candid\", nil\r\n\t}\r\n\t\r\n\tfor i := range r.TLS.PeerCertificates {\r\n\t\ttrusted, username := util.CheckTrustState(*r.TLS.PeerCertificates[i], d.clientCerts)\r\n\t\tif trusted {\r\n\t\t\treturn true, username, \"tls\", nil\r\n\t\t}\r\n\t}\r\n\t\r\n\treturn false, \"\", \"\", nil\r\n}","code-length":641,"reference":"\/\/ Authenticate validates an incoming http Request\n\/\/ It will check over what protocol it came, what type of request it is and\n\/\/ will validate the TLS certificate or Macaroon.\n\/\/\n\/\/ This does not perform authorization, only validates authentication","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *Daemon) State() *state.State {\r\n\treturn state.NewState(d.db, d.cluster, d.maas, d.os, d.endpoints)\r\n}","code-length":55,"reference":"\/\/ State creates a new State instance linked to our internal db and os.","result":"Create the state.","score":[0,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *Daemon) UnixSocket() string {\r\n\tpath := os.Getenv(\"LXD_SOCKET\")\r\n\tif path != \"\" {\r\n\t\treturn path\r\n\t}\r\n\treturn filepath.Join(d.os.VarDir, \"unix.socket\")\r\n}","code-length":76,"reference":"\/\/ UnixSocket returns the full path to the unix.socket file that this daemon is\n\/\/ listening on. Used by tests.","result":"Get the UnixSocket path.","score":[0.007,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *Daemon) Stop() error {\r\n\tlogger.Info(\"Starting shutdown sequence\")\r\n\terrs := []error{}\r\n\ttrackError := func(err error) {\r\n\t\tif err != nil {\r\n\t\t\terrs = append(errs, err)\r\n\t\t}\r\n\t}\r\n\tif d.endpoints != nil {\r\n\t\ttrackError(d.endpoints.Down())\r\n\t}\r\n\ttrackError(d.tasks.Stop(3 * time.Second))\r\n\ttrackError(d.clusterTasks.Stop(3 * time.Second))\r\n\tshouldUnmount := false\r\n\tif d.cluster != nil {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tch := make(chan bool)\r\n\t\tgo func() {\r\n\t\t\tn, err := d.numRunningContainers()\r\n\t\t\tch <- err != nil || n == 0\r\n\t\t}()\r\n\t\tselect {\r\n\t\tcase shouldUnmount = <-ch:\r\n\t\tcase <-time.After(2 * time.Second):\r\n\t\t\tshouldUnmount = true\r\n\t\t}\r\n\t\tlogger.Infof(\"Closing the database\")\r\n\t\terr := d.cluster.Close()\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif errors.Cause(err) == driver.ErrBadConn {\r\n\t\t\tlogger.Debugf(\"Could not close remote database cleanly: %v\", err)\r\n\t\t} else {\r\n\t\t\ttrackError(err)\r\n\t\t}\r\n\t}\r\n\tif d.db != nil {\r\n\t\ttrackError(d.db.Close())\r\n\t}\r\n\tif d.gateway != nil {\r\n\t\ttrackError(d.gateway.Shutdown())\r\n\t}\r\n\tif d.endpoints != nil {\r\n\t\ttrackError(d.endpoints.Down())\r\n\t}\r\n\tif d.endpoints != nil {\r\n\t\ttrackError(d.endpoints.Down())\r\n\t}\r\n\tif shouldUnmount {\r\n\t\tlogger.Infof(\"Unmounting temporary filesystems\")\r\n\t\tsyscall.Unmount(shared.VarPath(\"devlxd\"), syscall.MNT_DETACH)\r\n\t\tsyscall.Unmount(shared.VarPath(\"shmounts\"), syscall.MNT_DETACH)\r\n\t\tlogger.Infof(\"Done unmounting temporary filesystems\")\r\n\t} else {\r\n\t\tlogger.Debugf(\r\n\t\t\t\"Not unmounting temporary filesystems (containers are still running)\")\r\n\t}\r\n\tvar err error\r\n\tif n := len(errs); n > 0 {\r\n\t\tformat := \"%v\"\r\n\t\tif n > 1 {\r\n\t\t\tformat += fmt.Sprintf(\" (and %d more errors)\", n)\r\n\t\t}\r\n\t\terr = fmt.Errorf(format, errs[0])\r\n\t}\r\n\tif err != nil {\r\n\t\tlogger.Errorf(\"Failed to cleanly shutdown daemon: %v\", err)\r\n\t}\r\n\treturn err\r\n}","code-length":745,"reference":"\/\/ Stop stops the shared daemon.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *Daemon) setupExternalAuthentication(authEndpoint string, authPubkey string, expiry int64, domains string) error {\r\n\t\r\n\tauthDomains := []string{}\r\n\tfor _, domain := range strings.Split(domains, \",\") {\r\n\t\tif domain == \"\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tauthDomains = append(authDomains, strings.TrimSpace(domain))\r\n\t}\r\n\t\r\n\tif authEndpoint == \"\" {\r\n\t\td.externalAuth = nil\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\tidmClient, err := candidclient.New(candidclient.NewParams{\r\n\t\tBaseURL: authEndpoint,\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tidmClientWrapper := &IdentityClientWrapper{\r\n\t\tclient:       idmClient,\r\n\t\tValidDomains: authDomains,\r\n\t}\r\n\t\r\n\tkey, err := bakery.GenerateKey()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tpkCache := bakery.NewThirdPartyStore()\r\n\tpkLocator := httpbakery.NewThirdPartyLocator(nil, pkCache)\r\n\tif authPubkey != \"\" {\r\n\t\t\r\n\t\tpkKey := bakery.Key{}\r\n\t\terr := pkKey.UnmarshalText([]byte(authPubkey))\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\tpkCache.AddInfo(authEndpoint, bakery.ThirdPartyInfo{\r\n\t\t\tPublicKey: bakery.PublicKey{Key: pkKey},\r\n\t\t\tVersion:   3,\r\n\t\t})\r\n\t\t\r\n\t\tif strings.HasPrefix(authEndpoint, \"http:\r\n\t\t\tpkLocator.AllowInsecure()\r\n\t\t}\r\n\t}\r\n\t\r\n\tbakery := identchecker.NewBakery(identchecker.BakeryParams{\r\n\t\tKey:            key,\r\n\t\tLocation:       authEndpoint,\r\n\t\tLocator:        pkLocator,\r\n\t\tChecker:        httpbakery.NewChecker(),\r\n\t\tIdentityClient: idmClientWrapper,\r\n\t\tAuthorizer: identchecker.ACLAuthorizer{\r\n\t\t\tGetACL: func(ctx context.Context, op bakery.Op) ([]string, bool, error) {\r\n\t\t\t\treturn []string{identchecker.Everyone}, false, nil\r\n\t\t\t},\r\n\t\t},\r\n\t})\r\n\t\r\n\td.externalAuth = &externalAuth{\r\n\t\tendpoint: authEndpoint,\r\n\t\texpiry:   expiry,\r\n\t\tbakery:   bakery,\r\n\t}\r\n\treturn nil\r\n}","code-length":670,"reference":"\/\/ Setup external authentication","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc initializeDbObject(d *Daemon) (*db.Dump, error) {\r\n\tlogger.Info(\"Initializing local database\")\r\n\t\r\n\tif shared.PathExists(d.os.LegacyLocalDatabasePath()) {\r\n\t\tif shared.PathExists(d.os.LocalDatabasePath()) {\r\n\t\t\treturn nil, fmt.Errorf(\"Both legacy and new local database files exists\")\r\n\t\t}\r\n\t\tlogger.Info(\"Renaming local database file from lxd.db to database\/local.db\")\r\n\t\terr := os.Rename(d.os.LegacyLocalDatabasePath(), d.os.LocalDatabasePath())\r\n\t\tif err != nil {\r\n\t\t\treturn nil, errors.Wrap(err, \"Failed to rename legacy local database file\")\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tlegacy := map[int]*db.LegacyPatch{}\r\n\tfor i, patch := range legacyPatches {\r\n\t\tlegacy[i] = &db.LegacyPatch{\r\n\t\t\tHook: func(node *sql.DB) error {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tcluster := d.cluster\r\n\t\t\t\tdefer func() {\r\n\t\t\t\t\td.cluster = cluster\r\n\t\t\t\t}()\r\n\t\t\t\td.db = db.ForLegacyPatches(node)\r\n\t\t\t\td.cluster = db.ForLocalInspection(node)\r\n\t\t\t\treturn patch(d)\r\n\t\t\t},\r\n\t\t}\r\n\t}\r\n\tfor _, i := range legacyPatchesNeedingDB {\r\n\t\tlegacy[i].NeedsDB = true\r\n\t}\r\n\t\r\n\t\r\n\tfreshHook := func(db *db.Node) error {\r\n\t\tfor _, patchName := range patchesGetNames() {\r\n\t\t\terr := db.PatchesMarkApplied(patchName)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\tvar err error\r\n\tvar dump *db.Dump\r\n\td.db, dump, err = db.OpenNode(filepath.Join(d.os.VarDir, \"database\"), freshHook, legacy)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"Error creating database: %s\", err)\r\n\t}\r\n\treturn dump, nil\r\n}","code-length":577,"reference":"\/\/ Create a database connection and perform any updates needed.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WriteJSON(w http.ResponseWriter, body interface{}, debug bool) error {\r\n\tvar output io.Writer\r\n\tvar captured *bytes.Buffer\r\n\toutput = w\r\n\tif debug {\r\n\t\tcaptured = &bytes.Buffer{}\r\n\t\toutput = io.MultiWriter(w, captured)\r\n\t}\r\n\terr := json.NewEncoder(output).Encode(body)\r\n\tif captured != nil {\r\n\t\tshared.DebugJson(captured)\r\n\t}\r\n\treturn err\r\n}","code-length":138,"reference":"\/\/ WriteJSON encodes the body as JSON and sends it back to the client","result":"Write a JSON body.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EtagHash(data interface{}) (string, error) {\r\n\tetag := sha256.New()\r\n\terr := json.NewEncoder(etag).Encode(data)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn fmt.Sprintf(\"%x\", etag.Sum(nil)), nil\r\n}","code-length":91,"reference":"\/\/ EtagHash hashes the provided data and returns the sha256","result":"Generate the Etag hash.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EtagCheck(r *http.Request, data interface{}) error {\r\n\tmatch := r.Header.Get(\"If-Match\")\r\n\tif match == \"\" {\r\n\t\treturn nil\r\n\t}\r\n\thash, err := EtagHash(data)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif hash != match {\r\n\t\treturn fmt.Errorf(\"ETag doesn't match: %s vs %s\", hash, match)\r\n\t}\r\n\treturn nil\r\n}","code-length":134,"reference":"\/\/ EtagCheck validates the hash of the current state with the hash\n\/\/ provided by the client","result":"Check the ETag.","score":[0.0038,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HTTPClient(certificate string, proxy proxyFunc) (*http.Client, error) {\r\n\tvar err error\r\n\tvar cert *x509.Certificate\r\n\tif certificate != \"\" {\r\n\t\tcertBlock, _ := pem.Decode([]byte(certificate))\r\n\t\tif certBlock == nil {\r\n\t\t\treturn nil, fmt.Errorf(\"Invalid certificate\")\r\n\t\t}\r\n\t\tcert, err = x509.ParseCertificate(certBlock.Bytes)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\ttlsConfig, err := shared.GetTLSConfig(\"\", \"\", \"\", cert)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\ttr := &http.Transport{\r\n\t\tTLSClientConfig:   tlsConfig,\r\n\t\tDial:              shared.RFC3493Dialer,\r\n\t\tProxy:             proxy,\r\n\t\tDisableKeepAlives: true,\r\n\t}\r\n\tmyhttp := http.Client{\r\n\t\tTransport: tr,\r\n\t}\r\n\t\r\n\tmyhttp.CheckRedirect = func(req *http.Request, via []*http.Request) error {\r\n\t\t\r\n\t\treq.Header = via[len(via)-1].Header\r\n\t\treturn nil\r\n\t}\r\n\treturn &myhttp, nil\r\n}","code-length":334,"reference":"\/\/ HTTPClient returns an http.Client using the given certificate and proxy.","result":"Create a proxy function for the HTTP client.","score":[0.0955,0.0935]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsRecursionRequest(r *http.Request) bool {\r\n\trecursionStr := r.FormValue(\"recursion\")\r\n\trecursion, err := strconv.Atoi(recursionStr)\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\treturn recursion != 0\r\n}","code-length":79,"reference":"\/\/ IsRecursionRequest checks whether the given HTTP request is marked with the\n\/\/ \"recursion\" flag in its form values.","result":"Check if recursion is enabled.","score":[0.0146,0.0568]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetListeners(start int) []net.Listener {\r\n\tdefer func() {\r\n\t\tos.Unsetenv(\"LISTEN_PID\")\r\n\t\tos.Unsetenv(\"LISTEN_FDS\")\r\n\t}()\r\n\tpid, err := strconv.Atoi(os.Getenv(\"LISTEN_PID\"))\r\n\tif err != nil {\r\n\t\treturn nil\r\n\t}\r\n\tif pid != os.Getpid() {\r\n\t\treturn nil\r\n\t}\r\n\tfds, err := strconv.Atoi(os.Getenv(\"LISTEN_FDS\"))\r\n\tif err != nil {\r\n\t\treturn nil\r\n\t}\r\n\tlisteners := []net.Listener{}\r\n\tfor i := start; i < start+fds; i++ {\r\n\t\tsyscall.CloseOnExec(i)\r\n\t\tfile := os.NewFile(uintptr(i), fmt.Sprintf(\"inherited-fd%d\", i))\r\n\t\tlistener, err := net.FileListener(file)\r\n\t\tif err != nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tlisteners = append(listeners, listener)\r\n\t}\r\n\treturn listeners\r\n}","code-length":297,"reference":"\/\/ GetListeners returns the socket-activated network listeners, if any.\n\/\/\n\/\/ The 'start' parameter must be SystemdListenFDsStart, except in unit tests,\n\/\/ see the docstring of SystemdListenFDsStart below.","result":"Get the listeners from the system .","score":[0.0096,0.0386]}
{"code":"\/*is used to<extra_id_0>\r\nfunc internalSQLGet(d *Daemon, r *http.Request) Response {\r\n\tdatabase := r.FormValue(\"database\")\r\n\tif !shared.StringInSlice(database, []string{\"local\", \"global\"}) {\r\n\t\treturn BadRequest(fmt.Errorf(\"Invalid database\"))\r\n\t}\r\n\tschemaFormValue := r.FormValue(\"schema\")\r\n\tschemaOnly, err := strconv.Atoi(schemaFormValue)\r\n\tif err != nil {\r\n\t\tschemaOnly = 0\r\n\t}\r\n\tvar schema string\r\n\tvar db *sql.DB\r\n\tif database == \"global\" {\r\n\t\tdb = d.cluster.DB()\r\n\t\tschema = cluster.FreshSchema()\r\n\t} else {\r\n\t\tdb = d.db.DB()\r\n\t\tschema = node.FreshSchema()\r\n\t}\r\n\ttx, err := db.Begin()\r\n\tif err != nil {\r\n\t\treturn SmartError(errors.Wrap(err, \"failed to start transaction\"))\r\n\t}\r\n\tdefer tx.Rollback()\r\n\tdump, err := query.Dump(tx, schema, schemaOnly == 1)\r\n\tif err != nil {\r\n\t\treturn SmartError(errors.Wrapf(err, \"failed dump database %s\", database))\r\n\t}\r\n\treturn SyncResponse(true, internalSQLDump{Text: dump})\r\n}","code-length":342,"reference":"\/\/ Perform a database dump.","result":"Get the dump of the database.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc internalSQLPost(d *Daemon, r *http.Request) Response {\r\n\treq := &internalSQLQuery{}\r\n\t\r\n\terr := json.NewDecoder(r.Body).Decode(&req)\r\n\tif err != nil {\r\n\t\treturn BadRequest(err)\r\n\t}\r\n\tif !shared.StringInSlice(req.Database, []string{\"local\", \"global\"}) {\r\n\t\treturn BadRequest(fmt.Errorf(\"Invalid database\"))\r\n\t}\r\n\tif req.Query == \"\" {\r\n\t\treturn BadRequest(fmt.Errorf(\"No query provided\"))\r\n\t}\r\n\tvar db *sql.DB\r\n\tif req.Database == \"global\" {\r\n\t\tdb = d.cluster.DB()\r\n\t} else {\r\n\t\tdb = d.db.DB()\r\n\t}\r\n\tbatch := internalSQLBatch{}\r\n\tif req.Query == \".sync\" {\r\n\t\td.gateway.Sync()\r\n\t\treturn SyncResponse(true, batch)\r\n\t}\r\n\tfor _, query := range strings.Split(req.Query, \";\") {\r\n\t\tquery = strings.TrimLeft(query, \" \")\r\n\t\tif query == \"\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tresult := internalSQLResult{}\r\n\t\ttx, err := db.Begin()\r\n\t\tif err != nil {\r\n\t\t\treturn SmartError(err)\r\n\t\t}\r\n\t\tif strings.HasPrefix(strings.ToUpper(query), \"SELECT\") {\r\n\t\t\terr = internalSQLSelect(tx, query, &result)\r\n\t\t\ttx.Rollback()\r\n\t\t} else {\r\n\t\t\terr = internalSQLExec(tx, query, &result)\r\n\t\t\tif err != nil {\r\n\t\t\t\ttx.Rollback()\r\n\t\t\t} else {\r\n\t\t\t\terr = tx.Commit()\r\n\t\t\t}\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn SmartError(err)\r\n\t\t}\r\n\t\tbatch.Results = append(batch.Results, result)\r\n\t}\r\n\treturn SyncResponse(true, batch)\r\n}","code-length":527,"reference":"\/\/ Execute queries.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *CertInfo) PublicKey() []byte {\r\n\tdata := c.KeyPair().Certificate[0]\r\n\treturn pem.EncodeToMemory(&pem.Block{Type: \"CERTIFICATE\", Bytes: data})\r\n}","code-length":62,"reference":"\/\/ PublicKey is a convenience to encode the underlying public key to ASCII.","result":"Generate public keys.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *CertInfo) PrivateKey() []byte {\r\n\tecKey, ok := c.KeyPair().PrivateKey.(*ecdsa.PrivateKey)\r\n\tif ok {\r\n\t\tdata, err := x509.MarshalECPrivateKey(ecKey)\r\n\t\tif err != nil {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\treturn pem.EncodeToMemory(&pem.Block{Type: \"EC PRIVATE KEY\", Bytes: data})\r\n\t}\r\n\trsaKey, ok := c.KeyPair().PrivateKey.(*rsa.PrivateKey)\r\n\tif ok {\r\n\t\tdata := x509.MarshalPKCS1PrivateKey(rsaKey)\r\n\t\treturn pem.EncodeToMemory(&pem.Block{Type: \"RSA PRIVATE KEY\", Bytes: data})\r\n\t}\r\n\treturn nil\r\n}","code-length":197,"reference":"\/\/ PrivateKey is a convenience to encode the underlying private key.","result":"Generate the private key.","score":[0.0869,0.2481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *CertInfo) Fingerprint() string {\r\n\tfingerprint, err := CertFingerprintStr(string(c.PublicKey()))\r\n\t\r\n\t\r\n\tif err != nil {\r\n\t\tpanic(\"invalid public key material\")\r\n\t}\r\n\treturn fingerprint\r\n}","code-length":76,"reference":"\/\/ Fingerprint returns the fingerprint of the public key.","result":"Generate the fingerprint.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GenCert(certf string, keyf string, certtype bool) error {\r\n\t\r\n\tdir := path.Dir(certf)\r\n\terr := os.MkdirAll(dir, 0750)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdir = path.Dir(keyf)\r\n\terr = os.MkdirAll(dir, 0750)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tcertBytes, keyBytes, err := GenerateMemCert(certtype)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tcertOut, err := os.Create(certf)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"Failed to open %s for writing: %v\", certf, err)\r\n\t}\r\n\tcertOut.Write(certBytes)\r\n\tcertOut.Close()\r\n\tkeyOut, err := os.OpenFile(keyf, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0600)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"Failed to open %s for writing: %v\", keyf, err)\r\n\t}\r\n\tkeyOut.Write(keyBytes)\r\n\tkeyOut.Close()\r\n\treturn nil\r\n}","code-length":331,"reference":"\/\/ GenCert will create and populate a certificate file and a key file","result":"Generate the cert.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PrintServerInfo(c lxd.ContainerServer) error {\r\n\tserver, _, err := c.GetServer()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tenv := server.Environment\r\n\tfmt.Printf(\"Test environment:\\n\")\r\n\tfmt.Printf(\"  Server backend: %s\\n\", env.Server)\r\n\tfmt.Printf(\"  Server version: %s\\n\", env.ServerVersion)\r\n\tfmt.Printf(\"  Kernel: %s\\n\", env.Kernel)\r\n\tfmt.Printf(\"  Kernel architecture: %s\\n\", env.KernelArchitecture)\r\n\tfmt.Printf(\"  Kernel version: %s\\n\", env.KernelVersion)\r\n\tfmt.Printf(\"  Storage backend: %s\\n\", env.Storage)\r\n\tfmt.Printf(\"  Storage version: %s\\n\", env.StorageVersion)\r\n\tfmt.Printf(\"  Container backend: %s\\n\", env.Driver)\r\n\tfmt.Printf(\"  Container version: %s\\n\", env.DriverVersion)\r\n\tfmt.Printf(\"\\n\")\r\n\treturn nil\r\n}","code-length":277,"reference":"\/\/ PrintServerInfo prints out information about the server.","result":"Print server info.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LaunchContainers(c lxd.ContainerServer, count int, parallel int, image string, privileged bool, start bool, freeze bool) (time.Duration, error) {\r\n\tvar duration time.Duration\r\n\tbatchSize, err := getBatchSize(parallel)\r\n\tif err != nil {\r\n\t\treturn duration, err\r\n\t}\r\n\tprintTestConfig(count, batchSize, image, privileged, freeze)\r\n\tfingerprint, err := ensureImage(c, image)\r\n\tif err != nil {\r\n\t\treturn duration, err\r\n\t}\r\n\tbatchStart := func(index int, wg *sync.WaitGroup) {\r\n\t\tdefer wg.Done()\r\n\t\tname := getContainerName(count, index)\r\n\t\terr := createContainer(c, fingerprint, name, privileged)\r\n\t\tif err != nil {\r\n\t\t\tlogf(\"Failed to launch container '%s': %s\", name, err)\r\n\t\t\treturn\r\n\t\t}\r\n\t\tif start {\r\n\t\t\terr := startContainer(c, name)\r\n\t\t\tif err != nil {\r\n\t\t\t\tlogf(\"Failed to start container '%s': %s\", name, err)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tif freeze {\r\n\t\t\t\terr := freezeContainer(c, name)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tlogf(\"Failed to freeze container '%s': %s\", name, err)\r\n\t\t\t\t\treturn\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tduration = processBatch(count, batchSize, batchStart)\r\n\treturn duration, nil\r\n}","code-length":398,"reference":"\/\/ LaunchContainers launches a set of containers.","result":"Launch containers.","score":[0.041,0.1538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CreateContainers(c lxd.ContainerServer, count int, parallel int, fingerprint string, privileged bool) (time.Duration, error) {\r\n\tvar duration time.Duration\r\n\tbatchSize, err := getBatchSize(parallel)\r\n\tif err != nil {\r\n\t\treturn duration, err\r\n\t}\r\n\tbatchCreate := func(index int, wg *sync.WaitGroup) {\r\n\t\tdefer wg.Done()\r\n\t\tname := getContainerName(count, index)\r\n\t\terr := createContainer(c, fingerprint, name, privileged)\r\n\t\tif err != nil {\r\n\t\t\tlogf(\"Failed to launch container '%s': %s\", name, err)\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n\tduration = processBatch(count, batchSize, batchCreate)\r\n\treturn duration, nil\r\n}","code-length":210,"reference":"\/\/ CreateContainers create the specified number of containers.","result":"Create containers.","score":[0.0249,0.1351]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetContainers(c lxd.ContainerServer) ([]api.Container, error) {\r\n\tcontainers := []api.Container{}\r\n\tallContainers, err := c.GetContainers()\r\n\tif err != nil {\r\n\t\treturn containers, err\r\n\t}\r\n\tfor _, container := range allContainers {\r\n\t\tif container.Config[userConfigKey] == \"true\" {\r\n\t\t\tcontainers = append(containers, container)\r\n\t\t}\r\n\t}\r\n\treturn containers, nil\r\n}","code-length":133,"reference":"\/\/ GetContainers returns containers created by the benchmark.","result":"Get all the containers in the container server.","score":[0.1652,0.125]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StartContainers(c lxd.ContainerServer, containers []api.Container, parallel int) (time.Duration, error) {\r\n\tvar duration time.Duration\r\n\tbatchSize, err := getBatchSize(parallel)\r\n\tif err != nil {\r\n\t\treturn duration, err\r\n\t}\r\n\tcount := len(containers)\r\n\tlogf(\"Starting %d containers\", count)\r\n\tbatchStart := func(index int, wg *sync.WaitGroup) {\r\n\t\tdefer wg.Done()\r\n\t\tcontainer := containers[index]\r\n\t\tif !container.IsActive() {\r\n\t\t\terr := startContainer(c, container.Name)\r\n\t\t\tif err != nil {\r\n\t\t\t\tlogf(\"Failed to start container '%s': %s\", container.Name, err)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tduration = processBatch(count, batchSize, batchStart)\r\n\treturn duration, nil\r\n}","code-length":241,"reference":"\/\/ StartContainers starts containers created by the benchmark.","result":"Start containers.","score":[0,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc setQueryParam(uri, param, value string) (string, error) {\r\n\tfields, err := url.Parse(uri)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tvalues := fields.Query()\r\n\tvalues.Set(param, url.QueryEscape(value))\r\n\tfields.RawQuery = values.Encode()\r\n\treturn fields.String(), nil\r\n}","code-length":107,"reference":"\/\/ Set the value of a query parameter in the given URI.","result":"Set a query parameter.","score":[0.0677,0.2282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetImages() ([]api.Image, error) {\r\n\timages := []api.Image{}\r\n\t_, err := r.queryStruct(\"GET\", \"\/images?recursion=1\", nil, \"\", &images)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn images, nil\r\n}","code-length":96,"reference":"\/\/ Image handling functions\n\/\/ GetImages returns a list of available images as Image structs","result":"Get the images from the server.","score":[0.0431,0.0355]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetImageFile(fingerprint string, req ImageFileRequest) (*ImageFileResponse, error) {\r\n\treturn r.GetPrivateImageFile(fingerprint, \"\", req)\r\n}","code-length":57,"reference":"\/\/ GetImageFile downloads an image from the server, returning an ImageFileRequest struct","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetImageSecret(fingerprint string) (string, error) {\r\n\top, err := r.CreateImageSecret(fingerprint)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\topAPI := op.Get()\r\n\treturn opAPI.Metadata[\"secret\"].(string), nil\r\n}","code-length":93,"reference":"\/\/ GetImageSecret is a helper around CreateImageSecret that returns a secret for the image","result":"Get the secret from the image.","score":[0.0605,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetPrivateImage(fingerprint string, secret string) (*api.Image, string, error) {\r\n\timage := api.Image{}\r\n\t\r\n\tpath := fmt.Sprintf(\"\/images\/%s\", url.QueryEscape(fingerprint))\r\n\tvar err error\r\n\tpath, err = r.setQueryAttributes(path)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\tif secret != \"\" {\r\n\t\tpath, err = setQueryParam(path, \"secret\", secret)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, \"\", err\r\n\t\t}\r\n\t}\r\n\t\r\n\tetag, err := r.queryStruct(\"GET\", path, nil, \"\", &image)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\treturn &image, etag, nil\r\n}","code-length":226,"reference":"\/\/ GetPrivateImage is similar to GetImage but allows passing a secret download token","result":"Avoid the need for the function to be executed.","score":[0.0781,0.0397]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetPrivateImageFile(fingerprint string, secret string, req ImageFileRequest) (*ImageFileResponse, error) {\r\n\t\r\n\tif req.MetaFile == nil && req.RootfsFile == nil {\r\n\t\treturn nil, fmt.Errorf(\"No file requested\")\r\n\t}\r\n\turi := fmt.Sprintf(\"\/1.0\/images\/%s\/export\", url.QueryEscape(fingerprint))\r\n\tvar err error\r\n\turi, err = r.setQueryAttributes(uri)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tif secret == \"\" && shared.PathExists(\"\/dev\/lxd\/sock\") && os.Geteuid() == 0 {\r\n\t\tunixURI := fmt.Sprintf(\"http:\r\n\t\t\r\n\t\tdevlxdHTTP, err := unixHTTPClient(nil, \"\/dev\/lxd\/sock\")\r\n\t\tif err == nil {\r\n\t\t\tresp, err := lxdDownloadImage(fingerprint, unixURI, r.httpUserAgent, devlxdHTTP, req)\r\n\t\t\tif err == nil {\r\n\t\t\t\treturn resp, nil\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\turi = fmt.Sprintf(\"%s%s\", r.httpHost, uri)\r\n\tif secret != \"\" {\r\n\t\turi, err = setQueryParam(uri, \"secret\", secret)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\treturn lxdDownloadImage(fingerprint, uri, r.httpUserAgent, r.http, req)\r\n}","code-length":400,"reference":"\/\/ GetPrivateImageFile is similar to GetImageFile but allows passing a secret download token","result":"Get the file from the remote server.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetImageAliases() ([]api.ImageAliasesEntry, error) {\r\n\taliases := []api.ImageAliasesEntry{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", \"\/images\/aliases?recursion=1\", nil, \"\", &aliases)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn aliases, nil\r\n}","code-length":106,"reference":"\/\/ GetImageAliases returns the list of available aliases as ImageAliasesEntry structs","result":"Get the image aliases.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) tryCopyImage(req api.ImagesPost, urls []string) (RemoteOperation, error) {\r\n\tif len(urls) == 0 {\r\n\t\treturn nil, fmt.Errorf(\"The source server isn't listening on the network\")\r\n\t}\r\n\trop := remoteOperation{\r\n\t\tchDone: make(chan bool),\r\n\t}\r\n\t\r\n\tif !r.HasExtension(\"image_create_aliases\") && req.Aliases != nil {\r\n\t\trop.chPost = make(chan bool)\r\n\t\tgo func() {\r\n\t\t\tdefer close(rop.chPost)\r\n\t\t\t\r\n\t\t\t<-rop.chDone\r\n\t\t\tif rop.err != nil {\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\top, err := rop.GetTarget()\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tfingerprint := op.Metadata[\"fingerprint\"].(string)\r\n\t\t\t\r\n\t\t\tfor _, entry := range req.Aliases {\r\n\t\t\t\talias := api.ImageAliasesPost{}\r\n\t\t\t\talias.Name = entry.Name\r\n\t\t\t\talias.Target = fingerprint\r\n\t\t\t\tr.CreateImageAlias(alias)\r\n\t\t\t}\r\n\t\t}()\r\n\t}\r\n\t\r\n\tgo func() {\r\n\t\tsuccess := false\r\n\t\terrors := map[string]error{}\r\n\t\tfor _, serverURL := range urls {\r\n\t\t\treq.Source.Server = serverURL\r\n\t\t\top, err := r.CreateImage(req, nil)\r\n\t\t\tif err != nil {\r\n\t\t\t\terrors[serverURL] = err\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\trop.targetOp = op\r\n\t\t\tfor _, handler := range rop.handlers {\r\n\t\t\t\trop.targetOp.AddHandler(handler)\r\n\t\t\t}\r\n\t\t\terr = rop.targetOp.Wait()\r\n\t\t\tif err != nil {\r\n\t\t\t\terrors[serverURL] = err\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tsuccess = true\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif !success {\r\n\t\t\trop.err = remoteOperationError(\"Failed remote image download\", errors)\r\n\t\t}\r\n\t\tclose(rop.chDone)\r\n\t}()\r\n\treturn &rop, nil\r\n}","code-length":589,"reference":"\/\/ tryCopyImage iterates through the source server URLs until one lets it download the image","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) CopyImage(source ImageServer, image api.Image, args *ImageCopyArgs) (RemoteOperation, error) {\r\n\t\r\n\tif r == source {\r\n\t\treturn nil, fmt.Errorf(\"The source and target servers must be different\")\r\n\t}\r\n\t\r\n\tinfo, err := source.GetConnectionInfo()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\treq := api.ImagesPost{\r\n\t\tSource: &api.ImagesPostSource{\r\n\t\t\tImageSource: api.ImageSource{\r\n\t\t\t\tCertificate: info.Certificate,\r\n\t\t\t\tProtocol:    info.Protocol,\r\n\t\t\t},\r\n\t\t\tFingerprint: image.Fingerprint,\r\n\t\t\tMode:        \"pull\",\r\n\t\t\tType:        \"image\",\r\n\t\t},\r\n\t}\r\n\t\r\n\tif !image.Public {\r\n\t\tsecret, err := source.GetImageSecret(image.Fingerprint)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treq.Source.Secret = secret\r\n\t}\r\n\t\r\n\tif args != nil {\r\n\t\treq.Aliases = args.Aliases\r\n\t\treq.AutoUpdate = args.AutoUpdate\r\n\t\treq.Public = args.Public\r\n\t\tif args.CopyAliases {\r\n\t\t\treq.Aliases = image.Aliases\r\n\t\t\tif args.Aliases != nil {\r\n\t\t\t\treq.Aliases = append(req.Aliases, args.Aliases...)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn r.tryCopyImage(req, info.Addresses)\r\n}","code-length":412,"reference":"\/\/ CopyImage copies an image from a remote server. Additional options can be passed using ImageCopyArgs","result":"ImageCopyArgs.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) UpdateImage(fingerprint string, image api.ImagePut, ETag string) error {\r\n\t\r\n\t_, _, err := r.query(\"PUT\", fmt.Sprintf(\"\/images\/%s\", url.QueryEscape(fingerprint)), image, ETag)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":100,"reference":"\/\/ UpdateImage updates the image definition","result":"Update the image.","score":[0.1502,0.3289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) DeleteImage(fingerprint string) (Operation, error) {\r\n\t\r\n\top, _, err := r.queryOperation(\"DELETE\", fmt.Sprintf(\"\/images\/%s\", url.QueryEscape(fingerprint)), nil, \"\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":100,"reference":"\/\/ DeleteImage requests that LXD removes an image from the store","result":"Delete an image.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) RefreshImage(fingerprint string) (Operation, error) {\r\n\tif !r.HasExtension(\"image_force_refresh\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"image_force_refresh\\\" API extension\")\r\n\t}\r\n\t\r\n\top, _, err := r.queryOperation(\"POST\", fmt.Sprintf(\"\/images\/%s\/refresh\", url.QueryEscape(fingerprint)), nil, \"\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":150,"reference":"\/\/ RefreshImage requests that LXD issues an image refresh","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) CreateImageAlias(alias api.ImageAliasesPost) error {\r\n\t\r\n\t_, _, err := r.query(\"POST\", \"\/images\/aliases\", alias, \"\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":83,"reference":"\/\/ CreateImageAlias sets up a new image alias","result":"Create a new image alias.","score":[0.2716,0.3824]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) UpdateImageAlias(name string, alias api.ImageAliasesEntryPut, ETag string) error {\r\n\t\r\n\t_, _, err := r.query(\"PUT\", fmt.Sprintf(\"\/images\/aliases\/%s\", url.QueryEscape(name)), alias, ETag)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":105,"reference":"\/\/ UpdateImageAlias updates the image alias definition","result":"Update the alias in LXD mode.","score":[0.1943,0.3704]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) RenameImageAlias(name string, alias api.ImageAliasesEntryPost) error {\r\n\t\r\n\t_, _, err := r.query(\"POST\", fmt.Sprintf(\"\/images\/aliases\/%s\", url.QueryEscape(name)), alias, \"\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":102,"reference":"\/\/ RenameImageAlias renames an existing image alias","result":"Rename an image alias.","score":[0.1795,0.3814]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) DeleteImageAlias(name string) error {\r\n\t\r\n\t_, _, err := r.query(\"DELETE\", fmt.Sprintf(\"\/images\/aliases\/%s\", url.QueryEscape(name)), nil, \"\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":94,"reference":"\/\/ DeleteImageAlias removes an alias from the LXD image store","result":"Delete an image alias.","score":[0.0848,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Open(dir string) (*sql.DB, error) {\r\n\tpath := filepath.Join(dir, \"local.db\")\r\n\tdb, err := sqliteOpen(path)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"cannot open node database: %v\", err)\r\n\t}\r\n\treturn db, nil\r\n}","code-length":95,"reference":"\/\/ Open the node-local database object.","result":"Open the local database.","score":[0.274,0.3233]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EnsureSchema(db *sql.DB, dir string, hook schema.Hook) (int, error) {\r\n\tbackupDone := false\r\n\tschema := Schema()\r\n\tschema.File(filepath.Join(dir, \"patch.local.sql\"))\r\n\tschema.Hook(func(version int, tx *sql.Tx) error {\r\n\t\tif !backupDone {\r\n\t\t\tlogger.Infof(\"Updating the LXD database schema. Backup made as \\\"local.db.bak\\\"\")\r\n\t\t\tpath := filepath.Join(dir, \"local.db\")\r\n\t\t\terr := shared.FileCopy(path, path+\".bak\")\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tbackupDone = true\r\n\t\t}\r\n\t\tif version == -1 {\r\n\t\t\tlogger.Debugf(\"Running pre-update queries from file for local DB schema\")\r\n\t\t} else {\r\n\t\t\tlogger.Debugf(\"Updating DB schema from %d to %d\", version, version+1)\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tif hook != nil && version != -1 {\r\n\t\t\terr := hook(version, tx)\r\n\t\t\tif err != nil {\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\treturn schema.Ensure(db)\r\n}","code-length":332,"reference":"\/\/ EnsureSchema applies all relevant schema updates to the node-local\n\/\/ database.\n\/\/\n\/\/ Return the initial schema version found before starting the update, along\n\/\/ with any error occurred.","result":"Ensure the database schema is correct.","score":[0.0042,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FilesystemDetect(path string) (string, error) {\r\n\tfs := syscall.Statfs_t{}\r\n\terr := syscall.Statfs(path, &fs)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tswitch fs.Type {\r\n\tcase FilesystemSuperMagicBtrfs:\r\n\t\treturn \"btrfs\", nil\r\n\tcase FilesystemSuperMagicZfs:\r\n\t\treturn \"zfs\", nil\r\n\tcase FilesystemSuperMagicTmpfs:\r\n\t\treturn \"tmpfs\", nil\r\n\tcase FilesystemSuperMagicExt4:\r\n\t\treturn \"ext4\", nil\r\n\tcase FilesystemSuperMagicXfs:\r\n\t\treturn \"xfs\", nil\r\n\tcase FilesystemSuperMagicNfs:\r\n\t\treturn \"nfs\", nil\r\n\tdefault:\r\n\t\tlogger.Debugf(\"Unknown backing filesystem type: 0x%x\", fs.Type)\r\n\t\treturn string(fs.Type), nil\r\n\t}\r\n}","code-length":244,"reference":"\/\/ FilesystemDetect returns the filesystem on which the passed-in path sits.","result":"Detect the backing filesystem type.","score":[0.0861,0.0962]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Schema() *schema.Schema {\r\n\tschema := schema.NewFromMap(updates)\r\n\tschema.Fresh(freshSchema)\r\n\treturn schema\r\n}","code-length":49,"reference":"\/\/ Schema for the local database.","result":"Generate the schema.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc updateFromV37(tx *sql.Tx) error {\r\n\tcount, err := query.Count(tx, \"raft_nodes\", \"\")\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Fetch count of Raft nodes\")\r\n\t}\r\n\tif count == 0 {\r\n\t\t\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\t_, err = tx.Exec(`\r\nINSERT INTO config (key, value)\r\n  SELECT 'cluster.https_address', value FROM config WHERE key = 'core.https_address'\r\n`)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Insert cluster.https_address config\")\r\n\t}\r\n\treturn nil\r\n}","code-length":186,"reference":"\/\/ Schema updates begin here\n\/\/ Copy core.https_address to cluster.https_address in case this node is\n\/\/ clustered.","result":"Update the config from v.","score":[0,0.0316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ArchitectureGetLocal() (string, error) {\r\n\tuname, err := shared.Uname()\r\n\tif err != nil {\r\n\t\treturn ArchitectureDefault, err\r\n\t}\r\n\treturn uname.Machine, nil\r\n}","code-length":68,"reference":"\/\/ ArchitectureGetLocal returns the local hardware architecture","result":"Generate the generated code.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewController(url string, key string, machine string) (*Controller, error) {\r\n\tbaseURL := fmt.Sprintf(\"%s\/api\/2.0\/\", url)\r\n\t\r\n\tsrv, err := gomaasapi.NewController(gomaasapi.ControllerArgs{\r\n\t\tBaseURL: baseURL,\r\n\t\tAPIKey:  key,\r\n\t})\r\n\tif err != nil {\r\n\t\t\r\n\t\tif !strings.Contains(err.Error(), \"unsupported version\") {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn nil, fmt.Errorf(\"Unable to connect MAAS at '%s': %v\", baseURL,\r\n\t\t\tstrings.Split(strings.Split(err.Error(), \"unsupported version: \")[1], \" (\")[0])\r\n\t}\r\n\tsrvRaw, err := gomaasapi.NewAuthenticatedClient(baseURL, key)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tmachines, err := srv.Machines(gomaasapi.MachinesArgs{Hostnames: []string{machine}})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif len(machines) != 1 {\r\n\t\treturn nil, fmt.Errorf(\"Couldn't find the specified machine: %s\", machine)\r\n\t}\r\n\t\r\n\tc := Controller{}\r\n\tc.srv = srv\r\n\tc.srvRaw = *srvRaw\r\n\tc.machine = machines[0]\r\n\tc.url = baseURL\r\n\treturn &c, err\r\n}","code-length":390,"reference":"\/\/ NewController returns a new Controller using the specific MAAS server and machine","result":"Create a new controller.","score":[0.0476,0.155]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) CreateContainer(name string, interfaces []ContainerInterface) error {\r\n\t\r\n\tmacInterfaces, err := parseInterfaces(interfaces)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tsubnets, err := c.getSubnets()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tdevice, err := c.machine.CreateDevice(gomaasapi.CreateMachineDeviceArgs{\r\n\t\tHostname:      name,\r\n\t\tInterfaceName: interfaces[0].Name,\r\n\t\tMACAddress:    interfaces[0].MACAddress,\r\n\t\tVLAN:          subnets[interfaces[0].Subnets[0].Name].VLAN(),\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tsuccess := false\r\n\tdefer func() {\r\n\t\tif success == true {\r\n\t\t\treturn\r\n\t\t}\r\n\t\tc.DeleteContainer(name)\r\n\t}()\r\n\t\r\n\tfor _, iface := range interfaces[1:] {\r\n\t\t_, err := device.CreateInterface(gomaasapi.CreateInterfaceArgs{\r\n\t\t\tName:       iface.Name,\r\n\t\t\tMACAddress: iface.MACAddress,\r\n\t\t\tVLAN:       subnets[iface.Subnets[0].Name].VLAN(),\r\n\t\t})\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\t\r\n\tdevice, err = c.getDevice(name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tfor _, entry := range device.InterfaceSet() {\r\n\t\t\r\n\t\tiface, ok := macInterfaces[entry.MACAddress()]\r\n\t\tif !ok {\r\n\t\t\treturn fmt.Errorf(\"MAAS created an interface with a bad MAC: %s\", entry.MACAddress())\r\n\t\t}\r\n\t\t\r\n\t\tfor _, subnet := range iface.Subnets {\r\n\t\t\terr := entry.LinkSubnet(gomaasapi.LinkSubnetArgs{\r\n\t\t\t\tMode:      gomaasapi.LinkModeStatic,\r\n\t\t\t\tSubnet:    subnets[subnet.Name],\r\n\t\t\t\tIPAddress: subnet.Address,\r\n\t\t\t})\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tsuccess = true\r\n\treturn nil\r\n}","code-length":603,"reference":"\/\/ CreateContainer defines a new MAAS device for the controller","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) DefinedContainer(name string) (bool, error) {\r\n\tdevs, err := c.machine.Devices(gomaasapi.DevicesArgs{Hostname: []string{name}})\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\tif len(devs) == 1 {\r\n\t\treturn true, nil\r\n\t}\r\n\treturn false, nil\r\n}","code-length":112,"reference":"\/\/ DefinedContainer returns true if the container is defined in MAAS","result":"Test if the code is not compiled.","score":[0.1427,0.2411]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) UpdateContainer(name string, interfaces []ContainerInterface) error {\r\n\t\r\n\tmacInterfaces, err := parseInterfaces(interfaces)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tsubnets, err := c.getSubnets()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdevice, err := c.getDevice(name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\texistingInterfaces := map[string]gomaasapi.Interface{}\r\n\tfor _, entry := range device.InterfaceSet() {\r\n\t\t\r\n\t\tiface, ok := macInterfaces[entry.MACAddress()]\r\n\t\tif !ok {\r\n\t\t\t\r\n\t\t\terr = entry.Delete()\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\texistingSubnets := map[string]gomaasapi.Subnet{}\r\n\t\tfor _, link := range entry.Links() {\r\n\t\t\t\r\n\t\t\tfound := false\r\n\t\t\tfor _, subnet := range iface.Subnets {\r\n\t\t\t\tif subnet.Name == link.Subnet().Name() {\r\n\t\t\t\t\tif subnet.Address == \"\" || subnet.Address == link.IPAddress() {\r\n\t\t\t\t\t\tfound = true\r\n\t\t\t\t\t}\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif !found {\r\n\t\t\t\terr = entry.UnlinkSubnet(link.Subnet())\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\texistingSubnets[link.Subnet().Name()] = link.Subnet()\r\n\t\t}\r\n\t\t\r\n\t\tfor _, subnet := range iface.Subnets {\r\n\t\t\t\r\n\t\t\t_, ok := existingSubnets[subnet.Name]\r\n\t\t\tif ok {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\terr := entry.LinkSubnet(gomaasapi.LinkSubnetArgs{\r\n\t\t\t\tMode:      gomaasapi.LinkModeStatic,\r\n\t\t\t\tSubnet:    subnets[subnet.Name],\r\n\t\t\t\tIPAddress: subnet.Address,\r\n\t\t\t})\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\texistingInterfaces[entry.MACAddress()] = entry\r\n\t}\r\n\t\r\n\tfor _, iface := range macInterfaces {\r\n\t\t_, ok := existingInterfaces[iface.MACAddress]\r\n\t\tif ok {\r\n\t\t\t\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tentry, err := device.CreateInterface(gomaasapi.CreateInterfaceArgs{\r\n\t\t\tName:       iface.Name,\r\n\t\t\tMACAddress: iface.MACAddress,\r\n\t\t\tVLAN:       subnets[iface.Subnets[0].Name].VLAN(),\r\n\t\t})\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\tfor _, subnet := range iface.Subnets {\r\n\t\t\terr := entry.LinkSubnet(gomaasapi.LinkSubnetArgs{\r\n\t\t\t\tMode:      gomaasapi.LinkModeStatic,\r\n\t\t\t\tSubnet:    subnets[subnet.Name],\r\n\t\t\t\tIPAddress: subnet.Address,\r\n\t\t\t})\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":868,"reference":"\/\/ UpdateContainer updates the MAAS device's interfaces with the new provided state","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) RenameContainer(name string, newName string) error {\r\n\tdevice, err := c.getDevice(name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\turi, err := url.Parse(fmt.Sprintf(\"%s\/devices\/%s\/\", c.url, device.SystemID()))\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tvalues := url.Values{}\r\n\tvalues.Set(\"hostname\", newName)\r\n\t_, err = c.srvRaw.Put(uri, values)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":176,"reference":"\/\/ RenameContainer renames the MAAS device for the container without releasing any allocation","result":"Replace the generated code.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) DeleteContainer(name string) error {\r\n\tdevice, err := c.getDevice(name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = device.Delete()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":90,"reference":"\/\/ DeleteContainer removes the MAAS device for the container","result":"Delete the container.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Schema) Add(update Update) {\r\n\ts.updates = append(s.updates, update)\r\n}","code-length":39,"reference":"\/\/ Add a new update to the schema. It will be appended at the end of the\n\/\/ existing series.","result":"Generate the generated code.","score":[0.0059,0.0272]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ensureSchemaTableExists(tx *sql.Tx) error {\r\n\texists, err := DoesSchemaTableExist(tx)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to check if schema table is there: %v\", err)\r\n\t}\r\n\tif !exists {\r\n\t\terr := createSchemaTable(tx)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to create schema table: %v\", err)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":137,"reference":"\/\/ Ensure that the schema exists.","result":"Ensure that the schema table is created.","score":[0.5055,0.6506]}
{"code":"\/*is used to<extra_id_0>\r\nfunc queryCurrentVersion(tx *sql.Tx) (int, error) {\r\n\tversions, err := selectSchemaVersions(tx)\r\n\tif err != nil {\r\n\t\treturn -1, fmt.Errorf(\"failed to fetch update versions: %v\", err)\r\n\t}\r\n\t\r\n\thasVersion := func(v int) bool { return shared.IntInSlice(v, versions) }\r\n\tif hasVersion(30) && hasVersion(32) && !hasVersion(31) {\r\n\t\terr = insertSchemaVersion(tx, 31)\r\n\t\tif err != nil {\r\n\t\t\treturn -1, fmt.Errorf(\"failed to insert missing schema version 31\")\r\n\t\t}\r\n\t\tversions, err = selectSchemaVersions(tx)\r\n\t\tif err != nil {\r\n\t\t\treturn -1, fmt.Errorf(\"failed to fetch update versions: %v\", err)\r\n\t\t}\r\n\t}\r\n\t\r\n\tif hasVersion(37) && !hasVersion(38) {\r\n\t\tcount, err := query.Count(tx, \"config\", \"key = 'cluster.https_address'\")\r\n\t\tif err != nil {\r\n\t\t\treturn -1, fmt.Errorf(\"Failed to check if cluster.https_address is set: %v\", err)\r\n\t\t}\r\n\t\tif count == 1 {\r\n\t\t\t\r\n\t\t\terr := insertSchemaVersion(tx, 38)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn -1, fmt.Errorf(\"Failed to insert missing schema version 38\")\r\n\t\t\t}\r\n\t\t\tversions = append(versions, 38)\r\n\t\t}\r\n\t}\r\n\tcurrent := 0\r\n\tif len(versions) > 0 {\r\n\t\terr = checkSchemaVersionsHaveNoHoles(versions)\r\n\t\tif err != nil {\r\n\t\t\treturn -1, err\r\n\t\t}\r\n\t\tcurrent = versions[len(versions)-1]\r\n\t}\r\n\treturn current, nil\r\n}","code-length":484,"reference":"\/\/ Return the highest update version currently applied. Zero means that no\n\/\/ updates have been applied yet.","result":"Query the current version of the database.","score":[0.0399,0.0888]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ensureUpdatesAreApplied(tx *sql.Tx, current int, updates []Update, hook Hook) error {\r\n\tif current > len(updates) {\r\n\t\treturn fmt.Errorf(\r\n\t\t\t\"schema version '%d' is more recent than expected '%d'\",\r\n\t\t\tcurrent, len(updates))\r\n\t}\r\n\t\r\n\tif len(updates) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\tfor _, update := range updates[current:] {\r\n\t\tif hook != nil {\r\n\t\t\terr := hook(current, tx)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\r\n\t\t\t\t\t\"failed to execute hook (version %d): %v\", current, err)\r\n\t\t\t}\r\n\t\t}\r\n\t\terr := update(tx)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to apply update %d: %v\", current, err)\r\n\t\t}\r\n\t\tcurrent++\r\n\t\terr = insertSchemaVersion(tx, current)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to insert version %d\", current)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":308,"reference":"\/\/ Apply any pending update that was not yet applied.","result":"Ensure that all updates are applied to the database.","score":[0.109,0.1515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkSchemaVersionsHaveNoHoles(versions []int) error {\r\n\t\r\n\t\r\n\tfor i := range versions[:len(versions)-1] {\r\n\t\tif versions[i+1] != versions[i]+1 {\r\n\t\t\treturn fmt.Errorf(\"Missing updates: %d to %d\", versions[i], versions[i+1])\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":109,"reference":"\/\/ Check that the given list of update version numbers doesn't have \"holes\",\n\/\/ that is each version equal the preceding version plus 1.","result":"Check schema versions have no holes.","score":[0.0114,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkAllUpdatesAreApplied(tx *sql.Tx, updates []Update) error {\r\n\tversions, err := selectSchemaVersions(tx)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to fetch update versions: %v\", err)\r\n\t}\r\n\tif len(versions) == 0 {\r\n\t\treturn fmt.Errorf(\"expected schema table to contain at least one row\")\r\n\t}\r\n\terr = checkSchemaVersionsHaveNoHoles(versions)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tcurrent := versions[len(versions)-1]\r\n\tif current != len(updates) {\r\n\t\treturn fmt.Errorf(\"update level is %d, expected %d\", current, len(updates))\r\n\t}\r\n\treturn nil\r\n}","code-length":201,"reference":"\/\/ Check that all the given updates are applied.","result":"Check all updates are applied.","score":[0.2527,0.5186]}
{"code":"\/*is used to<extra_id_0>\r\nfunc formatSQL(statement string) string {\r\n\tlines := strings.Split(statement, \"\\n\")\r\n\tfor i, line := range lines {\r\n\t\tif strings.Contains(line, \"UNIQUE\") {\r\n\t\t\t\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tlines[i] = strings.Replace(line, \", \", \",\\n    \", -1)\r\n\t}\r\n\treturn strings.Join(lines, \"\\n\")\r\n}","code-length":115,"reference":"\/\/ Format the given SQL statement in a human-readable way.\n\/\/\n\/\/ In particular make sure that each column definition in a CREATE TABLE clause\n\/\/ is in its own row, since SQLite dumps occasionally stuff more than one\n\/\/ column in the same line.","result":"Format the SQL statement.","score":[0.0,0.0367]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetAllXattr(path string) (xattrs map[string]string, err error) {\r\n\te1 := fmt.Errorf(\"Extended attributes changed during retrieval\")\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tpre, err := llistxattr(path, nil)\r\n\tif err != nil || pre < 0 {\r\n\t\treturn nil, err\r\n\t}\r\n\tif pre == 0 {\r\n\t\treturn nil, nil\r\n\t}\r\n\tdest := make([]byte, pre)\r\n\tpost, err := llistxattr(path, dest)\r\n\tif err != nil || post < 0 {\r\n\t\treturn nil, err\r\n\t}\r\n\tif post != pre {\r\n\t\treturn nil, e1\r\n\t}\r\n\tsplit := strings.Split(string(dest), \"\\x00\")\r\n\tif split == nil {\r\n\t\treturn nil, fmt.Errorf(\"No valid extended attribute key found\")\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif split[len(split)-1] == \"\" {\r\n\t\tsplit = split[:len(split)-1]\r\n\t}\r\n\txattrs = make(map[string]string, len(split))\r\n\tfor _, x := range split {\r\n\t\txattr := string(x)\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tpre, err = syscall.Getxattr(path, xattr, nil)\r\n\t\tif err != nil || pre < 0 {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tdest = make([]byte, pre)\r\n\t\tpost := 0\r\n\t\tif pre > 0 {\r\n\t\t\tpost, err = syscall.Getxattr(path, xattr, dest)\r\n\t\t\tif err != nil || post < 0 {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t}\r\n\t\tif post != pre {\r\n\t\t\treturn nil, e1\r\n\t\t}\r\n\t\txattrs[xattr] = string(dest)\r\n\t}\r\n\treturn xattrs, nil\r\n}","code-length":525,"reference":"\/\/ GetAllXattr retrieves all extended attributes associated with a file,\n\/\/ directory or symbolic link.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetErrno(err error) (errno error, iserrno bool) {\r\n\tsysErr, ok := err.(*os.SyscallError)\r\n\tif ok {\r\n\t\treturn sysErr.Err, true\r\n\t}\r\n\tpathErr, ok := err.(*os.PathError)\r\n\tif ok {\r\n\t\treturn pathErr.Err, true\r\n\t}\r\n\ttmpErrno, ok := err.(syscall.Errno)\r\n\tif ok {\r\n\t\treturn tmpErrno, true\r\n\t}\r\n\treturn nil, false\r\n}","code-length":149,"reference":"\/\/ Detect whether err is an errno.","result":"Get errno from syscall.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Uname() (*Utsname, error) {\r\n\t\r\n\tuname := syscall.Utsname{}\r\n\terr := syscall.Uname(&uname)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &Utsname{\r\n\t\tSysname:    intArrayToString(uname.Sysname),\r\n\t\tNodename:   intArrayToString(uname.Nodename),\r\n\t\tRelease:    intArrayToString(uname.Release),\r\n\t\tVersion:    intArrayToString(uname.Version),\r\n\t\tMachine:    intArrayToString(uname.Machine),\r\n\t\tDomainname: intArrayToString(uname.Domainname),\r\n\t}, nil\r\n}","code-length":191,"reference":"\/\/ Uname returns Utsname as strings","result":"Get the Utsname of the current process.","score":[0.1615,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterStmt(sql string) int {\r\n\tcode := len(stmts)\r\n\tstmts[code] = sql\r\n\treturn code\r\n}","code-length":44,"reference":"\/\/ RegisterStmt register a SQL statement.\n\/\/\n\/\/ Registered statements will be prepared upfront and re-used, to speed up\n\/\/ execution.\n\/\/\n\/\/ Return a unique registration code.","result":"Register statements.","score":[0,0.0197]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PrepareStmts(db *sql.DB) (map[int]*sql.Stmt, error) {\r\n\tindex := map[int]*sql.Stmt{}\r\n\tfor code, sql := range stmts {\r\n\t\tstmt, err := db.Prepare(sql)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, errors.Wrapf(err, \"%q\", sql)\r\n\t\t}\r\n\t\tindex[code] = stmt\r\n\t}\r\n\treturn index, nil\r\n}","code-length":127,"reference":"\/\/ PrepareStmts prepares all registered statements and returns an index from\n\/\/ statement code to prepared statement object.","result":"Prepare statements in the database.","score":[0.0178,0.0599]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewGateway(db *db.Node, cert *shared.CertInfo, options ...Option) (*Gateway, error) {\r\n\tctx, cancel := context.WithCancel(context.Background())\r\n\to := newOptions()\r\n\tfor _, option := range options {\r\n\t\toption(o)\r\n\t}\r\n\tgateway := &Gateway{\r\n\t\tdb:        db,\r\n\t\tcert:      cert,\r\n\t\toptions:   o,\r\n\t\tctx:       ctx,\r\n\t\tcancel:    cancel,\r\n\t\tupgradeCh: make(chan struct{}, 16),\r\n\t\tacceptCh:  make(chan net.Conn),\r\n\t\tstore:     &dqliteServerStore{},\r\n\t}\r\n\terr := gateway.init()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn gateway, nil\r\n}","code-length":225,"reference":"\/\/ NewGateway creates a new Gateway for managing access to the dqlite cluster.\n\/\/\n\/\/ When a new gateway is created, the node-level database is queried to check\n\/\/ what kind of role this node plays and if it's exposed over the network. It\n\/\/ will initialize internal data structures accordingly, for example starting a\n\/\/ dqlite driver if this node is a database node.\n\/\/\n\/\/ After creation, the Daemon is expected to expose whatever http handlers the\n\/\/ HandlerFuncs method returns and to access the dqlite cluster using the gRPC\n\/\/ dialer returned by the Dialer method.","result":"Create a new connection to the database.","score":[0.0,0.0278]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Gateway) DialFunc() dqlite.DialFunc {\r\n\treturn func(ctx context.Context, address string) (net.Conn, error) {\r\n\t\t\r\n\t\tif g.memoryDial != nil {\r\n\t\t\treturn g.memoryDial(ctx, address)\r\n\t\t}\r\n\t\treturn dqliteNetworkDial(ctx, address, g.cert)\r\n\t}\r\n}","code-length":105,"reference":"\/\/ DialFunc returns a dial function that can be used to connect to one of the\n\/\/ dqlite nodes.","result":"Connect to a specific address.","score":[0.0174,0.1452]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Gateway) Shutdown() error {\r\n\tlogger.Debugf(\"Stop database gateway\")\r\n\tif g.raft != nil {\r\n\t\terr := g.raft.Shutdown()\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Failed to shutdown raft\")\r\n\t\t}\r\n\t}\r\n\tif g.server != nil {\r\n\t\tg.Sync()\r\n\t\tg.server.Close()\r\n\t\t\r\n\t\t\r\n\t\tg.memoryDial = nil\r\n\t}\r\n\treturn nil\r\n}","code-length":143,"reference":"\/\/ Shutdown this gateway, stopping the gRPC server and possibly the raft factory.","result":"Shutdown the database gateway.","score":[0.04,0.0826]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Gateway) Sync() {\r\n\tif g.server == nil {\r\n\t\treturn\r\n\t}\r\n\tdir := filepath.Join(g.db.Dir(), \"global\")\r\n\terr := g.server.Dump(\"db.bin\", dir)\r\n\tif err != nil {\r\n\t\t\r\n\t\tlogger.Warnf(\"Failed to dump database to disk: %v\", err)\r\n\t}\r\n}","code-length":111,"reference":"\/\/ Sync dumps the content of the database to disk. This is useful for\n\/\/ inspection purposes, and it's also needed by the activateifneeded command so\n\/\/ it can inspect the database in order to decide whether to activate the\n\/\/ daemon or not.","result":"Sync the database.","score":[0.0,0.0251]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Gateway) Reset(cert *shared.CertInfo) error {\r\n\terr := g.Shutdown()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = os.RemoveAll(filepath.Join(g.db.Dir(), \"global\"))\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = g.db.Transaction(func(tx *db.NodeTx) error {\r\n\t\treturn tx.RaftNodesReplace(nil)\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tg.cert = cert\r\n\treturn g.init()\r\n}","code-length":172,"reference":"\/\/ Reset the gateway, shutting it down and starting against from scratch using\n\/\/ the given certificate.\n\/\/\n\/\/ This is used when disabling clustering on a node.","result":"Reset the gateway.","score":[0.0001,0.0392]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Gateway) LeaderAddress() (string, error) {\r\n\t\r\n\tif g.memoryDial != nil {\r\n\t\treturn \"\", fmt.Errorf(\"Node is not clustered\")\r\n\t}\r\n\tctx, cancel := context.WithTimeout(g.ctx, 5*time.Second)\r\n\tdefer cancel()\r\n\t\r\n\t\r\n\tif g.raft != nil {\r\n\t\tfor ctx.Err() == nil {\r\n\t\t\taddress := string(g.raft.Raft().Leader())\r\n\t\t\tif address != \"\" {\r\n\t\t\t\treturn address, nil\r\n\t\t\t}\r\n\t\t\ttime.Sleep(time.Second)\r\n\t\t}\r\n\t\treturn \"\", ctx.Err()\r\n\t}\r\n\t\r\n\t\r\n\tconfig, err := tlsClientConfig(g.cert)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\taddresses := []string{}\r\n\terr = g.db.Transaction(func(tx *db.NodeTx) error {\r\n\t\tnodes, err := tx.RaftNodes()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tfor _, node := range nodes {\r\n\t\t\taddresses = append(addresses, node.Address)\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn \"\", errors.Wrap(err, \"Failed to fetch raft nodes addresses\")\r\n\t}\r\n\tif len(addresses) == 0 {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\treturn \"\", fmt.Errorf(\"No raft node known\")\r\n\t}\r\n\tfor _, address := range addresses {\r\n\t\turl := fmt.Sprintf(\"https:\r\n\t\trequest, err := http.NewRequest(\"GET\", url, nil)\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", err\r\n\t\t}\r\n\t\trequest = request.WithContext(ctx)\r\n\t\tclient := &http.Client{Transport: &http.Transport{TLSClientConfig: config}}\r\n\t\tresponse, err := client.Do(request)\r\n\t\tif err != nil {\r\n\t\t\tlogger.Debugf(\"Failed to fetch leader address from %s\", address)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif response.StatusCode != http.StatusOK {\r\n\t\t\tlogger.Debugf(\"Request for leader address from %s failed\", address)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tinfo := map[string]string{}\r\n\t\terr = shared.ReadToJSON(response.Body, &info)\r\n\t\tif err != nil {\r\n\t\t\tlogger.Debugf(\"Failed to parse leader address from %s\", address)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tleader := info[\"leader\"]\r\n\t\tif leader == \"\" {\r\n\t\t\tlogger.Debugf(\"Raft node %s returned no leader address\", address)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\treturn leader, nil\r\n\t}\r\n\treturn \"\", fmt.Errorf(\"RAFT cluster is unavailable\")\r\n}","code-length":741,"reference":"\/\/ LeaderAddress returns the address of the current raft leader.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Gateway) waitLeadership() error {\r\n\tn := 80\r\n\tsleep := 250 * time.Millisecond\r\n\tfor i := 0; i < n; i++ {\r\n\t\tif g.raft.raft.State() == raft.Leader {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\ttime.Sleep(sleep)\r\n\t}\r\n\treturn fmt.Errorf(\"RAFT node did not self-elect within %s\", time.Duration(n)*sleep)\r\n}","code-length":128,"reference":"\/\/ Wait for the raft node to become leader. Should only be used by Bootstrap,\n\/\/ since we know that we'll self elect.","result":"Wait for leadership.","score":[0.0007,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Gateway) currentRaftNodes() ([]db.RaftNode, error) {\r\n\tif g.raft == nil {\r\n\t\treturn nil, raft.ErrNotLeader\r\n\t}\r\n\tservers, err := g.raft.Servers()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tprovider := raftAddressProvider{db: g.db}\r\n\tnodes := make([]db.RaftNode, len(servers))\r\n\tfor i, server := range servers {\r\n\t\taddress, err := provider.ServerAddr(server.ID)\r\n\t\tif err != nil {\r\n\t\t\tif err != db.ErrNoSuchObject {\r\n\t\t\t\treturn nil, errors.Wrap(err, \"Failed to fetch raft server address\")\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\taddress = server.Address\r\n\t\t}\r\n\t\tid, err := strconv.Atoi(string(server.ID))\r\n\t\tif err != nil {\r\n\t\t\treturn nil, errors.Wrap(err, \"Non-numeric server ID\")\r\n\t\t}\r\n\t\tnodes[i].ID = int64(id)\r\n\t\tnodes[i].Address = string(address)\r\n\t}\r\n\treturn nodes, nil\r\n}","code-length":318,"reference":"\/\/ Return information about the LXD nodes that a currently part of the raft\n\/\/ cluster, as configured in the raft log. It returns an error if this node is\n\/\/ not the leader.","result":"Generate the code.","score":[0.0,0.0162]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Gateway) cachedRaftNodes() ([]string, error) {\r\n\tvar addresses []string\r\n\terr := g.db.Transaction(func(tx *db.NodeTx) error {\r\n\t\tvar err error\r\n\t\taddresses, err = tx.RaftNodeAddresses()\r\n\t\treturn err\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Failed to fetch raft nodes\")\r\n\t}\r\n\treturn addresses, nil\r\n}","code-length":130,"reference":"\/\/ Return the addresses of the raft nodes as stored in the node-level\n\/\/ database.\n\/\/\n\/\/ These values might leg behind the actual values, and are refreshed\n\/\/ periodically during heartbeats.","result":"Cache the raft nodes in the cache.","score":[0.0114,0.1261]}
{"code":"\/*is used to<extra_id_0>\r\nfunc dqliteMemoryDial(listener net.Listener) dqlite.DialFunc {\r\n\treturn func(ctx context.Context, address string) (net.Conn, error) {\r\n\t\treturn net.Dial(\"unix\", listener.Addr().String())\r\n\t}\r\n}","code-length":72,"reference":"\/\/ Create a dial function that connects to the given listener.","result":"Avoid memory leak.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DqliteLog(l dqlite.LogLevel, format string, a ...interface{}) {\r\n\tformat = fmt.Sprintf(\"Dqlite: %s\", format)\r\n\tswitch l {\r\n\tcase dqlite.LogDebug:\r\n\t\tlogger.Debugf(format, a...)\r\n\tcase dqlite.LogInfo:\r\n\t\tlogger.Debugf(format, a...)\r\n\tcase dqlite.LogWarn:\r\n\t\tlogger.Warnf(format, a...)\r\n\tcase dqlite.LogError:\r\n\t\tlogger.Errorf(format, a...)\r\n\t}\r\n}","code-length":151,"reference":"\/\/ DqliteLog redirects dqlite's logs to our own logger","result":"Log queries.","score":[0,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Response) MetadataAsMap() (map[string]interface{}, error) {\r\n\tret := map[string]interface{}{}\r\n\terr := r.MetadataAsStruct(&ret)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn ret, nil\r\n}","code-length":86,"reference":"\/\/ MetadataAsMap parses the Response metadata into a map","result":"Generate the response metadata.","score":[0.0915,0.2206]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Response) MetadataAsOperation() (*Operation, error) {\r\n\top := Operation{}\r\n\terr := r.MetadataAsStruct(&op)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &op, nil\r\n}","code-length":78,"reference":"\/\/ MetadataAsOperation turns the Response metadata into an Operation","result":"Generate the response metadata.","score":[0.0915,0.2206]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Response) MetadataAsStringSlice() ([]string, error) {\r\n\tsl := []string{}\r\n\terr := r.MetadataAsStruct(&sl)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn sl, nil\r\n}","code-length":78,"reference":"\/\/ MetadataAsStringSlice parses the Response metadata into a slice of string","result":"Parse the response metadata.","score":[0.0555,0.2859]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Response) MetadataAsStruct(target interface{}) error {\r\n\treturn json.Unmarshal(r.Metadata, &target)\r\n}","code-length":43,"reference":"\/\/ MetadataAsStruct parses the Response metadata into a provided struct","result":"Generate the code.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *CSVReport) Load() error {\r\n\tfile, err := os.Open(r.Filename)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer file.Close()\r\n\treader := csv.NewReader(file)\r\n\tfor line := 1; err != io.EOF; line++ {\r\n\t\trecord, err := reader.Read()\r\n\t\tif err == io.EOF {\r\n\t\t\tbreak\r\n\t\t} else if err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\terr = r.addRecord(record)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tlogf(\"Loaded report file %s\", r.Filename)\r\n\treturn nil\r\n}","code-length":201,"reference":"\/\/ Load reads current content of the filename and loads records.","result":"Load the report file .","score":[0.0861,0.0962]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *CSVReport) Write() error {\r\n\tfile, err := os.OpenFile(r.Filename, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0640)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer file.Close()\r\n\twriter := csv.NewWriter(file)\r\n\terr = writer.WriteAll(r.records)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tlogf(\"Written report file %s\", r.Filename)\r\n\treturn nil\r\n}","code-length":154,"reference":"\/\/ Write writes current records to file.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *CSVReport) AddRecord(label string, elapsed time.Duration) error {\r\n\tif len(r.records) == 0 {\r\n\t\tr.addRecord(csvFields)\r\n\t}\r\n\trecord := []string{\r\n\t\tfmt.Sprintf(\"%d\", time.Now().UnixNano()\/int64(time.Millisecond)),\r\n\t\tfmt.Sprintf(\"%d\", elapsed\/time.Millisecond),\r\n\t\tlabel,\r\n\t\t\"\",\r\n\t\t\"true\",\r\n\t}\r\n\treturn r.addRecord(record)\r\n}","code-length":151,"reference":"\/\/ AddRecord adds a record to the report.","result":"Add a record to the report.","score":[0.5757,0.7675]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadConfig(path string) (*Config, error) {\r\n\t\r\n\tcontent, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"Unable to read the configuration file: %v\", err)\r\n\t}\r\n\t\r\n\tc := NewConfig(filepath.Dir(path), false)\r\n\terr = yaml.Unmarshal(content, &c)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"Unable to decode the configuration: %v\", err)\r\n\t}\r\n\tfor k, r := range c.Remotes {\r\n\t\tif !r.Public && r.AuthType == \"\" {\r\n\t\t\tr.AuthType = \"tls\"\r\n\t\t\tc.Remotes[k] = r\r\n\t\t}\r\n\t}\r\n\t\r\n\tif c.Remotes == nil {\r\n\t\tc.Remotes = make(map[string]Remote)\r\n\t}\r\n\t\r\n\tfor k, v := range StaticRemotes {\r\n\t\tif c.Remotes[k].Project != \"\" {\r\n\t\t\tv.Project = c.Remotes[k].Project\r\n\t\t}\r\n\t\tc.Remotes[k] = v\r\n\t}\r\n\t\r\n\t\r\n\timages, ok := c.Remotes[\"images\"]\r\n\tif ok && images.Protocol != ImagesRemote.Protocol && images.Addr == ImagesRemote.Addr {\r\n\t\tc.Remotes[\"images\"] = ImagesRemote\r\n\t\tc.SaveConfig(path)\r\n\t}\r\n\treturn c, nil\r\n}","code-length":395,"reference":"\/\/ LoadConfig reads the configuration from the config path; if the path does\n\/\/ not exist, it returns a default configuration.","result":"Load the configuration file.","score":[0.0064,0.0518]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) SaveConfig(path string) error {\r\n\t\r\n\tconf := Config{}\r\n\terr := shared.DeepCopy(c, &conf)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"Unable to copy the configuration: %v\", err)\r\n\t}\r\n\t\r\n\tfor k := range StaticRemotes {\r\n\t\tif k == \"local\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tdelete(conf.Remotes, k)\r\n\t}\r\n\t\r\n\tf, err := os.Create(path)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"Unable to create the configuration file: %v\", err)\r\n\t}\r\n\tdefer f.Close()\r\n\t\r\n\tdata, err := yaml.Marshal(conf)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"Unable to marshal the configuration: %v\", err)\r\n\t}\r\n\t_, err = f.Write(data)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"Unable to write the configuration: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":289,"reference":"\/\/ SaveConfig writes the provided configuration to the config file.","result":"Save the configuration file.","score":[0.0938,0.2128]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l ChrootLoader) Get(path string) (io.Reader, error) {\r\n\t\r\n\tpath, err := filepath.EvalSymlinks(path)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tbasePath, err := filepath.EvalSymlinks(l.Path)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tif !strings.HasPrefix(path, basePath) {\r\n\t\treturn nil, fmt.Errorf(\"Attempting to access a file outside the container\")\r\n\t}\r\n\t\r\n\tbuf, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn bytes.NewReader(buf), nil\r\n}","code-length":198,"reference":"\/\/ Get reads the path's content from your local filesystem.","result":"Load the file in the container.","score":[0.0991,0.0521]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) ConfigPath(paths ...string) string {\r\n\tpath := []string{c.ConfigDir}\r\n\tpath = append(path, paths...)\r\n\treturn filepath.Join(path...)\r\n}","code-length":61,"reference":"\/\/ ConfigPath returns a joined path of the configuration directory and passed arguments","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) ServerCertPath(remote string) string {\r\n\treturn c.ConfigPath(\"servercerts\", fmt.Sprintf(\"%s.crt\", remote))\r\n}","code-length":50,"reference":"\/\/ ServerCertPath returns the path for the remote's server certificate","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewConfig(configDir string, defaults bool) *Config {\r\n\tconfig := &Config{ConfigDir: configDir}\r\n\tif defaults {\r\n\t\tconfig.Remotes = DefaultRemotes\r\n\t\tconfig.DefaultRemote = \"local\"\r\n\t}\r\n\treturn config\r\n}","code-length":78,"reference":"\/\/ NewConfig returns a Config, optionally using default remotes.","result":"Create a new config.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *migrationSourceWs) checkForPreDumpSupport() (bool, int) {\r\n\t\r\n\t\r\n\tcriuMigrationArgs := CriuMigrationArgs{\r\n\t\tcmd:          lxc.MIGRATE_FEATURE_CHECK,\r\n\t\tstateDir:     \"\",\r\n\t\tfunction:     \"feature-check\",\r\n\t\tstop:         false,\r\n\t\tactionScript: false,\r\n\t\tdumpDir:      \"\",\r\n\t\tpreDumpDir:   \"\",\r\n\t\tfeatures:     lxc.FEATURE_MEM_TRACK,\r\n\t}\r\n\terr := s.container.Migrate(&criuMigrationArgs)\r\n\tif err != nil {\r\n\t\t\r\n\t\t\r\n\t\treturn false, 0\r\n\t}\r\n\t\r\n\t\r\n\tuse_pre_dumps := true\r\n\t\r\n\ttmp := s.container.ExpandedConfig()[\"migration.incremental.memory\"]\r\n\tif tmp != \"\" {\r\n\t\tuse_pre_dumps = shared.IsTrue(tmp)\r\n\t}\r\n\tvar max_iterations int\r\n\t\r\n\t\r\n\t\r\n\ttmp = s.container.ExpandedConfig()[\"migration.incremental.memory.iterations\"]\r\n\tif tmp != \"\" {\r\n\t\tmax_iterations, _ = strconv.Atoi(tmp)\r\n\t} else {\r\n\t\t\r\n\t\tmax_iterations = 10\r\n\t}\r\n\tif max_iterations > 999 {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tmax_iterations = 999\r\n\t}\r\n\tlogger.Debugf(\"Using maximal %d iterations for pre-dumping\", max_iterations)\r\n\treturn use_pre_dumps, max_iterations\r\n}","code-length":418,"reference":"\/\/ Check if CRIU supports pre-dumping and number of\n\/\/ pre-dump iterations","result":"Check if the container has pre.","score":[0.1004,0.1645]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *migrationSourceWs) preDumpLoop(args *preDumpLoopArgs) (bool, error) {\r\n\t\r\n\tcriuMigrationArgs := CriuMigrationArgs{\r\n\t\tcmd:          lxc.MIGRATE_PRE_DUMP,\r\n\t\tstop:         false,\r\n\t\tactionScript: false,\r\n\t\tpreDumpDir:   args.preDumpDir,\r\n\t\tdumpDir:      args.dumpDir,\r\n\t\tstateDir:     args.checkpointDir,\r\n\t\tfunction:     \"migration\",\r\n\t}\r\n\tlogger.Debugf(\"Doing another pre-dump in %s\", args.preDumpDir)\r\n\tfinal := args.final\r\n\terr := s.container.Migrate(&criuMigrationArgs)\r\n\tif err != nil {\r\n\t\treturn final, err\r\n\t}\r\n\t\r\n\tctName, _, _ := containerGetParentAndSnapshotName(s.container.Name())\r\n\tstate := s.container.DaemonState()\r\n\terr = RsyncSend(ctName, shared.AddSlash(args.checkpointDir), s.criuConn, nil, args.rsyncFeatures, args.bwlimit, state.OS.ExecPath)\r\n\tif err != nil {\r\n\t\treturn final, err\r\n\t}\r\n\t\r\n\tdumpPath := shared.AddSlash(args.checkpointDir)\r\n\tdumpPath += shared.AddSlash(args.dumpDir)\r\n\twritten, skipped_parent, err := readCriuStatsDump(dumpPath)\r\n\tif err != nil {\r\n\t\treturn final, err\r\n\t}\r\n\tlogger.Debugf(\"CRIU pages written %d\", written)\r\n\tlogger.Debugf(\"CRIU pages skipped %d\", skipped_parent)\r\n\ttotal_pages := written + skipped_parent\r\n\tpercentage_skipped := int(100 - ((100 * written) \/ total_pages))\r\n\tlogger.Debugf(\"CRIU pages skipped percentage %d%%\", percentage_skipped)\r\n\t\r\n\t\r\n\tvar threshold int\r\n\ttmp := s.container.ExpandedConfig()[\"migration.incremental.memory.goal\"]\r\n\tif tmp != \"\" {\r\n\t\tthreshold, _ = strconv.Atoi(tmp)\r\n\t} else {\r\n\t\t\r\n\t\tthreshold = 70\r\n\t}\r\n\tif percentage_skipped > threshold {\r\n\t\tlogger.Debugf(\"Memory pages skipped (%d%%) due to pre-copy is larger than threshold (%d%%)\", percentage_skipped, threshold)\r\n\t\tlogger.Debugf(\"This was the last pre-dump; next dump is the final dump\")\r\n\t\tfinal = true\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tlogger.Debugf(\"Sending another header\")\r\n\tsync := migration.MigrationSync{\r\n\t\tFinalPreDump: proto.Bool(final),\r\n\t}\r\n\tdata, err := proto.Marshal(&sync)\r\n\tif err != nil {\r\n\t\treturn final, err\r\n\t}\r\n\terr = s.criuConn.WriteMessage(websocket.BinaryMessage, data)\r\n\tif err != nil {\r\n\t\ts.sendControl(err)\r\n\t\treturn final, err\r\n\t}\r\n\tlogger.Debugf(\"Sending another header done\")\r\n\treturn final, nil\r\n}","code-length":796,"reference":"\/\/ The function preDumpLoop is the main logic behind the pre-copy migration.\n\/\/ This function contains the actual pre-dump, the corresponding rsync\n\/\/ transfer and it tells the outer loop to abort if the threshold\n\/\/ of memory pages transferred by pre-dumping has been reached.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newRoot() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"lxd-generate\",\r\n\t\tShort: \"Code generation tool for LXD development\",\r\n\t\tLong: `This is the entry point for all \"go:generate\" directives\r\nused in LXD's source code.`,\r\n\t\tRunE: func(cmd *cobra.Command, args []string) error {\r\n\t\t\treturn fmt.Errorf(\"Not implemented\")\r\n\t\t},\r\n\t}\r\n\tcmd.AddCommand(newDb())\r\n\treturn cmd\r\n}","code-length":154,"reference":"\/\/ Return a new root command.","result":"Create a new root database.","score":[0.4052,0.4991]}
{"code":"\/*is used to<extra_id_0>\r\nfunc APIExtensionsCount() int {\r\n\tcount := len(APIExtensions)\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tartificialBump := os.Getenv(\"LXD_ARTIFICIALLY_BUMP_API_EXTENSIONS\")\r\n\tif artificialBump != \"\" {\r\n\t\tn, err := strconv.Atoi(artificialBump)\r\n\t\tif err == nil {\r\n\t\t\tcount += n\r\n\t\t}\r\n\t}\r\n\treturn count\r\n}","code-length":133,"reference":"\/\/ APIExtensionsCount returns the number of available API extensions.","result":"Count the number of API.","score":[0.2224,0.3424]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SelectURIs(stmt *sql.Stmt, f func(a ...interface{}) string, args ...interface{}) ([]string, error) {\r\n\trows, err := stmt.Query(args...)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrapf(err, \"Failed to query URIs\")\r\n\t}\r\n\tdefer rows.Close()\r\n\tcolumns, err := rows.Columns()\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Rows columns\")\r\n\t}\r\n\tparams := make([]interface{}, len(columns))\r\n\tdest := make([]interface{}, len(params))\r\n\tfor i := range params {\r\n\t\tparams[i] = \"\"\r\n\t\tdest[i] = &params[i]\r\n\t}\r\n\turis := []string{}\r\n\tfor rows.Next() {\r\n\t\terr := rows.Scan(dest...)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, errors.Wrapf(err, \"Failed to scan URI params\")\r\n\t\t}\r\n\t\turi := f(params...)\r\n\t\turis = append(uris, uri)\r\n\t}\r\n\terr = rows.Err()\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrapf(err, \"Failed to close URI result set\")\r\n\t}\r\n\treturn uris, nil\r\n}","code-length":345,"reference":"\/\/ SelectURIs returns a list of LXD API URI strings for the resource yielded by\n\/\/ the given query.\n\/\/\n\/\/ The f argument must be a function that formats the entity URI using the\n\/\/ columns yielded by the query.","result":"Query URIs in the database.","score":[0.0002,0.0267]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SelectStrings(tx *sql.Tx, query string, args ...interface{}) ([]string, error) {\r\n\tvalues := []string{}\r\n\tscan := func(rows *sql.Rows) error {\r\n\t\tvar value string\r\n\t\terr := rows.Scan(&value)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tvalues = append(values, value)\r\n\t\treturn nil\r\n\t}\r\n\terr := scanSingleColumn(tx, query, args, \"TEXT\", scan)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn values, nil\r\n}","code-length":169,"reference":"\/\/ SelectStrings executes a statement which must yield rows with a single string\n\/\/ column. It returns the list of column values.","result":"Select all strings in a transaction.","score":[0.0134,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc scanSingleColumn(tx *sql.Tx, query string, args []interface{}, typeName string, scan scanFunc) error {\r\n\trows, err := tx.Query(query, args...)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer rows.Close()\r\n\tfor rows.Next() {\r\n\t\terr := scan(rows)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\terr = rows.Err()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":156,"reference":"\/\/ Execute the given query and ensure that it yields rows with a single column\n\/\/ of the given database type. For every row yielded, execute the given\n\/\/ scanner.","result":"Scan a single column.","score":[0.0007,0.0684]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LazyHandler(h Handler) Handler {\r\n\treturn FuncHandler(func(r *Record) error {\r\n\t\t\r\n\t\t\r\n\t\thadErr := false\r\n\t\tfor i := 1; i < len(r.Ctx); i += 2 {\r\n\t\t\tlz, ok := r.Ctx[i].(Lazy)\r\n\t\t\tif ok {\r\n\t\t\t\tv, err := evaluateLazy(lz)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\thadErr = true\r\n\t\t\t\t\tr.Ctx[i] = err\r\n\t\t\t\t} else {\r\n\t\t\t\t\tif cs, ok := v.(stack.Trace); ok {\r\n\t\t\t\t\t\tv = cs.TrimBelow(stack.Call(r.CallPC[0])).\r\n\t\t\t\t\t\t\tTrimRuntime()\r\n\t\t\t\t\t}\r\n\t\t\t\t\tr.Ctx[i] = v\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\tif hadErr {\r\n\t\t\tr.Ctx = append(r.Ctx, errorKey, \"bad lazy\")\r\n\t\t}\r\n\t\treturn h.Log(r)\r\n\t})\r\n}","code-length":278,"reference":"\/\/ LazyHandler writes all values to the wrapped handler after evaluating\n\/\/ any lazy functions in the record's context. It is already wrapped\n\/\/ around StreamHandler and SyslogHandler in this library, you'll only need\n\/\/ it if you write your own Handler.","result":"Wrap lazy expressions in a function .","score":[0.0013,0.0519]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Callers() Trace {\r\n\tpcs := poolBuf()\r\n\tpcs = pcs[:cap(pcs)]\r\n\tn := runtime.Callers(2, pcs)\r\n\tcs := make([]Call, n)\r\n\tfor i, pc := range pcs[:n] {\r\n\t\tcs[i] = Call(pc)\r\n\t}\r\n\tputPoolBuf(pcs)\r\n\treturn cs\r\n}","code-length":112,"reference":"\/\/ Callers returns a Trace for the current goroutine with element 0\n\/\/ identifying the calling function.","result":"Get the call stack trace trace.","score":[0.0309,0.1607]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pc Call) name() string {\r\n\tpcFix := uintptr(pc) - 1\r\n\tfn := runtime.FuncForPC(pcFix)\r\n\tif fn == nil {\r\n\t\treturn \"???\"\r\n\t}\r\n\treturn fn.Name()\r\n}","code-length":75,"reference":"\/\/ name returns the import path qualified name of the function containing the\n\/\/ call.","result":"Get the function name.","score":[0.0289,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pcs Trace) TrimBelow(pc Call) Trace {\r\n\tfor len(pcs) > 0 && pcs[0] != pc {\r\n\t\tpcs = pcs[1:]\r\n\t}\r\n\treturn pcs\r\n}","code-length":65,"reference":"\/\/ TrimBelow returns a slice of the Trace with all entries below pc removed.","result":"Trim the trace.","score":[0.0104,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pcs Trace) TrimAbove(pc Call) Trace {\r\n\tfor len(pcs) > 0 && pcs[len(pcs)-1] != pc {\r\n\t\tpcs = pcs[:len(pcs)-1]\r\n\t}\r\n\treturn pcs\r\n}","code-length":75,"reference":"\/\/ TrimAbove returns a slice of the Trace with all entries above pc removed.","result":"Trim trace lines.","score":[0,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pcs Trace) TrimBelowName(name string) Trace {\r\n\tfor len(pcs) > 0 && pcs[0].name() != name {\r\n\t\tpcs = pcs[1:]\r\n\t}\r\n\treturn pcs\r\n}","code-length":68,"reference":"\/\/ TrimBelowName returns a slice of the Trace with all entries below the\n\/\/ lowest with function name name removed.","result":"Trim the name of the trace.","score":[0.0315,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pcs Trace) TrimAboveName(name string) Trace {\r\n\tfor len(pcs) > 0 && pcs[len(pcs)-1].name() != name {\r\n\t\tpcs = pcs[:len(pcs)-1]\r\n\t}\r\n\treturn pcs\r\n}","code-length":78,"reference":"\/\/ TrimAboveName returns a slice of the Trace with all entries above the\n\/\/ highest with function name name removed.","result":"Trim the trace .","score":[0.0059,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pcs Trace) TrimRuntime() Trace {\r\n\tfor len(pcs) > 0 && inGoroot(pcs[len(pcs)-1].file()) {\r\n\t\tpcs = pcs[:len(pcs)-1]\r\n\t}\r\n\treturn pcs\r\n}","code-length":78,"reference":"\/\/ TrimRuntime returns a slice of the Trace with the topmost entries from the\n\/\/ go runtime removed. It considers any calls originating from files under\n\/\/ GOROOT as part of the runtime.","result":"Trim the runtime trace.","score":[0.0003,0.0332]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetCaps(path string) ([]byte, error) {\r\n\txattrs, err := shared.GetAllXattr(path)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvalueStr, ok := xattrs[\"security.capability\"]\r\n\tif !ok {\r\n\t\treturn nil, nil\r\n\t}\r\n\treturn []byte(valueStr), nil\r\n}","code-length":107,"reference":"\/\/ GetCaps extracts the list of capabilities effective on the file","result":"Get the capabilities of a container.","score":[0.1104,0.1429]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetCaps(path string, caps []byte, uid int64) error {\r\n\tcpath := C.CString(path)\r\n\tdefer C.free(unsafe.Pointer(cpath))\r\n\tccaps := C.CString(string(caps))\r\n\tdefer C.free(unsafe.Pointer(ccaps))\r\n\tr := C.set_vfs_ns_caps(cpath, ccaps, C.ssize_t(len(caps)), C.uint32_t(uid))\r\n\tif r != 0 {\r\n\t\treturn fmt.Errorf(\"Failed to apply capabilities to: %s\", path)\r\n\t}\r\n\treturn nil\r\n}","code-length":169,"reference":"\/\/ SetCaps applies the caps for a particular root uid","result":"Set the capabilities of a path.","score":[0.1179,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pt *ProgressReader) Read(p []byte) (int, error) {\r\n\t\r\n\tn, err := pt.ReadCloser.Read(p)\r\n\t\r\n\tif pt.Tracker != nil {\r\n\t\tpt.Tracker.total += int64(n)\r\n\t\tpt.Tracker.update(n)\r\n\t}\r\n\treturn n, err\r\n}","code-length":101,"reference":"\/\/ Read in ProgressReader is the same as io.Read","result":"Read progress.","score":[0.0151,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Supported(path string) (bool, error) {\r\n\t\r\n\tdevPath, err := devForPath(path)\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\t\r\n\tcDevPath := C.CString(devPath)\r\n\tdefer C.free(unsafe.Pointer(cDevPath))\r\n\treturn C.quota_supported(cDevPath) == 0, nil\r\n}","code-length":113,"reference":"\/\/ Supported check if the given path supports project quotas","result":"Check quota usage.","score":[0,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetProject(path string) (uint32, error) {\r\n\t\r\n\tcPath := C.CString(path)\r\n\tdefer C.free(unsafe.Pointer(cPath))\r\n\tid := C.quota_get_path(cPath)\r\n\tif id < 0 {\r\n\t\treturn 0, fmt.Errorf(\"Failed to get project from '%s'\", path)\r\n\t}\r\n\treturn uint32(id), nil\r\n}","code-length":118,"reference":"\/\/ GetProject returns the project quota ID for the given path","result":"Get the project id from the path.","score":[0.1427,0.2978]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetProject(path string, id uint32) error {\r\n\t\r\n\tcPath := C.CString(path)\r\n\tdefer C.free(unsafe.Pointer(cPath))\r\n\tif C.quota_set_path(cPath, C.uint32_t(id)) != 0 {\r\n\t\treturn fmt.Errorf(\"Failed to set project id '%d' on '%s'\", id, path)\r\n\t}\r\n\treturn nil\r\n}","code-length":119,"reference":"\/\/ SetProject sets the project quota ID for the given path","result":"Set the project id on the path.","score":[0.1427,0.4208]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DeleteProject(path string, id uint32) error {\r\n\t\r\n\terr := SetProject(path, 0)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\terr = SetProjectQuota(path, id, 0)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":99,"reference":"\/\/ DeleteProject unsets the project id from the path and clears the quota for the project id","result":"Delete a project.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetProjectUsage(path string, id uint32) (int64, error) {\r\n\t\r\n\tdevPath, err := devForPath(path)\r\n\tif err != nil {\r\n\t\treturn -1, err\r\n\t}\r\n\t\r\n\tcDevPath := C.CString(devPath)\r\n\tdefer C.free(unsafe.Pointer(cDevPath))\r\n\tsize := C.quota_get_usage(cDevPath, C.uint32_t(id))\r\n\tif size < 0 {\r\n\t\treturn -1, fmt.Errorf(\"Failed to get project consumption for id '%d' on '%s'\", id, path)\r\n\t}\r\n\treturn int64(size), nil\r\n}","code-length":182,"reference":"\/\/ GetProjectUsage returns the current consumption","result":"Get project consumption.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetProjectQuota(path string, id uint32, bytes int64) error {\r\n\t\r\n\tdevPath, err := devForPath(path)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tcDevPath := C.CString(devPath)\r\n\tdefer C.free(unsafe.Pointer(cDevPath))\r\n\tif C.quota_set(cDevPath, C.uint32_t(id), C.int(bytes\/1024)) != 0 {\r\n\t\treturn fmt.Errorf(\"Failed to set project quota for id '%d' on '%s'\", id, path)\r\n\t}\r\n\treturn nil\r\n}","code-length":171,"reference":"\/\/ SetProjectQuota sets the quota on the project id","result":"Set the project quota on the specified path.","score":[0.3082,0.632]}
{"code":"\/*is used to<extra_id_0>\r\nfunc backupLoadByName(s *state.State, project, name string) (*backup, error) {\r\n\t\r\n\targs, err := s.Cluster.ContainerGetBackup(project, name)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Load backup from database\")\r\n\t}\r\n\t\r\n\tc, err := containerLoadById(s, args.ContainerID)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Load container from database\")\r\n\t}\r\n\t\r\n\treturn &backup{\r\n\t\tstate:            s,\r\n\t\tcontainer:        c,\r\n\t\tid:               args.ID,\r\n\t\tname:             name,\r\n\t\tcreationDate:     args.CreationDate,\r\n\t\texpiryDate:       args.ExpiryDate,\r\n\t\tcontainerOnly:    args.ContainerOnly,\r\n\t\toptimizedStorage: args.OptimizedStorage,\r\n\t}, nil\r\n}","code-length":246,"reference":"\/\/ Load a backup from the database","result":"Load a backup from the database.","score":[0.6801,0.7217]}
{"code":"\/*is used to<extra_id_0>\r\nfunc backupCreate(s *state.State, args db.ContainerBackupArgs, sourceContainer container) error {\r\n\t\r\n\terr := s.Cluster.ContainerBackupCreate(args)\r\n\tif err != nil {\r\n\t\tif err == db.ErrAlreadyDefined {\r\n\t\t\treturn fmt.Errorf(\"backup '%s' already exists\", args.Name)\r\n\t\t}\r\n\t\treturn errors.Wrap(err, \"Insert backup info into database\")\r\n\t}\r\n\t\r\n\tb, err := backupLoadByName(s, sourceContainer.Project(), args.Name)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Load backup object\")\r\n\t}\r\n\t\r\n\terr = sourceContainer.Storage().ContainerBackupCreate(*b, sourceContainer)\r\n\tif err != nil {\r\n\t\ts.Cluster.ContainerBackupRemove(args.Name)\r\n\t\treturn errors.Wrap(err, \"Backup storage\")\r\n\t}\r\n\treturn nil\r\n}","code-length":244,"reference":"\/\/ Create a new backup","result":"Create a backup in the container.","score":[0.3021,0.5011]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *backup) Rename(newName string) error {\r\n\toldBackupPath := shared.VarPath(\"backups\", b.name)\r\n\tnewBackupPath := shared.VarPath(\"backups\", newName)\r\n\t\r\n\tbackupsPath := shared.VarPath(\"backups\", b.container.Name())\r\n\tif !shared.PathExists(backupsPath) {\r\n\t\terr := os.MkdirAll(backupsPath, 0700)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\t\r\n\terr := os.Rename(oldBackupPath, newBackupPath)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tempty, _ := shared.PathIsEmpty(backupsPath)\r\n\tif empty {\r\n\t\terr := os.Remove(backupsPath)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\t\r\n\terr = b.state.Cluster.ContainerBackupRename(b.name, newName)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":293,"reference":"\/\/ Rename renames a container backup","result":"Rename a backup.","score":[0.1786,0.1754]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *backup) Delete() error {\r\n\treturn doBackupDelete(b.state, b.name, b.container.Name())\r\n}","code-length":44,"reference":"\/\/ Delete removes a container backup","result":"Delete backup.","score":[0.0677,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc backupFixStoragePool(c *db.Cluster, b backupInfo, useDefaultPool bool) error {\r\n\tvar poolName string\r\n\tif useDefaultPool {\r\n\t\t\r\n\t\t_, profile, err := c.ProfileGet(\"default\", \"default\")\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t_, v, err := shared.GetRootDiskDevice(profile.Devices)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tpoolName = v[\"pool\"]\r\n\t} else {\r\n\t\tpoolName = b.Pool\r\n\t}\r\n\t\r\n\t_, pool, err := c.StoragePoolGet(poolName)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tf := func(path string) error {\r\n\t\t\r\n\t\tbackup, err := slurpBackupFile(path)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\trootDiskDeviceFound := false\r\n\t\t\r\n\t\tbackup.Pool = pool\r\n\t\tif backup.Container.Devices != nil {\r\n\t\t\tdevName, _, err := shared.GetRootDiskDevice(backup.Container.Devices)\r\n\t\t\tif err == nil {\r\n\t\t\t\tbackup.Container.Devices[devName][\"pool\"] = poolName\r\n\t\t\t\trootDiskDeviceFound = true\r\n\t\t\t}\r\n\t\t}\r\n\t\tif backup.Container.ExpandedDevices != nil {\r\n\t\t\tdevName, _, err := shared.GetRootDiskDevice(backup.Container.ExpandedDevices)\r\n\t\t\tif err == nil {\r\n\t\t\t\tbackup.Container.ExpandedDevices[devName][\"pool\"] = poolName\r\n\t\t\t\trootDiskDeviceFound = true\r\n\t\t\t}\r\n\t\t}\r\n\t\tif !rootDiskDeviceFound {\r\n\t\t\treturn fmt.Errorf(\"No root device could be found\")\r\n\t\t}\r\n\t\tfile, err := os.Create(path)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdefer file.Close()\r\n\t\tdata, err := yaml.Marshal(&backup)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t_, err = file.Write(data)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\terr = f(shared.VarPath(\"storage-pools\", pool.Name, \"containers\", b.Name, \"backup.yaml\"))\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfor _, snap := range b.Snapshots {\r\n\t\terr = f(shared.VarPath(\"storage-pools\", pool.Name, \"containers-snapshots\", b.Name, snap,\r\n\t\t\t\"backup.yaml\"))\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":736,"reference":"\/\/ fixBackupStoragePool changes the pool information in the backup.yaml. This\n\/\/ is done only if the provided pool doesn't exist. In this case, the pool of\n\/\/ the default profile will be used.","result":"Code too long,keep in 512.","score":[0.0009,0.0166]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Count(tx *sql.Tx, table string, where string, args ...interface{}) (int, error) {\r\n\tstmt := fmt.Sprintf(\"SELECT COUNT(*) FROM %s\", table)\r\n\tif where != \"\" {\r\n\t\tstmt += fmt.Sprintf(\" WHERE %s\", where)\r\n\t}\r\n\trows, err := tx.Query(stmt, args...)\r\n\tif err != nil {\r\n\t\treturn -1, err\r\n\t}\r\n\tdefer rows.Close()\r\n\t\r\n\tif !rows.Next() {\r\n\t\treturn -1, fmt.Errorf(\"no rows returned\")\r\n\t}\r\n\tvar count int\r\n\terr = rows.Scan(&count)\r\n\tif err != nil {\r\n\t\treturn -1, fmt.Errorf(\"failed to scan count column\")\r\n\t}\r\n\tif rows.Next() {\r\n\t\treturn -1, fmt.Errorf(\"more than one row returned\")\r\n\t}\r\n\terr = rows.Err()\r\n\tif err != nil {\r\n\t\treturn -1, err\r\n\t}\r\n\treturn count, nil\r\n}","code-length":279,"reference":"\/\/ Count returns the number of rows in the given table.","result":"Count rows.","score":[0.0056,0.0495]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CountAll(tx *sql.Tx) (map[string]int, error) {\r\n\ttables, err := SelectStrings(tx, \"SELECT name FROM sqlite_master WHERE type = 'table'\")\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Failed to fetch table names\")\r\n\t}\r\n\tcounts := map[string]int{}\r\n\tfor _, table := range tables {\r\n\t\tcount, err := Count(tx, table, \"\")\r\n\t\tif err != nil {\r\n\t\t\treturn nil, errors.Wrapf(err, \"Failed to count rows of %s\", table)\r\n\t\t}\r\n\t\tcounts[table] = count\r\n\t}\r\n\treturn counts, nil\r\n}","code-length":188,"reference":"\/\/ CountAll returns a map associating each table name in the database\n\/\/ with the total count of its rows.","result":"Count all tables.","score":[0,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc InitTLSConfig() *tls.Config {\r\n\treturn &tls.Config{\r\n\t\tMinVersion: tls.VersionTLS12,\r\n\t\tCipherSuites: []uint16{\r\n\t\t\ttls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,\r\n\t\t\ttls.TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA,\r\n\t\t\ttls.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,\r\n\t\t\ttls.TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA,\r\n\t\t\ttls.TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,\r\n\t\t\ttls.TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA,\r\n\t\t\ttls.TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,\r\n\t\t\ttls.TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,\r\n\t\t},\r\n\t\tPreferServerCipherSuites: true,\r\n\t}\r\n}","code-length":280,"reference":"\/\/ InitTLSConfig returns a tls.Config populated with default encryption\n\/\/ parameters. This is used as baseline config for both client and server\n\/\/ certificates used by LXD.","result":"Initialize the TLS configuration.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageLvm) copyContainerThinpool(target container, source container, readonly bool) error {\r\n\terr := s.createSnapshotContainer(target, source, readonly)\r\n\tif err != nil {\r\n\t\tlogger.Errorf(\"Error creating snapshot LV for copy: %s\", err)\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tLVFilesystem := s.getLvmFilesystem()\r\n\tpoolName := s.getOnDiskPoolName()\r\n\tcontainerName := target.Name()\r\n\tcontainerLvmName := containerNameToLVName(containerName)\r\n\tcontainerLvDevPath := getLvmDevPath(target.Project(), poolName,\r\n\t\tstoragePoolVolumeAPIEndpointContainers, containerLvmName)\r\n\t\r\n\t\r\n\t\r\n\tif LVFilesystem == \"btrfs\" {\r\n\t\tourUmount, err := s.ContainerUmount(source, source.Path())\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif ourUmount {\r\n\t\t\tdefer s.ContainerMount(source)\r\n\t\t}\r\n\t}\r\n\tmsg, err := fsGenerateNewUUID(LVFilesystem, containerLvDevPath)\r\n\tif err != nil {\r\n\t\tlogger.Errorf(\"Failed to create new \\\"%s\\\" UUID for container \\\"%s\\\" on storage pool \\\"%s\\\": %s\", LVFilesystem, containerName, s.pool.Name, msg)\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":367,"reference":"\/\/ Copy a container on a storage pool that does use a thinpool.","result":"Copy the contents of the container.","score":[0.0601,0.0407]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageLvm) copyContainerLv(target container, source container, readonly bool, refresh bool) error {\r\n\texists, err := storageLVExists(getLvmDevPath(target.Project(), s.getOnDiskPoolName(),\r\n\t\tstoragePoolVolumeAPIEndpointContainers, containerNameToLVName(target.Name())))\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif !exists {\r\n\t\terr := s.ContainerCreate(target)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\ttargetName := target.Name()\r\n\ttargetStart, err := target.StorageStart()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif targetStart {\r\n\t\tdefer target.StorageStop()\r\n\t}\r\n\tsourceName := source.Name()\r\n\tsourceStart, err := source.StorageStart()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif sourceStart {\r\n\t\tdefer source.StorageStop()\r\n\t}\r\n\tsourcePool, err := source.StoragePool()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tsourceContainerMntPoint := getContainerMountPoint(source.Project(), sourcePool, sourceName)\r\n\tif source.IsSnapshot() {\r\n\t\tsourceContainerMntPoint = getSnapshotMountPoint(source.Project(), sourcePool, sourceName)\r\n\t}\r\n\ttargetContainerMntPoint := getContainerMountPoint(target.Project(), s.pool.Name, targetName)\r\n\tif target.IsSnapshot() {\r\n\t\ttargetContainerMntPoint = getSnapshotMountPoint(source.Project(), s.pool.Name, targetName)\r\n\t}\r\n\tif source.IsRunning() {\r\n\t\terr = source.Freeze()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdefer source.Unfreeze()\r\n\t}\r\n\tbwlimit := s.pool.Config[\"rsync.bwlimit\"]\r\n\toutput, err := rsyncLocalCopy(sourceContainerMntPoint, targetContainerMntPoint, bwlimit)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to rsync container: %s: %s\", string(output), err)\r\n\t}\r\n\tif readonly {\r\n\t\ttargetLvmName := containerNameToLVName(targetName)\r\n\t\tpoolName := s.getOnDiskPoolName()\r\n\t\toutput, err := shared.TryRunCommand(\"lvchange\", \"-pr\", fmt.Sprintf(\"%s\/%s_%s\", poolName, storagePoolVolumeAPIEndpointContainers, targetLvmName))\r\n\t\tif err != nil {\r\n\t\t\tlogger.Errorf(\"Failed to make LVM snapshot \\\"%s\\\" read-write: %s\", targetName, output)\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":711,"reference":"\/\/ Copy a container on a storage pool that does not use a thinpool.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageLvm) copyContainer(target container, source container, refresh bool) error {\r\n\ttargetPool, err := target.StoragePool()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ttargetContainerMntPoint := getContainerMountPoint(target.Project(), targetPool, target.Name())\r\n\terr = createContainerMountpoint(targetContainerMntPoint, target.Path(), target.IsPrivileged())\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tsourcePool, err := source.StoragePool()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif s.useThinpool && targetPool == sourcePool && !refresh {\r\n\t\t\r\n\t\t\r\n\t\terr = s.copyContainerThinpool(target, source, false)\r\n\t} else {\r\n\t\t\r\n\t\t\r\n\t\terr = s.copyContainerLv(target, source, false, refresh)\r\n\t}\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = target.TemplateApply(\"copy\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":297,"reference":"\/\/ Copy an lvm container.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageLvm) copyVolume(sourcePool string, source string) error {\r\n\ttargetMntPoint := getStoragePoolVolumeMountPoint(s.pool.Name, s.volume.Name)\r\n\terr := os.MkdirAll(targetMntPoint, 0711)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif s.useThinpool && sourcePool == s.pool.Name {\r\n\t\terr = s.copyVolumeThinpool(source, s.volume.Name, false)\r\n\t} else {\r\n\t\terr = s.copyVolumeLv(sourcePool, source, s.volume.Name, false)\r\n\t}\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":196,"reference":"\/\/ Copy an LVM custom volume.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolSimpleStreams) GetPrivateImage(fingerprint string, secret string) (*api.Image, string, error) {\r\n\treturn nil, \"\", fmt.Errorf(\"Private images aren't supported by the simplestreams protocol\")\r\n}","code-length":64,"reference":"\/\/ GetPrivateImage isn't relevant for the simplestreams protocol","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolSimpleStreams) GetPrivateImageFile(fingerprint string, secret string, req ImageFileRequest) (*ImageFileResponse, error) {\r\n\treturn nil, fmt.Errorf(\"Private images aren't supported by the simplestreams protocol\")\r\n}","code-length":67,"reference":"\/\/ GetPrivateImageFile isn't relevant for the simplestreams protocol","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolSimpleStreams) GetImageAliasNames() ([]string, error) {\r\n\t\r\n\taliases, err := r.ssClient.ListAliases()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tnames := []string{}\r\n\tfor _, alias := range aliases {\r\n\t\tnames = append(names, alias.Name)\r\n\t}\r\n\treturn names, nil\r\n}","code-length":117,"reference":"\/\/ GetImageAliasNames returns the list of available alias names","result":"Get image alias names.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ProtoRecv(ws *websocket.Conn, msg proto.Message) error {\r\n\tmt, r, err := ws.NextReader()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif mt != websocket.BinaryMessage {\r\n\t\treturn fmt.Errorf(\"Only binary messages allowed\")\r\n\t}\r\n\tbuf, err := ioutil.ReadAll(r)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = proto.Unmarshal(buf, msg)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":158,"reference":"\/\/ ProtoRecv gets a protobuf message from a websocket","result":"Receive messages from the websocket.","score":[0.108,0.218]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ProtoSend(ws *websocket.Conn, msg proto.Message) error {\r\n\tw, err := ws.NextWriter(websocket.BinaryMessage)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer w.Close()\r\n\tdata, err := proto.Marshal(msg)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = shared.WriteAll(w, data)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":140,"reference":"\/\/ ProtoSend sends a protobuf message over a websocket","result":"Send messages to the websocket.","score":[0,0.1163]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ProtoSendControl(ws *websocket.Conn, err error) {\r\n\tmessage := \"\"\r\n\tif err != nil {\r\n\t\tmessage = err.Error()\r\n\t}\r\n\tmsg := MigrationControl{\r\n\t\tSuccess: proto.Bool(err == nil),\r\n\t\tMessage: proto.String(message),\r\n\t}\r\n\tProtoSend(ws, &msg)\r\n}","code-length":104,"reference":"\/\/ ProtoSendControl sends a migration control message over a websocket","result":"Send migration control messages.","score":[0.1008,0.2719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (er stdinMirror) Read(p []byte) (int, error) {\r\n\tn, err := er.r.Read(p)\r\n\tv := rune(p[0])\r\n\tif v == '\\u0001' && !*er.foundEscape {\r\n\t\t*er.foundEscape = true\r\n\t\treturn 0, err\r\n\t}\r\n\tif v == 'q' && *er.foundEscape {\r\n\t\tselect {\r\n\t\tcase er.consoleDisconnect <- true:\r\n\t\t\treturn 0, err\r\n\t\tdefault:\r\n\t\t\treturn 0, err\r\n\t\t}\r\n\t}\r\n\t*er.foundEscape = false\r\n\treturn n, err\r\n}","code-length":179,"reference":"\/\/ The pty has been switched to raw mode so we will only ever read a single\n\/\/ byte. The buffer size is therefore uninteresting to us.","result":"Read from stdin.","score":[0,0.0203]}
{"code":"\/*is used to<extra_id_0>\r\nfunc doContainersGetFromNode(project, node string, cert *shared.CertInfo) ([]api.Container, error) {\r\n\tf := func() ([]api.Container, error) {\r\n\t\tclient, err := cluster.Connect(node, cert, true)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, errors.Wrapf(err, \"Failed to connect to node %s\", node)\r\n\t\t}\r\n\t\tclient = client.UseProject(project)\r\n\t\tcontainers, err := client.GetContainers()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, errors.Wrapf(err, \"Failed to get containers from node %s\", node)\r\n\t\t}\r\n\t\treturn containers, nil\r\n\t}\r\n\ttimeout := time.After(30 * time.Second)\r\n\tdone := make(chan struct{})\r\n\tvar containers []api.Container\r\n\tvar err error\r\n\tgo func() {\r\n\t\tcontainers, err = f()\r\n\t\tdone <- struct{}{}\r\n\t}()\r\n\tselect {\r\n\tcase <-timeout:\r\n\t\terr = fmt.Errorf(\"Timeout getting containers from node %s\", node)\r\n\tcase <-done:\r\n\t}\r\n\treturn containers, err\r\n}","code-length":312,"reference":"\/\/ Fetch information about the containers on the given remote node, using the\n\/\/ rest API and with a timeout of 30 seconds.","result":"Get the list of containers from a node.","score":[0.0301,0.1163]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Retry(f func() error) error {\r\n\t\r\n\tvar err error\r\n\tfor i := 0; i < 5; i++ {\r\n\t\terr = f()\r\n\t\tif err != nil {\r\n\t\t\tlogger.Debugf(\"Database error: %#v\", err)\r\n\t\t\tif IsRetriableError(err) {\r\n\t\t\t\tlogger.Debugf(\"Retry failed db interaction (%v)\", err)\r\n\t\t\t\ttime.Sleep(250 * time.Millisecond)\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t}\r\n\t\tbreak\r\n\t}\r\n\treturn err\r\n}","code-length":156,"reference":"\/\/ Retry wraps a function that interacts with the database, and retries it in\n\/\/ case a transient error is hit.\n\/\/\n\/\/ This should by typically used to wrap transactions.","result":"Retry db interaction.","score":[0.0,0.0177]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsRetriableError(err error) bool {\r\n\terr = errors.Cause(err)\r\n\tif err == nil {\r\n\t\treturn false\r\n\t}\r\n\tif err == sqlite3.ErrLocked || err == sqlite3.ErrBusy {\r\n\t\treturn true\r\n\t}\r\n\tif strings.Contains(err.Error(), \"database is locked\") {\r\n\t\treturn true\r\n\t}\r\n\tif strings.Contains(err.Error(), \"bad connection\") {\r\n\t\treturn true\r\n\t}\r\n\t\r\n\tif strings.Contains(err.Error(), \"disk I\/O error\") {\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":175,"reference":"\/\/ IsRetriableError returns true if the given error might be transient and the\n\/\/ interaction can be safely retried.","result":"Test if the error is a retryable error.","score":[0.055,0.1117]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AppArmorProfile() string {\r\n\tcontents, err := ioutil.ReadFile(\"\/proc\/self\/attr\/current\")\r\n\tif err == nil {\r\n\t\treturn strings.TrimSpace(string(contents))\r\n\t}\r\n\treturn \"\"\r\n}","code-length":72,"reference":"\/\/ AppArmorProfile returns the current apparmor profile.","result":"Get the AppArmor profile.","score":[0.1795,0.3814]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageBtrfs) StoragePoolVolumeCreate() error {\r\n\tlogger.Infof(\"Creating BTRFS storage volume \\\"%s\\\" on storage pool \\\"%s\\\"\", s.volume.Name, s.pool.Name)\r\n\t_, err := s.StoragePoolMount()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tisSnapshot := shared.IsSnapshot(s.volume.Name)\r\n\t\r\n\tvar customSubvolumePath string\r\n\tif isSnapshot {\r\n\t\tcustomSubvolumePath = s.getCustomSnapshotSubvolumePath(s.pool.Name)\r\n\t} else {\r\n\t\tcustomSubvolumePath = s.getCustomSubvolumePath(s.pool.Name)\r\n\t}\r\n\tif !shared.PathExists(customSubvolumePath) {\r\n\t\terr := os.MkdirAll(customSubvolumePath, 0700)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\t\r\n\tvar customSubvolumeName string\r\n\tif isSnapshot {\r\n\t\tcustomSubvolumeName = getStoragePoolVolumeSnapshotMountPoint(s.pool.Name, s.volume.Name)\r\n\t} else {\r\n\t\tcustomSubvolumeName = getStoragePoolVolumeMountPoint(s.pool.Name, s.volume.Name)\r\n\t}\r\n\terr = btrfsSubVolumeCreate(customSubvolumeName)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif s.volume.Config[\"size\"] != \"\" {\r\n\t\tsize, err := shared.ParseByteSizeString(s.volume.Config[\"size\"])\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\terr = s.StorageEntitySetQuota(storagePoolVolumeTypeCustom, size, nil)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tlogger.Infof(\"Created BTRFS storage volume \\\"%s\\\" on storage pool \\\"%s\\\"\", s.volume.Name, s.pool.Name)\r\n\treturn nil\r\n}","code-length":517,"reference":"\/\/ Functions dealing with storage volumes.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageBtrfs) ContainerStorageReady(container container) bool {\r\n\tcontainerMntPoint := getContainerMountPoint(container.Project(), s.pool.Name, container.Name())\r\n\treturn isBtrfsSubVolume(containerMntPoint)\r\n}","code-length":69,"reference":"\/\/ Functions dealing with container storage.","result":"Check if container storage is ready.","score":[0.193,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageBtrfs) ContainerCreateFromImage(container container, fingerprint string, tracker *ioprogress.ProgressTracker) error {\r\n\tlogger.Debugf(\"Creating BTRFS storage volume for container \\\"%s\\\" on storage pool \\\"%s\\\"\", s.volume.Name, s.pool.Name)\r\n\tsource := s.pool.Config[\"source\"]\r\n\tif source == \"\" {\r\n\t\treturn fmt.Errorf(\"no \\\"source\\\" property found for the storage pool\")\r\n\t}\r\n\t_, err := s.StoragePoolMount()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Failed to mount storage pool\")\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tcontainerSubvolumePath := s.getContainerSubvolumePath(s.pool.Name)\r\n\tif !shared.PathExists(containerSubvolumePath) {\r\n\t\terr := os.MkdirAll(containerSubvolumePath, containersDirMode)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Failed to create volume directory\")\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\timageMntPoint := getImageMountPoint(s.pool.Name, fingerprint)\r\n\timageStoragePoolLockID := getImageCreateLockID(s.pool.Name, fingerprint)\r\n\tlxdStorageMapLock.Lock()\r\n\tif waitChannel, ok := lxdStorageOngoingOperationMap[imageStoragePoolLockID]; ok {\r\n\t\tlxdStorageMapLock.Unlock()\r\n\t\tif _, ok := <-waitChannel; ok {\r\n\t\t\tlogger.Warnf(\"Received value over semaphore, this should not have happened\")\r\n\t\t}\r\n\t} else {\r\n\t\tlxdStorageOngoingOperationMap[imageStoragePoolLockID] = make(chan bool)\r\n\t\tlxdStorageMapLock.Unlock()\r\n\t\tvar imgerr error\r\n\t\tif !shared.PathExists(imageMntPoint) || !isBtrfsSubVolume(imageMntPoint) {\r\n\t\t\timgerr = s.ImageCreate(fingerprint, tracker)\r\n\t\t}\r\n\t\tlxdStorageMapLock.Lock()\r\n\t\tif waitChannel, ok := lxdStorageOngoingOperationMap[imageStoragePoolLockID]; ok {\r\n\t\t\tclose(waitChannel)\r\n\t\t\tdelete(lxdStorageOngoingOperationMap, imageStoragePoolLockID)\r\n\t\t}\r\n\t\tlxdStorageMapLock.Unlock()\r\n\t\tif imgerr != nil {\r\n\t\t\treturn errors.Wrap(imgerr, \"Failed to create image volume\")\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tcontainerSubvolumeName := getContainerMountPoint(container.Project(), s.pool.Name, container.Name())\r\n\terr = s.btrfsPoolVolumesSnapshot(imageMntPoint, containerSubvolumeName, false, false)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Failed to storage pool volume snapshot\")\r\n\t}\r\n\t\r\n\t\r\n\terr = createContainerMountpoint(containerSubvolumeName, container.Path(), container.IsPrivileged())\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Failed to create container mountpoint\")\r\n\t}\r\n\tlogger.Debugf(\"Created BTRFS storage volume for container \\\"%s\\\" on storage pool \\\"%s\\\"\", s.volume.Name, s.pool.Name)\r\n\terr = container.TemplateApply(\"create\")\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Failed to apply container template\")\r\n\t}\r\n\treturn nil\r\n}","code-length":879,"reference":"\/\/ And this function is why I started hating on btrfs...","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageBtrfs) ContainerSnapshotRename(snapshotContainer container, newName string) error {\r\n\tlogger.Debugf(\"Renaming BTRFS storage volume for snapshot \\\"%s\\\" from %s to %s\", s.volume.Name, s.volume.Name, newName)\r\n\t\r\n\t_, err := s.StoragePoolMount()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t\r\n\toldSnapshotSubvolumeName := getSnapshotMountPoint(snapshotContainer.Project(), s.pool.Name, snapshotContainer.Name())\r\n\tnewSnapshotSubvolumeName := getSnapshotMountPoint(snapshotContainer.Project(), s.pool.Name, newName)\r\n\terr = os.Rename(oldSnapshotSubvolumeName, newSnapshotSubvolumeName)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tlogger.Debugf(\"Renamed BTRFS storage volume for snapshot \\\"%s\\\" from %s to %s\", s.volume.Name, s.volume.Name, newName)\r\n\treturn nil\r\n}","code-length":255,"reference":"\/\/ ContainerSnapshotRename renames a snapshot of a container.","result":"Rename a container.","score":[0.109,0.3407]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageBtrfs) ContainerSnapshotCreateEmpty(snapshotContainer container) error {\r\n\tlogger.Debugf(\"Creating empty BTRFS storage volume for snapshot \\\"%s\\\" on storage pool \\\"%s\\\"\", s.volume.Name, s.pool.Name)\r\n\t\r\n\t_, err := s.StoragePoolMount()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tsourceName, _, _ := containerGetParentAndSnapshotName(snapshotContainer.Name())\r\n\tsnapshotSubvolumePath := getSnapshotSubvolumePath(snapshotContainer.Project(), s.pool.Name, sourceName)\r\n\tsnapshotSubvolumeName := getSnapshotMountPoint(snapshotContainer.Project(), s.pool.Name, snapshotContainer.Name())\r\n\tif !shared.PathExists(snapshotSubvolumePath) {\r\n\t\terr := os.MkdirAll(snapshotSubvolumePath, containersDirMode)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\terr = btrfsSubVolumeCreate(snapshotSubvolumeName)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tsnapshotMntPointSymlinkTarget := shared.VarPath(\"storage-pools\", s.pool.Name, \"containers-snapshots\", projectPrefix(snapshotContainer.Project(), sourceName))\r\n\tsnapshotMntPointSymlink := shared.VarPath(\"snapshots\", projectPrefix(snapshotContainer.Project(), sourceName))\r\n\tif !shared.PathExists(snapshotMntPointSymlink) {\r\n\t\terr := createContainerMountpoint(snapshotMntPointSymlinkTarget, snapshotMntPointSymlink, snapshotContainer.IsPrivileged())\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tlogger.Debugf(\"Created empty BTRFS storage volume for snapshot \\\"%s\\\" on storage pool \\\"%s\\\"\", s.volume.Name, s.pool.Name)\r\n\treturn nil\r\n}","code-length":456,"reference":"\/\/ Needed for live migration where an empty snapshot needs to be created before\n\/\/ rsyncing into it.","result":"Create a new empty snapshot.","score":[0.0178,0.0599]}
{"code":"\/*is used to<extra_id_0>\r\nfunc btrfsSubVolumesDelete(subvol string) error {\r\n\t\r\n\tsubsubvols, err := btrfsSubVolumesGet(subvol)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tsort.Sort(sort.Reverse(sort.StringSlice(subsubvols)))\r\n\tfor _, subsubvol := range subsubvols {\r\n\t\terr := btrfsSubVolumeDelete(path.Join(subvol, subsubvol))\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\t\r\n\terr = btrfsSubVolumeDelete(subvol)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":193,"reference":"\/\/ btrfsPoolVolumesDelete is the recursive variant on btrfsPoolVolumeDelete,\n\/\/ it first deletes subvolumes of the subvolume and then the\n\/\/ subvolume itself.","result":"Delete a subvolume.","score":[0,0.0249]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isBtrfsSubVolume(subvolPath string) bool {\r\n\tfs := syscall.Stat_t{}\r\n\terr := syscall.Lstat(subvolPath, &fs)\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\t\r\n\tif fs.Ino != 256 {\r\n\t\treturn false\r\n\t}\r\n\treturn true\r\n}","code-length":101,"reference":"\/\/ isBtrfsSubVolume returns true if the given Path is a btrfs subvolume else\n\/\/ false.","result":"Check if a subvolume is a btrfs subvolume.","score":[0.1355,0.3119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SelectConfig(tx *sql.Tx, table string, where string, args ...interface{}) (map[string]string, error) {\r\n\tquery := fmt.Sprintf(\"SELECT key, value FROM %s\", table)\r\n\tif where != \"\" {\r\n\t\tquery += fmt.Sprintf(\" WHERE %s\", where)\r\n\t}\r\n\trows, err := tx.Query(query, args...)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer rows.Close()\r\n\tvalues := map[string]string{}\r\n\tfor rows.Next() {\r\n\t\tvar key string\r\n\t\tvar value string\r\n\t\terr := rows.Scan(&key, &value)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tvalues[key] = value\r\n\t}\r\n\terr = rows.Err()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn values, nil\r\n}","code-length":257,"reference":"\/\/ SelectConfig executes a query statement against a \"config\" table, which must\n\/\/ have 'key' and 'value' columns. By default this query returns all keys, but\n\/\/ additional WHERE filters can be specified.\n\/\/\n\/\/ Returns a map of key names to their associated values.","result":"Select configuration values.","score":[0.0,0.0123]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UpdateConfig(tx *sql.Tx, table string, values map[string]string) error {\r\n\tchanges := map[string]string{}\r\n\tdeletes := []string{}\r\n\tfor key, value := range values {\r\n\t\tif value == \"\" {\r\n\t\t\tdeletes = append(deletes, key)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tchanges[key] = value\r\n\t}\r\n\terr := upsertConfig(tx, table, changes)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"updating values failed\")\r\n\t}\r\n\terr = deleteConfig(tx, table, deletes)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"deleting values failed\")\r\n\t}\r\n\treturn nil\r\n}","code-length":203,"reference":"\/\/ UpdateConfig updates the given keys in the given table. Config keys set to\n\/\/ empty values will be deleted.","result":"Update the config values.","score":[0.0059,0.0815]}
{"code":"\/*is used to<extra_id_0>\r\nfunc deleteConfig(tx *sql.Tx, table string, keys []string) error {\r\n\tn := len(keys)\r\n\tif n == 0 {\r\n\t\treturn nil\r\n\t}\r\n\tquery := fmt.Sprintf(\"DELETE FROM %s WHERE key IN %s\", table, Params(n))\r\n\tvalues := make([]interface{}, n)\r\n\tfor i, key := range keys {\r\n\t\tvalues[i] = key\r\n\t}\r\n\t_, err := tx.Exec(query, values...)\r\n\treturn err\r\n}","code-length":142,"reference":"\/\/ Delete the given key rows from the given config table.","result":"Delete config keys.","score":[0.0337,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FormatSection(header string, content string) string {\r\n\tout := \"\"\r\n\t\r\n\tif header != \"\" {\r\n\t\tout += header + \":\\n\"\r\n\t}\r\n\t\r\n\tfor _, line := range strings.Split(content, \"\\n\") {\r\n\t\tif line != \"\" {\r\n\t\t\tout += \"  \"\r\n\t\t}\r\n\t\tout += line + \"\\n\"\r\n\t}\r\n\tif header != \"\" {\r\n\t\t\r\n\t\tout += \"\\n\"\r\n\t} else {\r\n\t\t\r\n\t\tout = strings.TrimSuffix(out, \"\\n\")\r\n\t}\r\n\treturn out\r\n}","code-length":171,"reference":"\/\/ FormatSection properly indents a text section","result":"Format a section.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetProjects() ([]api.Project, error) {\r\n\tif !r.HasExtension(\"projects\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"projects\\\" API extension\")\r\n\t}\r\n\tprojects := []api.Project{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", \"\/projects?recursion=1\", nil, \"\", &projects)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn projects, nil\r\n}","code-length":139,"reference":"\/\/ GetProjects returns a list of available Project structs","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetProject(name string) (*api.Project, string, error) {\r\n\tif !r.HasExtension(\"projects\") {\r\n\t\treturn nil, \"\", fmt.Errorf(\"The server is missing the required \\\"projects\\\" API extension\")\r\n\t}\r\n\tproject := api.Project{}\r\n\t\r\n\tetag, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/projects\/%s\", url.QueryEscape(name)), nil, \"\", &project)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\treturn &project, etag, nil\r\n}","code-length":159,"reference":"\/\/ GetProject returns a Project entry for the provided name","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) CreateProject(project api.ProjectsPost) error {\r\n\tif !r.HasExtension(\"projects\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"projects\\\" API extension\")\r\n\t}\r\n\t\r\n\t_, _, err := r.query(\"POST\", \"\/projects\", project, \"\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":117,"reference":"\/\/ CreateProject defines a new container project","result":"Create a new project.","score":[0.2134,0.2799]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) UpdateProject(name string, project api.ProjectPut, ETag string) error {\r\n\tif !r.HasExtension(\"projects\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"projects\\\" API extension\")\r\n\t}\r\n\t\r\n\t_, _, err := r.query(\"PUT\", fmt.Sprintf(\"\/projects\/%s\", url.QueryEscape(name)), project, ETag)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":138,"reference":"\/\/ UpdateProject updates the project to match the provided Project struct","result":"Update the project in the LXD.","score":[0.1313,0.3006]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) RenameProject(name string, project api.ProjectPost) (Operation, error) {\r\n\tif !r.HasExtension(\"projects\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"projects\\\" API extension\")\r\n\t}\r\n\t\r\n\top, _, err := r.queryOperation(\"POST\", fmt.Sprintf(\"\/projects\/%s\", url.QueryEscape(name)), project, \"\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":146,"reference":"\/\/ RenameProject renames an existing project entry","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (er Reader) Read(p []byte) (int, error) {\r\nagain:\r\n\tn, err := er.Reader.Read(p)\r\n\tif err == nil {\r\n\t\treturn n, nil\r\n\t}\r\n\t\r\n\terrno, ok := shared.GetErrno(err)\r\n\tif ok && (errno == syscall.EAGAIN || errno == syscall.EINTR) {\r\n\t\tgoto again\r\n\t}\r\n\treturn n, err\r\n}","code-length":128,"reference":"\/\/ Read behaves like io.Reader.Read but will retry on EAGAIN","result":"Avoid the need for the following code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ew Writer) Write(p []byte) (int, error) {\r\nagain:\r\n\tn, err := ew.Writer.Write(p)\r\n\tif err == nil {\r\n\t\treturn n, nil\r\n\t}\r\n\t\r\n\terrno, ok := shared.GetErrno(err)\r\n\tif ok && (errno == syscall.EAGAIN || errno == syscall.EINTR) {\r\n\t\tgoto again\r\n\t}\r\n\treturn n, err\r\n}","code-length":128,"reference":"\/\/ Write behaves like io.Writer.Write but will retry on EAGAIN","result":"Write to a file.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCanceler() *Canceler {\r\n\tc := Canceler{}\r\n\tc.lock.Lock()\r\n\tc.reqChCancel = make(map[*http.Request]chan struct{})\r\n\tc.lock.Unlock()\r\n\treturn &c\r\n}","code-length":75,"reference":"\/\/ NewCanceler returns a new Canceler struct","result":"Create a new canceler.","score":[0.2134,0.2799]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Canceler) Cancelable() bool {\r\n\tc.lock.Lock()\r\n\tlength := len(c.reqChCancel)\r\n\tc.lock.Unlock()\r\n\treturn length > 0\r\n}","code-length":62,"reference":"\/\/ Cancelable indicates whether there are operations that support cancelation","result":"Check if the request is cancelable.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Canceler) Cancel() error {\r\n\tif !c.Cancelable() {\r\n\t\treturn fmt.Errorf(\"This operation can't be canceled at this time\")\r\n\t}\r\n\tc.lock.Lock()\r\n\tfor req, ch := range c.reqChCancel {\r\n\t\tclose(ch)\r\n\t\tdelete(c.reqChCancel, req)\r\n\t}\r\n\tc.lock.Unlock()\r\n\treturn nil\r\n}","code-length":121,"reference":"\/\/ Cancel will attempt to cancel all ongoing operations","result":"Cancel a request.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CancelableDownload(c *Canceler, client *http.Client, req *http.Request) (*http.Response, chan bool, error) {\r\n\tchDone := make(chan bool)\r\n\tchCancel := make(chan struct{})\r\n\tif c != nil {\r\n\t\tc.lock.Lock()\r\n\t\tc.reqChCancel[req] = chCancel\r\n\t\tc.lock.Unlock()\r\n\t}\r\n\treq.Cancel = chCancel\r\n\tgo func() {\r\n\t\t<-chDone\r\n\t\tif c != nil {\r\n\t\t\tc.lock.Lock()\r\n\t\t\tdelete(c.reqChCancel, req)\r\n\t\t\tc.lock.Unlock()\r\n\t\t}\r\n\t}()\r\n\tresp, err := client.Do(req)\r\n\treturn resp, chDone, err\r\n}","code-length":216,"reference":"\/\/ CancelableDownload performs an http request and allows for it to be canceled at any time","result":"Cancel a download.","score":[0,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc clusterGet(d *Daemon, r *http.Request) Response {\r\n\tname := \"\"\r\n\terr := d.cluster.Transaction(func(tx *db.ClusterTx) error {\r\n\t\tvar err error\r\n\t\tname, err = tx.NodeName()\r\n\t\treturn err\r\n\t})\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\t\r\n\t\r\n\tif name == \"none\" {\r\n\t\tname = \"\"\r\n\t}\r\n\tmemberConfig, err := clusterGetMemberConfig(d.cluster)\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\tcluster := api.Cluster{\r\n\t\tServerName:   name,\r\n\t\tEnabled:      name != \"\",\r\n\t\tMemberConfig: memberConfig,\r\n\t}\r\n\treturn SyncResponseETag(true, cluster, cluster)\r\n}","code-length":229,"reference":"\/\/ Return information about the cluster.","result":"Fetch cluster info.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc clusterGetMemberConfig(cluster *db.Cluster) ([]api.ClusterMemberConfigKey, error) {\r\n\tvar pools map[string]map[string]string\r\n\tvar networks map[string]map[string]string\r\n\tkeys := []api.ClusterMemberConfigKey{}\r\n\terr := cluster.Transaction(func(tx *db.ClusterTx) error {\r\n\t\tvar err error\r\n\t\tpools, err = tx.StoragePoolsNodeConfig()\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"Failed to fetch storage pools configuration\")\r\n\t\t}\r\n\t\tnetworks, err = tx.NetworksNodeConfig()\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"Failed to fetch networks configuration\")\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tfor pool, config := range pools {\r\n\t\tfor key := range config {\r\n\t\t\tif strings.HasPrefix(key, \"volatile.\") {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tkey := api.ClusterMemberConfigKey{\r\n\t\t\t\tEntity:      \"storage-pool\",\r\n\t\t\t\tName:        pool,\r\n\t\t\t\tKey:         key,\r\n\t\t\t\tDescription: fmt.Sprintf(\"\\\"%s\\\" property for storage pool \\\"%s\\\"\", key, pool),\r\n\t\t\t}\r\n\t\t\tkeys = append(keys, key)\r\n\t\t}\r\n\t}\r\n\tfor network, config := range networks {\r\n\t\tfor key := range config {\r\n\t\t\tif strings.HasPrefix(key, \"volatile.\") {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tkey := api.ClusterMemberConfigKey{\r\n\t\t\t\tEntity:      \"network\",\r\n\t\t\t\tName:        network,\r\n\t\t\t\tKey:         key,\r\n\t\t\t\tDescription: fmt.Sprintf(\"\\\"%s\\\" property for network \\\"%s\\\"\", key, network),\r\n\t\t\t}\r\n\t\t\tkeys = append(keys, key)\r\n\t\t}\r\n\t}\r\n\treturn keys, nil\r\n}","code-length":524,"reference":"\/\/ Fetch information about all node-specific configuration keys set on the\n\/\/ storage pools and networks of this cluster.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc clusterPutDisable(d *Daemon) Response {\r\n\t\r\n\terr := d.cluster.Close()\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\t\r\n\tfor _, suffix := range []string{\"crt\", \"key\", \"ca\"} {\r\n\t\tpath := filepath.Join(d.os.VarDir, \"cluster.\"+suffix)\r\n\t\tif !shared.PathExists(path) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\terr := os.Remove(path)\r\n\t\tif err != nil {\r\n\t\t\treturn InternalError(err)\r\n\t\t}\r\n\t}\r\n\tcert, err := util.LoadCert(d.os.VarDir)\r\n\tif err != nil {\r\n\t\treturn InternalError(errors.Wrap(err, \"failed to parse node certificate\"))\r\n\t}\r\n\t\r\n\td.endpoints.NetworkUpdateCert(cert)\r\n\terr = d.gateway.Reset(cert)\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\t\r\n\taddress, err := node.HTTPSAddress(d.db)\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\tstore := d.gateway.ServerStore()\r\n\td.cluster, err = db.OpenCluster(\r\n\t\t\"db.bin\", store, address, \"\/unused\/db\/dir\",\r\n\t\td.config.DqliteSetupTimeout,\r\n\t\tdqlite.WithDialFunc(d.gateway.DialFunc()),\r\n\t\tdqlite.WithContext(d.gateway.Context()),\r\n\t)\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\t\r\n\td.stopClusterTasks()\r\n\t\r\n\tversion.UserAgentFeatures(nil)\r\n\treturn EmptySyncResponse\r\n}","code-length":472,"reference":"\/\/ Disable clustering on a node.","result":"Disable cluster.","score":[0.0677,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc tryClusterRebalance(d *Daemon) error {\r\n\tleader, err := d.gateway.LeaderAddress()\r\n\tif err != nil {\r\n\t\t\r\n\t\treturn errors.Wrap(err, \"failed to get current leader node\")\r\n\t}\r\n\tcert := d.endpoints.NetworkCert()\r\n\tclient, err := cluster.Connect(leader, cert, true)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to connect to leader node\")\r\n\t}\r\n\t_, _, err = client.RawQuery(\"POST\", \"\/internal\/cluster\/rebalance\", nil, \"\")\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"request to rebalance cluster failed\")\r\n\t}\r\n\treturn nil\r\n}","code-length":196,"reference":"\/\/ This function is used to notify the leader that a node was removed, it will\n\/\/ decide whether to promote a new node as database node.","result":"Rebalance cluster.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc internalClusterPostRebalance(d *Daemon, r *http.Request) Response {\r\n\t\r\n\t\r\n\tlocalAddress, err := node.ClusterAddress(d.db)\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\tleader, err := d.gateway.LeaderAddress()\r\n\tif err != nil {\r\n\t\treturn InternalError(err)\r\n\t}\r\n\tif localAddress != leader {\r\n\t\tlogger.Debugf(\"Redirect cluster rebalance request to %s\", leader)\r\n\t\turl := &url.URL{\r\n\t\t\tScheme: \"https\",\r\n\t\t\tPath:   \"\/internal\/cluster\/rebalance\",\r\n\t\t\tHost:   leader,\r\n\t\t}\r\n\t\treturn SyncResponseRedirect(url.String())\r\n\t}\r\n\tlogger.Debugf(\"Rebalance cluster\")\r\n\t\r\n\taddress, nodes, err := cluster.Rebalance(d.State(), d.gateway)\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\tif address == \"\" {\r\n\t\treturn SyncResponse(true, nil)\r\n\t}\r\n\t\r\n\tpost := &internalClusterPostPromoteRequest{}\r\n\tfor _, node := range nodes {\r\n\t\tpost.RaftNodes = append(post.RaftNodes, internalRaftNode{\r\n\t\t\tID:      node.ID,\r\n\t\t\tAddress: node.Address,\r\n\t\t})\r\n\t}\r\n\tcert := d.endpoints.NetworkCert()\r\n\tclient, err := cluster.Connect(address, cert, false)\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\t_, _, err = client.RawQuery(\"POST\", \"\/internal\/cluster\/promote\", post, \"\")\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\treturn SyncResponse(true, nil)\r\n}","code-length":480,"reference":"\/\/ Used to update the cluster after a database node has been removed, and\n\/\/ possibly promote another one as database node.","result":"Redirect the rebalance request to the leader.","score":[0.0225,0.0488]}
{"code":"\/*is used to<extra_id_0>\r\nfunc internalClusterPostPromote(d *Daemon, r *http.Request) Response {\r\n\treq := internalClusterPostPromoteRequest{}\r\n\t\r\n\terr := json.NewDecoder(r.Body).Decode(&req)\r\n\tif err != nil {\r\n\t\treturn BadRequest(err)\r\n\t}\r\n\t\r\n\tif len(req.RaftNodes) == 0 {\r\n\t\treturn BadRequest(fmt.Errorf(\"No raft nodes provided\"))\r\n\t}\r\n\tnodes := make([]db.RaftNode, len(req.RaftNodes))\r\n\tfor i, node := range req.RaftNodes {\r\n\t\tnodes[i].ID = node.ID\r\n\t\tnodes[i].Address = node.Address\r\n\t}\r\n\terr = cluster.Promote(d.State(), d.gateway, nodes)\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\treturn SyncResponse(true, nil)\r\n}","code-length":245,"reference":"\/\/ Used to promote the local non-database node to be a database one.","result":"Create a new cluster .","score":[0.0485,0.041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Filters(pkg *ast.Package, entity string) [][]string {\r\n\tobjects := pkg.Scope.Objects\r\n\tfilters := [][]string{}\r\n\tprefix := fmt.Sprintf(\"%sObjectsBy\", entity)\r\n\tfor name := range objects {\r\n\t\tif !strings.HasPrefix(name, prefix) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\trest := name[len(prefix):]\r\n\t\tfilters = append(filters, strings.Split(rest, \"And\"))\r\n\t}\r\n\tsort.SliceStable(filters, func(i, j int) bool {\r\n\t\treturn len(filters[i]) > len(filters[j])\r\n\t})\r\n\treturn filters\r\n}","code-length":181,"reference":"\/\/ Filters parses all filtering statement defined for the given entity. It\n\/\/ returns all supported combinations of filters, sorted by number of criteria.","result":"Filter the package.","score":[0.0004,0.0457]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Parse(pkg *ast.Package, name string) (*Mapping, error) {\r\n\tstr := findStruct(pkg.Scope, name)\r\n\tif str == nil {\r\n\t\treturn nil, fmt.Errorf(\"No declaration found for %q\", name)\r\n\t}\r\n\tfields, err := parseStruct(str)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrapf(err, \"Failed to parse %q\", name)\r\n\t}\r\n\tm := &Mapping{\r\n\t\tPackage: pkg.Name,\r\n\t\tName:    name,\r\n\t\tFields:  fields,\r\n\t}\r\n\treturn m, nil\r\n}","code-length":171,"reference":"\/\/ Parse the structure declaration with the given name found in the given Go\n\/\/ package.","result":"Parse the package.","score":[0.0084,0.102]}
{"code":"\/*is used to<extra_id_0>\r\nfunc findStruct(scope *ast.Scope, name string) *ast.StructType {\r\n\tobj := scope.Lookup(name)\r\n\tif obj == nil {\r\n\t\treturn nil\r\n\t}\r\n\ttyp, ok := obj.Decl.(*ast.TypeSpec)\r\n\tif !ok {\r\n\t\treturn nil\r\n\t}\r\n\tstr, ok := typ.Type.(*ast.StructType)\r\n\tif !ok {\r\n\t\treturn nil\r\n\t}\r\n\treturn str\r\n}","code-length":133,"reference":"\/\/ Find the StructType node for the structure with the given name","result":"Find the struct .","score":[0.0611,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc parseStruct(str *ast.StructType) ([]*Field, error) {\r\n\tfields := make([]*Field, 0)\r\n\tfor _, f := range str.Fields.List {\r\n\t\tif len(f.Names) == 0 {\r\n\t\t\t\r\n\t\t\tident, ok := f.Type.(*ast.Ident)\r\n\t\t\tif !ok {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\ttyp, ok := ident.Obj.Decl.(*ast.TypeSpec)\r\n\t\t\tif !ok {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tparentStr, ok := typ.Type.(*ast.StructType)\r\n\t\t\tif !ok {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tparentFields, err := parseStruct(parentStr)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, errors.Wrapf(err, \"Failed to parse parent struct\")\r\n\t\t\t}\r\n\t\t\tfields = append(fields, parentFields...)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif len(f.Names) != 1 {\r\n\t\t\treturn nil, fmt.Errorf(\"Expected a single field name, got %q\", f.Names)\r\n\t\t}\r\n\t\tfield, err := parseField(f)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tfields = append(fields, field)\r\n\t}\r\n\treturn fields, nil\r\n}","code-length":359,"reference":"\/\/ Extract field information from the given structure.","result":"Parse the struct .","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetProfileNames() ([]string, error) {\r\n\turls := []string{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", \"\/profiles\", nil, \"\", &urls)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tnames := []string{}\r\n\tfor _, url := range urls {\r\n\t\tfields := strings.Split(url, \"\/profiles\/\")\r\n\t\tnames = append(names, strings.Split(fields[len(fields)-1], \"?\")[0])\r\n\t}\r\n\treturn names, nil\r\n}","code-length":160,"reference":"\/\/ Profile handling functions\n\/\/ GetProfileNames returns a list of available profile names","result":"Get the list of all the profiles.","score":[0.0969,0.1512]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetProfiles() ([]api.Profile, error) {\r\n\tprofiles := []api.Profile{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", \"\/profiles?recursion=1\", nil, \"\", &profiles)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn profiles, nil\r\n}","code-length":99,"reference":"\/\/ GetProfiles returns a list of available Profile structs","result":"Get the list of all the profiles.","score":[0.1716,0.2131]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetProfile(name string) (*api.Profile, string, error) {\r\n\tprofile := api.Profile{}\r\n\t\r\n\tetag, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/profiles\/%s\", url.QueryEscape(name)), nil, \"\", &profile)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\treturn &profile, etag, nil\r\n}","code-length":118,"reference":"\/\/ GetProfile returns a Profile entry for the provided name","result":"Get the profile from the server.","score":[0.0991,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) CreateProfile(profile api.ProfilesPost) error {\r\n\t\r\n\t_, _, err := r.query(\"POST\", \"\/profiles\", profile, \"\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":79,"reference":"\/\/ CreateProfile defines a new container profile","result":"Create a new profile.","score":[0.2134,0.2799]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) UpdateProfile(name string, profile api.ProfilePut, ETag string) error {\r\n\t\r\n\t_, _, err := r.query(\"PUT\", fmt.Sprintf(\"\/profiles\/%s\", url.QueryEscape(name)), profile, ETag)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":100,"reference":"\/\/ UpdateProfile updates the profile to match the provided Profile struct","result":"Update the profile.","score":[0.0284,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) RenameProfile(name string, profile api.ProfilePost) error {\r\n\t\r\n\t_, _, err := r.query(\"POST\", fmt.Sprintf(\"\/profiles\/%s\", url.QueryEscape(name)), profile, \"\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":97,"reference":"\/\/ RenameProfile renames an existing profile entry","result":"Rename the profile.","score":[0,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Load(schema Schema, values map[string]string) (Map, error) {\r\n\tm := Map{\r\n\t\tschema: schema,\r\n\t}\r\n\t\r\n\t_, err := m.update(values)\r\n\treturn m, err\r\n}","code-length":73,"reference":"\/\/ Load creates a new configuration Map with the given schema and initial\n\/\/ values. It is meant to be called with a set of initial values that were set\n\/\/ at a previous time and persisted to some storage like a database.\n\/\/\n\/\/ If one or more keys fail to be loaded, return an ErrorList describing what\n\/\/ went wrong. Non-failing keys are still loaded in the returned Map.","result":"Load the map.","score":[0.0,0.0234]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Map) Dump() map[string]interface{} {\r\n\tvalues := map[string]interface{}{}\r\n\tfor name, key := range m.schema {\r\n\t\tvalue := m.GetRaw(name)\r\n\t\tif value != key.Default {\r\n\t\t\tif key.Hidden {\r\n\t\t\t\tvalues[name] = true\r\n\t\t\t} else {\r\n\t\t\t\tvalues[name] = value\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn values\r\n}","code-length":131,"reference":"\/\/ Dump the current configuration held by this Map.\n\/\/\n\/\/ Keys that match their default value will not be included in the dump. Also,\n\/\/ if a Key has its Hidden attribute set to true, it will be rendered as\n\/\/ \"true\", for obfuscating the actual value.","result":"Dump the map.","score":[0.0,0.0345]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Map) GetRaw(name string) string {\r\n\tkey := m.schema.mustGetKey(name)\r\n\tvalue, ok := m.values[name]\r\n\tif !ok {\r\n\t\tvalue = key.Default\r\n\t}\r\n\treturn value\r\n}","code-length":79,"reference":"\/\/ GetRaw returns the value of the given key, which must be of type String.","result":"Get the raw value of a map.","score":[0.0806,0.1056]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Map) GetString(name string) string {\r\n\tm.schema.assertKeyType(name, String)\r\n\treturn m.GetRaw(name)\r\n}","code-length":50,"reference":"\/\/ GetString returns the value of the given key, which must be of type String.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Map) GetBool(name string) bool {\r\n\tm.schema.assertKeyType(name, Bool)\r\n\treturn shared.IsTrue(m.GetRaw(name))\r\n}","code-length":56,"reference":"\/\/ GetBool returns the value of the given key, which must be of type Bool.","result":"Get the value of a.","score":[0.067,0.1071]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Map) GetInt64(name string) int64 {\r\n\tm.schema.assertKeyType(name, Int64)\r\n\tn, err := strconv.ParseInt(m.GetRaw(name), 10, 64)\r\n\tif err != nil {\r\n\t\tpanic(fmt.Sprintf(\"cannot convert to int64: %v\", err))\r\n\t}\r\n\treturn n\r\n}","code-length":105,"reference":"\/\/ GetInt64 returns the value of the given key, which must be of type Int64.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Map) update(values map[string]string) ([]string, error) {\r\n\t\r\n\t\r\n\tinitial := m.values == nil\r\n\tif initial {\r\n\t\tm.values = make(map[string]string, len(values))\r\n\t}\r\n\t\r\n\t\r\n\terrors := ErrorList{}\r\n\tnames := []string{}\r\n\tfor name, value := range values {\r\n\t\tchanged, err := m.set(name, value, initial)\r\n\t\tif err != nil {\r\n\t\t\terrors.add(name, value, err.Error())\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif changed {\r\n\t\t\tnames = append(names, name)\r\n\t\t}\r\n\t}\r\n\tsort.Strings(names)\r\n\tvar err error\r\n\tif errors.Len() > 0 {\r\n\t\terrors.sort()\r\n\t\terr = errors\r\n\t}\r\n\treturn names, err\r\n}","code-length":245,"reference":"\/\/ Update the current values in the map using the newly provided ones. Return a\n\/\/ list of key names that were actually changed and an ErrorList with possible\n\/\/ errors.","result":"Update the map.","score":[0.0001,0.0355]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Map) set(name string, value string, initial bool) (bool, error) {\r\n\tkey, ok := m.schema[name]\r\n\tif !ok {\r\n\t\treturn false, fmt.Errorf(\"unknown key\")\r\n\t}\r\n\terr := key.validate(value)\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\t\r\n\tcurrent := m.GetRaw(name)\r\n\tif key.Type == Bool {\r\n\t\tvalue = normalizeBool(value)\r\n\t\tcurrent = normalizeBool(current)\r\n\t}\r\n\t\r\n\t\r\n\tif value == current {\r\n\t\treturn false, nil\r\n\t}\r\n\t\r\n\t\r\n\tif !initial && key.Setter != nil {\r\n\t\tvalue, err = key.Setter(value)\r\n\t\tif err != nil {\r\n\t\t\treturn false, err\r\n\t\t}\r\n\t}\r\n\tif value == \"\" {\r\n\t\tdelete(m.values, name)\r\n\t} else {\r\n\t\tm.values[name] = value\r\n\t}\r\n\treturn true, nil\r\n}","code-length":289,"reference":"\/\/ Set or change an individual key. Empty string means delete this value and\n\/\/ effectively revert it to the default. Return a boolean indicating whether\n\/\/ the value has changed, and error if something went wrong.","result":"Set the value of a field in the map.","score":[0.0097,0.0731]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DoesSchemaTableExist(tx *sql.Tx) (bool, error) {\r\n\tstatement := `\r\nSELECT COUNT(name) FROM sqlite_master WHERE type = 'table' AND name = 'schema'\r\n`\r\n\trows, err := tx.Query(statement)\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\tdefer rows.Close()\r\n\tif !rows.Next() {\r\n\t\treturn false, fmt.Errorf(\"schema table query returned no rows\")\r\n\t}\r\n\tvar count int\r\n\terr = rows.Scan(&count)\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\treturn count == 1, nil\r\n}","code-length":182,"reference":"\/\/ DoesSchemaTableExist return whether the schema table is present in the\n\/\/ database.","result":"Check if a table exists in a transaction.","score":[0.0884,0.08]}
{"code":"\/*is used to<extra_id_0>\r\nfunc selectSchemaVersions(tx *sql.Tx) ([]int, error) {\r\n\tstatement := `\r\nSELECT version FROM schema ORDER BY version\r\n`\r\n\treturn query.SelectIntegers(tx, statement)\r\n}","code-length":63,"reference":"\/\/ Return all versions in the schema table, in increasing order.","result":"Generate the generated code.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc selectTablesSQL(tx *sql.Tx) ([]string, error) {\r\n\tstatement := `\r\nSELECT sql FROM sqlite_master WHERE\r\n  type IN ('table', 'index', 'view') AND\r\n  name != 'schema' AND\r\n  name NOT LIKE 'sqlite_%'\r\nORDER BY name\r\n`\r\n\treturn query.SelectStrings(tx, statement)\r\n}","code-length":100,"reference":"\/\/ Return a list of SQL statements that can be used to create all tables in the\n\/\/ database.","result":"Generate the SQL for the selectTablesSQL function.","score":[0.0346,0.0562]}
{"code":"\/*is used to<extra_id_0>\r\nfunc createSchemaTable(tx *sql.Tx) error {\r\n\tstatement := `\r\nCREATE TABLE schema (\r\n    id         INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\r\n    version    INTEGER NOT NULL,\r\n    updated_at DATETIME NOT NULL,\r\n    UNIQUE (version)\r\n)\r\n`\r\n\t_, err := tx.Exec(statement)\r\n\treturn err\r\n}","code-length":102,"reference":"\/\/ Create the schema table.","result":"Create the schema table.","score":[0.7788,0.8099]}
{"code":"\/*is used to<extra_id_0>\r\nfunc insertSchemaVersion(tx *sql.Tx, new int) error {\r\n\tstatement := `\r\nINSERT INTO schema (version, updated_at) VALUES (?, strftime(\"%s\"))\r\n`\r\n\t_, err := tx.Exec(statement, new)\r\n\treturn err\r\n}","code-length":77,"reference":"\/\/ Insert a new version into the schema table.","result":"Insert schema version.","score":[0.0657,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewState(node *db.Node, cluster *db.Cluster, maas *maas.Controller, os *sys.OS, endpoints *endpoints.Endpoints) *State {\r\n\treturn &State{\r\n\t\tNode:      node,\r\n\t\tCluster:   cluster,\r\n\t\tMAAS:      maas,\r\n\t\tOS:        os,\r\n\t\tEndpoints: endpoints,\r\n\t}\r\n}","code-length":108,"reference":"\/\/ NewState returns a new State object with the given database and operating\n\/\/ system components.","result":"Create a new state.","score":[0.0225,0.1267]}
{"code":"\/*is used to<extra_id_0>\r\nfunc containerLXCUnload(c *containerLXC) {\r\n\truntime.SetFinalizer(c, nil)\r\n\tif c.c != nil {\r\n\t\tc.c.Release()\r\n\t\tc.c = nil\r\n\t}\r\n}","code-length":74,"reference":"\/\/ Unload is called by the garbage collector","result":"Unload the containerLXC.","score":[0.0917,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc containerLXCInstantiate(s *state.State, args db.ContainerArgs) *containerLXC {\r\n\treturn &containerLXC{\r\n\t\tstate:        s,\r\n\t\tid:           args.ID,\r\n\t\tproject:      args.Project,\r\n\t\tname:         args.Name,\r\n\t\tdescription:  args.Description,\r\n\t\tephemeral:    args.Ephemeral,\r\n\t\tarchitecture: args.Architecture,\r\n\t\tcType:        args.Ctype,\r\n\t\tcreationDate: args.CreationDate,\r\n\t\tlastUsedDate: args.LastUsedDate,\r\n\t\tprofiles:     args.Profiles,\r\n\t\tlocalConfig:  args.Config,\r\n\t\tlocalDevices: args.Devices,\r\n\t\tstateful:     args.Stateful,\r\n\t\tnode:         args.Node,\r\n\t\texpiryDate:   args.ExpiryDate,\r\n\t}\r\n}","code-length":238,"reference":"\/\/ Create a container struct without initializing it.","result":"Instantiate the container.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *containerLXC) initStorage() error {\r\n\tif c.storage != nil {\r\n\t\treturn nil\r\n\t}\r\n\ts, err := storagePoolVolumeContainerLoadInit(c.state, c.Project(), c.Name())\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tc.storage = s\r\n\treturn nil\r\n}","code-length":103,"reference":"\/\/ Initialize storage interface for this container","result":"Initialize the storage .","score":[0.1795,0.1493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *containerLXC) OnNetworkUp(deviceName string, hostName string) error {\r\n\tdevice := c.expandedDevices[deviceName]\r\n\tdevice[\"host_name\"] = hostName\r\n\treturn c.setupHostVethDevice(device)\r\n}","code-length":72,"reference":"\/\/ OnNetworkUp is called by the LXD callhook when the LXC network up script is run.","result":"Disable the on.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *containerLXC) setupHostVethDevice(device types.Device) error {\r\n\t\r\n\tif device[\"host_name\"] == \"\" {\r\n\t\tdevice[\"host_name\"] = c.getHostInterface(device[\"name\"])\r\n\t}\r\n\t\r\n\tif device[\"host_name\"] == \"\" {\r\n\t\treturn fmt.Errorf(\"LXC doesn't know about this device and the host_name property isn't set, can't find host side veth name\")\r\n\t}\r\n\t\r\n\terr := c.setNetworkLimits(device)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\terr = c.setNetworkRoutes(device)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":206,"reference":"\/\/ setupHostVethDevice configures a nic device's host side veth settings.","result":"Set up host side veth device .","score":[0.2167,0.3036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *containerLXC) getLxcState() (lxc.State, error) {\r\n\tif c.IsSnapshot() {\r\n\t\treturn lxc.StateMap[\"STOPPED\"], nil\r\n\t}\r\n\t\r\n\terr := c.initLXC(false)\r\n\tif err != nil {\r\n\t\treturn lxc.StateMap[\"STOPPED\"], err\r\n\t}\r\n\tmonitor := make(chan lxc.State, 1)\r\n\tgo func(c *lxc.Container) {\r\n\t\tmonitor <- c.State()\r\n\t}(c.c)\r\n\tselect {\r\n\tcase state := <-monitor:\r\n\t\treturn state, nil\r\n\tcase <-time.After(5 * time.Second):\r\n\t\treturn lxc.StateMap[\"FROZEN\"], LxcMonitorStateError\r\n\t}\r\n}","code-length":220,"reference":"\/\/ Get lxc container state, with 1 second timeout\n\/\/ If we don't get a reply, assume the lxc monitor is hung","result":"Get the container state.","score":[0.0047,0.0743]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *containerLXC) StorageStartSensitive() (bool, error) {\r\n\t\r\n\terr := c.initStorage()\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\tvar isOurOperation bool\r\n\tif c.IsSnapshot() {\r\n\t\tisOurOperation, err = c.storage.ContainerSnapshotStart(c)\r\n\t} else {\r\n\t\tisOurOperation, err = c.storage.ContainerMount(c)\r\n\t}\r\n\treturn isOurOperation, err\r\n}","code-length":144,"reference":"\/\/ Kill this function as soon as zfs is fixed.","result":"Initialize the storage interface.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *containerLXC) deviceExistsInDevicesFolder(prefix string, path string) bool {\r\n\trelativeDestPath := strings.TrimPrefix(path, \"\/\")\r\n\tdevName := fmt.Sprintf(\"%s.%s\", strings.Replace(prefix, \"\/\", \"-\", -1), strings.Replace(relativeDestPath, \"\/\", \"-\", -1))\r\n\tdevPath := filepath.Join(c.DevicesPath(), devName)\r\n\treturn shared.PathExists(devPath)\r\n}","code-length":124,"reference":"\/\/ Check if the unix device already exists.","result":"Check if device exists in devices folder.","score":[0.2191,0.3235]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *containerLXC) createDiskDevice(name string, m types.Device) (string, error) {\r\n\t\r\n\trelativeDestPath := strings.TrimPrefix(m[\"path\"], \"\/\")\r\n\tdevName := fmt.Sprintf(\"disk.%s.%s\", strings.Replace(name, \"\/\", \"-\", -1), strings.Replace(relativeDestPath, \"\/\", \"-\", -1))\r\n\tdevPath := filepath.Join(c.DevicesPath(), devName)\r\n\tsrcPath := shared.HostPath(m[\"source\"])\r\n\t\r\n\tisOptional := shared.IsTrue(m[\"optional\"])\r\n\tisReadOnly := shared.IsTrue(m[\"readonly\"])\r\n\tisRecursive := shared.IsTrue(m[\"recursive\"])\r\n\tisFile := false\r\n\tif m[\"pool\"] == \"\" {\r\n\t\tisFile = !shared.IsDir(srcPath) && !deviceIsBlockdev(srcPath)\r\n\t} else {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif filepath.IsAbs(m[\"source\"]) {\r\n\t\t\treturn \"\", fmt.Errorf(\"When the \\\"pool\\\" property is set \\\"source\\\" must specify the name of a volume, not a path\")\r\n\t\t}\r\n\t\tvolumeTypeName := \"\"\r\n\t\tvolumeName := filepath.Clean(m[\"source\"])\r\n\t\tslash := strings.Index(volumeName, \"\/\")\r\n\t\tif (slash > 0) && (len(volumeName) > slash) {\r\n\t\t\t\r\n\t\t\tvolumeName = m[\"source\"][(slash + 1):]\r\n\t\t\t\r\n\t\t\tvolumeTypeName = m[\"source\"][:slash]\r\n\t\t}\r\n\t\tswitch volumeTypeName {\r\n\t\tcase storagePoolVolumeTypeNameContainer:\r\n\t\t\treturn \"\", fmt.Errorf(\"Using container storage volumes is not supported\")\r\n\t\tcase \"\":\r\n\t\t\t\r\n\t\t\tvolumeTypeName = storagePoolVolumeTypeNameCustom\r\n\t\t\tfallthrough\r\n\t\tcase storagePoolVolumeTypeNameCustom:\r\n\t\t\tsrcPath = shared.VarPath(\"storage-pools\", m[\"pool\"], volumeTypeName, volumeName)\r\n\t\tcase storagePoolVolumeTypeNameImage:\r\n\t\t\treturn \"\", fmt.Errorf(\"Using image storage volumes is not supported\")\r\n\t\tdefault:\r\n\t\t\treturn \"\", fmt.Errorf(\"Unknown storage type prefix \\\"%s\\\" found\", volumeTypeName)\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tvolumeType, _ := storagePoolVolumeTypeNameToType(volumeTypeName)\r\n\t\ts, err := storagePoolVolumeAttachInit(c.state, m[\"pool\"], volumeName, volumeType, c)\r\n\t\tif err != nil && !isOptional {\r\n\t\t\treturn \"\", fmt.Errorf(\"Failed to initialize storage volume \\\"%s\\\" of type \\\"%s\\\" on storage pool \\\"%s\\\": %s\",\r\n\t\t\t\tvolumeName,\r\n\t\t\t\tvolumeTypeName,\r\n\t\t\t\tm[\"pool\"], err)\r\n\t\t} else if err == nil {\r\n\t\t\t_, err = s.StoragePoolVolumeMount()\r\n\t\t\tif err != nil {\r\n\t\t\t\tmsg := fmt.Sprintf(\"Could not mount storage volume \\\"%s\\\" of type \\\"%s\\\" on storage pool \\\"%s\\\": %s.\",\r\n\t\t\t\t\tvolumeName,\r\n\t\t\t\t\tvolumeTypeName,\r\n\t\t\t\t\tm[\"pool\"], err)\r\n\t\t\t\tif !isOptional {\r\n\t\t\t\t\tlogger.Errorf(msg)\r\n\t\t\t\t\treturn \"\", err\r\n\t\t\t\t}\r\n\t\t\t\tlogger.Warnf(msg)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\tif !shared.PathExists(srcPath) {\r\n\t\tif isOptional {\r\n\t\t\treturn \"\", nil\r\n\t\t}\r\n\t\treturn \"\", fmt.Errorf(\"Source path %s doesn't exist for device %s\", srcPath, name)\r\n\t}\r\n\t\r\n\tif !shared.PathExists(c.DevicesPath()) {\r\n\t\terr := os.Mkdir(c.DevicesPath(), 0711)\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", err\r\n\t\t}\r\n\t}\r\n\t\r\n\tif shared.PathExists(devPath) {\r\n\t\terr := os.Remove(devPath)\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", err\r\n\t\t}\r\n\t}\r\n\t\r\n\tif isFile {\r\n\t\tf, err := os.Create(devPath)\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", err\r\n\t\t}\r\n\t\tf.Close()\r\n\t} else {\r\n\t\terr := os.Mkdir(devPath, 0700)\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", err\r\n\t\t}\r\n\t}\r\n\t\r\n\terr := deviceMountDisk(srcPath, devPath, isReadOnly, isRecursive, m[\"propagation\"])\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn devPath, nil\r\n}","code-length":1204,"reference":"\/\/ Disk device handling","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *containerLXC) setNetworkRoutes(m types.Device) error {\r\n\tif !shared.PathExists(fmt.Sprintf(\"\/sys\/class\/net\/%s\", m[\"host_name\"])) {\r\n\t\treturn fmt.Errorf(\"Unknown or missing host side veth: %s\", m[\"host_name\"])\r\n\t}\r\n\t\r\n\t_, err := shared.RunCommand(\"ip\", \"-4\", \"route\", \"flush\", \"dev\", m[\"host_name\"], \"proto\", \"static\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t_, err = shared.RunCommand(\"ip\", \"-6\", \"route\", \"flush\", \"dev\", m[\"host_name\"], \"proto\", \"static\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif m[\"ipv4.routes\"] != \"\" {\r\n\t\tfor _, route := range strings.Split(m[\"ipv4.routes\"], \",\") {\r\n\t\t\troute = strings.TrimSpace(route)\r\n\t\t\t_, err := shared.RunCommand(\"ip\", \"-4\", \"route\", \"add\", \"dev\", m[\"host_name\"], route, \"proto\", \"static\")\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\tif m[\"ipv6.routes\"] != \"\" {\r\n\t\tfor _, route := range strings.Split(m[\"ipv6.routes\"], \",\") {\r\n\t\t\troute = strings.TrimSpace(route)\r\n\t\t\t_, err := shared.RunCommand(\"ip\", \"-6\", \"route\", \"add\", \"dev\", m[\"host_name\"], route, \"proto\", \"static\")\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":472,"reference":"\/\/ setNetworkRoutes applies any static routes configured from the host to the container nic.","result":"Set the routes for the host.","score":[0.067,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *containerLXC) Path() string {\r\n\tname := projectPrefix(c.Project(), c.Name())\r\n\treturn containerPath(name, c.IsSnapshot())\r\n}","code-length":55,"reference":"\/\/ Various container paths","result":"Generate the path of the container.","score":[0,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *containerLXC) maasInterfaces() ([]maas.ContainerInterface, error) {\r\n\tinterfaces := []maas.ContainerInterface{}\r\n\tfor k, m := range c.expandedDevices {\r\n\t\tif m[\"type\"] != \"nic\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif m[\"maas.subnet.ipv4\"] == \"\" && m[\"maas.subnet.ipv6\"] == \"\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tm, err := c.fillNetworkDevice(k, m)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tsubnets := []maas.ContainerInterfaceSubnet{}\r\n\t\t\r\n\t\tif m[\"maas.subnet.ipv4\"] != \"\" {\r\n\t\t\tsubnet := maas.ContainerInterfaceSubnet{\r\n\t\t\t\tName:    m[\"maas.subnet.ipv4\"],\r\n\t\t\t\tAddress: m[\"ipv4.address\"],\r\n\t\t\t}\r\n\t\t\tsubnets = append(subnets, subnet)\r\n\t\t}\r\n\t\t\r\n\t\tif m[\"maas.subnet.ipv6\"] != \"\" {\r\n\t\t\tsubnet := maas.ContainerInterfaceSubnet{\r\n\t\t\t\tName:    m[\"maas.subnet.ipv6\"],\r\n\t\t\t\tAddress: m[\"ipv6.address\"],\r\n\t\t\t}\r\n\t\t\tsubnets = append(subnets, subnet)\r\n\t\t}\r\n\t\tiface := maas.ContainerInterface{\r\n\t\t\tName:       m[\"name\"],\r\n\t\t\tMACAddress: m[\"hwaddr\"],\r\n\t\t\tSubnets:    subnets,\r\n\t\t}\r\n\t\tinterfaces = append(interfaces, iface)\r\n\t}\r\n\treturn interfaces, nil\r\n}","code-length":436,"reference":"\/\/ Internal MAAS handling","result":"Generate the container interface .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getSystemHandler(syslog string, debug bool, format log.Format) log.Handler {\r\n\t\r\n\tif syslog != \"\" {\r\n\t\tif !debug {\r\n\t\t\treturn log.LvlFilterHandler(\r\n\t\t\t\tlog.LvlInfo,\r\n\t\t\t\tlog.Must.SyslogHandler(syslog, format),\r\n\t\t\t)\r\n\t\t}\r\n\t\treturn log.Must.SyslogHandler(syslog, format)\r\n\t}\r\n\treturn nil\r\n}","code-length":125,"reference":"\/\/ getSystemHandler on Linux writes messages to syslog.","result":"Get the handler for the system log.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc findNvidiaMinor(pci string) (string, error) {\r\n\tnvidiaPath := fmt.Sprintf(\"\/proc\/driver\/nvidia\/gpus\/%s\/information\", pci)\r\n\tbuf, err := ioutil.ReadFile(nvidiaPath)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tstrBuf := strings.TrimSpace(string(buf))\r\n\tidx := strings.Index(strBuf, \"Device Minor:\")\r\n\tif idx != -1 {\r\n\t\tidx += len(\"Device Minor:\")\r\n\t\tstrBuf = strBuf[idx:]\r\n\t\tstrBuf = strings.TrimSpace(strBuf)\r\n\t\tparts := strings.SplitN(strBuf, \"\\n\", 2)\r\n\t\t_, err = strconv.Atoi(parts[0])\r\n\t\tif err == nil {\r\n\t\t\treturn parts[0], nil\r\n\t\t}\r\n\t}\r\n\tminor, err := findNvidiaMinorOld()\r\n\tif err == nil {\r\n\t\treturn minor, nil\r\n\t}\r\n\treturn \"\", err\r\n}","code-length":281,"reference":"\/\/ Return string for minor number of nvidia device corresponding to the given pci id","result":"Find the device minor number.","score":[0.0428,0.1071]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetLogger(syslog string, logfile string, verbose bool, debug bool, customHandler log.Handler) (logger.Logger, error) {\r\n\tLog := log.New()\r\n\tvar handlers []log.Handler\r\n\tvar syshandler log.Handler\r\n\t\r\n\tsyshandler = getSystemHandler(syslog, debug, LogfmtFormat())\r\n\tif syshandler != nil {\r\n\t\thandlers = append(handlers, syshandler)\r\n\t}\r\n\t\r\n\tif logfile != \"\" {\r\n\t\tif !pathExists(filepath.Dir(logfile)) {\r\n\t\t\treturn nil, fmt.Errorf(\"Log file path doesn't exist: %s\", filepath.Dir(logfile))\r\n\t\t}\r\n\t\tif !debug {\r\n\t\t\thandlers = append(\r\n\t\t\t\thandlers,\r\n\t\t\t\tlog.LvlFilterHandler(\r\n\t\t\t\t\tlog.LvlInfo,\r\n\t\t\t\t\tlog.Must.FileHandler(logfile, LogfmtFormat()),\r\n\t\t\t\t),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\thandlers = append(handlers, log.Must.FileHandler(logfile, LogfmtFormat()))\r\n\t\t}\r\n\t}\r\n\t\r\n\tformat := LogfmtFormat()\r\n\tif term.IsTty(os.Stderr.Fd()) {\r\n\t\tformat = TerminalFormat()\r\n\t}\r\n\tif verbose || debug {\r\n\t\tif !debug {\r\n\t\t\thandlers = append(\r\n\t\t\t\thandlers,\r\n\t\t\t\tlog.LvlFilterHandler(\r\n\t\t\t\t\tlog.LvlInfo,\r\n\t\t\t\t\tlog.StreamHandler(os.Stderr, format),\r\n\t\t\t\t),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\thandlers = append(handlers, log.StreamHandler(os.Stderr, format))\r\n\t\t}\r\n\t} else {\r\n\t\thandlers = append(\r\n\t\t\thandlers,\r\n\t\t\tlog.LvlFilterHandler(\r\n\t\t\t\tlog.LvlWarn,\r\n\t\t\t\tlog.StreamHandler(os.Stderr, format),\r\n\t\t\t),\r\n\t\t)\r\n\t}\r\n\tif customHandler != nil {\r\n\t\thandlers = append(handlers, customHandler)\r\n\t}\r\n\tLog.SetHandler(log.MultiHandler(handlers...))\r\n\treturn Log, nil\r\n}","code-length":557,"reference":"\/\/ GetLogger returns a logger suitable for using as logger.Log.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetLogger(newLogger logger.Logger) func() {\r\n\torigLog := logger.Log\r\n\tlogger.Log = newLogger\r\n\treturn func() {\r\n\t\tlogger.Log = origLog\r\n\t}\r\n}","code-length":64,"reference":"\/\/ SetLogger installs the given logger as global logger. It returns a function\n\/\/ that can be used to restore whatever logger was installed beforehand.","result":"Set the logger.","score":[0.0003,0.0439]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WaitRecord(ch chan *log.Record, timeout time.Duration) *log.Record {\r\n\tselect {\r\n\tcase record := <-ch:\r\n\t\treturn record\r\n\tcase <-time.After(timeout):\r\n\t\treturn nil\r\n\t}\r\n}","code-length":74,"reference":"\/\/ WaitRecord blocks until a log.Record is received on the given channel. It\n\/\/ returns the emitted record, or nil if no record was received within the\n\/\/ given timeout. Useful in conjunction with log.ChannelHandler, for\n\/\/ asynchronous testing.","result":"Wait for a record to be written to the log.","score":[0.0084,0.0554]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AddContext(logger logger.Logger, ctx log.Ctx) logger.Logger {\r\n\tlog15logger, ok := logger.(log.Logger)\r\n\tif !ok {\r\n\t\tlogger.Error(\"couldn't downcast logger to add context\", log.Ctx{\"logger\": log15logger, \"ctx\": ctx})\r\n\t\treturn logger\r\n\t}\r\n\treturn log15logger.New(ctx)\r\n}","code-length":108,"reference":"\/\/ AddContext will return a copy of the logger with extra context added","result":"Add context to logger.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDottedVersion(versionString string) (*DottedVersion, error) {\r\n\tformatError := fmt.Errorf(\"Invalid version format: %s\", versionString)\r\n\tsplit := strings.Split(versionString, \".\")\r\n\tif len(split) < 2 {\r\n\t\treturn nil, formatError\r\n\t}\r\n\tmaj, err := strconv.Atoi(split[0])\r\n\tif err != nil {\r\n\t\treturn nil, formatError\r\n\t}\r\n\tmin, err := strconv.Atoi(split[1])\r\n\tif err != nil {\r\n\t\treturn nil, formatError\r\n\t}\r\n\tpatch := -1\r\n\tif len(split) == 3 {\r\n\t\tpatch, err = strconv.Atoi(split[2])\r\n\t\tif err != nil {\r\n\t\t\treturn nil, formatError\r\n\t\t}\r\n\t}\r\n\treturn &DottedVersion{\r\n\t\tMajor: maj,\r\n\t\tMinor: min,\r\n\t\tPatch: patch,\r\n\t}, nil\r\n}","code-length":263,"reference":"\/\/ NewDottedVersion returns a new Version.","result":"Create a new version object.","score":[0.2782,0.3178]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Parse(s string) (*DottedVersion, error) {\r\n\tr, _ := regexp.Compile(`^([0-9]+.[0-9]+(.[0-9]+))?.*`)\r\n\tmatches := r.FindAllStringSubmatch(s, -1)\r\n\tif len(matches[0]) < 2 {\r\n\t\treturn nil, fmt.Errorf(\"Can't parse a version\")\r\n\t}\r\n\treturn NewDottedVersion(matches[0][1])\r\n}","code-length":125,"reference":"\/\/ Parse parses a string starting with a dotted version and returns it.","result":"Parse a version.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v *DottedVersion) String() string {\r\n\tversion := fmt.Sprintf(\"%d.%d\", v.Major, v.Minor)\r\n\tif v.Patch != -1 {\r\n\t\tversion += fmt.Sprintf(\".%d\", v.Patch)\r\n\t}\r\n\treturn version\r\n}","code-length":84,"reference":"\/\/ String returns version as a string","result":"Generate the version string.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v *DottedVersion) Compare(other *DottedVersion) int {\r\n\tresult := compareInts(v.Major, other.Major)\r\n\tif result != 0 {\r\n\t\treturn result\r\n\t}\r\n\tresult = compareInts(v.Minor, other.Minor)\r\n\tif result != 0 {\r\n\t\treturn result\r\n\t}\r\n\treturn compareInts(v.Patch, other.Patch)\r\n}","code-length":113,"reference":"\/\/ Compare returns result of comparison between two versions","result":"Compare two versions.","score":[0.0657,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc projectCreateDefaultProfile(tx *db.ClusterTx, project string) error {\r\n\t\r\n\tprofile := db.Profile{}\r\n\tprofile.Project = project\r\n\tprofile.Name = \"default\"\r\n\tprofile.Description = fmt.Sprintf(\"Default LXD profile for project %s\", project)\r\n\tprofile.Config = map[string]string{}\r\n\tprofile.Devices = types.Devices{}\r\n\t_, err := tx.ProfileCreate(profile)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Add default profile to database\")\r\n\t}\r\n\treturn nil\r\n}","code-length":156,"reference":"\/\/ Create the default profile of a project.","result":"Create a default profile for a project.","score":[0.2755,0.5646]}
{"code":"\/*is used to<extra_id_0>\r\nfunc projectChange(d *Daemon, project *api.Project, req api.ProjectPut) Response {\r\n\t\r\n\tfeaturesChanged := req.Config[\"features.images\"] != project.Config[\"features.images\"] || req.Config[\"features.profiles\"] != project.Config[\"features.profiles\"]\r\n\t\r\n\tif project.Name == \"default\" && featuresChanged {\r\n\t\treturn BadRequest(fmt.Errorf(\"You can't change the features of the default project\"))\r\n\t}\r\n\tif !projectIsEmpty(project) && featuresChanged {\r\n\t\treturn BadRequest(fmt.Errorf(\"Features can only be changed on empty projects\"))\r\n\t}\r\n\t\r\n\terr := projectValidateConfig(req.Config)\r\n\tif err != nil {\r\n\t\treturn BadRequest(err)\r\n\t}\r\n\t\r\n\terr = d.cluster.Transaction(func(tx *db.ClusterTx) error {\r\n\t\terr := tx.ProjectUpdate(project.Name, req)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Persist profile changes\")\r\n\t\t}\r\n\t\tif req.Config[\"features.profiles\"] != project.Config[\"features.profiles\"] {\r\n\t\t\tif req.Config[\"features.profiles\"] == \"true\" {\r\n\t\t\t\terr = projectCreateDefaultProfile(tx, project.Name)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t} else {\r\n\t\t\t\t\r\n\t\t\t\terr = tx.ProfileDelete(project.Name, \"default\")\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn errors.Wrap(err, \"Delete project default profile\")\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\treturn EmptySyncResponse\r\n}","code-length":458,"reference":"\/\/ Common logic between PUT and PATCH.","result":"Change project configuration.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc projectIsEmpty(project *api.Project) bool {\r\n\tif len(project.UsedBy) > 0 {\r\n\t\t\r\n\t\tif len(project.UsedBy) == 1 && strings.Contains(project.UsedBy[0], \"\/profiles\/default\") {\r\n\t\t\treturn true\r\n\t\t}\r\n\t\treturn false\r\n\t}\r\n\treturn true\r\n}","code-length":100,"reference":"\/\/ Check if a project is empty.","result":"Check if project is empty.","score":[0.4051,0.7118]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetCertificateFingerprints() ([]string, error) {\r\n\tcertificates := []string{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", \"\/certificates\", nil, \"\", &certificates)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tfingerprints := []string{}\r\n\tfor _, fingerprint := range certificates {\r\n\t\tfields := strings.Split(fingerprint, \"\/certificates\/\")\r\n\t\tfingerprints = append(fingerprints, fields[len(fields)-1])\r\n\t}\r\n\treturn fingerprints, nil\r\n}","code-length":161,"reference":"\/\/ Certificate handling functions\n\/\/ GetCertificateFingerprints returns a list of certificate fingerprints","result":"Generate the certificate fingerprints.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetCertificates() ([]api.Certificate, error) {\r\n\tcertificates := []api.Certificate{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", \"\/certificates?recursion=1\", nil, \"\", &certificates)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn certificates, nil\r\n}","code-length":102,"reference":"\/\/ GetCertificates returns a list of certificates","result":"Get the certificates from the server.","score":[0.1634,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetCertificate(fingerprint string) (*api.Certificate, string, error) {\r\n\tcertificate := api.Certificate{}\r\n\t\r\n\tetag, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/certificates\/%s\", url.QueryEscape(fingerprint)), nil, \"\", &certificate)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\treturn &certificate, etag, nil\r\n}","code-length":119,"reference":"\/\/ GetCertificate returns the certificate entry for the provided fingerprint","result":"Fetch the certificate from the server.","score":[0.1551,0.2662]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) CreateCertificate(certificate api.CertificatesPost) error {\r\n\t\r\n\t_, _, err := r.query(\"POST\", \"\/certificates\", certificate, \"\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":80,"reference":"\/\/ CreateCertificate adds a new certificate to the LXD trust store","result":"Create new certificates.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) UpdateCertificate(fingerprint string, certificate api.CertificatePut, ETag string) error {\r\n\tif !r.HasExtension(\"certificate_update\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"certificate_update\\\" API extension\")\r\n\t}\r\n\t\r\n\t_, _, err := r.query(\"PUT\", fmt.Sprintf(\"\/certificates\/%s\", url.QueryEscape(fingerprint)), certificate, ETag)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":143,"reference":"\/\/ UpdateCertificate updates the certificate definition","result":"Update the certificate.","score":[0.1502,0.3289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) DeleteCertificate(fingerprint string) error {\r\n\t\r\n\t_, _, err := r.query(\"DELETE\", fmt.Sprintf(\"\/certificates\/%s\", url.QueryEscape(fingerprint)), nil, \"\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":92,"reference":"\/\/ DeleteCertificate removes a certificate from the LXD trust store","result":"Delete a certificate.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc containerMetadataTemplatesGet(d *Daemon, r *http.Request) Response {\r\n\tproject := projectParam(r)\r\n\tname := mux.Vars(r)[\"name\"]\r\n\t\r\n\tresponse, err := ForwardedResponseIfContainerIsRemote(d, r, project, name)\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\tif response != nil {\r\n\t\treturn response\r\n\t}\r\n\t\r\n\tc, err := containerLoadByProjectAndName(d.State(), project, name)\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\t\r\n\tourStart, err := c.StorageStart()\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\tif ourStart {\r\n\t\tdefer c.StorageStop()\r\n\t}\r\n\t\r\n\ttemplateName := r.FormValue(\"path\")\r\n\tif templateName == \"\" {\r\n\t\t\r\n\t\ttemplatesPath := filepath.Join(c.Path(), \"templates\")\r\n\t\tfilesInfo, err := ioutil.ReadDir(templatesPath)\r\n\t\tif err != nil {\r\n\t\t\treturn InternalError(err)\r\n\t\t}\r\n\t\ttemplates := []string{}\r\n\t\tfor _, info := range filesInfo {\r\n\t\t\tif !info.IsDir() {\r\n\t\t\t\ttemplates = append(templates, info.Name())\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn SyncResponse(true, templates)\r\n\t}\r\n\t\r\n\ttemplatePath, err := getContainerTemplatePath(c, templateName)\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\tif !shared.PathExists(templatePath) {\r\n\t\treturn NotFound(fmt.Errorf(\"Path '%s' not found\", templatePath))\r\n\t}\r\n\t\r\n\t\r\n\ttemplate, err := os.Open(templatePath)\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\tdefer template.Close()\r\n\ttempfile, err := ioutil.TempFile(\"\", \"lxd_template\")\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\tdefer tempfile.Close()\r\n\t_, err = io.Copy(tempfile, template)\r\n\tif err != nil {\r\n\t\treturn InternalError(err)\r\n\t}\r\n\tfiles := make([]fileResponseEntry, 1)\r\n\tfiles[0].identifier = templateName\r\n\tfiles[0].path = tempfile.Name()\r\n\tfiles[0].filename = templateName\r\n\treturn FileResponse(r, files, nil, true)\r\n}","code-length":664,"reference":"\/\/ Return a list of templates used in a container or the content of a template","result":"Code too long,keep in 512.","score":[0.0266,0.0336]}
{"code":"\/*is used to<extra_id_0>\r\nfunc containerMetadataTemplatesPostPut(d *Daemon, r *http.Request) Response {\r\n\tproject := projectParam(r)\r\n\tname := mux.Vars(r)[\"name\"]\r\n\t\r\n\tresponse, err := ForwardedResponseIfContainerIsRemote(d, r, project, name)\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\tif response != nil {\r\n\t\treturn response\r\n\t}\r\n\t\r\n\tc, err := containerLoadByProjectAndName(d.State(), project, name)\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\t\r\n\tourStart, err := c.StorageStart()\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\tif ourStart {\r\n\t\tdefer c.StorageStop()\r\n\t}\r\n\t\r\n\ttemplateName := r.FormValue(\"path\")\r\n\tif templateName == \"\" {\r\n\t\treturn BadRequest(fmt.Errorf(\"missing path argument\"))\r\n\t}\r\n\t\r\n\ttemplatePath, err := getContainerTemplatePath(c, templateName)\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\tif r.Method == \"POST\" && shared.PathExists(templatePath) {\r\n\t\treturn BadRequest(fmt.Errorf(\"Template already exists\"))\r\n\t}\r\n\t\r\n\ttemplate, err := os.OpenFile(templatePath, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0644)\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\tdefer template.Close()\r\n\t_, err = io.Copy(template, r.Body)\r\n\tif err != nil {\r\n\t\treturn InternalError(err)\r\n\t}\r\n\treturn EmptySyncResponse\r\n}","code-length":469,"reference":"\/\/ Add a container template file","result":"Create a container metadata template.","score":[0.2782,0.3178]}
{"code":"\/*is used to<extra_id_0>\r\nfunc containerMetadataTemplatesDelete(d *Daemon, r *http.Request) Response {\r\n\tproject := projectParam(r)\r\n\tname := mux.Vars(r)[\"name\"]\r\n\t\r\n\tresponse, err := ForwardedResponseIfContainerIsRemote(d, r, project, name)\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\tif response != nil {\r\n\t\treturn response\r\n\t}\r\n\t\r\n\tc, err := containerLoadByProjectAndName(d.State(), project, name)\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\t\r\n\tourStart, err := c.StorageStart()\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\tif ourStart {\r\n\t\tdefer c.StorageStop()\r\n\t}\r\n\t\r\n\ttemplateName := r.FormValue(\"path\")\r\n\tif templateName == \"\" {\r\n\t\treturn BadRequest(fmt.Errorf(\"missing path argument\"))\r\n\t}\r\n\ttemplatePath, err := getContainerTemplatePath(c, templateName)\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\tif !shared.PathExists(templatePath) {\r\n\t\treturn NotFound(fmt.Errorf(\"Path '%s' not found\", templatePath))\r\n\t}\r\n\t\r\n\terr = os.Remove(templatePath)\r\n\tif err != nil {\r\n\t\treturn InternalError(err)\r\n\t}\r\n\treturn EmptySyncResponse\r\n}","code-length":390,"reference":"\/\/ Delete a container template","result":"Delete container metadata templates.","score":[0.2959,0.2041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getContainerTemplatePath(c container, filename string) (string, error) {\r\n\tif strings.Contains(filename, \"\/\") {\r\n\t\treturn \"\", fmt.Errorf(\"Invalid template filename\")\r\n\t}\r\n\treturn filepath.Join(c.Path(), \"templates\", filename), nil\r\n}","code-length":78,"reference":"\/\/ Return the full path of a container template.","result":"Generate container templates.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e Error) Error() string {\r\n\tmessage := fmt.Sprintf(\"cannot set '%s'\", e.Name)\r\n\tif e.Value != nil {\r\n\t\tmessage += fmt.Sprintf(\" to '%v'\", e.Value)\r\n\t}\r\n\treturn message + fmt.Sprintf(\": %s\", e.Reason)\r\n}","code-length":94,"reference":"\/\/ Error implements the error interface.","result":"Generate the error message.","score":[0.274,0.3233]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l ErrorList) Error() string {\r\n\tswitch len(l) {\r\n\tcase 0:\r\n\t\treturn \"no errors\"\r\n\tcase 1:\r\n\t\treturn l[0].Error()\r\n\t}\r\n\treturn fmt.Sprintf(\"%s (and %d more errors)\", l[0], len(l)-1)\r\n}","code-length":94,"reference":"\/\/ ErrorList implements the error interface.","result":"Construct the error message.","score":[0.274,0.3233]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *ErrorList) add(name string, value interface{}, reason string) {\r\n\t*l = append(*l, &Error{name, value, reason})\r\n}","code-length":51,"reference":"\/\/ Add adds an Error with given key name, value and reason.","result":"Add error to the list.","score":[0.0593,0.0885]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UpdateSchema() error {\r\n\terr := cluster.SchemaDotGo()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Update cluster database schema\")\r\n\t}\r\n\terr = node.SchemaDotGo()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Update node database schema\")\r\n\t}\r\n\treturn nil\r\n}","code-length":103,"reference":"\/\/ UpdateSchema updates the schema.go file of the cluster and node databases.","result":"Update the cluster schema.","score":[0.0611,0.2282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc doProfileUpdateCluster(d *Daemon, project, name string, old api.ProfilePut) error {\r\n\tnodeName := \"\"\r\n\terr := d.cluster.Transaction(func(tx *db.ClusterTx) error {\r\n\t\tvar err error\r\n\t\tnodeName, err = tx.NodeName()\r\n\t\treturn err\r\n\t})\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to query local node name\")\r\n\t}\r\n\tcontainers, err := getProfileContainersInfo(d.cluster, project, name)\r\n\tif err != nil {\r\n\t\treturn errors.Wrapf(err, \"failed to query containers associated with profile '%s'\", name)\r\n\t}\r\n\tfailures := map[string]error{}\r\n\tfor _, args := range containers {\r\n\t\terr := doProfileUpdateContainer(d, name, old, nodeName, args)\r\n\t\tif err != nil {\r\n\t\t\tfailures[args.Name] = err\r\n\t\t}\r\n\t}\r\n\tif len(failures) != 0 {\r\n\t\tmsg := \"The following containers failed to update (profile change still saved):\\n\"\r\n\t\tfor cname, err := range failures {\r\n\t\t\tmsg += fmt.Sprintf(\" - %s: %s\\n\", cname, err)\r\n\t\t}\r\n\t\treturn fmt.Errorf(\"%s\", msg)\r\n\t}\r\n\treturn nil\r\n}","code-length":351,"reference":"\/\/ Like doProfileUpdate but does not update the database, since it was already\n\/\/ updated by doProfileUpdate itself, called on the notifying node.","result":"Update the cluster profile.","score":[0.0028,0.0474]}
{"code":"\/*is used to<extra_id_0>\r\nfunc doProfileUpdateContainer(d *Daemon, name string, old api.ProfilePut, nodeName string, args db.ContainerArgs) error {\r\n\tif args.Node != \"\" && args.Node != nodeName {\r\n\t\t\r\n\t\treturn nil\r\n\t}\r\n\tprofiles, err := d.cluster.ProfilesGet(args.Project, args.Profiles)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfor i, profileName := range args.Profiles {\r\n\t\tif profileName == name {\r\n\t\t\t\r\n\t\t\tprofiles[i].Config = old.Config\r\n\t\t\tprofiles[i].Devices = old.Devices\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tc := containerLXCInstantiate(d.State(), args)\r\n\tc.expandConfig(profiles)\r\n\tc.expandDevices(profiles)\r\n\treturn c.Update(db.ContainerArgs{\r\n\t\tArchitecture: c.Architecture(),\r\n\t\tConfig:       c.LocalConfig(),\r\n\t\tDescription:  c.Description(),\r\n\t\tDevices:      c.LocalDevices(),\r\n\t\tEphemeral:    c.IsEphemeral(),\r\n\t\tProfiles:     c.Profiles(),\r\n\t\tProject:      c.Project(),\r\n\t}, true)\r\n}","code-length":315,"reference":"\/\/ Profile update of a single container.","result":"Update the profile on a container.","score":[0.1943,0.2899]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getProfileContainersInfo(cluster *db.Cluster, project, profile string) ([]db.ContainerArgs, error) {\r\n\t\r\n\t\r\n\tnames, err := cluster.ProfileContainersGet(project, profile)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrapf(err, \"failed to query containers with profile '%s'\", profile)\r\n\t}\r\n\tcontainers := []db.ContainerArgs{}\r\n\terr = cluster.Transaction(func(tx *db.ClusterTx) error {\r\n\t\tfor ctProject, ctNames := range names {\r\n\t\t\tfor _, ctName := range ctNames {\r\n\t\t\t\tcontainer, err := tx.ContainerGet(ctProject, ctName)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t\tcontainers = append(containers, db.ContainerToArgs(container))\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrapf(err, \"Failed to fetch containers\")\r\n\t}\r\n\treturn containers, nil\r\n}","code-length":275,"reference":"\/\/ Query the db for information about containers associated with the given\n\/\/ profile.","result":"Get the profile containers info.","score":[0.0472,0.0763]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetNetworkNames() ([]string, error) {\r\n\tif !r.HasExtension(\"network\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"network\\\" API extension\")\r\n\t}\r\n\turls := []string{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", \"\/networks\", nil, \"\", &urls)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tnames := []string{}\r\n\tfor _, url := range urls {\r\n\t\tfields := strings.Split(url, \"\/networks\/\")\r\n\t\tnames = append(names, fields[len(fields)-1])\r\n\t}\r\n\treturn names, nil\r\n}","code-length":192,"reference":"\/\/ GetNetworkNames returns a list of network names","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetNetworks() ([]api.Network, error) {\r\n\tif !r.HasExtension(\"network\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"network\\\" API extension\")\r\n\t}\r\n\tnetworks := []api.Network{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", \"\/networks?recursion=1\", nil, \"\", &networks)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn networks, nil\r\n}","code-length":139,"reference":"\/\/ GetNetworks returns a list of Network struct","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetNetwork(name string) (*api.Network, string, error) {\r\n\tif !r.HasExtension(\"network\") {\r\n\t\treturn nil, \"\", fmt.Errorf(\"The server is missing the required \\\"network\\\" API extension\")\r\n\t}\r\n\tnetwork := api.Network{}\r\n\t\r\n\tetag, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/networks\/%s\", url.QueryEscape(name)), nil, \"\", &network)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\treturn &network, etag, nil\r\n}","code-length":159,"reference":"\/\/ GetNetwork returns a Network entry for the provided name","result":"Avoid the need for a function to be called.","score":[0.1435,0.1515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetNetworkLeases(name string) ([]api.NetworkLease, error) {\r\n\tif !r.HasExtension(\"network_leases\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"network_leases\\\" API extension\")\r\n\t}\r\n\tleases := []api.NetworkLease{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/networks\/%s\/leases\", url.QueryEscape(name)), nil, \"\", &leases)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn leases, nil\r\n}","code-length":169,"reference":"\/\/ GetNetworkLeases returns a list of Network struct","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetNetworkState(name string) (*api.NetworkState, error) {\r\n\tif !r.HasExtension(\"network_state\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"network_state\\\" API extension\")\r\n\t}\r\n\tstate := api.NetworkState{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/networks\/%s\/state\", url.QueryEscape(name)), nil, \"\", &state)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &state, nil\r\n}","code-length":162,"reference":"\/\/ GetNetworkState returns metrics and information on the running network","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) CreateNetwork(network api.NetworksPost) error {\r\n\tif !r.HasExtension(\"network\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"network\\\" API extension\")\r\n\t}\r\n\t\r\n\t_, _, err := r.query(\"POST\", \"\/networks\", network, \"\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":117,"reference":"\/\/ CreateNetwork defines a new network using the provided Network struct","result":"Create a new function.","score":[0.0785,0.182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) UpdateNetwork(name string, network api.NetworkPut, ETag string) error {\r\n\tif !r.HasExtension(\"network\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"network\\\" API extension\")\r\n\t}\r\n\t\r\n\t_, _, err := r.query(\"PUT\", fmt.Sprintf(\"\/networks\/%s\", url.QueryEscape(name)), network, ETag)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":138,"reference":"\/\/ UpdateNetwork updates the network to match the provided Network struct","result":"Update the network in the LXD.","score":[0.1313,0.3006]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) RenameNetwork(name string, network api.NetworkPost) error {\r\n\tif !r.HasExtension(\"network\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"network\\\" API extension\")\r\n\t}\r\n\t\r\n\t_, _, err := r.query(\"POST\", fmt.Sprintf(\"\/networks\/%s\", url.QueryEscape(name)), network, \"\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":135,"reference":"\/\/ RenameNetwork renames an existing network entry","result":"Replace the default.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Open(name string, store dqlite.ServerStore, options ...dqlite.DriverOption) (*sql.DB, error) {\r\n\tdriver, err := dqlite.NewDriver(store, options...)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Failed to create dqlite driver\")\r\n\t}\r\n\tdriverName := dqliteDriverName()\r\n\tsql.Register(driverName, driver)\r\n\t\r\n\t\r\n\t\r\n\tif name == \"\" {\r\n\t\tname = \"db.bin\"\r\n\t}\r\n\tdb, err := sql.Open(driverName, name)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"cannot open cluster database: %v\", err)\r\n\t}\r\n\treturn db, nil\r\n}","code-length":204,"reference":"\/\/ Open the cluster database object.\n\/\/\n\/\/ The name argument is the name of the cluster database. It defaults to\n\/\/ 'db.bin', but can be overwritten for testing.\n\/\/\n\/\/ The dialer argument is a function that returns a gRPC dialer that can be\n\/\/ used to connect to a database node using the gRPC SQL package.","result":"Open cluster database.","score":[0.0,0.0487]}
{"code":"\/*is used to<extra_id_0>\r\nfunc URLEncode(path string, query map[string]string) (string, error) {\r\n\tu, err := url.Parse(path)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tparams := url.Values{}\r\n\tfor key, value := range query {\r\n\t\tparams.Add(key, value)\r\n\t}\r\n\tu.RawQuery = params.Encode()\r\n\treturn u.String(), nil\r\n}","code-length":121,"reference":"\/\/ URLEncode encodes a path and query parameters to a URL.","result":"Encode the URL.","score":[0.0284,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsUnixSocket(path string) bool {\r\n\tstat, err := os.Stat(path)\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\treturn (stat.Mode() & os.ModeSocket) == os.ModeSocket\r\n}","code-length":73,"reference":"\/\/ IsUnixSocket returns true if the given path is either a Unix socket\n\/\/ or a symbolic link pointing at a Unix socket.","result":"Detect if a file is a unix socket.","score":[0.0318,0.2377]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HostPath(path string) string {\r\n\t\r\n\tif len(path) == 0 {\r\n\t\treturn path\r\n\t}\r\n\t\r\n\tif path == \"-\" {\r\n\t\treturn path\r\n\t}\r\n\t\r\n\tsnap := os.Getenv(\"SNAP\")\r\n\tsnapName := os.Getenv(\"SNAP_NAME\")\r\n\tif snap == \"\" || snapName != \"lxd\" {\r\n\t\treturn path\r\n\t}\r\n\t\r\n\tif path[0] != os.PathSeparator {\r\n\t\t\r\n\t\tppid := os.Getppid()\r\n\t\tif ppid < 1 {\r\n\t\t\treturn path\r\n\t\t}\r\n\t\tpwd, err := os.Readlink(fmt.Sprintf(\"\/proc\/%d\/cwd\", ppid))\r\n\t\tif err != nil {\r\n\t\t\treturn path\r\n\t\t}\r\n\t\tpath = filepath.Clean(strings.Join([]string{pwd, path}, string(os.PathSeparator)))\r\n\t}\r\n\t\r\n\tfor _, prefix := range []string{\"\/dev\", \"\/snap\", \"\/var\/snap\", \"\/var\/lib\/snapd\"} {\r\n\t\tif path == prefix || strings.HasPrefix(path, fmt.Sprintf(\"%s\/\", prefix)) {\r\n\t\t\treturn path\r\n\t\t}\r\n\t}\r\n\treturn fmt.Sprintf(\"\/var\/lib\/snapd\/hostfs%s\", path)\r\n}","code-length":360,"reference":"\/\/ HostPath returns the host path for the provided path\n\/\/ On a normal system, this does nothing\n\/\/ When inside of a snap environment, returns the real path","result":"Resolve host paths.","score":[0.0001,0.0189]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FileMove(oldPath string, newPath string) error {\r\n\terr := os.Rename(oldPath, newPath)\r\n\tif err == nil {\r\n\t\treturn nil\r\n\t}\r\n\terr = FileCopy(oldPath, newPath)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tos.Remove(oldPath)\r\n\treturn nil\r\n}","code-length":103,"reference":"\/\/ FileMove tries to move a file by using os.Rename,\n\/\/ if that fails it tries to copy the file and remove the source.","result":"\treturn err.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DirCopy(source string, dest string) error {\r\n\t\r\n\tinfo, err := os.Stat(source)\r\n\tif err != nil {\r\n\t\treturn errors.Wrapf(err, \"failed to get source directory info\")\r\n\t}\r\n\tif !info.IsDir() {\r\n\t\treturn fmt.Errorf(\"source is not a directory\")\r\n\t}\r\n\t\r\n\tif PathExists(dest) {\r\n\t\terr := os.RemoveAll(dest)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"failed to remove destination directory %s\", dest)\r\n\t\t}\r\n\t}\r\n\t\r\n\terr = os.MkdirAll(dest, info.Mode())\r\n\tif err != nil {\r\n\t\treturn errors.Wrapf(err, \"failed to create destination directory %s\", dest)\r\n\t}\r\n\t\r\n\tentries, err := ioutil.ReadDir(source)\r\n\tif err != nil {\r\n\t\treturn errors.Wrapf(err, \"failed to read source directory %s\", source)\r\n\t}\r\n\tfor _, entry := range entries {\r\n\t\tsourcePath := filepath.Join(source, entry.Name())\r\n\t\tdestPath := filepath.Join(dest, entry.Name())\r\n\t\tif entry.IsDir() {\r\n\t\t\terr := DirCopy(sourcePath, destPath)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn errors.Wrapf(err, \"failed to copy sub-directory from %s to %s\", sourcePath, destPath)\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\terr := FileCopy(sourcePath, destPath)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn errors.Wrapf(err, \"failed to copy file from %s to %s\", sourcePath, destPath)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":467,"reference":"\/\/ DirCopy copies a directory recursively, overwriting the target if it exists.","result":"Copy a directory.","score":[0.0203,0.1689]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StringMapHasStringKey(m map[string]string, keys ...string) bool {\r\n\tfor _, k := range keys {\r\n\t\tif _, ok := m[k]; ok {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":78,"reference":"\/\/ StringMapHasStringKey returns true if any of the supplied keys are present in the map.","result":"Test if the map has string keys.","score":[0.0612,0.0704]}
{"code":"\/*is used to<extra_id_0>\r\nfunc TextEditor(inPath string, inContent []byte) ([]byte, error) {\r\n\tvar f *os.File\r\n\tvar err error\r\n\tvar path string\r\n\t\r\n\teditor := os.Getenv(\"VISUAL\")\r\n\tif editor == \"\" {\r\n\t\teditor = os.Getenv(\"EDITOR\")\r\n\t\tif editor == \"\" {\r\n\t\t\tfor _, p := range []string{\"editor\", \"vi\", \"emacs\", \"nano\"} {\r\n\t\t\t\t_, err := exec.LookPath(p)\r\n\t\t\t\tif err == nil {\r\n\t\t\t\t\teditor = p\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tif editor == \"\" {\r\n\t\t\t\treturn []byte{}, fmt.Errorf(\"No text editor found, please set the EDITOR environment variable\")\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif inPath == \"\" {\r\n\t\t\r\n\t\tf, err = ioutil.TempFile(\"\", \"lxd_editor_\")\r\n\t\tif err != nil {\r\n\t\t\treturn []byte{}, err\r\n\t\t}\r\n\t\terr = os.Chmod(f.Name(), 0600)\r\n\t\tif err != nil {\r\n\t\t\tf.Close()\r\n\t\t\tos.Remove(f.Name())\r\n\t\t\treturn []byte{}, err\r\n\t\t}\r\n\t\tf.Write(inContent)\r\n\t\tf.Close()\r\n\t\tpath = fmt.Sprintf(\"%s.yaml\", f.Name())\r\n\t\tos.Rename(f.Name(), path)\r\n\t\tdefer os.Remove(path)\r\n\t} else {\r\n\t\tpath = inPath\r\n\t}\r\n\tcmdParts := strings.Fields(editor)\r\n\tcmd := exec.Command(cmdParts[0], append(cmdParts[1:], path)...)\r\n\tcmd.Stdin = os.Stdin\r\n\tcmd.Stdout = os.Stdout\r\n\tcmd.Stderr = os.Stderr\r\n\terr = cmd.Run()\r\n\tif err != nil {\r\n\t\treturn []byte{}, err\r\n\t}\r\n\tcontent, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\treturn []byte{}, err\r\n\t}\r\n\treturn content, nil\r\n}","code-length":565,"reference":"\/\/ Spawn the editor with a temporary YAML file for editing configs","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WriteTempFile(dir string, prefix string, content string) (string, error) {\r\n\tf, err := ioutil.TempFile(dir, prefix)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tdefer f.Close()\r\n\t_, err = f.WriteString(content)\r\n\treturn f.Name(), err\r\n}","code-length":96,"reference":"\/\/ WriteTempFile creates a temp file with the specified content","result":"Write a file to a temporary file.","score":[0.1251,0.1031]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RenderTemplate(template string, ctx pongo2.Context) (string, error) {\r\n\t\r\n\ttpl, err := pongo2.FromString(\"{% autoescape off %}\" + template + \"{% endautoescape %}\")\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\t\r\n\tret, err := tpl.Execute(ctx)\r\n\tif err != nil {\r\n\t\treturn ret, err\r\n\t}\r\n\t\r\n\tif strings.Contains(ret, \"{{\") || strings.Contains(ret, \"{%\") {\r\n\t\treturn RenderTemplate(ret, ctx)\r\n\t}\r\n\treturn ret, err\r\n}","code-length":170,"reference":"\/\/ RenderTemplate renders a pongo2 template.","result":"Render template.","score":[0.0677,0.1786]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Every(interval time.Duration, options ...EveryOption) Schedule {\r\n\tevery := &every{}\r\n\tfor _, option := range options {\r\n\t\toption(every)\r\n\t}\r\n\tfirst := true\r\n\treturn func() (time.Duration, error) {\r\n\t\tvar err error\r\n\t\tif first && every.skipFirst {\r\n\t\t\terr = ErrSkip\r\n\t\t}\r\n\t\tfirst = false\r\n\t\treturn interval, err\r\n\t}\r\n}","code-length":129,"reference":"\/\/ Every returns a Schedule that always returns the given time interval.","result":"Create a schedule function .","score":[0.0593,0.1659]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageLvm) StoragePoolMount() (bool, error) {\r\n\tsource := s.pool.Config[\"source\"]\r\n\tif source == \"\" {\r\n\t\treturn false, fmt.Errorf(\"no \\\"source\\\" property found for the storage pool\")\r\n\t}\r\n\tif !filepath.IsAbs(source) {\r\n\t\treturn true, nil\r\n\t}\r\n\tpoolMountLockID := getPoolMountLockID(s.pool.Name)\r\n\tlxdStorageMapLock.Lock()\r\n\tif waitChannel, ok := lxdStorageOngoingOperationMap[poolMountLockID]; ok {\r\n\t\tlxdStorageMapLock.Unlock()\r\n\t\tif _, ok := <-waitChannel; ok {\r\n\t\t\tlogger.Warnf(\"Received value over semaphore, this should not have happened\")\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\treturn false, nil\r\n\t}\r\n\tlxdStorageOngoingOperationMap[poolMountLockID] = make(chan bool)\r\n\tlxdStorageMapLock.Unlock()\r\n\tremoveLockFromMap := func() {\r\n\t\tlxdStorageMapLock.Lock()\r\n\t\tif waitChannel, ok := lxdStorageOngoingOperationMap[poolMountLockID]; ok {\r\n\t\t\tclose(waitChannel)\r\n\t\t\tdelete(lxdStorageOngoingOperationMap, poolMountLockID)\r\n\t\t}\r\n\t\tlxdStorageMapLock.Unlock()\r\n\t}\r\n\tdefer removeLockFromMap()\r\n\tif filepath.IsAbs(source) && !shared.IsBlockdevPath(source) {\r\n\t\t\r\n\t\tloopF, loopErr := prepareLoopDev(source, 0)\r\n\t\tif loopErr != nil {\r\n\t\t\treturn false, loopErr\r\n\t\t}\r\n\t\t\r\n\t\tloopErr = unsetAutoclearOnLoopDev(int(loopF.Fd()))\r\n\t\tif loopErr != nil {\r\n\t\t\treturn false, loopErr\r\n\t\t}\r\n\t\ts.loopInfo = loopF\r\n\t}\r\n\treturn true, nil\r\n}","code-length":504,"reference":"\/\/ Currently only used for loop-backed LVM storage pools. Can be called without\n\/\/ overhead since it is essentially a noop for non-loop-backed LVM storage\n\/\/ pools.","result":"Mount the storage volume.","score":[0.001,0.0202]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Dump(tx *sql.Tx, schema string, schemaOnly bool) (string, error) {\r\n\tschemas := dumpParseSchema(schema)\r\n\t\r\n\tdump := `PRAGMA foreign_keys=OFF;\r\nBEGIN TRANSACTION;\r\n`\r\n\t\r\n\ttableDump, err := dumpTable(tx, \"schema\", dumpSchemaTable)\r\n\tif err != nil {\r\n\t\treturn \"\", errors.Wrapf(err, \"failed to dump table schema\")\r\n\t}\r\n\tdump += tableDump\r\n\t\r\n\ttables := make([]string, 0)\r\n\tfor table := range schemas {\r\n\t\ttables = append(tables, table)\r\n\t}\r\n\tsort.Strings(tables)\r\n\tfor _, table := range tables {\r\n\t\tif schemaOnly {\r\n\t\t\t\r\n\t\t\tdump += schemas[table] + \"\\n\"\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\ttableDump, err := dumpTable(tx, table, schemas[table])\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", errors.Wrapf(err, \"failed to dump table %s\", table)\r\n\t\t}\r\n\t\tdump += tableDump\r\n\t}\r\n\t\r\n\tif !schemaOnly {\r\n\t\ttableDump, err = dumpTable(tx, \"sqlite_sequence\", \"DELETE FROM sqlite_sequence;\")\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", errors.Wrapf(err, \"failed to dump table sqlite_sequence\")\r\n\t\t}\r\n\t\tdump += tableDump\r\n\t}\r\n\t\r\n\tdump += \"COMMIT;\\n\"\r\n\treturn dump, nil\r\n}","code-length":403,"reference":"\/\/ Dump returns a SQL text dump of all rows across all tables, similar to\n\/\/ sqlite3's dump feature","result":"Dump the database.","score":[0.002,0.0287]}
{"code":"\/*is used to<extra_id_0>\r\nfunc dumpTable(tx *sql.Tx, table, schema string) (string, error) {\r\n\tstatements := []string{schema}\r\n\t\r\n\trows, err := tx.Query(fmt.Sprintf(\"SELECT * FROM %s ORDER BY rowid\", table))\r\n\tif err != nil {\r\n\t\treturn \"\", errors.Wrap(err, \"failed to fetch rows\")\r\n\t}\r\n\tdefer rows.Close()\r\n\t\r\n\tcolumns, err := rows.Columns()\r\n\tif err != nil {\r\n\t\treturn \"\", errors.Wrap(err, \"failed to get columns\")\r\n\t}\r\n\t\r\n\tfor i := 0; rows.Next(); i++ {\r\n\t\traw := make([]interface{}, len(columns))\r\n\t\trow := make([]interface{}, len(columns))\r\n\t\tfor i := range raw {\r\n\t\t\trow[i] = &raw[i]\r\n\t\t}\r\n\t\terr := rows.Scan(row...)\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", errors.Wrapf(err, \"failed to scan row %d\", i)\r\n\t\t}\r\n\t\tvalues := make([]string, len(columns))\r\n\t\tfor j, v := range raw {\r\n\t\t\tswitch v := v.(type) {\r\n\t\t\tcase int64:\r\n\t\t\t\tvalues[j] = strconv.FormatInt(v, 10)\r\n\t\t\tcase string:\r\n\t\t\t\tvalues[j] = fmt.Sprintf(\"'%s'\", v)\r\n\t\t\tcase []byte:\r\n\t\t\t\tvalues[j] = fmt.Sprintf(\"'%s'\", string(v))\r\n\t\t\tcase time.Time:\r\n\t\t\t\tvalues[j] = strconv.FormatInt(v.Unix(), 10)\r\n\t\t\tdefault:\r\n\t\t\t\tif v != nil {\r\n\t\t\t\t\treturn \"\", fmt.Errorf(\"bad type in column %s of row %d\", columns[j], i)\r\n\t\t\t\t}\r\n\t\t\t\tvalues[j] = \"NULL\"\r\n\t\t\t}\r\n\t\t}\r\n\t\tstatement := fmt.Sprintf(\"INSERT INTO %s VALUES(%s);\", table, strings.Join(values, \",\"))\r\n\t\tstatements = append(statements, statement)\r\n\t}\r\n\treturn strings.Join(statements, \"\\n\") + \"\\n\", nil\r\n}","code-length":569,"reference":"\/\/ Dump a single table, returning a SQL text containing statements for its\n\/\/ schema and data.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ProjectHasProfiles(name string) (bool, error) {\r\n\treturn projectHasProfiles(c.tx, name)\r\n}","code-length":46,"reference":"\/\/ ProjectHasProfiles is a helper to check if a project has the profiles\n\/\/ feature enabled.","result":"Generate the code.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ProjectNames() ([]string, error) {\r\n\tstmt := \"SELECT name FROM projects\"\r\n\tnames, err := query.SelectStrings(c.tx, stmt)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Fetch project names\")\r\n\t}\r\n\treturn names, nil\r\n}","code-length":95,"reference":"\/\/ ProjectNames returns the names of all available projects.","result":"Generate code for the generated code.","score":[0.1171,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ProjectMap() (map[int64]string, error) {\r\n\tstmt := \"SELECT id, name FROM projects\"\r\n\trows, err := c.tx.Query(stmt)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer rows.Close()\r\n\tresult := map[int64]string{}\r\n\tfor i := 0; rows.Next(); i++ {\r\n\t\tvar id int64\r\n\t\tvar name string\r\n\t\terr := rows.Scan(&id, &name)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tresult[id] = name\r\n\t}\r\n\terr = rows.Err()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn result, nil\r\n}","code-length":219,"reference":"\/\/ ProjectMap returns the names and ids of all available projects.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ProjectHasImages(name string) (bool, error) {\r\n\tproject, err := c.ProjectGet(name)\r\n\tif err != nil {\r\n\t\treturn false, errors.Wrap(err, \"fetch project\")\r\n\t}\r\n\tenabled := project.Config[\"features.images\"] == \"true\"\r\n\treturn enabled, nil\r\n}","code-length":99,"reference":"\/\/ ProjectHasImages is a helper to check if a project has the images\n\/\/ feature enabled.","result":"Check if project has.","score":[0.0189,0.1727]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ProjectUpdate(name string, object api.ProjectPut) error {\r\n\tstmt := c.stmt(projectUpdate)\r\n\tresult, err := stmt.Exec(object.Description, name)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Update project\")\r\n\t}\r\n\tn, err := result.RowsAffected()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Fetch affected rows\")\r\n\t}\r\n\tif n != 1 {\r\n\t\treturn fmt.Errorf(\"Query updated %d rows instead of 1\", n)\r\n\t}\r\n\tid, err := c.ProjectID(name)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Fetch project ID\")\r\n\t}\r\n\t\r\n\t_, err = c.tx.Exec(`\r\nDELETE FROM projects_config WHERE projects_config.project_id = ?\r\n`, id)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Delete project config\")\r\n\t}\r\n\t\r\n\tstmt = c.stmt(projectCreateConfigRef)\r\n\tfor key, value := range object.Config {\r\n\t\t_, err := stmt.Exec(id, key, value)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Insert config for project\")\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":358,"reference":"\/\/ ProjectUpdate updates the project matching the given key parameters.","result":"Update the project description.","score":[0.1008,0.1596]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetCluster() (*api.Cluster, string, error) {\r\n\tif !r.HasExtension(\"clustering\") {\r\n\t\treturn nil, \"\", fmt.Errorf(\"The server is missing the required \\\"clustering\\\" API extension\")\r\n\t}\r\n\tcluster := &api.Cluster{}\r\n\tetag, err := r.queryStruct(\"GET\", \"\/cluster\", nil, \"\", &cluster)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\treturn cluster, etag, nil\r\n}","code-length":140,"reference":"\/\/ GetCluster returns information about a cluster\n\/\/\n\/\/ If this client is not trusted, the password must be supplied","result":"Generate the generated code.","score":[0.0059,0.0272]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) UpdateCluster(cluster api.ClusterPut, ETag string) (Operation, error) {\r\n\tif !r.HasExtension(\"clustering\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"clustering\\\" API extension\")\r\n\t}\r\n\tif cluster.ServerAddress != \"\" || cluster.ClusterPassword != \"\" || len(cluster.MemberConfig) > 0 {\r\n\t\tif !r.HasExtension(\"clustering_join\") {\r\n\t\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"clustering_join\\\" API extension\")\r\n\t\t}\r\n\t}\r\n\top, _, err := r.queryOperation(\"PUT\", \"\/cluster\", cluster, \"\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":210,"reference":"\/\/ UpdateCluster requests to bootstrap a new cluster or join an existing one.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetClusterMemberNames() ([]string, error) {\r\n\tif !r.HasExtension(\"clustering\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"clustering\\\" API extension\")\r\n\t}\r\n\turls := []string{}\r\n\t_, err := r.queryStruct(\"GET\", \"\/cluster\/members\", nil, \"\", &urls)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn urls, nil\r\n}","code-length":134,"reference":"\/\/ GetClusterMemberNames returns the URLs of the current members in the cluster","result":"Generate code for the generated code.","score":[0.071,0.0439]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetClusterMembers() ([]api.ClusterMember, error) {\r\n\tif !r.HasExtension(\"clustering\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"clustering\\\" API extension\")\r\n\t}\r\n\tmembers := []api.ClusterMember{}\r\n\t_, err := r.queryStruct(\"GET\", \"\/cluster\/members?recursion=1\", nil, \"\", &members)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn members, nil\r\n}","code-length":143,"reference":"\/\/ GetClusterMembers returns the current members of the cluster","result":"Generate code for the generated code.","score":[0.1171,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetClusterMember(name string) (*api.ClusterMember, string, error) {\r\n\tif !r.HasExtension(\"clustering\") {\r\n\t\treturn nil, \"\", fmt.Errorf(\"The server is missing the required \\\"clustering\\\" API extension\")\r\n\t}\r\n\tmember := api.ClusterMember{}\r\n\tetag, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/cluster\/members\/%s\", name), nil, \"\", &member)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\treturn &member, etag, nil\r\n}","code-length":157,"reference":"\/\/ GetClusterMember returns information about the given member","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) RenameClusterMember(name string, member api.ClusterMemberPost) error {\r\n\tif !r.HasExtension(\"clustering\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"clustering\\\" API extension\")\r\n\t}\r\n\t_, _, err := r.query(\"POST\", fmt.Sprintf(\"\/cluster\/members\/%s\", name), member, \"\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":132,"reference":"\/\/ RenameClusterMember changes the name of an existing member","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *EventListener) Disconnect() {\r\n\tif e.disconnected {\r\n\t\treturn\r\n\t}\r\n\t\r\n\te.r.eventListenersLock.Lock()\r\n\tdefer e.r.eventListenersLock.Unlock()\r\n\t\r\n\tfor i, listener := range e.r.eventListeners {\r\n\t\tif listener == e {\r\n\t\t\tcopy(e.r.eventListeners[i:], e.r.eventListeners[i+1:])\r\n\t\t\te.r.eventListeners[len(e.r.eventListeners)-1] = nil\r\n\t\t\te.r.eventListeners = e.r.eventListeners[:len(e.r.eventListeners)-1]\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\t\r\n\te.err = nil\r\n\te.disconnected = true\r\n\tclose(e.chActive)\r\n}","code-length":222,"reference":"\/\/ Disconnect must be used once done listening for events","result":"Disconnect the listener.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CompareVersions(version1, version2 [2]int) (int, error) {\r\n\tschema1, extensions1 := version1[0], version1[1]\r\n\tschema2, extensions2 := version2[0], version2[1]\r\n\tif schema1 == schema2 && extensions1 == extensions2 {\r\n\t\treturn 0, nil\r\n\t}\r\n\tif schema1 >= schema2 && extensions1 >= extensions2 {\r\n\t\treturn 1, nil\r\n\t}\r\n\tif schema1 <= schema2 && extensions1 <= extensions2 {\r\n\t\treturn 2, nil\r\n\t}\r\n\treturn -1, fmt.Errorf(\"nodes have inconsistent versions\")\r\n}","code-length":170,"reference":"\/\/ CompareVersions the versions of two LXD nodes.\n\/\/\n\/\/ A version consists of the version the node's schema and the number of API\n\/\/ extensions it supports.\n\/\/\n\/\/ Return 0 if they equal, 1 if the first version is greater than the second\n\/\/ and 2 if the second is greater than the first.\n\/\/\n\/\/ Return an error if inconsistent versions are detected, for example the first\n\/\/ node's schema is greater than the second's, but the number of extensions is\n\/\/ smaller.","result":"Compare two versions of the same node.","score":[0.0,0.0256]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) HasClientCertificate() bool {\r\n\tcertf := c.ConfigPath(\"client.crt\")\r\n\tkeyf := c.ConfigPath(\"client.key\")\r\n\tif !shared.PathExists(certf) || !shared.PathExists(keyf) {\r\n\t\treturn false\r\n\t}\r\n\treturn true\r\n}","code-length":92,"reference":"\/\/ HasClientCertificate will return true if a client certificate has already been generated","result":"Check if the client certificate has been generated.","score":[0.174,0.3568]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) GenerateClientCertificate() error {\r\n\tif c.HasClientCertificate() {\r\n\t\treturn nil\r\n\t}\r\n\tcertf := c.ConfigPath(\"client.crt\")\r\n\tkeyf := c.ConfigPath(\"client.key\")\r\n\treturn shared.FindOrGenCert(certf, keyf, true)\r\n}","code-length":93,"reference":"\/\/ GenerateClientCertificate will generate the needed client.crt and client.key if needed","result":"Generate client certificate.","score":[0,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadModule(module string) error {\r\n\tif shared.PathExists(fmt.Sprintf(\"\/sys\/module\/%s\", module)) {\r\n\t\treturn nil\r\n\t}\r\n\t_, err := shared.RunCommand(\"modprobe\", module)\r\n\treturn err\r\n}","code-length":77,"reference":"\/\/ LoadModule loads the kernel module with the given name, by invoking\n\/\/ modprobe.","result":"Load modules.","score":[0,0.0391]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Parse(name string) (*ast.Package, error) {\r\n\tbase := os.Getenv(\"GOPATH\")\r\n\tif base == \"\" {\r\n\t\tbase = \"~\/go\"\r\n\t}\r\n\tdir := filepath.Join(base, \"src\", name)\r\n\tfset := token.NewFileSet()\r\n\tpaths, err := filepath.Glob(filepath.Join(dir, \"*.go\"))\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Search source file\")\r\n\t}\r\n\tfiles := map[string]*ast.File{}\r\n\tfor _, path := range paths {\r\n\t\t\r\n\t\tif strings.Contains(path, \"_test.go\") {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tfile, err := parser.ParseFile(fset, path, nil, parser.ParseComments)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"Parse Go source file %q\", path)\r\n\t\t}\r\n\t\tfiles[path] = file\r\n\t}\r\n\t\r\n\tpkg, _ := ast.NewPackage(fset, files, nil, nil)\r\n\treturn pkg, nil\r\n}","code-length":298,"reference":"\/\/ Parse runs the Go parser against the given package name.","result":"Parse the package .","score":[0.0731,0.1456]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Endpoints) PprofAddress() string {\r\n\te.mu.RLock()\r\n\tdefer e.mu.RUnlock()\r\n\tlistener := e.listeners[pprof]\r\n\tif listener == nil {\r\n\t\treturn \"\"\r\n\t}\r\n\treturn listener.Addr().String()\r\n}","code-length":85,"reference":"\/\/ PprofAddress returns the network addresss of the pprof endpoint, or an empty string if there's no pprof endpoint","result":"Generate the Pprof address.","score":[0.0075,0.0571]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Endpoints) PprofUpdateAddress(address string) error {\r\n\tif address != \"\" {\r\n\t\taddress = util.CanonicalNetworkAddress(address)\r\n\t}\r\n\toldAddress := e.NetworkAddress()\r\n\tif address == oldAddress {\r\n\t\treturn nil\r\n\t}\r\n\tlogger.Infof(\"Update pprof address\")\r\n\te.mu.Lock()\r\n\tdefer e.mu.Unlock()\r\n\t\r\n\te.closeListener(pprof)\r\n\t\r\n\tif address == \"\" {\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\tgetListener := func(address string) (*net.Listener, error) {\r\n\t\tvar err error\r\n\t\tvar listener net.Listener\r\n\t\tfor i := 0; i < 10; i++ {\r\n\t\t\tlistener, err = net.Listen(\"tcp\", address)\r\n\t\t\tif err == nil {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\ttime.Sleep(100 * time.Millisecond)\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"Cannot listen on http socket: %v\", err)\r\n\t\t}\r\n\t\treturn &listener, nil\r\n\t}\r\n\t\r\n\tif address != \"\" {\r\n\t\tlistener, err := getListener(address)\r\n\t\tif err != nil {\r\n\t\t\t\r\n\t\t\tlistener, err1 := getListener(oldAddress)\r\n\t\t\tif err1 == nil {\r\n\t\t\t\te.listeners[pprof] = *listener\r\n\t\t\t\te.serveHTTP(pprof)\r\n\t\t\t}\r\n\t\t\treturn err\r\n\t\t}\r\n\t\te.listeners[pprof] = *listener\r\n\t\te.serveHTTP(pprof)\r\n\t}\r\n\treturn nil\r\n}","code-length":447,"reference":"\/\/ PprofUpdateAddress updates the address for the pprof endpoint, shutting it down and restarting it.","result":"Update the address of the pprof endpoint.","score":[0.0959,0.3408]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMethod(database, pkg, entity, kind string, config map[string]string) (*Method, error) {\r\n\tpackages, err := Packages()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tmethod := &Method{\r\n\t\tdb:       database,\r\n\t\tpkg:      pkg,\r\n\t\tentity:   entity,\r\n\t\tkind:     kind,\r\n\t\tconfig:   config,\r\n\t\tpackages: packages,\r\n\t}\r\n\treturn method, nil\r\n}","code-length":141,"reference":"\/\/ NewMethod return a new method code snippet for executing a certain mapping.","result":"Create a new method.","score":[0.0476,0.0826]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Method) Generate(buf *file.Buffer) error {\r\n\tif strings.HasSuffix(m.kind, \"Ref\") {\r\n\t\treturn m.ref(buf)\r\n\t}\r\n\tswitch m.kind {\r\n\tcase \"URIs\":\r\n\t\treturn m.uris(buf)\r\n\tcase \"List\":\r\n\t\treturn m.list(buf)\r\n\tcase \"Get\":\r\n\t\treturn m.get(buf)\r\n\tcase \"ID\":\r\n\t\treturn m.id(buf)\r\n\tcase \"Exists\":\r\n\t\treturn m.exists(buf)\r\n\tcase \"Create\":\r\n\t\treturn m.create(buf)\r\n\tcase \"Rename\":\r\n\t\treturn m.rename(buf)\r\n\tcase \"Update\":\r\n\t\treturn m.update(buf)\r\n\tcase \"Delete\":\r\n\t\treturn m.delete(buf)\r\n\tdefault:\r\n\t\treturn fmt.Errorf(\"Unknown method kind '%s'\", m.kind)\r\n\t}\r\n}","code-length":260,"reference":"\/\/ Generate the desired method.","result":"Generate the method .","score":[0.3519,0.3827]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Method) fillSliceReferenceField(buf *file.Buffer, nk []*Field, field *Field) error {\r\n\tobjectsVar := fmt.Sprintf(\"%sObjects\", lex.Minuscule(field.Name))\r\n\tmethodName := fmt.Sprintf(\"%s%sRef\", lex.Capital(m.entity), field.Name)\r\n\tbuf.L(\"\r\n\tbuf.L(\"%s, err := c.%s(filter)\", objectsVar, methodName)\r\n\tbuf.L(\"if err != nil {\")\r\n\tbuf.L(\"        return nil, errors.Wrap(err, \\\"Failed to fetch field %s\\\")\", field.Name)\r\n\tbuf.L(\"}\")\r\n\tbuf.N()\r\n\tbuf.L(\"for i := range objects {\")\r\n\tneedle := \"\"\r\n\tfor i, key := range nk[:len(nk)-1] {\r\n\t\tneedle += fmt.Sprintf(\"[objects[i].%s]\", key.Name)\r\n\t\tsubIndexTyp := indexType(nk[i+1:], field.Type.Name)\r\n\t\tbuf.L(\"        _, ok := %s%s\", objectsVar, needle)\r\n\t\tbuf.L(\"        if !ok {\")\r\n\t\tbuf.L(\"                subIndex := %s{}\", subIndexTyp)\r\n\t\tbuf.L(\"                %s%s = subIndex\", objectsVar, needle)\r\n\t\tbuf.L(\"        }\")\r\n\t\tbuf.N()\r\n\t}\r\n\tneedle += fmt.Sprintf(\"[objects[i].%s]\", nk[len(nk)-1].Name)\r\n\tbuf.L(\"        value := %s%s\", objectsVar, needle)\r\n\tbuf.L(\"        if value == nil {\")\r\n\tbuf.L(\"                value = %s{}\", field.Type.Name)\r\n\tbuf.L(\"        }\")\r\n\tbuf.L(\"        objects[i].%s = value\", field.Name)\r\n\tbuf.L(\"}\")\r\n\tbuf.N()\r\n\treturn nil\r\n}","code-length":508,"reference":"\/\/ Populate a field consisting of a slice of objects referencing the\n\/\/ entity. This information is available by joining a the view or table\n\/\/ associated with the type of the referenced objects, which must contain the\n\/\/ natural key of the entity.","result":"Fill the slice reference field.","score":[0.0001,0.0249]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) StoragePoolID(name string) (int64, error) {\r\n\tstmt := \"SELECT id FROM storage_pools WHERE name=?\"\r\n\tids, err := query.SelectIntegers(c.tx, stmt, name)\r\n\tif err != nil {\r\n\t\treturn -1, err\r\n\t}\r\n\tswitch len(ids) {\r\n\tcase 0:\r\n\t\treturn -1, ErrNoSuchObject\r\n\tcase 1:\r\n\t\treturn int64(ids[0]), nil\r\n\tdefault:\r\n\t\treturn -1, fmt.Errorf(\"more than one pool has the given name\")\r\n\t}\r\n}","code-length":167,"reference":"\/\/ StoragePoolID returns the ID of the pool with the given name.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) StoragePoolIDsNotPending() (map[string]int64, error) {\r\n\tpools := []struct {\r\n\t\tid   int64\r\n\t\tname string\r\n\t}{}\r\n\tdest := func(i int) []interface{} {\r\n\t\tpools = append(pools, struct {\r\n\t\t\tid   int64\r\n\t\t\tname string\r\n\t\t}{})\r\n\t\treturn []interface{}{&pools[i].id, &pools[i].name}\r\n\t}\r\n\tstmt, err := c.tx.Prepare(\"SELECT id, name FROM storage_pools WHERE NOT state=?\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer stmt.Close()\r\n\terr = query.SelectObjects(stmt, dest, storagePoolPending)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tids := map[string]int64{}\r\n\tfor _, pool := range pools {\r\n\t\tids[pool.name] = pool.id\r\n\t}\r\n\treturn ids, nil\r\n}","code-length":277,"reference":"\/\/ StoragePoolIDsNotPending returns a map associating each storage pool name to its ID.\n\/\/\n\/\/ Pending storage pools are skipped.","result":"Generate code for the cluster transaction.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) StoragePoolNodeJoin(poolID, nodeID int64) error {\r\n\tcolumns := []string{\"storage_pool_id\", \"node_id\"}\r\n\tvalues := []interface{}{poolID, nodeID}\r\n\t_, err := query.UpsertObject(c.tx, \"storage_pools_nodes\", columns, values)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to add storage pools node entry\")\r\n\t}\r\n\treturn nil\r\n}","code-length":131,"reference":"\/\/ StoragePoolNodeJoin adds a new entry in the storage_pools_nodes table.\n\/\/\n\/\/ It should only be used when a new node joins the cluster, when it's safe to\n\/\/ assume that the relevant pool has already been created on the joining node,\n\/\/ and we just need to track it.","result":"Join a node in a cluster.","score":[0.0002,0.0548]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) StoragePoolNodeJoinCeph(poolID, nodeID int64) error {\r\n\t\r\n\t\r\n\tstmt := \"SELECT node_id FROM storage_pools_nodes WHERE storage_pool_id=?\"\r\n\tnodeIDs, err := query.SelectIntegers(c.tx, stmt, poolID)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to fetch IDs of nodes with ceph pool\")\r\n\t}\r\n\tif len(nodeIDs) == 0 {\r\n\t\treturn fmt.Errorf(\"ceph pool is not linked to any node\")\r\n\t}\r\n\totherNodeID := nodeIDs[0]\r\n\t\r\n\t_, err = c.tx.Exec(`\r\nINSERT INTO storage_volumes(name, storage_pool_id, node_id, type, description, project_id)\r\n  SELECT name, storage_pool_id, ?, type, description, 1\r\n    FROM storage_volumes WHERE storage_pool_id=? AND node_id=?\r\n`, nodeID, poolID, otherNodeID)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to create node ceph volumes\")\r\n\t}\r\n\t\r\n\tstmt = `\r\nSELECT id FROM storage_volumes WHERE storage_pool_id=? AND node_id=?\r\n  ORDER BY name, type\r\n`\r\n\tvolumeIDs, err := query.SelectIntegers(c.tx, stmt, poolID, nodeID)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to get joining node's ceph volume IDs\")\r\n\t}\r\n\totherVolumeIDs, err := query.SelectIntegers(c.tx, stmt, poolID, otherNodeID)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to get other node's ceph volume IDs\")\r\n\t}\r\n\tif len(volumeIDs) != len(otherVolumeIDs) {\r\n\t\treturn fmt.Errorf(\"not all ceph volumes were copied\")\r\n\t}\r\n\tfor i, otherVolumeID := range otherVolumeIDs {\r\n\t\tconfig, err := query.SelectConfig(\r\n\t\t\tc.tx, \"storage_volumes_config\", \"storage_volume_id=?\", otherVolumeID)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"failed to get storage volume config\")\r\n\t\t}\r\n\t\tfor key, value := range config {\r\n\t\t\t_, err := c.tx.Exec(`\r\nINSERT INTO storage_volumes_config(storage_volume_id, key, value) VALUES(?, ?, ?)\r\n`, volumeIDs[i], key, value)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn errors.Wrap(err, \"failed to copy volume config\")\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":696,"reference":"\/\/ StoragePoolNodeJoinCeph updates internal state to reflect that nodeID is\n\/\/ joining a cluster where poolID is a ceph pool.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) StoragePoolConfigAdd(poolID, nodeID int64, config map[string]string) error {\r\n\treturn storagePoolConfigAdd(c.tx, poolID, nodeID, config)\r\n}","code-length":60,"reference":"\/\/ StoragePoolConfigAdd adds a new entry in the storage_pools_config table","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) StoragePoolCreatePending(node, name, driver string, conf map[string]string) error {\r\n\t\r\n\t\r\n\tpool := struct {\r\n\t\tid     int64\r\n\t\tdriver string\r\n\t\tstate  int\r\n\t}{}\r\n\tvar errConsistency error\r\n\tdest := func(i int) []interface{} {\r\n\t\t\r\n\t\tif i != 0 {\r\n\t\t\terrConsistency = fmt.Errorf(\"more than one pool exists with the given name\")\r\n\t\t}\r\n\t\treturn []interface{}{&pool.id, &pool.driver, &pool.state}\r\n\t}\r\n\tstmt, err := c.tx.Prepare(\"SELECT id, driver, state FROM storage_pools WHERE name=?\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer stmt.Close()\r\n\terr = query.SelectObjects(stmt, dest, name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif errConsistency != nil {\r\n\t\treturn errConsistency\r\n\t}\r\n\tvar poolID = pool.id\r\n\tif poolID == 0 {\r\n\t\t\r\n\t\t\r\n\t\tcolumns := []string{\"name\", \"driver\"}\r\n\t\tvalues := []interface{}{name, driver}\r\n\t\tpoolID, err = query.UpsertObject(c.tx, \"storage_pools\", columns, values)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t} else {\r\n\t\t\r\n\t\t\r\n\t\tif pool.driver != driver {\r\n\t\t\treturn fmt.Errorf(\"pool already exists with a different driver\")\r\n\t\t}\r\n\t\tif pool.state != storagePoolPending {\r\n\t\t\treturn fmt.Errorf(\"pool is not in pending state\")\r\n\t\t}\r\n\t}\r\n\t\r\n\tnodeInfo, err := c.NodeByName(node)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tcount, err := query.Count(\r\n\t\tc.tx, \"storage_pools_nodes\", \"storage_pool_id=? AND node_id=?\", poolID, nodeInfo.ID)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif count != 0 {\r\n\t\treturn ErrAlreadyDefined\r\n\t}\r\n\t\r\n\tcolumns := []string{\"storage_pool_id\", \"node_id\"}\r\n\tvalues := []interface{}{poolID, nodeInfo.ID}\r\n\t_, err = query.UpsertObject(c.tx, \"storage_pools_nodes\", columns, values)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = c.StoragePoolConfigAdd(poolID, nodeInfo.ID, conf)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":708,"reference":"\/\/ StoragePoolCreatePending creates a new pending storage pool on the node with\n\/\/ the given name.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) StoragePoolCreated(name string) error {\r\n\treturn c.storagePoolState(name, storagePoolCreated)\r\n}","code-length":44,"reference":"\/\/ StoragePoolCreated sets the state of the given pool to \"Created\".","result":"Generate the code.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) StoragePoolErrored(name string) error {\r\n\treturn c.storagePoolState(name, storagePoolErrored)\r\n}","code-length":46,"reference":"\/\/ StoragePoolErrored sets the state of the given pool to \"Errored\".","result":"Generate the code.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) StoragePoolNodeConfigs(poolID int64) (map[string]map[string]string, error) {\r\n\t\r\n\tnodes, err := c.Nodes()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tstmt := `\r\nSELECT nodes.name FROM nodes\r\n  LEFT JOIN storage_pools_nodes ON storage_pools_nodes.node_id = nodes.id\r\n  LEFT JOIN storage_pools ON storage_pools_nodes.storage_pool_id = storage_pools.id\r\nWHERE storage_pools.id = ? AND storage_pools.state = ?\r\n`\r\n\tdefined, err := query.SelectStrings(c.tx, stmt, poolID, storagePoolPending)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tmissing := []string{}\r\n\tfor _, node := range nodes {\r\n\t\tif !shared.StringInSlice(node.Name, defined) {\r\n\t\t\tmissing = append(missing, node.Name)\r\n\t\t}\r\n\t}\r\n\tif len(missing) > 0 {\r\n\t\treturn nil, fmt.Errorf(\"Pool not defined on nodes: %s\", strings.Join(missing, \", \"))\r\n\t}\r\n\tconfigs := map[string]map[string]string{}\r\n\tfor _, node := range nodes {\r\n\t\tconfig, err := query.SelectConfig(\r\n\t\t\tc.tx, \"storage_pools_config\", \"storage_pool_id=? AND node_id=?\", poolID, node.ID)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tconfigs[node.Name] = config\r\n\t}\r\n\treturn configs, nil\r\n}","code-length":437,"reference":"\/\/ StoragePoolNodeConfigs returns the node-specific configuration of all\n\/\/ nodes grouped by node name, for the given poolID.\n\/\/\n\/\/ If the storage pool is not defined on all nodes, an error is returned.","result":"Fetch the config from the storage pool.","score":[0.0053,0.0816]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolsGetDrivers() ([]string, error) {\r\n\tvar poolDriver string\r\n\tquery := \"SELECT DISTINCT driver FROM storage_pools\"\r\n\tinargs := []interface{}{}\r\n\toutargs := []interface{}{poolDriver}\r\n\tresult, err := queryScan(c.db, query, inargs, outargs)\r\n\tif err != nil {\r\n\t\treturn []string{}, err\r\n\t}\r\n\tif len(result) == 0 {\r\n\t\treturn []string{}, ErrNoSuchObject\r\n\t}\r\n\tdrivers := []string{}\r\n\tfor _, driver := range result {\r\n\t\tdrivers = append(drivers, driver[0].(string))\r\n\t}\r\n\treturn drivers, nil\r\n}","code-length":195,"reference":"\/\/ StoragePoolsGetDrivers returns the names of all storage volumes attached to\n\/\/ a given storage pool.","result":"Get the storage pools drivers.","score":[0.0317,0.0671]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolGetID(poolName string) (int64, error) {\r\n\tpoolID := int64(-1)\r\n\tquery := \"SELECT id FROM storage_pools WHERE name=?\"\r\n\tinargs := []interface{}{poolName}\r\n\toutargs := []interface{}{&poolID}\r\n\terr := dbQueryRowScan(c.db, query, inargs, outargs)\r\n\tif err != nil {\r\n\t\tif err == sql.ErrNoRows {\r\n\t\t\treturn -1, ErrNoSuchObject\r\n\t\t}\r\n\t}\r\n\treturn poolID, nil\r\n}","code-length":158,"reference":"\/\/ StoragePoolGetID returns the id of a single storage pool.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolGet(poolName string) (int64, *api.StoragePool, error) {\r\n\tvar poolDriver string\r\n\tpoolID := int64(-1)\r\n\tdescription := sql.NullString{}\r\n\tvar state int\r\n\tquery := \"SELECT id, driver, description, state FROM storage_pools WHERE name=?\"\r\n\tinargs := []interface{}{poolName}\r\n\toutargs := []interface{}{&poolID, &poolDriver, &description, &state}\r\n\terr := dbQueryRowScan(c.db, query, inargs, outargs)\r\n\tif err != nil {\r\n\t\tif err == sql.ErrNoRows {\r\n\t\t\treturn -1, nil, ErrNoSuchObject\r\n\t\t}\r\n\t\treturn -1, nil, err\r\n\t}\r\n\tconfig, err := c.StoragePoolConfigGet(poolID)\r\n\tif err != nil {\r\n\t\treturn -1, nil, err\r\n\t}\r\n\tstoragePool := api.StoragePool{\r\n\t\tName:   poolName,\r\n\t\tDriver: poolDriver,\r\n\t}\r\n\tstoragePool.Description = description.String\r\n\tstoragePool.Config = config\r\n\tswitch state {\r\n\tcase storagePoolPending:\r\n\t\tstoragePool.Status = \"Pending\"\r\n\tcase storagePoolCreated:\r\n\t\tstoragePool.Status = \"Created\"\r\n\tdefault:\r\n\t\tstoragePool.Status = \"Unknown\"\r\n\t}\r\n\tnodes, err := c.storagePoolNodes(poolID)\r\n\tif err != nil {\r\n\t\treturn -1, nil, err\r\n\t}\r\n\tstoragePool.Locations = nodes\r\n\treturn poolID, &storagePool, nil\r\n}","code-length":427,"reference":"\/\/ StoragePoolGet returns a single storage pool.","result":"Get storage pool information.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) storagePoolNodes(poolID int64) ([]string, error) {\r\n\tstmt := `\r\nSELECT nodes.name FROM nodes\r\n  JOIN storage_pools_nodes ON storage_pools_nodes.node_id = nodes.id\r\n  WHERE storage_pools_nodes.storage_pool_id = ?\r\n`\r\n\tvar nodes []string\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tvar err error\r\n\t\tnodes, err = query.SelectStrings(tx.tx, stmt, poolID)\r\n\t\treturn err\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn nodes, nil\r\n}","code-length":182,"reference":"\/\/ Return the names of the nodes the given pool is defined on.","result":"Fetch the list of storage pool nodes in a cluster.","score":[0.1137,0.2929]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolConfigGet(poolID int64) (map[string]string, error) {\r\n\tvar key, value string\r\n\tquery := \"SELECT key, value FROM storage_pools_config WHERE storage_pool_id=? AND (node_id=? OR node_id IS NULL)\"\r\n\tinargs := []interface{}{poolID, c.nodeID}\r\n\toutargs := []interface{}{key, value}\r\n\tresults, err := queryScan(c.db, query, inargs, outargs)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tconfig := map[string]string{}\r\n\tfor _, r := range results {\r\n\t\tkey = r[0].(string)\r\n\t\tvalue = r[1].(string)\r\n\t\tconfig[key] = value\r\n\t}\r\n\treturn config, nil\r\n}","code-length":225,"reference":"\/\/ StoragePoolConfigGet returns the config of a storage pool.","result":"Generate code for the generated code.","score":[0.1171,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolCreate(poolName string, poolDescription string, poolDriver string, poolConfig map[string]string) (int64, error) {\r\n\tvar id int64\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tresult, err := tx.tx.Exec(\"INSERT INTO storage_pools (name, description, driver, state) VALUES (?, ?, ?, ?)\", poolName, poolDescription, poolDriver, storagePoolCreated)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tid, err = result.LastInsertId()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\tcolumns := []string{\"storage_pool_id\", \"node_id\"}\r\n\t\tvalues := []interface{}{id, c.nodeID}\r\n\t\t_, err = query.UpsertObject(tx.tx, \"storage_pools_nodes\", columns, values)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\terr = storagePoolConfigAdd(tx.tx, id, c.nodeID, poolConfig)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\tid = -1\r\n\t}\r\n\treturn id, nil\r\n}","code-length":346,"reference":"\/\/ StoragePoolCreate creates new storage pool.","result":"Create a new storage pool.","score":[0.4052,0.6356]}
{"code":"\/*is used to<extra_id_0>\r\nfunc storagePoolConfigAdd(tx *sql.Tx, poolID, nodeID int64, poolConfig map[string]string) error {\r\n\tstr := \"INSERT INTO storage_pools_config (storage_pool_id, node_id, key, value) VALUES(?, ?, ?, ?)\"\r\n\tstmt, err := tx.Prepare(str)\r\n\tdefer stmt.Close()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfor k, v := range poolConfig {\r\n\t\tif v == \"\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvar nodeIDValue interface{}\r\n\t\tif !shared.StringInSlice(k, StoragePoolNodeConfigKeys) {\r\n\t\t\tnodeIDValue = nil\r\n\t\t} else {\r\n\t\t\tnodeIDValue = nodeID\r\n\t\t}\r\n\t\t_, err = stmt.Exec(poolID, nodeIDValue, k, v)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":257,"reference":"\/\/ Add new storage pool config.","result":"Add a new storage pool config.","score":[0.6389,0.8067]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolUpdate(poolName, description string, poolConfig map[string]string) error {\r\n\tpoolID, _, err := c.StoragePoolGet(poolName)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = c.Transaction(func(tx *ClusterTx) error {\r\n\t\terr = StoragePoolUpdateDescription(tx.tx, poolID, description)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\terr = StoragePoolConfigClear(tx.tx, poolID, c.nodeID)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\terr = storagePoolConfigAdd(tx.tx, poolID, c.nodeID, poolConfig)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\treturn err\r\n}","code-length":237,"reference":"\/\/ StoragePoolUpdate updates a storage pool.","result":"Update the storage pool configuration.","score":[0.1967,0.1695]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StoragePoolConfigClear(tx *sql.Tx, poolID, nodeID int64) error {\r\n\t_, err := tx.Exec(\"DELETE FROM storage_pools_config WHERE storage_pool_id=? AND (node_id=? OR node_id IS NULL)\", poolID, nodeID)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":100,"reference":"\/\/ StoragePoolConfigClear deletes the storage pool config.","result":"Clear the config in the storage pool.","score":[0.2284,0.2679]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolDelete(poolName string) (*api.StoragePool, error) {\r\n\tpoolID, pool, err := c.StoragePoolGet(poolName)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\terr = exec(c.db, \"DELETE FROM storage_pools WHERE id=?\", poolID)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn pool, nil\r\n}","code-length":126,"reference":"\/\/ StoragePoolDelete deletes storage pool.","result":"Delete the storage pool.","score":[0.3519,0.5215]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolVolumesGetNames(poolID int64) ([]string, error) {\r\n\tvar volumeName string\r\n\tquery := \"SELECT name FROM storage_volumes WHERE storage_pool_id=? AND node_id=?\"\r\n\tinargs := []interface{}{poolID, c.nodeID}\r\n\toutargs := []interface{}{volumeName}\r\n\tresult, err := queryScan(c.db, query, inargs, outargs)\r\n\tif err != nil {\r\n\t\treturn []string{}, err\r\n\t}\r\n\tvar out []string\r\n\tfor _, r := range result {\r\n\t\tout = append(out, r[0].(string))\r\n\t}\r\n\treturn out, nil\r\n}","code-length":188,"reference":"\/\/ StoragePoolVolumesGetNames gets the names of all storage volumes attached to\n\/\/ a given storage pool.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolVolumesGet(project string, poolID int64, volumeTypes []int) ([]*api.StorageVolume, error) {\r\n\tvar nodeIDs []int\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tvar err error\r\n\t\tnodeIDs, err = query.SelectIntegers(tx.tx, `\r\nSELECT DISTINCT node_id\r\n  FROM storage_volumes\r\n  JOIN projects ON projects.id = storage_volumes.project_id\r\n WHERE (projects.name=? OR storage_volumes.type=?) AND storage_pool_id=?\r\n`, project, StoragePoolVolumeTypeCustom, poolID)\r\n\t\treturn err\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvolumes := []*api.StorageVolume{}\r\n\tfor _, nodeID := range nodeIDs {\r\n\t\tnodeVolumes, err := c.storagePoolVolumesGet(project, poolID, int64(nodeID), volumeTypes)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tvolumes = append(volumes, nodeVolumes...)\r\n\t}\r\n\treturn volumes, nil\r\n}","code-length":298,"reference":"\/\/ StoragePoolVolumesGet returns all storage volumes attached to a given\n\/\/ storage pool on any node.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolNodeVolumesGet(poolID int64, volumeTypes []int) ([]*api.StorageVolume, error) {\r\n\treturn c.storagePoolVolumesGet(\"default\", poolID, c.nodeID, volumeTypes)\r\n}","code-length":68,"reference":"\/\/ StoragePoolNodeVolumesGet returns all storage volumes attached to a given\n\/\/ storage pool on the current node.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) storagePoolVolumesGet(project string, poolID, nodeID int64, volumeTypes []int) ([]*api.StorageVolume, error) {\r\n\t\r\n\t\r\n\tresult := []*api.StorageVolume{}\r\n\tfor _, volumeType := range volumeTypes {\r\n\t\tvolumeNames, err := c.StoragePoolVolumesGetType(project, volumeType, poolID, nodeID)\r\n\t\tif err != nil && err != sql.ErrNoRows {\r\n\t\t\treturn nil, errors.Wrap(err, \"failed to fetch volume types\")\r\n\t\t}\r\n\t\tfor _, volumeName := range volumeNames {\r\n\t\t\t_, volume, err := c.StoragePoolVolumeGetType(project, volumeName, volumeType, poolID, nodeID)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, errors.Wrap(err, \"failed to fetch volume type\")\r\n\t\t\t}\r\n\t\t\tresult = append(result, volume)\r\n\t\t}\r\n\t}\r\n\tif len(result) == 0 {\r\n\t\treturn result, ErrNoSuchObject\r\n\t}\r\n\treturn result, nil\r\n}","code-length":280,"reference":"\/\/ Returns all storage volumes attached to a given storage pool on the given\n\/\/ node.","result":"Generate the code.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolVolumesGetType(project string, volumeType int, poolID, nodeID int64) ([]string, error) {\r\n\tvar poolName string\r\n\tquery := `\r\nSELECT storage_volumes.name\r\n  FROM storage_volumes\r\n  JOIN projects ON projects.id=storage_volumes.project_id\r\n WHERE (projects.name=? OR storage_volumes.type=?) AND storage_pool_id=? AND node_id=? AND type=?\r\n`\r\n\tinargs := []interface{}{project, StoragePoolVolumeTypeCustom, poolID, nodeID, volumeType}\r\n\toutargs := []interface{}{poolName}\r\n\tresult, err := queryScan(c.db, query, inargs, outargs)\r\n\tif err != nil {\r\n\t\treturn []string{}, err\r\n\t}\r\n\tresponse := []string{}\r\n\tfor _, r := range result {\r\n\t\tresponse = append(response, r[0].(string))\r\n\t}\r\n\treturn response, nil\r\n}","code-length":253,"reference":"\/\/ StoragePoolVolumesGetType get all storage volumes attached to a given\n\/\/ storage pool of a given volume type, on the given node.","result":"Generate the generated code.","score":[0.0035,0.0248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolVolumeSnapshotsGetType(volumeName string, volumeType int, poolID int64) ([]string, error) {\r\n\tresult := []string{}\r\n\tregexp := volumeName + shared.SnapshotDelimiter\r\n\tlength := len(regexp)\r\n\tquery := \"SELECT name FROM storage_volumes WHERE storage_pool_id=? AND node_id=? AND type=? AND snapshot=? AND SUBSTR(name,1,?)=?\"\r\n\tinargs := []interface{}{poolID, c.nodeID, volumeType, true, length, regexp}\r\n\toutfmt := []interface{}{volumeName}\r\n\tdbResults, err := queryScan(c.db, query, inargs, outfmt)\r\n\tif err != nil {\r\n\t\treturn result, err\r\n\t}\r\n\tfor _, r := range dbResults {\r\n\t\tresult = append(result, r[0].(string))\r\n\t}\r\n\treturn result, nil\r\n}","code-length":237,"reference":"\/\/ StoragePoolVolumeSnapshotsGetType get all snapshots of a storage volume\n\/\/ attached to a given storage pool of a given volume type, on the given node.","result":"Get the list of snapshots for a given.","score":[0.0235,0.1073]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolNodeVolumesGetType(volumeType int, poolID int64) ([]string, error) {\r\n\treturn c.StoragePoolVolumesGetType(\"default\", volumeType, poolID, c.nodeID)\r\n}","code-length":66,"reference":"\/\/ StoragePoolNodeVolumesGetType returns all storage volumes attached to a\n\/\/ given storage pool of a given volume type, on the current node.","result":"Generate the generated code.","score":[0.0035,0.0248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolVolumeGetType(project string, volumeName string, volumeType int, poolID, nodeID int64) (int64, *api.StorageVolume, error) {\r\n\t\r\n\t\r\n\tif volumeType == StoragePoolVolumeTypeCustom {\r\n\t\tproject = \"default\"\r\n\t}\r\n\tvolumeID, err := c.StoragePoolVolumeGetTypeID(project, volumeName, volumeType, poolID, nodeID)\r\n\tif err != nil {\r\n\t\treturn -1, nil, err\r\n\t}\r\n\tvolumeNode, err := c.StorageVolumeNodeGet(volumeID)\r\n\tif err != nil {\r\n\t\treturn -1, nil, err\r\n\t}\r\n\tvolumeConfig, err := c.StorageVolumeConfigGet(volumeID)\r\n\tif err != nil {\r\n\t\treturn -1, nil, err\r\n\t}\r\n\tvolumeDescription, err := c.StorageVolumeDescriptionGet(volumeID)\r\n\tif err != nil {\r\n\t\treturn -1, nil, err\r\n\t}\r\n\tvolumeTypeName, err := StoragePoolVolumeTypeToName(volumeType)\r\n\tif err != nil {\r\n\t\treturn -1, nil, err\r\n\t}\r\n\tstorageVolume := api.StorageVolume{\r\n\t\tType: volumeTypeName,\r\n\t}\r\n\tstorageVolume.Name = volumeName\r\n\tstorageVolume.Description = volumeDescription\r\n\tstorageVolume.Config = volumeConfig\r\n\tstorageVolume.Location = volumeNode\r\n\treturn volumeID, &storageVolume, nil\r\n}","code-length":379,"reference":"\/\/ StoragePoolVolumeGetType returns a single storage volume attached to a\n\/\/ given storage pool of a given type, on the node with the given ID.","result":"Get the volume type id.","score":[0.0052,0.0652]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolNodeVolumeGetType(volumeName string, volumeType int, poolID int64) (int64, *api.StorageVolume, error) {\r\n\treturn c.StoragePoolNodeVolumeGetTypeByProject(\"default\", volumeName, volumeType, poolID)\r\n}","code-length":77,"reference":"\/\/ StoragePoolNodeVolumeGetType gets a single storage volume attached to a\n\/\/ given storage pool of a given type, on the current node.","result":"StoragePoolNodeVolumeGetTypeByProject.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolNodeVolumeGetTypeByProject(project, volumeName string, volumeType int, poolID int64) (int64, *api.StorageVolume, error) {\r\n\treturn c.StoragePoolVolumeGetType(project, volumeName, volumeType, poolID, c.nodeID)\r\n}","code-length":83,"reference":"\/\/ StoragePoolNodeVolumeGetTypeByProject gets a single storage volume attached to a\n\/\/ given storage pool of a given type, on the current node in the given project.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolVolumeUpdate(volumeName string, volumeType int, poolID int64, volumeDescription string, volumeConfig map[string]string) error {\r\n\tvolumeID, _, err := c.StoragePoolNodeVolumeGetType(volumeName, volumeType, poolID)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = c.Transaction(func(tx *ClusterTx) error {\r\n\t\terr = storagePoolVolumeReplicateIfCeph(tx.tx, volumeID, \"default\", volumeName, volumeType, poolID, func(volumeID int64) error {\r\n\t\t\terr = StorageVolumeConfigClear(tx.tx, volumeID)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\terr = StorageVolumeConfigAdd(tx.tx, volumeID, volumeConfig)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\treturn StorageVolumeDescriptionUpdate(tx.tx, volumeID, volumeDescription)\r\n\t\t})\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\treturn err\r\n}","code-length":294,"reference":"\/\/ StoragePoolVolumeUpdate updates the storage volume attached to a given storage\n\/\/ pool.","result":"Update the storage volume configuration.","score":[0.0999,0.2587]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolVolumeDelete(project, volumeName string, volumeType int, poolID int64) error {\r\n\tvolumeID, _, err := c.StoragePoolNodeVolumeGetTypeByProject(project, volumeName, volumeType, poolID)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = c.Transaction(func(tx *ClusterTx) error {\r\n\t\terr := storagePoolVolumeReplicateIfCeph(tx.tx, volumeID, project, volumeName, volumeType, poolID, func(volumeID int64) error {\r\n\t\t\t_, err := tx.tx.Exec(\"DELETE FROM storage_volumes WHERE id=?\", volumeID)\r\n\t\t\treturn err\r\n\t\t})\r\n\t\treturn err\r\n\t})\r\n\treturn err\r\n}","code-length":202,"reference":"\/\/ StoragePoolVolumeDelete deletes the storage volume attached to a given storage\n\/\/ pool.","result":"Delete a storage volume from the.","score":[0.0941,0.1626]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolVolumeRename(project, oldVolumeName string, newVolumeName string, volumeType int, poolID int64) error {\r\n\tvolumeID, _, err := c.StoragePoolNodeVolumeGetTypeByProject(project, oldVolumeName, volumeType, poolID)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = c.Transaction(func(tx *ClusterTx) error {\r\n\t\terr := storagePoolVolumeReplicateIfCeph(tx.tx, volumeID, project, oldVolumeName, volumeType, poolID, func(volumeID int64) error {\r\n\t\t\t_, err := tx.tx.Exec(\"UPDATE storage_volumes SET name=? WHERE id=? AND type=?\", newVolumeName, volumeID, volumeType)\r\n\t\t\treturn err\r\n\t\t})\r\n\t\treturn err\r\n\t})\r\n\treturn err\r\n}","code-length":222,"reference":"\/\/ StoragePoolVolumeRename renames the storage volume attached to a given storage pool.","result":"Generate code for the generated code.","score":[0.071,0.0439]}
{"code":"\/*is used to<extra_id_0>\r\nfunc storagePoolVolumeReplicateIfCeph(tx *sql.Tx, volumeID int64, project, volumeName string, volumeType int, poolID int64, f func(int64) error) error {\r\n\tdriver, err := storagePoolDriverGet(tx, poolID)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tvolumeIDs := []int64{volumeID}\r\n\t\r\n\t\r\n\tif driver == \"ceph\" {\r\n\t\tvolumeIDs, err = storageVolumeIDsGet(tx, project, volumeName, volumeType, poolID)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tfor _, volumeID := range volumeIDs {\r\n\t\terr := f(volumeID)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":227,"reference":"\/\/ This a convenience to replicate a certain volume change to all nodes if the\n\/\/ underlying driver is ceph.","result":"Replicate storage volume.","score":[0,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolVolumeCreate(project, volumeName, volumeDescription string, volumeType int, snapshot bool, poolID int64, volumeConfig map[string]string) (int64, error) {\r\n\tvar thisVolumeID int64\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tnodeIDs := []int{int(c.nodeID)}\r\n\t\tdriver, err := storagePoolDriverGet(tx.tx, poolID)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\tif driver == \"ceph\" {\r\n\t\t\tnodeIDs, err = query.SelectIntegers(tx.tx, \"SELECT id FROM nodes\")\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\tfor _, nodeID := range nodeIDs {\r\n\t\t\tresult, err := tx.tx.Exec(`\r\nINSERT INTO storage_volumes (storage_pool_id, node_id, type, snapshot, name, description, project_id) VALUES (?, ?, ?, ?, ?, ?, (SELECT id FROM projects WHERE name = ?))\r\n`,\r\n\t\t\t\tpoolID, nodeID, volumeType, snapshot, volumeName, volumeDescription, project)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tvolumeID, err := result.LastInsertId()\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif int64(nodeID) == c.nodeID {\r\n\t\t\t\t\r\n\t\t\t\tthisVolumeID = volumeID\r\n\t\t\t}\r\n\t\t\terr = StorageVolumeConfigAdd(tx.tx, volumeID, volumeConfig)\r\n\t\t\tif err != nil {\r\n\t\t\t\ttx.tx.Rollback()\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\tthisVolumeID = -1\r\n\t}\r\n\treturn thisVolumeID, err\r\n}","code-length":494,"reference":"\/\/ StoragePoolVolumeCreate creates a new storage volume attached to a given\n\/\/ storage pool.","result":"Create a storage volume in the storage pool.","score":[0.1291,0.3814]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolVolumeGetTypeID(project string, volumeName string, volumeType int, poolID, nodeID int64) (int64, error) {\r\n\tvolumeID := int64(-1)\r\n\tquery := `SELECT storage_volumes.id\r\nFROM storage_volumes\r\nJOIN storage_pools ON storage_volumes.storage_pool_id = storage_pools.id\r\nJOIN projects ON storage_volumes.project_id = projects.id\r\nWHERE projects.name=? AND storage_volumes.storage_pool_id=? AND storage_volumes.node_id=?\r\nAND storage_volumes.name=? AND storage_volumes.type=?`\r\n\tinargs := []interface{}{project, poolID, nodeID, volumeName, volumeType}\r\n\toutargs := []interface{}{&volumeID}\r\n\terr := dbQueryRowScan(c.db, query, inargs, outargs)\r\n\tif err != nil {\r\n\t\tif err == sql.ErrNoRows {\r\n\t\t\treturn -1, ErrNoSuchObject\r\n\t\t}\r\n\t\treturn -1, err\r\n\t}\r\n\treturn volumeID, nil\r\n}","code-length":277,"reference":"\/\/ StoragePoolVolumeGetTypeID returns the ID of a storage volume on a given\n\/\/ storage pool of a given storage volume type, on the given node.","result":"Avoid the need for the function to be executed.","score":[0.0245,0.0427]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StoragePoolNodeVolumeGetTypeID(volumeName string, volumeType int, poolID int64) (int64, error) {\r\n\treturn c.StoragePoolVolumeGetTypeID(\"default\", volumeName, volumeType, poolID, c.nodeID)\r\n}","code-length":75,"reference":"\/\/ StoragePoolNodeVolumeGetTypeID get the ID of a storage volume on a given\n\/\/ storage pool of a given storage volume type, on the current node.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StoragePoolVolumeTypeToName(volumeType int) (string, error) {\r\n\tswitch volumeType {\r\n\tcase StoragePoolVolumeTypeContainer:\r\n\t\treturn StoragePoolVolumeTypeNameContainer, nil\r\n\tcase StoragePoolVolumeTypeImage:\r\n\t\treturn StoragePoolVolumeTypeNameImage, nil\r\n\tcase StoragePoolVolumeTypeCustom:\r\n\t\treturn StoragePoolVolumeTypeNameCustom, nil\r\n\t}\r\n\treturn \"\", fmt.Errorf(\"invalid storage volume type\")\r\n}","code-length":121,"reference":"\/\/ StoragePoolVolumeTypeToName converts a volume integer type code to its\n\/\/ human-readable name.","result":"Convert storage volume type to name.","score":[0.085,0.2033]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DevicesAdd(tx *sql.Tx, w string, cID int64, devices types.Devices) error {\r\n\t\r\n\tstr1 := fmt.Sprintf(\"INSERT INTO %ss_devices (%s_id, name, type) VALUES (?, ?, ?)\", w, w)\r\n\tstmt1, err := tx.Prepare(str1)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer stmt1.Close()\r\n\t\r\n\tstr2 := fmt.Sprintf(\"INSERT INTO %ss_devices_config (%s_device_id, key, value) VALUES (?, ?, ?)\", w, w)\r\n\tstmt2, err := tx.Prepare(str2)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer stmt2.Close()\r\n\t\r\n\tfor k, v := range devices {\r\n\t\tt, err := dbDeviceTypeToInt(v[\"type\"])\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tresult, err := stmt1.Exec(cID, k, t)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tid64, err := result.LastInsertId()\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"Error inserting device %s into database\", k)\r\n\t\t}\r\n\t\tid := int(id64)\r\n\t\tfor ck, cv := range v {\r\n\t\t\t\r\n\t\t\tif ck == \"type\" || cv == \"\" {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\t_, err = stmt2.Exec(id, ck, cv)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":447,"reference":"\/\/ DevicesAdd adds a new device.","result":"Add a new device to the database.","score":[0.2284,0.4827]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) Devices(project, qName string, isprofile bool) (types.Devices, error) {\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tenabled, err := tx.ProjectHasProfiles(project)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif !enabled {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar q string\r\n\tif isprofile {\r\n\t\tq = `SELECT profiles_devices.id, profiles_devices.name, profiles_devices.type\r\n\t\t\tFROM profiles_devices\r\n                        JOIN profiles ON profiles_devices.profile_id = profiles.id\r\n                        JOIN projects ON projects.id=profiles.project_id\r\n   \t\tWHERE projects.name=? AND profiles.name=?`\r\n\t} else {\r\n\t\tq = `SELECT containers_devices.id, containers_devices.name, containers_devices.type\r\n\t\t\tFROM containers_devices\r\n                        JOIN containers\tON containers_devices.container_id = containers.id\r\n                        JOIN projects ON projects.id=containers.project_id\r\n\t\t\tWHERE projects.name=? AND containers.name=?`\r\n\t}\r\n\tvar id, dtype int\r\n\tvar name, stype string\r\n\tinargs := []interface{}{project, qName}\r\n\toutfmt := []interface{}{id, name, dtype}\r\n\tresults, err := queryScan(c.db, q, inargs, outfmt)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdevices := types.Devices{}\r\n\tfor _, r := range results {\r\n\t\tid = r[0].(int)\r\n\t\tname = r[1].(string)\r\n\t\tstype, err = dbDeviceTypeToString(r[2].(int))\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tnewdev, err := dbDeviceConfig(c.db, id, isprofile)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tnewdev[\"type\"] = stype\r\n\t\tdevices[name] = newdev\r\n\t}\r\n\treturn devices, nil\r\n}","code-length":581,"reference":"\/\/ Devices returns the devices matching the given filters.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *Node) Patches() ([]string, error) {\r\n\tinargs := []interface{}{}\r\n\toutfmt := []interface{}{\"\"}\r\n\tquery := fmt.Sprintf(\"SELECT name FROM patches\")\r\n\tresult, err := queryScan(n.db, query, inargs, outfmt)\r\n\tif err != nil {\r\n\t\treturn []string{}, err\r\n\t}\r\n\tresponse := []string{}\r\n\tfor _, r := range result {\r\n\t\tresponse = append(response, r[0].(string))\r\n\t}\r\n\treturn response, nil\r\n}","code-length":156,"reference":"\/\/ Patches returns the names of all patches currently applied on this node.","result":"Fetch patches from the database.","score":[0.0577,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *Node) PatchesMarkApplied(patch string) error {\r\n\tstmt := `INSERT INTO patches (name, applied_at) VALUES (?, strftime(\"%s\"));`\r\n\t_, err := n.db.Exec(stmt, patch)\r\n\treturn err\r\n}","code-length":75,"reference":"\/\/ PatchesMarkApplied marks the patch with the given name as applied on this node.","result":"Mark the node as applied.","score":[0.0472,0.1145]}
{"code":"\/*is used to<extra_id_0>\r\nfunc entityType(pkg string, entity string) string {\r\n\ttyp := lex.Capital(entity)\r\n\tif pkg != \"db\" {\r\n\t\ttyp = pkg + \".\" + typ\r\n\t}\r\n\treturn typ\r\n}","code-length":65,"reference":"\/\/ Return Go type of the given database entity.","result":"Generate the entity type .","score":[0.1284,0.1163]}
{"code":"\/*is used to<extra_id_0>\r\nfunc entityPost(entity string) string {\r\n\treturn fmt.Sprintf(\"%sPost\", lex.Capital(lex.Plural(entity)))\r\n}","code-length":44,"reference":"\/\/ Return the name of the Post struct for the given entity.","result":"Generate post entity functions.","score":[0,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc stmtCodeVar(entity string, kind string, filters ...string) string {\r\n\tname := fmt.Sprintf(\"%s%s\", entity, lex.Camel(kind))\r\n\tif len(filters) > 0 {\r\n\t\tname += \"By\"\r\n\t\tname += strings.Join(filters, \"And\")\r\n\t}\r\n\treturn name\r\n}","code-length":95,"reference":"\/\/ Return the name of the global variable holding the registration code for\n\/\/ the given kind of statement aganst the given entity.","result":"Generate code variables.","score":[0.0005,0.0238]}
{"code":"\/*is used to<extra_id_0>\r\nfunc destFunc(slice string, typ string, fields []*Field) string {\r\n\tf := fmt.Sprintf(`func(i int) []interface{} {\r\n                      %s = append(%s, %s{})\r\n                      return []interface{}{\r\n`, slice, slice, typ)\r\n\tfor _, field := range fields {\r\n\t\tf += fmt.Sprintf(\"&%s[i].%s,\\n\", slice, field.Name)\r\n\t}\r\n\tf += \"        }\\n\"\r\n\tf += \"}\"\r\n\treturn f\r\n}","code-length":145,"reference":"\/\/ Return the code for a \"dest\" function, to be passed as parameter to\n\/\/ query.SelectObjects in order to scan a single row.","result":"Create a function to create a slice of dests.","score":[0.0338,0.0694]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CompareConfigs(config1, config2 map[string]string, exclude []string) error {\r\n\tif exclude == nil {\r\n\t\texclude = []string{}\r\n\t}\r\n\tdelta := []string{}\r\n\tfor key, value := range config1 {\r\n\t\tif shared.StringInSlice(key, exclude) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif config2[key] != value {\r\n\t\t\tdelta = append(delta, key)\r\n\t\t}\r\n\t}\r\n\tfor key, value := range config2 {\r\n\t\tif shared.StringInSlice(key, exclude) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif config1[key] != value {\r\n\t\t\tpresent := false\r\n\t\t\tfor i := range delta {\r\n\t\t\t\tif delta[i] == key {\r\n\t\t\t\t\tpresent = true\r\n\t\t\t\t}\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\tif !present {\r\n\t\t\t\tdelta = append(delta, key)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tsort.Strings(delta)\r\n\tif len(delta) > 0 {\r\n\t\treturn fmt.Errorf(\"different values for keys: %s\", strings.Join(delta, \", \"))\r\n\t}\r\n\treturn nil\r\n}","code-length":325,"reference":"\/\/ CompareConfigs compares two config maps and returns an error if they differ.","result":"Compare two maps of configs.","score":[0.0577,0.2095]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CopyConfig(config map[string]string) map[string]string {\r\n\tcopy := map[string]string{}\r\n\tfor key, value := range config {\r\n\t\tcopy[key] = value\r\n\t}\r\n\treturn copy\r\n}","code-length":70,"reference":"\/\/ CopyConfig creates a new map with a copy of the given config.","result":"Copy config.","score":[0.002,0.084]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewNotifier(state *state.State, cert *shared.CertInfo, policy NotifierPolicy) (Notifier, error) {\r\n\taddress, err := node.ClusterAddress(state.Node)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"failed to fetch node address\")\r\n\t}\r\n\t\r\n\tif address == \"\" {\r\n\t\tnullNotifier := func(func(lxd.ContainerServer) error) error { return nil }\r\n\t\treturn nullNotifier, nil\r\n\t}\r\n\tpeers := []string{}\r\n\terr = state.Cluster.Transaction(func(tx *db.ClusterTx) error {\r\n\t\tofflineThreshold, err := tx.NodeOfflineThreshold()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tnodes, err := tx.Nodes()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tfor _, node := range nodes {\r\n\t\t\tif node.Address == address || node.Address == \"0.0.0.0\" {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tif node.IsOffline(offlineThreshold) {\r\n\t\t\t\tswitch policy {\r\n\t\t\t\tcase NotifyAll:\r\n\t\t\t\t\treturn fmt.Errorf(\"peer node %s is down\", node.Address)\r\n\t\t\t\tcase NotifyAlive:\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tpeers = append(peers, node.Address)\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tnotifier := func(hook func(lxd.ContainerServer) error) error {\r\n\t\terrs := make([]error, len(peers))\r\n\t\twg := sync.WaitGroup{}\r\n\t\twg.Add(len(peers))\r\n\t\tfor i, address := range peers {\r\n\t\t\tlogger.Debugf(\"Notify node %s of state changes\", address)\r\n\t\t\tgo func(i int, address string) {\r\n\t\t\t\tdefer wg.Done()\r\n\t\t\t\tclient, err := Connect(address, cert, true)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\terrs[i] = errors.Wrapf(err, \"failed to connect to peer %s\", address)\r\n\t\t\t\t\treturn\r\n\t\t\t\t}\r\n\t\t\t\terr = hook(client)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\terrs[i] = errors.Wrapf(err, \"failed to notify peer %s\", address)\r\n\t\t\t\t}\r\n\t\t\t}(i, address)\r\n\t\t}\r\n\t\twg.Wait()\r\n\t\t\r\n\t\tfor i, err := range errs {\r\n\t\t\tif err != nil {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tif isClientConnectionError(err) && policy == NotifyAlive {\r\n\t\t\t\t\tlogger.Warnf(\"Could not notify node %s\", peers[i])\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\treturn notifier, nil\r\n}","code-length":761,"reference":"\/\/ NewNotifier builds a Notifier that can be used to notify other peers using\n\/\/ the given policy.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Events(endpoints *endpoints.Endpoints, cluster *db.Cluster, f func(int64, api.Event)) (task.Func, task.Schedule) {\r\n\tlisteners := map[int64]*lxd.EventListener{}\r\n\t\r\n\t\r\n\t\r\n\tupdate := func(ctx context.Context) {\r\n\t\tch := make(chan struct{})\r\n\t\tgo func() {\r\n\t\t\teventsUpdateListeners(endpoints, cluster, listeners, f)\r\n\t\t\tch <- struct{}{}\r\n\t\t}()\r\n\t\tselect {\r\n\t\tcase <-ch:\r\n\t\tcase <-ctx.Done():\r\n\t\t}\r\n\t}\r\n\tschedule := task.Every(time.Second)\r\n\treturn update, schedule\r\n}","code-length":188,"reference":"\/\/ Events starts a task that continuously monitors the list of cluster nodes and\n\/\/ maintains a pool of websocket connections against all of them, in order to\n\/\/ get notified about events.\n\/\/\n\/\/ Whenever an event is received the given callback is invoked.","result":"Update the listeners.","score":[0.0,0.0123]}
{"code":"\/*is used to<extra_id_0>\r\nfunc eventsConnect(address string, cert *shared.CertInfo) (*lxd.EventListener, error) {\r\n\tclient, err := Connect(address, cert, true)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\t\r\n\tclient = client.UseProject(\"*\")\r\n\treturn client.GetEvents()\r\n}","code-length":98,"reference":"\/\/ Establish a client connection to get events from the given node.","result":"Connect to the events API.","score":[0.078,0.2793]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageDir) StoragePoolInit() error {\r\n\terr := s.StorageCoreInit()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":59,"reference":"\/\/ Initialize a full storage interface.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getAAProfileContent(c container) string {\r\n\tprofile := strings.TrimLeft(AA_PROFILE_BASE, \"\\n\")\r\n\t\r\n\tif aaParserSupports(\"unix\") {\r\n\t\tprofile += `\r\n  ### Feature: unix\r\n  # Allow receive via unix sockets from anywhere\r\n  unix (receive),\r\n  # Allow all unix in the container\r\n  unix peer=(label=@{profile_name}),\r\n`\r\n\t}\r\n\t\r\n\tif shared.PathExists(\"\/proc\/self\/ns\/cgroup\") {\r\n\t\tprofile += \"\\n  ### Feature: cgroup namespace\\n\"\r\n\t\tprofile += \"  mount fstype=cgroup -> \/sys\/fs\/cgroup\/**,\\n\"\r\n\t\tprofile += \"  mount fstype=cgroup2 -> \/sys\/fs\/cgroup\/**,\\n\"\r\n\t}\r\n\tstate := c.DaemonState()\r\n\tif state.OS.AppArmorStacking && !state.OS.AppArmorStacked {\r\n\t\tprofile += \"\\n  ### Feature: apparmor stacking\\n\"\r\n\t\tprofile += `  ### Configuration: apparmor profile loading (in namespace)\r\n  deny \/sys\/k[^e]*{,\/**} wklx,\r\n  deny \/sys\/ke[^r]*{,\/**} wklx,\r\n  deny \/sys\/ker[^n]*{,\/**} wklx,\r\n  deny \/sys\/kern[^e]*{,\/**} wklx,\r\n  deny \/sys\/kerne[^l]*{,\/**} wklx,\r\n  deny \/sys\/kernel\/[^s]*{,\/**} wklx,\r\n  deny \/sys\/kernel\/s[^e]*{,\/**} wklx,\r\n  deny \/sys\/kernel\/se[^c]*{,\/**} wklx,\r\n  deny \/sys\/kernel\/sec[^u]*{,\/**} wklx,\r\n  deny \/sys\/kernel\/secu[^r]*{,\/**} wklx,\r\n  deny \/sys\/kernel\/secur[^i]*{,\/**} wklx,\r\n  deny \/sys\/kernel\/securi[^t]*{,\/**} wklx,\r\n  deny \/sys\/kernel\/securit[^y]*{,\/**} wklx,\r\n  deny \/sys\/kernel\/security\/[^a]*{,\/**} wklx,\r\n  deny \/sys\/kernel\/security\/a[^p]*{,\/**} wklx,\r\n  deny \/sys\/kernel\/security\/ap[^p]*{,\/**} wklx,\r\n  deny \/sys\/kernel\/security\/app[^a]*{,\/**} wklx,\r\n  deny \/sys\/kernel\/security\/appa[^r]*{,\/**} wklx,\r\n  deny \/sys\/kernel\/security\/appar[^m]*{,\/**} wklx,\r\n  deny \/sys\/kernel\/security\/apparm[^o]*{,\/**} wklx,\r\n  deny \/sys\/kernel\/security\/apparmo[^r]*{,\/**} wklx,\r\n  deny \/sys\/kernel\/security\/apparmor?*{,\/**} wklx,\r\n  deny \/sys\/kernel\/security?*{,\/**} wklx,\r\n  deny \/sys\/kernel?*{,\/**} wklx,\r\n`\r\n\t\tprofile += fmt.Sprintf(\"  change_profile -> \\\":%s:*\\\",\\n\", AANamespace(c))\r\n\t\tprofile += fmt.Sprintf(\"  change_profile -> \\\":%s:\r\n\t} else {\r\n\t\tprofile += \"\\n  ### Feature: apparmor stacking (not present)\\n\"\r\n\t\tprofile += \"  deny \/sys\/k*{,\/**} wklx,\\n\"\r\n\t}\r\n\tif c.IsNesting() {\r\n\t\t\r\n\t\tprofile += \"\\n  ### Configuration: nesting\\n\"\r\n\t\tprofile += strings.TrimLeft(AA_PROFILE_NESTING, \"\\n\")\r\n\t\tif !state.OS.AppArmorStacking || state.OS.AppArmorStacked {\r\n\t\t\tprofile += fmt.Sprintf(\"  change_profile -> \\\"%s\\\",\\n\", AAProfileFull(c))\r\n\t\t}\r\n\t}\r\n\tif !c.IsPrivileged() || state.OS.RunningInUserNS {\r\n\t\t\r\n\t\tprofile += \"\\n  ### Configuration: unprivileged containers\\n\"\r\n\t\tprofile += strings.TrimLeft(AA_PROFILE_UNPRIVILEGED, \"\\n\")\r\n\t}\r\n\t\r\n\trawApparmor, ok := c.ExpandedConfig()[\"raw.apparmor\"]\r\n\tif ok {\r\n\t\tprofile += \"\\n  ### Configuration: raw.apparmor\\n\"\r\n\t\tfor _, line := range strings.Split(strings.Trim(rawApparmor, \"\\n\"), \"\\n\") {\r\n\t\t\tprofile += fmt.Sprintf(\"  %s\\n\", line)\r\n\t\t}\r\n\t}\r\n\treturn fmt.Sprintf(`#include <tunables\/global>\r\nprofile \"%s\" flags=(attach_disconnected,mediate_deleted) {\r\n%s\r\n}\r\n`, AAProfileFull(c), strings.Trim(profile, \"\\n\"))\r\n}","code-length":1284,"reference":"\/\/ getProfileContent generates the apparmor profile template from the given\n\/\/ container. This includes the stock lxc includes as well as stuff from\n\/\/ raw.apparmor.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AALoadProfile(c container) error {\r\n\tstate := c.DaemonState()\r\n\tif !state.OS.AppArmorAdmin {\r\n\t\treturn nil\r\n\t}\r\n\tif err := mkApparmorNamespace(c, AANamespace(c)); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tprofile := path.Join(aaPath, \"profiles\", AAProfileShort(c))\r\n\tcontent, err := ioutil.ReadFile(profile)\r\n\tif err != nil && !os.IsNotExist(err) {\r\n\t\treturn err\r\n\t}\r\n\tupdated := getAAProfileContent(c)\r\n\tif string(content) != string(updated) {\r\n\t\tif err := os.MkdirAll(path.Join(aaPath, \"cache\"), 0700); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif err := os.MkdirAll(path.Join(aaPath, \"profiles\"), 0700); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif err := ioutil.WriteFile(profile, []byte(updated), 0600); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn runApparmor(APPARMOR_CMD_LOAD, c)\r\n}","code-length":330,"reference":"\/\/ Ensure that the container's policy is loaded into the kernel so the\n\/\/ container can boot.","result":"Reload the profile.","score":[0.0038,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AADestroy(c container) error {\r\n\tstate := c.DaemonState()\r\n\tif !state.OS.AppArmorAdmin {\r\n\t\treturn nil\r\n\t}\r\n\tif state.OS.AppArmorStacking && !state.OS.AppArmorStacked {\r\n\t\tp := path.Join(\"\/sys\/kernel\/security\/apparmor\/policy\/namespaces\", AANamespace(c))\r\n\t\tif err := os.Remove(p); err != nil {\r\n\t\t\tlogger.Error(\"Error removing apparmor namespace\", log.Ctx{\"err\": err, \"ns\": p})\r\n\t\t}\r\n\t}\r\n\treturn runApparmor(APPARMOR_CMD_UNLOAD, c)\r\n}","code-length":190,"reference":"\/\/ Ensure that the container's policy namespace is unloaded to free kernel\n\/\/ memory. This does not delete the policy from disk or cache.","result":"Destroy a container.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AAParseProfile(c container) error {\r\n\tstate := c.DaemonState()\r\n\tif !state.OS.AppArmorAvailable {\r\n\t\treturn nil\r\n\t}\r\n\treturn runApparmor(APPARMOR_CMD_PARSE, c)\r\n}","code-length":77,"reference":"\/\/ Parse the profile without loading it into the kernel.","result":"Parse profile from appArmor.","score":[0.0848,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getSystemHandler(syslog string, debug bool, format log.Format) log.Handler {\r\n\treturn nil\r\n}","code-length":37,"reference":"\/\/ getSystemHandler on Windows does nothing.","result":"Get the system handler.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NotifyUpgradeCompleted(state *state.State, cert *shared.CertInfo) error {\r\n\tnotifier, err := NewNotifier(state, cert, NotifyAll)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn notifier(func(client lxd.ContainerServer) error {\r\n\t\tinfo, err := client.GetConnectionInfo()\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"failed to get connection info\")\r\n\t\t}\r\n\t\turl := fmt.Sprintf(\"%s%s\", info.Addresses[0], databaseEndpoint)\r\n\t\trequest, err := http.NewRequest(\"PATCH\", url, nil)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"failed to create database notify upgrade request\")\r\n\t\t}\r\n\t\thttpClient, err := client.GetHTTPClient()\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"failed to get HTTP client\")\r\n\t\t}\r\n\t\tresponse, err := httpClient.Do(request)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"failed to notify node about completed upgrade\")\r\n\t\t}\r\n\t\tif response.StatusCode != http.StatusOK {\r\n\t\t\treturn fmt.Errorf(\"database upgrade notification failed: %s\", response.Status)\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n}","code-length":352,"reference":"\/\/ NotifyUpgradeCompleted sends a notification to all other nodes in the\n\/\/ cluster that any possible pending database update has been applied, and any\n\/\/ nodes which was waiting for this node to be upgraded should re-check if it's\n\/\/ okay to move forward.","result":"Notify the node about completed upgrade.","score":[0.0004,0.0249]}
{"code":"\/*is used to<extra_id_0>\r\nfunc KeepUpdated(state *state.State) (task.Func, task.Schedule) {\r\n\tf := func(ctx context.Context) {\r\n\t\tch := make(chan struct{})\r\n\t\tgo func() {\r\n\t\t\tmaybeUpdate(state)\r\n\t\t\tclose(ch)\r\n\t\t}()\r\n\t\tselect {\r\n\t\tcase <-ctx.Done():\r\n\t\tcase <-ch:\r\n\t\t}\r\n\t}\r\n\tschedule := task.Every(5 * time.Minute)\r\n\treturn f, schedule\r\n}","code-length":143,"reference":"\/\/ KeepUpdated is a task that continuously monitor this node's version to see it\n\/\/ it's out of date with respect to other nodes. In the node is out of date,\n\/\/ and the LXD_CLUSTER_UPDATE environment variable is set, then the task\n\/\/ executes the executable that the variable is pointing at.","result":"Keep the state in the future.","score":[0.0001,0.0316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc maybeUpdate(state *state.State) {\r\n\tshouldUpdate := false\r\n\tenabled, err := Enabled(state.Node)\r\n\tif err != nil {\r\n\t\tlogger.Errorf(\"Failed to check clustering is enabled: %v\", err)\r\n\t\treturn\r\n\t}\r\n\tif !enabled {\r\n\t\treturn\r\n\t}\r\n\terr = state.Cluster.Transaction(func(tx *db.ClusterTx) error {\r\n\t\toutdated, err := tx.NodeIsOutdated()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tshouldUpdate = outdated\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\t\r\n\t\tlogger.Errorf(\"Failed to check if this node is out-of-date: %v\", err)\r\n\t\treturn\r\n\t}\r\n\tif !shouldUpdate {\r\n\t\tlogger.Debugf(\"Cluster node is up-to-date\")\r\n\t\treturn\r\n\t}\r\n\tlogger.Infof(\"Node is out-of-date with respect to other cluster nodes\")\r\n\tupdateExecutable := os.Getenv(\"LXD_CLUSTER_UPDATE\")\r\n\tif updateExecutable == \"\" {\r\n\t\tlogger.Debug(\"No LXD_CLUSTER_UPDATE variable set, skipping auto-update\")\r\n\t\treturn\r\n\t}\r\n\tlogger.Infof(\"Triggering cluster update using: %s\", updateExecutable)\r\n\t_, err = shared.RunCommand(updateExecutable)\r\n\tif err != nil {\r\n\t\tlogger.Errorf(\"Cluster upgrade failed: '%v'\", err.Error())\r\n\t\treturn\r\n\t}\r\n}","code-length":407,"reference":"\/\/ Check this node's version and possibly run LXD_CLUSTER_UPDATE.","result":"Trigger cluster update.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewServer(apiURL string, apiKey string, agentAuthURL string, agentUsername string, agentPrivateKey string, agentPublicKey string) (*Server, error) {\r\n\tr := Server{\r\n\t\tapiURL:          apiURL,\r\n\t\tapiKey:          apiKey,\r\n\t\tlastSyncID:      \"\",\r\n\t\tlastChange:      time.Time{},\r\n\t\tresources:       make(map[string]string),\r\n\t\tpermissions:     make(map[string]map[string][]string),\r\n\t\tpermissionsLock: &sync.Mutex{},\r\n\t}\r\n\t\r\n\tvar keyPair bakery.KeyPair\r\n\tkeyPair.Private.UnmarshalText([]byte(agentPrivateKey))\r\n\tkeyPair.Public.UnmarshalText([]byte(agentPublicKey))\r\n\tr.client = httpbakery.NewClient()\r\n\tauthInfo := agent.AuthInfo{\r\n\t\tKey: &keyPair,\r\n\t\tAgents: []agent.Agent{\r\n\t\t\t{\r\n\t\t\t\tURL:      agentAuthURL,\r\n\t\t\t\tUsername: agentUsername,\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n\terr := agent.SetUpAuth(r.client, &authInfo)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tr.client.Client.Jar, err = cookiejar.New(nil)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &r, nil\r\n}","code-length":367,"reference":"\/\/ NewServer returns a new RBAC server instance.","result":"Create a new server.","score":[0.1662,0.2467]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Server) StartStatusCheck() {\r\n\t\r\n\tr.hasStatusChanged()\r\n\tr.statusDone = make(chan int)\r\n\tgo func() {\r\n\t\tfor {\r\n\t\t\tselect {\r\n\t\t\tcase <-r.statusDone:\r\n\t\t\t\treturn\r\n\t\t\tcase <-time.After(time.Minute):\r\n\t\t\t\tif r.hasStatusChanged() {\r\n\t\t\t\t\tr.flushCache()\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}()\r\n}","code-length":138,"reference":"\/\/ StartStatusCheck starts a periodic status checker.","result":"Start the status check.","score":[0.1509,0.1493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Server) SyncProjects() error {\r\n\tif r.ProjectsFunc == nil {\r\n\t\treturn fmt.Errorf(\"ProjectsFunc isn't configured yet, cannot sync\")\r\n\t}\r\n\tresources := []rbacResource{}\r\n\tresourcesMap := map[string]string{}\r\n\t\r\n\tprojects, err := r.ProjectsFunc()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tfor id, name := range projects {\r\n\t\tresources = append(resources, rbacResource{\r\n\t\t\tName:       name,\r\n\t\t\tIdentifier: strconv.FormatInt(id, 10),\r\n\t\t})\r\n\t\tresourcesMap[name] = strconv.FormatInt(id, 10)\r\n\t}\r\n\t\r\n\terr = r.postResources(resources, nil, true)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tr.resourcesLock.Lock()\r\n\tr.resources = resourcesMap\r\n\tr.resourcesLock.Unlock()\r\n\treturn nil\r\n}","code-length":265,"reference":"\/\/ SyncProjects updates the list of projects in RBAC","result":"Avoid the need for the function to be called.","score":[0.1219,0.0556]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Server) AddProject(id int64, name string) error {\r\n\tresource := rbacResource{\r\n\t\tName:       name,\r\n\t\tIdentifier: strconv.FormatInt(id, 10),\r\n\t}\r\n\t\r\n\terr := r.postResources([]rbacResource{resource}, nil, false)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tr.resourcesLock.Lock()\r\n\tr.resources[name] = strconv.FormatInt(id, 10)\r\n\tr.resourcesLock.Unlock()\r\n\treturn nil\r\n}","code-length":155,"reference":"\/\/ AddProject adds a new project resource to RBAC.","result":"Add a project to the server.","score":[0.1541,0.3628]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Server) DeleteProject(id int64) error {\r\n\t\r\n\terr := r.postResources(nil, []string{strconv.FormatInt(id, 10)}, false)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tr.resourcesLock.Lock()\r\n\tfor k, v := range r.resources {\r\n\t\tif v == strconv.FormatInt(id, 10) {\r\n\t\t\tdelete(r.resources, k)\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tr.resourcesLock.Unlock()\r\n\treturn nil\r\n}","code-length":160,"reference":"\/\/ DeleteProject adds a new project resource to RBAC.","result":"Delete a project.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Server) RenameProject(id int64, name string) error {\r\n\treturn r.AddProject(id, name)\r\n}","code-length":43,"reference":"\/\/ RenameProject renames an existing project resource in RBAC.","result":"Generate the package.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Server) IsAdmin(username string) bool {\r\n\tr.permissionsLock.Lock()\r\n\tdefer r.permissionsLock.Unlock()\r\n\t\r\n\t_, cached := r.permissions[username]\r\n\tif !cached {\r\n\t\tr.syncPermissions(username)\r\n\t}\r\n\treturn shared.StringInSlice(\"admin\", r.permissions[username][\"\"])\r\n}","code-length":105,"reference":"\/\/ IsAdmin returns whether or not the provided user is an admin.","result":"Check if the user is an admin.","score":[0.2617,0.4209]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Server) HasPermission(username, project, permission string) bool {\r\n\tr.permissionsLock.Lock()\r\n\tdefer r.permissionsLock.Unlock()\r\n\t\r\n\t_, cached := r.permissions[username]\r\n\tif !cached {\r\n\t\tr.syncPermissions(username)\r\n\t}\r\n\tr.resourcesLock.Lock()\r\n\tpermissions := r.permissions[username][r.resources[project]]\r\n\tr.resourcesLock.Unlock()\r\n\treturn shared.StringInSlice(permission, permissions)\r\n}","code-length":140,"reference":"\/\/ HasPermission returns whether or not the user has the permission to perform a certain task.","result":"Check if a user has the permission.","score":[0.0988,0.2483]}
{"code":"\/*is used to<extra_id_0>\r\nfunc rsyncSend(conn *websocket.Conn, path string, rsyncArgs string) error {\r\n\tcmd, dataSocket, stderr, err := rsyncSendSetup(path, rsyncArgs)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif dataSocket != nil {\r\n\t\tdefer dataSocket.Close()\r\n\t}\r\n\treadDone, writeDone := shared.WebsocketMirror(conn, dataSocket, io.ReadCloser(dataSocket), nil, nil)\r\n\toutput, err := ioutil.ReadAll(stderr)\r\n\tif err != nil {\r\n\t\tcmd.Process.Kill()\r\n\t\tcmd.Wait()\r\n\t\treturn fmt.Errorf(\"Failed to rsync: %v\\n%s\", err, output)\r\n\t}\r\n\terr = cmd.Wait()\r\n\t<-readDone\r\n\t<-writeDone\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"Failed to rsync: %v\\n%s\", err, output)\r\n\t}\r\n\treturn nil\r\n}","code-length":262,"reference":"\/\/ Send an rsync stream of a path over a websocket","result":"Send a file to a remote server.","score":[0.12,0.1415]}
{"code":"\/*is used to<extra_id_0>\r\nfunc rsyncSendSetup(path string, rsyncArgs string) (*exec.Cmd, net.Conn, io.ReadCloser, error) {\r\n\tauds := fmt.Sprintf(\"@lxd-p2c\/%s\", uuid.NewRandom().String())\r\n\tif len(auds) > shared.ABSTRACT_UNIX_SOCK_LEN-1 {\r\n\t\tauds = auds[:shared.ABSTRACT_UNIX_SOCK_LEN-1]\r\n\t}\r\n\tl, err := net.Listen(\"unix\", auds)\r\n\tif err != nil {\r\n\t\treturn nil, nil, nil, err\r\n\t}\r\n\texecPath, err := os.Readlink(\"\/proc\/self\/exe\")\r\n\tif err != nil {\r\n\t\treturn nil, nil, nil, err\r\n\t}\r\n\tif !shared.PathExists(execPath) {\r\n\t\texecPath = os.Args[0]\r\n\t}\r\n\trsyncCmd := fmt.Sprintf(\"sh -c \\\"%s netcat %s\\\"\", execPath, auds)\r\n\targs := []string{\r\n\t\t\"-ar\",\r\n\t\t\"--devices\",\r\n\t\t\"--numeric-ids\",\r\n\t\t\"--partial\",\r\n\t\t\"--sparse\",\r\n\t\t\"--xattrs\",\r\n\t\t\"--delete\",\r\n\t\t\"--compress\",\r\n\t\t\"--compress-level=2\",\r\n\t}\r\n\t\r\n\trsyncCheckVersion := func(min string) bool {\r\n\t\tout, err := shared.RunCommand(\"rsync\", \"--version\")\r\n\t\tif err != nil {\r\n\t\t\treturn false\r\n\t\t}\r\n\t\tfields := strings.Split(out, \" \")\r\n\t\tcurVer, err := version.Parse(fields[3])\r\n\t\tif err != nil {\r\n\t\t\treturn false\r\n\t\t}\r\n\t\tminVer, err := version.Parse(min)\r\n\t\tif err != nil {\r\n\t\t\treturn false\r\n\t\t}\r\n\t\treturn curVer.Compare(minVer) >= 0\r\n\t}\r\n\tif rsyncCheckVersion(\"3.1.0\") {\r\n\t\targs = append(args, \"--ignore-missing-args\")\r\n\t}\r\n\tif rsyncArgs != \"\" {\r\n\t\targs = append(args, strings.Split(rsyncArgs, \" \")...)\r\n\t}\r\n\targs = append(args, []string{path, \"localhost:\/tmp\/foo\"}...)\r\n\targs = append(args, []string{\"-e\", rsyncCmd}...)\r\n\tcmd := exec.Command(\"rsync\", args...)\r\n\tcmd.Stdout = os.Stderr\r\n\tstderr, err := cmd.StderrPipe()\r\n\tif err != nil {\r\n\t\treturn nil, nil, nil, err\r\n\t}\r\n\tif err := cmd.Start(); err != nil {\r\n\t\treturn nil, nil, nil, err\r\n\t}\r\n\tconn, err := l.Accept()\r\n\tif err != nil {\r\n\t\tcmd.Process.Kill()\r\n\t\tcmd.Wait()\r\n\t\treturn nil, nil, nil, err\r\n\t}\r\n\tl.Close()\r\n\treturn cmd, conn, stderr, nil\r\n}","code-length":797,"reference":"\/\/ Spawn the rsync process","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc tlsClientConfig(info *shared.CertInfo) (*tls.Config, error) {\r\n\tkeypair := info.KeyPair()\r\n\tca := info.CA()\r\n\tconfig := shared.InitTLSConfig()\r\n\tconfig.Certificates = []tls.Certificate{keypair}\r\n\tconfig.RootCAs = x509.NewCertPool()\r\n\tif ca != nil {\r\n\t\tconfig.RootCAs.AddCert(ca)\r\n\t}\r\n\t\r\n\t\r\n\tcert, err := x509.ParseCertificate(keypair.Certificate[0])\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tcert.IsCA = true\r\n\tcert.KeyUsage = x509.KeyUsageCertSign\r\n\tconfig.RootCAs.AddCert(cert)\r\n\tif cert.DNSNames != nil {\r\n\t\tconfig.ServerName = cert.DNSNames[0]\r\n\t}\r\n\treturn config, nil\r\n}","code-length":236,"reference":"\/\/ Return a TLS configuration suitable for establishing inter-node network\n\/\/ connections using the cluster certificate.","result":"Create a TLS client.","score":[0.0225,0.1267]}
{"code":"\/*is used to<extra_id_0>\r\nfunc tlsCheckCert(r *http.Request, info *shared.CertInfo) bool {\r\n\tcert, err := x509.ParseCertificate(info.KeyPair().Certificate[0])\r\n\tif err != nil {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tpanic(fmt.Sprintf(\"invalid keypair material: %v\", err))\r\n\t}\r\n\ttrustedCerts := map[string]x509.Certificate{\"0\": *cert}\r\n\ttrusted, _ := util.CheckTrustState(*r.TLS.PeerCertificates[0], trustedCerts)\r\n\treturn r.TLS != nil && trusted\r\n}","code-length":151,"reference":"\/\/ Return true if the given request is presenting the given cluster certificate.","result":"Check the certificate.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc internalClusterContainerMovedPost(d *Daemon, r *http.Request) Response {\r\n\tproject := projectParam(r)\r\n\tcontainerName := mux.Vars(r)[\"name\"]\r\n\terr := containerPostCreateContainerMountPoint(d, project, containerName)\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\treturn EmptySyncResponse\r\n}","code-length":103,"reference":"\/\/ Notification that a container was moved.\n\/\/\n\/\/ At the moment it's used for ceph-based containers, where the target node needs\n\/\/ to create the appropriate mount points.","result":"Create the container mount point.","score":[0.0026,0.1187]}
{"code":"\/*is used to<extra_id_0>\r\nfunc containerPostCreateContainerMountPoint(d *Daemon, project, containerName string) error {\r\n\tc, err := containerLoadByProjectAndName(d.State(), project, containerName)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Failed to load moved container on target node\")\r\n\t}\r\n\tpoolName, err := c.StoragePool()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Failed get pool name of moved container on target node\")\r\n\t}\r\n\tsnapshotNames, err := d.cluster.ContainerGetSnapshots(project, containerName)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Failed to create container snapshot names\")\r\n\t}\r\n\tcontainerMntPoint := getContainerMountPoint(c.Project(), poolName, containerName)\r\n\terr = createContainerMountpoint(containerMntPoint, c.Path(), c.IsPrivileged())\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Failed to create container mount point on target node\")\r\n\t}\r\n\tfor _, snapshotName := range snapshotNames {\r\n\t\tmntPoint := getSnapshotMountPoint(project, poolName, snapshotName)\r\n\t\tsnapshotsSymlinkTarget := shared.VarPath(\"storage-pools\",\r\n\t\t\tpoolName, \"containers-snapshots\", containerName)\r\n\t\tsnapshotMntPointSymlink := shared.VarPath(\"snapshots\", containerName)\r\n\t\terr := createSnapshotMountpoint(mntPoint, snapshotsSymlinkTarget, snapshotMntPointSymlink)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Failed to create snapshot mount point on target node\")\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":410,"reference":"\/\/ Used after to create the appropriate mounts point after a container has been\n\/\/ moved.","result":"Create the container mount point on the target node.","score":[0.0737,0.2431]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (list Devices) Contains(k string, d Device) bool {\r\n\t\r\n\tif list[k] == nil {\r\n\t\treturn false\r\n\t}\r\n\told := list[k]\r\n\treturn deviceEquals(old, d)\r\n}","code-length":71,"reference":"\/\/ Contains checks if a given device exists in the set and if it's\n\/\/ identical to that provided","result":"Check if the device contains a Device.","score":[0.0411,0.1685]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (list Devices) Update(newlist Devices) (map[string]Device, map[string]Device, map[string]Device, []string) {\r\n\trmlist := map[string]Device{}\r\n\taddlist := map[string]Device{}\r\n\tupdatelist := map[string]Device{}\r\n\tfor key, d := range list {\r\n\t\tif !newlist.Contains(key, d) {\r\n\t\t\trmlist[key] = d\r\n\t\t}\r\n\t}\r\n\tfor key, d := range newlist {\r\n\t\tif !list.Contains(key, d) {\r\n\t\t\taddlist[key] = d\r\n\t\t}\r\n\t}\r\n\tupdateDiff := []string{}\r\n\tfor key, d := range addlist {\r\n\t\tsrcOldDevice := rmlist[key]\r\n\t\tvar oldDevice Device\r\n\t\terr := shared.DeepCopy(&srcOldDevice, &oldDevice)\r\n\t\tif err != nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tsrcNewDevice := newlist[key]\r\n\t\tvar newDevice Device\r\n\t\terr = shared.DeepCopy(&srcNewDevice, &newDevice)\r\n\t\tif err != nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tupdateDiff = deviceEqualsDiffKeys(oldDevice, newDevice)\r\n\t\tfor _, k := range []string{\"limits.max\", \"limits.read\", \"limits.write\", \"limits.egress\", \"limits.ingress\", \"ipv4.address\", \"ipv6.address\", \"ipv4.routes\", \"ipv6.routes\"} {\r\n\t\t\tdelete(oldDevice, k)\r\n\t\t\tdelete(newDevice, k)\r\n\t\t}\r\n\t\tif deviceEquals(oldDevice, newDevice) {\r\n\t\t\tdelete(rmlist, key)\r\n\t\t\tdelete(addlist, key)\r\n\t\t\tupdatelist[key] = d\r\n\t\t}\r\n\t}\r\n\treturn rmlist, addlist, updatelist, updateDiff\r\n}","code-length":505,"reference":"\/\/ Update returns the difference between two sets","result":"Update the device list.","score":[0.1398,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (list Devices) DeviceNames() []string {\r\n\tsortable := sortableDevices{}\r\n\tfor k, d := range list {\r\n\t\tsortable = append(sortable, namedDevice{k, d})\r\n\t}\r\n\tsort.Sort(sortable)\r\n\treturn sortable.Names()\r\n}","code-length":80,"reference":"\/\/ DeviceNames returns the name of all devices in the set, sorted properly","result":"Generate the generated code.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Infof(format string, args ...interface{}) {\r\n\tif Log != nil {\r\n\t\tLog.Info(fmt.Sprintf(format, args...))\r\n\t}\r\n}","code-length":54,"reference":"\/\/ Infof logs at the INFO log level using a standard printf format string","result":"Print the log message.","score":[0.0312,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Debugf(format string, args ...interface{}) {\r\n\tif Log != nil {\r\n\t\tLog.Debug(fmt.Sprintf(format, args...))\r\n\t}\r\n}","code-length":54,"reference":"\/\/ Debugf logs at the DEBUG log level using a standard printf format string","result":"Debug the log.","score":[0.0104,0.0775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Warnf(format string, args ...interface{}) {\r\n\tif Log != nil {\r\n\t\tLog.Warn(fmt.Sprintf(format, args...))\r\n\t}\r\n}","code-length":54,"reference":"\/\/ Warnf logs at the WARNING log level using a standard printf format string","result":"Print warnings and errors to the console.","score":[0.0594,0.0752]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Errorf(format string, args ...interface{}) {\r\n\tif Log != nil {\r\n\t\tLog.Error(fmt.Sprintf(format, args...))\r\n\t}\r\n}","code-length":54,"reference":"\/\/ Errorf logs at the ERROR log level using a standard printf format string","result":"Print error messages.","score":[0,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Critf(format string, args ...interface{}) {\r\n\tif Log != nil {\r\n\t\tLog.Crit(fmt.Sprintf(format, args...))\r\n\t}\r\n}","code-length":57,"reference":"\/\/ Critf logs at the CRITICAL log level using a standard printf format string","result":"Print the log message.","score":[0.0312,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc eventForward(id int64, event api.Event) {\r\n\tif event.Type == \"logging\" {\r\n\t\t\r\n\t\tlogEntry := api.EventLogging{}\r\n\t\terr := json.Unmarshal(event.Metadata, &logEntry)\r\n\t\tif err != nil {\r\n\t\t\treturn\r\n\t\t}\r\n\t\tif !debug && logEntry.Level == \"dbug\" {\r\n\t\t\treturn\r\n\t\t}\r\n\t\tif !debug && !verbose && logEntry.Level == \"info\" {\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n\terr := eventBroadcast(\"\", event, true)\r\n\tif err != nil {\r\n\t\tlogger.Warnf(\"Failed to forward event from node %d: %v\", id, err)\r\n\t}\r\n}","code-length":202,"reference":"\/\/ Forward to the local events dispatcher an event received from another node .","result":"Forward events from the node.","score":[0.0562,0.1527]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StorageProgressReader(op *operation, key string, description string) func(io.ReadCloser) io.ReadCloser {\r\n\treturn func(reader io.ReadCloser) io.ReadCloser {\r\n\t\tif op == nil {\r\n\t\t\treturn reader\r\n\t\t}\r\n\t\tprogress := func(progressInt int64, speedInt int64) {\r\n\t\t\tprogressWrapperRender(op, key, description, progressInt, speedInt)\r\n\t\t}\r\n\t\treadPipe := &ioprogress.ProgressReader{\r\n\t\t\tReadCloser: reader,\r\n\t\t\tTracker: &ioprogress.ProgressTracker{\r\n\t\t\t\tHandler: progress,\r\n\t\t\t},\r\n\t\t}\r\n\t\treturn readPipe\r\n\t}\r\n}","code-length":189,"reference":"\/\/ StorageProgressReader reports the read progress.","result":"Wrap progress reader in a progress reader.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StorageProgressWriter(op *operation, key string, description string) func(io.WriteCloser) io.WriteCloser {\r\n\treturn func(writer io.WriteCloser) io.WriteCloser {\r\n\t\tif op == nil {\r\n\t\t\treturn writer\r\n\t\t}\r\n\t\tprogress := func(progressInt int64, speedInt int64) {\r\n\t\t\tprogressWrapperRender(op, key, description, progressInt, speedInt)\r\n\t\t}\r\n\t\twritePipe := &ioprogress.ProgressWriter{\r\n\t\t\tWriteCloser: writer,\r\n\t\t\tTracker: &ioprogress.ProgressTracker{\r\n\t\t\t\tHandler: progress,\r\n\t\t\t},\r\n\t\t}\r\n\t\treturn writePipe\r\n\t}\r\n}","code-length":189,"reference":"\/\/ StorageProgressWriter reports the write progress.","result":"Write progress to storage.","score":[0,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetLSBRelease() (map[string]string, error) {\r\n\tosRelease, err := getLSBRelease(\"\/etc\/os-release\")\r\n\tif os.IsNotExist(err) {\r\n\t\treturn getLSBRelease(\"\/usr\/lib\/os-release\")\r\n\t}\r\n\treturn osRelease, err\r\n}","code-length":91,"reference":"\/\/ GetLSBRelease returns a map with Linux distribution information","result":"Get the lsb release of the current OS.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Reset(path string, imports []string) error {\r\n\tcontent := fmt.Sprintf(`package %s\r\nimport (\r\n`, os.Getenv(\"GOPACKAGE\"), os.Args[0])\r\n\tfor _, uri := range imports {\r\n\t\tcontent += fmt.Sprintf(\"\\t%q\\n\", uri)\r\n\t}\r\n\tcontent += \")\\n\\n\"\r\n\t\r\n\tcontent += \"var _ = api.ServerEnvironment{}\\n\"\r\n\tbytes := []byte(content)\r\n\tvar err error\r\n\tif path == \"-\" {\r\n\t\t_, err = os.Stdout.Write(bytes)\r\n\t} else {\r\n\t\terr = ioutil.WriteFile(path, []byte(content), 0644)\r\n\t}\r\n\tif err != nil {\r\n\t\terrors.Wrapf(err, \"Reset target source file '%s'\", path)\r\n\t}\r\n\treturn nil\r\n}","code-length":235,"reference":"\/\/ Reset an auto-generated source file, writing a new empty file header.","result":"Reset the source file.","score":[0.0514,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Append(path string, snippet Snippet) error {\r\n\tbuffer := newBuffer()\r\n\tbuffer.N()\r\n\terr := snippet.Generate(buffer)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Generate code snippet\")\r\n\t}\r\n\tvar file *os.File\r\n\tif path == \"-\" {\r\n\t\tfile = os.Stdout\r\n\t} else {\r\n\t\tfile, err = os.OpenFile(path, os.O_APPEND|os.O_WRONLY, 0644)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"Open target source code file '%s'\", path)\r\n\t\t}\r\n\t\tdefer file.Close()\r\n\t}\r\n\tbytes, err := buffer.code()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t_, err = file.Write(bytes)\r\n\tif err != nil {\r\n\t\treturn errors.Wrapf(err, \"Append snippet to target source code file '%s'\", path)\r\n\t}\r\n\treturn nil\r\n}","code-length":276,"reference":"\/\/ Append a code snippet to a file.","result":"Append code snippet to a target source code file.","score":[0.4221,0.631]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ContainerToArgs(container *Container) ContainerArgs {\r\n\targs := ContainerArgs{\r\n\t\tID:           container.ID,\r\n\t\tProject:      container.Project,\r\n\t\tName:         container.Name,\r\n\t\tNode:         container.Node,\r\n\t\tCtype:        ContainerType(container.Type),\r\n\t\tArchitecture: container.Architecture,\r\n\t\tEphemeral:    container.Ephemeral,\r\n\t\tCreationDate: container.CreationDate,\r\n\t\tStateful:     container.Stateful,\r\n\t\tLastUsedDate: container.LastUseDate,\r\n\t\tDescription:  container.Description,\r\n\t\tConfig:       container.Config,\r\n\t\tDevices:      container.Devices,\r\n\t\tProfiles:     container.Profiles,\r\n\t\tExpiryDate:   container.ExpiryDate,\r\n\t}\r\n\tif args.Devices == nil {\r\n\t\targs.Devices = types.Devices{}\r\n\t}\r\n\treturn args\r\n}","code-length":245,"reference":"\/\/ ContainerToArgs is a convenience to convert the new Container db struct into\n\/\/ the legacy ContainerArgs.","result":"Convert a container to args.","score":[0.0259,0.1266]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ContainerNames(project string) ([]string, error) {\r\n\tstmt := `\r\nSELECT containers.name FROM containers\r\n  JOIN projects ON projects.id = containers.project_id\r\n  WHERE projects.name = ? AND containers.type = ?\r\n`\r\n\treturn query.SelectStrings(c.tx, stmt, project, CTypeRegular)\r\n}","code-length":100,"reference":"\/\/ ContainerNames returns the names of all containers the given project.","result":"Generate the code.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ContainerNodeAddress(project string, name string) (string, error) {\r\n\tstmt := `\r\nSELECT nodes.id, nodes.address\r\n  FROM nodes\r\n  JOIN containers ON containers.node_id = nodes.id\r\n  JOIN projects ON projects.id = containers.project_id\r\n WHERE projects.name = ? AND containers.name = ?\r\n`\r\n\tvar address string\r\n\tvar id int64\r\n\trows, err := c.tx.Query(stmt, project, name)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tdefer rows.Close()\r\n\tif !rows.Next() {\r\n\t\treturn \"\", ErrNoSuchObject\r\n\t}\r\n\terr = rows.Scan(&id, &address)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tif rows.Next() {\r\n\t\treturn \"\", fmt.Errorf(\"more than one node associated with container\")\r\n\t}\r\n\terr = rows.Err()\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tif id == c.nodeID {\r\n\t\treturn \"\", nil\r\n\t}\r\n\treturn address, nil\r\n}","code-length":307,"reference":"\/\/ ContainerNodeAddress returns the address of the node hosting the container\n\/\/ with the given name in the given project.\n\/\/\n\/\/ It returns the empty string if the container is hosted on this node.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ContainersListByNodeAddress(project string) (map[string][]string, error) {\r\n\tofflineThreshold, err := c.NodeOfflineThreshold()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tstmt := `\r\nSELECT containers.name, nodes.id, nodes.address, nodes.heartbeat\r\n  FROM containers\r\n  JOIN nodes ON nodes.id = containers.node_id\r\n  JOIN projects ON projects.id = containers.project_id\r\n  WHERE containers.type=?\r\n    AND projects.name = ?\r\n  ORDER BY containers.id\r\n`\r\n\trows, err := c.tx.Query(stmt, CTypeRegular, project)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer rows.Close()\r\n\tresult := map[string][]string{}\r\n\tfor i := 0; rows.Next(); i++ {\r\n\t\tvar name string\r\n\t\tvar nodeAddress string\r\n\t\tvar nodeID int64\r\n\t\tvar nodeHeartbeat time.Time\r\n\t\terr := rows.Scan(&name, &nodeID, &nodeAddress, &nodeHeartbeat)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tif nodeID == c.nodeID {\r\n\t\t\tnodeAddress = \"\"\r\n\t\t} else if nodeIsOffline(offlineThreshold, nodeHeartbeat) {\r\n\t\t\tnodeAddress = \"0.0.0.0\"\r\n\t\t}\r\n\t\tresult[nodeAddress] = append(result[nodeAddress], name)\r\n\t}\r\n\terr = rows.Err()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn result, nil\r\n}","code-length":434,"reference":"\/\/ ContainersListByNodeAddress returns the names of all containers grouped by\n\/\/ cluster node address.\n\/\/\n\/\/ The node address of containers running on the local node is set to the empty\n\/\/ string, to distinguish it from remote nodes.\n\/\/\n\/\/ Containers whose node is down are addeded to the special address \"0.0.0.0\".","result":"Fetch the containers list by node address.","score":[0.0004,0.062]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ContainerListExpanded() ([]Container, error) {\r\n\tcontainers, err := c.ContainerList(ContainerFilter{})\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Load containers\")\r\n\t}\r\n\tprofiles, err := c.ProfileList(ProfileFilter{})\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Load profiles\")\r\n\t}\r\n\t\r\n\tprofilesByProjectAndName := map[string]map[string]Profile{}\r\n\tfor _, profile := range profiles {\r\n\t\tprofilesByName, ok := profilesByProjectAndName[profile.Project]\r\n\t\tif !ok {\r\n\t\t\tprofilesByName = map[string]Profile{}\r\n\t\t\tprofilesByProjectAndName[profile.Project] = profilesByName\r\n\t\t}\r\n\t\tprofilesByName[profile.Name] = profile\r\n\t}\r\n\tfor i, container := range containers {\r\n\t\tprofiles := make([]api.Profile, len(container.Profiles))\r\n\t\tfor j, name := range container.Profiles {\r\n\t\t\tprofile := profilesByProjectAndName[container.Project][name]\r\n\t\t\tprofiles[j] = *ProfileToAPI(&profile)\r\n\t\t}\r\n\t\tcontainers[i].Config = ProfilesExpandConfig(container.Config, profiles)\r\n\t\tcontainers[i].Devices = ProfilesExpandDevices(container.Devices, profiles)\r\n\t}\r\n\treturn containers, nil\r\n}","code-length":369,"reference":"\/\/ ContainerListExpanded loads all containers across all projects and expands\n\/\/ their config and devices using the profiles they are associated to.","result":"Expand the container list of the cluster tx.","score":[0.0241,0.0728]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ContainersByNodeName(project string) (map[string]string, error) {\r\n\tstmt := `\r\nSELECT containers.name, nodes.name\r\n  FROM containers\r\n  JOIN nodes ON nodes.id = containers.node_id\r\n  JOIN projects ON projects.id = containers.project_id\r\n  WHERE containers.type=?\r\n    AND projects.name = ?\r\n`\r\n\trows, err := c.tx.Query(stmt, CTypeRegular, project)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer rows.Close()\r\n\tresult := map[string]string{}\r\n\tfor i := 0; rows.Next(); i++ {\r\n\t\tvar name string\r\n\t\tvar nodeName string\r\n\t\terr := rows.Scan(&name, &nodeName)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tresult[name] = nodeName\r\n\t}\r\n\terr = rows.Err()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn result, nil\r\n}","code-length":285,"reference":"\/\/ ContainersByNodeName returns a map associating each container to the name of\n\/\/ its node.","result":"Return containers by node name.","score":[0,0.0714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) SnapshotIDsAndNames(name string) (map[int]string, error) {\r\n\tprefix := name + shared.SnapshotDelimiter\r\n\tlength := len(prefix)\r\n\tobjects := make([]struct {\r\n\t\tID   int\r\n\t\tName string\r\n\t}, 0)\r\n\tdest := func(i int) []interface{} {\r\n\t\tobjects = append(objects, struct {\r\n\t\t\tID   int\r\n\t\t\tName string\r\n\t\t}{})\r\n\t\treturn []interface{}{&objects[i].ID, &objects[i].Name}\r\n\t}\r\n\tstmt, err := c.tx.Prepare(\"SELECT id, name FROM containers WHERE SUBSTR(name,1,?)=? AND type=?\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer stmt.Close()\r\n\terr = query.SelectObjects(stmt, dest, length, prefix, CTypeSnapshot)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tresult := make(map[int]string)\r\n\tfor i := range objects {\r\n\t\tresult[objects[i].ID] = strings.Split(objects[i].Name, shared.SnapshotDelimiter)[1]\r\n\t}\r\n\treturn result, nil\r\n}","code-length":325,"reference":"\/\/ SnapshotIDsAndNames returns a map of snapshot IDs to snapshot names for the\n\/\/ container with the given name.","result":"Generate the code.","score":[0.002,0.0287]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ContainerNodeList() ([]Container, error) {\r\n\tnode, err := c.NodeName()\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Local node name\")\r\n\t}\r\n\tfilter := ContainerFilter{\r\n\t\tNode: node,\r\n\t\tType: int(CTypeRegular),\r\n\t}\r\n\treturn c.ContainerList(filter)\r\n}","code-length":113,"reference":"\/\/ ContainerNodeList returns all container objects on the local node.","result":"Generate code for the generated code.","score":[0.0991,0.0521]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ContainerNodeProjectList(project string) ([]Container, error) {\r\n\tnode, err := c.NodeName()\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Local node name\")\r\n\t}\r\n\tfilter := ContainerFilter{\r\n\t\tProject: project,\r\n\t\tNode:    node,\r\n\t\tType:    int(CTypeRegular),\r\n\t}\r\n\treturn c.ContainerList(filter)\r\n}","code-length":128,"reference":"\/\/ ContainerNodeProjectList returns all container objects on the local node within the given project.","result":"List containers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ContainerRemove(project, name string) error {\r\n\treturn c.Transaction(func(tx *ClusterTx) error {\r\n\t\treturn tx.ContainerDelete(project, name)\r\n\t})\r\n}","code-length":63,"reference":"\/\/ ContainerRemove removes the container with the given name from the database.","result":"Remove the container.","score":[0.0203,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ContainerProjectAndName(id int) (string, string, error) {\r\n\tq := `\r\nSELECT projects.name, containers.name\r\n  FROM containers\r\n  JOIN projects ON projects.id = containers.project_id\r\nWHERE containers.id=?\r\n`\r\n\tproject := \"\"\r\n\tname := \"\"\r\n\targ1 := []interface{}{id}\r\n\targ2 := []interface{}{&project, &name}\r\n\terr := dbQueryRowScan(c.db, q, arg1, arg2)\r\n\tif err == sql.ErrNoRows {\r\n\t\treturn \"\", \"\", ErrNoSuchObject\r\n\t}\r\n\treturn project, name, err\r\n}","code-length":177,"reference":"\/\/ ContainerProjectAndName returns the project and the name of the container\n\/\/ with the given ID.","result":"Generate the generated code.","score":[0.0159,0.0338]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ContainerConfigClear(tx *sql.Tx, id int) error {\r\n\t_, err := tx.Exec(\"DELETE FROM containers_config WHERE container_id=?\", id)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t_, err = tx.Exec(\"DELETE FROM containers_profiles WHERE container_id=?\", id)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t_, err = tx.Exec(`DELETE FROM containers_devices_config WHERE id IN\r\n\t\t(SELECT containers_devices_config.id\r\n\t\t FROM containers_devices_config JOIN containers_devices\r\n\t\t ON containers_devices_config.container_device_id=containers_devices.id\r\n\t\t WHERE containers_devices.container_id=?)`, id)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t_, err = tx.Exec(\"DELETE FROM containers_devices WHERE container_id=?\", id)\r\n\treturn err\r\n}","code-length":244,"reference":"\/\/ ContainerConfigClear removes any config associated with the container with\n\/\/ the given ID.","result":"Clear the config of a container.","score":[0.0605,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ContainerConfigGet(id int, key string) (string, error) {\r\n\tq := \"SELECT value FROM containers_config WHERE container_id=? AND key=?\"\r\n\tvalue := \"\"\r\n\targ1 := []interface{}{id, key}\r\n\targ2 := []interface{}{&value}\r\n\terr := dbQueryRowScan(c.db, q, arg1, arg2)\r\n\tif err == sql.ErrNoRows {\r\n\t\treturn \"\", ErrNoSuchObject\r\n\t}\r\n\treturn value, err\r\n}","code-length":141,"reference":"\/\/ ContainerConfigGet returns the value of the given key in the configuration\n\/\/ of the container with the given ID.","result":"Get the value of a container config.","score":[0.0558,0.107]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ContainerConfigRemove(id int, key string) error {\r\n\terr := exec(c.db, \"DELETE FROM containers_config WHERE key=? AND container_id=?\", key, id)\r\n\treturn err\r\n}","code-length":65,"reference":"\/\/ ContainerConfigRemove removes the given key from the config of the container\n\/\/ with the given ID.","result":"Remove the container config.","score":[0.0175,0.0955]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ContainerSetStateful(id int, stateful bool) error {\r\n\tstatefulInt := 0\r\n\tif stateful {\r\n\t\tstatefulInt = 1\r\n\t}\r\n\terr := exec(c.db, \"UPDATE containers SET stateful=? WHERE id=?\", statefulInt, id)\r\n\treturn err\r\n}","code-length":89,"reference":"\/\/ ContainerSetStateful toggles the stateful flag of the container with the\n\/\/ given ID.","result":"Set the container state.","score":[0.0371,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ContainerProfilesInsert(tx *sql.Tx, id int, project string, profiles []string) error {\r\n\tenabled, err := projectHasProfiles(tx, project)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Check if project has profiles\")\r\n\t}\r\n\tif !enabled {\r\n\t\tproject = \"default\"\r\n\t}\r\n\tapplyOrder := 1\r\n\tstr := `\r\nINSERT INTO containers_profiles (container_id, profile_id, apply_order)\r\n  VALUES (\r\n    ?,\r\n    (SELECT profiles.id\r\n     FROM profiles\r\n     JOIN projects ON projects.id=profiles.project_id\r\n     WHERE projects.name=? AND profiles.name=?),\r\n    ?\r\n  )\r\n`\r\n\tstmt, err := tx.Prepare(str)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer stmt.Close()\r\n\tfor _, profile := range profiles {\r\n\t\t_, err = stmt.Exec(id, project, profile, applyOrder)\r\n\t\tif err != nil {\r\n\t\t\tlogger.Debugf(\"Error adding profile %s to container: %s\",\r\n\t\t\t\tprofile, err)\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tapplyOrder = applyOrder + 1\r\n\t}\r\n\treturn nil\r\n}","code-length":333,"reference":"\/\/ ContainerProfilesInsert associates the container with the given ID with the\n\/\/ profiles with the given names in the given project.","result":"Insert profiles to containers.","score":[0.0046,0.0259]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ContainerProfiles(id int) ([]string, error) {\r\n\tvar name string\r\n\tvar profiles []string\r\n\tquery := `\r\n        SELECT name FROM containers_profiles\r\n        JOIN profiles ON containers_profiles.profile_id=profiles.id\r\n\t\tWHERE container_id=?\r\n        ORDER BY containers_profiles.apply_order`\r\n\tinargs := []interface{}{id}\r\n\toutfmt := []interface{}{name}\r\n\tresults, err := queryScan(c.db, query, inargs, outfmt)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tfor _, r := range results {\r\n\t\tname = r[0].(string)\r\n\t\tprofiles = append(profiles, name)\r\n\t}\r\n\treturn profiles, nil\r\n}","code-length":211,"reference":"\/\/ ContainerProfiles returns a list of profiles for a given container ID.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ContainerConfig(id int) (map[string]string, error) {\r\n\tvar key, value string\r\n\tq := `SELECT key, value FROM containers_config WHERE container_id=?`\r\n\tinargs := []interface{}{id}\r\n\toutfmt := []interface{}{key, value}\r\n\t\r\n\tresults, err := queryScan(c.db, q, inargs, outfmt)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tconfig := map[string]string{}\r\n\tfor _, r := range results {\r\n\t\tkey = r[0].(string)\r\n\t\tvalue = r[1].(string)\r\n\t\tconfig[key] = value\r\n\t}\r\n\treturn config, nil\r\n}","code-length":202,"reference":"\/\/ ContainerConfig gets the container configuration map from the DB","result":"Get the container config from the cluster.","score":[0.1958,0.499]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ContainerSetState(id int, state string) error {\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\t\r\n\t\tstr := fmt.Sprintf(\"INSERT OR REPLACE INTO containers_config (container_id, key, value) VALUES (?, 'volatile.last_state.power', ?)\")\r\n\t\tstmt, err := tx.tx.Prepare(str)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdefer stmt.Close()\r\n\t\tif _, err = stmt.Exec(id, state); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\treturn err\r\n}","code-length":186,"reference":"\/\/ ContainerSetState sets the the power state of the container with the given ID.","result":"Set the container state.","score":[0.0371,0.1154]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ContainerUpdate(tx *sql.Tx, id int, description string, architecture int, ephemeral bool,\r\n\texpiryDate time.Time) error {\r\n\tstr := fmt.Sprintf(\"UPDATE containers SET description=?, architecture=?, ephemeral=?, expiry_date=? WHERE id=?\")\r\n\tstmt, err := tx.Prepare(str)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer stmt.Close()\r\n\tephemeralInt := 0\r\n\tif ephemeral {\r\n\t\tephemeralInt = 1\r\n\t}\r\n\tif expiryDate.IsZero() {\r\n\t\t_, err = stmt.Exec(description, architecture, ephemeralInt, \"\", id)\r\n\t} else {\r\n\t\t_, err = stmt.Exec(description, architecture, ephemeralInt, expiryDate, id)\r\n\t}\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":231,"reference":"\/\/ ContainerUpdate updates the description, architecture and ephemeral flag of\n\/\/ the container with the given ID.","result":"Update the container in the database.","score":[0.0483,0.1985]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ContainerLastUsedUpdate(id int, date time.Time) error {\r\n\tstmt := `UPDATE containers SET last_use_date=? WHERE id=?`\r\n\terr := exec(c.db, stmt, date, id)\r\n\treturn err\r\n}","code-length":74,"reference":"\/\/ ContainerLastUsedUpdate updates the last_use_date field of the container\n\/\/ with the given ID.","result":"Date of a container.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ContainerGetSnapshots(project, name string) ([]string, error) {\r\n\tresult := []string{}\r\n\tregexp := name + shared.SnapshotDelimiter\r\n\tlength := len(regexp)\r\n\tq := `\r\nSELECT containers.name\r\n  FROM containers\r\n  JOIN projects ON projects.id = containers.project_id\r\nWHERE projects.name=? AND containers.type=? AND SUBSTR(containers.name,1,?)=?\r\n`\r\n\tinargs := []interface{}{project, CTypeSnapshot, length, regexp}\r\n\toutfmt := []interface{}{name}\r\n\tdbResults, err := queryScan(c.db, q, inargs, outfmt)\r\n\tif err != nil {\r\n\t\treturn result, err\r\n\t}\r\n\tfor _, r := range dbResults {\r\n\t\tresult = append(result, r[0].(string))\r\n\t}\r\n\treturn result, nil\r\n}","code-length":236,"reference":"\/\/ ContainerGetSnapshots returns the names of all snapshots of the container\n\/\/ in the given project with the given name.","result":"Generate code for the generated code.","score":[0.0187,0.0269]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ContainerGetSnapshotsFull(project string, name string) ([]Container, error) {\r\n\tfilter := ContainerFilter{\r\n\t\tParent:  name,\r\n\t\tProject: project,\r\n\t\tType:    int(CTypeSnapshot),\r\n\t}\r\n\treturn c.ContainerList(filter)\r\n}","code-length":90,"reference":"\/\/ ContainerGetSnapshotsFull returns all container objects for snapshots of a given container","result":"Get the list of snapshots in a cluster transaction.","score":[0.1149,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ContainerNextSnapshot(project string, name string, pattern string) int {\r\n\tbase := name + shared.SnapshotDelimiter\r\n\tlength := len(base)\r\n\tq := `\r\nSELECT containers.name\r\n  FROM containers\r\n  JOIN projects ON projects.id = containers.project_id\r\n WHERE projects.name=? AND containers.type=? AND SUBSTR(containers.name,1,?)=?`\r\n\tvar numstr string\r\n\tinargs := []interface{}{project, CTypeSnapshot, length, base}\r\n\toutfmt := []interface{}{numstr}\r\n\tresults, err := queryScan(c.db, q, inargs, outfmt)\r\n\tif err != nil {\r\n\t\treturn 0\r\n\t}\r\n\tmax := 0\r\n\tfor _, r := range results {\r\n\t\tsnapOnlyName := strings.SplitN(r[0].(string), shared.SnapshotDelimiter, 2)[1]\r\n\t\tfields := strings.SplitN(pattern, \"%d\", 2)\r\n\t\tvar num int\r\n\t\tcount, err := fmt.Sscanf(snapOnlyName, fmt.Sprintf(\"%s%%d%s\", fields[0], fields[1]), &num)\r\n\t\tif err != nil || count != 1 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif num >= max {\r\n\t\t\tmax = num + 1\r\n\t\t}\r\n\t}\r\n\treturn max\r\n}","code-length":357,"reference":"\/\/ ContainerNextSnapshot returns the index the next snapshot of the container\n\/\/ with the given name and pattern should have.","result":"Generate the generated code.","score":[0.0059,0.0272]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ContainerPool(project, containerName string) (string, error) {\r\n\t\r\n\t\r\n\t\r\n\tpoolName := \"\"\r\n\tquery := `\r\nSELECT storage_pools.name FROM storage_pools\r\n  JOIN storage_volumes ON storage_pools.id=storage_volumes.storage_pool_id\r\n  JOIN containers ON containers.name=storage_volumes.name\r\n  JOIN projects ON projects.id=containers.project_id\r\n WHERE projects.name=? AND storage_volumes.node_id=? AND storage_volumes.name=? AND storage_volumes.type=?\r\n`\r\n\tinargs := []interface{}{project, c.nodeID, containerName, StoragePoolVolumeTypeContainer}\r\n\toutargs := []interface{}{&poolName}\r\n\terr := c.tx.QueryRow(query, inargs...).Scan(outargs...)\r\n\tif err != nil {\r\n\t\tif err == sql.ErrNoRows {\r\n\t\t\treturn \"\", ErrNoSuchObject\r\n\t\t}\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn poolName, nil\r\n}","code-length":268,"reference":"\/\/ ContainerPool returns the storage pool of a given container.","result":"Generate the code.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ContainerGetBackup(project, name string) (ContainerBackupArgs, error) {\r\n\targs := ContainerBackupArgs{}\r\n\targs.Name = name\r\n\tcontainerOnlyInt := -1\r\n\toptimizedStorageInt := -1\r\n\tq := `\r\nSELECT containers_backups.id, containers_backups.container_id,\r\n       containers_backups.creation_date, containers_backups.expiry_date,\r\n       containers_backups.container_only, containers_backups.optimized_storage\r\n    FROM containers_backups\r\n    JOIN containers ON containers.id=containers_backups.container_id\r\n    JOIN projects ON projects.id=containers.project_id\r\n    WHERE projects.name=? AND containers_backups.name=?\r\n`\r\n\targ1 := []interface{}{project, name}\r\n\targ2 := []interface{}{&args.ID, &args.ContainerID, &args.CreationDate,\r\n\t\t&args.ExpiryDate, &containerOnlyInt, &optimizedStorageInt}\r\n\terr := dbQueryRowScan(c.db, q, arg1, arg2)\r\n\tif err != nil {\r\n\t\tif err == sql.ErrNoRows {\r\n\t\t\treturn args, ErrNoSuchObject\r\n\t\t}\r\n\t\treturn args, err\r\n\t}\r\n\tif containerOnlyInt == 1 {\r\n\t\targs.ContainerOnly = true\r\n\t}\r\n\tif optimizedStorageInt == 1 {\r\n\t\targs.OptimizedStorage = true\r\n\t}\r\n\treturn args, nil\r\n}","code-length":386,"reference":"\/\/ ContainerGetBackup returns the backup with the given name.","result":"Get the container.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ContainerGetBackups(project, name string) ([]string, error) {\r\n\tvar result []string\r\n\tq := `SELECT containers_backups.name FROM containers_backups\r\nJOIN containers ON containers_backups.container_id=containers.id\r\nJOIN projects ON projects.id=containers.project_id\r\nWHERE projects.name=? AND containers.name=?`\r\n\tinargs := []interface{}{project, name}\r\n\toutfmt := []interface{}{name}\r\n\tdbResults, err := queryScan(c.db, q, inargs, outfmt)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tfor _, r := range dbResults {\r\n\t\tresult = append(result, r[0].(string))\r\n\t}\r\n\treturn result, nil\r\n}","code-length":212,"reference":"\/\/ ContainerGetBackups returns the names of all backups of the container\n\/\/ with the given name.","result":"Generate code for the generated code.","score":[0.0365,0.0333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ContainerBackupCreate(args ContainerBackupArgs) error {\r\n\t_, err := c.ContainerBackupID(args.Name)\r\n\tif err == nil {\r\n\t\treturn ErrAlreadyDefined\r\n\t}\r\n\terr = c.Transaction(func(tx *ClusterTx) error {\r\n\t\tcontainerOnlyInt := 0\r\n\t\tif args.ContainerOnly {\r\n\t\t\tcontainerOnlyInt = 1\r\n\t\t}\r\n\t\toptimizedStorageInt := 0\r\n\t\tif args.OptimizedStorage {\r\n\t\t\toptimizedStorageInt = 1\r\n\t\t}\r\n\t\tstr := fmt.Sprintf(\"INSERT INTO containers_backups (container_id, name, creation_date, expiry_date, container_only, optimized_storage) VALUES (?, ?, ?, ?, ?, ?)\")\r\n\t\tstmt, err := tx.tx.Prepare(str)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdefer stmt.Close()\r\n\t\tresult, err := stmt.Exec(args.ContainerID, args.Name,\r\n\t\t\targs.CreationDate.Unix(), args.ExpiryDate.Unix(), containerOnlyInt,\r\n\t\t\toptimizedStorageInt)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t_, err = result.LastInsertId()\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"Error inserting %s into database\", args.Name)\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\treturn err\r\n}","code-length":382,"reference":"\/\/ ContainerBackupCreate creates a new backup","result":"Create a backup in the cluster.","score":[0.2296,0.4259]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ContainerBackupRemove(name string) error {\r\n\tid, err := c.ContainerBackupID(name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = exec(c.db, \"DELETE FROM containers_backups WHERE id=?\", id)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":107,"reference":"\/\/ ContainerBackupRemove removes the container backup with the given name from\n\/\/ the database.","result":"Remove backup from container.","score":[0.0312,0.1154]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ContainerBackupRename(oldName, newName string) error {\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tstr := fmt.Sprintf(\"UPDATE containers_backups SET name = ? WHERE name = ?\")\r\n\t\tstmt, err := tx.tx.Prepare(str)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdefer stmt.Close()\r\n\t\tlogger.Debug(\r\n\t\t\t\"Calling SQL Query\",\r\n\t\t\tlog.Ctx{\r\n\t\t\t\t\"query\":   \"UPDATE containers_backups SET name = ? WHERE name = ?\",\r\n\t\t\t\t\"oldName\": oldName,\r\n\t\t\t\t\"newName\": newName})\r\n\t\tif _, err := stmt.Exec(newName, oldName); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\treturn err\r\n}","code-length":234,"reference":"\/\/ ContainerBackupRename renames a container backup from the given current name\n\/\/ to the new one.","result":"Rename the backup.","score":[0.0054,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ContainerBackupsGetExpired() ([]string, error) {\r\n\tvar result []string\r\n\tvar name string\r\n\tvar expiryDate string\r\n\tq := `SELECT containers_backups.name, containers_backups.expiry_date FROM containers_backups`\r\n\toutfmt := []interface{}{name, expiryDate}\r\n\tdbResults, err := queryScan(c.db, q, nil, outfmt)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tfor _, r := range dbResults {\r\n\t\ttimestamp := r[1]\r\n\t\tvar backupExpiry time.Time\r\n\t\terr = backupExpiry.UnmarshalText([]byte(timestamp.(string)))\r\n\t\tif err != nil {\r\n\t\t\treturn []string{}, err\r\n\t\t}\r\n\t\tif backupExpiry.IsZero() {\r\n\t\t\t\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tif time.Now().Unix()-backupExpiry.Unix() >= 0 {\r\n\t\t\tresult = append(result, r[0].(string))\r\n\t\t}\r\n\t}\r\n\treturn result, nil\r\n}","code-length":292,"reference":"\/\/ ContainerBackupsGetExpired returns a list of expired container backups.","result":"Get expired backups from the cluster.","score":[0.1171,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DefaultOS() *OS {\r\n\tnewOS := &OS{\r\n\t\tVarDir:   shared.VarPath(),\r\n\t\tCacheDir: shared.CachePath(),\r\n\t\tLogDir:   shared.LogPath(),\r\n\t}\r\n\tnewOS.InotifyWatch.Fd = -1\r\n\tnewOS.InotifyWatch.Targets = make(map[string]*InotifyTargetInfo)\r\n\treturn newOS\r\n}","code-length":115,"reference":"\/\/ DefaultOS returns a fresh uninitialized OS instance with default values.","result":"Initialize the default OS.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *OS) Init() error {\r\n\terr := s.initDirs()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ts.Architectures, err = util.GetArchitectures()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ts.LxcPath = filepath.Join(s.VarDir, \"containers\")\r\n\ts.BackingFS, err = util.FilesystemDetect(s.LxcPath)\r\n\tif err != nil {\r\n\t\tlogger.Error(\"Error detecting backing fs\", log.Ctx{\"err\": err})\r\n\t}\r\n\ts.IdmapSet = util.GetIdmapSet()\r\n\ts.ExecPath = util.GetExecPath()\r\n\ts.RunningInUserNS = shared.RunningInUserNS()\r\n\ts.initAppArmor()\r\n\ts.initCGroup()\r\n\treturn nil\r\n}","code-length":234,"reference":"\/\/ Init our internal data structures.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (op *operation) GetWebsocket(secret string) (*websocket.Conn, error) {\r\n\treturn op.r.GetOperationWebsocket(op.ID, secret)\r\n}","code-length":51,"reference":"\/\/ GetWebsocket returns a raw websocket connection from the operation","result":"Generate the code.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (op *operation) Refresh() error {\r\n\t\r\n\tnewOp, _, err := op.r.GetOperation(op.ID)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\top.Operation = *newOp\r\n\treturn nil\r\n}","code-length":82,"reference":"\/\/ Refresh pulls the current version of the operation and updates the struct","result":"Refresh the operation.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (op *remoteOperation) CancelTarget() error {\r\n\tif op.targetOp == nil {\r\n\t\treturn fmt.Errorf(\"No associated target operation\")\r\n\t}\r\n\treturn op.targetOp.Cancel()\r\n}","code-length":64,"reference":"\/\/ CancelTarget attempts to cancel the target operation","result":"Cancel the target operation.","score":[0.1662,0.3874]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (op *remoteOperation) GetTarget() (*api.Operation, error) {\r\n\tif op.targetOp == nil {\r\n\t\treturn nil, fmt.Errorf(\"No associated target operation\")\r\n\t}\r\n\topAPI := op.targetOp.Get()\r\n\treturn &opAPI, nil\r\n}","code-length":84,"reference":"\/\/ GetTarget returns the target operation","result":"Get the target operation.","score":[0.274,0.3233]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Endpoints) up(config *Config) error {\r\n\te.mu.Lock()\r\n\tdefer e.mu.Unlock()\r\n\te.servers = map[kind]*http.Server{\r\n\t\tdevlxd:  config.DevLxdServer,\r\n\t\tlocal:   config.RestServer,\r\n\t\tnetwork: config.RestServer,\r\n\t\tcluster: config.RestServer,\r\n\t\tpprof:   pprofCreateServer(),\r\n\t}\r\n\te.cert = config.Cert\r\n\te.inherited = map[kind]bool{}\r\n\tvar err error\r\n\t\r\n\tsystemdListeners := util.GetListeners(e.systemdListenFDsStart)\r\n\tif len(systemdListeners) > 0 {\r\n\t\te.listeners = activatedListeners(systemdListeners, e.cert)\r\n\t\tfor kind := range e.listeners {\r\n\t\t\te.inherited[kind] = true\r\n\t\t}\r\n\t} else {\r\n\t\te.listeners = map[kind]net.Listener{}\r\n\t\te.listeners[local], err = localCreateListener(config.UnixSocket, config.LocalUnixSocketGroup)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"local endpoint: %v\", err)\r\n\t\t}\r\n\t}\r\n\t\r\n\te.listeners[devlxd], err = createDevLxdlListener(config.Dir)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif config.NetworkAddress != \"\" {\r\n\t\tlistener, ok := e.listeners[network]\r\n\t\tif ok {\r\n\t\t\tlogger.Infof(\"Replacing inherited TCP socket with configured one\")\r\n\t\t\tlistener.Close()\r\n\t\t\te.inherited[network] = false\r\n\t\t}\r\n\t\t\r\n\t\te.listeners[network] = networkCreateListener(config.NetworkAddress, e.cert)\r\n\t\tisCovered := util.IsAddressCovered(config.ClusterAddress, config.NetworkAddress)\r\n\t\tif config.ClusterAddress != \"\" && !isCovered {\r\n\t\t\te.listeners[cluster], err = clusterCreateListener(config.ClusterAddress, e.cert)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tlogger.Infof(\"Starting cluster handler:\")\r\n\t\t\te.serveHTTP(cluster)\r\n\t\t}\r\n\t}\r\n\tif config.DebugAddress != \"\" {\r\n\t\te.listeners[pprof], err = pprofCreateListener(config.DebugAddress)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tlogger.Infof(\"Starting pprof handler:\")\r\n\t\te.serveHTTP(pprof)\r\n\t}\r\n\tlogger.Infof(\"Starting \/dev\/lxd handler:\")\r\n\te.serveHTTP(devlxd)\r\n\tlogger.Infof(\"REST API daemon:\")\r\n\te.serveHTTP(local)\r\n\te.serveHTTP(network)\r\n\treturn nil\r\n}","code-length":749,"reference":"\/\/ Up brings up all configured endpoints and starts accepting HTTP requests.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Endpoints) Down() error {\r\n\te.mu.Lock()\r\n\tdefer e.mu.Unlock()\r\n\tif e.listeners[network] != nil || e.listeners[local] != nil {\r\n\t\tlogger.Infof(\"Stopping REST API handler:\")\r\n\t\terr := e.closeListener(network)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\terr = e.closeListener(local)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tif e.listeners[cluster] != nil {\r\n\t\tlogger.Infof(\"Stopping cluster handler:\")\r\n\t\terr := e.closeListener(cluster)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tif e.listeners[devlxd] != nil {\r\n\t\tlogger.Infof(\"Stopping \/dev\/lxd handler:\")\r\n\t\terr := e.closeListener(devlxd)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tif e.listeners[pprof] != nil {\r\n\t\tlogger.Infof(\"Stopping pprof handler:\")\r\n\t\terr := e.closeListener(pprof)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tif e.tomb != nil {\r\n\t\te.tomb.Kill(nil)\r\n\t\te.tomb.Wait()\r\n\t}\r\n\treturn nil\r\n}","code-length":395,"reference":"\/\/ Down brings down all endpoints and stops serving HTTP requests.","result":"Stop the endpoints.","score":[0,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Endpoints) serveHTTP(kind kind) {\r\n\tlistener := e.listeners[kind]\r\n\tif listener == nil {\r\n\t\treturn\r\n\t}\r\n\tctx := log.Ctx{\"socket\": listener.Addr()}\r\n\tif e.inherited[kind] {\r\n\t\tctx[\"inherited\"] = true\r\n\t}\r\n\tmessage := fmt.Sprintf(\" - binding %s\", descriptions[kind])\r\n\tlogger.Info(message, ctx)\r\n\tserver := e.servers[kind]\r\n\t\r\n\t\r\n\tif e.tomb == nil {\r\n\t\te.tomb = &tomb.Tomb{}\r\n\t}\r\n\te.tomb.Go(func() error {\r\n\t\tserver.Serve(listener)\r\n\t\treturn nil\r\n\t})\r\n}","code-length":207,"reference":"\/\/ Start an HTTP server for the endpoint associated with the given code.","result":"Serve HTTP endpoints.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Endpoints) closeListener(kind kind) error {\r\n\tlistener := e.listeners[kind]\r\n\tif listener == nil {\r\n\t\treturn nil\r\n\t}\r\n\tdelete(e.listeners, kind)\r\n\tlogger.Info(\" - closing socket\", log.Ctx{\"socket\": listener.Addr()})\r\n\treturn listener.Close()\r\n}","code-length":96,"reference":"\/\/ Stop the HTTP server of the endpoint associated with the given code. The\n\/\/ associated socket will be shutdown too.","result":"Close the listener.","score":[0.001,0.026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc activatedListeners(systemdListeners []net.Listener, cert *shared.CertInfo) map[kind]net.Listener {\r\n\tlisteners := map[kind]net.Listener{}\r\n\tfor _, listener := range systemdListeners {\r\n\t\tvar kind kind\r\n\t\tswitch listener.(type) {\r\n\t\tcase *net.UnixListener:\r\n\t\t\tkind = local\r\n\t\tcase *net.TCPListener:\r\n\t\t\tkind = network\r\n\t\t\tlistener = networkTLSListener(listener, cert)\r\n\t\tdefault:\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tlisteners[kind] = listener\r\n\t}\r\n\treturn listeners\r\n}","code-length":167,"reference":"\/\/ Use the listeners associated with the file descriptors passed via\n\/\/ socket-based activation.","result":"Activate systemd listeners.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) CandidServer() (string, string, int64, string) {\r\n\treturn c.m.GetString(\"candid.api.url\"),\r\n\t\tc.m.GetString(\"candid.api.key\"),\r\n\t\tc.m.GetInt64(\"candid.expiry\"),\r\n\t\tc.m.GetString(\"candid.domains\")\r\n}","code-length":104,"reference":"\/\/ CandidServer returns all the Candid settings needed to connect to a server.","result":"Initialize the CandidServer.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) RBACServer() (string, string, int64, string, string, string, string) {\r\n\treturn c.m.GetString(\"rbac.api.url\"),\r\n\t\tc.m.GetString(\"rbac.api.key\"),\r\n\t\tc.m.GetInt64(\"rbac.expiry\"),\r\n\t\tc.m.GetString(\"rbac.agent.url\"),\r\n\t\tc.m.GetString(\"rbac.agent.username\"),\r\n\t\tc.m.GetString(\"rbac.agent.private_key\"),\r\n\t\tc.m.GetString(\"rbac.agent.public_key\")\r\n}","code-length":174,"reference":"\/\/ RBACServer returns all the Candid settings needed to connect to a server.","result":"Generate the RBACServer.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) AutoUpdateInterval() time.Duration {\r\n\tn := c.m.GetInt64(\"images.auto_update_interval\")\r\n\treturn time.Duration(n) * time.Hour\r\n}","code-length":60,"reference":"\/\/ AutoUpdateInterval returns the configured images auto update interval.","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) MAASController() (string, string) {\r\n\turl := c.m.GetString(\"maas.api.url\")\r\n\tkey := c.m.GetString(\"maas.api.key\")\r\n\treturn url, key\r\n}","code-length":73,"reference":"\/\/ MAASController the configured MAAS url and key, if any.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) OfflineThreshold() time.Duration {\r\n\tn := c.m.GetInt64(\"cluster.offline_threshold\")\r\n\treturn time.Duration(n) * time.Second\r\n}","code-length":57,"reference":"\/\/ OfflineThreshold returns the configured heartbeat threshold, i.e. the\n\/\/ number of seconds before after which an unresponsive node is considered\n\/\/ offline..","result":"Set the cluster.","score":[0.0005,0.0238]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ConfigGetString(cluster *db.Cluster, key string) (string, error) {\r\n\tconfig, err := configGet(cluster)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn config.m.GetString(key), nil\r\n}","code-length":77,"reference":"\/\/ ConfigGetString is a convenience for loading the cluster configuration and\n\/\/ returning the value of a particular key.\n\/\/\n\/\/ It's a deprecated API meant to be used by call sites that are not\n\/\/ interacting with the database in a transactional way.","result":"Get the config value.","score":[0.0,0.0125]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ConfigGetBool(cluster *db.Cluster, key string) (bool, error) {\r\n\tconfig, err := configGet(cluster)\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\treturn config.m.GetBool(key), nil\r\n}","code-length":78,"reference":"\/\/ ConfigGetBool is a convenience for loading the cluster configuration and\n\/\/ returning the value of a particular boolean key.\n\/\/\n\/\/ It's a deprecated API meant to be used by call sites that are not\n\/\/ interacting with the database in a transactional way.","result":"Get the config value.","score":[0.0,0.0122]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ConfigGetInt64(cluster *db.Cluster, key string) (int64, error) {\r\n\tconfig, err := configGet(cluster)\r\n\tif err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\treturn config.m.GetInt64(key), nil\r\n}","code-length":79,"reference":"\/\/ ConfigGetInt64 is a convenience for loading the cluster configuration and\n\/\/ returning the value of a particular key.\n\/\/\n\/\/ It's a deprecated API meant to be used by call sites that are not\n\/\/ interacting with the database in a transactional way.","result":"Get the config value.","score":[0.0,0.0125]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Endpoints) ClusterAddress() string {\r\n\te.mu.RLock()\r\n\tdefer e.mu.RUnlock()\r\n\tlistener := e.listeners[cluster]\r\n\tif listener == nil {\r\n\t\treturn \"\"\r\n\t}\r\n\treturn listener.Addr().String()\r\n}","code-length":83,"reference":"\/\/ ClusterAddress returns the cluster addresss of the cluster endpoint, or an\n\/\/ empty string if there's no cluster endpoint.","result":"Get the cluster address.","score":[0.0083,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Debug(msg string, ctx ...interface{}) {\r\n\tif Log != nil {\r\n\t\tpc, fn, line, _ := runtime.Caller(1)\r\n\t\tmsg := fmt.Sprintf(\"%s: %d: %s: %s\", fn, line, runtime.FuncForPC(pc).Name(), msg)\r\n\t\tLog.Debug(msg, ctx...)\r\n\t}\r\n}","code-length":104,"reference":"\/\/ General wrappers around Logger interface functions.","result":"Print debug messages.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RestServer(d *Daemon) *http.Server {\r\n\t\r\n\tmux := mux.NewRouter()\r\n\tmux.StrictSlash(false)\r\n\tmux.HandleFunc(\"\/\", func(w http.ResponseWriter, r *http.Request) {\r\n\t\tw.Header().Set(\"Content-Type\", \"application\/json\")\r\n\t\tSyncResponse(true, []string{\"\/1.0\"}).Render(w)\r\n\t})\r\n\tfor endpoint, f := range d.gateway.HandlerFuncs() {\r\n\t\tmux.HandleFunc(endpoint, f)\r\n\t}\r\n\tfor _, c := range api10 {\r\n\t\td.createCmd(mux, \"1.0\", c)\r\n\t}\r\n\tfor _, c := range apiInternal {\r\n\t\td.createCmd(mux, \"internal\", c)\r\n\t}\r\n\tmux.NotFoundHandler = http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\r\n\t\tlogger.Info(\"Sending top level 404\", log.Ctx{\"url\": r.URL})\r\n\t\tw.Header().Set(\"Content-Type\", \"application\/json\")\r\n\t\tNotFound(nil).Render(w)\r\n\t})\r\n\treturn &http.Server{Handler: &lxdHttpServer{r: mux, d: d}}\r\n}","code-length":337,"reference":"\/\/ RestServer creates an http.Server capable of handling requests against the LXD REST\n\/\/ API endpoint.","result":"Serve the rest server.","score":[0.0159,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc projectParam(request *http.Request) string {\r\n\tproject := queryParam(request, \"project\")\r\n\tif project == \"\" {\r\n\t\tproject = \"default\"\r\n\t}\r\n\treturn project\r\n}","code-length":62,"reference":"\/\/ Extract the project query parameter from the given request.","result":"Specify the project parameter.","score":[0.1008,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc queryParam(request *http.Request, key string) string {\r\n\tvar values url.Values\r\n\tvar err error\r\n\tif request.URL != nil {\r\n\t\tvalues, err = url.ParseQuery(request.URL.RawQuery)\r\n\t\tif err != nil {\r\n\t\t\tlogger.Warnf(\"Failed to parse query string %q: %v\", request.URL.RawQuery, err)\r\n\t\t\treturn \"\"\r\n\t\t}\r\n\t}\r\n\tif values == nil {\r\n\t\tvalues = make(url.Values)\r\n\t}\r\n\treturn values.Get(key)\r\n}","code-length":157,"reference":"\/\/ Extract the given query parameter directly from the URL, never from an\n\/\/ encoded body.","result":"Get the value of a query parameter.","score":[0.0531,0.0662]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newDb() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"db [sub-command]\",\r\n\t\tShort: \"Database-related code generation.\",\r\n\t\tRunE: func(cmd *cobra.Command, args []string) error {\r\n\t\t\treturn fmt.Errorf(\"Not implemented\")\r\n\t\t},\r\n\t}\r\n\tcmd.AddCommand(newDbSchema())\r\n\tcmd.AddCommand(newDbMapper())\r\n\treturn cmd\r\n}","code-length":137,"reference":"\/\/ Return a new db command.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t OperationType) Description() string {\r\n\tswitch t {\r\n\tcase OperationClusterBootstrap:\r\n\t\treturn \"Creating bootstrap node\"\r\n\tcase OperationClusterJoin:\r\n\t\treturn \"Joining cluster\"\r\n\tcase OperationBackupCreate:\r\n\t\treturn \"Backing up container\"\r\n\tcase OperationBackupRename:\r\n\t\treturn \"Renaming container backup\"\r\n\tcase OperationBackupRestore:\r\n\t\treturn \"Restoring backup\"\r\n\tcase OperationBackupRemove:\r\n\t\treturn \"Removing container backup\"\r\n\tcase OperationConsoleShow:\r\n\t\treturn \"Showing console\"\r\n\tcase OperationContainerCreate:\r\n\t\treturn \"Creating container\"\r\n\tcase OperationContainerUpdate:\r\n\t\treturn \"Updating container\"\r\n\tcase OperationContainerRename:\r\n\t\treturn \"Renaming container\"\r\n\tcase OperationContainerMigrate:\r\n\t\treturn \"Migrating container\"\r\n\tcase OperationContainerLiveMigrate:\r\n\t\treturn \"Live-migrating container\"\r\n\tcase OperationContainerFreeze:\r\n\t\treturn \"Freezing container\"\r\n\tcase OperationContainerUnfreeze:\r\n\t\treturn \"Unfreezing container\"\r\n\tcase OperationContainerDelete:\r\n\t\treturn \"Deleting container\"\r\n\tcase OperationContainerStart:\r\n\t\treturn \"Starting container\"\r\n\tcase OperationContainerStop:\r\n\t\treturn \"Stopping container\"\r\n\tcase OperationContainerRestart:\r\n\t\treturn \"Restarting container\"\r\n\tcase OperationCommandExec:\r\n\t\treturn \"Executing command\"\r\n\tcase OperationSnapshotCreate:\r\n\t\treturn \"Snapshotting container\"\r\n\tcase OperationSnapshotRename:\r\n\t\treturn \"Renaming snapshot\"\r\n\tcase OperationSnapshotRestore:\r\n\t\treturn \"Restoring snapshot\"\r\n\tcase OperationSnapshotTransfer:\r\n\t\treturn \"Transferring snapshot\"\r\n\tcase OperationSnapshotUpdate:\r\n\t\treturn \"Updating snapshot\"\r\n\tcase OperationSnapshotDelete:\r\n\t\treturn \"Deleting snapshot\"\r\n\tcase OperationImageDownload:\r\n\t\treturn \"Downloading image\"\r\n\tcase OperationImageDelete:\r\n\t\treturn \"Deleting image\"\r\n\tcase OperationImageToken:\r\n\t\treturn \"Image download token\"\r\n\tcase OperationImageRefresh:\r\n\t\treturn \"Refreshing image\"\r\n\tcase OperationVolumeCopy:\r\n\t\treturn \"Copying storage volume\"\r\n\tcase OperationVolumeCreate:\r\n\t\treturn \"Creating storage volume\"\r\n\tcase OperationVolumeMigrate:\r\n\t\treturn \"Migrating storage volume\"\r\n\tcase OperationVolumeMove:\r\n\t\treturn \"Moving storage volume\"\r\n\tcase OperationVolumeSnapshotCreate:\r\n\t\treturn \"Creating storage volume snapshot\"\r\n\tcase OperationVolumeSnapshotDelete:\r\n\t\treturn \"Deleting storage volume snapshot\"\r\n\tcase OperationVolumeSnapshotUpdate:\r\n\t\treturn \"Updating storage volume snapshot\"\r\n\tcase OperationProjectRename:\r\n\t\treturn \"Renaming project\"\r\n\tcase OperationImagesExpire:\r\n\t\treturn \"Cleaning up expired images\"\r\n\tcase OperationImagesPruneLeftover:\r\n\t\treturn \"Pruning leftover image files\"\r\n\tcase OperationImagesUpdate:\r\n\t\treturn \"Updating images\"\r\n\tcase OperationImagesSynchronize:\r\n\t\treturn \"Synchronizing images\"\r\n\tcase OperationLogsExpire:\r\n\t\treturn \"Expiring log files\"\r\n\tcase OperationInstanceTypesUpdate:\r\n\t\treturn \"Updating instance types\"\r\n\tcase OperationBackupsExpire:\r\n\t\treturn \"Cleaning up expired backups\"\r\n\tcase OperationSnapshotsExpire:\r\n\t\treturn \"Cleaning up expired snapshots\"\r\n\tdefault:\r\n\t\treturn \"Executing operation\"\r\n\t}\r\n}","code-length":880,"reference":"\/\/ Description return a human-readable description of the operation type.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t OperationType) Permission() string {\r\n\tswitch t {\r\n\tcase OperationBackupCreate:\r\n\t\treturn \"operate-containers\"\r\n\tcase OperationBackupRename:\r\n\t\treturn \"operate-containers\"\r\n\tcase OperationBackupRestore:\r\n\t\treturn \"operate-containers\"\r\n\tcase OperationBackupRemove:\r\n\t\treturn \"operate-containers\"\r\n\tcase OperationConsoleShow:\r\n\t\treturn \"operate-containers\"\r\n\tcase OperationContainerFreeze:\r\n\t\treturn \"operate-containers\"\r\n\tcase OperationContainerUnfreeze:\r\n\t\treturn \"operate-containers\"\r\n\tcase OperationContainerStart:\r\n\t\treturn \"operate-containers\"\r\n\tcase OperationContainerStop:\r\n\t\treturn \"operate-containers\"\r\n\tcase OperationContainerRestart:\r\n\t\treturn \"operate-containers\"\r\n\tcase OperationCommandExec:\r\n\t\treturn \"operate-containers\"\r\n\tcase OperationSnapshotCreate:\r\n\t\treturn \"operate-containers\"\r\n\tcase OperationSnapshotRename:\r\n\t\treturn \"operate-containers\"\r\n\tcase OperationSnapshotTransfer:\r\n\t\treturn \"operate-containers\"\r\n\tcase OperationSnapshotUpdate:\r\n\t\treturn \"operate-containers\"\r\n\tcase OperationSnapshotDelete:\r\n\t\treturn \"operate-containers\"\r\n\tcase OperationContainerCreate:\r\n\t\treturn \"manage-containers\"\r\n\tcase OperationContainerUpdate:\r\n\t\treturn \"manage-containers\"\r\n\tcase OperationContainerRename:\r\n\t\treturn \"manage-containers\"\r\n\tcase OperationContainerMigrate:\r\n\t\treturn \"manage-containers\"\r\n\tcase OperationContainerLiveMigrate:\r\n\t\treturn \"manage-containers\"\r\n\tcase OperationContainerDelete:\r\n\t\treturn \"manage-containers\"\r\n\tcase OperationSnapshotRestore:\r\n\t\treturn \"manage-containers\"\r\n\tcase OperationImageDownload:\r\n\t\treturn \"manage-images\"\r\n\tcase OperationImageDelete:\r\n\t\treturn \"manage-images\"\r\n\tcase OperationImageToken:\r\n\t\treturn \"manage-images\"\r\n\tcase OperationImageRefresh:\r\n\t\treturn \"manage-images\"\r\n\tcase OperationImagesUpdate:\r\n\t\treturn \"manage-images\"\r\n\tcase OperationImagesSynchronize:\r\n\t\treturn \"manage-images\"\r\n\t}\r\n\treturn \"\"\r\n}","code-length":579,"reference":"\/\/ Permission returns the needed RBAC permission to cancel the oepration","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) OperationsUUIDs() ([]string, error) {\r\n\tstmt := \"SELECT uuid FROM operations WHERE node_id=?\"\r\n\treturn query.SelectStrings(c.tx, stmt, c.nodeID)\r\n}","code-length":65,"reference":"\/\/ OperationsUUIDs returns the UUIDs of all operations associated with this\n\/\/ node.","result":"Generate the code.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) OperationNodes(project string) ([]string, error) {\r\n\tstmt := `\r\nSELECT DISTINCT nodes.address\r\n  FROM operations\r\n  LEFT OUTER JOIN projects ON projects.id = operations.project_id\r\n  JOIN nodes ON nodes.id = operations.node_id\r\n WHERE projects.name = ? OR operations.project_id IS NULL\r\n`\r\n\treturn query.SelectStrings(c.tx, stmt, project)\r\n}","code-length":118,"reference":"\/\/ OperationNodes returns a list of nodes that have running operations","result":"Query the operation nodes.","score":[0,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) OperationByUUID(uuid string) (Operation, error) {\r\n\tnull := Operation{}\r\n\toperations, err := c.operations(\"uuid=?\", uuid)\r\n\tif err != nil {\r\n\t\treturn null, err\r\n\t}\r\n\tswitch len(operations) {\r\n\tcase 0:\r\n\t\treturn null, ErrNoSuchObject\r\n\tcase 1:\r\n\t\treturn operations[0], nil\r\n\tdefault:\r\n\t\treturn null, fmt.Errorf(\"more than one node matches\")\r\n\t}\r\n}","code-length":142,"reference":"\/\/ OperationByUUID returns the operation with the given UUID.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) OperationAdd(project, uuid string, typ OperationType) (int64, error) {\r\n\tvar projectID interface{}\r\n\tif project != \"\" {\r\n\t\tvar err error\r\n\t\tprojectID, err = c.ProjectID(project)\r\n\t\tif err != nil {\r\n\t\t\treturn -1, errors.Wrap(err, \"Fetch project ID\")\r\n\t\t}\r\n\t} else {\r\n\t\tprojectID = nil\r\n\t}\r\n\tcolumns := []string{\"uuid\", \"node_id\", \"type\", \"project_id\"}\r\n\tvalues := []interface{}{uuid, c.nodeID, typ, projectID}\r\n\treturn query.UpsertObject(c.tx, \"operations\", columns, values)\r\n}","code-length":193,"reference":"\/\/ OperationAdd adds a new operations to the table.","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) OperationRemove(uuid string) error {\r\n\tresult, err := c.tx.Exec(\"DELETE FROM operations WHERE uuid=?\", uuid)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tn, err := result.RowsAffected()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif n != 1 {\r\n\t\treturn fmt.Errorf(\"query deleted %d rows instead of 1\", n)\r\n\t}\r\n\treturn nil\r\n}","code-length":134,"reference":"\/\/ OperationRemove removes the operation with the given UUID.","result":"Remove the operation from the cluster.","score":[0.1833,0.431]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) operations(where string, args ...interface{}) ([]Operation, error) {\r\n\toperations := []Operation{}\r\n\tdest := func(i int) []interface{} {\r\n\t\toperations = append(operations, Operation{})\r\n\t\treturn []interface{}{\r\n\t\t\t&operations[i].ID,\r\n\t\t\t&operations[i].UUID,\r\n\t\t\t&operations[i].NodeAddress,\r\n\t\t\t&operations[i].Type,\r\n\t\t}\r\n\t}\r\n\tsql := `\r\nSELECT operations.id, uuid, nodes.address, type FROM operations JOIN nodes ON nodes.id = node_id `\r\n\tif where != \"\" {\r\n\t\tsql += fmt.Sprintf(\"WHERE %s \", where)\r\n\t}\r\n\tsql += \"ORDER BY operations.id\"\r\n\tstmt, err := c.tx.Prepare(sql)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer stmt.Close()\r\n\terr = query.SelectObjects(stmt, dest, args...)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Failed to fetch operations\")\r\n\t}\r\n\treturn operations, nil\r\n}","code-length":305,"reference":"\/\/ Operations returns all operations in the cluster, filtered by the given clause.","result":"Fetch operations from the cluster.","score":[0.0577,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc expireLogsTask(state *state.State) (task.Func, task.Schedule) {\r\n\tf := func(ctx context.Context) {\r\n\t\topRun := func(op *operation) error {\r\n\t\t\treturn expireLogs(ctx, state)\r\n\t\t}\r\n\t\top, err := operationCreate(state.Cluster, \"\", operationClassTask, db.OperationLogsExpire, nil, nil, opRun, nil, nil)\r\n\t\tif err != nil {\r\n\t\t\tlogger.Error(\"Failed to start log expiry operation\", log.Ctx{\"err\": err})\r\n\t\t\treturn\r\n\t\t}\r\n\t\tlogger.Infof(\"Expiring log files\")\r\n\t\t_, err = op.Run()\r\n\t\tif err != nil {\r\n\t\t\tlogger.Error(\"Failed to expire logs\", log.Ctx{\"err\": err})\r\n\t\t}\r\n\t\tlogger.Infof(\"Done expiring log files\")\r\n\t}\r\n\treturn f, task.Daily()\r\n}","code-length":248,"reference":"\/\/ This task function expires logs when executed. It's started by the Daemon\n\/\/ and will run once every 24h.","result":"Expire log files.","score":[0,0.1025]}
{"code":"\/*is used to<extra_id_0>\r\nfunc absPath(path string) string {\r\n\t\r\n\t_, filename, _, _ := runtime.Caller(1)\r\n\telems := strings.Split(filename, string(filepath.Separator))\r\n\tfor i := len(elems) - 1; i >= 0; i-- {\r\n\t\tif elems[i] == \"lxd\" {\r\n\t\t\telems = append([]string{string(filepath.Separator)}, elems[:i]...)\r\n\t\t\telems = append(elems, path)\r\n\t\t\treturn filepath.Join(elems...)\r\n\t\t}\r\n\t}\r\n\tlog.Fatalf(\"Could not found root dir of LXD tree source tree\")\r\n\treturn \"\"\r\n}","code-length":178,"reference":"\/\/ Given its relative path with respect to the LXD surce tree, return the full\n\/\/ path of a file.","result":"Generate the absolute path.","score":[0.0059,0.0272]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s Schema) Keys() []string {\r\n\tkeys := make([]string, len(s))\r\n\ti := 0\r\n\tfor key := range s {\r\n\t\tkeys[i] = key\r\n\t\ti++\r\n\t}\r\n\tsort.Strings(keys)\r\n\treturn keys\r\n}","code-length":85,"reference":"\/\/ Keys returns all keys defined in the schema","result":"Generate the schema keys.","score":[0.1294,0.2206]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s Schema) Defaults() map[string]interface{} {\r\n\tvalues := make(map[string]interface{}, len(s))\r\n\tfor name, key := range s {\r\n\t\tvalues[name] = key.Default\r\n\t}\r\n\treturn values\r\n}","code-length":76,"reference":"\/\/ Defaults returns a map of all key names in the schema along with their default\n\/\/ values.","result":"Generate the code.","score":[0.0028,0.0303]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s Schema) mustGetKey(name string) Key {\r\n\tkey, ok := s[name]\r\n\tif !ok {\r\n\t\tpanic(fmt.Sprintf(\"attempt to access unknown key '%s'\", name))\r\n\t}\r\n\treturn key\r\n}","code-length":76,"reference":"\/\/ Get the Key associated with the given name, or panic.","result":"Check if the key is required.","score":[0.0839,0.0952]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s Schema) assertKeyType(name string, code Type) {\r\n\tkey := s.mustGetKey(name)\r\n\tif key.Type != code {\r\n\t\tpanic(fmt.Sprintf(\"key '%s' has type code %d, not %d\", name, key.Type, code))\r\n\t}\r\n}","code-length":88,"reference":"\/\/ Assert that the Key with the given name as the given type. Panic if no Key\n\/\/ with such name exists, or if it does not match the tiven type.","result":"Assert key type .","score":[0.0004,0.0353]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v *Key) validate(value string) error {\r\n\tvalidator := v.Validator\r\n\tif validator == nil {\r\n\t\t\r\n\t\tvalidator = func(string) error { return nil }\r\n\t}\r\n\t\r\n\tif value == \"\" {\r\n\t\treturn validator(v.Default)\r\n\t}\r\n\tswitch v.Type {\r\n\tcase String:\r\n\tcase Bool:\r\n\t\tif !shared.StringInSlice(strings.ToLower(value), booleans) {\r\n\t\t\treturn fmt.Errorf(\"invalid boolean\")\r\n\t\t}\r\n\tcase Int64:\r\n\t\t_, err := strconv.ParseInt(value, 10, 64)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"invalid integer\")\r\n\t\t}\r\n\tdefault:\r\n\t\tpanic(fmt.Sprintf(\"unexpected value type: %d\", v.Type))\r\n\t}\r\n\tif v.Deprecated != \"\" && value != v.Default {\r\n\t\treturn fmt.Errorf(\"deprecated: %s\", v.Deprecated)\r\n\t}\r\n\t\r\n\treturn validator(value)\r\n}","code-length":281,"reference":"\/\/ Tells if the given value can be assigned to this particular Value instance.","result":"Validate the value.","score":[0.0104,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetStoragePoolVolumes(pool string) ([]api.StorageVolume, error) {\r\n\tif !r.HasExtension(\"storage\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"storage\\\" API extension\")\r\n\t}\r\n\tvolumes := []api.StorageVolume{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/storage-pools\/%s\/volumes?recursion=1\", url.QueryEscape(pool)), nil, \"\", &volumes)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn volumes, nil\r\n}","code-length":165,"reference":"\/\/ GetStoragePoolVolumes returns a list of StorageVolume entries for the provided pool","result":"Generate the generated code.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetStoragePoolVolume(pool string, volType string, name string) (*api.StorageVolume, string, error) {\r\n\tif !r.HasExtension(\"storage\") {\r\n\t\treturn nil, \"\", fmt.Errorf(\"The server is missing the required \\\"storage\\\" API extension\")\r\n\t}\r\n\tvolume := api.StorageVolume{}\r\n\t\r\n\tpath := fmt.Sprintf(\"\/storage-pools\/%s\/volumes\/%s\/%s\", url.QueryEscape(pool), url.QueryEscape(volType), url.QueryEscape(name))\r\n\tetag, err := r.queryStruct(\"GET\", path, nil, \"\", &volume)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\treturn &volume, etag, nil\r\n}","code-length":199,"reference":"\/\/ GetStoragePoolVolume returns a StorageVolume entry for the provided pool and volume name","result":"Generate the generated code.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) CreateStoragePoolVolume(pool string, volume api.StorageVolumesPost) error {\r\n\tif !r.HasExtension(\"storage\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"storage\\\" API extension\")\r\n\t}\r\n\t\r\n\tpath := fmt.Sprintf(\"\/storage-pools\/%s\/volumes\/%s\", url.QueryEscape(pool), url.QueryEscape(volume.Type))\r\n\t_, _, err := r.query(\"POST\", path, volume, \"\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":159,"reference":"\/\/ CreateStoragePoolVolume defines a new storage volume","result":"Create a new storage volume.","score":[0.3318,0.433]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) CreateStoragePoolVolumeSnapshot(pool string, volumeType string, volumeName string, snapshot api.StorageVolumeSnapshotsPost) (Operation, error) {\r\n\tif !r.HasExtension(\"storage_api_volume_snapshots\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"storage_api_volume_snapshots\\\" API extension\")\r\n\t}\r\n\t\r\n\tpath := fmt.Sprintf(\"\/storage-pools\/%s\/volumes\/%s\/%s\/snapshots\",\r\n\t\turl.QueryEscape(pool),\r\n\t\turl.QueryEscape(volumeType),\r\n\t\turl.QueryEscape(volumeName))\r\n\top, _, err := r.queryOperation(\"POST\", path, snapshot, \"\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":215,"reference":"\/\/ CreateStoragePoolVolumeSnapshot defines a new storage volume","result":"Create a new storage volume snapshot.","score":[0.5115,0.5752]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetStoragePoolVolumeSnapshots(pool string, volumeType string, volumeName string) ([]api.StorageVolumeSnapshot, error) {\r\n\tif !r.HasExtension(\"storage_api_volume_snapshots\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"storage_api_volume_snapshots\\\" API extension\")\r\n\t}\r\n\tsnapshots := []api.StorageVolumeSnapshot{}\r\n\tpath := fmt.Sprintf(\"\/storage-pools\/%s\/volumes\/%s\/%s\/snapshots?recursion=1\",\r\n\t\turl.QueryEscape(pool),\r\n\t\turl.QueryEscape(volumeType),\r\n\t\turl.QueryEscape(volumeName))\r\n\t_, err := r.queryStruct(\"GET\", path, nil, \"\", &snapshots)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn snapshots, nil\r\n}","code-length":225,"reference":"\/\/ GetStoragePoolVolumeSnapshots returns a list of snapshots for the storage\n\/\/ volume","result":"Generate code for the generated code.","score":[0.1004,0.1645]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetStoragePoolVolumeSnapshot(pool string, volumeType string, volumeName string, snapshotName string) (*api.StorageVolumeSnapshot, string, error) {\r\n\tif !r.HasExtension(\"storage_api_volume_snapshots\") {\r\n\t\treturn nil, \"\", fmt.Errorf(\"The server is missing the required \\\"storage_api_volume_snapshots\\\" API extension\")\r\n\t}\r\n\tsnapshot := api.StorageVolumeSnapshot{}\r\n\tpath := fmt.Sprintf(\"\/storage-pools\/%s\/volumes\/%s\/%s\/snapshots\/%s\",\r\n\t\turl.QueryEscape(pool),\r\n\t\turl.QueryEscape(volumeType),\r\n\t\turl.QueryEscape(volumeName),\r\n\t\turl.QueryEscape(snapshotName))\r\n\tetag, err := r.queryStruct(\"GET\", path, nil, \"\", &snapshot)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\treturn &snapshot, etag, nil\r\n}","code-length":245,"reference":"\/\/ GetStoragePoolVolumeSnapshot returns a snapshots for the storage volume","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) UpdateStoragePoolVolumeSnapshot(pool string, volumeType string, volumeName string, snapshotName string, volume api.StorageVolumeSnapshotPut, ETag string) error {\r\n\tif !r.HasExtension(\"storage_api_volume_snapshots\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"storage_api_volume_snapshots\\\" API extension\")\r\n\t}\r\n\t\r\n\tpath := fmt.Sprintf(\"\/storage-pools\/%s\/volumes\/%s\/%s\/snapshots\/%s\", url.QueryEscape(pool), url.QueryEscape(volumeType), url.QueryEscape(volumeName), url.QueryEscape(snapshotName))\r\n\t_, _, err := r.queryOperation(\"PUT\", path, volume, ETag)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":210,"reference":"\/\/ UpdateStoragePoolVolumeSnapshot updates the volume to match the provided StoragePoolVolume struct","result":"Generate the generated code.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) MigrateStoragePoolVolume(pool string, volume api.StorageVolumePost) (Operation, error) {\r\n\tif !r.HasExtension(\"storage_api_remote_volume_handling\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"storage_api_remote_volume_handling\\\" API extension\")\r\n\t}\r\n\t\r\n\tif !volume.Migration {\r\n\t\treturn nil, fmt.Errorf(\"Can't ask for a rename through MigrateStoragePoolVolume\")\r\n\t}\r\n\t\r\n\tpath := fmt.Sprintf(\"\/storage-pools\/%s\/volumes\/custom\/%s\", url.QueryEscape(pool), volume.Name)\r\n\top, _, err := r.queryOperation(\"POST\", path, volume, \"\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":222,"reference":"\/\/ MigrateStoragePoolVolume requests that LXD prepares for a storage volume migration","result":"Create a new storage volume.","score":[0.0861,0.0962]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) MoveStoragePoolVolume(pool string, source ContainerServer, sourcePool string, volume api.StorageVolume, args *StoragePoolVolumeMoveArgs) (RemoteOperation, error) {\r\n\tif !r.HasExtension(\"storage_api_local_volume_handling\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"storage_api_local_volume_handling\\\" API extension\")\r\n\t}\r\n\tif r != source {\r\n\t\treturn nil, fmt.Errorf(\"Moving storage volumes between remotes is not implemented\")\r\n\t}\r\n\treq := api.StorageVolumePost{\r\n\t\tName: args.Name,\r\n\t\tPool: pool,\r\n\t}\r\n\t\r\n\top, _, err := r.queryOperation(\"POST\", fmt.Sprintf(\"\/storage-pools\/%s\/volumes\/%s\/%s\", url.QueryEscape(sourcePool), url.QueryEscape(volume.Type), volume.Name), req, \"\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\trop := remoteOperation{\r\n\t\ttargetOp: op,\r\n\t\tchDone:   make(chan bool),\r\n\t}\r\n\t\r\n\tgo func() {\r\n\t\trop.err = rop.targetOp.Wait()\r\n\t\tclose(rop.chDone)\r\n\t}()\r\n\treturn &rop, nil\r\n}","code-length":345,"reference":"\/\/ MoveStoragePoolVolume renames or moves an existing storage volume","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) UpdateStoragePoolVolume(pool string, volType string, name string, volume api.StorageVolumePut, ETag string) error {\r\n\tif !r.HasExtension(\"storage\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"storage\\\" API extension\")\r\n\t}\r\n\tif volume.Restore != \"\" && !r.HasExtension(\"storage_api_volume_snapshots\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"storage_api_volume_snapshots\\\" API extension\")\r\n\t}\r\n\t\r\n\tpath := fmt.Sprintf(\"\/storage-pools\/%s\/volumes\/%s\/%s\", url.QueryEscape(pool), url.QueryEscape(volType), url.QueryEscape(name))\r\n\t_, _, err := r.query(\"PUT\", path, volume, ETag)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":233,"reference":"\/\/ UpdateStoragePoolVolume updates the volume to match the provided StoragePoolVolume struct","result":"Generate the generated code.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) DeleteStoragePoolVolume(pool string, volType string, name string) error {\r\n\tif !r.HasExtension(\"storage\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"storage\\\" API extension\")\r\n\t}\r\n\t\r\n\tpath := fmt.Sprintf(\"\/storage-pools\/%s\/volumes\/%s\/%s\", url.QueryEscape(pool), url.QueryEscape(volType), url.QueryEscape(name))\r\n\t_, _, err := r.query(\"DELETE\", path, nil, \"\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":167,"reference":"\/\/ DeleteStoragePoolVolume deletes a storage pool","result":"Remove the trailing comma.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) RenameStoragePoolVolume(pool string, volType string, name string, volume api.StorageVolumePost) error {\r\n\tif !r.HasExtension(\"storage_api_volume_rename\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"storage_api_volume_rename\\\" API extension\")\r\n\t}\r\n\tpath := fmt.Sprintf(\"\/storage-pools\/%s\/volumes\/%s\/%s\", url.QueryEscape(pool), url.QueryEscape(volType), url.QueryEscape(name))\r\n\t\r\n\t_, _, err := r.query(\"POST\", path, volume, \"\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":186,"reference":"\/\/ RenameStoragePoolVolume renames a storage volume","result":"Rename storage volume.","score":[0.1502,0.1754]}
{"code":"\/*is used to<extra_id_0>\r\nfunc doStoragePoolCreateInternal(state *state.State, poolName, poolDescription string, driver string, config map[string]string, isNotification bool) error {\r\n\ttryUndo := true\r\n\ts, err := storagePoolInit(state, poolName)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif s, ok := s.(*storageCeph); ok && isNotification {\r\n\t\tvolumeMntPoint := getStoragePoolVolumeMountPoint(s.pool.Name, s.volume.Name)\r\n\t\treturn os.MkdirAll(volumeMntPoint, 0711)\r\n\t}\r\n\terr = s.StoragePoolCreate()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer func() {\r\n\t\tif !tryUndo {\r\n\t\t\treturn\r\n\t\t}\r\n\t\ts.StoragePoolDelete()\r\n\t}()\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tpostCreateConfig := s.GetStoragePoolWritable().Config\r\n\tconfigDiff, _ := storageConfigDiff(config, postCreateConfig)\r\n\tif len(configDiff) > 0 {\r\n\t\t\r\n\t\terr = state.Cluster.StoragePoolUpdate(poolName, poolDescription, postCreateConfig)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"Error inserting %s into database: %s\", poolName, err)\r\n\t\t}\r\n\t}\r\n\t\r\n\ttryUndo = false\r\n\treturn nil\r\n}","code-length":384,"reference":"\/\/ This performs all non-db related work needed to create the pool.","result":"Create the storage pool.","score":[0.0514,0.2282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc containerGetParentAndSnapshotName(name string) (string, string, bool) {\r\n\tfields := strings.SplitN(name, shared.SnapshotDelimiter, 2)\r\n\tif len(fields) == 1 {\r\n\t\treturn name, \"\", false\r\n\t}\r\n\treturn fields[0], fields[1], true\r\n}","code-length":87,"reference":"\/\/ Helper functions\n\/\/ Returns the parent container name, snapshot name, and whether it actually was\n\/\/ a snapshot name.","result":"Get the parent and snapshot name.","score":[0.0368,0.2398]}
{"code":"\/*is used to<extra_id_0>\r\nfunc containerLoadFromAllProjects(s *state.State) ([]container, error) {\r\n\tvar projects []string\r\n\terr := s.Cluster.Transaction(func(tx *db.ClusterTx) error {\r\n\t\tvar err error\r\n\t\tprojects, err = tx.ProjectNames()\r\n\t\treturn err\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tcontainers := []container{}\r\n\tfor _, project := range projects {\r\n\t\tprojectContainers, err := containerLoadByProject(s, project)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, errors.Wrapf(nil, \"Load containers in project %s\", project)\r\n\t\t}\r\n\t\tcontainers = append(containers, projectContainers...)\r\n\t}\r\n\treturn containers, nil\r\n}","code-length":210,"reference":"\/\/ Load all containers across all projects.","result":"Load all containers in all projects.","score":[0.411,0.7014]}
{"code":"\/*is used to<extra_id_0>\r\nfunc containerLoadNodeAll(s *state.State) ([]container, error) {\r\n\t\r\n\tvar cts []db.Container\r\n\terr := s.Cluster.Transaction(func(tx *db.ClusterTx) error {\r\n\t\tvar err error\r\n\t\tcts, err = tx.ContainerNodeList()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn containerLoadAllInternal(cts, s)\r\n}","code-length":151,"reference":"\/\/ Load all containers of this nodes.","result":"Load all containers in the cluster.","score":[0.3366,0.4267]}
{"code":"\/*is used to<extra_id_0>\r\nfunc containerLoadNodeProjectAll(s *state.State, project string) ([]container, error) {\r\n\t\r\n\tvar cts []db.Container\r\n\terr := s.Cluster.Transaction(func(tx *db.ClusterTx) error {\r\n\t\tvar err error\r\n\t\tcts, err = tx.ContainerNodeProjectList(project)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn containerLoadAllInternal(cts, s)\r\n}","code-length":159,"reference":"\/\/ Load all containers of this nodes under the given project.","result":"Load all containers in a node project.","score":[0.2019,0.4208]}
{"code":"\/*is used to<extra_id_0>\r\nfunc heartbeatNode(taskCtx context.Context, address string, cert *shared.CertInfo, raftNodes []db.RaftNode) error {\r\n\tlogger.Debugf(\"Sending heartbeat request to %s\", address)\r\n\tconfig, err := tlsClientConfig(cert)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\turl := fmt.Sprintf(\"https:\r\n\tclient := &http.Client{Transport: &http.Transport{TLSClientConfig: config}}\r\n\tbuffer := bytes.Buffer{}\r\n\terr = json.NewEncoder(&buffer).Encode(raftNodes)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\trequest, err := http.NewRequest(\"PUT\", url, bytes.NewReader(buffer.Bytes()))\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)\r\n\tdefer cancel()\r\n\trequest = request.WithContext(ctx)\r\n\trequest.Close = true\r\n\t\r\n\terrCh := make(chan error)\r\n\tgo func() {\r\n\t\tresponse, err := client.Do(request)\r\n\t\tif err != nil {\r\n\t\t\terrCh <- errors.Wrap(err, \"failed to send HTTP request\")\r\n\t\t\treturn\r\n\t\t}\r\n\t\tdefer response.Body.Close()\r\n\t\tif response.StatusCode != http.StatusOK {\r\n\t\t\terrCh <- fmt.Errorf(\"HTTP request failed: %s\", response.Status)\r\n\t\t\treturn\r\n\t\t}\r\n\t\terrCh <- nil\r\n\t}()\r\n\tselect {\r\n\tcase err := <-errCh:\r\n\t\treturn err\r\n\tcase <-taskCtx.Done():\r\n\t\treturn taskCtx.Err()\r\n\t}\r\n}","code-length":448,"reference":"\/\/ Perform a single heartbeat request against the node with the given address.","result":"Send a heartbeat request to a node.","score":[0.1073,0.2061]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *cmdList) dotPrefixMatch(short string, full string) bool {\r\n\tfullMembs := strings.Split(full, \".\")\r\n\tshortMembs := strings.Split(short, \".\")\r\n\tif len(fullMembs) != len(shortMembs) {\r\n\t\treturn false\r\n\t}\r\n\tfor i := range fullMembs {\r\n\t\tif !strings.HasPrefix(fullMembs[i], shortMembs[i]) {\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":144,"reference":"\/\/ This seems a little excessive.","result":"Match the command name in the command list.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageZfs) ContainerMount(c container) (bool, error) {\r\n\treturn s.doContainerMount(c.Project(), c.Name(), c.IsPrivileged())\r\n}","code-length":55,"reference":"\/\/ Things we don't need to care about","result":"Mount the container.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageZfs) ContainerStorageReady(container container) bool {\r\n\tvolumeName := projectPrefix(container.Project(), container.Name())\r\n\tfs := fmt.Sprintf(\"containers\/%s\", volumeName)\r\n\treturn zfsFilesystemEntityExists(s.getOnDiskPoolName(), fs)\r\n}","code-length":82,"reference":"\/\/ Things we do have to care about","result":"Check if storage volume is ready for container.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AskChoice(question string, choices []string, defaultAnswer string) string {\r\n\tfor {\r\n\t\tanswer := askQuestion(question, defaultAnswer)\r\n\t\tif shared.StringInSlice(answer, choices) {\r\n\t\t\treturn answer\r\n\t\t}\r\n\t\tinvalidInput()\r\n\t}\r\n}","code-length":86,"reference":"\/\/ AskChoice asks the user to select one of multiple options","result":"Generate the question.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AskInt(question string, min int64, max int64, defaultAnswer string) int64 {\r\n\tfor {\r\n\t\tanswer := askQuestion(question, defaultAnswer)\r\n\t\tresult, err := strconv.ParseInt(answer, 10, 64)\r\n\t\tif err == nil && (min == -1 || result >= min) && (max == -1 || result <= max) {\r\n\t\t\treturn result\r\n\t\t}\r\n\t\tinvalidInput()\r\n\t}\r\n}","code-length":125,"reference":"\/\/ AskInt asks the user to enter an integer between a min and max value","result":"Generate the code.","score":[0.0075,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AskString(question string, defaultAnswer string, validate func(string) error) string {\r\n\tfor {\r\n\t\tanswer := askQuestion(question, defaultAnswer)\r\n\t\tif validate != nil {\r\n\t\t\terror := validate(answer)\r\n\t\t\tif error != nil {\r\n\t\t\t\tfmt.Fprintf(os.Stderr, \"Invalid input: %s\\n\\n\", error)\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\treturn answer\r\n\t\t}\r\n\t\tif len(answer) != 0 {\r\n\t\t\treturn answer\r\n\t\t}\r\n\t\tinvalidInput()\r\n\t}\r\n}","code-length":160,"reference":"\/\/ AskString asks the user to enter a string, which optionally\n\/\/ conforms to a validation function.","result":"Ask the user for a string.","score":[0.0483,0.2358]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AskPassword(question string) string {\r\n\tfor {\r\n\t\tfmt.Printf(question)\r\n\t\tpwd, _ := terminal.ReadPassword(0)\r\n\t\tfmt.Println(\"\")\r\n\t\tinFirst := string(pwd)\r\n\t\tinFirst = strings.TrimSuffix(inFirst, \"\\n\")\r\n\t\tfmt.Printf(\"Again: \")\r\n\t\tpwd, _ = terminal.ReadPassword(0)\r\n\t\tfmt.Println(\"\")\r\n\t\tinSecond := string(pwd)\r\n\t\tinSecond = strings.TrimSuffix(inSecond, \"\\n\")\r\n\t\tif inFirst == inSecond {\r\n\t\t\treturn inFirst\r\n\t\t}\r\n\t\tinvalidInput()\r\n\t}\r\n}","code-length":189,"reference":"\/\/ AskPassword asks the user to enter a password.","result":"Ask for a password.","score":[0.1294,0.3007]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AskPasswordOnce(question string) string {\r\n\tfmt.Printf(question)\r\n\tpwd, _ := terminal.ReadPassword(0)\r\n\tfmt.Println(\"\")\r\n\treturn string(pwd)\r\n}","code-length":62,"reference":"\/\/ AskPasswordOnce asks the user to enter a password.\n\/\/\n\/\/ It's the same as AskPassword, but it won't ask to enter it again.","result":"Ask for a password.","score":[0.003,0.1162]}
{"code":"\/*is used to<extra_id_0>\r\nfunc askQuestion(question, defaultAnswer string) string {\r\n\tfmt.Printf(question)\r\n\treturn readAnswer(defaultAnswer)\r\n}","code-length":43,"reference":"\/\/ Ask a question on the output stream and read the answer from the input stream","result":"Generate the code.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc readAnswer(defaultAnswer string) string {\r\n\tanswer, _ := stdin.ReadString('\\n')\r\n\tanswer = strings.TrimSuffix(answer, \"\\n\")\r\n\tanswer = strings.TrimSpace(answer)\r\n\tif answer == \"\" {\r\n\t\tanswer = defaultAnswer\r\n\t}\r\n\treturn answer\r\n}","code-length":89,"reference":"\/\/ Read the user's answer from the input stream, trimming newline and providing a default.","result":"Read the default answer.","score":[0.0289,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc profilePost(d *Daemon, r *http.Request) Response {\r\n\tproject := projectParam(r)\r\n\tname := mux.Vars(r)[\"name\"]\r\n\tif name == \"default\" {\r\n\t\treturn Forbidden(errors.New(\"The 'default' profile cannot be renamed\"))\r\n\t}\r\n\treq := api.ProfilePost{}\r\n\tif err := json.NewDecoder(r.Body).Decode(&req); err != nil {\r\n\t\treturn BadRequest(err)\r\n\t}\r\n\t\r\n\tif req.Name == \"\" {\r\n\t\treturn BadRequest(fmt.Errorf(\"No name provided\"))\r\n\t}\r\n\tif strings.Contains(req.Name, \"\/\") {\r\n\t\treturn BadRequest(fmt.Errorf(\"Profile names may not contain slashes\"))\r\n\t}\r\n\tif shared.StringInSlice(req.Name, []string{\".\", \"..\"}) {\r\n\t\treturn BadRequest(fmt.Errorf(\"Invalid profile name '%s'\", req.Name))\r\n\t}\r\n\terr := d.cluster.Transaction(func(tx *db.ClusterTx) error {\r\n\t\thasProfiles, err := tx.ProjectHasProfiles(project)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Check project features\")\r\n\t\t}\r\n\t\tif !hasProfiles {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\t\r\n\t\t_, err = tx.ProfileGet(project, req.Name)\r\n\t\tif err == nil {\r\n\t\t\treturn fmt.Errorf(\"Name '%s' already in use\", req.Name)\r\n\t\t}\r\n\t\treturn tx.ProfileRename(project, name, req.Name)\r\n\t})\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\treturn SyncResponseLocation(true, nil, fmt.Sprintf(\"\/%s\/profiles\/%s\", version.APIVersion, req.Name))\r\n}","code-length":479,"reference":"\/\/ The handler for the post operation.","result":"Rename a profile.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc profileDelete(d *Daemon, r *http.Request) Response {\r\n\tproject := projectParam(r)\r\n\tname := mux.Vars(r)[\"name\"]\r\n\tif name == \"default\" {\r\n\t\treturn Forbidden(errors.New(\"The 'default' profile cannot be deleted\"))\r\n\t}\r\n\terr := d.cluster.Transaction(func(tx *db.ClusterTx) error {\r\n\t\thasProfiles, err := tx.ProjectHasProfiles(project)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Check project features\")\r\n\t\t}\r\n\t\tif !hasProfiles {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\tprofile, err := tx.ProfileGet(project, name)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif len(profile.UsedBy) > 0 {\r\n\t\t\treturn fmt.Errorf(\"Profile is currently in use\")\r\n\t\t}\r\n\t\treturn tx.ProfileDelete(project, name)\r\n\t})\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\treturn EmptySyncResponse\r\n}","code-length":298,"reference":"\/\/ The handler for the delete operation.","result":"Delete a profile.","score":[0,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsRootDiskDevice(device map[string]string) bool {\r\n\tif device[\"type\"] == \"disk\" && device[\"path\"] == \"\/\" && device[\"source\"] == \"\" {\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":69,"reference":"\/\/ IsRootDiskDevice returns true if the given device representation is\n\/\/ configured as root disk for a container. It typically get passed a specific\n\/\/ entry of api.Container.Devices.","result":"Detect root disk devices.","score":[0.0011,0.0732]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetRootDiskDevice(devices map[string]map[string]string) (string, map[string]string, error) {\r\n\tvar devName string\r\n\tvar dev map[string]string\r\n\tfor n, d := range devices {\r\n\t\tif IsRootDiskDevice(d) {\r\n\t\t\tif devName != \"\" {\r\n\t\t\t\treturn \"\", nil, fmt.Errorf(\"More than one root device found\")\r\n\t\t\t}\r\n\t\t\tdevName = n\r\n\t\t\tdev = d\r\n\t\t}\r\n\t}\r\n\tif devName != \"\" {\r\n\t\treturn devName, dev, nil\r\n\t}\r\n\treturn \"\", nil, fmt.Errorf(\"No root device could be found\")\r\n}","code-length":182,"reference":"\/\/ GetRootDiskDevice returns the container device that is configured as root disk","result":"Get the root disk device name.","score":[0.1194,0.2769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ForwardedResponse(client lxd.ContainerServer, request *http.Request) Response {\r\n\treturn &forwardedResponse{\r\n\t\tclient:  client,\r\n\t\trequest: request,\r\n\t}\r\n}","code-length":62,"reference":"\/\/ ForwardedResponse takes a request directed to a node and forwards it to\n\/\/ another node, writing back the response it gegs.","result":"Generate the response for the forwarded request.","score":[0.0268,0.0732]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ForwardedResponseIfTargetIsRemote(d *Daemon, request *http.Request) Response {\r\n\ttargetNode := queryParam(request, \"target\")\r\n\tif targetNode == \"\" {\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\t\r\n\taddress, err := cluster.ResolveTarget(d.cluster, targetNode)\r\n\tif err != nil {\r\n\t\treturn SmartError(err)\r\n\t}\r\n\tif address != \"\" {\r\n\t\t\r\n\t\tcert := d.endpoints.NetworkCert()\r\n\t\tclient, err := cluster.Connect(address, cert, false)\r\n\t\tif err != nil {\r\n\t\t\treturn SmartError(err)\r\n\t\t}\r\n\t\treturn ForwardedResponse(client, request)\r\n\t}\r\n\treturn nil\r\n}","code-length":198,"reference":"\/\/ ForwardedResponseIfTargetIsRemote redirects a request to the request has a\n\/\/ targetNode parameter pointing to a node which is not the local one.","result":"Return a response if target is a remote node.","score":[0.0338,0.0926]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ForwardedResponseIfContainerIsRemote(d *Daemon, r *http.Request, project, name string) (Response, error) {\r\n\tcert := d.endpoints.NetworkCert()\r\n\tclient, err := cluster.ConnectIfContainerIsRemote(d.cluster, project, name, cert)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif client == nil {\r\n\t\treturn nil, nil\r\n\t}\r\n\treturn ForwardedResponse(client, r), nil\r\n}","code-length":132,"reference":"\/\/ ForwardedResponseIfContainerIsRemote redirects a request to the node running\n\/\/ the container with the given name. If the container is local, nothing gets\n\/\/ done and nil is returned.","result":"Generate the ForwardedResponse function.","score":[0.0006,0.0189]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ForwardedOperationResponse(project string, op *api.Operation) Response {\r\n\treturn &forwardedOperationResponse{\r\n\t\top:      op,\r\n\t\tproject: project,\r\n\t}\r\n}","code-length":60,"reference":"\/\/ ForwardedOperationResponse creates a response that forwards the metadata of\n\/\/ an operation created on another node.","result":"Generate the response.","score":[0.0038,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ProgressRenderer) Done(msg string) {\r\n\t\r\n\tp.lock.Lock()\r\n\tdefer p.lock.Unlock()\r\n\t\r\n\tif p.done {\r\n\t\treturn\r\n\t}\r\n\t\r\n\tp.done = true\r\n\t\r\n\tif p.Quiet {\r\n\t\tmsg = \"\"\r\n\t}\r\n\t\r\n\tmsg = p.truncate(msg)\r\n\t\r\n\tif msg == \"\" && p.maxLength == 0 {\r\n\t\treturn\r\n\t}\r\n\t\r\n\tif msg != \"\" {\r\n\t\tmsg += \"\\n\"\r\n\t}\r\n\tif len(msg) > p.maxLength {\r\n\t\tp.maxLength = len(msg)\r\n\t} else {\r\n\t\tfmt.Printf(\"\\r%s\", strings.Repeat(\" \", p.maxLength))\r\n\t}\r\n\tfmt.Print(\"\\r\")\r\n\tfmt.Print(msg)\r\n}","code-length":242,"reference":"\/\/ Done prints the final status and prevents any update","result":"Avoid the need for the following code.","score":[0.1052,0.0515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ProgressRenderer) Update(status string) {\r\n\t\r\n\ttimeout := p.wait.Sub(time.Now())\r\n\tif timeout.Seconds() > 0 {\r\n\t\ttime.Sleep(timeout)\r\n\t}\r\n\t\r\n\tp.lock.Lock()\r\n\tdefer p.lock.Unlock()\r\n\t\r\n\tif p.done {\r\n\t\treturn\r\n\t}\r\n\t\r\n\tif p.Quiet {\r\n\t\treturn\r\n\t}\r\n\t\r\n\tif p.terminal == 0 {\r\n\t\tif !termios.IsTerminal(int(os.Stdout.Fd())) {\r\n\t\t\tp.terminal = -1\r\n\t\t}\r\n\t\tp.terminal = 1\r\n\t}\r\n\tif p.terminal != 1 {\r\n\t\treturn\r\n\t}\r\n\t\r\n\tmsg := \"%s\"\r\n\tif p.Format != \"\" {\r\n\t\tmsg = p.Format\r\n\t}\r\n\tmsg = fmt.Sprintf(msg, status)\r\n\t\r\n\tmsg = \"\\r\" + p.truncate(msg)\r\n\t\r\n\tif len(msg) == 1 && p.maxLength == 0 {\r\n\t\treturn\r\n\t}\r\n\tif len(msg) > p.maxLength {\r\n\t\tp.maxLength = len(msg)\r\n\t} else {\r\n\t\tfmt.Printf(\"\\r%s\", strings.Repeat(\" \", p.maxLength))\r\n\t}\r\n\tfmt.Print(msg)\r\n}","code-length":376,"reference":"\/\/ Update changes the status message to the provided string","result":"Update the progress of the current progress.","score":[0.1385,0.1546]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ProgressRenderer) Warn(status string, timeout time.Duration) {\r\n\t\r\n\tp.lock.Lock()\r\n\tdefer p.lock.Unlock()\r\n\t\r\n\tif p.done {\r\n\t\treturn\r\n\t}\r\n\t\r\n\tp.wait = time.Now().Add(timeout)\r\n\tmsg := fmt.Sprintf(\"%s\", status)\r\n\t\r\n\tmsg = \"\\r\" + p.truncate(msg)\r\n\t\r\n\tif len(msg) == 1 && p.maxLength == 0 {\r\n\t\treturn\r\n\t}\r\n\tif len(msg) > p.maxLength {\r\n\t\tp.maxLength = len(msg)\r\n\t} else {\r\n\t\tfmt.Printf(\"\\r%s\", strings.Repeat(\" \", p.maxLength))\r\n\t}\r\n\tfmt.Print(msg)\r\n}","code-length":220,"reference":"\/\/ Warn shows a temporary message instead of the status","result":"Avoid the need for the function to be called.","score":[0.109,0.0505]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ProgressRenderer) UpdateProgress(progress ioprogress.ProgressData) {\r\n\tp.Update(progress.Text)\r\n}","code-length":43,"reference":"\/\/ UpdateProgress is a helper to update the status using an iopgress instance","result":"Generate the generated code.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ProgressRenderer) UpdateOp(op api.Operation) {\r\n\tif op.Metadata == nil {\r\n\t\treturn\r\n\t}\r\n\tfor key, value := range op.Metadata {\r\n\t\tif !strings.HasSuffix(key, \"_progress\") {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tp.Update(value.(string))\r\n\t\tbreak\r\n\t}\r\n}","code-length":109,"reference":"\/\/ UpdateOp is a helper to update the status using a LXD API operation","result":"Update the progress of a function.","score":[0.0605,0.1936]}
{"code":"\/*is used to<extra_id_0>\r\nfunc updateFromV6(tx *sql.Tx) error {\r\n\t\r\n\tnodeIDs, err := query.SelectIntegers(tx, \"SELECT id FROM nodes\")\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to get IDs of current nodes\")\r\n\t}\r\n\t\r\n\tpoolIDs, err := query.SelectIntegers(tx, `\r\nSELECT id FROM storage_pools WHERE driver='zfs'\r\n`)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to get IDs of current zfs pools\")\r\n\t}\r\n\tfor _, poolID := range poolIDs {\r\n\t\t\r\n\t\tconfig, err := query.SelectConfig(\r\n\t\t\ttx, \"storage_pools_config\", \"storage_pool_id=? AND node_id IS NULL\", poolID)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"failed to fetch of zfs pool config\")\r\n\t\t}\r\n\t\tpoolName, ok := config[\"zfs.pool_name\"]\r\n\t\tif !ok {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\t_, err = tx.Exec(`\r\nDELETE FROM storage_pools_config WHERE key='zfs.pool_name' AND storage_pool_id=? AND node_id IS NULL\r\n`, poolID)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"failed to delete zfs.pool_name config\")\r\n\t\t}\r\n\t\t\r\n\t\tfor _, nodeID := range nodeIDs {\r\n\t\t\t_, err := tx.Exec(`\r\nINSERT INTO storage_pools_config(storage_pool_id, node_id, key, value)\r\n  VALUES(?, ?, 'zfs.pool_name', ?)\r\n`, poolID, nodeID, poolName)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn errors.Wrap(err, \"failed to create zfs.pool_name node config\")\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":509,"reference":"\/\/ The zfs.pool_name config key is node-specific, and needs to be linked to\n\/\/ nodes.","result":"Update storage from v.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc localCreateListener(path string, group string) (net.Listener, error) {\r\n\terr := CheckAlreadyRunning(path)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\terr = socketUnixRemoveStale(path)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tlistener, err := socketUnixListen(path)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\terr = localSetAccess(path, group)\r\n\tif err != nil {\r\n\t\tlistener.Close()\r\n\t\treturn nil, err\r\n\t}\r\n\treturn listener, nil\r\n}","code-length":175,"reference":"\/\/ Create a new net.Listener bound to the unix socket of the local endpoint.","result":"Create a local listener on the local machine.","score":[0.1221,0.2799]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewStmt(database, pkg, entity, kind string, config map[string]string) (*Stmt, error) {\r\n\tpackages, err := Packages()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tstmt := &Stmt{\r\n\t\tdb:       database,\r\n\t\tpkg:      pkg,\r\n\t\tentity:   entity,\r\n\t\tkind:     kind,\r\n\t\tconfig:   config,\r\n\t\tpackages: packages,\r\n\t}\r\n\treturn stmt, nil\r\n}","code-length":141,"reference":"\/\/ NewStmt return a new statement code snippet for running the given kind of\n\/\/ query against the given database entity.","result":"Create a statement.","score":[0.001,0.026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Stmt) Generate(buf *file.Buffer) error {\r\n\tif strings.HasPrefix(s.kind, \"objects\") {\r\n\t\treturn s.objects(buf)\r\n\t}\r\n\tif strings.HasPrefix(s.kind, \"create\") && strings.HasSuffix(s.kind, \"-ref\") {\r\n\t\treturn s.createRef(buf)\r\n\t}\r\n\tif strings.HasSuffix(s.kind, \"-ref\") || strings.Contains(s.kind, \"-ref-by-\") {\r\n\t\treturn s.ref(buf)\r\n\t}\r\n\tif strings.HasPrefix(s.kind, \"names\") {\r\n\t\treturn s.names(buf)\r\n\t}\r\n\tswitch s.kind {\r\n\tcase \"create\":\r\n\t\treturn s.create(buf)\r\n\tcase \"id\":\r\n\t\treturn s.id(buf)\r\n\tcase \"rename\":\r\n\t\treturn s.rename(buf)\r\n\tcase \"update\":\r\n\t\treturn s.update(buf)\r\n\tcase \"delete\":\r\n\t\treturn s.delete(buf)\r\n\tdefault:\r\n\t\treturn fmt.Errorf(\"Unknown statement '%s'\", s.kind)\r\n\t}\r\n}","code-length":311,"reference":"\/\/ Generate plumbing and wiring code for the desired statement.","result":"Generate the statement.","score":[0.0521,0.1613]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Stmt) register(buf *file.Buffer, sql string, filters ...string) {\r\n\tkind := strings.Replace(s.kind, \"-\", \"_\", -1)\r\n\tif kind == \"id\" {\r\n\t\tkind = \"ID\"\r\n\t}\r\n\tbuf.L(\"var %s = %s.RegisterStmt(`\\n%s\\n`)\", stmtCodeVar(s.entity, kind, filters...), s.db, sql)\r\n}","code-length":123,"reference":"\/\/ Output a line of code that registers the given statement and declares the\n\/\/ associated statement code global variable.","result":"Register the statement.","score":[0.0014,0.0546]}
{"code":"\/*is used to<extra_id_0>\r\nfunc httpsLXD(url string, args *ConnectionArgs) (ContainerServer, error) {\r\n\t\r\n\tif args == nil {\r\n\t\targs = &ConnectionArgs{}\r\n\t}\r\n\t\r\n\tserver := ProtocolLXD{\r\n\t\thttpCertificate:  args.TLSServerCert,\r\n\t\thttpHost:         url,\r\n\t\thttpProtocol:     \"https\",\r\n\t\thttpUserAgent:    args.UserAgent,\r\n\t\tbakeryInteractor: args.AuthInteractor,\r\n\t}\r\n\tif args.AuthType == \"candid\" {\r\n\t\tserver.RequireAuthenticated(true)\r\n\t}\r\n\t\r\n\thttpClient, err := tlsHTTPClient(args.HTTPClient, args.TLSClientCert, args.TLSClientKey, args.TLSCA, args.TLSServerCert, args.InsecureSkipVerify, args.Proxy)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif args.CookieJar != nil {\r\n\t\thttpClient.Jar = args.CookieJar\r\n\t}\r\n\tserver.http = httpClient\r\n\tif args.AuthType == \"candid\" {\r\n\t\tserver.setupBakeryClient()\r\n\t}\r\n\t\r\n\tif !args.SkipGetServer {\r\n\t\t_, _, err := server.GetServer()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\treturn &server, nil\r\n}","code-length":364,"reference":"\/\/ Internal function called by ConnectLXD and ConnectPublicLXD","result":"Connect to a https server.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c Container) IsActive() bool {\r\n\tswitch c.StatusCode {\r\n\tcase Stopped:\r\n\t\treturn false\r\n\tcase Error:\r\n\t\treturn false\r\n\tdefault:\r\n\t\treturn true\r\n\t}\r\n}","code-length":70,"reference":"\/\/ IsActive checks whether the container state indicates the container is active","result":"Check if a container is active.","score":[0.1004,0.2242]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NodeTx) RaftNodeAddress(id int64) (string, error) {\r\n\tstmt := \"SELECT address FROM raft_nodes WHERE id=?\"\r\n\taddresses, err := query.SelectStrings(n.tx, stmt, id)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tswitch len(addresses) {\r\n\tcase 0:\r\n\t\treturn \"\", ErrNoSuchObject\r\n\tcase 1:\r\n\t\treturn addresses[0], nil\r\n\tdefault:\r\n\t\t\r\n\t\t\r\n\t\treturn \"\", fmt.Errorf(\"more than one match found\")\r\n\t}\r\n}","code-length":158,"reference":"\/\/ RaftNodeAddress returns the address of the LXD raft node with the given ID,\n\/\/ if any matching row exists.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NodeTx) RaftNodeFirst(address string) error {\r\n\tcolumns := []string{\"id\", \"address\"}\r\n\tvalues := []interface{}{int64(1), address}\r\n\tid, err := query.UpsertObject(n.tx, \"raft_nodes\", columns, values)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif id != 1 {\r\n\t\treturn fmt.Errorf(\"could not set raft node ID to 1\")\r\n\t}\r\n\treturn nil\r\n}","code-length":136,"reference":"\/\/ RaftNodeFirst adds a the first node of the cluster. It ensures that the\n\/\/ database ID is 1, to match the server ID of first raft log entry.\n\/\/\n\/\/ This method is supposed to be called when there are no rows in raft_nodes,\n\/\/ and it will replace whatever existing row has ID 1.","result":"Create a new transaction to store the RaftNode.","score":[0.0005,0.0293]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NodeTx) RaftNodeAdd(address string) (int64, error) {\r\n\tcolumns := []string{\"address\"}\r\n\tvalues := []interface{}{address}\r\n\treturn query.UpsertObject(n.tx, \"raft_nodes\", columns, values)\r\n}","code-length":77,"reference":"\/\/ RaftNodeAdd adds a node to the current list of LXD nodes that are part of the\n\/\/ dqlite Raft cluster. It returns the ID of the newly inserted row.","result":"Add a new RaftNode.","score":[0.0005,0.0684]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NodeTx) RaftNodeDelete(id int64) error {\r\n\tdeleted, err := query.DeleteObject(n.tx, \"raft_nodes\", id)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif !deleted {\r\n\t\treturn ErrNoSuchObject\r\n\t}\r\n\treturn nil\r\n}","code-length":94,"reference":"\/\/ RaftNodeDelete removes a node from the current list of LXD nodes that are\n\/\/ part of the dqlite Raft cluster.","result":"Delete the RaftNode.","score":[0.001,0.026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NodeTx) RaftNodesReplace(nodes []RaftNode) error {\r\n\t_, err := n.tx.Exec(\"DELETE FROM raft_nodes\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tcolumns := []string{\"id\", \"address\"}\r\n\tfor _, node := range nodes {\r\n\t\tvalues := []interface{}{node.ID, node.Address}\r\n\t\t_, err := query.UpsertObject(n.tx, \"raft_nodes\", columns, values)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":166,"reference":"\/\/ RaftNodesReplace replaces the current list of raft nodes.","result":"Replace the code.","score":[0.0553,0.2232]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *OS) initCGroup() {\r\n\tflags := []*bool{\r\n\t\t&s.CGroupBlkioController,\r\n\t\t&s.CGroupCPUController,\r\n\t\t&s.CGroupCPUacctController,\r\n\t\t&s.CGroupCPUsetController,\r\n\t\t&s.CGroupDevicesController,\r\n\t\t&s.CGroupFreezerController,\r\n\t\t&s.CGroupMemoryController,\r\n\t\t&s.CGroupNetPrioController,\r\n\t\t&s.CGroupPidsController,\r\n\t\t&s.CGroupSwapAccounting,\r\n\t}\r\n\tfor i, flag := range flags {\r\n\t\t*flag = shared.PathExists(\"\/sys\/fs\/cgroup\/\" + cGroups[i].path)\r\n\t\tif !*flag {\r\n\t\t\tlogger.Warnf(cGroups[i].warn)\r\n\t\t}\r\n\t}\r\n}","code-length":240,"reference":"\/\/ Detect CGroup support.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc sqliteDirectAccess(conn *sqlite3.SQLiteConn) error {\r\n\t\r\n\t\r\n\t_, err := conn.Exec(\"PRAGMA journal_mode=wal\", nil)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t_, err = conn.Exec(\"PRAGMA journal_size_limit=-1\", nil)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t\r\n\t_, err = conn.Exec(\"PRAGMA wal_autocheckpoint=0\", nil)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":178,"reference":"\/\/ Configure the sqlite connection so that it's safe to access the\n\/\/ dqlite-managed sqlite file, also without setting up raft.","result":"Enable direct access.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ContainerGet(project string, name string) (*Container, error) {\r\n\tfilter := ContainerFilter{}\r\n\tfilter.Project = project\r\n\tfilter.Name = name\r\n\tfilter.Type = -1\r\n\tobjects, err := c.ContainerList(filter)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Failed to fetch Container\")\r\n\t}\r\n\tswitch len(objects) {\r\n\tcase 0:\r\n\t\treturn nil, ErrNoSuchObject\r\n\tcase 1:\r\n\t\treturn &objects[0], nil\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"More than one container matches\")\r\n\t}\r\n}","code-length":181,"reference":"\/\/ ContainerGet returns the container with the given key.","result":"Generate code for the code generated by the compiler.","score":[0.1449,0.1111]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ContainerID(project string, name string) (int64, error) {\r\n\tstmt := c.stmt(containerID)\r\n\trows, err := stmt.Query(project, name)\r\n\tif err != nil {\r\n\t\treturn -1, errors.Wrap(err, \"Failed to get container ID\")\r\n\t}\r\n\tdefer rows.Close()\r\n\t\r\n\tif !rows.Next() {\r\n\t\treturn -1, ErrNoSuchObject\r\n\t}\r\n\tvar id int64\r\n\terr = rows.Scan(&id)\r\n\tif err != nil {\r\n\t\treturn -1, errors.Wrap(err, \"Failed to scan ID\")\r\n\t}\r\n\tif rows.Next() {\r\n\t\treturn -1, fmt.Errorf(\"More than one row returned\")\r\n\t}\r\n\terr = rows.Err()\r\n\tif err != nil {\r\n\t\treturn -1, errors.Wrap(err, \"Result set failure\")\r\n\t}\r\n\treturn id, nil\r\n}","code-length":260,"reference":"\/\/ ContainerID return the ID of the container with the given key.","result":"Generate the generated code.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ContainerExists(project string, name string) (bool, error) {\r\n\t_, err := c.ContainerID(project, name)\r\n\tif err != nil {\r\n\t\tif err == ErrNoSuchObject {\r\n\t\t\treturn false, nil\r\n\t\t}\r\n\t\treturn false, err\r\n\t}\r\n\treturn true, nil\r\n}","code-length":101,"reference":"\/\/ ContainerExists checks if a container with the given key exists.","result":"Check if the container exists.","score":[0.1023,0.3577]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Mapping) ContainsFields(fields []*Field) bool {\r\n\tmatches := map[*Field]bool{}\r\n\tfor _, field := range m.Fields {\r\n\t\tfor _, other := range fields {\r\n\t\t\tif field.Name == other.Name && field.Type.Name == other.Type.Name {\r\n\t\t\t\tmatches[field] = true\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn len(matches) == len(fields)\r\n}","code-length":127,"reference":"\/\/ ContainsFields checks that the mapping contains fields with the same type\n\/\/ and name of given ones.","result":"Test if the fields are equal.","score":[0.0311,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Mapping) FieldByName(name string) *Field {\r\n\tfor _, field := range m.Fields {\r\n\t\tif field.Name == name {\r\n\t\t\treturn field\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":71,"reference":"\/\/ FieldByName returns the field with the given name, if any.","result":"Find the field by name.","score":[0.1023,0.0962]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Mapping) FieldColumnName(name string) string {\r\n\tfield := m.FieldByName(name)\r\n\treturn fmt.Sprintf(\"%s.%s\", entityTable(m.Name), field.Column())\r\n}","code-length":62,"reference":"\/\/ FieldColumnName returns the column name of the field with the given name,\n\/\/ prefixed with the entity's table name.","result":"Generate the field column name.","score":[0.0201,0.1081]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Mapping) FilterFieldByName(name string) (*Field, error) {\r\n\tfield := m.FieldByName(name)\r\n\tif field == nil {\r\n\t\treturn nil, fmt.Errorf(\"Unknown filter %q\", name)\r\n\t}\r\n\tif field.Type.Code != TypeColumn {\r\n\t\treturn nil, fmt.Errorf(\"Unknown filter %q not a column\", name)\r\n\t}\r\n\treturn field, nil\r\n}","code-length":119,"reference":"\/\/ FilterFieldByName returns the field with the given name if that field can be\n\/\/ used as query filter, an error otherwise.","result":"Filter by column name.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Mapping) ColumnFields(exclude ...string) []*Field {\r\n\tfields := []*Field{}\r\n\tfor _, field := range m.Fields {\r\n\t\tif shared.StringInSlice(field.Name, exclude) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif field.Type.Code == TypeColumn {\r\n\t\t\tfields = append(fields, field)\r\n\t\t}\r\n\t}\r\n\treturn fields\r\n}","code-length":119,"reference":"\/\/ ColumnFields returns the fields that map directly to a database column,\n\/\/ either on this table or on a joined one.","result":"Generate the generated code.","score":[0.0035,0.0248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Mapping) ScalarFields() []*Field {\r\n\tfields := []*Field{}\r\n\tfor _, field := range m.Fields {\r\n\t\tif field.Config.Get(\"join\") != \"\" {\r\n\t\t\tfields = append(fields, field)\r\n\t\t}\r\n\t}\r\n\treturn fields\r\n}","code-length":89,"reference":"\/\/ ScalarFields returns the fields that map directly to a single database\n\/\/ column on another table that can be joined to this one.","result":"Generate the code.","score":[0.0004,0.0228]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Mapping) RefFields() []*Field {\r\n\tfields := []*Field{}\r\n\tfor _, field := range m.Fields {\r\n\t\tif field.Type.Code == TypeSlice || field.Type.Code == TypeMap {\r\n\t\t\tfields = append(fields, field)\r\n\t\t}\r\n\t}\r\n\treturn fields\r\n}","code-length":96,"reference":"\/\/ RefFields returns the fields that are one-to-many references to other\n\/\/ tables.","result":"Generate the code.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *Field) Column() string {\r\n\tif f.Type.Code != TypeColumn {\r\n\t\tpanic(\"attempt to get column name of non-column field\")\r\n\t}\r\n\tcolumn := lex.Snake(f.Name)\r\n\tjoin := f.Config.Get(\"join\")\r\n\tif join != \"\" {\r\n\t\tcolumn = fmt.Sprintf(\"%s AS %s\", join, column)\r\n\t}\r\n\treturn column\r\n}","code-length":121,"reference":"\/\/ Column returns the name of the database column the field maps to. The type\n\/\/ code of the field must be TypeColumn.","result":"Generate the generated code.","score":[0.0028,0.0237]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *Field) ZeroValue() string {\r\n\tif f.Type.Code != TypeColumn {\r\n\t\tpanic(\"attempt to get zero value of non-column field\")\r\n\t}\r\n\tswitch f.Type.Name {\r\n\tcase \"string\":\r\n\t\treturn `\"\"`\r\n\tcase \"int\":\r\n\t\t\r\n\t\t\r\n\t\treturn \"-1\"\r\n\tdefault:\r\n\t\tpanic(\"unsupported zero value\")\r\n\t}\r\n}","code-length":124,"reference":"\/\/ ZeroValue returns the literal representing the zero value for this field. The type\n\/\/ code of the field must be TypeColumn.","result":"Generate the zero value of a field.","score":[0.0443,0.1815]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FieldColumns(fields []*Field) string {\r\n\tcolumns := make([]string, len(fields))\r\n\tfor i, field := range fields {\r\n\t\tcolumns[i] = field.Column()\r\n\t}\r\n\treturn strings.Join(columns, \", \")\r\n}","code-length":77,"reference":"\/\/ FieldColumns converts thegiven fields to list of column names separated\n\/\/ by a comma.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FieldArgs(fields []*Field) string {\r\n\targs := make([]string, len(fields))\r\n\tfor i, field := range fields {\r\n\t\targs[i] = fmt.Sprintf(\"%s %s\", lex.Minuscule(field.Name), field.Type.Name)\r\n\t}\r\n\treturn strings.Join(args, \", \")\r\n}","code-length":98,"reference":"\/\/ FieldArgs converts the given fields to function arguments, rendering their\n\/\/ name and type.","result":"Generate the field args.","score":[0.0204,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FieldParams(fields []*Field) string {\r\n\targs := make([]string, len(fields))\r\n\tfor i, field := range fields {\r\n\t\targs[i] = lex.Minuscule(field.Name)\r\n\t}\r\n\treturn strings.Join(args, \", \")\r\n}","code-length":83,"reference":"\/\/ FieldParams converts the given fields to function parameters, rendering their\n\/\/ name.","result":"Generate the field params.","score":[0.0337,0.0826]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FieldCriteria(fields []*Field) string {\r\n\tcriteria := make([]string, len(fields))\r\n\tfor i, field := range fields {\r\n\t\tcriteria[i] = fmt.Sprintf(\"%s = ?\", field.Column())\r\n\t}\r\n\treturn strings.Join(criteria, \" AND \")\r\n}","code-length":87,"reference":"\/\/ FieldCriteria converts the given fields to AND-separated WHERE criteria.","result":"Build the field criteria.","score":[0.0848,0.1596]}
{"code":"\/*is used to<extra_id_0>\r\nfunc initDataClusterApply(d lxd.ContainerServer, config *initDataCluster) error {\r\n\tif config == nil || !config.Enabled {\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\tcurrentCluster, etag, err := d.GetCluster()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Failed to retrieve current cluster config\")\r\n\t}\r\n\t\r\n\tif !currentCluster.Enabled {\r\n\t\t\r\n\t\top, err := d.UpdateCluster(config.ClusterPut, etag)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Failed to configure cluster\")\r\n\t\t}\r\n\t\terr = op.Wait()\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Failed to configure cluster\")\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":222,"reference":"\/\/ Helper to initialize LXD clustering.\n\/\/\n\/\/ Used by the 'lxd init' command.","result":"Apply the cluster configuration.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc JsonFormatEx(pretty, lineSeparated bool) Format {\r\n\tjsonMarshal := json.Marshal\r\n\tif pretty {\r\n\t\tjsonMarshal = func(v interface{}) ([]byte, error) {\r\n\t\t\treturn json.MarshalIndent(v, \"\", \"    \")\r\n\t\t}\r\n\t}\r\n\treturn FormatFunc(func(r *Record) []byte {\r\n\t\tprops := make(map[string]interface{})\r\n\t\tprops[r.KeyNames.Time] = r.Time\r\n\t\tprops[r.KeyNames.Lvl] = r.Lvl\r\n\t\tprops[r.KeyNames.Msg] = r.Msg\r\n\t\tfor i := 0; i < len(r.Ctx); i += 2 {\r\n\t\t\tk, ok := r.Ctx[i].(string)\r\n\t\t\tif !ok {\r\n\t\t\t\tprops[errorKey] = fmt.Sprintf(\"%+v is not a string key\", r.Ctx[i])\r\n\t\t\t}\r\n\t\t\tprops[k] = formatJsonValue(r.Ctx[i+1])\r\n\t\t}\r\n\t\tb, err := jsonMarshal(props)\r\n\t\tif err != nil {\r\n\t\t\tb, _ = jsonMarshal(map[string]string{\r\n\t\t\t\terrorKey: err.Error(),\r\n\t\t\t})\r\n\t\t\treturn b\r\n\t\t}\r\n\t\tif lineSeparated {\r\n\t\t\tb = append(b, '\\n')\r\n\t\t}\r\n\t\treturn b\r\n\t})\r\n}","code-length":375,"reference":"\/\/ JsonFormatEx formats log records as JSON objects. If pretty is true,\n\/\/ records will be pretty-printed. If lineSeparated is true, records\n\/\/ will be logged with a new line between each record.","result":"Format json .","score":[0,0.0333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc formatLogfmtValue(value interface{}) string {\r\n\tif value == nil {\r\n\t\treturn \"nil\"\r\n\t}\r\n\tvalue = formatShared(value)\r\n\tswitch v := value.(type) {\r\n\tcase bool:\r\n\t\treturn strconv.FormatBool(v)\r\n\tcase float32:\r\n\t\treturn strconv.FormatFloat(float64(v), floatFormat, 3, 64)\r\n\tcase float64:\r\n\t\treturn strconv.FormatFloat(v, floatFormat, 3, 64)\r\n\tcase int, int8, int16, int32, int64, uint, uint8, uint16, uint32, uint64:\r\n\t\treturn fmt.Sprintf(\"%d\", value)\r\n\tcase string:\r\n\t\treturn escapeString(v)\r\n\tdefault:\r\n\t\treturn escapeString(fmt.Sprintf(\"%+v\", value))\r\n\t}\r\n}","code-length":226,"reference":"\/\/ formatValue formats a value for serialization","result":"Format logfmt values.","score":[0,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ResolveTarget(cluster *db.Cluster, target string) (string, error) {\r\n\taddress := \"\"\r\n\terr := cluster.Transaction(func(tx *db.ClusterTx) error {\r\n\t\tname, err := tx.NodeName()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif target == name {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tnode, err := tx.NodeByName(target)\r\n\t\tif err != nil {\r\n\t\t\tif err == db.ErrNoSuchObject {\r\n\t\t\t\treturn fmt.Errorf(\"No cluster member called '%s'\", target)\r\n\t\t\t}\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif node.Name != name {\r\n\t\t\taddress = node.Address\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\treturn address, err\r\n}","code-length":223,"reference":"\/\/ ResolveTarget is a convenience for handling the value ?targetNode query\n\/\/ parameter. It returns the address of the given node, or the empty string if\n\/\/ the given node is the local one.","result":"Resolve a target in a cluster.","score":[0.0018,0.016]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pt *ProgressWriter) Write(p []byte) (int, error) {\r\n\t\r\n\tn, err := pt.WriteCloser.Write(p)\r\n\t\r\n\tif pt.Tracker != nil {\r\n\t\tpt.Tracker.total += int64(n)\r\n\t\tpt.Tracker.update(n)\r\n\t}\r\n\treturn n, err\r\n}","code-length":101,"reference":"\/\/ Write in ProgressWriter is the same as io.Write","result":"Write to the progress writer.","score":[0.1284,0.1163]}
{"code":"\/*is used to<extra_id_0>\r\nfunc updateNodeVersion(tx *sql.Tx, address string, apiExtensions int) error {\r\n\tstmt := \"UPDATE nodes SET schema=?, api_extensions=? WHERE address=?\"\r\n\tresult, err := tx.Exec(stmt, len(updates), apiExtensions, address)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tn, err := result.RowsAffected()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif n != 1 {\r\n\t\treturn fmt.Errorf(\"updated %d rows instead of 1\", n)\r\n\t}\r\n\treturn nil\r\n}","code-length":157,"reference":"\/\/ Update the schema and api_extensions columns of the row in the nodes table\n\/\/ that matches the given id.\n\/\/\n\/\/ If not such row is found, an error is returned.","result":"Update node version.","score":[0.0,0.0344]}
{"code":"\/*is used to<extra_id_0>\r\nfunc selectNodesVersions(tx *sql.Tx) ([][2]int, error) {\r\n\tversions := [][2]int{}\r\n\tdest := func(i int) []interface{} {\r\n\t\tversions = append(versions, [2]int{})\r\n\t\treturn []interface{}{&versions[i][0], &versions[i][1]}\r\n\t}\r\n\tstmt, err := tx.Prepare(\"SELECT schema, api_extensions FROM nodes\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer stmt.Close()\r\n\terr = query.SelectObjects(stmt, dest)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn versions, nil\r\n}","code-length":189,"reference":"\/\/ Return a slice of binary integer tuples. Each tuple contains the schema\n\/\/ version and number of api extensions of a node in the cluster.","result":"Select nodes versions from the database.","score":[0.0069,0.0625]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetArchitectures() ([]int, error) {\r\n\tarchitectures := []int{}\r\n\tarchitectureName, err := osarch.ArchitectureGetLocal()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tarchitecture, err := osarch.ArchitectureId(architectureName)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tarchitectures = append(architectures, architecture)\r\n\tpersonalities, err := osarch.ArchitecturePersonalities(architecture)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tfor _, personality := range personalities {\r\n\t\tarchitectures = append(architectures, personality)\r\n\t}\r\n\treturn architectures, nil\r\n}","code-length":209,"reference":"\/\/ GetArchitectures returns the list of supported architectures.","result":"Get the current architectures.","score":[0.1398,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RuntimeLiblxcVersionAtLeast(major int, minor int, micro int) bool {\r\n\tversion := golxc.Version()\r\n\tversion = strings.Replace(version, \" (devel)\", \"-devel\", 1)\r\n\tparts := strings.Split(version, \".\")\r\n\tpartsLen := len(parts)\r\n\tif partsLen == 0 {\r\n\t\treturn false\r\n\t}\r\n\tdevelParts := strings.Split(parts[partsLen-1], \"-\")\r\n\tif len(develParts) == 2 && develParts[1] == \"devel\" {\r\n\t\treturn true\r\n\t}\r\n\tmaj := -1\r\n\tmin := -1\r\n\tmic := -1\r\n\tfor i, v := range parts {\r\n\t\tif i > 2 {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tnum, err := strconv.Atoi(v)\r\n\t\tif err != nil {\r\n\t\t\treturn false\r\n\t\t}\r\n\t\tswitch i {\r\n\t\tcase 0:\r\n\t\t\tmaj = num\r\n\t\tcase 1:\r\n\t\t\tmin = num\r\n\t\tcase 2:\r\n\t\t\tmic = num\r\n\t\t}\r\n\t}\r\n\t\r\n\tif maj > major {\r\n\t\treturn true\r\n\t}\r\n\tif maj < major {\r\n\t\treturn false\r\n\t}\r\n\t\r\n\tif min > minor {\r\n\t\treturn true\r\n\t}\r\n\tif min < minor {\r\n\t\treturn false\r\n\t}\r\n\t\r\n\tif mic > micro {\r\n\t\treturn true\r\n\t}\r\n\tif mic < micro {\r\n\t\treturn false\r\n\t}\r\n\treturn true\r\n}","code-length":430,"reference":"\/\/ RuntimeLiblxcVersionAtLeast checks if the system's liblxc matches the\n\/\/ provided version requirement","result":"Check the version of the runtime library.","score":[0.0902,0.1613]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetExecPath() string {\r\n\texecPath := os.Getenv(\"LXD_EXEC_PATH\")\r\n\tif execPath != \"\" {\r\n\t\treturn execPath\r\n\t}\r\n\texecPath, err := os.Readlink(\"\/proc\/self\/exe\")\r\n\tif err != nil {\r\n\t\texecPath = \"bad-exec-path\"\r\n\t}\r\n\treturn execPath\r\n}","code-length":109,"reference":"\/\/ GetExecPath returns the path to the current binary","result":"Get the exec path from the LXD instance.","score":[0.1613,0.1685]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Connect(address string, cert *shared.CertInfo, notify bool) (lxd.ContainerServer, error) {\r\n\targs := &lxd.ConnectionArgs{\r\n\t\tTLSServerCert: string(cert.PublicKey()),\r\n\t\tTLSClientCert: string(cert.PublicKey()),\r\n\t\tTLSClientKey:  string(cert.PrivateKey()),\r\n\t\tSkipGetServer: true,\r\n\t}\r\n\tif notify {\r\n\t\targs.UserAgent = \"lxd-cluster-notifier\"\r\n\t}\r\n\turl := fmt.Sprintf(\"https:\r\n\treturn lxd.ConnectLXD(url, args)\r\n}","code-length":164,"reference":"\/\/ Connect is a convenience around lxd.ConnectLXD that configures the client\n\/\/ with the correct parameters for node-to-node communication.\n\/\/\n\/\/ If 'notify' switch is true, then the user agent will be set to the special\n\/\/ value 'lxd-cluster-notifier', which can be used in some cases to distinguish\n\/\/ between a regular client request and an internal cluster request.","result":"Connect to the LXD server.","score":[0.0,0.028]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ConnectIfContainerIsRemote(cluster *db.Cluster, project, name string, cert *shared.CertInfo) (lxd.ContainerServer, error) {\r\n\tvar address string\r\n\terr := cluster.Transaction(func(tx *db.ClusterTx) error {\r\n\t\tvar err error\r\n\t\taddress, err = tx.ContainerNodeAddress(project, name)\r\n\t\treturn err\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif address == \"\" {\r\n\t\t\r\n\t\treturn nil, nil\r\n\t}\r\n\treturn Connect(address, cert, false)\r\n}","code-length":163,"reference":"\/\/ ConnectIfContainerIsRemote figures out the address of the node which is\n\/\/ running the container with the given name. If it's not the local node will\n\/\/ connect to it and return the connected client, otherwise it will just return\n\/\/ nil.","result":"Connect if container is remote.","score":[0.0002,0.0522]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ConnectIfVolumeIsRemote(cluster *db.Cluster, poolID int64, volumeName string, volumeType int, cert *shared.CertInfo) (lxd.ContainerServer, error) {\r\n\tvar addresses []string\r\n\terr := cluster.Transaction(func(tx *db.ClusterTx) error {\r\n\t\tvar err error\r\n\t\taddresses, err = tx.StorageVolumeNodeAddresses(poolID, \"default\", volumeName, volumeType)\r\n\t\treturn err\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif len(addresses) > 1 {\r\n\t\tvar driver string\r\n\t\terr := cluster.Transaction(func(tx *db.ClusterTx) error {\r\n\t\t\tvar err error\r\n\t\t\tdriver, err = tx.StoragePoolDriver(poolID)\r\n\t\t\treturn err\r\n\t\t})\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tif driver == \"ceph\" {\r\n\t\t\treturn nil, nil\r\n\t\t}\r\n\t\treturn nil, fmt.Errorf(\"more than one node has a volume named %s\", volumeName)\r\n\t}\r\n\taddress := addresses[0]\r\n\tif address == \"\" {\r\n\t\treturn nil, nil\r\n\t}\r\n\treturn Connect(address, cert, false)\r\n}","code-length":337,"reference":"\/\/ ConnectIfVolumeIsRemote figures out the address of the node on which the\n\/\/ volume with the given name is defined. If it's not the local node will\n\/\/ connect to it and return the connected client, otherwise it will just return\n\/\/ nil.\n\/\/\n\/\/ If there is more than one node with a matching volume name, an error is\n\/\/ returned.","result":"Connect to a remote storage volume.","score":[0.0,0.0453]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetupTrust(cert, targetAddress, targetCert, targetPassword string) error {\r\n\t\r\n\targs := &lxd.ConnectionArgs{\r\n\t\tTLSServerCert: targetCert,\r\n\t}\r\n\ttarget, err := lxd.ConnectLXD(fmt.Sprintf(\"https:\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to connect to target cluster node\")\r\n\t}\r\n\tblock, _ := pem.Decode([]byte(cert))\r\n\tif block == nil {\r\n\t\treturn errors.Wrap(err, \"failed to decode certificate\")\r\n\t}\r\n\tcertificate := base64.StdEncoding.EncodeToString(block.Bytes)\r\n\tpost := api.CertificatesPost{\r\n\t\tPassword:    targetPassword,\r\n\t\tCertificate: certificate,\r\n\t}\r\n\tfingerprint, err := shared.CertFingerprintStr(cert)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to calculate fingerprint\")\r\n\t}\r\n\tpost.Name = fmt.Sprintf(\"lxd.cluster.%s\", fingerprint)\r\n\tpost.Type = \"client\"\r\n\terr = target.CreateCertificate(post)\r\n\tif err != nil && err.Error() != \"Certificate already in trust store\" {\r\n\t\treturn errors.Wrap(err, \"Failed to add client cert to cluster\")\r\n\t}\r\n\treturn nil\r\n}","code-length":345,"reference":"\/\/ SetupTrust is a convenience around ContainerServer.CreateCertificate that\n\/\/ adds the given client certificate to the trusted pool of the cluster at the\n\/\/ given address, using the given password.","result":"Setup trust store.","score":[0,0.0183]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetStoragePools() ([]api.StoragePool, error) {\r\n\tif !r.HasExtension(\"storage\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"storage\\\" API extension\")\r\n\t}\r\n\tpools := []api.StoragePool{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", \"\/storage-pools?recursion=1\", nil, \"\", &pools)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn pools, nil\r\n}","code-length":144,"reference":"\/\/ GetStoragePools returns a list of StoragePool entries","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetStoragePool(name string) (*api.StoragePool, string, error) {\r\n\tif !r.HasExtension(\"storage\") {\r\n\t\treturn nil, \"\", fmt.Errorf(\"The server is missing the required \\\"storage\\\" API extension\")\r\n\t}\r\n\tpool := api.StoragePool{}\r\n\t\r\n\tetag, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/storage-pools\/%s\", url.QueryEscape(name)), nil, \"\", &pool)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\treturn &pool, etag, nil\r\n}","code-length":164,"reference":"\/\/ GetStoragePool returns a StoragePool entry for the provided pool name","result":"Generate the generated code.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) CreateStoragePool(pool api.StoragePoolsPost) error {\r\n\tif !r.HasExtension(\"storage\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"storage\\\" API extension\")\r\n\t}\r\n\tif pool.Driver == \"ceph\" && !r.HasExtension(\"storage_driver_ceph\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"storage_driver_ceph\\\" API extension\")\r\n\t}\r\n\t\r\n\t_, _, err := r.query(\"POST\", \"\/storage-pools\", pool, \"\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":178,"reference":"\/\/ CreateStoragePool defines a new storage pool using the provided StoragePool struct","result":"Generate the generated code.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) UpdateStoragePool(name string, pool api.StoragePoolPut, ETag string) error {\r\n\tif !r.HasExtension(\"storage\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"storage\\\" API extension\")\r\n\t}\r\n\t\r\n\t_, _, err := r.query(\"PUT\", fmt.Sprintf(\"\/storage-pools\/%s\", url.QueryEscape(name)), pool, ETag)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":142,"reference":"\/\/ UpdateStoragePool updates the pool to match the provided StoragePool struct","result":"Update the storage pool.","score":[0.0555,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) DeleteStoragePool(name string) error {\r\n\tif !r.HasExtension(\"storage\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"storage\\\" API extension\")\r\n\t}\r\n\t\r\n\t_, _, err := r.query(\"DELETE\", fmt.Sprintf(\"\/storage-pools\/%s\", url.QueryEscape(name)), nil, \"\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":132,"reference":"\/\/ DeleteStoragePool deletes a storage pool","result":"Delete the storage pool.","score":[0.1938,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetStoragePoolResources(name string) (*api.ResourcesStoragePool, error) {\r\n\tif !r.HasExtension(\"resources\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"resources\\\" API extension\")\r\n\t}\r\n\tres := api.ResourcesStoragePool{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/storage-pools\/%s\/resources\", url.QueryEscape(name)), nil, \"\", &res)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &res, nil\r\n}","code-length":163,"reference":"\/\/ GetStoragePoolResources gets the resources available to a given storage pool","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *OS) initDirs() error {\r\n\tdirs := []struct {\r\n\t\tpath string\r\n\t\tmode os.FileMode\r\n\t}{\r\n\t\t{s.VarDir, 0711},\r\n\t\t{filepath.Join(s.VarDir, \"backups\"), 0700},\r\n\t\t{s.CacheDir, 0700},\r\n\t\t{filepath.Join(s.VarDir, \"containers\"), 0711},\r\n\t\t{filepath.Join(s.VarDir, \"database\"), 0700},\r\n\t\t{filepath.Join(s.VarDir, \"devices\"), 0711},\r\n\t\t{filepath.Join(s.VarDir, \"devlxd\"), 0755},\r\n\t\t{filepath.Join(s.VarDir, \"disks\"), 0700},\r\n\t\t{filepath.Join(s.VarDir, \"images\"), 0700},\r\n\t\t{s.LogDir, 0700},\r\n\t\t{filepath.Join(s.VarDir, \"networks\"), 0711},\r\n\t\t{filepath.Join(s.VarDir, \"security\"), 0700},\r\n\t\t{filepath.Join(s.VarDir, \"shmounts\"), 0711},\r\n\t\t{filepath.Join(s.VarDir, \"snapshots\"), 0700},\r\n\t\t{filepath.Join(s.VarDir, \"storage-pools\"), 0711},\r\n\t}\r\n\tfor _, dir := range dirs {\r\n\t\terr := os.Mkdir(dir.path, dir.mode)\r\n\t\tif err != nil && !os.IsExist(err) {\r\n\t\t\treturn errors.Wrapf(err, \"failed to init dir %s\", dir.path)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":436,"reference":"\/\/ Make sure all our directories are available.","result":"Initialize the directories.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NodeTx) Config() (map[string]string, error) {\r\n\treturn query.SelectConfig(n.tx, \"config\", \"\")\r\n}","code-length":49,"reference":"\/\/ Config fetches all LXD node-level config keys.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NodeTx) UpdateConfig(values map[string]string) error {\r\n\treturn query.UpdateConfig(n.tx, \"config\", values)\r\n}","code-length":49,"reference":"\/\/ UpdateConfig updates the given LXD node-level configuration keys in the\n\/\/ config table. Config keys set to empty values will be deleted.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) Config() (map[string]string, error) {\r\n\treturn query.SelectConfig(c.tx, \"config\", \"\")\r\n}","code-length":49,"reference":"\/\/ Config fetches all LXD cluster config keys.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) UpdateConfig(values map[string]string) error {\r\n\treturn query.UpdateConfig(c.tx, \"config\", values)\r\n}","code-length":49,"reference":"\/\/ UpdateConfig updates the given LXD cluster configuration keys in the\n\/\/ config table. Config keys set to empty values will be deleted.","result":"Generate the generated code.","score":[0.0028,0.0237]}
{"code":"\/*is used to<extra_id_0>\r\nfunc storagePoolClusterConfigForEtag(dbConfig map[string]string) map[string]string {\r\n\tconfig := util.CopyConfig(dbConfig)\r\n\tfor _, key := range db.StoragePoolNodeConfigKeys {\r\n\t\tdelete(config, key)\r\n\t}\r\n\treturn config\r\n}","code-length":84,"reference":"\/\/ This helper deletes any node-specific values from the config object, since\n\/\/ they should not be part of the calculated etag.","result":"Generate the config file.","score":[0.005,0.0495]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetEvents() (*EventListener, error) {\r\n\t\r\n\tr.eventListenersLock.Lock()\r\n\tdefer r.eventListenersLock.Unlock()\r\n\t\r\n\tlistener := EventListener{\r\n\t\tr:        r,\r\n\t\tchActive: make(chan bool),\r\n\t}\r\n\tif r.eventListeners != nil {\r\n\t\t\r\n\t\tr.eventListeners = append(r.eventListeners, &listener)\r\n\t\treturn &listener, nil\r\n\t}\r\n\t\r\n\tr.eventListeners = []*EventListener{}\r\n\t\r\n\turl, err := r.setQueryAttributes(\"\/events\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tconn, err := r.websocket(url)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tr.eventListeners = append(r.eventListeners, &listener)\r\n\t\r\n\t\r\n\tstopCh := make(chan struct{}, 0)\r\n\tgo func() {\r\n\t\tfor {\r\n\t\t\tselect {\r\n\t\t\tcase <-time.After(time.Minute):\r\n\t\t\tcase <-stopCh:\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\tr.eventListenersLock.Lock()\r\n\t\t\tif len(r.eventListeners) == 0 {\r\n\t\t\t\t\r\n\t\t\t\tconn.Close()\r\n\t\t\t\tr.eventListeners = nil\r\n\t\t\t\tr.eventListenersLock.Unlock()\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\tr.eventListenersLock.Unlock()\r\n\t\t}\r\n\t}()\r\n\t\r\n\tgo func() {\r\n\t\tfor {\r\n\t\t\t_, data, err := conn.ReadMessage()\r\n\t\t\tif err != nil {\r\n\t\t\t\t\r\n\t\t\t\tr.eventListenersLock.Lock()\r\n\t\t\t\tdefer r.eventListenersLock.Unlock()\r\n\t\t\t\t\r\n\t\t\t\tfor _, listener := range r.eventListeners {\r\n\t\t\t\t\tlistener.err = err\r\n\t\t\t\t\tlistener.disconnected = true\r\n\t\t\t\t\tclose(listener.chActive)\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\tr.eventListeners = nil\r\n\t\t\t\tconn.Close()\r\n\t\t\t\tclose(stopCh)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tevent := api.Event{}\r\n\t\t\terr = json.Unmarshal(data, &event)\r\n\t\t\tif err != nil {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif event.Type == \"\" {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tr.eventListenersLock.Lock()\r\n\t\t\tfor _, listener := range r.eventListeners {\r\n\t\t\t\tlistener.targetsLock.Lock()\r\n\t\t\t\tfor _, target := range listener.targets {\r\n\t\t\t\t\tif target.types != nil && !shared.StringInSlice(event.Type, target.types) {\r\n\t\t\t\t\t\tcontinue\r\n\t\t\t\t\t}\r\n\t\t\t\t\tgo target.function(event)\r\n\t\t\t\t}\r\n\t\t\t\tlistener.targetsLock.Unlock()\r\n\t\t\t}\r\n\t\t\tr.eventListenersLock.Unlock()\r\n\t\t}\r\n\t}()\r\n\treturn &listener, nil\r\n}","code-length":795,"reference":"\/\/ Event handling functions\n\/\/ GetEvents connects to the LXD monitoring interface","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LogfmtFormat() log.Format {\r\n\treturn log.FormatFunc(func(r *log.Record) []byte {\r\n\t\tcommon := []interface{}{r.KeyNames.Time, r.Time, r.KeyNames.Lvl, r.Lvl, r.KeyNames.Msg, r.Msg}\r\n\t\tbuf := &bytes.Buffer{}\r\n\t\tlogfmt(buf, common, 0, false)\r\n\t\tbuf.Truncate(buf.Len() - 1)\r\n\t\tbuf.WriteByte(' ')\r\n\t\tlogfmt(buf, r.Ctx, 0, true)\r\n\t\treturn buf.Bytes()\r\n\t})\r\n}","code-length":165,"reference":"\/\/ LogfmtFormat return a formatter for a text log file","result":"Format log messages.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) StorageVolumeNodeAddresses(poolID int64, project, name string, typ int) ([]string, error) {\r\n\tnodes := []struct {\r\n\t\tid      int64\r\n\t\taddress string\r\n\t}{}\r\n\tdest := func(i int) []interface{} {\r\n\t\tnodes = append(nodes, struct {\r\n\t\t\tid      int64\r\n\t\t\taddress string\r\n\t\t}{})\r\n\t\treturn []interface{}{&nodes[i].id, &nodes[i].address}\r\n\t}\r\n\tsql := `\r\nSELECT nodes.id, nodes.address\r\n  FROM nodes\r\n  JOIN storage_volumes ON storage_volumes.node_id=nodes.id\r\n  JOIN projects ON projects.id = storage_volumes.project_id\r\n WHERE storage_volumes.storage_pool_id=? AND projects.name=? AND storage_volumes.name=? AND storage_volumes.type=?\r\n`\r\n\tstmt, err := c.tx.Prepare(sql)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer stmt.Close()\r\n\terr = query.SelectObjects(stmt, dest, poolID, project, name, typ)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\taddresses := []string{}\r\n\tfor _, node := range nodes {\r\n\t\taddress := node.address\r\n\t\tif node.id == c.nodeID {\r\n\t\t\taddress = \"\"\r\n\t\t}\r\n\t\taddresses = append(addresses, address)\r\n\t}\r\n\tsort.Strings(addresses)\r\n\tif len(addresses) == 0 {\r\n\t\treturn nil, ErrNoSuchObject\r\n\t}\r\n\treturn addresses, nil\r\n}","code-length":434,"reference":"\/\/ StorageVolumeNodeAddresses returns the addresses of all nodes on which the\n\/\/ volume with the given name if defined.\n\/\/\n\/\/ The empty string is used in place of the address of the current node.","result":"Generate the code.","score":[0.0,0.0157]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StorageVolumeNodeGet(volumeID int64) (string, error) {\r\n\tname := \"\"\r\n\tquery := `\r\nSELECT nodes.name FROM storage_volumes\r\n  JOIN nodes ON nodes.id=storage_volumes.node_id\r\n   WHERE storage_volumes.id=?\r\n`\r\n\tinargs := []interface{}{volumeID}\r\n\toutargs := []interface{}{&name}\r\n\terr := dbQueryRowScan(c.db, query, inargs, outargs)\r\n\tif err != nil {\r\n\t\tif err == sql.ErrNoRows {\r\n\t\t\treturn \"\", ErrNoSuchObject\r\n\t\t}\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn name, nil\r\n}","code-length":187,"reference":"\/\/ StorageVolumeNodeGet returns the name of the node a storage volume is on.","result":"Get the node name of a storage volume.","score":[0.1645,0.45]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StorageVolumeConfigGet(volumeID int64) (map[string]string, error) {\r\n\tvar key, value string\r\n\tquery := \"SELECT key, value FROM storage_volumes_config WHERE storage_volume_id=?\"\r\n\tinargs := []interface{}{volumeID}\r\n\toutargs := []interface{}{key, value}\r\n\tresults, err := queryScan(c.db, query, inargs, outargs)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tconfig := map[string]string{}\r\n\tfor _, r := range results {\r\n\t\tkey = r[0].(string)\r\n\t\tvalue = r[1].(string)\r\n\t\tconfig[key] = value\r\n\t}\r\n\treturn config, nil\r\n}","code-length":207,"reference":"\/\/ StorageVolumeConfigGet gets the config of a storage volume.","result":"Get the storage volume config from the storage.","score":[0.1613,0.2247]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StorageVolumeDescriptionGet(volumeID int64) (string, error) {\r\n\tdescription := sql.NullString{}\r\n\tquery := \"SELECT description FROM storage_volumes WHERE id=?\"\r\n\tinargs := []interface{}{volumeID}\r\n\toutargs := []interface{}{&description}\r\n\terr := dbQueryRowScan(c.db, query, inargs, outargs)\r\n\tif err != nil {\r\n\t\tif err == sql.ErrNoRows {\r\n\t\t\treturn \"\", ErrNoSuchObject\r\n\t\t}\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn description.String, nil\r\n}","code-length":162,"reference":"\/\/ StorageVolumeDescriptionGet gets the description of a storage volume.","result":"Get the description of a storage volume.","score":[0.6287,0.7943]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StorageVolumeIsAvailable(pool, volume string) (bool, error) {\r\n\tisAvailable := false\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tid, err := tx.StoragePoolID(pool)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"Fetch storage pool ID for %q\", pool)\r\n\t\t}\r\n\t\tdriver, err := tx.StoragePoolDriver(id)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"Fetch storage pool driver for %q\", pool)\r\n\t\t}\r\n\t\tif driver != \"ceph\" {\r\n\t\t\tisAvailable = true\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tnode, err := tx.NodeName()\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"Fetch node name\")\r\n\t\t}\r\n\t\tcontainers, err := tx.ContainerListExpanded()\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"Fetch containers\")\r\n\t\t}\r\n\t\tfor _, container := range containers {\r\n\t\t\tfor _, device := range container.Devices {\r\n\t\t\t\tif device[\"type\"] != \"disk\" {\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\tif device[\"pool\"] != pool {\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\tif device[\"source\"] != volume {\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\tif container.Node != node {\r\n\t\t\t\t\t\r\n\t\t\t\t\t\r\n\t\t\t\t\treturn nil\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\tisAvailable = true\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\treturn isAvailable, nil\r\n}","code-length":460,"reference":"\/\/ StorageVolumeIsAvailable checks that if a custom volume available for being attached.\n\/\/\n\/\/ Always return true for non-Ceph volumes.\n\/\/\n\/\/ For Ceph volumes, return true if the volume is either not attached to any\n\/\/ other container, or attached to containers on this node.","result":"Check if a storage volume is available on a node.","score":[0.0063,0.1255]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StorageVolumeDescriptionUpdate(tx *sql.Tx, volumeID int64, description string) error {\r\n\t_, err := tx.Exec(\"UPDATE storage_volumes SET description=? WHERE id=?\", description, volumeID)\r\n\treturn err\r\n}","code-length":64,"reference":"\/\/ StorageVolumeDescriptionUpdate updates the description of a storage volume.","result":"Update storage volume description.","score":[0.0915,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StorageVolumeConfigAdd(tx *sql.Tx, volumeID int64, volumeConfig map[string]string) error {\r\n\tstr := \"INSERT INTO storage_volumes_config (storage_volume_id, key, value) VALUES(?, ?, ?)\"\r\n\tstmt, err := tx.Prepare(str)\r\n\tdefer stmt.Close()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfor k, v := range volumeConfig {\r\n\t\tif v == \"\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t_, err = stmt.Exec(volumeID, k, v)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":186,"reference":"\/\/ StorageVolumeConfigAdd adds a new storage volume config into database.","result":"Create a new storage volume config.","score":[0.3102,0.4134]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StorageVolumeConfigClear(tx *sql.Tx, volumeID int64) error {\r\n\t_, err := tx.Exec(\"DELETE FROM storage_volumes_config WHERE storage_volume_id=?\", volumeID)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":81,"reference":"\/\/ StorageVolumeConfigClear deletes storage volume config.","result":"Clear the storage volume config.","score":[0.4052,0.4991]}
{"code":"\/*is used to<extra_id_0>\r\nfunc storageVolumeIDsGet(tx *sql.Tx, project, volumeName string, volumeType int, poolID int64) ([]int64, error) {\r\n\tids, err := query.SelectIntegers(tx, `\r\nSELECT storage_volumes.id\r\n  FROM storage_volumes\r\n  JOIN projects ON projects.id = storage_volumes.project_id\r\n WHERE projects.name=? AND storage_volumes.name=? AND storage_volumes.type=? AND storage_pool_id=?\r\n`, project, volumeName, volumeType, poolID)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tids64 := make([]int64, len(ids))\r\n\tfor i, id := range ids {\r\n\t\tids64[i] = int64(id)\r\n\t}\r\n\treturn ids64, nil\r\n}","code-length":212,"reference":"\/\/ Get the IDs of all volumes with the given name and type associated with the\n\/\/ given pool, regardless of their node_id column.","result":"Generate the generated code.","score":[0.0022,0.0227]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StorageVolumeCleanupImages(fingerprints []string) error {\r\n\tstmt := fmt.Sprintf(\r\n\t\t\"DELETE FROM storage_volumes WHERE type=? AND name NOT IN %s\",\r\n\t\tquery.Params(len(fingerprints)))\r\n\targs := []interface{}{StoragePoolVolumeTypeImage}\r\n\tfor _, fingerprint := range fingerprints {\r\n\t\targs = append(args, fingerprint)\r\n\t}\r\n\terr := exec(c.db, stmt, args...)\r\n\treturn err\r\n}","code-length":136,"reference":"\/\/ StorageVolumeCleanupImages removes the volumes with the given fingerprints.","result":"Cleanup storage volumes.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) StorageVolumeMoveToLVMThinPoolNameKey() error {\r\n\terr := exec(c.db, \"UPDATE storage_pools_config SET key='lvm.thinpool_name' WHERE key='volume.lvm.thinpool_name';\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = exec(c.db, \"DELETE FROM storage_volumes_config WHERE key='lvm.thinpool_name';\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":152,"reference":"\/\/ StorageVolumeMoveToLVMThinPoolNameKey upgrades the config keys of LVM\n\/\/ volumes.","result":"Create storage volume.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Buffer) L(format string, a ...interface{}) {\r\n\tfmt.Fprintf(b.buf, format, a...)\r\n\tb.N()\r\n}","code-length":52,"reference":"\/\/ L accumulates a single line of source code.","result":"Print the line.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Buffer) code() ([]byte, error) {\r\n\tcode, err := format.Source(b.buf.Bytes())\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Can't format generated source code\")\r\n\t}\r\n\treturn code, nil\r\n}","code-length":84,"reference":"\/\/ Returns the source code to add to the target file.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Pretty(input interface{}) string {\r\n\tpretty, err := json.MarshalIndent(input, \"\\t\", \"\\t\")\r\n\tif err != nil {\r\n\t\treturn fmt.Sprintf(\"%v\", input)\r\n\t}\r\n\treturn fmt.Sprintf(\"\\n\\t%s\", pretty)\r\n}","code-length":84,"reference":"\/\/ Pretty will attempt to convert any Go structure into a string suitable for logging","result":"Print the input to json.","score":[0.0325,0.0357]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Endpoints) NetworkPublicKey() []byte {\r\n\te.mu.RLock()\r\n\tdefer e.mu.RUnlock()\r\n\treturn e.cert.PublicKey()\r\n}","code-length":55,"reference":"\/\/ NetworkPublicKey returns the public key of the TLS certificate used by the\n\/\/ network endpoint.","result":"Generate the public key for the endpoints.","score":[0.0988,0.209]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Endpoints) NetworkPrivateKey() []byte {\r\n\te.mu.RLock()\r\n\tdefer e.mu.RUnlock()\r\n\treturn e.cert.PrivateKey()\r\n}","code-length":55,"reference":"\/\/ NetworkPrivateKey returns the private key of the TLS certificate used by the\n\/\/ network endpoint.","result":"Generate the network private key.","score":[0.035,0.1007]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Endpoints) NetworkCert() *shared.CertInfo {\r\n\te.mu.RLock()\r\n\tdefer e.mu.RUnlock()\r\n\treturn e.cert\r\n}","code-length":55,"reference":"\/\/ NetworkCert returns the full TLS certificate information for this endpoint.","result":"Generate the network certificate.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Endpoints) NetworkAddress() string {\r\n\te.mu.RLock()\r\n\tdefer e.mu.RUnlock()\r\n\tlistener := e.listeners[network]\r\n\tif listener == nil {\r\n\t\treturn \"\"\r\n\t}\r\n\treturn listener.Addr().String()\r\n}","code-length":83,"reference":"\/\/ NetworkAddress returns the network addresss of the network endpoint, or an\n\/\/ empty string if there's no network endpoint","result":"Get the network address of the endpoints.","score":[0.0469,0.1688]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Endpoints) NetworkUpdateAddress(address string) error {\r\n\tif address != \"\" {\r\n\t\taddress = util.CanonicalNetworkAddress(address)\r\n\t}\r\n\toldAddress := e.NetworkAddress()\r\n\tif address == oldAddress {\r\n\t\treturn nil\r\n\t}\r\n\tclusterAddress := e.ClusterAddress()\r\n\tlogger.Infof(\"Update network address\")\r\n\te.mu.Lock()\r\n\tdefer e.mu.Unlock()\r\n\t\r\n\te.closeListener(network)\r\n\t\r\n\tif address == \"\" {\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\t\r\n\tif clusterAddress != \"\" && util.IsAddressCovered(clusterAddress, address) {\r\n\t\te.closeListener(cluster)\r\n\t}\r\n\t\r\n\tgetListener := func(address string) (*net.Listener, error) {\r\n\t\tvar err error\r\n\t\tvar listener net.Listener\r\n\t\tfor i := 0; i < 10; i++ {\r\n\t\t\tlistener, err = net.Listen(\"tcp\", address)\r\n\t\t\tif err == nil {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\ttime.Sleep(100 * time.Millisecond)\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"cannot listen on https socket: %v\", err)\r\n\t\t}\r\n\t\treturn &listener, nil\r\n\t}\r\n\t\r\n\tif address != \"\" {\r\n\t\tlistener, err := getListener(address)\r\n\t\tif err != nil {\r\n\t\t\t\r\n\t\t\tlistener, err1 := getListener(oldAddress)\r\n\t\t\tif err1 == nil {\r\n\t\t\t\te.listeners[network] = networkTLSListener(*listener, e.cert)\r\n\t\t\t\te.serveHTTP(network)\r\n\t\t\t}\r\n\t\t\treturn err\r\n\t\t}\r\n\t\te.listeners[network] = networkTLSListener(*listener, e.cert)\r\n\t\te.serveHTTP(network)\r\n\t}\r\n\treturn nil\r\n}","code-length":510,"reference":"\/\/ NetworkUpdateAddress updates the address for the network endpoint, shutting\n\/\/ it down and restarting it.","result":"Update the network address.","score":[0.0225,0.1727]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Endpoints) NetworkUpdateCert(cert *shared.CertInfo) {\r\n\te.mu.Lock()\r\n\tdefer e.mu.Unlock()\r\n\te.cert = cert\r\n\tlistener, ok := e.listeners[network]\r\n\tif !ok {\r\n\t\treturn\r\n\t}\r\n\tlistener.(*networkListener).Config(cert)\r\n\t\r\n\tlistener, ok = e.listeners[cluster]\r\n\tif !ok {\r\n\t\treturn\r\n\t}\r\n\tlistener.(*networkListener).Config(cert)\r\n}","code-length":144,"reference":"\/\/ NetworkUpdateCert updates the TLS keypair and CA used by the network\n\/\/ endpoint.\n\/\/\n\/\/ If the network endpoint is active, in-flight requests will continue using\n\/\/ the old certificate, and only new requests will use the new one.","result":"Update the network certificate.","score":[0.0001,0.0412]}
{"code":"\/*is used to<extra_id_0>\r\nfunc networkCreateListener(address string, cert *shared.CertInfo) net.Listener {\r\n\tlistener, err := net.Listen(\"tcp\", util.CanonicalNetworkAddress(address))\r\n\tif err != nil {\r\n\t\tlogger.Error(\"Cannot listen on https socket, skipping...\", log.Ctx{\"err\": err})\r\n\t\treturn nil\r\n\t}\r\n\treturn networkTLSListener(listener, cert)\r\n}","code-length":107,"reference":"\/\/ Create a new net.Listener bound to the tcp socket of the network endpoint.","result":"Create a listener for the network.","score":[0.0796,0.1936]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *networkListener) Accept() (net.Conn, error) {\r\n\tc, err := l.Listener.Accept()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tl.mu.RLock()\r\n\tdefer l.mu.RUnlock()\r\n\tconfig := l.config\r\n\treturn tls.Server(c, config), nil\r\n}","code-length":104,"reference":"\/\/ Accept waits for and returns the next incoming TLS connection then use the\n\/\/ current TLS configuration to handle it.","result":"Accept connections from the network.","score":[0.0116,0.0773]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *networkListener) Config(cert *shared.CertInfo) {\r\n\tconfig := util.ServerTLSConfig(cert)\r\n\tl.mu.Lock()\r\n\tdefer l.mu.Unlock()\r\n\tl.config = config\r\n}","code-length":69,"reference":"\/\/ Config safely swaps the underlying TLS configuration.","result":"Configure the listener.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n NodeInfo) IsOffline(threshold time.Duration) bool {\r\n\treturn nodeIsOffline(threshold, n.Heartbeat)\r\n}","code-length":41,"reference":"\/\/ IsOffline returns true if the last successful heartbeat time of the node is\n\/\/ older than the given threshold.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NodeByAddress(address string) (NodeInfo, error) {\r\n\tnull := NodeInfo{}\r\n\tnodes, err := c.nodes(false , \"address=?\", address)\r\n\tif err != nil {\r\n\t\treturn null, err\r\n\t}\r\n\tswitch len(nodes) {\r\n\tcase 0:\r\n\t\treturn null, ErrNoSuchObject\r\n\tcase 1:\r\n\t\treturn nodes[0], nil\r\n\tdefault:\r\n\t\treturn null, fmt.Errorf(\"more than one node matches\")\r\n\t}\r\n}","code-length":145,"reference":"\/\/ NodeByAddress returns the node with the given network address.","result":"Query the cluster tx.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NodePendingByAddress(address string) (NodeInfo, error) {\r\n\tnull := NodeInfo{}\r\n\tnodes, err := c.nodes(true , \"address=?\", address)\r\n\tif err != nil {\r\n\t\treturn null, err\r\n\t}\r\n\tswitch len(nodes) {\r\n\tcase 0:\r\n\t\treturn null, ErrNoSuchObject\r\n\tcase 1:\r\n\t\treturn nodes[0], nil\r\n\tdefault:\r\n\t\treturn null, fmt.Errorf(\"more than one node matches\")\r\n\t}\r\n}","code-length":146,"reference":"\/\/ NodePendingByAddress returns the pending node with the given network address.","result":"Check if the node is already in the tx.","score":[0.1284,0.1389]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NodeByName(name string) (NodeInfo, error) {\r\n\tnull := NodeInfo{}\r\n\tnodes, err := c.nodes(false , \"name=?\", name)\r\n\tif err != nil {\r\n\t\treturn null, err\r\n\t}\r\n\tswitch len(nodes) {\r\n\tcase 0:\r\n\t\treturn null, ErrNoSuchObject\r\n\tcase 1:\r\n\t\treturn nodes[0], nil\r\n\tdefault:\r\n\t\treturn null, fmt.Errorf(\"more than one node matches\")\r\n\t}\r\n}","code-length":144,"reference":"\/\/ NodeByName returns the node with the given name.","result":"Query the database.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NodeName() (string, error) {\r\n\tstmt := \"SELECT name FROM nodes WHERE id=?\"\r\n\tnames, err := query.SelectStrings(c.tx, stmt, c.nodeID)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tswitch len(names) {\r\n\tcase 0:\r\n\t\treturn \"\", nil\r\n\tcase 1:\r\n\t\treturn names[0], nil\r\n\tdefault:\r\n\t\treturn \"\", fmt.Errorf(\"inconsistency: non-unique node ID\")\r\n\t}\r\n}","code-length":148,"reference":"\/\/ NodeName returns the name of the node this method is invoked on.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NodeAddress() (string, error) {\r\n\tstmt := \"SELECT address FROM nodes WHERE id=?\"\r\n\taddresses, err := query.SelectStrings(c.tx, stmt, c.nodeID)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tswitch len(addresses) {\r\n\tcase 0:\r\n\t\treturn \"\", nil\r\n\tcase 1:\r\n\t\treturn addresses[0], nil\r\n\tdefault:\r\n\t\treturn \"\", fmt.Errorf(\"inconsistency: non-unique node ID\")\r\n\t}\r\n}","code-length":149,"reference":"\/\/ NodeAddress returns the address of the node this method is invoked on.","result":"Get the node address.","score":[0.0476,0.155]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NodeIsOutdated() (bool, error) {\r\n\tnodes, err := c.nodes(false , \"\")\r\n\tif err != nil {\r\n\t\treturn false, errors.Wrap(err, \"Failed to fetch nodes\")\r\n\t}\r\n\t\r\n\tversion := [2]int{}\r\n\tfor _, node := range nodes {\r\n\t\tif node.ID == c.nodeID {\r\n\t\t\tversion = node.Version()\r\n\t\t}\r\n\t}\r\n\tif version[0] == 0 || version[1] == 0 {\r\n\t\treturn false, fmt.Errorf(\"Inconsistency: local node not found\")\r\n\t}\r\n\t\r\n\tfor _, node := range nodes {\r\n\t\tif node.ID == c.nodeID {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tn, err := util.CompareVersions(node.Version(), version)\r\n\t\tif err != nil {\r\n\t\t\terrors.Wrapf(err, \"Failed to compare with version of node %s\", node.Name)\r\n\t\t}\r\n\t\tif n == 1 {\r\n\t\t\t\r\n\t\t\treturn true, nil\r\n\t\t}\r\n\t}\r\n\treturn false, nil\r\n}","code-length":307,"reference":"\/\/ NodeIsOutdated returns true if there's some cluster node having an API or\n\/\/ schema version greater than the node this method is invoked on.","result":"Generate code for the generated code.","score":[0.0081,0.0216]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NodesCount() (int, error) {\r\n\tcount, err := query.Count(c.tx, \"nodes\", \"\")\r\n\tif err != nil {\r\n\t\treturn 0, errors.Wrap(err, \"failed to count existing nodes\")\r\n\t}\r\n\treturn count, nil\r\n}","code-length":87,"reference":"\/\/ NodesCount returns the number of nodes in the LXD cluster.\n\/\/\n\/\/ Since there's always at least one node row, even when not-clustered, the\n\/\/ return value is greater than zero","result":"Count existing nodes.","score":[0,0.0172]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NodeRename(old, new string) error {\r\n\tcount, err := query.Count(c.tx, \"nodes\", \"name=?\", new)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to check existing nodes\")\r\n\t}\r\n\tif count != 0 {\r\n\t\treturn ErrAlreadyDefined\r\n\t}\r\n\tstmt := `UPDATE nodes SET name=? WHERE name=?`\r\n\tresult, err := c.tx.Exec(stmt, new, old)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to update node name\")\r\n\t}\r\n\tn, err := result.RowsAffected()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to get rows count\")\r\n\t}\r\n\tif n != 1 {\r\n\t\treturn fmt.Errorf(\"expected to update one row, not %d\", n)\r\n\t}\r\n\treturn nil\r\n}","code-length":247,"reference":"\/\/ NodeRename changes the name of an existing node.\n\/\/\n\/\/ Return an error if a node with the same name already exists.","result":"Generate code for the generated code.","score":[0.0114,0.0235]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) nodes(pending bool, where string, args ...interface{}) ([]NodeInfo, error) {\r\n\tnodes := []NodeInfo{}\r\n\tdest := func(i int) []interface{} {\r\n\t\tnodes = append(nodes, NodeInfo{})\r\n\t\treturn []interface{}{\r\n\t\t\t&nodes[i].ID,\r\n\t\t\t&nodes[i].Name,\r\n\t\t\t&nodes[i].Address,\r\n\t\t\t&nodes[i].Description,\r\n\t\t\t&nodes[i].Schema,\r\n\t\t\t&nodes[i].APIExtensions,\r\n\t\t\t&nodes[i].Heartbeat,\r\n\t\t}\r\n\t}\r\n\tif pending {\r\n\t\targs = append([]interface{}{1}, args...)\r\n\t} else {\r\n\t\targs = append([]interface{}{0}, args...)\r\n\t}\r\n\tsql := `\r\nSELECT id, name, address, description, schema, api_extensions, heartbeat FROM nodes WHERE pending=? `\r\n\tif where != \"\" {\r\n\t\tsql += fmt.Sprintf(\"AND %s \", where)\r\n\t}\r\n\tsql += \"ORDER BY id\"\r\n\tstmt, err := c.tx.Prepare(sql)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer stmt.Close()\r\n\terr = query.SelectObjects(stmt, dest, args...)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Failed to fetch nodes\")\r\n\t}\r\n\treturn nodes, nil\r\n}","code-length":384,"reference":"\/\/ Nodes returns all LXD nodes part of the cluster.","result":"Fetch the nodes from the database.","score":[0.1179,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NodeAdd(name string, address string) (int64, error) {\r\n\tcolumns := []string{\"name\", \"address\", \"schema\", \"api_extensions\"}\r\n\tvalues := []interface{}{name, address, cluster.SchemaVersion, version.APIExtensionsCount()}\r\n\treturn query.UpsertObject(c.tx, \"nodes\", columns, values)\r\n}","code-length":101,"reference":"\/\/ NodeAdd adds a node to the current list of LXD nodes that are part of the\n\/\/ cluster. It returns the ID of the newly inserted row.","result":"Add a node to the cluster.","score":[0.0163,0.218]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NodePending(id int64, pending bool) error {\r\n\tvalue := 0\r\n\tif pending {\r\n\t\tvalue = 1\r\n\t}\r\n\tresult, err := c.tx.Exec(\"UPDATE nodes SET pending=? WHERE id=?\", value, id)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tn, err := result.RowsAffected()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif n != 1 {\r\n\t\treturn fmt.Errorf(\"query updated %d rows instead of 1\", n)\r\n\t}\r\n\treturn nil\r\n}","code-length":165,"reference":"\/\/ NodePending toggles the pending flag for the node. A node is pending when\n\/\/ it's been accepted in the cluster, but has not yet actually joined it.","result":"Update the node pending status.","score":[0.0032,0.0584]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NodeUpdate(id int64, name string, address string) error {\r\n\tresult, err := c.tx.Exec(\"UPDATE nodes SET name=?, address=? WHERE id=?\", name, address, id)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tn, err := result.RowsAffected()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif n != 1 {\r\n\t\treturn fmt.Errorf(\"query updated %d rows instead of 1\", n)\r\n\t}\r\n\treturn nil\r\n}","code-length":150,"reference":"\/\/ NodeUpdate updates the name an address of a node.","result":"Update the node in the cluster.","score":[0.0991,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NodeRemove(id int64) error {\r\n\tresult, err := c.tx.Exec(\"DELETE FROM nodes WHERE id=?\", id)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tn, err := result.RowsAffected()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif n != 1 {\r\n\t\treturn fmt.Errorf(\"query deleted %d rows instead of 1\", n)\r\n\t}\r\n\treturn nil\r\n}","code-length":135,"reference":"\/\/ NodeRemove removes the node with the given id.","result":"Remove the node from the cluster.","score":[0.1833,0.431]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NodeHeartbeat(address string, heartbeat time.Time) error {\r\n\tstmt := \"UPDATE nodes SET heartbeat=? WHERE address=?\"\r\n\tresult, err := c.tx.Exec(stmt, heartbeat, address)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tn, err := result.RowsAffected()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif n != 1 {\r\n\t\treturn fmt.Errorf(\"expected to update one row and not %d\", n)\r\n\t}\r\n\treturn nil\r\n}","code-length":151,"reference":"\/\/ NodeHeartbeat updates the heartbeat column of the node with the given address.","result":"Update the node heartbeat in the cluster.","score":[0.1153,0.3]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NodeIsEmpty(id int64) (string, error) {\r\n\t\r\n\tcontainers, err := query.SelectStrings(c.tx, \"SELECT name FROM containers WHERE node_id=?\", id)\r\n\tif err != nil {\r\n\t\treturn \"\", errors.Wrapf(err, \"Failed to get containers for node %d\", id)\r\n\t}\r\n\tif len(containers) > 0 {\r\n\t\tmessage := fmt.Sprintf(\r\n\t\t\t\"Node still has the following containers: %s\", strings.Join(containers, \", \"))\r\n\t\treturn message, nil\r\n\t}\r\n\t\r\n\timages := []struct {\r\n\t\tfingerprint string\r\n\t\tnodeID      int64\r\n\t}{}\r\n\tdest := func(i int) []interface{} {\r\n\t\timages = append(images, struct {\r\n\t\t\tfingerprint string\r\n\t\t\tnodeID      int64\r\n\t\t}{})\r\n\t\treturn []interface{}{&images[i].fingerprint, &images[i].nodeID}\r\n\t}\r\n\tstmt, err := c.tx.Prepare(`\r\nSELECT fingerprint, node_id FROM images JOIN images_nodes ON images.id=images_nodes.image_id`)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tdefer stmt.Close()\r\n\terr = query.SelectObjects(stmt, dest)\r\n\tif err != nil {\r\n\t\treturn \"\", errors.Wrapf(err, \"Failed to get image list for node %d\", id)\r\n\t}\r\n\tindex := map[string][]int64{}\r\n\tfor _, image := range images {\r\n\t\tindex[image.fingerprint] = append(index[image.fingerprint], image.nodeID)\r\n\t}\r\n\tfingerprints := []string{}\r\n\tfor fingerprint, ids := range index {\r\n\t\tif len(ids) > 1 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif ids[0] == id {\r\n\t\t\tfingerprints = append(fingerprints, fingerprint)\r\n\t\t}\r\n\t}\r\n\tif len(fingerprints) > 0 {\r\n\t\tmessage := fmt.Sprintf(\r\n\t\t\t\"Node still has the following images: %s\", strings.Join(fingerprints, \", \"))\r\n\t\treturn message, nil\r\n\t}\r\n\t\r\n\tvolumes, err := query.SelectStrings(\r\n\t\tc.tx, \"SELECT name FROM storage_volumes WHERE node_id=? AND type=?\",\r\n\t\tid, StoragePoolVolumeTypeCustom)\r\n\tif err != nil {\r\n\t\treturn \"\", errors.Wrapf(err, \"Failed to get custom volumes for node %d\", id)\r\n\t}\r\n\tif len(volumes) > 0 {\r\n\t\tmessage := fmt.Sprintf(\r\n\t\t\t\"Node still has the following custom volumes: %s\", strings.Join(volumes, \", \"))\r\n\t\treturn message, nil\r\n\t}\r\n\treturn \"\", nil\r\n}","code-length":730,"reference":"\/\/ NodeIsEmpty returns an empty string if the node with the given ID has no\n\/\/ containers or images associated with it. Otherwise, it returns a message\n\/\/ say what's left.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NodeClear(id int64) error {\r\n\t_, err := c.tx.Exec(\"DELETE FROM containers WHERE node_id=?\", id)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tids, err := query.SelectIntegers(c.tx, \"SELECT image_id FROM images_nodes WHERE node_id=?\", id)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t_, err = c.tx.Exec(\"DELETE FROM images_nodes WHERE node_id=?\", id)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tfor _, id := range ids {\r\n\t\tcount, err := query.Count(c.tx, \"images_nodes\", \"image_id=?\", id)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif count > 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t_, err = c.tx.Exec(\"DELETE FROM images WHERE id=?\", id)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":307,"reference":"\/\/ NodeClear removes any container or image associated with this node.","result":"Clear the node.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NodeOfflineThreshold() (time.Duration, error) {\r\n\tthreshold := time.Duration(DefaultOfflineThreshold) * time.Second\r\n\tvalues, err := query.SelectStrings(\r\n\t\tc.tx, \"SELECT value FROM config WHERE key='cluster.offline_threshold'\")\r\n\tif err != nil {\r\n\t\treturn -1, err\r\n\t}\r\n\tif len(values) > 0 {\r\n\t\tseconds, err := strconv.Atoi(values[0])\r\n\t\tif err != nil {\r\n\t\t\treturn -1, err\r\n\t\t}\r\n\t\tthreshold = time.Duration(seconds) * time.Second\r\n\t}\r\n\treturn threshold, nil\r\n}","code-length":182,"reference":"\/\/ NodeOfflineThreshold returns the amount of time that needs to elapse after\n\/\/ which a series of unsuccessful heartbeat will make the node be considered\n\/\/ offline.","result":"Set the node offline threshold.","score":[0.0042,0.0756]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NodeUpdateVersion(id int64, version [2]int) error {\r\n\tstmt := \"UPDATE nodes SET schema=?, api_extensions=? WHERE id=?\"\r\n\tresult, err := c.tx.Exec(stmt, version[0], version[1], id)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Failed to update nodes table\")\r\n\t}\r\n\tn, err := result.RowsAffected()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Failed to get affected rows\")\r\n\t}\r\n\tif n != 1 {\r\n\t\treturn fmt.Errorf(\"Expected exactly one row to be updated\")\r\n\t}\r\n\treturn nil\r\n}","code-length":185,"reference":"\/\/ NodeUpdateVersion updates the schema and API version of the node with the\n\/\/ given id. This is used only in tests.","result":"Update the version of the node.","score":[0.0297,0.1824]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Transaction(db *sql.DB, f func(*sql.Tx) error) error {\r\n\ttx, err := db.Begin()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to begin transaction\")\r\n\t}\r\n\terr = f(tx)\r\n\tif err != nil {\r\n\t\treturn rollback(tx, err)\r\n\t}\r\n\terr = tx.Commit()\r\n\tif err == sql.ErrTxDone {\r\n\t\terr = nil\r\n\t}\r\n\treturn err\r\n}","code-length":141,"reference":"\/\/ Transaction executes the given function within a database transaction.","result":"Create a transaction.","score":[0.0471,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc rollback(tx *sql.Tx, reason error) error {\r\n\terr := tx.Rollback()\r\n\tif err != nil {\r\n\t\tlogger.Warnf(\"Failed to rollback transaction after error (%v): %v\", reason, err)\r\n\t}\r\n\treturn reason\r\n}","code-length":77,"reference":"\/\/ Rollback a transaction after the given error occurred. If the rollback\n\/\/ succeeds the given error is returned, otherwise a new error that wraps it\n\/\/ gets generated and returned.","result":"Rollback the transaction.","score":[0.0,0.0355]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ProfileURIs(filter ProfileFilter) ([]string, error) {\r\n\t\r\n\tcriteria := map[string]interface{}{}\r\n\tif filter.Project != \"\" {\r\n\t\tcriteria[\"Project\"] = filter.Project\r\n\t}\r\n\tif filter.Name != \"\" {\r\n\t\tcriteria[\"Name\"] = filter.Name\r\n\t}\r\n\t\r\n\tvar stmt *sql.Stmt\r\n\tvar args []interface{}\r\n\tif criteria[\"Project\"] != nil && criteria[\"Name\"] != nil {\r\n\t\tstmt = c.stmt(profileNamesByProjectAndName)\r\n\t\targs = []interface{}{\r\n\t\t\tfilter.Project,\r\n\t\t\tfilter.Name,\r\n\t\t}\r\n\t} else if criteria[\"Project\"] != nil {\r\n\t\tstmt = c.stmt(profileNamesByProject)\r\n\t\targs = []interface{}{\r\n\t\t\tfilter.Project,\r\n\t\t}\r\n\t} else {\r\n\t\tstmt = c.stmt(profileNames)\r\n\t\targs = []interface{}{}\r\n\t}\r\n\tcode := cluster.EntityTypes[\"profile\"]\r\n\tformatter := cluster.EntityFormatURIs[code]\r\n\treturn query.SelectURIs(stmt, formatter, args...)\r\n}","code-length":313,"reference":"\/\/ ProfileURIs returns all available profile URIs.","result":"Query the database.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ProfileGet(project string, name string) (*Profile, error) {\r\n\tfilter := ProfileFilter{}\r\n\tfilter.Project = project\r\n\tfilter.Name = name\r\n\tobjects, err := c.ProfileList(filter)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Failed to fetch Profile\")\r\n\t}\r\n\tswitch len(objects) {\r\n\tcase 0:\r\n\t\treturn nil, ErrNoSuchObject\r\n\tcase 1:\r\n\t\treturn &objects[0], nil\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"More than one profile matches\")\r\n\t}\r\n}","code-length":172,"reference":"\/\/ ProfileGet returns the profile with the given key.","result":"Generate code for the code generated by the compiler.","score":[0.1449,0.1111]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ProfileExists(project string, name string) (bool, error) {\r\n\t_, err := c.ProfileID(project, name)\r\n\tif err != nil {\r\n\t\tif err == ErrNoSuchObject {\r\n\t\t\treturn false, nil\r\n\t\t}\r\n\t\treturn false, err\r\n\t}\r\n\treturn true, nil\r\n}","code-length":101,"reference":"\/\/ ProfileExists checks if a profile with the given key exists.","result":"Generate code for the code generated by the compiler.","score":[0.0976,0.0463]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ProfileConfigRef(filter ProfileFilter) (map[string]map[string]map[string]string, error) {\r\n\t\r\n\tobjects := make([]struct {\r\n\t\tProject string\r\n\t\tName    string\r\n\t\tKey     string\r\n\t\tValue   string\r\n\t}, 0)\r\n\t\r\n\tcriteria := map[string]interface{}{}\r\n\tif filter.Project != \"\" {\r\n\t\tcriteria[\"Project\"] = filter.Project\r\n\t}\r\n\tif filter.Name != \"\" {\r\n\t\tcriteria[\"Name\"] = filter.Name\r\n\t}\r\n\t\r\n\tvar stmt *sql.Stmt\r\n\tvar args []interface{}\r\n\tif criteria[\"Project\"] != nil && criteria[\"Name\"] != nil {\r\n\t\tstmt = c.stmt(profileConfigRefByProjectAndName)\r\n\t\targs = []interface{}{\r\n\t\t\tfilter.Project,\r\n\t\t\tfilter.Name,\r\n\t\t}\r\n\t} else if criteria[\"Project\"] != nil {\r\n\t\tstmt = c.stmt(profileConfigRefByProject)\r\n\t\targs = []interface{}{\r\n\t\t\tfilter.Project,\r\n\t\t}\r\n\t} else {\r\n\t\tstmt = c.stmt(profileConfigRef)\r\n\t\targs = []interface{}{}\r\n\t}\r\n\t\r\n\tdest := func(i int) []interface{} {\r\n\t\tobjects = append(objects, struct {\r\n\t\t\tProject string\r\n\t\t\tName    string\r\n\t\t\tKey     string\r\n\t\t\tValue   string\r\n\t\t}{})\r\n\t\treturn []interface{}{\r\n\t\t\t&objects[i].Project,\r\n\t\t\t&objects[i].Name,\r\n\t\t\t&objects[i].Key,\r\n\t\t\t&objects[i].Value,\r\n\t\t}\r\n\t}\r\n\t\r\n\terr := query.SelectObjects(stmt, dest, args...)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Failed to fetch  ref for profiles\")\r\n\t}\r\n\t\r\n\tindex := map[string]map[string]map[string]string{}\r\n\tfor _, object := range objects {\r\n\t\t_, ok := index[object.Project]\r\n\t\tif !ok {\r\n\t\t\tsubIndex := map[string]map[string]string{}\r\n\t\t\tindex[object.Project] = subIndex\r\n\t\t}\r\n\t\titem, ok := index[object.Project][object.Name]\r\n\t\tif !ok {\r\n\t\t\titem = map[string]string{}\r\n\t\t}\r\n\t\tindex[object.Project][object.Name] = item\r\n\t\titem[object.Key] = object.Value\r\n\t}\r\n\treturn index, nil\r\n}","code-length":683,"reference":"\/\/ ProfileConfigRef returns entities used by profiles.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ProfileUsedByRef(filter ProfileFilter) (map[string]map[string][]string, error) {\r\n\t\r\n\tobjects := make([]struct {\r\n\t\tProject string\r\n\t\tName    string\r\n\t\tValue   string\r\n\t}, 0)\r\n\t\r\n\tcriteria := map[string]interface{}{}\r\n\tif filter.Project != \"\" {\r\n\t\tcriteria[\"Project\"] = filter.Project\r\n\t}\r\n\tif filter.Name != \"\" {\r\n\t\tcriteria[\"Name\"] = filter.Name\r\n\t}\r\n\t\r\n\tvar stmt *sql.Stmt\r\n\tvar args []interface{}\r\n\tif criteria[\"Project\"] != nil && criteria[\"Name\"] != nil {\r\n\t\tstmt = c.stmt(profileUsedByRefByProjectAndName)\r\n\t\targs = []interface{}{\r\n\t\t\tfilter.Project,\r\n\t\t\tfilter.Name,\r\n\t\t}\r\n\t} else if criteria[\"Project\"] != nil {\r\n\t\tstmt = c.stmt(profileUsedByRefByProject)\r\n\t\targs = []interface{}{\r\n\t\t\tfilter.Project,\r\n\t\t}\r\n\t} else {\r\n\t\tstmt = c.stmt(profileUsedByRef)\r\n\t\targs = []interface{}{}\r\n\t}\r\n\t\r\n\tdest := func(i int) []interface{} {\r\n\t\tobjects = append(objects, struct {\r\n\t\t\tProject string\r\n\t\t\tName    string\r\n\t\t\tValue   string\r\n\t\t}{})\r\n\t\treturn []interface{}{\r\n\t\t\t&objects[i].Project,\r\n\t\t\t&objects[i].Name,\r\n\t\t\t&objects[i].Value,\r\n\t\t}\r\n\t}\r\n\t\r\n\terr := query.SelectObjects(stmt, dest, args...)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Failed to fetch string ref for profiles\")\r\n\t}\r\n\t\r\n\tindex := map[string]map[string][]string{}\r\n\tfor _, object := range objects {\r\n\t\t_, ok := index[object.Project]\r\n\t\tif !ok {\r\n\t\t\tsubIndex := map[string][]string{}\r\n\t\t\tindex[object.Project] = subIndex\r\n\t\t}\r\n\t\titem, ok := index[object.Project][object.Name]\r\n\t\tif !ok {\r\n\t\t\titem = []string{}\r\n\t\t}\r\n\t\tindex[object.Project][object.Name] = append(item, object.Value)\r\n\t}\r\n\treturn index, nil\r\n}","code-length":643,"reference":"\/\/ ProfileUsedByRef returns entities used by profiles.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ProfileCreate(object Profile) (int64, error) {\r\n\t\r\n\texists, err := c.ProfileExists(object.Project, object.Name)\r\n\tif err != nil {\r\n\t\treturn -1, errors.Wrap(err, \"Failed to check for duplicates\")\r\n\t}\r\n\tif exists {\r\n\t\treturn -1, fmt.Errorf(\"This profile already exists\")\r\n\t}\r\n\targs := make([]interface{}, 3)\r\n\t\r\n\targs[0] = object.Project\r\n\targs[1] = object.Name\r\n\targs[2] = object.Description\r\n\t\r\n\tstmt := c.stmt(profileCreate)\r\n\t\r\n\tresult, err := stmt.Exec(args...)\r\n\tif err != nil {\r\n\t\treturn -1, errors.Wrap(err, \"Failed to create profile\")\r\n\t}\r\n\tid, err := result.LastInsertId()\r\n\tif err != nil {\r\n\t\treturn -1, errors.Wrap(err, \"Failed to fetch profile ID\")\r\n\t}\r\n\t\r\n\tstmt = c.stmt(profileCreateConfigRef)\r\n\tfor key, value := range object.Config {\r\n\t\t_, err := stmt.Exec(id, key, value)\r\n\t\tif err != nil {\r\n\t\t\treturn -1, errors.Wrap(err, \"Insert config for profile\")\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor name, config := range object.Devices {\r\n\t\ttyp, ok := config[\"type\"]\r\n\t\tif !ok {\r\n\t\t\treturn -1, fmt.Errorf(\"No type for device %s\", name)\r\n\t\t}\r\n\t\ttypCode, err := dbDeviceTypeToInt(typ)\r\n\t\tif err != nil {\r\n\t\t\treturn -1, errors.Wrapf(err, \"Device type code for %s\", typ)\r\n\t\t}\r\n\t\tstmt = c.stmt(profileCreateDevicesRef)\r\n\t\tresult, err := stmt.Exec(id, name, typCode)\r\n\t\tif err != nil {\r\n\t\t\treturn -1, errors.Wrapf(err, \"Insert device %s\", name)\r\n\t\t}\r\n\t\tdeviceID, err := result.LastInsertId()\r\n\t\tif err != nil {\r\n\t\t\treturn -1, errors.Wrap(err, \"Failed to fetch device ID\")\r\n\t\t}\r\n\t\tstmt = c.stmt(profileCreateDevicesConfigRef)\r\n\t\tfor key, value := range config {\r\n\t\t\t_, err := stmt.Exec(deviceID, key, value)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn -1, errors.Wrap(err, \"Insert config for profile\")\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn id, nil\r\n}","code-length":692,"reference":"\/\/ ProfileCreate adds a new profile to the database.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ProfileRename(project string, name string, to string) error {\r\n\tstmt := c.stmt(profileRename)\r\n\tresult, err := stmt.Exec(to, project, name)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Rename profile\")\r\n\t}\r\n\tn, err := result.RowsAffected()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Fetch affected rows\")\r\n\t}\r\n\tif n != 1 {\r\n\t\treturn fmt.Errorf(\"Query affected %d rows instead of 1\", n)\r\n\t}\r\n\treturn nil\r\n}","code-length":166,"reference":"\/\/ ProfileRename renames the profile matching the given key parameters.","result":"Rename a project profile.","score":[0,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) ProfileDelete(project string, name string) error {\r\n\tstmt := c.stmt(profileDelete)\r\n\tresult, err := stmt.Exec(project, name)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Delete profile\")\r\n\t}\r\n\tn, err := result.RowsAffected()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Fetch affected rows\")\r\n\t}\r\n\tif n != 1 {\r\n\t\treturn fmt.Errorf(\"Query deleted %d rows instead of 1\", n)\r\n\t}\r\n\treturn nil\r\n}","code-length":161,"reference":"\/\/ ProfileDelete deletes the profile matching the given key parameters.","result":"Delete profile.","score":[0,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ServerTLSConfig(cert *shared.CertInfo) *tls.Config {\r\n\tconfig := shared.InitTLSConfig()\r\n\tconfig.ClientAuth = tls.RequestClientCert\r\n\tconfig.Certificates = []tls.Certificate{cert.KeyPair()}\r\n\tconfig.NextProtos = []string{\"h2\"}\r\n\tif cert.CA() != nil {\r\n\t\tpool := x509.NewCertPool()\r\n\t\tpool.AddCert(cert.CA())\r\n\t\tconfig.RootCAs = pool\r\n\t\tconfig.ClientCAs = pool\r\n\t\tlogger.Infof(\"LXD is in CA mode, only CA-signed certificates will be allowed\")\r\n\t}\r\n\tconfig.BuildNameToCertificate()\r\n\treturn config\r\n}","code-length":185,"reference":"\/\/ ServerTLSConfig returns a new server-side tls.Config generated from the give\n\/\/ certificate info.","result":"Generate the server TLS config.","score":[0.0397,0.0763]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NetworkInterfaceAddress() string {\r\n\tifaces, err := net.Interfaces()\r\n\tif err != nil {\r\n\t\treturn \"\"\r\n\t}\r\n\tfor _, iface := range ifaces {\r\n\t\tif shared.IsLoopback(&iface) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\taddrs, err := iface.Addrs()\r\n\t\tif err != nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif len(addrs) == 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\taddr, ok := addrs[0].(*net.IPNet)\r\n\t\tif !ok {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\treturn addr.IP.String()\r\n\t}\r\n\treturn \"\"\r\n}","code-length":194,"reference":"\/\/ NetworkInterfaceAddress returns the first non-loopback address of any of the\n\/\/ system network interfaces.\n\/\/\n\/\/ Return the empty string if none is found.","result":"Get the network interface address.","score":[0.0052,0.0435]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsAddressCovered(address1, address2 string) bool {\r\n\tif address1 == address2 {\r\n\t\treturn true\r\n\t}\r\n\thost1, port1, err := net.SplitHostPort(address1)\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\thost2, port2, err := net.SplitHostPort(address2)\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\t\r\n\t\r\n\tif port2 != port1 {\r\n\t\treturn false\r\n\t}\r\n\t\r\n\t\r\n\tif host2 == \"0.0.0.0\" {\r\n\t\tip := net.ParseIP(host1)\r\n\t\tif ip != nil && ip.To4() != nil {\r\n\t\t\treturn true\r\n\t\t}\r\n\t\treturn false\r\n\t}\r\n\t\r\n\t\r\n\tif host2 == \"::\" || host2 == \"\" {\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":257,"reference":"\/\/ IsAddressCovered detects if network address1 is actually covered by\n\/\/ address2, in the sense that they are either the same address or address2 is\n\/\/ specified using a wildcard with the same port of address1.","result":"Check if two addresses are covered by the same host.","score":[0.0166,0.1714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SelectObjects(stmt *sql.Stmt, dest Dest, args ...interface{}) error {\r\n\trows, err := stmt.Query(args...)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer rows.Close()\r\n\tfor i := 0; rows.Next(); i++ {\r\n\t\terr := rows.Scan(dest(i)...)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\terr = rows.Err()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":157,"reference":"\/\/ SelectObjects executes a statement which must yield rows with a specific\n\/\/ columns schema. It invokes the given Dest hook for each yielded row.","result":"Select objects from a statement.","score":[0.0044,0.0217]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DeleteObject(tx *sql.Tx, table string, id int64) (bool, error) {\r\n\tstmt := fmt.Sprintf(\"DELETE FROM %s WHERE id=?\", table)\r\n\tresult, err := tx.Exec(stmt, id)\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\tn, err := result.RowsAffected()\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\tif n > 1 {\r\n\t\treturn true, fmt.Errorf(\"more than one row was deleted\")\r\n\t}\r\n\treturn n == 1, nil\r\n}","code-length":161,"reference":"\/\/ DeleteObject removes the row identified by the given ID. The given table\n\/\/ must have a primary key column called 'id'.\n\/\/\n\/\/ It returns a flag indicating if a matching row was actually found and\n\/\/ deleted or not.","result":"Delete object.","score":[0,0.0135]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Task) loop(ctx context.Context) {\r\n\t\r\n\t\r\n\tdelay := immediately\r\n\tfor {\r\n\t\tvar timer <-chan time.Time\r\n\t\tschedule, err := t.schedule()\r\n\t\tswitch err {\r\n\t\tcase ErrSkip:\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tdelay = schedule\r\n\t\t\tfallthrough\r\n\t\tcase nil:\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tif schedule > 0 {\r\n\t\t\t\ttimer = time.After(delay)\r\n\t\t\t} else {\r\n\t\t\t\ttimer = make(chan time.Time)\r\n\t\t\t}\r\n\t\tdefault:\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tif schedule <= 0 {\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\ttimer = time.After(schedule)\r\n\t\t}\r\n\t\tselect {\r\n\t\tcase <-timer:\r\n\t\t\tif err == nil {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tt.f(ctx)\r\n\t\t\t\tdelay = schedule\r\n\t\t\t} else {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tdelay = immediately\r\n\t\t\t}\r\n\t\tcase <-ctx.Done():\r\n\t\t\treturn\r\n\t\tcase <-t.reset:\r\n\t\t\tdelay = immediately\r\n\t\t}\r\n\t}\r\n}","code-length":346,"reference":"\/\/ Execute the our task function according to our schedule, until the given\n\/\/ context gets cancelled.","result":"Loop the task .","score":[0.0147,0.0637]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsTerminal(fd int) bool {\r\n\t_, err := GetState(fd)\r\n\treturn err == nil\r\n}","code-length":40,"reference":"\/\/ IsTerminal returns true if the given file descriptor is a terminal.","result":"Detect terminal .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc socketUnixListen(path string) (net.Listener, error) {\r\n\taddr, err := net.ResolveUnixAddr(\"unix\", path)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"cannot resolve socket address: %v\", err)\r\n\t}\r\n\tlistener, err := net.ListenUnix(\"unix\", addr)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"cannot bind socket: %v\", err)\r\n\t}\r\n\treturn listener, err\r\n}","code-length":133,"reference":"\/\/ Bind to the given unix socket path.","result":"Listen on unix socket.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc socketUnixRemoveStale(path string) error {\r\n\t\r\n\tif !shared.PathExists(path) {\r\n\t\treturn nil\r\n\t}\r\n\tlogger.Debugf(\"Detected stale unix socket, deleting\")\r\n\terr := os.Remove(path)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"could not delete stale local socket: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":112,"reference":"\/\/ Remove any stale socket file at the given path.","result":"Remove a stale unix socket.","score":[0.1051,0.1053]}
{"code":"\/*is used to<extra_id_0>\r\nfunc socketUnixSetPermissions(path string, mode os.FileMode) error {\r\n\terr := os.Chmod(path, mode)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"cannot set permissions on local socket: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":81,"reference":"\/\/ Change the file mode of the given unix socket file,","result":"Set permissions on socket unix sockets.","score":[0.0998,0.0952]}
{"code":"\/*is used to<extra_id_0>\r\nfunc socketUnixSetOwnership(path string, group string) error {\r\n\tvar gid int\r\n\tvar err error\r\n\tif group != \"\" {\r\n\t\tgid, err = shared.GroupId(group)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"cannot get group ID of '%s': %v\", group, err)\r\n\t\t}\r\n\t} else {\r\n\t\tgid = os.Getgid()\r\n\t}\r\n\terr = os.Chown(path, os.Getuid(), gid)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"cannot change ownership on local socket: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":177,"reference":"\/\/ Change the ownership of the given unix socket file,","result":"Set ownership on local socket.","score":[0.0884,0.0526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc cephOSDPoolExists(ClusterName string, poolName string, userName string) bool {\r\n\t_, err := shared.RunCommand(\r\n\t\t\"ceph\",\r\n\t\t\"--name\", fmt.Sprintf(\"client.%s\", userName),\r\n\t\t\"--cluster\", ClusterName,\r\n\t\t\"osd\",\r\n\t\t\"pool\",\r\n\t\t\"get\",\r\n\t\tpoolName,\r\n\t\t\"size\")\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\treturn true\r\n}","code-length":140,"reference":"\/\/ cephOSDPoolExists checks whether a given OSD pool exists.","result":"Check if the pool exists.","score":[0.1527,0.2972]}
{"code":"\/*is used to<extra_id_0>\r\nfunc cephOSDPoolDestroy(clusterName string, poolName string, userName string) error {\r\n\t_, err := shared.RunCommand(\"ceph\",\r\n\t\t\"--name\", fmt.Sprintf(\"client.%s\", userName),\r\n\t\t\"--cluster\", clusterName,\r\n\t\t\"osd\",\r\n\t\t\"pool\",\r\n\t\t\"delete\",\r\n\t\tpoolName,\r\n\t\tpoolName,\r\n\t\t\"--yes-i-really-really-mean-it\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":155,"reference":"\/\/ cephOSDPoolDestroy destroys an OSD pool.\n\/\/ - A call to cephOSDPoolDestroy will destroy a pool including any storage\n\/\/   volumes that still exist in the pool.\n\/\/ - In case the OSD pool that is supposed to be deleted does not exist this\n\/\/   command will still exit 0. This means that if the caller wants to be sure\n\/\/   that this call actually deleted an OSD pool it needs to check for the\n\/\/   existence of the pool first.","result":"Destroy the pool.","score":[0.0,0.0205]}
{"code":"\/*is used to<extra_id_0>\r\nfunc cephRBDVolumeExists(clusterName string, poolName string, volumeName string,\r\n\tvolumeType string, userName string) bool {\r\n\t_, err := shared.RunCommand(\r\n\t\t\"rbd\",\r\n\t\t\"--id\", userName,\r\n\t\t\"--cluster\", clusterName,\r\n\t\t\"--pool\", poolName,\r\n\t\t\"image-meta\",\r\n\t\t\"list\",\r\n\t\tfmt.Sprintf(\"%s_%s\", volumeType, volumeName))\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\treturn true\r\n}","code-length":151,"reference":"\/\/ cephRBDVolumeExists checks whether a given RBD storage volume exists.","result":"Check if the volume exists.","score":[0.125,0.269]}
{"code":"\/*is used to<extra_id_0>\r\nfunc cephRBDSnapshotProtect(clusterName string, poolName string,\r\n\tvolumeName string, volumeType string, snapshotName string,\r\n\tuserName string) error {\r\n\t_, err := shared.RunCommand(\r\n\t\t\"rbd\",\r\n\t\t\"--id\", userName,\r\n\t\t\"--cluster\", clusterName,\r\n\t\t\"--pool\", poolName,\r\n\t\t\"snap\",\r\n\t\t\"protect\",\r\n\t\t\"--snap\", snapshotName,\r\n\t\tfmt.Sprintf(\"%s_%s\", volumeType, volumeName))\r\n\tif err != nil {\r\n\t\trunError, ok := err.(shared.RunError)\r\n\t\tif ok {\r\n\t\t\texitError, ok := runError.Err.(*exec.ExitError)\r\n\t\t\tif ok {\r\n\t\t\t\twaitStatus := exitError.Sys().(syscall.WaitStatus)\r\n\t\t\t\tif waitStatus.ExitStatus() == 16 {\r\n\t\t\t\t\t\r\n\t\t\t\t\treturn nil\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":277,"reference":"\/\/ cephRBDSnapshotProtect protects a given snapshot from being deleted\n\/\/ This is a precondition to be able to create RBD clones from a given snapshot.","result":"Protect a snapshot.","score":[0.0003,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc cephRBDCloneCreate(sourceClusterName string, sourcePoolName string,\r\n\tsourceVolumeName string, sourceVolumeType string,\r\n\tsourceSnapshotName string, targetPoolName string,\r\n\ttargetVolumeName string, targetVolumeType string,\r\n\tuserName string) error {\r\n\t_, err := shared.RunCommand(\r\n\t\t\"rbd\",\r\n\t\t\"--id\", userName,\r\n\t\t\"--cluster\", sourceClusterName,\r\n\t\t\"--image-feature\", \"layering\",\r\n\t\t\"clone\",\r\n\t\tfmt.Sprintf(\"%s\/%s_%s@%s\", sourcePoolName, sourceVolumeType,\r\n\t\t\tsourceVolumeName, sourceSnapshotName),\r\n\t\tfmt.Sprintf(\"%s\/%s_%s\", targetPoolName, targetVolumeType,\r\n\t\t\ttargetVolumeName))\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":231,"reference":"\/\/ cephRBDCloneCreate creates a clone from a protected RBD snapshot","result":"Create a new RBD volume.","score":[0.1051,0.1579]}
{"code":"\/*is used to<extra_id_0>\r\nfunc cephRBDSnapshotListClones(clusterName string, poolName string,\r\n\tvolumeName string, volumeType string,\r\n\tsnapshotName string, userName string) ([]string, error) {\r\n\tmsg, err := shared.RunCommand(\r\n\t\t\"rbd\",\r\n\t\t\"--id\", userName,\r\n\t\t\"--cluster\", clusterName,\r\n\t\t\"--pool\", poolName,\r\n\t\t\"children\",\r\n\t\t\"--image\", fmt.Sprintf(\"%s_%s\", volumeType, volumeName),\r\n\t\t\"--snap\", snapshotName)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tmsg = strings.TrimSpace(msg)\r\n\tclones := strings.Fields(msg)\r\n\tif len(clones) == 0 {\r\n\t\treturn nil, db.ErrNoSuchObject\r\n\t}\r\n\treturn clones, nil\r\n}","code-length":228,"reference":"\/\/ cephRBDSnapshotListClones list all clones of an RBD snapshot","result":"List the clones of a snapshot.","score":[0.1656,0.2937]}
{"code":"\/*is used to<extra_id_0>\r\nfunc cephRBDVolumeMarkDeleted(clusterName string, poolName string,\r\n\tvolumeType string, oldVolumeName string, newVolumeName string,\r\n\tuserName string, suffix string) error {\r\n\tdeletedName := fmt.Sprintf(\"%s\/zombie_%s_%s\", poolName, volumeType,\r\n\t\tnewVolumeName)\r\n\tif suffix != \"\" {\r\n\t\tdeletedName = fmt.Sprintf(\"%s_%s\", deletedName, suffix)\r\n\t}\r\n\t_, err := shared.RunCommand(\r\n\t\t\"rbd\",\r\n\t\t\"--id\", userName,\r\n\t\t\"--cluster\", clusterName,\r\n\t\t\"mv\",\r\n\t\tfmt.Sprintf(\"%s\/%s_%s\", poolName, volumeType, oldVolumeName),\r\n\t\tdeletedName)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":225,"reference":"\/\/ cephRBDVolumeMarkDeleted marks an RBD storage volume as being in \"zombie\"\n\/\/ state\n\/\/ An RBD storage volume that is in zombie state is not tracked in LXD's\n\/\/ database anymore but still needs to be kept around for the sake of any\n\/\/ dependent storage entities in the storage pool. This usually happens when an\n\/\/ RBD storage volume has protected snapshots; a scenario most common when\n\/\/ creating a sparse copy of a container or when LXD updated an image and the\n\/\/ image still has dependent container clones.","result":"Mark volume as deleted.","score":[0.0,0.0182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc cephRBDVolumeUnmarkDeleted(clusterName string, poolName string,\r\n\tvolumeName string, volumeType string, userName string, oldSuffix string,\r\n\tnewSuffix string) error {\r\n\toldName := fmt.Sprintf(\"%s\/zombie_%s_%s\", poolName, volumeType, volumeName)\r\n\tif oldSuffix != \"\" {\r\n\t\toldName = fmt.Sprintf(\"%s_%s\", oldName, oldSuffix)\r\n\t}\r\n\tnewName := fmt.Sprintf(\"%s\/%s_%s\", poolName, volumeType, volumeName)\r\n\tif newSuffix != \"\" {\r\n\t\tnewName = fmt.Sprintf(\"%s_%s\", newName, newSuffix)\r\n\t}\r\n\t_, err := shared.RunCommand(\r\n\t\t\"rbd\",\r\n\t\t\"--id\", userName,\r\n\t\t\"--cluster\", clusterName,\r\n\t\t\"mv\",\r\n\t\toldName,\r\n\t\tnewName)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":262,"reference":"\/\/ cephRBDVolumeUnmarkDeleted unmarks an RBD storage volume as being in \"zombie\"\n\/\/ state\n\/\/ - An RBD storage volume that is in zombie is not tracked in LXD's database\n\/\/   anymore but still needs to be kept around for the sake of any dependent\n\/\/   storage entities in the storage pool.\n\/\/ - This function is mostly used when a user has deleted the storage volume of\n\/\/   an image from the storage pool and then triggers a container creation. If\n\/\/   LXD detects that the storage volume for the given hash already exists in\n\/\/   the pool but is marked as \"zombie\" it will unmark it as a zombie instead of\n\/\/   creating another storage volume for the image.","result":"Mark volumes as deleted.","score":[0.0,0.0138]}
{"code":"\/*is used to<extra_id_0>\r\nfunc cephRBDVolumeRename(clusterName string, poolName string, volumeType string,\r\n\toldVolumeName string, newVolumeName string, userName string) error {\r\n\t_, err := shared.RunCommand(\r\n\t\t\"rbd\",\r\n\t\t\"--id\", userName,\r\n\t\t\"--cluster\", clusterName,\r\n\t\t\"mv\",\r\n\t\tfmt.Sprintf(\"%s\/%s_%s\", poolName, volumeType, oldVolumeName),\r\n\t\tfmt.Sprintf(\"%s\/%s_%s\", poolName, volumeType, newVolumeName))\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":167,"reference":"\/\/ cephRBDVolumeRename renames a given RBD storage volume\n\/\/ Note that this usually requires that the image be unmapped under its original\n\/\/ name, then renamed, and finally will be remapped again. If it is not unmapped\n\/\/ under its original name and the callers maps it under its new name the image\n\/\/ will be mapped twice. This will prevent it from being deleted.","result":"Rename a RBD volume.","score":[0.0,0.0434]}
{"code":"\/*is used to<extra_id_0>\r\nfunc cephRBDVolumeSnapshotRename(clusterName string, poolName string,\r\n\tvolumeName string, volumeType string, oldSnapshotName string,\r\n\tnewSnapshotName string, userName string) error {\r\n\t_, err := shared.RunCommand(\r\n\t\t\"rbd\",\r\n\t\t\"--id\", userName,\r\n\t\t\"--cluster\", clusterName,\r\n\t\t\"snap\",\r\n\t\t\"rename\",\r\n\t\tfmt.Sprintf(\"%s\/%s_%s@%s\", poolName, volumeType, volumeName,\r\n\t\t\toldSnapshotName),\r\n\t\tfmt.Sprintf(\"%s\/%s_%s@%s\", poolName, volumeType, volumeName,\r\n\t\t\tnewSnapshotName))\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":202,"reference":"\/\/ cephRBDVolumeRename renames a given RBD storage volume\n\/\/ Note that if the snapshot is mapped - which it usually shouldn't be - this\n\/\/ usually requires that the snapshot be unmapped under its original name, then\n\/\/ renamed, and finally will be remapped again. If it is not unmapped under its\n\/\/ original name and the caller maps it under its new name the snapshot will be\n\/\/ mapped twice. This will prevent it from being deleted.","result":"Rename a snapshot.","score":[0.0,0.0266]}
{"code":"\/*is used to<extra_id_0>\r\nfunc cephRBDSnapshotDelete(clusterName string, poolName string,\r\n\tvolumeName string, volumeType string, snapshotName string,\r\n\tuserName string) error {\r\n\t_, err := shared.RunCommand(\r\n\t\t\"rbd\",\r\n\t\t\"--id\", userName,\r\n\t\t\"--cluster\", clusterName,\r\n\t\t\"--pool\", poolName,\r\n\t\t\"snap\",\r\n\t\t\"rm\",\r\n\t\tfmt.Sprintf(\"%s_%s@%s\", volumeType, volumeName, snapshotName))\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":163,"reference":"\/\/ cephRBDSnapshotDelete deletes an RBD snapshot\n\/\/ This requires that the snapshot does not have any clones and is unmapped and\n\/\/ unprotected.","result":"Delete a snapshot.","score":[0,0.0238]}
{"code":"\/*is used to<extra_id_0>\r\nfunc cephRBDVolumeCopy(clusterName string, oldVolumeName string,\r\n\tnewVolumeName string, userName string) error {\r\n\t_, err := shared.RunCommand(\r\n\t\t\"rbd\",\r\n\t\t\"--id\", userName,\r\n\t\t\"--cluster\", clusterName,\r\n\t\t\"cp\",\r\n\t\toldVolumeName,\r\n\t\tnewVolumeName)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":128,"reference":"\/\/ cephRBDVolumeCopy copies an RBD storage volume\n\/\/ This is a non-sparse copy which doesn't introduce any dependency relationship\n\/\/ between the source RBD storage volume and the target RBD storage volume. The\n\/\/ operations is similar to creating an empty RBD storage volume and rsyncing\n\/\/ the contents of the source RBD storage volume into it.","result":"Copy volume.","score":[0.0,0.0194]}
{"code":"\/*is used to<extra_id_0>\r\nfunc cephRBDVolumeListSnapshots(clusterName string, poolName string,\r\n\tvolumeName string, volumeType string,\r\n\tuserName string) ([]string, error) {\r\n\tmsg, err := shared.RunCommand(\r\n\t\t\"rbd\",\r\n\t\t\"--id\", userName,\r\n\t\t\"--format\", \"json\",\r\n\t\t\"--cluster\", clusterName,\r\n\t\t\"--pool\", poolName,\r\n\t\t\"snap\",\r\n\t\t\"ls\", fmt.Sprintf(\"%s_%s\", volumeType, volumeName))\r\n\tif err != nil {\r\n\t\treturn []string{}, err\r\n\t}\r\n\tvar data []map[string]interface{}\r\n\terr = json.Unmarshal([]byte(msg), &data)\r\n\tif err != nil {\r\n\t\treturn []string{}, err\r\n\t}\r\n\tsnapshots := []string{}\r\n\tfor _, v := range data {\r\n\t\t_, ok := v[\"name\"]\r\n\t\tif !ok {\r\n\t\t\treturn []string{}, fmt.Errorf(\"No \\\"name\\\" property found\")\r\n\t\t}\r\n\t\tname, ok := v[\"name\"].(string)\r\n\t\tif !ok {\r\n\t\t\treturn []string{}, fmt.Errorf(\"\\\"name\\\" property did not have string type\")\r\n\t\t}\r\n\t\tname = strings.TrimSpace(name)\r\n\t\tsnapshots = append(snapshots, name)\r\n\t}\r\n\tif len(snapshots) == 0 {\r\n\t\treturn []string{}, db.ErrNoSuchObject\r\n\t}\r\n\treturn snapshots, nil\r\n}","code-length":397,"reference":"\/\/ cephRBDVolumeListSnapshots retrieves the snapshots of an RBD storage volume\n\/\/ The format of the snapshot names is simply the part after the @. So given a\n\/\/ valid RBD path relative to a pool\n\/\/ <osd-pool-name>\/<rbd-storage-volume>@<rbd-snapshot-name>\n\/\/ this will only return\n\/\/ <rbd-snapshot-name>","result":"List all snapshots in a volume.","score":[0.0004,0.0373]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageCeph) getRBDSize() (string, error) {\r\n\tsz, err := shared.ParseByteSizeString(s.volume.Config[\"size\"])\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\t\r\n\tif sz == 0 {\r\n\t\tsz, _ = shared.ParseByteSizeString(\"10GB\")\r\n\t}\r\n\treturn fmt.Sprintf(\"%dB\", sz), nil\r\n}","code-length":121,"reference":"\/\/ getRBDSize returns the size the RBD storage volume is supposed to be created\n\/\/ with","result":"Generate the source code.","score":[0.0159,0.0338]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageCeph) getRBDFilesystem() string {\r\n\tif s.volume.Config[\"block.filesystem\"] != \"\" {\r\n\t\treturn s.volume.Config[\"block.filesystem\"]\r\n\t}\r\n\tif s.pool.Config[\"volume.block.filesystem\"] != \"\" {\r\n\t\treturn s.pool.Config[\"volume.block.filesystem\"]\r\n\t}\r\n\treturn \"ext4\"\r\n}","code-length":111,"reference":"\/\/ getRBDFilesystem returns the filesystem the RBD storage volume is supposed to\n\/\/ be created with","result":"Generate the code for the RBD storage driver.","score":[0.1131,0.2467]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageCeph) copyWithoutSnapshotsFull(target container,\r\n\tsource container) error {\r\n\tlogger.Debugf(`Creating non-sparse copy of RBD storage volume for container \"%s\" to \"%s\" without snapshots`, source.Name(), target.Name())\r\n\tsourceIsSnapshot := source.IsSnapshot()\r\n\tsourceContainerName := projectPrefix(source.Project(), source.Name())\r\n\ttargetContainerName := projectPrefix(target.Project(), target.Name())\r\n\toldVolumeName := fmt.Sprintf(\"%s\/container_%s\", s.OSDPoolName,\r\n\t\tsourceContainerName)\r\n\tnewVolumeName := fmt.Sprintf(\"%s\/container_%s\", s.OSDPoolName,\r\n\t\ttargetContainerName)\r\n\tif sourceIsSnapshot {\r\n\t\tsourceContainerOnlyName, sourceSnapshotOnlyName, _ :=\r\n\t\t\tcontainerGetParentAndSnapshotName(sourceContainerName)\r\n\t\toldVolumeName = fmt.Sprintf(\"%s\/container_%s@snapshot_%s\",\r\n\t\t\ts.OSDPoolName, sourceContainerOnlyName,\r\n\t\t\tsourceSnapshotOnlyName)\r\n\t}\r\n\terr := cephRBDVolumeCopy(s.ClusterName, oldVolumeName, newVolumeName,\r\n\t\ts.UserName)\r\n\tif err != nil {\r\n\t\tlogger.Debugf(`Failed to create full RBD copy \"%s\" to \"%s\": %s`, source.Name(), target.Name(), err)\r\n\t\treturn err\r\n\t}\r\n\t_, err = cephRBDVolumeMap(s.ClusterName, s.OSDPoolName, targetContainerName,\r\n\t\tstoragePoolVolumeTypeNameContainer, s.UserName)\r\n\tif err != nil {\r\n\t\tlogger.Errorf(`Failed to map RBD storage volume for image \"%s\" on storage pool \"%s\": %s`, targetContainerName, s.pool.Name, err)\r\n\t\treturn err\r\n\t}\r\n\ttargetContainerMountPoint := getContainerMountPoint(target.Project(), s.pool.Name, target.Name())\r\n\terr = createContainerMountpoint(targetContainerMountPoint, target.Path(), target.IsPrivileged())\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tourMount, err := target.StorageStart()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif ourMount {\r\n\t\tdefer target.StorageStop()\r\n\t}\r\n\terr = target.TemplateApply(\"copy\")\r\n\tif err != nil {\r\n\t\tlogger.Errorf(`Failed to apply copy template for container \"%s\": %s`, target.Name(), err)\r\n\t\treturn err\r\n\t}\r\n\tlogger.Debugf(`Applied copy template for container \"%s\"`, target.Name())\r\n\tlogger.Debugf(`Created non-sparse copy of RBD storage volume for container \"%s\" to \"%s\" without snapshots`, source.Name(),\r\n\t\ttarget.Name())\r\n\treturn nil\r\n}","code-length":715,"reference":"\/\/ copyWithoutSnapshotsFull creates a non-sparse copy of a container\n\/\/ This does not introduce a dependency relation between the source RBD storage\n\/\/ volume and the target RBD storage volume.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageCeph) copyWithoutSnapshotsSparse(target container,\r\n\tsource container) error {\r\n\tlogger.Debugf(`Creating sparse copy of RBD storage volume for container \"%s\" to \"%s\" without snapshots`, source.Name(),\r\n\t\ttarget.Name())\r\n\tsourceIsSnapshot := source.IsSnapshot()\r\n\tsourceContainerName := projectPrefix(source.Project(), source.Name())\r\n\ttargetContainerName := projectPrefix(target.Project(), target.Name())\r\n\tsourceContainerOnlyName := sourceContainerName\r\n\tsourceSnapshotOnlyName := \"\"\r\n\tsnapshotName := fmt.Sprintf(\"zombie_snapshot_%s\",\r\n\t\tuuid.NewRandom().String())\r\n\tif sourceIsSnapshot {\r\n\t\tsourceContainerOnlyName, sourceSnapshotOnlyName, _ =\r\n\t\t\tcontainerGetParentAndSnapshotName(sourceContainerName)\r\n\t\tsnapshotName = fmt.Sprintf(\"snapshot_%s\", sourceSnapshotOnlyName)\r\n\t} else {\r\n\t\t\r\n\t\terr := cephRBDSnapshotCreate(s.ClusterName, s.OSDPoolName,\r\n\t\t\tsourceContainerName, storagePoolVolumeTypeNameContainer,\r\n\t\t\tsnapshotName, s.UserName)\r\n\t\tif err != nil {\r\n\t\t\tlogger.Errorf(`Failed to create snapshot for RBD storage volume for image \"%s\" on storage pool \"%s\": %s`, targetContainerName, s.pool.Name, err)\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\t\r\n\terr := cephRBDSnapshotProtect(s.ClusterName, s.OSDPoolName,\r\n\t\tsourceContainerOnlyName, storagePoolVolumeTypeNameContainer,\r\n\t\tsnapshotName, s.UserName)\r\n\tif err != nil {\r\n\t\tlogger.Errorf(`Failed to protect snapshot for RBD storage volume for image \"%s\" on storage pool \"%s\": %s`, snapshotName, s.pool.Name, err)\r\n\t\treturn err\r\n\t}\r\n\terr = cephRBDCloneCreate(s.ClusterName, s.OSDPoolName,\r\n\t\tsourceContainerOnlyName, storagePoolVolumeTypeNameContainer,\r\n\t\tsnapshotName, s.OSDPoolName, targetContainerName,\r\n\t\tstoragePoolVolumeTypeNameContainer, s.UserName)\r\n\tif err != nil {\r\n\t\tlogger.Errorf(`Failed to clone new RBD storage volume for container \"%s\": %s`, targetContainerName, err)\r\n\t\treturn err\r\n\t}\r\n\t\r\n\terr = s.cephRBDGenerateUUID(projectPrefix(target.Project(), target.Name()), storagePoolVolumeTypeNameContainer)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\ttargetContainerMountPoint := getContainerMountPoint(target.Project(), s.pool.Name, target.Name())\r\n\terr = createContainerMountpoint(targetContainerMountPoint, target.Path(), target.IsPrivileged())\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tourMount, err := target.StorageStart()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif ourMount {\r\n\t\tdefer target.StorageStop()\r\n\t}\r\n\terr = target.TemplateApply(\"copy\")\r\n\tif err != nil {\r\n\t\tlogger.Errorf(`Failed to apply copy template for container \"%s\": %s`, target.Name(), err)\r\n\t\treturn err\r\n\t}\r\n\tlogger.Debugf(`Applied copy template for container \"%s\"`, target.Name())\r\n\tlogger.Debugf(`Created sparse copy of RBD storage volume for container \"%s\" to \"%s\" without snapshots`, source.Name(),\r\n\t\ttarget.Name())\r\n\treturn nil\r\n}","code-length":893,"reference":"\/\/ copyWithoutSnapshotsFull creates a sparse copy of a container\n\/\/ This introduces a dependency relation between the source RBD storage volume\n\/\/ and the target RBD storage volume.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetConfigCmd(noPortForwarding *bool) *cobra.Command {\r\n\tvar format string\r\n\tgetConfig := &cobra.Command{\r\n\t\tShort: \"Retrieve Pachyderm's current auth configuration\",\r\n\t\tLong:  \"Retrieve Pachyderm's current auth configuration\",\r\n\t\tRun: cmdutil.RunFixedArgs(0, func(args []string) error {\r\n\t\t\tc, err := client.NewOnUserMachine(true, !*noPortForwarding, \"user\")\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"could not connect: %v\", err)\r\n\t\t\t}\r\n\t\t\tdefer c.Close()\r\n\t\t\tresp, err := c.GetConfiguration(c.Ctx(), &auth.GetConfigurationRequest{})\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t\t}\r\n\t\t\tif resp.Configuration == nil {\r\n\t\t\t\tfmt.Println(\"no auth config set\")\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\toutput, err := json.MarshalIndent(resp.Configuration, \"\", \"  \")\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"could not marshal response:\\n%v\\ndue to: %v\", resp.Configuration, err)\r\n\t\t\t}\r\n\t\t\tswitch format {\r\n\t\t\tcase \"json\":\r\n\t\t\t\t\r\n\t\t\tcase \"yaml\":\r\n\t\t\t\toutput, err = yaml.JSONToYAML(output)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn fmt.Errorf(\"could not convert json to yaml: %v\", err)\r\n\t\t\t\t}\r\n\t\t\tdefault:\r\n\t\t\t\treturn fmt.Errorf(\"invalid output format: %v\", format)\r\n\t\t\t}\r\n\t\t\tfmt.Println(string(output))\r\n\t\t\treturn nil\r\n\t\t}),\r\n\t}\r\n\tgetConfig.Flags().StringVarP(&format, \"output-format\", \"o\", \"json\", \"output \"+\r\n\t\t\"format (\\\"json\\\" or \\\"yaml\\\")\")\r\n\treturn cmdutil.CreateAlias(getConfig, \"auth get-config\")\r\n}","code-length":526,"reference":"\/\/ GetConfigCmd returns a cobra command that lets the caller see the configured\n\/\/ auth backends in Pachyderm","result":"Code too long,keep in 512.","score":[0.0178,0.0299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetConfigCmd(noPortForwarding *bool) *cobra.Command {\r\n\tvar file string\r\n\tsetConfig := &cobra.Command{\r\n\t\tShort: \"Set Pachyderm's current auth configuration\",\r\n\t\tLong:  \"Set Pachyderm's current auth configuration\",\r\n\t\tRun: cmdutil.RunFixedArgs(0, func(args []string) error {\r\n\t\t\tc, err := client.NewOnUserMachine(true, !*noPortForwarding, \"user\")\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"could not connect: %v\", err)\r\n\t\t\t}\r\n\t\t\tdefer c.Close()\r\n\t\t\tvar configBytes []byte\r\n\t\t\tif file == \"-\" {\r\n\t\t\t\tvar err error\r\n\t\t\t\tconfigBytes, err = ioutil.ReadAll(os.Stdin)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn fmt.Errorf(\"could not read config from stdin: %v\", err)\r\n\t\t\t\t}\r\n\t\t\t} else if file != \"\" {\r\n\t\t\t\tvar err error\r\n\t\t\t\tconfigBytes, err = ioutil.ReadFile(file)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn fmt.Errorf(\"could not read config from %q: %v\", file, err)\r\n\t\t\t\t}\r\n\t\t\t} else {\r\n\t\t\t\treturn errors.New(\"must set input file (use \\\"-\\\" to read from stdin)\")\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tvar config auth.AuthConfig\r\n\t\t\tif err := yaml.Unmarshal(configBytes, &config); err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"could not parse config: %v\", err)\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\t_, err = c.SetConfiguration(c.Ctx(), &auth.SetConfigurationRequest{\r\n\t\t\t\tConfiguration: &config,\r\n\t\t\t})\r\n\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t}),\r\n\t}\r\n\tsetConfig.Flags().StringVarP(&file, \"file\", \"f\", \"-\", \"input file (to use \"+\r\n\t\t\"as the new config\")\r\n\treturn cmdutil.CreateAlias(setConfig, \"auth set-config\")\r\n}","code-length":542,"reference":"\/\/ SetConfigCmd returns a cobra command that lets the caller configure auth\n\/\/ backends in Pachyderm","result":"Code too long,keep in 512.","score":[0.0266,0.0336]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSharder(discoveryClient discovery.Client, numShards uint64, namespace string) Sharder {\r\n\treturn newSharder(discoveryClient, numShards, namespace)\r\n}","code-length":53,"reference":"\/\/ NewSharder creates a Sharder using a discovery client.","result":"Generate a new sharder.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRouter(\r\n\tsharder Sharder,\r\n\tdialer grpcutil.Dialer,\r\n\tlocalAddress string,\r\n) Router {\r\n\treturn newRouter(\r\n\t\tsharder,\r\n\t\tdialer,\r\n\t\tlocalAddress,\r\n\t)\r\n}","code-length":81,"reference":"\/\/ NewRouter creates a Router.","result":"Create a new router.","score":[0.2488,0.5215]}
{"code":"\/*is used to<extra_id_0>\r\nfunc renewUserCredentials(ctx context.Context, pachdAddress string, adminToken string, userToken string, ttl time.Duration) error {\r\n\t\r\n\tclient, err := pclient.NewFromAddress(pachdAddress)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer client.Close()\r\n\tclient = client.WithCtx(ctx)\r\n\tclient.SetAuthToken(adminToken)\r\n\t_, err = client.AuthAPIClient.ExtendAuthToken(client.Ctx(), &auth.ExtendAuthTokenRequest{\r\n\t\tToken: userToken,\r\n\t\tTTL:   int64(ttl.Seconds()),\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":191,"reference":"\/\/ renewUserCredentials extends the TTL of the Pachyderm authentication token\n\/\/ 'userToken', using the vault plugin's Admin credentials. 'userToken' belongs\n\/\/ to the user who is calling vault, and would like to extend their Pachyderm\n\/\/ session.","result":"Renew user credentials.","score":[0.0,0.0298]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLocalClient(root string) (Client, error) {\r\n\tif err := os.MkdirAll(root, 0755); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &localClient{root}, nil\r\n}","code-length":69,"reference":"\/\/ NewLocalClient returns a Client that stores data on the local file system","result":"Create a local client.","score":[0.04,0.0826]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AddSpanToAnyExisting(ctx context.Context, operation string, kvs ...interface{}) (opentracing.Span, context.Context) {\r\n\tif parentSpan := opentracing.SpanFromContext(ctx); parentSpan != nil {\r\n\t\tspan := opentracing.StartSpan(operation, opentracing.ChildOf(parentSpan.Context()))\r\n\t\ttagSpan(span, kvs)\r\n\t\treturn span, opentracing.ContextWithSpan(ctx, span)\r\n\t}\r\n\treturn nil, ctx\r\n}","code-length":125,"reference":"\/\/ AddSpanToAnyExisting checks 'ctx' for Jaeger tracing information, and if\n\/\/ tracing metadata is present, it generates a new span for 'operation', marks\n\/\/ it as a child of the existing span, and returns it.","result":"Add a new span to any existing spans.","score":[0.0105,0.0977]}
{"code":"\/*is used to<extra_id_0>\r\nfunc InstallJaegerTracerFromEnv() {\r\n\tjaegerOnce.Do(func() {\r\n\t\tjaegerEndpoint, onUserMachine := os.LookupEnv(jaegerEndpointEnvVar)\r\n\t\tif !onUserMachine {\r\n\t\t\tif host, ok := os.LookupEnv(\"JAEGER_COLLECTOR_SERVICE_HOST\"); ok {\r\n\t\t\t\tport := os.Getenv(\"JAEGER_COLLECTOR_SERVICE_PORT_JAEGER_COLLECTOR_HTTP\")\r\n\t\t\t\tjaegerEndpoint = fmt.Sprintf(\"%s:%s\", host, port)\r\n\t\t\t}\r\n\t\t}\r\n\t\tif jaegerEndpoint == \"\" {\r\n\t\t\treturn\r\n\t\t}\r\n\t\tings.TrimPrefix(jaegerEndpoint, \"http:\r\n\t\tjaegerEndpoint = strings.TrimSuffix(jaegerEndpoint, \"\/api\/traces\")\r\n\t\tjaegerEndpoint = fmt.Sprintf(\"http:\r\n\t\tcfg := jaegercfg.Configuration{\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tSampler: &jaegercfg.SamplerConfig{\r\n\t\t\t\tType:  \"const\",\r\n\t\t\t\tParam: 1,\r\n\t\t\t},\r\n\t\t\tReporter: &jaegercfg.ReporterConfig{\r\n\t\t\t\tLogSpans:            true,\r\n\t\t\t\tBufferFlushInterval: 1 * time.Second,\r\n\t\t\t\tCollectorEndpoint:   jaegerEndpoint,\r\n\t\t\t},\r\n\t\t}\r\n\t\t\r\n\t\tlogger := jaeger.Logger(jaeger.NullLogger)\r\n\t\tif !onUserMachine {\r\n\t\t\tlogger = jaeger.StdLogger\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\ttracer, _, err := cfg.New(JaegerServiceName, jaegercfg.Logger(logger))\r\n\t\tif err != nil {\r\n\t\t\tpanic(fmt.Sprintf(\"could not install Jaeger tracer: %v\", err))\r\n\t\t}\r\n\t\topentracing.SetGlobalTracer(tracer)\r\n\t})\r\n}","code-length":501,"reference":"\/\/ InstallJaegerTracerFromEnv installs a Jaeger client as then opentracing\n\/\/ global tracer, relying on environment variables to configure the client. It\n\/\/ returns the address used to initialize the global tracer, if any\n\/\/ initialization occurred","result":"Install Jaeger tracer from environment variables.","score":[0.0015,0.0455]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UnaryClientInterceptor() grpc.UnaryClientInterceptor {\r\n\treturn otgrpc.OpenTracingClientInterceptor(opentracing.GlobalTracer(),\r\n\t\totgrpc.IncludingSpans(addTraceIfTracingEnabled))\r\n}","code-length":57,"reference":"\/\/ UnaryClientInterceptor returns a GRPC interceptor for non-streaming GRPC RPCs","result":"Create the UnaryClientInterceptor.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StreamClientInterceptor() grpc.StreamClientInterceptor {\r\n\treturn otgrpc.OpenTracingStreamClientInterceptor(opentracing.GlobalTracer(),\r\n\t\totgrpc.IncludingSpans(addTraceIfTracingEnabled))\r\n}","code-length":58,"reference":"\/\/ StreamClientInterceptor returns a GRPC interceptor for non-streaming GRPC RPCs","result":"Create a stream client interceptor.","score":[0.0884,0.0526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UnaryServerInterceptor() grpc.UnaryServerInterceptor {\r\n\treturn otgrpc.OpenTracingServerInterceptor(opentracing.GlobalTracer(),\r\n\t\totgrpc.IncludingSpans(addTraceIfTracingEnabled))\r\n}","code-length":57,"reference":"\/\/ UnaryServerInterceptor returns a GRPC interceptor for non-streaming GRPC RPCs","result":"Create the UnaryServerInterceptor.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StreamServerInterceptor() grpc.StreamServerInterceptor {\r\n\treturn otgrpc.OpenTracingStreamServerInterceptor(opentracing.GlobalTracer(),\r\n\t\totgrpc.IncludingSpans(addTraceIfTracingEnabled))\r\n}","code-length":58,"reference":"\/\/ StreamServerInterceptor returns a GRPC interceptor for non-streaming GRPC RPCs","result":"Create a stream server interceptor.","score":[0.0884,0.0526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CloseAndReportTraces() {\r\n\tif c, ok := opentracing.GlobalTracer().(io.Closer); ok {\r\n\t\tc.Close()\r\n\t}\r\n}","code-length":51,"reference":"\/\/ CloseAndReportTraces tries to close the global tracer, which, in the case of\n\/\/ the Jaeger tracer, causes it to send any unreported traces to the collector","result":"Close and report traces.","score":[0,0.0202]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newWriter(ctx context.Context, objC obj.Client, prefix string) *Writer {\r\n\t\r\n\thash := buzhash64.New()\r\n\thash.Write(make([]byte, WindowSize))\r\n\treturn &Writer{\r\n\t\tctx:       ctx,\r\n\t\tobjC:      objC,\r\n\t\tprefix:    prefix,\r\n\t\tcbs:       []func([]*DataRef) error{},\r\n\t\tbuf:       &bytes.Buffer{},\r\n\t\thash:      hash,\r\n\t\tsplitMask: (1 << uint64(AverageBits)) - 1,\r\n\t}\r\n}","code-length":162,"reference":"\/\/ newWriter creates a new Writer.","result":"Create a new writer.","score":[0.274,0.6843]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *ConstantBackOff) For(maxElapsed time.Duration) *ConstantBackOff {\r\n\tb.MaxElapsedTime = maxElapsed\r\n\treturn b\r\n}","code-length":49,"reference":"\/\/ For sets b.MaxElapsedTime to 'maxElapsed' and returns b","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *logger) Log(request interface{}, response interface{}, err error, duration time.Duration) {\r\n\tif err != nil {\r\n\t\tl.LogAtLevelFromDepth(request, response, err, duration, logrus.ErrorLevel, 4)\r\n\t} else {\r\n\t\tl.LogAtLevelFromDepth(request, response, err, duration, logrus.InfoLevel, 4)\r\n\t}\r\n\t\r\n\t\r\n\tgo l.ReportMetric(getMethodName(), duration, err)\r\n}","code-length":131,"reference":"\/\/ Helper function used to log requests and responses from our GRPC method\n\/\/ implementations","result":"Log the request and response to the client.","score":[0.0688,0.3119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f FormatterFunc) Format(entry *logrus.Entry) ([]byte, error) {\r\n\treturn f(entry)\r\n}","code-length":42,"reference":"\/\/ Format proxies the closure in order to satisfy `logrus.Formatter`'s\n\/\/ interface.","result":"Generate the code.","score":[0.0203,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewGRPCLogWriter(logger *logrus.Logger, source string) *GRPCLogWriter {\r\n\treturn &GRPCLogWriter{\r\n\t\tlogger: logger,\r\n\t\tsource: source,\r\n\t}\r\n}","code-length":62,"reference":"\/\/ NewGRPCLogWriter creates a new GRPC log writer. `logger` specifies the\n\/\/ underlying logger, and `source` specifies where these logs are coming from;\n\/\/ it is added as a entry field for all log messages.","result":"Create a new log writer.","score":[0.0011,0.0781]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Read() (*Config, error) {\r\n\tvar c *Config\r\n\t\r\n\tp := configPath()\r\n\tif raw, err := ioutil.ReadFile(p); err == nil {\r\n\t\terr = json.Unmarshal(raw, &c)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t} else if os.IsNotExist(err) {\r\n\t\t\r\n\t\tfmt.Println(\"no config detected at %q. Generating new config...\", p)\r\n\t\tc = &Config{}\r\n\t} else {\r\n\t\treturn nil, fmt.Errorf(\"fatal: could not read config at %q: %v\", p, err)\r\n\t}\r\n\tif c.UserID == \"\" {\r\n\t\tfmt.Printf(\"No UserID present in config. Generating new UserID and \"+\r\n\t\t\t\"updating config at %s\\n\", p)\r\n\t\tuuid, err := uuid.NewV4()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tc.UserID = uuid.String()\r\n\t\tif err := c.Write(); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\treturn c, nil\r\n}","code-length":316,"reference":"\/\/ Read loads the Pachyderm config on this machine.\n\/\/ If an existing configuration cannot be found, it sets up the defaults. Read\n\/\/ returns a nil Config if and only if it returns a non-nil error.","result":"Read the config file.","score":[0.0001,0.0445]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) Write() error {\r\n\trawConfig, err := json.MarshalIndent(c, \"\", \"  \")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tp := configPath()\r\n\tif _, ok := os.LookupEnv(configEnvVar); ok {\r\n\t\t\r\n\t\td := filepath.Dir(p)\r\n\t\tif _, err := os.Stat(d); err != nil {\r\n\t\t\treturn fmt.Errorf(\"cannot use config at %s: could not stat parent directory (%v)\", p, err)\r\n\t\t}\r\n\t} else {\r\n\t\t\r\n\t\terr = os.MkdirAll(defaultConfigDir, 0755)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn ioutil.WriteFile(p, rawConfig, 0644)\r\n}","code-length":223,"reference":"\/\/ Write writes the configuration in 'c' to this machine's Pachyderm config\n\/\/ file.","result":"Write the config file .","score":[0.0523,0.1145]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *readWriter) Read(val proto.Message) error {\r\n\tbuf, err := r.ReadBytes()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn proto.Unmarshal(buf, val)\r\n}","code-length":70,"reference":"\/\/ Read reads val from r.","result":"Read from the reader.","score":[0.2304,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *readWriter) Write(val proto.Message) (int64, error) {\r\n\tbytes, err := proto.Marshal(val)\r\n\tif err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\treturn r.WriteBytes(bytes)\r\n}","code-length":77,"reference":"\/\/ Write writes val to r.","result":"Message to the writer.","score":[0.1938,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewReadWriter(rw io.ReadWriter) ReadWriter {\r\n\treturn &readWriter{r: rw, w: rw}\r\n}","code-length":42,"reference":"\/\/ NewReadWriter returns a new ReadWriter with rw as both its source and its sink.","result":"Generate a new ReadWriter.","score":[0.0289,0.1349]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RunGitHookServer(address string, etcdAddress string, etcdPrefix string) error {\r\n\tc, err := client.NewFromAddress(address)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tetcdClient, err := etcd.New(etcd.Config{\r\n\t\tEndpoints:   []string{etcdAddress},\r\n\t\tDialOptions: client.DefaultDialOptions(),\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\thook, err := github.New()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ts := &gitHookServer{\r\n\t\thook,\r\n\t\tc,\r\n\t\tetcdClient,\r\n\t\tppsdb.Pipelines(etcdClient, etcdPrefix),\r\n\t}\r\n\treturn http.ListenAndServe(fmt.Sprintf(\":%d\", GitHookPort), s)\r\n}","code-length":235,"reference":"\/\/ RunGitHookServer starts the webhook server","result":"Run the git hook server.","score":[0.1967,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newLoggingPipe() *loggingPipe {\r\n\tp := &loggingPipe{}\r\n\tp.clientReader, p.clientWriter = io.Pipe()\r\n\tp.clientReader = io.TeeReader(p.clientReader, &p.ServerToClientBuf)\r\n\tp.serverReader, p.serverWriter = io.Pipe()\r\n\tp.serverReader = io.TeeReader(p.serverReader, &p.ClientToServerBuf)\r\n\treturn p\r\n}","code-length":123,"reference":"\/\/ newLoggingPipe initializes a loggingPipe","result":"Create a new logging pipe.","score":[0.2403,0.1]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *loggingConn) Read(b []byte) (n int, err error) {\r\n\treturn l.r.Read(b)\r\n}","code-length":45,"reference":"\/\/ Read implements the corresponding method of net.Conn","result":"Log the read.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *loggingConn) Write(b []byte) (n int, err error) {\r\n\treturn l.w.Write(b)\r\n}","code-length":45,"reference":"\/\/ Write implements the corresponding method of net.Conn","result":"Log the error.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *TestListener) Accept() (net.Conn, error) {\r\n\tconn := <-l.connCh\r\n\tif conn == nil {\r\n\t\treturn nil, errors.New(\"Accept() has already been called on this TestListener\")\r\n\t}\r\n\treturn conn, nil\r\n}","code-length":80,"reference":"\/\/ Accept implements the corresponding method of net.Listener for\n\/\/ TestListener","result":"Test the code.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *TestListener) Close() error {\r\n\tl.connMu.Lock()\r\n\tdefer l.connMu.Unlock()\r\n\tc := <-l.connCh\r\n\tif c != nil {\r\n\t\tclose(l.connCh)\r\n\t}\r\n\treturn nil\r\n}","code-length":82,"reference":"\/\/ Close implements the corresponding method of net.Listener for\n\/\/ TestListener. Any blocked Accept operations will be unblocked and return\n\/\/ errors.","result":"Close the listener.","score":[0.0009,0.0498]}
{"code":"\/*is used to<extra_id_0>\r\nfunc errorf(c ErrCode, fmtStr string, args ...interface{}) error {\r\n\treturn &hashTreeError{\r\n\t\tcode: c,\r\n\t\ts:    fmt.Sprintf(fmtStr, args...),\r\n\t}\r\n}","code-length":68,"reference":"\/\/ errorf is analogous to fmt.Errorf, but generates hashTreeErrors instead of\n\/\/ errorStrings.","result":"Generate the error message.","score":[0,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc InitWithKube(config *Configuration) *ServiceEnv {\r\n\tenv := InitServiceEnv(config)\r\n\tenv.kubeEg.Go(env.initKubeClient)\r\n\treturn env\r\n}","code-length":59,"reference":"\/\/ InitWithKube is like InitServiceEnv, but also assumes that it's run inside\n\/\/ a kubernetes cluster and tries to connect to the kubernetes API server.","result":"Initialize service env with kube.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (env *ServiceEnv) GetEtcdClient() *etcd.Client {\r\n\tif err := env.etcdEg.Wait(); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tif env.etcdClient == nil {\r\n\t\tpanic(\"service env never connected to etcd\")\r\n\t}\r\n\treturn env.etcdClient\r\n}","code-length":100,"reference":"\/\/ GetEtcdClient returns the already connected etcd client without modification.","result":"Get etcd client from service env.","score":[0.1402,0.1953]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (env *ServiceEnv) GetKubeClient() *kube.Clientset {\r\n\tif err := env.kubeEg.Wait(); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tif env.kubeClient == nil {\r\n\t\tpanic(\"service env never connected to kubernetes\")\r\n\t}\r\n\treturn env.kubeClient\r\n}","code-length":101,"reference":"\/\/ GetKubeClient returns the already connected Kubernetes API client without\n\/\/ modification.","result":"Get the kubernetes client.","score":[0.0432,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewHasher(jobModulus uint64, pipelineModulus uint64) *Hasher {\r\n\treturn &Hasher{\r\n\t\tJobModulus:      jobModulus,\r\n\t\tPipelineModulus: pipelineModulus,\r\n\t}\r\n}","code-length":70,"reference":"\/\/ NewHasher creates a hasher.","result":"PipelineModulus uint.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Hasher) HashJob(jobID string) uint64 {\r\n\treturn uint64(adler32.Checksum([]byte(jobID))) % s.JobModulus\r\n}","code-length":54,"reference":"\/\/ HashJob computes and returns the hash of a job.","result":"Generate the code.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Hasher) HashPipeline(pipelineName string) uint64 {\r\n\treturn uint64(adler32.Checksum([]byte(pipelineName))) % s.PipelineModulus\r\n}","code-length":54,"reference":"\/\/ HashPipeline computes and returns the hash of a pipeline.","result":"Generate the code.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Status(ctx context.Context, pipelineRcName string, etcdClient *etcd.Client, etcdPrefix string, workerGrpcPort uint16) ([]*pps.WorkerStatus, error) {\r\n\tworkerClients, err := Clients(ctx, pipelineRcName, etcdClient, etcdPrefix, workerGrpcPort)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar result []*pps.WorkerStatus\r\n\tfor _, workerClient := range workerClients {\r\n\t\tstatus, err := workerClient.Status(ctx, &types.Empty{})\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tresult = append(result, status)\r\n\t}\r\n\treturn result, nil\r\n}","code-length":193,"reference":"\/\/ Status returns the statuses of workers referenced by pipelineRcName.\n\/\/ pipelineRcName is the name of the pipeline's RC and can be gotten with\n\/\/ ppsutil.PipelineRcName. You can also pass \"\" for pipelineRcName to get all\n\/\/ clients for all workers.","result":"Get the status of all workers.","score":[0.001,0.1137]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Cancel(ctx context.Context, pipelineRcName string, etcdClient *etcd.Client,\r\n\tetcdPrefix string, workerGrpcPort uint16, jobID string, dataFilter []string) error {\r\n\tworkerClients, err := Clients(ctx, pipelineRcName, etcdClient, etcdPrefix, workerGrpcPort)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tsuccess := false\r\n\tfor _, workerClient := range workerClients {\r\n\t\tresp, err := workerClient.Cancel(ctx, &CancelRequest{\r\n\t\t\tJobID:       jobID,\r\n\t\t\tDataFilters: dataFilter,\r\n\t\t})\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif resp.Success {\r\n\t\t\tsuccess = true\r\n\t\t}\r\n\t}\r\n\tif !success {\r\n\t\treturn fmt.Errorf(\"datum matching filter %+v could not be found for jobID %s\", dataFilter, jobID)\r\n\t}\r\n\treturn nil\r\n}","code-length":257,"reference":"\/\/ Cancel cancels a set of datums running on workers.\n\/\/ pipelineRcName is the name of the pipeline's RC and can be gotten with\n\/\/ ppsutil.PipelineRcName.","result":"Cancel a job.","score":[0.0002,0.0422]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Conns(ctx context.Context, pipelineRcName string, etcdClient *etcd.Client, etcdPrefix string, workerGrpcPort uint16) ([]*grpc.ClientConn, error) {\r\n\tresp, err := etcdClient.Get(ctx, path.Join(etcdPrefix, WorkerEtcdPrefix, pipelineRcName), etcd.WithPrefix())\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar result []*grpc.ClientConn\r\n\tfor _, kv := range resp.Kvs {\r\n\t\tconn, err := grpc.Dial(fmt.Sprintf(\"%s:%d\", path.Base(string(kv.Key)), workerGrpcPort),\r\n\t\t\tappend(client.DefaultDialOptions(), grpc.WithInsecure())...)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tresult = append(result, conn)\r\n\t}\r\n\treturn result, nil\r\n}","code-length":236,"reference":"\/\/ Conns returns a slice of connections to worker servers.\n\/\/ pipelineRcName is the name of the pipeline's RC and can be gotten with\n\/\/ ppsutil.PipelineRcName. You can also pass \"\" for pipelineRcName to get all\n\/\/ clients for all workers.","result":"Get the list of connections to the worker.","score":[0.0053,0.1518]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Clients(ctx context.Context, pipelineRcName string, etcdClient *etcd.Client, etcdPrefix string, workerGrpcPort uint16) ([]Client, error) {\r\n\tconns, err := Conns(ctx, pipelineRcName, etcdClient, etcdPrefix, workerGrpcPort)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar result []Client\r\n\tfor _, conn := range conns {\r\n\t\tresult = append(result, newClient(conn))\r\n\t}\r\n\treturn result, nil\r\n}","code-length":142,"reference":"\/\/ Clients returns a slice of worker clients for a pipeline.\n\/\/ pipelineRcName is the name of the pipeline's RC and can be gotten with\n\/\/ ppsutil.PipelineRcName. You can also pass \"\" for pipelineRcName to get all\n\/\/ clients for all workers.","result":"Get the list of clients from the client library.","score":[0.0044,0.1479]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(address string) (Client, error) {\r\n\tport, err := strconv.Atoi(os.Getenv(client.PPSWorkerPortEnv))\r\n\tif err != nil {\r\n\t\treturn Client{}, err\r\n\t}\r\n\tconn, err := grpc.Dial(fmt.Sprintf(\"%s:%d\", address, port),\r\n\t\tappend(client.DefaultDialOptions(), grpc.WithInsecure())...)\r\n\tif err != nil {\r\n\t\treturn Client{}, err\r\n\t}\r\n\treturn newClient(conn), nil\r\n}","code-length":143,"reference":"\/\/ NewClient returns a worker client for the worker at the IP address passed in.","result":"Create a new client.","score":[0.0204,0.036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RunFixedArgs(numArgs int, run func([]string) error) func(*cobra.Command, []string) {\r\n\treturn func(cmd *cobra.Command, args []string) {\r\n\t\tif len(args) != numArgs {\r\n\t\t\tfmt.Printf(\"expected %d arguments, got %d\\n\\n\", numArgs, len(args))\r\n\t\t\tcmd.Usage()\r\n\t\t} else {\r\n\t\t\tif err := run(args); err != nil {\r\n\t\t\t\tErrorAndExit(\"%v\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":156,"reference":"\/\/ RunFixedArgs wraps a function in a function\n\/\/ that checks its exact argument count.","result":"Run the command with fixed arguments.","score":[0,0.0355]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RunBoundedArgs(min int, max int, run func([]string) error) func(*cobra.Command, []string) {\r\n\treturn func(cmd *cobra.Command, args []string) {\r\n\t\tif len(args) < min || len(args) > max {\r\n\t\t\tfmt.Printf(\"expected %d to %d arguments, got %d\\n\\n\", min, max, len(args))\r\n\t\t\tcmd.Usage()\r\n\t\t} else {\r\n\t\t\tif err := run(args); err != nil {\r\n\t\t\t\tErrorAndExit(\"%v\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":169,"reference":"\/\/ RunBoundedArgs wraps a function in a function\n\/\/ that checks its argument count is within a range.","result":"Run the command with the given arguments.","score":[0,0.0296]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Run(run func(args []string) error) func(*cobra.Command, []string) {\r\n\treturn func(_ *cobra.Command, args []string) {\r\n\t\tif err := run(args); err != nil {\r\n\t\t\tErrorAndExit(err.Error())\r\n\t\t}\r\n\t}\r\n}","code-length":89,"reference":"\/\/ Run makes a new cobra run function that wraps the given function.","result":"Run the command.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ErrorAndExit(format string, args ...interface{}) {\r\n\tif errString := strings.TrimSpace(fmt.Sprintf(format, args...)); errString != \"\" {\r\n\t\tfmt.Fprintf(os.Stderr, \"%s\\n\", errString)\r\n\t}\r\n\tos.Exit(1)\r\n}","code-length":86,"reference":"\/\/ ErrorAndExit errors with the given format and args, and then exits.","result":"Avoid error handling.","score":[0,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseCommit(arg string) (*pfs.Commit, error) {\r\n\tparts := strings.SplitN(arg, \"@\", 2)\r\n\tif parts[0] == \"\" {\r\n\t\treturn nil, fmt.Errorf(\"invalid format \\\"%s\\\": repo cannot be empty\", arg)\r\n\t}\r\n\tcommit := &pfs.Commit{\r\n\t\tRepo: &pfs.Repo{\r\n\t\t\tName: parts[0],\r\n\t\t},\r\n\t\tID: \"\",\r\n\t}\r\n\tif len(parts) == 2 {\r\n\t\tcommit.ID = parts[1]\r\n\t}\r\n\treturn commit, nil\r\n}","code-length":166,"reference":"\/\/ ParseCommit takes an argument of the form \"repo[@branch-or-commit]\" and\n\/\/ returns the corresponding *pfs.Commit.","result":"Parse a commit string.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseBranch(arg string) (*pfs.Branch, error) {\r\n\tcommit, err := ParseCommit(arg)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &pfs.Branch{Repo: commit.Repo, Name: commit.ID}, nil\r\n}","code-length":84,"reference":"\/\/ ParseBranch takes an argument of the form \"repo[@branch]\" and\n\/\/ returns the corresponding *pfs.Branch.  This uses ParseCommit under the hood\n\/\/ because a branch name is usually interchangeable with a commit-id.","result":"Parse branch arguments.","score":[0.0,0.0172]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseFile(arg string) (*pfs.File, error) {\r\n\trepoAndRest := strings.SplitN(arg, \"@\", 2)\r\n\tif repoAndRest[0] == \"\" {\r\n\t\treturn nil, fmt.Errorf(\"invalid format \\\"%s\\\": repo cannot be empty\", arg)\r\n\t}\r\n\tfile := &pfs.File{\r\n\t\tCommit: &pfs.Commit{\r\n\t\t\tRepo: &pfs.Repo{\r\n\t\t\t\tName: repoAndRest[0],\r\n\t\t\t},\r\n\t\t\tID: \"\",\r\n\t\t},\r\n\t\tPath: \"\",\r\n\t}\r\n\tif len(repoAndRest) > 1 {\r\n\t\tcommitAndPath := strings.SplitN(repoAndRest[1], \":\", 2)\r\n\t\tif commitAndPath[0] == \"\" {\r\n\t\t\treturn nil, fmt.Errorf(\"invalid format \\\"%s\\\": commit cannot be empty\", arg)\r\n\t\t}\r\n\t\tfile.Commit.ID = commitAndPath[0]\r\n\t\tif len(commitAndPath) > 1 {\r\n\t\t\tfile.Path = commitAndPath[1]\r\n\t\t}\r\n\t}\r\n\treturn file, nil\r\n}","code-length":300,"reference":"\/\/ ParseFile takes an argument of the form \"repo[@branch-or-commit[:path]]\", and\n\/\/ returns the corresponding *pfs.File.","result":"Parse a file from a git repository.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *RepeatedStringArg) Set(s string) error {\r\n\t*r = append(*r, s)\r\n\treturn nil\r\n}","code-length":44,"reference":"\/\/ Set adds a string to r","result":"Set the value of the repeated string arg.","score":[0.1652,0.1408]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetDocsUsage(command *cobra.Command) {\r\n\tcommand.SetHelpTemplate(`{{or .Long .Short}}\r\n{{.UsageString}}\r\n`)\r\n\tcommand.SetUsageFunc(func(cmd *cobra.Command) error {\r\n\t\trootCmd := cmd.Root()\r\n\t\t\r\n\t\tvar associated []*cobra.Command\r\n\t\tvar walk func(*cobra.Command)\r\n\t\twalk = func(cursor *cobra.Command) {\r\n\t\t\tif cursor.Name() == cmd.Name() && cursor.CommandPath() != cmd.CommandPath() {\r\n\t\t\t\tassociated = append(associated, cursor)\r\n\t\t\t}\r\n\t\t\tfor _, subcmd := range cursor.Commands() {\r\n\t\t\t\twalk(subcmd)\r\n\t\t\t}\r\n\t\t}\r\n\t\twalk(rootCmd)\r\n\t\tvar maxCommandPath int\r\n\t\tfor _, x := range associated {\r\n\t\t\tcommandPathLen := len(x.CommandPath())\r\n\t\t\tif commandPathLen > maxCommandPath {\r\n\t\t\t\tmaxCommandPath = commandPathLen\r\n\t\t\t}\r\n\t\t}\r\n\t\ttemplateFuncs := template.FuncMap{\r\n\t\t\t\"pad\": func(s string) string {\r\n\t\t\t\tformat := fmt.Sprintf(\"%%-%ds\", maxCommandPath+1)\r\n\t\t\t\treturn fmt.Sprintf(format, s)\r\n\t\t\t},\r\n\t\t\t\"associated\": func() []*cobra.Command {\r\n\t\t\t\treturn associated\r\n\t\t\t},\r\n\t\t}\r\n\t\ttext := `Associated Commands:{{range associated}}{{if .IsAvailableCommand}}\r\n  {{pad .CommandPath}} {{.Short}}{{end}}{{end}}`\r\n\t\tt := template.New(\"top\")\r\n\t\tt.Funcs(templateFuncs)\r\n\t\ttemplate.Must(t.Parse(text))\r\n\t\treturn t.Execute(cmd.Out(), cmd)\r\n\t})\r\n}","code-length":489,"reference":"\/\/ SetDocsUsage sets the usage string for a docs-style command.  Docs commands\n\/\/ have no functionality except to output some docs and related commands, and\n\/\/ should not specify a 'Run' attribute.","result":"Set usage for docs.","score":[0.0003,0.0514]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *apiServer) makeCronCommits(pachClient *client.APIClient, in *pps.Input) error {\r\n\tschedule, err := cron.ParseStandard(in.Cron.Spec)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tcommitInfo, err := pachClient.InspectCommit(in.Cron.Repo, \"master\")\r\n\tif err != nil && !isNilBranchErr(err) {\r\n\t\treturn err\r\n\t} else if commitInfo != nil && commitInfo.Finished == nil {\r\n\t\t\r\n\t\tif err = pachClient.DeleteCommit(in.Cron.Repo, \"master\"); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tvar latestTime time.Time\r\n\tfiles, err := pachClient.ListFile(in.Cron.Repo, \"master\", \"\")\r\n\tif err != nil && !isNilBranchErr(err) {\r\n\t\treturn err\r\n\t} else if err != nil || len(files) == 0 {\r\n\t\t\r\n\t\tlatestTime, err = types.TimestampFromProto(in.Cron.Start)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t} else {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tlatestTime, err = time.Parse(time.RFC3339, path.Base(files[len(files)-1].File.Path))\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tfor {\r\n\t\t\r\n\t\tnext := schedule.Next(latestTime)\r\n\t\t\r\n\t\ttime.Sleep(time.Until(next))\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\t_, err = pachClient.StartCommit(in.Cron.Repo, \"master\")\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif in.Cron.Overwrite {\r\n\t\t\t\r\n\t\t\terr := pachClient.DeleteFile(in.Cron.Repo, \"master\", latestTime.Format(time.RFC3339))\r\n\t\t\tif err != nil && !isNotFoundErr(err) && !isNilBranchErr(err) {\r\n\t\t\t\treturn fmt.Errorf(\"delete error %v\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\t_, err = pachClient.PutFile(in.Cron.Repo, \"master\", next.Format(time.RFC3339), strings.NewReader(\"\"))\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"put error %v\", err)\r\n\t\t}\r\n\t\terr = pachClient.FinishCommit(in.Cron.Repo, \"master\")\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\tlatestTime = next\r\n\t}\r\n}","code-length":713,"reference":"\/\/ makeCronCommits makes commits to a single cron input's repo. It's\n\/\/ a helper function called by monitorPipeline.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *tracingObjClient) Writer(ctx context.Context, name string) (io.WriteCloser, error) {\r\n\tspan, ctx := tracing.AddSpanToAnyExisting(ctx, o.provider+\".Writer\", \"name\", name)\r\n\tif span != nil {\r\n\t\tdefer span.Finish()\r\n\t}\r\n\treturn o.Client.Writer(ctx, name)\r\n}","code-length":103,"reference":"\/\/ Writer implements the corresponding method in the Client interface","result":"Create a new object client.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *tracingObjClient) Reader(ctx context.Context, name string, offset uint64, size uint64) (io.ReadCloser, error) {\r\n\tspan, ctx := tracing.AddSpanToAnyExisting(ctx, o.provider+\".Reader\",\r\n\t\t\"name\", name,\r\n\t\t\"offset\", fmt.Sprintf(\"%d\", offset),\r\n\t\t\"size\", fmt.Sprintf(\"%d\", size))\r\n\tdefer tracing.FinishAnySpan(span)\r\n\treturn o.Client.Reader(ctx, name, offset, size)\r\n}","code-length":142,"reference":"\/\/ Reader implements the corresponding method in the Client interface","result":"Test if the object is not created by the user.","score":[0.1291,0.1]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *tracingObjClient) Delete(ctx context.Context, name string) error {\r\n\tspan, ctx := tracing.AddSpanToAnyExisting(ctx, o.provider+\".Delete\",\r\n\t\t\"name\", name)\r\n\tdefer tracing.FinishAnySpan(span)\r\n\treturn o.Client.Delete(ctx, name)\r\n}","code-length":91,"reference":"\/\/ Delete implements the corresponding method in the Client interface","result":"Trace the call to the provider.","score":[0.1179,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *tracingObjClient) Walk(ctx context.Context, prefix string, fn func(name string) error) error {\r\n\tspan, ctx := tracing.AddSpanToAnyExisting(ctx, o.provider+\".Walk\",\r\n\t\t\"prefix\", prefix)\r\n\tdefer tracing.FinishAnySpan(span)\r\n\treturn o.Client.Walk(ctx, prefix, fn)\r\n}","code-length":101,"reference":"\/\/ Walk implements the corresponding method in the Client interface","result":"Trace the call to the function.","score":[0.1179,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *tracingObjClient) Exists(ctx context.Context, name string) bool {\r\n\tspan, ctx := tracing.AddSpanToAnyExisting(ctx, o.provider+\".Exists\",\r\n\t\t\"name\", name)\r\n\tdefer tracing.FinishAnySpan(span)\r\n\treturn o.Client.Exists(ctx, name)\r\n}","code-length":91,"reference":"\/\/ Exists implements the corresponding method in the Client interface","result":"Test if the object exists.","score":[0.0884,0.0526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetBlock(hash hash.Hash) *Block {\r\n\treturn &Block{\r\n\t\tHash: base64.URLEncoding.EncodeToString(hash.Sum(nil)),\r\n\t}\r\n}","code-length":56,"reference":"\/\/ GetBlock encodes a hash into a readable format in the form of a Block.","result":"Get the block hash.","score":[0.0204,0.036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *healthServer) Health(context.Context, *types.Empty) (*types.Empty, error) {\r\n\tif !h.ready {\r\n\t\treturn nil, fmt.Errorf(\"server not ready\")\r\n\t}\r\n\treturn &types.Empty{}, nil\r\n}","code-length":78,"reference":"\/\/ Health implements the Health method for healthServer.","result":"Test health server.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc split(p string) (string, string) {\r\n\treturn clean(path.Dir(p)), base(p)\r\n}","code-length":41,"reference":"\/\/ split is like path.Split, but uses this library's defaults for canonical\n\/\/ paths","result":"Split a path.","score":[0,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ValidatePath(path string) error {\r\n\tpath = clean(path)\r\n\tmatch, _ := regexp.MatchString(\"^[ -~]+$\", path)\r\n\tif !match {\r\n\t\treturn fmt.Errorf(\"path (%v) invalid: only printable ASCII characters allowed\", path)\r\n\t}\r\n\tif IsGlob(path) {\r\n\t\treturn fmt.Errorf(\"path (%v) invalid: globbing character (%v) not allowed in path\", path, globRegex.FindString(path))\r\n\t}\r\n\treturn nil\r\n}","code-length":140,"reference":"\/\/ ValidatePath checks if a file path is legal","result":"Validate the path.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MatchDatum(filter []string, data []*pps.InputFile) bool {\r\n\t\r\n\t\r\n\tmatchesData := true\r\ndataFilters:\r\n\tfor _, dataFilter := range filter {\r\n\t\tfor _, datum := range data {\r\n\t\t\tif dataFilter == datum.Path ||\r\n\t\t\t\tdataFilter == base64.StdEncoding.EncodeToString(datum.Hash) ||\r\n\t\t\t\tdataFilter == hex.EncodeToString(datum.Hash) {\r\n\t\t\t\tcontinue dataFilters\r\n\t\t\t}\r\n\t\t}\r\n\t\tmatchesData = false\r\n\t\tbreak\r\n\t}\r\n\treturn matchesData\r\n}","code-length":165,"reference":"\/\/ MatchDatum checks if a datum matches a filter.  To match each string in\n\/\/ filter must correspond match at least 1 datum's Path or Hash. Order of\n\/\/ filter and data is irrelevant.","result":"Match data.","score":[0,0.0162]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCacheServer(router shard.Router, shards uint64) CacheServer {\r\n\tserver := &groupCacheServer{\r\n\t\tLogger:      log.NewLogger(\"CacheServer\"),\r\n\t\trouter:      router,\r\n\t\tlocalShards: make(map[uint64]bool),\r\n\t\tshards:      shards,\r\n\t}\r\n\tgroupcache.RegisterPeerPicker(func() groupcache.PeerPicker { return server })\r\n\treturn server\r\n}","code-length":120,"reference":"\/\/ NewCacheServer creates a new CacheServer.","result":"Create a new cache server.","score":[0.2782,0.4991]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *apiServer) authorizePipelineOp(pachClient *client.APIClient, operation pipelineOperation, input *pps.Input, output string) error {\r\n\tctx := pachClient.Ctx()\r\n\tme, err := pachClient.WhoAmI(ctx, &auth.WhoAmIRequest{})\r\n\tif auth.IsErrNotActivated(err) {\r\n\t\treturn nil\r\n\t} else if err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif input != nil {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tvar eg errgroup.Group\r\n\t\tdone := make(map[string]struct{})\r\n\t\tpps.VisitInput(input, func(in *pps.Input) {\r\n\t\t\tvar repo string\r\n\t\t\tif in.Pfs != nil {\r\n\t\t\t\trepo = in.Pfs.Repo\r\n\t\t\t} else {\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tif _, ok := done[repo]; ok {\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tdone[repo] = struct{}{}\r\n\t\t\teg.Go(func() error {\r\n\t\t\t\tresp, err := pachClient.Authorize(ctx, &auth.AuthorizeRequest{\r\n\t\t\t\t\tRepo:  repo,\r\n\t\t\t\t\tScope: auth.Scope_READER,\r\n\t\t\t\t})\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t\tif !resp.Authorized {\r\n\t\t\t\t\treturn &auth.ErrNotAuthorized{\r\n\t\t\t\t\t\tSubject:  me.Username,\r\n\t\t\t\t\t\tRepo:     repo,\r\n\t\t\t\t\t\tRequired: auth.Scope_READER,\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t\treturn nil\r\n\t\t\t})\r\n\t\t})\r\n\t\tif err := eg.Wait(); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tvar required auth.Scope\r\n\tswitch operation {\r\n\tcase pipelineOpCreate:\r\n\t\tif _, err := pachClient.InspectRepo(output); err == nil {\r\n\t\t\treturn fmt.Errorf(\"cannot overwrite repo \\\"%s\\\" with new output repo\", output)\r\n\t\t} else if !isNotFoundErr(err) {\r\n\t\t\treturn err\r\n\t\t}\r\n\tcase pipelineOpListDatum, pipelineOpGetLogs:\r\n\t\trequired = auth.Scope_READER\r\n\tcase pipelineOpUpdate:\r\n\t\trequired = auth.Scope_WRITER\r\n\tcase pipelineOpDelete:\r\n\t\trequired = auth.Scope_OWNER\r\n\tdefault:\r\n\t\treturn fmt.Errorf(\"internal error, unrecognized operation %v\", operation)\r\n\t}\r\n\tif required != auth.Scope_NONE {\r\n\t\tresp, err := pachClient.Authorize(ctx, &auth.AuthorizeRequest{\r\n\t\t\tRepo:  output,\r\n\t\t\tScope: required,\r\n\t\t})\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif !resp.Authorized {\r\n\t\t\treturn &auth.ErrNotAuthorized{\r\n\t\t\t\tSubject:  me.Username,\r\n\t\t\t\tRepo:     output,\r\n\t\t\t\tRequired: required,\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":815,"reference":"\/\/ authorizePipelineOp checks if the user indicated by 'ctx' is authorized\n\/\/ to perform 'operation' on the pipeline in 'info'","result":"Code too long,keep in 512.","score":[0.012,0.027]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *apiServer) sudo(pachClient *client.APIClient, f func(*client.APIClient) error) error {\r\n\t\r\n\tsuperUserTokenOnce.Do(func() {\r\n\t\tb := backoff.NewExponentialBackOff()\r\n\t\tb.MaxElapsedTime = 60 * time.Second\r\n\t\tb.MaxInterval = 5 * time.Second\r\n\t\tif err := backoff.Retry(func() error {\r\n\t\t\tsuperUserTokenCol := col.NewCollection(a.env.GetEtcdClient(), ppsconsts.PPSTokenKey, nil, &types.StringValue{}, nil, nil).ReadOnly(pachClient.Ctx())\r\n\t\t\tvar result types.StringValue\r\n\t\t\tif err := superUserTokenCol.Get(\"\", &result); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tsuperUserToken = result.Value\r\n\t\t\treturn nil\r\n\t\t}, b); err != nil {\r\n\t\t\tpanic(fmt.Sprintf(\"couldn't get PPS superuser token: %v\", err))\r\n\t\t}\r\n\t})\r\n\t\r\n\t\r\n\tsuperUserClient := pachClient.WithCtx(pachClient.Ctx())\r\n\tsuperUserClient.SetAuthToken(superUserToken)\r\n\treturn f(superUserClient)\r\n}","code-length":322,"reference":"\/\/ sudo is a helper function that copies 'pachClient' grants it PPS's superuser\n\/\/ token, and calls 'f' with the superuser client. This helps isolate PPS's use\n\/\/ of its superuser token so that it's not widely copied and is unlikely to\n\/\/ leak authority to parts of the code that aren't supposed to have it.\n\/\/\n\/\/ Note that because the argument to 'f' is a superuser client, it should not\n\/\/ be used to make any calls with unvalidated user input. Any such use could be\n\/\/ exploited to make PPS a confused deputy","result":"Run the command .","score":[0.0,0.0115]}
{"code":"\/*is used to<extra_id_0>\r\nfunc setPipelineDefaults(pipelineInfo *pps.PipelineInfo) {\r\n\tnow := time.Now()\r\n\tif pipelineInfo.Transform.Image == \"\" {\r\n\t\tpipelineInfo.Transform.Image = DefaultUserImage\r\n\t}\r\n\tpps.VisitInput(pipelineInfo.Input, func(input *pps.Input) {\r\n\t\tif input.Pfs != nil {\r\n\t\t\tif input.Pfs.Branch == \"\" {\r\n\t\t\t\tinput.Pfs.Branch = \"master\"\r\n\t\t\t}\r\n\t\t\tif input.Pfs.Name == \"\" {\r\n\t\t\t\tinput.Pfs.Name = input.Pfs.Repo\r\n\t\t\t}\r\n\t\t}\r\n\t\tif input.Cron != nil {\r\n\t\t\tif input.Cron.Start == nil {\r\n\t\t\t\tstart, _ := types.TimestampProto(now)\r\n\t\t\t\tinput.Cron.Start = start\r\n\t\t\t}\r\n\t\t\tif input.Cron.Repo == \"\" {\r\n\t\t\t\tinput.Cron.Repo = fmt.Sprintf(\"%s_%s\", pipelineInfo.Pipeline.Name, input.Cron.Name)\r\n\t\t\t}\r\n\t\t}\r\n\t\tif input.Git != nil {\r\n\t\t\tif input.Git.Branch == \"\" {\r\n\t\t\t\tinput.Git.Branch = \"master\"\r\n\t\t\t}\r\n\t\t\tif input.Git.Name == \"\" {\r\n\t\t\t\t\r\n\t\t\t\tnput.Git.URL), \".\")\r\n\t\t\t\tinput.Git.Name = tokens[0]\r\n\t\t\t}\r\n\t\t}\r\n\t})\r\n\tif pipelineInfo.OutputBranch == \"\" {\r\n\t\t\r\n\t\tpipelineInfo.OutputBranch = \"master\"\r\n\t}\r\n\tif pipelineInfo.CacheSize == \"\" {\r\n\t\tpipelineInfo.CacheSize = \"64M\"\r\n\t}\r\n\tif pipelineInfo.ResourceRequests == nil && pipelineInfo.CacheSize != \"\" {\r\n\t\tpipelineInfo.ResourceRequests = &pps.ResourceSpec{\r\n\t\t\tMemory: pipelineInfo.CacheSize,\r\n\t\t}\r\n\t}\r\n\tif pipelineInfo.MaxQueueSize < 1 {\r\n\t\tpipelineInfo.MaxQueueSize = 1\r\n\t}\r\n\tif pipelineInfo.DatumTries == 0 {\r\n\t\tpipelineInfo.DatumTries = DefaultDatumTries\r\n\t}\r\n}","code-length":560,"reference":"\/\/ setPipelineDefaults sets the default values for a pipeline info","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *apiServer) incrementGCGeneration(ctx context.Context) error {\r\n\tresp, err := a.env.GetEtcdClient().Get(ctx, client.GCGenerationKey)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif resp.Count == 0 {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif _, err := a.env.GetEtcdClient().Put(ctx, client.GCGenerationKey, \"1\"); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t} else {\r\n\t\toldGen, err := strconv.Atoi(string(resp.Kvs[0].Value))\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tnewGen := oldGen + 1\r\n\t\tif _, err := a.env.GetEtcdClient().Put(ctx, client.GCGenerationKey, strconv.Itoa(newGen)); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":258,"reference":"\/\/ incrementGCGeneration increments the GC generation number in etcd","result":"Generate code for the generated code.","score":[0.1171,0.1149]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDebugServer(name string, etcdClient *etcd.Client, etcdPrefix string, workerGrpcPort uint16) debug.DebugServer {\r\n\treturn &debugServer{\r\n\t\tname:           name,\r\n\t\tetcdClient:     etcdClient,\r\n\t\tetcdPrefix:     etcdPrefix,\r\n\t\tworkerGrpcPort: workerGrpcPort,\r\n\t}\r\n}","code-length":103,"reference":"\/\/ NewDebugServer creates a new server that serves the debug api over GRPC","result":"Create a debug server.","score":[0.04,0.2112]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) Health() error {\r\n\t_, err := c.healthClient.Health(c.Ctx(), &types.Empty{})\r\n\treturn grpcutil.ScrubGRPC(err)\r\n}","code-length":59,"reference":"\/\/ Health health checks pachd, it returns an error if pachd isn't healthy.","result":"Check health of a service.","score":[0.0485,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newObjBlockAPIServer(dir string, cacheBytes int64, etcdAddress string, objClient obj.Client, test bool) (*objBlockAPIServer, error) {\r\n\t\r\n\t\r\n\tif err := obj.TestStorage(context.Background(), objClient); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\toneCacheShare := cacheBytes \/ (objectCacheShares + tagCacheShares + objectInfoCacheShares + blockCacheShares)\r\n\ts := &objBlockAPIServer{\r\n\t\tLogger:           log.NewLogger(\"pfs.BlockAPI.Obj\"),\r\n\t\tdir:              dir,\r\n\t\tobjClient:        objClient,\r\n\t\tobjectIndexes:    make(map[string]*pfsclient.ObjectIndex),\r\n\t\tobjectCacheBytes: oneCacheShare * objectCacheShares,\r\n\t}\r\n\tobjectGroupName := \"object\"\r\n\ttagGroupName := \"tag\"\r\n\tobjectInfoGroupName := \"objectInfo\"\r\n\tblockGroupName := \"block\"\r\n\tif test {\r\n\t\tuuid := uuid.New()\r\n\t\tobjectGroupName += uuid\r\n\t\ttagGroupName += uuid\r\n\t\tobjectInfoGroupName += uuid\r\n\t\tblockGroupName += uuid\r\n\t}\r\n\ts.objectCache = groupcache.NewGroup(objectGroupName, oneCacheShare*objectCacheShares, groupcache.GetterFunc(s.objectGetter))\r\n\ts.tagCache = groupcache.NewGroup(tagGroupName, oneCacheShare*tagCacheShares, groupcache.GetterFunc(s.tagGetter))\r\n\ts.objectInfoCache = groupcache.NewGroup(objectInfoGroupName, oneCacheShare*objectInfoCacheShares, groupcache.GetterFunc(s.objectInfoGetter))\r\n\ts.blockCache = groupcache.NewGroup(blockGroupName, oneCacheShare*blockCacheShares, groupcache.GetterFunc(s.blockGetter))\r\n\tif !test {\r\n\t\tRegisterCacheStats(\"tag\", &s.tagCache.Stats)\r\n\t\tRegisterCacheStats(\"object\", &s.objectCache.Stats)\r\n\t\tRegisterCacheStats(\"object_info\", &s.objectInfoCache.Stats)\r\n\t}\r\n\tgo s.watchGC(etcdAddress)\r\n\treturn s, nil\r\n}","code-length":534,"reference":"\/\/ In test mode, we use unique names for cache groups, since we might want\n\/\/ to run multiple block servers locally, which would conflict if groups\n\/\/ had the same name. We also do not report stats to prometheus","result":"Code too long,keep in 512.","score":[0,0.0274]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *objBlockAPIServer) watchGC(etcdAddress string) {\r\n\tb := backoff.NewInfiniteBackOff()\r\n\tbackoff.RetryNotify(func() error {\r\n\t\tetcdClient, err := etcd.New(etcd.Config{\r\n\t\t\tEndpoints:   []string{etcdAddress},\r\n\t\t\tDialOptions: client.DefaultDialOptions(),\r\n\t\t})\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"error instantiating etcd client: %v\", err)\r\n\t\t}\r\n\t\twatcher, err := watch.NewWatcher(context.Background(), etcdClient, \"\", client.GCGenerationKey, nil)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"error instantiating watch stream from generation number: %v\", err)\r\n\t\t}\r\n\t\tdefer watcher.Close()\r\n\t\tfor {\r\n\t\t\tev, ok := <-watcher.Watch()\r\n\t\t\tif ev.Err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"error from generation number watch: %v\", ev.Err)\r\n\t\t\t}\r\n\t\t\tif !ok {\r\n\t\t\t\treturn fmt.Errorf(\"generation number watch stream closed unexpectedly\")\r\n\t\t\t}\r\n\t\t\tnewGen, err := strconv.Atoi(string(ev.Value))\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"error converting the generation number: %v\", err)\r\n\t\t\t}\r\n\t\t\ts.setGeneration(newGen)\r\n\t\t}\r\n\t}, b, func(err error, d time.Duration) error {\r\n\t\tlogrus.Errorf(\"error running GC watcher in block server: %v; retrying in %s\", err, d)\r\n\t\treturn nil\r\n\t})\r\n}","code-length":430,"reference":"\/\/ watchGC watches for GC runs and invalidate all cache when GC happens.","result":"Watch the generation number of the GC server.","score":[0.0743,0.08]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *objBlockAPIServer) splitKey(key string) string {\r\n\tgen := s.getGeneration()\r\n\tif len(key) < prefixLength {\r\n\t\treturn fmt.Sprintf(\"%s.%d\", key, gen)\r\n\t}\r\n\treturn fmt.Sprintf(\"%s.%s.%d\", key[:prefixLength], key[prefixLength:], gen)\r\n}","code-length":99,"reference":"\/\/ splitKey splits a key into the format we want, and also postpends\n\/\/ the generation number","result":"Split the key.","score":[0.0038,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewWriter(w io.Writer, header string) *Writer {\r\n\tif header[len(header)-1] != '\\n' {\r\n\t\tpanic(\"header must end in a new line\")\r\n\t}\r\n\ttabwriter := ansiterm.NewTabWriter(w, 0, 1, 1, ' ', 0)\r\n\ttabwriter.Write([]byte(header))\r\n\treturn &Writer{\r\n\t\tw:      tabwriter,\r\n\t\tlines:  1,\r\n\t\theader: []byte(header),\r\n\t}\r\n}","code-length":142,"reference":"\/\/ NewWriter returns a new Writer, it will flush when\n\/\/ it gets termHeight many lines, including the header line.\n\/\/ The header line will be reprinted termHeight many lines have been written.\n\/\/ NewStreamingWriter will panic if it's given a header that doesn't end in \\n.","result":"Create a new tabwriter.","score":[0.0,0.0234]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *Writer) Write(buf []byte) (int, error) {\r\n\tif w.lines >= termHeight {\r\n\t\tif err := w.Flush(); err != nil {\r\n\t\t\treturn 0, err\r\n\t\t}\r\n\t\tif _, err := w.w.Write(w.header); err != nil {\r\n\t\t\treturn 0, err\r\n\t\t}\r\n\t\tw.lines++\r\n\t}\r\n\tw.lines += bytes.Count(buf, []byte{'\\n'})\r\n\treturn w.w.Write(buf)\r\n}","code-length":149,"reference":"\/\/ Write writes a line to the tabwriter.","result":"Write to a file.","score":[0.1547,0.1974]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PrintRepoHeader(w io.Writer, printAuth bool) {\r\n\tif printAuth {\r\n\t\tfmt.Fprint(w, RepoAuthHeader)\r\n\t\treturn\r\n\t}\r\n\tfmt.Fprint(w, RepoHeader)\r\n}","code-length":71,"reference":"\/\/ PrintRepoHeader prints a repo header.","result":"Print the repo header.","score":[0.274,0.4406]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PrintRepoInfo(w io.Writer, repoInfo *pfs.RepoInfo, fullTimestamps bool) {\r\n\tfmt.Fprintf(w, \"%s\\t\", repoInfo.Repo.Name)\r\n\tif fullTimestamps {\r\n\t\tfmt.Fprintf(w, \"%s\\t\", repoInfo.Created.String())\r\n\t} else {\r\n\t\tfmt.Fprintf(w, \"%s\\t\", pretty.Ago(repoInfo.Created))\r\n\t}\r\n\tfmt.Fprintf(w, \"%s\\t\", units.BytesSize(float64(repoInfo.SizeBytes)))\r\n\tif repoInfo.AuthInfo != nil {\r\n\t\tfmt.Fprintf(w, \"%s\\t\", repoInfo.AuthInfo.AccessLevel.String())\r\n\t}\r\n\tfmt.Fprintln(w)\r\n}","code-length":206,"reference":"\/\/ PrintRepoInfo pretty-prints repo info.","result":"Print the repo info.","score":[0.3519,0.3827]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PrintDetailedRepoInfo(repoInfo *PrintableRepoInfo) error {\r\n\ttemplate, err := template.New(\"RepoInfo\").Funcs(funcMap).Parse(\r\n\t\t`Name: {{.Repo.Name}}{{if .Description}}\r\nDescription: {{.Description}}{{end}}{{if .FullTimestamps}}\r\nCreated: {{.Created}}{{else}}\r\nCreated: {{prettyAgo .Created}}{{end}}\r\nSize of HEAD on master: {{prettySize .SizeBytes}}{{if .AuthInfo}}\r\nAccess level: {{ .AuthInfo.AccessLevel.String }}{{end}}\r\n`)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = template.Execute(os.Stdout, repoInfo)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":216,"reference":"\/\/ PrintDetailedRepoInfo pretty-prints detailed repo info.","result":"Print the repo info for a.","score":[0.193,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PrintBranch(w io.Writer, branchInfo *pfs.BranchInfo) {\r\n\tfmt.Fprintf(w, \"%s\\t\", branchInfo.Branch.Name)\r\n\tif branchInfo.Head != nil {\r\n\t\tfmt.Fprintf(w, \"%s\\t\\n\", branchInfo.Head.ID)\r\n\t} else {\r\n\t\tfmt.Fprintf(w, \"-\\t\\n\")\r\n\t}\r\n}","code-length":116,"reference":"\/\/ PrintBranch pretty-prints a Branch.","result":"Print the branch info.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PrintCommitInfo(w io.Writer, commitInfo *pfs.CommitInfo, fullTimestamps bool) {\r\n\tfmt.Fprintf(w, \"%s\\t\", commitInfo.Commit.Repo.Name)\r\n\tfmt.Fprintf(w, \"%s\\t\", commitInfo.Branch.Name)\r\n\tfmt.Fprintf(w, \"%s\\t\", commitInfo.Commit.ID)\r\n\tif commitInfo.ParentCommit != nil {\r\n\t\tfmt.Fprintf(w, \"%s\\t\", commitInfo.ParentCommit.ID)\r\n\t} else {\r\n\t\tfmt.Fprint(w, \"<none>\\t\")\r\n\t}\r\n\tif fullTimestamps {\r\n\t\tfmt.Fprintf(w, \"%s\\t\", commitInfo.Started.String())\r\n\t} else {\r\n\t\tfmt.Fprintf(w, \"%s\\t\", pretty.Ago(commitInfo.Started))\r\n\t}\r\n\tif commitInfo.Finished != nil {\r\n\t\tfmt.Fprintf(w, fmt.Sprintf(\"%s\\t\", pretty.TimeDifference(commitInfo.Started, commitInfo.Finished)))\r\n\t\tfmt.Fprintf(w, \"%s\\t\\n\", units.BytesSize(float64(commitInfo.SizeBytes)))\r\n\t} else {\r\n\t\tfmt.Fprintf(w, \"-\\t\")\r\n\t\t\r\n\t\tfmt.Fprintf(w, \"-\\t\\n\")\r\n\t}\r\n}","code-length":355,"reference":"\/\/ PrintCommitInfo pretty-prints commit info.","result":"Print commit info to the console.","score":[0.193,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PrintDetailedCommitInfo(commitInfo *PrintableCommitInfo) error {\r\n\ttemplate, err := template.New(\"CommitInfo\").Funcs(funcMap).Parse(\r\n\t\t`Commit: {{.Commit.Repo.Name}}@{{.Commit.ID}}{{if .Branch}}\r\nOriginal Branch: {{.Branch.Name}}{{end}}{{if .Description}}\r\nDescription: {{.Description}}{{end}}{{if .ParentCommit}}\r\nParent: {{.ParentCommit.ID}}{{end}}{{if .FullTimestamps}}\r\nStarted: {{.Started}}{{else}}\r\nStarted: {{prettyAgo .Started}}{{end}}{{if .Finished}}{{if .FullTimestamps}}\r\nFinished: {{.Finished}}{{else}}\r\nFinished: {{prettyAgo .Finished}}{{end}}{{end}}\r\nSize: {{prettySize .SizeBytes}}{{if .Provenance}}\r\nProvenance: {{range .Provenance}} {{.Commit.Repo.Name}}@{{.Commit.ID}} ({{.Branch.Name}}) {{end}} {{end}}\r\n`)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = template.Execute(os.Stdout, commitInfo)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":329,"reference":"\/\/ PrintDetailedCommitInfo pretty-prints detailed commit info.","result":"Print the commit info.","score":[0.274,0.3233]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PrintFileInfo(w io.Writer, fileInfo *pfs.FileInfo, fullTimestamps bool) {\r\n\tfmt.Fprintf(w, \"%s\\t\", fileInfo.File.Commit.ID)\r\n\tfmt.Fprintf(w, \"%s\\t\", fileInfo.File.Path)\r\n\tif fileInfo.FileType == pfs.FileType_FILE {\r\n\t\tfmt.Fprint(w, \"file\\t\")\r\n\t} else {\r\n\t\tfmt.Fprint(w, \"dir\\t\")\r\n\t}\r\n\tif fileInfo.Committed == nil {\r\n\t\tfmt.Fprintf(w, \"-\\t\")\r\n\t} else if fullTimestamps {\r\n\t\tfmt.Fprintf(w, \"%s\\t\", fileInfo.Committed.String())\r\n\t} else {\r\n\t\tfmt.Fprintf(w, \"%s\\t\", pretty.Ago(fileInfo.Committed))\r\n\t}\r\n\tfmt.Fprintf(w, \"%s\\t\\n\", units.BytesSize(float64(fileInfo.SizeBytes)))\r\n}","code-length":257,"reference":"\/\/ PrintFileInfo pretty-prints file info.\n\/\/ If recurse is false and directory size is 0, display \"-\" instead\n\/\/ If fast is true and file size is 0, display \"-\" instead","result":"Print the file info.","score":[0.0005,0.0353]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PrintDetailedFileInfo(fileInfo *pfs.FileInfo) error {\r\n\ttemplate, err := template.New(\"FileInfo\").Funcs(funcMap).Parse(\r\n\t\t`Path: {{.File.Path}}\r\nType: {{fileType .FileType}}\r\nSize: {{prettySize .SizeBytes}}\r\nChildren: {{range .Children}} {{.}} {{end}}\r\n`)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn template.Execute(os.Stdout, fileInfo)\r\n}","code-length":132,"reference":"\/\/ PrintDetailedFileInfo pretty-prints detailed file info.","result":"Print detailed file info.","score":[0.3991,0.5077]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Add(s string, ancestors int) string {\r\n\treturn fmt.Sprintf(\"%s~%d\", s, ancestors)\r\n}","code-length":41,"reference":"\/\/ Add adds an ancestry reference to the given string.","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RetryNotify(operation Operation, b BackOff, notify Notify) error {\r\n\tvar err error\r\n\tvar next time.Duration\r\n\tb.Reset()\r\n\tfor {\r\n\t\tif err = operation(); err == nil {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tif next = b.NextBackOff(); next == Stop {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif notify != nil {\r\n\t\t\tif err := notify(err, next); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\ttime.Sleep(next)\r\n\t}\r\n}","code-length":162,"reference":"\/\/ RetryNotify calls notify function with the error and wait duration\n\/\/ for each failed attempt before sleep.","result":"Retry the operation.","score":[0.0028,0.0303]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *MergeCache) Get(id int64, w io.Writer, filter Filter) (retErr error) {\r\n\tr, err := c.Cache.Get(fmt.Sprint(id))\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer func() {\r\n\t\tif err := r.Close(); err != nil && retErr == nil {\r\n\t\t\tretErr = err\r\n\t\t}\r\n\t}()\r\n\treturn NewWriter(w).Copy(NewReader(r, filter))\r\n}","code-length":139,"reference":"\/\/ Get does a filtered write of id's hashtree to the passed in io.Writer.","result":"Get the object from.","score":[0.0312,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *MergeCache) Delete(id int64) error {\r\n\treturn c.Cache.Delete(fmt.Sprint(id))\r\n}","code-length":44,"reference":"\/\/ Delete deletes a hashtree from the cache.","result":"Delete the file.","score":[0.0917,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PrintJobInfo(w io.Writer, jobInfo *ppsclient.JobInfo, fullTimestamps bool) {\r\n\tfmt.Fprintf(w, \"%s\\t\", jobInfo.Job.ID)\r\n\tfmt.Fprintf(w, \"%s\\t\", jobInfo.Pipeline.Name)\r\n\tif fullTimestamps {\r\n\t\tfmt.Fprintf(w, \"%s\\t\", jobInfo.Started.String())\r\n\t} else {\r\n\t\tfmt.Fprintf(w, \"%s\\t\", pretty.Ago(jobInfo.Started))\r\n\t}\r\n\tif jobInfo.Finished != nil {\r\n\t\tfmt.Fprintf(w, \"%s\\t\", pretty.TimeDifference(jobInfo.Started, jobInfo.Finished))\r\n\t} else {\r\n\t\tfmt.Fprintf(w, \"-\\t\")\r\n\t}\r\n\tfmt.Fprintf(w, \"%d\\t\", jobInfo.Restart)\r\n\tif jobInfo.DataRecovered != 0 {\r\n\t\tfmt.Fprintf(w, \"%d + %d + %d \/ %d\\t\", jobInfo.DataProcessed, jobInfo.DataSkipped, jobInfo.DataRecovered, jobInfo.DataTotal)\r\n\t} else {\r\n\t\tfmt.Fprintf(w, \"%d + %d \/ %d\\t\", jobInfo.DataProcessed, jobInfo.DataSkipped, jobInfo.DataTotal)\r\n\t}\r\n\tfmt.Fprintf(w, \"%s\\t\", pretty.Size(jobInfo.Stats.DownloadBytes))\r\n\tfmt.Fprintf(w, \"%s\\t\", pretty.Size(jobInfo.Stats.UploadBytes))\r\n\tif jobInfo.State == ppsclient.JobState_JOB_FAILURE {\r\n\t\tfmt.Fprintf(w, \"%s: %s\\t\\n\", jobState(jobInfo.State), safeTrim(jobInfo.Reason, jobReasonLen))\r\n\t} else {\r\n\t\tfmt.Fprintf(w, \"%s\\t\\n\", jobState(jobInfo.State))\r\n\t}\r\n}","code-length":498,"reference":"\/\/ PrintJobInfo pretty-prints job info.","result":"Print job info to the console.","score":[0.193,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PrintPipelineInfo(w io.Writer, pipelineInfo *ppsclient.PipelineInfo, fullTimestamps bool) {\r\n\tfmt.Fprintf(w, \"%s\\t\", pipelineInfo.Pipeline.Name)\r\n\tfmt.Fprintf(w, \"%s\\t\", ShorthandInput(pipelineInfo.Input))\r\n\tif fullTimestamps {\r\n\t\tfmt.Fprintf(w, \"%s\\t\", pipelineInfo.CreatedAt.String())\r\n\t} else {\r\n\t\tfmt.Fprintf(w, \"%s\\t\", pretty.Ago(pipelineInfo.CreatedAt))\r\n\t}\r\n\tfmt.Fprintf(w, \"%s \/ %s\\t\\n\", pipelineState(pipelineInfo.State), jobState(pipelineInfo.LastJobState))\r\n}","code-length":187,"reference":"\/\/ PrintPipelineInfo pretty-prints pipeline info.","result":"Print pipeline information.","score":[0.2096,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PrintWorkerStatus(w io.Writer, workerStatus *ppsclient.WorkerStatus, fullTimestamps bool) {\r\n\tfmt.Fprintf(w, \"%s\\t\", workerStatus.WorkerID)\r\n\tfmt.Fprintf(w, \"%s\\t\", workerStatus.JobID)\r\n\tfor _, datum := range workerStatus.Data {\r\n\t\tfmt.Fprintf(w, datum.Path)\r\n\t}\r\n\tfmt.Fprintf(w, \"\\t\")\r\n\tif fullTimestamps {\r\n\t\tfmt.Fprintf(w, \"%s\\t\", workerStatus.Started.String())\r\n\t} else {\r\n\t\tfmt.Fprintf(w, \"%s\\t\", pretty.Ago(workerStatus.Started))\r\n\t}\r\n\tfmt.Fprintf(w, \"%d\\t\\n\", workerStatus.QueueSize)\r\n}","code-length":214,"reference":"\/\/ PrintWorkerStatus pretty prints a worker status.","result":"Print worker status in the console.","score":[0.1634,0.1449]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PrintDetailedJobInfo(jobInfo *PrintableJobInfo) error {\r\n\ttemplate, err := template.New(\"JobInfo\").Funcs(funcMap).Parse(\r\n\t\t`ID: {{.Job.ID}} {{if .Pipeline}}\r\nPipeline: {{.Pipeline.Name}} {{end}} {{if .ParentJob}}\r\nParent: {{.ParentJob.ID}} {{end}}{{if .FullTimestamps}}\r\nStarted: {{.Started}}{{else}}\r\nStarted: {{prettyAgo .Started}} {{end}}{{if .Finished}}\r\nDuration: {{prettyTimeDifference .Started .Finished}} {{end}}\r\nState: {{jobState .State}}\r\nReason: {{.Reason}}\r\nProcessed: {{.DataProcessed}}\r\nFailed: {{.DataFailed}}\r\nSkipped: {{.DataSkipped}}\r\nRecovered: {{.DataRecovered}}\r\nTotal: {{.DataTotal}}\r\nData Downloaded: {{prettySize .Stats.DownloadBytes}}\r\nData Uploaded: {{prettySize .Stats.UploadBytes}}\r\nDownload Time: {{prettyDuration .Stats.DownloadTime}}\r\nProcess Time: {{prettyDuration .Stats.ProcessTime}}\r\nUpload Time: {{prettyDuration .Stats.UploadTime}}\r\nDatum Timeout: {{.DatumTimeout}}\r\nJob Timeout: {{.JobTimeout}}\r\nWorker Status:\r\n{{workerStatus .}}Restarts: {{.Restart}}\r\nParallelismSpec: {{.ParallelismSpec}}\r\n{{ if .ResourceRequests }}ResourceRequests:\r\n  CPU: {{ .ResourceRequests.Cpu }}\r\n  Memory: {{ .ResourceRequests.Memory }} {{end}}\r\n{{ if .ResourceLimits }}ResourceLimits:\r\n  CPU: {{ .ResourceLimits.Cpu }}\r\n  Memory: {{ .ResourceLimits.Memory }}\r\n  {{ if .ResourceLimits.Gpu }}GPU:\r\n    Type: {{ .ResourceLimits.Gpu.Type }}\r\n    Number: {{ .ResourceLimits.Gpu.Number }} {{end}} {{end}}\r\n{{ if .Service }}Service:\r\n\t{{ if .Service.InternalPort }}InternalPort: {{ .Service.InternalPort }} {{end}}\r\n\t{{ if .Service.ExternalPort }}ExternalPort: {{ .Service.ExternalPort }} {{end}} {{end}}Input:\r\n{{jobInput .}}\r\nTransform:\r\n{{prettyTransform .Transform}} {{if .OutputCommit}}\r\nOutput Commit: {{.OutputCommit.ID}} {{end}} {{ if .StatsCommit }}\r\nStats Commit: {{.StatsCommit.ID}} {{end}} {{ if .Egress }}\r\nEgress: {{.Egress.URL}} {{end}}\r\n`)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = template.Execute(os.Stdout, jobInfo)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":667,"reference":"\/\/ PrintDetailedJobInfo pretty-prints detailed job info.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PrintDetailedPipelineInfo(pipelineInfo *PrintablePipelineInfo) error {\r\n\ttemplate, err := template.New(\"PipelineInfo\").Funcs(funcMap).Parse(\r\n\t\t`Name: {{.Pipeline.Name}}{{if .Description}}\r\nDescription: {{.Description}}{{end}}{{if .FullTimestamps }}\r\nCreated: {{.CreatedAt}}{{ else }}\r\nCreated: {{prettyAgo .CreatedAt}} {{end}}\r\nState: {{pipelineState .State}}\r\nStopped: {{ .Stopped }}\r\nReason: {{.Reason}}\r\nParallelism Spec: {{.ParallelismSpec}}\r\n{{ if .ResourceRequests }}ResourceRequests:\r\n  CPU: {{ .ResourceRequests.Cpu }}\r\n  Memory: {{ .ResourceRequests.Memory }} {{end}}\r\n{{ if .ResourceLimits }}ResourceLimits:\r\n  CPU: {{ .ResourceLimits.Cpu }}\r\n  Memory: {{ .ResourceLimits.Memory }}\r\n  {{ if .ResourceLimits.Gpu }}GPU:\r\n    Type: {{ .ResourceLimits.Gpu.Type }} \r\n    Number: {{ .ResourceLimits.Gpu.Number }} {{end}} {{end}}\r\nDatum Timeout: {{.DatumTimeout}}\r\nJob Timeout: {{.JobTimeout}}\r\nInput:\r\n{{pipelineInput .PipelineInfo}}\r\n{{ if .GithookURL }}Githook URL: {{.GithookURL}} {{end}}\r\nOutput Branch: {{.OutputBranch}}\r\nTransform:\r\n{{prettyTransform .Transform}}\r\n{{ if .Egress }}Egress: {{.Egress.URL}} {{end}}\r\n{{if .RecentError}} Recent Error: {{.RecentError}} {{end}}\r\nJob Counts:\r\n{{jobCounts .JobCounts}}\r\n`)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = template.Execute(os.Stdout, pipelineInfo)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":467,"reference":"\/\/ PrintDetailedPipelineInfo pretty-prints detailed pipeline info.","result":"Print detailed pipeline info.","score":[0.3991,0.5077]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PrintDatumInfo(w io.Writer, datumInfo *ppsclient.DatumInfo) {\r\n\ttotalTime := \"-\"\r\n\tif datumInfo.Stats != nil {\r\n\t\ttotalTime = units.HumanDuration(client.GetDatumTotalTime(datumInfo.Stats))\r\n\t}\r\n\tfmt.Fprintf(w, \"%s\\t%s\\t%s\\n\", datumInfo.Datum.ID, datumState(datumInfo.State), totalTime)\r\n}","code-length":122,"reference":"\/\/ PrintDatumInfo pretty-prints file info.\n\/\/ If recurse is false and directory size is 0, display \"-\" instead\n\/\/ If fast is true and file size is 0, display \"-\" instead","result":"Print the datum info.","score":[0.0004,0.0177]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PrintDetailedDatumInfo(w io.Writer, datumInfo *ppsclient.DatumInfo) {\r\n\tfmt.Fprintf(w, \"ID\\t%s\\n\", datumInfo.Datum.ID)\r\n\tfmt.Fprintf(w, \"Job ID\\t%s\\n\", datumInfo.Datum.Job.ID)\r\n\tfmt.Fprintf(w, \"State\\t%s\\n\", datumInfo.State)\r\n\tfmt.Fprintf(w, \"Data Downloaded\\t%s\\n\", pretty.Size(datumInfo.Stats.DownloadBytes))\r\n\tfmt.Fprintf(w, \"Data Uploaded\\t%s\\n\", pretty.Size(datumInfo.Stats.UploadBytes))\r\n\ttotalTime := client.GetDatumTotalTime(datumInfo.Stats).String()\r\n\tfmt.Fprintf(w, \"Total Time\\t%s\\n\", totalTime)\r\n\tvar downloadTime string\r\n\tdl, err := types.DurationFromProto(datumInfo.Stats.DownloadTime)\r\n\tif err != nil {\r\n\t\tdownloadTime = err.Error()\r\n\t}\r\n\tdownloadTime = dl.String()\r\n\tfmt.Fprintf(w, \"Download Time\\t%s\\n\", downloadTime)\r\n\tvar procTime string\r\n\tproc, err := types.DurationFromProto(datumInfo.Stats.ProcessTime)\r\n\tif err != nil {\r\n\t\tprocTime = err.Error()\r\n\t}\r\n\tprocTime = proc.String()\r\n\tfmt.Fprintf(w, \"Process Time\\t%s\\n\", procTime)\r\n\tvar uploadTime string\r\n\tul, err := types.DurationFromProto(datumInfo.Stats.UploadTime)\r\n\tif err != nil {\r\n\t\tuploadTime = err.Error()\r\n\t}\r\n\tuploadTime = ul.String()\r\n\tfmt.Fprintf(w, \"Upload Time\\t%s\\n\", uploadTime)\r\n\tfmt.Fprintf(w, \"PFS State:\\n\")\r\n\ttw := ansiterm.NewTabWriter(w, 10, 1, 3, ' ', 0)\r\n\tPrintFileHeader(tw)\r\n\tPrintFile(tw, datumInfo.PfsState)\r\n\ttw.Flush()\r\n\tfmt.Fprintf(w, \"Inputs:\\n\")\r\n\ttw = ansiterm.NewTabWriter(w, 10, 1, 3, ' ', 0)\r\n\tPrintFileHeader(tw)\r\n\tfor _, d := range datumInfo.Data {\r\n\t\tPrintFile(tw, d.File)\r\n\t}\r\n\ttw.Flush()\r\n}","code-length":641,"reference":"\/\/ PrintDetailedDatumInfo pretty-prints detailed info about a datum","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PrintFile(w io.Writer, file *pfsclient.File) {\r\n\tfmt.Fprintf(w, \"  %s\\t%s\\t%s\\t\\n\", file.Commit.Repo.Name, file.Commit.ID, file.Path)\r\n}","code-length":75,"reference":"\/\/ PrintFile values for a pfs file.","result":"Print the file.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ShorthandInput(input *ppsclient.Input) string {\r\n\tswitch {\r\n\tcase input == nil:\r\n\t\treturn \"none\"\r\n\tcase input.Pfs != nil:\r\n\t\treturn fmt.Sprintf(\"%s:%s\", input.Pfs.Repo, input.Pfs.Glob)\r\n\tcase input.Cross != nil:\r\n\t\tvar subInput []string\r\n\t\tfor _, input := range input.Cross {\r\n\t\t\tsubInput = append(subInput, ShorthandInput(input))\r\n\t\t}\r\n\t\treturn \"(\" + strings.Join(subInput, \" \u2a2f \") + \")\"\r\n\tcase input.Union != nil:\r\n\t\tvar subInput []string\r\n\t\tfor _, input := range input.Union {\r\n\t\t\tsubInput = append(subInput, ShorthandInput(input))\r\n\t\t}\r\n\t\treturn \"(\" + strings.Join(subInput, \" \u222a \") + \")\"\r\n\tcase input.Cron != nil:\r\n\t\treturn fmt.Sprintf(\"%s:%s\", input.Cron.Name, input.Cron.Spec)\r\n\t}\r\n\treturn \"\"\r\n}","code-length":288,"reference":"\/\/ ShorthandInput renders a pps.Input as a short, readable string","result":"Generate a shorthand input string.","score":[0.0884,0.0526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v *vaultCredentialsProvider) Retrieve() (credentials.Value, error) {\r\n\tvar emptyCreds, result credentials.Value\r\n\t\r\n\tvaultSecret, err := v.vaultClient.Logical().Read(path.Join(\"aws\", \"creds\", v.vaultRole))\r\n\tif err != nil {\r\n\t\treturn emptyCreds, fmt.Errorf(\"could not retrieve creds from vault: %v\", err)\r\n\t}\r\n\taccessKeyIface, accessKeyOk := vaultSecret.Data[\"access_key\"]\r\n\tawsSecretIface, awsSecretOk := vaultSecret.Data[\"secret_key\"]\r\n\tif !accessKeyOk || !awsSecretOk {\r\n\t\treturn emptyCreds, fmt.Errorf(\"aws creds not present in vault response\")\r\n\t}\r\n\t\r\n\tresult.AccessKeyID, accessKeyOk = accessKeyIface.(string)\r\n\tresult.SecretAccessKey, awsSecretOk = awsSecretIface.(string)\r\n\tif !accessKeyOk || !awsSecretOk {\r\n\t\treturn emptyCreds, fmt.Errorf(\"aws creds in vault response were not both strings (%T and %T)\", accessKeyIface, awsSecretIface)\r\n\t}\r\n\t\r\n\tv.updateLease(vaultSecret)\r\n\tgo func() {\r\n\t\tfor {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\trenewInterval := v.getLeaseDuration()\r\n\t\t\tif renewInterval.Seconds() < oneDayInSeconds {\r\n\t\t\t\trenewInterval = oneDayInSeconds * time.Second\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\ttime.Sleep(renewInterval)\r\n\t\t\tbackoff.RetryNotify(func() error {\r\n\t\t\t\t\r\n\t\t\t\tvaultSecret, err := v.vaultClient.Sys().Renew(v.leaseID, twoDaysInSeconds)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t\tv.updateLease(vaultSecret)\r\n\t\t\t\treturn nil\r\n\t\t\t}, backoff.NewExponentialBackOff(), func(err error, _ time.Duration) error {\r\n\t\t\t\tlog.Errorf(\"could not renew vault lease: %v\", err)\r\n\t\t\t\treturn nil\r\n\t\t\t})\r\n\t\t}\r\n\t}()\r\n\t","code-length":530,"reference":"\/\/ Retrieve returns nil if it successfully retrieved the value.  Error is\n\/\/ returned if the value were not obtainable, or empty.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v *vaultCredentialsProvider) IsExpired() bool {\r\n\tv.leaseMu.Lock()\r\n\tdefer v.leaseMu.Unlock()\r\n\treturn time.Now().After(v.leaseLastRenew.Add(v.leaseDuration))\r\n}","code-length":69,"reference":"\/\/ IsExpired returns if the credentials are no longer valid, and need to be\n\/\/ retrieved.","result":"Validate the credentials.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewBranch(repoName string, branchName string) *pfs.Branch {\r\n\treturn &pfs.Branch{\r\n\t\tRepo: NewRepo(repoName),\r\n\t\tName: branchName,\r\n\t}\r\n}","code-length":63,"reference":"\/\/ NewBranch creates a pfs.Branch","result":"Create a new branch.","score":[0.2488,0.3827]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCommit(repoName string, commitID string) *pfs.Commit {\r\n\treturn &pfs.Commit{\r\n\t\tRepo: NewRepo(repoName),\r\n\t\tID:   commitID,\r\n\t}\r\n}","code-length":66,"reference":"\/\/ NewCommit creates a pfs.Commit.","result":"Create a new commit.","score":[0.2488,0.3827]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCommitProvenance(repoName string, branchName string, commitID string) *pfs.CommitProvenance {\r\n\treturn &pfs.CommitProvenance{\r\n\t\tCommit: NewCommit(repoName, commitID),\r\n\t\tBranch: NewBranch(repoName, branchName),\r\n\t}\r\n}","code-length":82,"reference":"\/\/ NewCommitProvenance creates a pfs.CommitProvenance.","result":"Create commit provenance.","score":[0,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFile(repoName string, commitID string, path string) *pfs.File {\r\n\treturn &pfs.File{\r\n\t\tCommit: NewCommit(repoName, commitID),\r\n\t\tPath:   path,\r\n\t}\r\n}","code-length":70,"reference":"\/\/ NewFile creates a pfs.File.","result":"Create a new file.","score":[0.2488,0.3827]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) CreateRepo(repoName string) error {\r\n\t_, err := c.PfsAPIClient.CreateRepo(\r\n\t\tc.Ctx(),\r\n\t\t&pfs.CreateRepoRequest{\r\n\t\t\tRepo: NewRepo(repoName),\r\n\t\t},\r\n\t)\r\n\treturn grpcutil.ScrubGRPC(err)\r\n}","code-length":97,"reference":"\/\/ CreateRepo creates a new Repo object in pfs with the given name. Repos are\n\/\/ the top level data object in pfs and should be used to store data of a\n\/\/ similar type. For example rather than having a single Repo for an entire\n\/\/ project you might have separate Repos for logs, metrics, database dumps etc.","result":"Create a new repo.","score":[0.0,0.028]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) InspectRepo(repoName string) (*pfs.RepoInfo, error) {\r\n\tresp, err := c.PfsAPIClient.InspectRepo(\r\n\t\tc.Ctx(),\r\n\t\t&pfs.InspectRepoRequest{\r\n\t\t\tRepo: NewRepo(repoName),\r\n\t\t},\r\n\t)\r\n\tif err != nil {\r\n\t\treturn nil, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn resp, nil\r\n}","code-length":128,"reference":"\/\/ InspectRepo returns info about a specific Repo.","result":"Call the API client to get the repo info.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) ListRepo() ([]*pfs.RepoInfo, error) {\r\n\trequest := &pfs.ListRepoRequest{}\r\n\trepoInfos, err := c.PfsAPIClient.ListRepo(\r\n\t\tc.Ctx(),\r\n\t\trequest,\r\n\t)\r\n\tif err != nil {\r\n\t\treturn nil, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn repoInfos.RepoInfo, nil\r\n}","code-length":119,"reference":"\/\/ ListRepo returns info about all Repos.\n\/\/ provenance specifies a set of provenance repos, only repos which have ALL of\n\/\/ the specified repos as provenance will be returned unless provenance is nil\n\/\/ in which case it is ignored.","result":"List all repos in a PFS project.","score":[0.0018,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) DeleteRepo(repoName string, force bool) error {\r\n\t_, err := c.PfsAPIClient.DeleteRepo(\r\n\t\tc.Ctx(),\r\n\t\t&pfs.DeleteRepoRequest{\r\n\t\t\tRepo:  NewRepo(repoName),\r\n\t\t\tForce: force,\r\n\t\t},\r\n\t)\r\n\treturn grpcutil.ScrubGRPC(err)\r\n}","code-length":109,"reference":"\/\/ DeleteRepo deletes a repo and reclaims the storage space it was using. Note\n\/\/ that as of 1.0 we do not reclaim the blocks that the Repo was referencing,\n\/\/ this is because they may also be referenced by other Repos and deleting them\n\/\/ would make those Repos inaccessible. This will be resolved in later\n\/\/ versions.\n\/\/ If \"force\" is set to true, the repo will be removed regardless of errors.\n\/\/ This argument should be used with care.","result":"Delete a repo.","score":[0.0,0.0135]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) BuildCommit(repoName string, branch string, parent string, treeObject string) (*pfs.Commit, error) {\r\n\tcommit, err := c.PfsAPIClient.BuildCommit(\r\n\t\tc.Ctx(),\r\n\t\t&pfs.BuildCommitRequest{\r\n\t\t\tParent: NewCommit(repoName, parent),\r\n\t\t\tBranch: branch,\r\n\t\t\tTree:   &pfs.Object{Hash: treeObject},\r\n\t\t},\r\n\t)\r\n\tif err != nil {\r\n\t\treturn nil, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn commit, nil\r\n}","code-length":165,"reference":"\/\/ BuildCommit builds a commit in a single call from an existing HashTree that\n\/\/ has already been written to the object store. Note this is a more advanced\n\/\/ pattern for creating commits that's mostly used internally.","result":"Build a tree object.","score":[0.0001,0.0289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) StartCommitParent(repoName string, branch string, parentCommit string) (*pfs.Commit, error) {\r\n\tcommit, err := c.PfsAPIClient.StartCommit(\r\n\t\tc.Ctx(),\r\n\t\t&pfs.StartCommitRequest{\r\n\t\t\tParent: &pfs.Commit{\r\n\t\t\t\tRepo: &pfs.Repo{\r\n\t\t\t\t\tName: repoName,\r\n\t\t\t\t},\r\n\t\t\t\tID: parentCommit,\r\n\t\t\t},\r\n\t\t\tBranch: branch,\r\n\t\t},\r\n\t)\r\n\tif err != nil {\r\n\t\treturn nil, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn commit, nil\r\n}","code-length":183,"reference":"\/\/ StartCommitParent begins the process of committing data to a Repo. Once started\n\/\/ you can write to the Commit with PutFile and when all the data has been\n\/\/ written you must finish the Commit with FinishCommit. NOTE, data is not\n\/\/ persisted until FinishCommit is called.\n\/\/ branch is a more convenient way to build linear chains of commits. When a\n\/\/ commit is started with a non empty branch the value of branch becomes an\n\/\/ alias for the created Commit. This enables a more intuitive access pattern.\n\/\/ When the commit is started on a branch the previous head of the branch is\n\/\/ used as the parent of the commit.\n\/\/ parentCommit specifies the parent Commit, upon creation the new Commit will\n\/\/ appear identical to the parent Commit, data can safely be added to the new\n\/\/ commit without affecting the contents of the parent Commit. You may pass \"\"\n\/\/ as parentCommit in which case the new Commit will have no parent and will\n\/\/ initially appear empty.","result":"Start a commit parent.","score":[1.032e-19,0.0095]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) FinishCommit(repoName string, commitID string) error {\r\n\t_, err := c.PfsAPIClient.FinishCommit(\r\n\t\tc.Ctx(),\r\n\t\t&pfs.FinishCommitRequest{\r\n\t\t\tCommit: NewCommit(repoName, commitID),\r\n\t\t},\r\n\t)\r\n\treturn grpcutil.ScrubGRPC(err)\r\n}","code-length":104,"reference":"\/\/ FinishCommit ends the process of committing data to a Repo and persists the\n\/\/ Commit. Once a Commit is finished the data becomes immutable and future\n\/\/ attempts to write to it with PutFile will error.","result":"Call the APIClient to call the FinishCommit API.","score":[0.0052,0.0587]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) InspectCommit(repoName string, commitID string) (*pfs.CommitInfo, error) {\r\n\treturn c.inspectCommit(repoName, commitID, pfs.CommitState_STARTED)\r\n}","code-length":64,"reference":"\/\/ InspectCommit returns info about a specific Commit.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) BlockCommit(repoName string, commitID string) (*pfs.CommitInfo, error) {\r\n\treturn c.inspectCommit(repoName, commitID, pfs.CommitState_FINISHED)\r\n}","code-length":64,"reference":"\/\/ BlockCommit returns info about a specific Commit, but blocks until that\n\/\/ commit has been finished.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) ListCommit(repoName string, to string, from string, number uint64) ([]*pfs.CommitInfo, error) {\r\n\tvar result []*pfs.CommitInfo\r\n\tif err := c.ListCommitF(repoName, to, from, number, func(ci *pfs.CommitInfo) error {\r\n\t\tresult = append(result, ci)\r\n\t\treturn nil\r\n\t}); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn result, nil\r\n}","code-length":136,"reference":"\/\/ ListCommit lists commits.\n\/\/ If only `repo` is given, all commits in the repo are returned.\n\/\/ If `to` is given, only the ancestors of `to`, including `to` itself,\n\/\/ are considered.\n\/\/ If `from` is given, only the descendents of `from`, including `from`\n\/\/ itself, are considered.\n\/\/ `number` determines how many commits are returned.  If `number` is 0,\n\/\/ all commits that match the aforementioned criteria are returned.","result":"List commits in a repo.","score":[0.0,0.0233]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) ListCommitF(repoName string, to string, from string, number uint64, f func(*pfs.CommitInfo) error) error {\r\n\treq := &pfs.ListCommitRequest{\r\n\t\tRepo:   NewRepo(repoName),\r\n\t\tNumber: number,\r\n\t}\r\n\tif from != \"\" {\r\n\t\treq.From = NewCommit(repoName, from)\r\n\t}\r\n\tif to != \"\" {\r\n\t\treq.To = NewCommit(repoName, to)\r\n\t}\r\n\tstream, err := c.PfsAPIClient.ListCommitStream(c.Ctx(), req)\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tfor {\r\n\t\tci, err := stream.Recv()\r\n\t\tif err == io.EOF {\r\n\t\t\tbreak\r\n\t\t} else if err != nil {\r\n\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\t\tif err := f(ci); err != nil {\r\n\t\t\tif err == errutil.ErrBreak {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":314,"reference":"\/\/ ListCommitF lists commits, calling f with each commit.\n\/\/ If only `repo` is given, all commits in the repo are returned.\n\/\/ If `to` is given, only the ancestors of `to`, including `to` itself,\n\/\/ are considered.\n\/\/ If `from` is given, only the descendents of `from`, including `from`\n\/\/ itself, are considered.\n\/\/ `number` determines how many commits are returned.  If `number` is 0,\n\/\/ all commits that match the aforementioned criteria are returned.","result":"Generate the generated code.","score":[0.0,0.0073]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) ListCommitByRepo(repoName string) ([]*pfs.CommitInfo, error) {\r\n\treturn c.ListCommit(repoName, \"\", \"\", 0)\r\n}","code-length":54,"reference":"\/\/ ListCommitByRepo lists all commits in a repo.","result":"ListCommitByRepo.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) CreateBranch(repoName string, branch string, commit string, provenance []*pfs.Branch) error {\r\n\tvar head *pfs.Commit\r\n\tif commit != \"\" {\r\n\t\thead = NewCommit(repoName, commit)\r\n\t}\r\n\t_, err := c.PfsAPIClient.CreateBranch(\r\n\t\tc.Ctx(),\r\n\t\t&pfs.CreateBranchRequest{\r\n\t\t\tBranch:     NewBranch(repoName, branch),\r\n\t\t\tHead:       head,\r\n\t\t\tProvenance: provenance,\r\n\t\t},\r\n\t)\r\n\treturn grpcutil.ScrubGRPC(err)\r\n}","code-length":168,"reference":"\/\/ CreateBranch creates a new branch","result":"Create a new branch.","score":[0.274,0.5077]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) InspectBranch(repoName string, branch string) (*pfs.BranchInfo, error) {\r\n\tbranchInfo, err := c.PfsAPIClient.InspectBranch(\r\n\t\tc.Ctx(),\r\n\t\t&pfs.InspectBranchRequest{\r\n\t\t\tBranch: NewBranch(repoName, branch),\r\n\t\t},\r\n\t)\r\n\treturn branchInfo, grpcutil.ScrubGRPC(err)\r\n}","code-length":115,"reference":"\/\/ InspectBranch returns information on a specific PFS branch","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) ListBranch(repoName string) ([]*pfs.BranchInfo, error) {\r\n\tbranchInfos, err := c.PfsAPIClient.ListBranch(\r\n\t\tc.Ctx(),\r\n\t\t&pfs.ListBranchRequest{\r\n\t\t\tRepo: NewRepo(repoName),\r\n\t\t},\r\n\t)\r\n\tif err != nil {\r\n\t\treturn nil, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn branchInfos.BranchInfo, nil\r\n}","code-length":133,"reference":"\/\/ ListBranch lists the active branches on a Repo.","result":"List the branch of a repository.","score":[0.1392,0.3628]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) SetBranch(repoName string, commit string, branch string) error {\r\n\treturn c.CreateBranch(repoName, branch, commit, nil)\r\n}","code-length":51,"reference":"\/\/ SetBranch sets a commit and its ancestors as a branch.\n\/\/ SetBranch is deprecated in favor of CommitBranch.","result":"Set the branch name.","score":[0,0.0286]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) DeleteBranch(repoName string, branch string, force bool) error {\r\n\t_, err := c.PfsAPIClient.DeleteBranch(\r\n\t\tc.Ctx(),\r\n\t\t&pfs.DeleteBranchRequest{\r\n\t\t\tBranch: NewBranch(repoName, branch),\r\n\t\t\tForce:  force,\r\n\t\t},\r\n\t)\r\n\treturn grpcutil.ScrubGRPC(err)\r\n}","code-length":114,"reference":"\/\/ DeleteBranch deletes a branch, but leaves the commits themselves intact.\n\/\/ In other words, those commits can still be accessed via commit IDs and\n\/\/ other branches they happen to be on.","result":"Delete a branch.","score":[0.0,0.0625]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) DeleteCommit(repoName string, commitID string) error {\r\n\t_, err := c.PfsAPIClient.DeleteCommit(\r\n\t\tc.Ctx(),\r\n\t\t&pfs.DeleteCommitRequest{\r\n\t\t\tCommit: NewCommit(repoName, commitID),\r\n\t\t},\r\n\t)\r\n\treturn grpcutil.ScrubGRPC(err)\r\n}","code-length":104,"reference":"\/\/ DeleteCommit deletes a commit.","result":"Delete a commit.","score":[0.2964,0.6134]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) FlushCommit(commits []*pfs.Commit, toRepos []*pfs.Repo) (CommitInfoIterator, error) {\r\n\tctx, cancel := context.WithCancel(c.Ctx())\r\n\tstream, err := c.PfsAPIClient.FlushCommit(\r\n\t\tctx,\r\n\t\t&pfs.FlushCommitRequest{\r\n\t\t\tCommits: commits,\r\n\t\t\tToRepos: toRepos,\r\n\t\t},\r\n\t)\r\n\tif err != nil {\r\n\t\tcancel()\r\n\t\treturn nil, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn &commitInfoIterator{stream, cancel}, nil\r\n}","code-length":171,"reference":"\/\/ FlushCommit returns an iterator that returns commits that have the\n\/\/ specified `commits` as provenance.  Note that the iterator can block if\n\/\/ jobs have not successfully completed. This in effect waits for all of the\n\/\/ jobs that are triggered by a set of commits to complete.\n\/\/\n\/\/ If toRepos is not nil then only the commits up to and including those\n\/\/ repos will be considered, otherwise all repos are considered.\n\/\/\n\/\/ Note that it's never necessary to call FlushCommit to run jobs, they'll\n\/\/ run no matter what, FlushCommit just allows you to wait for them to\n\/\/ complete and see their output once they do.","result":"Stream commits to repos.","score":[0.0,0.0099]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) FlushCommitF(commits []*pfs.Commit, toRepos []*pfs.Repo, f func(*pfs.CommitInfo) error) error {\r\n\tstream, err := c.PfsAPIClient.FlushCommit(\r\n\t\tc.Ctx(),\r\n\t\t&pfs.FlushCommitRequest{\r\n\t\t\tCommits: commits,\r\n\t\t\tToRepos: toRepos,\r\n\t\t},\r\n\t)\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tfor {\r\n\t\tci, err := stream.Recv()\r\n\t\tif err != nil {\r\n\t\t\tif err == io.EOF {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\t\tif err := f(ci); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n}","code-length":238,"reference":"\/\/ FlushCommitF calls f with commits that have the specified `commits` as\n\/\/ provenance. Note that it can block if jobs have not successfully\n\/\/ completed. This in effect waits for all of the jobs that are triggered by a\n\/\/ set of commits to complete.\n\/\/\n\/\/ If toRepos is not nil then only the commits up to and including those repos\n\/\/ will be considered, otherwise all repos are considered.\n\/\/\n\/\/ Note that it's never necessary to call FlushCommit to run jobs, they'll run\n\/\/ no matter what, FlushCommitF just allows you to wait for them to complete and\n\/\/ see their output once they do.","result":"Flush commits to.","score":[1.844e-16,0.0051]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) FlushCommitAll(commits []*pfs.Commit, toRepos []*pfs.Repo) ([]*pfs.CommitInfo, error) {\r\n\tvar result []*pfs.CommitInfo\r\n\tif err := c.FlushCommitF(commits, toRepos, func(ci *pfs.CommitInfo) error {\r\n\t\tresult = append(result, ci)\r\n\t\treturn nil\r\n\t}); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn result, nil\r\n}","code-length":136,"reference":"\/\/ FlushCommitAll returns commits that have the specified `commits` as\n\/\/ provenance. Note that it can block if jobs have not successfully\n\/\/ completed. This in effect waits for all of the jobs that are triggered by a\n\/\/ set of commits to complete.\n\/\/\n\/\/ If toRepos is not nil then only the commits up to and including those repos\n\/\/ will be considered, otherwise all repos are considered.\n\/\/\n\/\/ Note that it's never necessary to call FlushCommit to run jobs, they'll run\n\/\/ no matter what, FlushCommitAll just allows you to wait for them to complete and\n\/\/ see their output once they do.","result":"Flush commits.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) SubscribeCommit(repo string, branch string, from string, state pfs.CommitState) (CommitInfoIterator, error) {\r\n\tctx, cancel := context.WithCancel(c.Ctx())\r\n\treq := &pfs.SubscribeCommitRequest{\r\n\t\tRepo:   NewRepo(repo),\r\n\t\tBranch: branch,\r\n\t\tState:  state,\r\n\t}\r\n\tif from != \"\" {\r\n\t\treq.From = NewCommit(repo, from)\r\n\t}\r\n\tstream, err := c.PfsAPIClient.SubscribeCommit(ctx, req)\r\n\tif err != nil {\r\n\t\tcancel()\r\n\t\treturn nil, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn &commitInfoIterator{stream, cancel}, nil\r\n}","code-length":202,"reference":"\/\/ SubscribeCommit is like ListCommit but it keeps listening for commits as\n\/\/ they come in.","result":"Subscribe to a commit.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) SubscribeCommitF(repo, branch, from string, state pfs.CommitState, f func(*pfs.CommitInfo) error) error {\r\n\treq := &pfs.SubscribeCommitRequest{\r\n\t\tRepo:   NewRepo(repo),\r\n\t\tBranch: branch,\r\n\t\tState:  state,\r\n\t}\r\n\tif from != \"\" {\r\n\t\treq.From = NewCommit(repo, from)\r\n\t}\r\n\tstream, err := c.PfsAPIClient.SubscribeCommit(c.Ctx(), req)\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tfor {\r\n\t\tci, err := stream.Recv()\r\n\t\tif err != nil {\r\n\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\t\tif err := f(ci); err != nil {\r\n\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\t}\r\n}","code-length":253,"reference":"\/\/ SubscribeCommitF is like ListCommit but it calls a callback function with\n\/\/ the results rather than returning an iterator.","result":"Subscribe to commits.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) PutObjectAsync(tags []*pfs.Tag) (*PutObjectWriteCloserAsync, error) {\r\n\tw, err := c.newPutObjectWriteCloserAsync(tags)\r\n\tif err != nil {\r\n\t\treturn nil, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn w, nil\r\n}","code-length":93,"reference":"\/\/ PutObjectAsync puts a value into the object store asynchronously.","result":"Create a new object.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) PutObject(_r io.Reader, tags ...string) (object *pfs.Object, _ int64, retErr error) {\r\n\tr := grpcutil.ReaderWrapper{_r}\r\n\tw, err := c.newPutObjectWriteCloser(tags...)\r\n\tif err != nil {\r\n\t\treturn nil, 0, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tdefer func() {\r\n\t\tif err := w.Close(); err != nil && retErr == nil {\r\n\t\t\tretErr = grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\t\tif retErr == nil {\r\n\t\t\tobject = w.object\r\n\t\t}\r\n\t}()\r\n\tbuf := grpcutil.GetBuffer()\r\n\tdefer grpcutil.PutBuffer(buf)\r\n\twritten, err := io.CopyBuffer(w, r, buf)\r\n\tif err != nil {\r\n\t\treturn nil, 0, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\t\r\n\treturn nil, written, nil\r\n}","code-length":267,"reference":"\/\/ PutObject puts a value into the object store and tags it with 0 or more tags.","result":"Generate the generated code.","score":[0.0124,0.0318]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) PutObjectSplit(_r io.Reader) (objects []*pfs.Object, _ int64, retErr error) {\r\n\tr := grpcutil.ReaderWrapper{_r}\r\n\tw, err := c.newPutObjectSplitWriteCloser()\r\n\tif err != nil {\r\n\t\treturn nil, 0, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tdefer func() {\r\n\t\tif err := w.Close(); err != nil && retErr == nil {\r\n\t\t\tretErr = grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\t\tif retErr == nil {\r\n\t\t\tobjects = w.objects\r\n\t\t}\r\n\t}()\r\n\tbuf := grpcutil.GetBuffer()\r\n\tdefer grpcutil.PutBuffer(buf)\r\n\twritten, err := io.CopyBuffer(w, r, buf)\r\n\tif err != nil {\r\n\t\treturn nil, 0, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\t\r\n\treturn nil, written, nil\r\n}","code-length":264,"reference":"\/\/ PutObjectSplit is the same as PutObject except that the data is splitted\n\/\/ into several smaller objects.  This is primarily useful if you'd like to\n\/\/ be able to resume upload.","result":"Upload a split object to the server.","score":[0.0054,0.0508]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) GetObject(hash string, writer io.Writer) error {\r\n\tgetObjectClient, err := c.ObjectAPIClient.GetObject(\r\n\t\tc.Ctx(),\r\n\t\t&pfs.Object{Hash: hash},\r\n\t)\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tif err := grpcutil.WriteFromStreamingBytesClient(getObjectClient, writer); err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn nil\r\n}","code-length":147,"reference":"\/\/ GetObject gets an object out of the object store by hash.","result":"Generate the generated code.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) GetObjectReader(hash string) (io.ReadCloser, error) {\r\n\tctx, cancel := context.WithCancel(c.Ctx())\r\n\tgetObjectClient, err := c.ObjectAPIClient.GetObject(\r\n\t\tctx,\r\n\t\t&pfs.Object{Hash: hash},\r\n\t)\r\n\tif err != nil {\r\n\t\treturn nil, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn grpcutil.NewStreamingBytesReader(getObjectClient, cancel), nil\r\n}","code-length":137,"reference":"\/\/ GetObjectReader returns a reader for an object in object store by hash.","result":"Get the object reader.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) GetObjects(hashes []string, offset uint64, size uint64, totalSize uint64, writer io.Writer) error {\r\n\tvar objects []*pfs.Object\r\n\tfor _, hash := range hashes {\r\n\t\tobjects = append(objects, &pfs.Object{Hash: hash})\r\n\t}\r\n\tgetObjectsClient, err := c.ObjectAPIClient.GetObjects(\r\n\t\tc.Ctx(),\r\n\t\t&pfs.GetObjectsRequest{\r\n\t\t\tObjects:     objects,\r\n\t\t\tOffsetBytes: offset,\r\n\t\t\tSizeBytes:   size,\r\n\t\t\tTotalSize:   totalSize,\r\n\t\t},\r\n\t)\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tif err := grpcutil.WriteFromStreamingBytesClient(getObjectsClient, writer); err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn nil\r\n}","code-length":248,"reference":"\/\/ GetObjects gets several objects out of the object store by hash.","result":"Generate the generated code.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) TagObject(hash string, tags ...string) error {\r\n\tvar _tags []*pfs.Tag\r\n\tfor _, tag := range tags {\r\n\t\t_tags = append(_tags, &pfs.Tag{Name: tag})\r\n\t}\r\n\tif _, err := c.ObjectAPIClient.TagObject(\r\n\t\tc.Ctx(),\r\n\t\t&pfs.TagObjectRequest{\r\n\t\t\tObject: &pfs.Object{Hash: hash},\r\n\t\t\tTags:   _tags,\r\n\t\t},\r\n\t); err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn nil\r\n}","code-length":176,"reference":"\/\/ TagObject applies a tag to an existing object.","result":"Call the function directly.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) ListObject(f func(*pfs.Object) error) error {\r\n\tlistObjectClient, err := c.ObjectAPIClient.ListObjects(c.Ctx(), &pfs.ListObjectsRequest{})\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tfor {\r\n\t\tobject, err := listObjectClient.Recv()\r\n\t\tif err != nil {\r\n\t\t\tif err == io.EOF {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\t\tif err := f(object); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n}","code-length":187,"reference":"\/\/ ListObject lists objects stored in pfs.","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) InspectObject(hash string) (*pfs.ObjectInfo, error) {\r\n\tvalue, err := c.ObjectAPIClient.InspectObject(\r\n\t\tc.Ctx(),\r\n\t\t&pfs.Object{Hash: hash},\r\n\t)\r\n\tif err != nil {\r\n\t\treturn nil, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn value, nil\r\n}","code-length":111,"reference":"\/\/ InspectObject returns info about an Object.","result":"Call the client to get.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) GetTag(tag string, writer io.Writer) error {\r\n\tgetTagClient, err := c.ObjectAPIClient.GetTag(\r\n\t\tc.Ctx(),\r\n\t\t&pfs.Tag{Name: tag},\r\n\t)\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tif err := grpcutil.WriteFromStreamingBytesClient(getTagClient, writer); err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn nil\r\n}","code-length":148,"reference":"\/\/ GetTag gets an object out of the object store by tag.","result":"Get the object.","score":[0.0203,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) GetTagReader(tag string) (io.ReadCloser, error) {\r\n\tctx, cancel := context.WithCancel(c.Ctx())\r\n\tgetTagClient, err := c.ObjectAPIClient.GetTag(\r\n\t\tctx,\r\n\t\t&pfs.Tag{Name: tag},\r\n\t)\r\n\tif err != nil {\r\n\t\treturn nil, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn grpcutil.NewStreamingBytesReader(getTagClient, cancel), nil\r\n}","code-length":138,"reference":"\/\/ GetTagReader returns a reader for an object in object store by tag.","result":"Get a tag reader.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) ListTag(f func(*pfs.ListTagsResponse) error) error {\r\n\tlistTagClient, err := c.ObjectAPIClient.ListTags(c.Ctx(), &pfs.ListTagsRequest{IncludeObject: true})\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tfor {\r\n\t\tlistTagResponse, err := listTagClient.Recv()\r\n\t\tif err != nil {\r\n\t\t\tif err == io.EOF {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\t\tif err := f(listTagResponse); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n}","code-length":198,"reference":"\/\/ ListTag lists tags stored in pfs.","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) Compact() error {\r\n\t_, err := c.ObjectAPIClient.Compact(\r\n\t\tc.Ctx(),\r\n\t\t&types.Empty{},\r\n\t)\r\n\treturn err\r\n}","code-length":63,"reference":"\/\/ Compact forces compaction of objects.","result":"Compact the object.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) NewPutFileClient() (PutFileClient, error) {\r\n\tpfc, err := c.PfsAPIClient.PutFile(c.Ctx())\r\n\tif err != nil {\r\n\t\treturn nil, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn &putFileClient{c: pfc}, nil\r\n}","code-length":95,"reference":"\/\/ NewPutFileClient returns a new client for putting files into pfs in a single request.","result":"Create a new client for PFS.","score":[0.1348,0.266]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *putFileClient) PutFileOverwrite(repoName string, commitID string, path string, reader io.Reader, overwriteIndex int64) (_ int, retErr error) {\r\n\twriter, err := c.newPutFileWriteCloser(repoName, commitID, path, pfs.Delimiter_NONE, 0, 0, 0, &pfs.OverwriteIndex{Index: overwriteIndex})\r\n\tif err != nil {\r\n\t\treturn 0, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tdefer func() {\r\n\t\tif err := writer.Close(); err != nil && retErr == nil {\r\n\t\t\tretErr = err\r\n\t\t}\r\n\t}()\r\n\twritten, err := io.Copy(writer, reader)\r\n\treturn int(written), grpcutil.ScrubGRPC(err)\r\n}","code-length":207,"reference":"\/\/ PutFileOverwrite is like PutFile but it overwrites the file rather than\n\/\/ appending to it.  overwriteIndex allows you to specify the index of the\n\/\/ object starting from which you'd like to overwrite.  If you want to\n\/\/ overwrite the entire file, specify an index of 0.","result":"Overwrite a file.","score":[0,0.0115]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *putFileClient) Close() error {\r\n\t_, err := c.c.CloseAndRecv()\r\n\treturn grpcutil.ScrubGRPC(err)\r\n}","code-length":52,"reference":"\/\/ Close must be called after you're done using a putFileClient.\n\/\/ Further requests will throw errors.","result":"Close the client.","score":[0.0038,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) CopyFile(srcRepo, srcCommit, srcPath, dstRepo, dstCommit, dstPath string, overwrite bool) error {\r\n\tif _, err := c.PfsAPIClient.CopyFile(c.Ctx(),\r\n\t\t&pfs.CopyFileRequest{\r\n\t\t\tSrc:       NewFile(srcRepo, srcCommit, srcPath),\r\n\t\t\tDst:       NewFile(dstRepo, dstCommit, dstPath),\r\n\t\t\tOverwrite: overwrite,\r\n\t\t}); err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn nil\r\n}","code-length":150,"reference":"\/\/ CopyFile copys a file from one pfs location to another. It can be used on\n\/\/ directories or regular files.","result":"Copy file from source to destination.","score":[0.0248,0.1619]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) GetFile(repoName string, commitID string, path string, offset int64, size int64, writer io.Writer) error {\r\n\tif c.limiter != nil {\r\n\t\tc.limiter.Acquire()\r\n\t\tdefer c.limiter.Release()\r\n\t}\r\n\tapiGetFileClient, err := c.getFile(repoName, commitID, path, offset, size)\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tif err := grpcutil.WriteFromStreamingBytesClient(apiGetFileClient, writer); err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn nil\r\n}","code-length":186,"reference":"\/\/ GetFile returns the contents of a file at a specific Commit.\n\/\/ offset specifies a number of bytes that should be skipped in the beginning of the file.\n\/\/ size limits the total amount of data returned, note you will get fewer bytes\n\/\/ than size if you pass a value larger than the size of the file.\n\/\/ If size is set to 0 then all of the data will be returned.","result":"Get a file by path.","score":[0.0,0.0224]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) GetFileReader(repoName string, commitID string, path string, offset int64, size int64) (io.Reader, error) {\r\n\tapiGetFileClient, err := c.getFile(repoName, commitID, path, offset, size)\r\n\tif err != nil {\r\n\t\treturn nil, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn grpcutil.NewStreamingBytesReader(apiGetFileClient, nil), nil\r\n}","code-length":123,"reference":"\/\/ GetFileReader returns a reader for the contents of a file at a specific Commit.\n\/\/ offset specifies a number of bytes that should be skipped in the beginning of the file.\n\/\/ size limits the total amount of data returned, note you will get fewer bytes\n\/\/ than size if you pass a value larger than the size of the file.\n\/\/ If size is set to 0 then all of the data will be returned.","result":"Stream the contents.","score":[0.0,0.0072]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) GetFileReadSeeker(repoName string, commitID string, path string) (io.ReadSeeker, error) {\r\n\tfileInfo, err := c.InspectFile(repoName, commitID, path)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treader, err := c.GetFileReader(repoName, commitID, path, 0, 0)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &getFileReadSeeker{\r\n\t\tReader: reader,\r\n\t\tfile:   NewFile(repoName, commitID, path),\r\n\t\toffset: 0,\r\n\t\tsize:   int64(fileInfo.SizeBytes),\r\n\t\tc:      c,\r\n\t}, nil\r\n}","code-length":201,"reference":"\/\/ GetFileReadSeeker returns a reader for the contents of a file at a specific\n\/\/ Commit that permits Seeking to different points in the file.","result":"Get a file readSeeker.","score":[0.0024,0.0437]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) InspectFile(repoName string, commitID string, path string) (*pfs.FileInfo, error) {\r\n\treturn c.inspectFile(repoName, commitID, path)\r\n}","code-length":59,"reference":"\/\/ InspectFile returns info about a specific file.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) ListFile(repoName string, commitID string, path string) ([]*pfs.FileInfo, error) {\r\n\tvar result []*pfs.FileInfo\r\n\tif err := c.ListFileF(repoName, commitID, path, 0, func(fi *pfs.FileInfo) error {\r\n\t\tresult = append(result, fi)\r\n\t\treturn nil\r\n\t}); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn result, nil\r\n}","code-length":131,"reference":"\/\/ ListFile returns info about all files in a Commit under path.","result":"List files.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) ListFileHistory(repoName string, commitID string, path string, history int64) ([]*pfs.FileInfo, error) {\r\n\tvar result []*pfs.FileInfo\r\n\tif err := c.ListFileF(repoName, commitID, path, history, func(fi *pfs.FileInfo) error {\r\n\t\tresult = append(result, fi)\r\n\t\treturn nil\r\n\t}); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn result, nil\r\n}","code-length":136,"reference":"\/\/ ListFileHistory returns info about all files and their history in a Commit under path.","result":"List files in a repository.","score":[0.0509,0.1825]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) ListFileF(repoName string, commitID string, path string, history int64, f func(fi *pfs.FileInfo) error) error {\r\n\tfs, err := c.PfsAPIClient.ListFileStream(\r\n\t\tc.Ctx(),\r\n\t\t&pfs.ListFileRequest{\r\n\t\t\tFile:    NewFile(repoName, commitID, path),\r\n\t\t\tHistory: history,\r\n\t\t},\r\n\t)\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tfor {\r\n\t\tfi, err := fs.Recv()\r\n\t\tif err == io.EOF {\r\n\t\t\treturn nil\r\n\t\t} else if err != nil {\r\n\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\t\tif err := f(fi); err != nil {\r\n\t\t\tif err == errutil.ErrBreak {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n}","code-length":266,"reference":"\/\/ ListFileF returns info about all files in a Commit under path, calling f with each FileInfo.","result":"Stream files from a git repository.","score":[0.0367,0.0629]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) Walk(repoName string, commitID string, path string, f WalkFn) error {\r\n\tfs, err := c.PfsAPIClient.WalkFile(\r\n\t\tc.Ctx(),\r\n\t\t&pfs.WalkFileRequest{File: NewFile(repoName, commitID, path)})\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tfor {\r\n\t\tfi, err := fs.Recv()\r\n\t\tif err == io.EOF {\r\n\t\t\treturn nil\r\n\t\t} else if err != nil {\r\n\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\t\tif err := f(fi); err != nil {\r\n\t\t\tif err == errutil.ErrBreak {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n}","code-length":230,"reference":"\/\/ Walk walks the pfs filesystem rooted at path. walkFn will be called for each\n\/\/ file found under path in lexicographical order. This includes both regular\n\/\/ files and directories.","result":"Generate code for the generated code.","score":[0.0036,0.0351]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) DeleteFile(repoName string, commitID string, path string) error {\r\n\t_, err := c.PfsAPIClient.DeleteFile(\r\n\t\tc.Ctx(),\r\n\t\t&pfs.DeleteFileRequest{\r\n\t\t\tFile: NewFile(repoName, commitID, path),\r\n\t\t},\r\n\t)\r\n\treturn err\r\n}","code-length":100,"reference":"\/\/ DeleteFile deletes a file from a Commit.\n\/\/ DeleteFile leaves a tombstone in the Commit, assuming the file isn't written\n\/\/ to later attempting to get the file from the finished commit will result in\n\/\/ not found error.\n\/\/ The file will of course remain intact in the Commit's parent.","result":"Delete a file.","score":[0.0,0.0212]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *PutObjectWriteCloserAsync) Write(p []byte) (int, error) {\r\n\tselect {\r\n\tcase err := <-w.errChan:\r\n\t\tif err != nil {\r\n\t\t\treturn 0, grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\tdefault:\r\n\t\tfor len(w.buf)+len(p) > cap(w.buf) {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\ti := cap(w.buf) - len(w.buf)\r\n\t\t\tw.buf = append(w.buf, p[:i]...)\r\n\t\t\tp = p[i:]\r\n\t\t\tw.writeChan <- w.buf\r\n\t\t\tw.buf = grpcutil.GetBuffer()[:0]\r\n\t\t}\r\n\t\tw.buf = append(w.buf, p...)\r\n\t}\r\n\treturn len(p), nil\r\n}","code-length":226,"reference":"\/\/ Write performs a write.","result":"Write to the writer.","score":[0.2488,0.102]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *PutObjectWriteCloserAsync) Close() error {\r\n\tw.writeChan <- w.buf\r\n\tclose(w.writeChan)\r\n\terr := <-w.errChan\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tw.object, err = w.client.CloseAndRecv()\r\n\treturn grpcutil.ScrubGRPC(err)\r\n}","code-length":113,"reference":"\/\/ Close closes the writer.","result":"Close the object.","score":[0.2493,0.2083]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PrettyPrintVersionNoAdditional(version *pb.Version) string {\r\n\treturn fmt.Sprintf(\"%d.%d.%d\", version.Major, version.Minor, version.Micro)\r\n}","code-length":54,"reference":"\/\/ PrettyPrintVersionNoAdditional returns a version string without\n\/\/ version.Additional.","result":"Print version information.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc recursiveBlockQuoteExamples(parent *cobra.Command) {\r\n\tif parent.Example != \"\" {\r\n\t\tparent.Example = fmt.Sprintf(\"```sh\\n%s\\n```\", parent.Example)\r\n\t}\r\n\tfor _, cmd := range parent.Commands() {\r\n\t\trecursiveBlockQuoteExamples(cmd)\r\n\t}\r\n}","code-length":99,"reference":"\/\/ Walk the command tree, wrap any examples in a block-quote with shell highlighting","result":"Generate the example for block quotes.","score":[0.0509,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc errMissingField(field string) *logical.Response {\r\n\treturn logical.ErrorResponse(fmt.Sprintf(\"missing required field '%s'\", field))\r\n}","code-length":47,"reference":"\/\/ errMissingField returns a logical response error that prints a consistent\n\/\/ error message for when a required field is missing.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc validateFields(req *logical.Request, data *framework.FieldData) error {\r\n\tvar unknownFields []string\r\n\tfor k := range req.Data {\r\n\t\tif _, ok := data.Schema[k]; !ok {\r\n\t\t\tunknownFields = append(unknownFields, k)\r\n\t\t}\r\n\t}\r\n\tif len(unknownFields) > 0 {\r\n\t\treturn fmt.Errorf(\"unknown fields: %q\", unknownFields)\r\n\t}\r\n\treturn nil\r\n}","code-length":129,"reference":"\/\/ validateFields verifies that no bad arguments were given to the request.","result":"Validate the fields of a request.","score":[0.0845,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc putConfig(ctx context.Context, s logical.Storage, cfg *config) error {\r\n\tentry, err := logical.StorageEntryJSON(\"config\", cfg)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"%v: failed to generate storage entry\", err)\r\n\t}\r\n\tif err := s.Put(ctx, entry); err != nil {\r\n\t\treturn fmt.Errorf(\"%v: failed to write configuration to storage\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":127,"reference":"\/\/ putConfig parses and returns the configuration data from the storage backend.","result":"Store the configuration in a file.","score":[0.1004,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getConfig(ctx context.Context, s logical.Storage) (*config, error) {\r\n\tentry, err := s.Get(ctx, \"config\")\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"%v: failed to get config from storage\", err)\r\n\t}\r\n\tif entry == nil || len(entry.Value) == 0 {\r\n\t\treturn nil, errors.New(\"no configuration in storage\")\r\n\t}\r\n\tvar result config\r\n\tif err := entry.DecodeJSON(&result); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"%v: failed to decode configuration\", err)\r\n\t}\r\n\treturn &result, nil\r\n}","code-length":175,"reference":"\/\/ getConfig parses and returns the configuration data from the storage backend.","result":"Get the configuration from the storage.","score":[0.1322,0.3289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Serve(\r\n\tservers ...ServerOptions,\r\n) (retErr error) {\r\n\tfor _, server := range servers {\r\n\t\tif server.RegisterFunc == nil {\r\n\t\t\treturn ErrMustSpecifyRegisterFunc\r\n\t\t}\r\n\t\tif server.Port == 0 {\r\n\t\t\treturn ErrMustSpecifyPort\r\n\t\t}\r\n\t\topts := []grpc.ServerOption{\r\n\t\t\tgrpc.MaxConcurrentStreams(math.MaxUint32),\r\n\t\t\tgrpc.MaxRecvMsgSize(server.MaxMsgSize),\r\n\t\t\tgrpc.MaxSendMsgSize(server.MaxMsgSize),\r\n\t\t\tgrpc.KeepaliveEnforcementPolicy(keepalive.EnforcementPolicy{\r\n\t\t\t\tMinTime:             5 * time.Second,\r\n\t\t\t\tPermitWithoutStream: true,\r\n\t\t\t}),\r\n\t\t\tgrpc.UnaryInterceptor(tracing.UnaryServerInterceptor()),\r\n\t\t\tgrpc.StreamInterceptor(tracing.StreamServerInterceptor()),\r\n\t\t}\r\n\t\tif server.PublicPortTLSAllowed {\r\n\t\t\t\r\n\t\t\tcertPath := path.Join(TLSVolumePath, TLSCertFile)\r\n\t\t\tkeyPath := path.Join(TLSVolumePath, TLSKeyFile)\r\n\t\t\t_, certPathStatErr := os.Stat(certPath)\r\n\t\t\t_, keyPathStatErr := os.Stat(keyPath)\r\n\t\t\tif certPathStatErr != nil {\r\n\t\t\t\tlog.Warnf(\"TLS disabled: could not stat public cert at %s: %v\", certPath, certPathStatErr)\r\n\t\t\t}\r\n\t\t\tif keyPathStatErr != nil {\r\n\t\t\t\tlog.Warnf(\"TLS disabled: could not stat private key at %s: %v\", keyPath, keyPathStatErr)\r\n\t\t\t}\r\n\t\t\tif certPathStatErr == nil && keyPathStatErr == nil {\r\n\t\t\t\t\r\n\t\t\t\ttransportCreds, err := credentials.NewServerTLSFromFile(certPath, keyPath)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn fmt.Errorf(\"couldn't build transport creds: %v\", err)\r\n\t\t\t\t}\r\n\t\t\t\topts = append(opts, grpc.Creds(transportCreds))\r\n\t\t\t}\r\n\t\t}\r\n\t\tgrpcServer := grpc.NewServer(opts...)\r\n\t\tif err := server.RegisterFunc(grpcServer); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tlistener, err := net.Listen(\"tcp\", fmt.Sprintf(\":%d\", server.Port))\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif server.Cancel != nil {\r\n\t\t\tgo func() {\r\n\t\t\t\t<-server.Cancel\r\n\t\t\t\tif err := listener.Close(); err != nil {\r\n\t\t\t\t\tfmt.Printf(\"listener.Close(): %v\\n\", err)\r\n\t\t\t\t}\r\n\t\t\t}()\r\n\t\t}\r\n\t\tif err := grpcServer.Serve(listener); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":739,"reference":"\/\/ Serve serves stuff.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPuller() *Puller {\r\n\treturn &Puller{\r\n\t\terrCh: make(chan error, 1),\r\n\t\tpipes: make(map[string]bool),\r\n\t}\r\n}","code-length":62,"reference":"\/\/ NewPuller creates a new Puller struct.","result":"Create a new puller.","score":[0.2134,0.4395]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Puller) PullTree(client *pachclient.APIClient, root string, tree hashtree.HashTree, pipes bool, concurrency int) error {\r\n\tlimiter := limit.New(concurrency)\r\n\tvar eg errgroup.Group\r\n\tif err := tree.Walk(\"\/\", func(path string, node *hashtree.NodeProto) error {\r\n\t\tif node.FileNode != nil {\r\n\t\t\tpath := filepath.Join(root, path)\r\n\t\t\tvar hashes []string\r\n\t\t\tfor _, object := range node.FileNode.Objects {\r\n\t\t\t\thashes = append(hashes, object.Hash)\r\n\t\t\t}\r\n\t\t\tif pipes {\r\n\t\t\t\treturn p.makePipe(path, func(w io.Writer) error {\r\n\t\t\t\t\treturn client.GetObjects(hashes, 0, 0, uint64(node.SubtreeSize), w)\r\n\t\t\t\t})\r\n\t\t\t}\r\n\t\t\tlimiter.Acquire()\r\n\t\t\teg.Go(func() (retErr error) {\r\n\t\t\t\tdefer limiter.Release()\r\n\t\t\t\treturn p.makeFile(path, func(w io.Writer) error {\r\n\t\t\t\t\treturn client.GetObjects(hashes, 0, 0, uint64(node.SubtreeSize), w)\r\n\t\t\t\t})\r\n\t\t\t})\r\n\t\t}\r\n\t\treturn nil\r\n\t}); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn eg.Wait()\r\n}","code-length":361,"reference":"\/\/ PullTree pulls from a raw HashTree rather than a repo.","result":"Pull a tree.","score":[0.0284,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Push(client *pachclient.APIClient, root string, commit *pfs.Commit, overwrite bool) error {\r\n\tvar g errgroup.Group\r\n\tif err := filepath.Walk(root, func(path string, info os.FileInfo, err error) error {\r\n\t\tg.Go(func() (retErr error) {\r\n\t\t\tif path == root || info.IsDir() {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\tf, err := os.Open(path)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tdefer func() {\r\n\t\t\t\tif err := f.Close(); err != nil && retErr == nil {\r\n\t\t\t\t\tretErr = err\r\n\t\t\t\t}\r\n\t\t\t}()\r\n\t\t\trelPath, err := filepath.Rel(root, path)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif overwrite {\r\n\t\t\t\tif err := client.DeleteFile(commit.Repo.Name, commit.ID, relPath); err != nil {\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\t_, err = client.PutFile(commit.Repo.Name, commit.ID, relPath, f)\r\n\t\t\treturn err\r\n\t\t})\r\n\t\treturn nil\r\n\t}); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn g.Wait()\r\n}","code-length":355,"reference":"\/\/ Push puts files under root into an open commit.","result":"Push files to a repository.","score":[0.1051,0.1053]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PushObj(pachClient *pachclient.APIClient, commit *pfs.Commit, objClient obj.Client, root string) error {\r\n\tvar eg errgroup.Group\r\n\tsem := make(chan struct{}, 200)\r\n\tif err := pachClient.Walk(commit.Repo.Name, commit.ID, \"\", func(fileInfo *pfs.FileInfo) error {\r\n\t\tif fileInfo.FileType != pfs.FileType_FILE {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\teg.Go(func() (retErr error) {\r\n\t\t\tsem <- struct{}{}\r\n\t\t\tdefer func() { <-sem }()\r\n\t\t\tw, err := objClient.Writer(pachClient.Ctx(), filepath.Join(root, fileInfo.File.Path))\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tdefer func() {\r\n\t\t\t\tif err := w.Close(); err != nil && retErr == nil {\r\n\t\t\t\t\tretErr = err\r\n\t\t\t\t}\r\n\t\t\t}()\r\n\t\t\treturn pachClient.GetFile(commit.Repo.Name, commit.ID, fileInfo.File.Path, 0, 0, w)\r\n\t\t})\r\n\t\treturn nil\r\n\t}); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn eg.Wait()\r\n}","code-length":334,"reference":"\/\/ PushObj pushes data from commit to an object store.","result":"Push objects to the server.","score":[0.0884,0.1579]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PushFile(c *pachclient.APIClient, pfc pachclient.PutFileClient, pfsFile *pfs.File, osFile io.ReadSeeker) error {\r\n\tfileInfo, err := c.InspectFile(pfsFile.Commit.Repo.Name, pfsFile.Commit.ID, pfsFile.Path)\r\n\tif err != nil && !isNotExist(err) {\r\n\t\treturn err\r\n\t}\r\n\tvar i int\r\n\tvar object *pfs.Object\r\n\tif fileInfo != nil {\r\n\t\tfor i, object = range fileInfo.Objects {\r\n\t\t\thash := pfs.NewHash()\r\n\t\t\tif _, err := io.CopyN(hash, osFile, pfs.ChunkSize); err != nil {\r\n\t\t\t\tif err == io.EOF {\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif object.Hash != pfs.EncodeHash(hash.Sum(nil)) {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif _, err := osFile.Seek(int64(i)*pfs.ChunkSize, 0); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t_, err = pfc.PutFileOverwrite(pfsFile.Commit.Repo.Name, pfsFile.Commit.ID, pfsFile.Path, osFile, int64(i))\r\n\treturn err\r\n}","code-length":355,"reference":"\/\/ PushFile makes sure that pfsFile has the same content as osFile.","result":"Push files to the server.","score":[0.0593,0.0442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) Dump(w io.Writer) error {\r\n\tgoroClient, err := c.DebugClient.Dump(c.Ctx(), &debug.DumpRequest{})\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn grpcutil.ScrubGRPC(grpcutil.WriteFromStreamingBytesClient(goroClient, w))\r\n}","code-length":106,"reference":"\/\/ Dump writes debug information from the server to w.","result":"Dump debug messages.","score":[0.0471,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) Profile(profile string, duration time.Duration, w io.Writer) error {\r\n\tvar d *types.Duration\r\n\tif duration != 0 {\r\n\t\td = types.DurationProto(duration)\r\n\t}\r\n\tprofileClient, err := c.DebugClient.Profile(c.Ctx(), &debug.ProfileRequest{\r\n\t\tProfile:  profile,\r\n\t\tDuration: d,\r\n\t})\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn grpcutil.ScrubGRPC(grpcutil.WriteFromStreamingBytesClient(profileClient, w))\r\n}","code-length":165,"reference":"\/\/ Profile writes a pprof profile for pachd to w.","result":"Debug the profile of the debug client.","score":[0.1052,0.0515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) Binary(w io.Writer) error {\r\n\tbinaryClient, err := c.DebugClient.Binary(c.Ctx(), &debug.BinaryRequest{})\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn grpcutil.ScrubGRPC(grpcutil.WriteFromStreamingBytesClient(binaryClient, w))\r\n}","code-length":104,"reference":"\/\/ Binary writes the running pachd binary to w.","result":"Debug binary calls.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterCacheStats(cacheName string, groupCacheStats *groupcache.Stats) {\r\n\tc := &cacheStats{\r\n\t\tcacheName:    cacheName,\r\n\t\tdescriptions: make(map[string]*prometheus.Desc),\r\n\t\tstats:        groupCacheStats,\r\n\t}\r\n\tif err := prometheus.Register(c); err != nil {\r\n\t\t\r\n\t\tif _, ok := err.(prometheus.AlreadyRegisteredError); !ok {\r\n\t\t\tlogrus.Infof(\"error registering prometheus metric: %v\", err)\r\n\t\t}\r\n\t}\r\n}","code-length":152,"reference":"\/\/ RegisterCacheStats creates a new wrapper for groupcache stats that implements\n\/\/ the prometheus.Collector interface, and registers it","result":"Register the cache stats in groupcache.","score":[0.0311,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *counter) wait(n int64) {\r\n\tc.mu.Lock()\r\n\tdefer c.mu.Unlock()\r\n\tfor c.n < n {\r\n\t\tc.cond.Wait()\r\n\t}\r\n}","code-length":68,"reference":"\/\/ wait until more than n bytes have been written","result":"Wait for a given n.","score":[0,0.1053]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RunWorkload(\r\n\tclient *client.APIClient,\r\n\trand *rand.Rand,\r\n\tsize int,\r\n) error {\r\n\tworker := newWorker(rand)\r\n\tfor i := 0; i < size; i++ {\r\n\t\tif err := worker.work(client); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tfor _, job := range worker.startedJobs {\r\n\t\tjobInfo, err := client.InspectJob(job.ID, true)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif jobInfo.State != pps.JobState_JOB_SUCCESS {\r\n\t\t\treturn fmt.Errorf(\"job %s failed\", job.ID)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":210,"reference":"\/\/ RunWorkload runs a test workload against a Pachyderm cluster.","result":"Run a workload.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *worker) createRepo(c *client.APIClient) error {\r\n\trepoName := w.randString(10)\r\n\tif err := c.CreateRepo(repoName); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tw.repos = append(w.repos, &pfs.Repo{Name: repoName})\r\n\t\r\n\t\r\n\t\r\n\tcommit, err := c.StartCommit(repoName, \"\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tw.started = append(w.started, commit)\r\n\treturn nil\r\n}","code-length":158,"reference":"\/\/ createRepo creates a new repo in the cluster","result":"Create a new repo.","score":[0.1294,0.3464]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *worker) advanceCommit(c *client.APIClient) error {\r\n\tif len(w.started) >= maxStartedCommits || len(w.finished) == 0 {\r\n\t\t\r\n\t\tif len(w.started) == 0 {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\ti := w.rand.Intn(len(w.started))\r\n\t\tcommit := w.started[i]\r\n\t\t\r\n\t\t\r\n\t\tif _, err := c.PutFile(commit.Repo.Name, commit.ID, w.randString(10), w.reader()); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif err := c.FinishCommit(commit.Repo.Name, commit.ID); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\tw.started = append(w.started[:i], w.started[i+1:]...)\r\n\t\tw.finished = append(w.finished, commit)\r\n\t} else {\r\n\t\t\r\n\t\tcommit := w.finished[w.rand.Intn(len(w.finished))]\r\n\t\tcommit, err := c.StartCommitParent(commit.Repo.Name, \"\", commit.ID)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tw.started = append(w.started, commit)\r\n\t}\r\n\treturn nil\r\n}","code-length":352,"reference":"\/\/ advanceCommit either starts or finishes a commit, depending on the state of\n\/\/ the cluster.","result":"Generate code for the code.","score":[0.0266,0.0336]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RandString(r *rand.Rand, n int) string {\r\n\tb := make([]byte, n)\r\n\tfor i := range b {\r\n\t\tb[i] = letters[r.Intn(len(letters))]\r\n\t}\r\n\treturn string(b)\r\n}","code-length":82,"reference":"\/\/ RandString returns a random alphabetical string of size n","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewReader(rand *rand.Rand, bytes int64) io.Reader {\r\n\treturn &reader{\r\n\t\trand:  rand,\r\n\t\tbytes: bytes,\r\n\t}\r\n}","code-length":58,"reference":"\/\/ NewReader returns a Reader which generates strings of characters.","result":"Generate code.","score":[0,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc iterDir(tx *bolt.Tx, path string, f func(k, v []byte, c *bolt.Cursor) error) error {\r\n\tnode, err := get(tx, path)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif node.DirNode == nil {\r\n\t\treturn errorf(PathConflict, \"the file at \\\"%s\\\" is not a directory\",\r\n\t\t\tpath)\r\n\t}\r\n\tc := NewChildCursor(tx, path)\r\n\tfor k, v := c.K(), c.V(); k != nil; k, v = c.Next() {\r\n\t\tif err := f(k, v, c.c); err != nil {\r\n\t\t\tif err == errutil.ErrBreak {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":227,"reference":"\/\/ iterDir iterates through the nodes under path, it errors with PathNotFound if path doesn't exist, it errors with PathConflict if path exists but isn't a directory.","result":"Iterate over a directory.","score":[0.0014,0.1035]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *dbHashTree) FSSize() int64 {\r\n\trootNode, err := h.Get(\"\/\")\r\n\tif err != nil {\r\n\t\treturn 0\r\n\t}\r\n\treturn rootNode.SubtreeSize\r\n}","code-length":66,"reference":"\/\/ FSSize gets the size of the hashtree","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *dbHashTree) Diff(oldHashTree HashTree, newPath string, oldPath string, recursiveDepth int64, f func(path string, node *NodeProto, new bool) error) (retErr error) {\r\n\t\r\n\told := oldHashTree.(*dbHashTree)\r\n\tif old == nil {\r\n\t\treturn fmt.Errorf(\"unrecognized HashTree type\")\r\n\t}\r\n\trollback := func(tx *bolt.Tx) {\r\n\t\tif err := tx.Rollback(); err != nil && retErr == nil {\r\n\t\t\tretErr = err\r\n\t\t}\r\n\t}\r\n\tvar newTx *bolt.Tx\r\n\tvar oldTx *bolt.Tx\r\n\tif h == oldHashTree {\r\n\t\ttx, err := h.Begin(false)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tnewTx = tx\r\n\t\toldTx = tx\r\n\t\tdefer rollback(tx)\r\n\t} else {\r\n\t\tvar err error\r\n\t\tnewTx, err = h.Begin(false)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdefer rollback(newTx)\r\n\t\toldTx, err = old.Begin(false)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdefer rollback(oldTx)\r\n\t}\r\n\treturn diff(newTx, oldTx, newPath, oldPath, recursiveDepth, f)\r\n}","code-length":378,"reference":"\/\/ Diff returns the diff of two hashtrees at particular paths.","result":"RecursiveDepth int.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *dbHashTree) Serialize(_w io.Writer) error {\r\n\tw := pbutil.NewWriter(_w)\r\n\treturn h.View(func(tx *bolt.Tx) error {\r\n\t\tfor _, bucket := range buckets {\r\n\t\t\tb := tx.Bucket(b(bucket))\r\n\t\t\tif _, err := w.Write(\r\n\t\t\t\t&BucketHeader{\r\n\t\t\t\t\tBucket: bucket,\r\n\t\t\t\t}); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif err := b.ForEach(func(k, v []byte) error {\r\n\t\t\t\tif _, err := w.WriteBytes(k); err != nil {\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t\t_, err := w.WriteBytes(v)\r\n\t\t\t\treturn err\r\n\t\t\t}); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif _, err := w.WriteBytes(SentinelByte); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n}","code-length":278,"reference":"\/\/ Serialize serializes a binary version of the hashtree.","result":"Serialize the hash tree.","score":[0.1088,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *dbHashTree) Deserialize(_r io.Reader) error {\r\n\tr := pbutil.NewReader(_r)\r\n\thdr := &BucketHeader{}\r\n\tbatchSize := 10000\r\n\tkvs := make(chan *keyValue, batchSize\/10)\r\n\t\r\n\teg, copyCtx := errgroup.WithContext(context.Background())\r\n\teg.Go(func() error {\r\n\t\tvar bucket []byte\r\n\t\tfor {\r\n\t\t\tcount := 0\r\n\t\t\tif err := h.Update(func(tx *bolt.Tx) error {\r\n\t\t\t\tif bucket != nil {\r\n\t\t\t\t\ttx.Bucket(bucket).FillPercent = 1\r\n\t\t\t\t}\r\n\t\t\t\tfor kv := range kvs {\r\n\t\t\t\t\tif kv.k == nil {\r\n\t\t\t\t\t\tbucket = kv.v\r\n\t\t\t\t\t\tcontinue\r\n\t\t\t\t\t}\r\n\t\t\t\t\tif err := tx.Bucket(bucket).Put(kv.k, kv.v); err != nil {\r\n\t\t\t\t\t\treturn err\r\n\t\t\t\t\t}\r\n\t\t\t\t\tcount++\r\n\t\t\t\t\tif count >= batchSize {\r\n\t\t\t\t\t\treturn nil\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t\treturn nil\r\n\t\t\t}); err != nil || copyCtx.Err() != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif count <= 0 {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t}\r\n\t})\r\n\teg.Go(func() error {\r\n\t\tdefer close(kvs)\r\n\t\tfor {\r\n\t\t\thdr.Reset()\r\n\t\t\t\r\n\t\t\tif err := r.Read(hdr); err != nil {\r\n\t\t\t\tif err == io.EOF {\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tbucket := b(hdr.Bucket)\r\n\t\t\tselect {\r\n\t\t\tcase kvs <- &keyValue{nil, bucket}:\r\n\t\t\tcase <-copyCtx.Done():\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\tfor {\r\n\t\t\t\t_k, err := r.ReadBytes()\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t\tif bytes.Equal(_k, SentinelByte) {\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\tk := make([]byte, len(_k))\r\n\t\t\t\tcopy(k, _k)\r\n\t\t\t\t_v, err := r.ReadBytes()\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t\tv := make([]byte, len(_v))\r\n\t\t\t\tcopy(v, _v)\r\n\t\t\t\tselect {\r\n\t\t\t\tcase kvs <- &keyValue{k, v}:\r\n\t\t\t\tcase <-copyCtx.Done():\r\n\t\t\t\t\treturn nil\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\treturn eg.Wait()\r\n}","code-length":717,"reference":"\/\/ Deserialize deserializes a hashtree.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *dbHashTree) Copy() (HashTree, error) {\r\n\tif err := h.Hash(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tr, w := io.Pipe()\r\n\tvar eg errgroup.Group\r\n\teg.Go(func() (retErr error) {\r\n\t\tdefer func() {\r\n\t\t\tif err := w.Close(); err != nil && retErr == nil {\r\n\t\t\t\tretErr = err\r\n\t\t\t}\r\n\t\t}()\r\n\t\treturn h.Serialize(w)\r\n\t})\r\n\tvar result HashTree\r\n\teg.Go(func() error {\r\n\t\tvar err error\r\n\t\tresult, err = DeserializeDBHashTree(pathlib.Dir(h.Path()), r)\r\n\t\treturn err\r\n\t})\r\n\tif err := eg.Wait(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn result, nil\r\n}","code-length":245,"reference":"\/\/ Copy returns a copy of the hashtree.","result":"Copy the hash tree to a new file.","score":[0.1828,0.1875]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *dbHashTree) Destroy() error {\r\n\tpath := h.Path()\r\n\tif err := h.Close(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn os.Remove(path)\r\n}","code-length":67,"reference":"\/\/ Destroy cleans up the on disk structures for the hashtree.","result":"Destroy the hash tree.","score":[0.066,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *dbHashTree) PutFileOverwrite(path string, objects []*pfs.Object, overwriteIndex *pfs.OverwriteIndex, sizeDelta int64) error {\r\n\treturn h.putFile(path, objects, overwriteIndex, sizeDelta, false)\r\n}","code-length":72,"reference":"\/\/ PutFileOverwrite is the same as PutFile, except that instead of\n\/\/ appending the objects to the end of the given file, the objects\n\/\/ are inserted to the given index, and the existing objects starting\n\/\/ from the given index are removed.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *dbHashTree) PutDirHeaderFooter(path string, header, footer *pfs.Object, headerSize, footerSize int64) error {\r\n\tpath = clean(path)\r\n\treturn h.Batch(func(tx *bolt.Tx) error {\r\n\t\t\r\n\t\t\r\n\t\tnode, err := get(tx, path)\r\n\t\tif err != nil && Code(err) != PathNotFound {\r\n\t\t\treturn errorf(Internal, \"could not get node at %q: %v\", path, err)\r\n\t\t}\r\n\t\tif node != nil && node.nodetype() != directory {\r\n\t\t\treturn errorf(PathConflict, \"cannot add header to non-directory file \"+\r\n\t\t\t\t\"at %q; a file of type %s is already there\", path, node.nodetype())\r\n\t\t}\r\n\t\t\r\n\t\tvar newNode bool\r\n\t\tif node == nil {\r\n\t\t\tnewNode = true\r\n\t\t\tnode = &NodeProto{\r\n\t\t\t\tName: base(path),\r\n\t\t\t\tDirNode: &DirectoryNodeProto{\r\n\t\t\t\t\tShared: &Shared{},\r\n\t\t\t\t},\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tSubtreeSize: headerSize + footerSize,\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\theaderSame := (node.DirNode.Shared.Header == nil && header == nil) ||\r\n\t\t\t(node.DirNode.Shared.Header != nil && node.DirNode.Shared.Header.Hash == header.Hash)\r\n\t\tfooterSame := (node.DirNode.Shared.Footer == nil && footer == nil) ||\r\n\t\t\t(node.DirNode.Shared.Footer != nil && node.DirNode.Shared.Footer.Hash == footer.Hash)\r\n\t\tif newNode || !headerSame || !footerSame {\r\n\t\t\tnode.DirNode.Shared = &Shared{\r\n\t\t\t\tHeader:     header,\r\n\t\t\t\tFooter:     footer,\r\n\t\t\t\tHeaderSize: headerSize,\r\n\t\t\t\tFooterSize: footerSize,\r\n\t\t\t}\r\n\t\t\treturn put(tx, path, node)\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n}","code-length":526,"reference":"\/\/ PutDirHeaderFooter implements the hashtree.PutDirHeaderFooter interface\n\/\/ method","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *dbHashTree) PutFileHeaderFooter(path string, objects []*pfs.Object, size int64) error {\r\n\treturn h.putFile(path, objects, nil, size, true)\r\n}","code-length":61,"reference":"\/\/ PutFileHeaderFooter implements the HashTree PutFileHeaderFooter method","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc deleteDir(tx *bolt.Tx, path string) error {\r\n\tc := fs(tx).Cursor()\r\n\tprefix := append(b(path), nullByte[0])\r\n\tfor k, _ := c.Seek(prefix); bytes.HasPrefix(k, prefix); k, _ = c.Next() {\r\n\t\tif err := c.Delete(); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn fs(tx).Delete(b(path))\r\n}","code-length":131,"reference":"\/\/ deleteDir deletes a directory and all the children under it","result":"Delete a directory.","score":[0.0284,0.1838]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewReader(r io.Reader, filter Filter) *Reader {\r\n\treturn &Reader{\r\n\t\tpbr:    pbutil.NewReader(r),\r\n\t\tfilter: filter,\r\n\t}\r\n}","code-length":61,"reference":"\/\/ NewReader creates a new hashtree reader.","result":"Create a reader.","score":[0.128,0.3872]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Reader) Read() (*MergeNode, error) {\r\n\t_k, err := r.pbr.ReadBytes()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif r.filter != nil {\r\n\t\tfor {\r\n\t\t\tif r.filter(_k) {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\t_, err = r.pbr.ReadBytes()\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\t_k, err = r.pbr.ReadBytes()\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tk := make([]byte, len(_k))\r\n\tcopy(k, _k)\r\n\t_v, err := r.pbr.ReadBytes()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tv := make([]byte, len(_v))\r\n\tcopy(v, _v)\r\n\treturn &MergeNode{\r\n\t\tk: k,\r\n\t\tv: v,\r\n\t}, nil\r\n}","code-length":301,"reference":"\/\/ Read reads the next merge node.","result":"Read the merge node from the source file.","score":[0.1828,0.2113]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewWriter(w io.Writer) *Writer {\r\n\treturn &Writer{\r\n\t\tpbw: pbutil.NewWriter(w),\r\n\t}\r\n}","code-length":49,"reference":"\/\/ NewWriter creates a new hashtree writer.","result":"Create a new writer.","score":[0.2362,0.5597]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *Writer) Write(n *MergeNode) error {\r\n\t\r\n\tif n.nodeProto != nil {\r\n\t\tvar err error\r\n\t\tn.v, err = n.nodeProto.Marshal()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\t\r\n\tif bytes.Equal(n.k, nullByte) {\r\n\t\tif n.nodeProto == nil {\r\n\t\t\tn.nodeProto = &NodeProto{}\r\n\t\t\tif err := n.nodeProto.Unmarshal(n.v); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\tw.size = uint64(n.nodeProto.SubtreeSize)\r\n\t}\r\n\t\r\n\tif w.offset > uint64(len(w.idxs)+1)*IndexSize {\r\n\t\tw.idxs = append(w.idxs, &Index{\r\n\t\t\tK:      n.k,\r\n\t\t\tOffset: w.offset,\r\n\t\t})\r\n\t}\r\n\tb, err := w.pbw.WriteBytes(n.k)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tw.offset += uint64(b)\r\n\tb, err = w.pbw.WriteBytes(n.v)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tw.offset += uint64(b)\r\n\treturn nil\r\n}","code-length":369,"reference":"\/\/ Write writes the next merge node.","result":"Write the merge node to the stream.","score":[0.2125,0.2143]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *Writer) Copy(r *Reader) error {\r\n\tfor {\r\n\t\tn, err := r.Read()\r\n\t\tif err != nil {\r\n\t\t\tif err == io.EOF {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif err := w.Write(n); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n}","code-length":117,"reference":"\/\/ Copy copies a hashtree reader in a writer.","result":"Copy a Reader to a Writer.","score":[0.1541,0.4276]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *Writer) Index() ([]byte, error) {\r\n\tbuf := &bytes.Buffer{}\r\n\tpbw := pbutil.NewWriter(buf)\r\n\tfor _, idx := range w.idxs {\r\n\t\tif _, err := pbw.Write(idx); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\treturn buf.Bytes(), nil\r\n}","code-length":110,"reference":"\/\/ Index returns the index for a hashtree writer.","result":"Generate the index file.","score":[0.1294,0.2206]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetRangeFromIndex(r io.Reader, prefix string) (uint64, uint64, error) {\r\n\tprefix = clean(prefix)\r\n\tpbr := pbutil.NewReader(r)\r\n\tidx := &Index{}\r\n\tk := b(prefix)\r\n\tvar lower, upper uint64\r\n\titer := func(f func(int) bool) error {\r\n\t\tfor {\r\n\t\t\tif err := pbr.Read(idx); err != nil {\r\n\t\t\t\tif err == io.EOF {\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tvar cmp int\r\n\t\t\tif len(k) < len(idx.K) {\r\n\t\t\t\tcmp = bytes.Compare(k, idx.K[:len(k)])\r\n\t\t\t} else {\r\n\t\t\t\tcmp = bytes.Compare(k[:len(idx.K)], idx.K)\r\n\t\t\t}\r\n\t\t\tif f(cmp) {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\tlow := func(cmp int) bool {\r\n\t\tif cmp > 0 {\r\n\t\t\tlower = idx.Offset\r\n\t\t\treturn false\r\n\t\t} else if cmp < 0 {\r\n\t\t\t\r\n\t\t\tupper = idx.Offset\r\n\t\t}\r\n\t\treturn true\r\n\t}\r\n\tup := func(cmp int) bool {\r\n\t\tif cmp < 0 {\r\n\t\t\tupper = idx.Offset\r\n\t\t\treturn true\r\n\t\t}\r\n\t\treturn false\r\n\t}\r\n\t\r\n\titer(low)\r\n\t\r\n\tif upper <= 0 {\r\n\t\titer(up)\r\n\t}\r\n\t\r\n\tif upper <= 0 {\r\n\t\treturn lower, 0, nil\r\n\t}\r\n\t\r\n\treturn lower, upper - lower, nil\r\n}","code-length":469,"reference":"\/\/ GetRangeFromIndex returns a subtree byte range in a serialized hashtree based on a passed in prefix.","result":"Get the range from the index.","score":[0.0309,0.0314]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFilter(numTrees int64, tree int64) Filter {\r\n\treturn func(k []byte) bool {\r\n\t\tif pathToTree(k, numTrees) == uint64(tree) {\r\n\t\t\treturn true\r\n\t\t}\r\n\t\treturn false\r\n\t}\r\n}","code-length":80,"reference":"\/\/ NewFilter creates a filter for a hashtree shard.","result":"Create a filter.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PathToTree(path string, numTrees int64) uint64 {\r\n\tpath = clean(path)\r\n\treturn pathToTree(b(path), numTrees)\r\n}","code-length":51,"reference":"\/\/ PathToTree computes the hashtree shard for a path.","result":"Generate the tree structure.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Merge(w *Writer, rs []*Reader) error {\r\n\tif len(rs) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\tmq := &mergePQ{q: make([]*nodeStream, len(rs)+1)}\r\n\t\r\n\tfor _, r := range rs {\r\n\t\tif err := mq.insert(&nodeStream{r: r}); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tfor mq.q[1] != nil {\r\n\t\t\r\n\t\tns, err := mq.next()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\tn, err := merge(ns)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\tif err := w.Write(n); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":245,"reference":"\/\/ Merge merges a collection of hashtree readers into a hashtree writer.","result":"Merge multiple streams.","score":[0.0203,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *dbHashTree) Hash() error {\r\n\treturn h.Batch(func(tx *bolt.Tx) error {\r\n\t\treturn canonicalize(tx, \"\")\r\n\t})\r\n}","code-length":58,"reference":"\/\/ Hash updates all of the hashes and node size metadata, it also checks\n\/\/ for conflicts.","result":"Generate the hash of the database.","score":[0.0436,0.1607]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsGlob(pattern string) bool {\r\n\tpattern = clean(pattern)\r\n\treturn globRegex.Match([]byte(pattern))\r\n}","code-length":44,"reference":"\/\/ IsGlob checks if the pattern contains a glob character","result":"Detect globs .","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GlobLiteralPrefix(pattern string) string {\r\n\tpattern = clean(pattern)\r\n\tidx := globRegex.FindStringIndex(pattern)\r\n\tif idx == nil {\r\n\t\treturn pattern\r\n\t}\r\n\treturn pattern[:idx[0]]\r\n}","code-length":73,"reference":"\/\/ GlobLiteralPrefix returns the prefix before the first glob character","result":"Match the pattern.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetHashTreeObject(pachClient *client.APIClient, storageRoot string, treeRef *pfs.Object) (HashTree, error) {\r\n\treturn getHashTree(storageRoot, func(w io.Writer) error {\r\n\t\treturn pachClient.GetObject(treeRef.Hash, w)\r\n\t})\r\n}","code-length":87,"reference":"\/\/ GetHashTreeObject is a convenience function to deserialize a HashTree from an object in the object store.","result":"Get the object hash tree.","score":[0.0308,0.1187]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetHashTreeTag(pachClient *client.APIClient, storageRoot string, treeRef *pfs.Tag) (HashTree, error) {\r\n\treturn getHashTree(storageRoot, func(w io.Writer) error {\r\n\t\treturn pachClient.GetTag(treeRef.Name, w)\r\n\t})\r\n}","code-length":87,"reference":"\/\/ GetHashTreeTag is a convenience function to deserialize a HashTree from an tagged object in the object store.","result":"Get the hash tree tag.","score":[0.0178,0.0299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PutHashTree(pachClient *client.APIClient, tree HashTree, tags ...string) (*pfs.Object, error) {\r\n\tr, w := io.Pipe()\r\n\tvar eg errgroup.Group\r\n\teg.Go(func() (retErr error) {\r\n\t\tdefer func() {\r\n\t\t\tif err := w.Close(); err != nil && retErr == nil {\r\n\t\t\t\tretErr = err\r\n\t\t\t}\r\n\t\t}()\r\n\t\treturn tree.Serialize(w)\r\n\t})\r\n\tvar treeRef *pfs.Object\r\n\teg.Go(func() error {\r\n\t\tvar err error\r\n\t\ttreeRef, _, err = pachClient.PutObject(r, tags...)\r\n\t\treturn err\r\n\t})\r\n\tif err := eg.Wait(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn treeRef, nil\r\n}","code-length":235,"reference":"\/\/ PutHashTree is a convenience function for putting a HashTree to an object store.","result":"Store the hash tree in the datastore.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewChildCursor(tx *bolt.Tx, path string) *ChildCursor {\r\n\tpath = clean(path)\r\n\tc := fs(tx).Cursor()\r\n\tdir := b(path)\r\n\tk, v := c.Seek(append(dir, nullByte[0]))\r\n\tif !bytes.Equal(dir, nullByte) {\r\n\t\tdir = append(dir, nullByte[0])\r\n\t}\r\n\tif !bytes.HasPrefix(k, dir) {\r\n\t\tk, v = nil, nil\r\n\t}\r\n\treturn &ChildCursor{\r\n\t\tc:   c,\r\n\t\tdir: dir,\r\n\t\tk:   k,\r\n\t\tv:   v,\r\n\t}\r\n}","code-length":191,"reference":"\/\/ NewChildCursor creates a new child cursor.","result":"Create a new child cursor.","score":[0.5042,0.7324]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *ChildCursor) Next() ([]byte, []byte) {\r\n\tif d.k == nil {\r\n\t\treturn nil, nil\r\n\t}\r\n\tk, v := d.c.Seek(append(d.k, 1))\r\n\tif !bytes.HasPrefix(k, d.dir) {\r\n\t\tk, v = nil, nil\r\n\t}\r\n\td.k, d.v = k, v\r\n\treturn k, v\r\n}","code-length":125,"reference":"\/\/ Next gets the next key, value pair.","result":"Iterate over the child cursor.","score":[0.1319,0.0649]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewOrdered(root string) *Ordered {\r\n\troot = clean(root)\r\n\to := &Ordered{}\r\n\tn := &node{\r\n\t\tpath: \"\",\r\n\t\tnodeProto: &NodeProto{\r\n\t\t\tName:    \"\",\r\n\t\t\tDirNode: &DirectoryNodeProto{},\r\n\t\t},\r\n\t\thash: sha256.New(),\r\n\t}\r\n\to.fs = append(o.fs, n)\r\n\to.dirStack = append(o.dirStack, n)\r\n\to.MkdirAll(root)\r\n\to.root = root\r\n\treturn o\r\n}","code-length":162,"reference":"\/\/ NewOrdered creates a new ordered hashtree.","result":"Create an ordered file.","score":[0.1509,0.1493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *Ordered) MkdirAll(path string) {\r\n\tvar paths []string\r\n\tfor path != \"\" {\r\n\t\tpaths = append(paths, path)\r\n\t\tpath, _ = split(path)\r\n\t}\r\n\tfor i := len(paths) - 1; i >= 0; i-- {\r\n\t\to.PutDir(paths[i])\r\n\t}\r\n}","code-length":104,"reference":"\/\/ MkdirAll puts all of the parent directories of a given\n\/\/ path into the hashtree.","result":"Create a directory.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *Ordered) PutDir(path string) {\r\n\tpath = clean(path)\r\n\tif path == \"\" {\r\n\t\treturn\r\n\t}\r\n\tnodeProto := &NodeProto{\r\n\t\tName:    base(path),\r\n\t\tDirNode: &DirectoryNodeProto{},\r\n\t}\r\n\to.putDir(path, nodeProto)\r\n}","code-length":102,"reference":"\/\/ PutDir puts a directory in the hashtree.","result":"Create a directory tree.","score":[0.1662,0.2467]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *Ordered) Serialize(_w io.Writer) error {\r\n\tw := NewWriter(_w)\r\n\t\r\n\tfor len(o.dirStack) > 1 {\r\n\t\tchild := o.dirStack[len(o.dirStack)-1]\r\n\t\tchild.nodeProto.Hash = child.hash.Sum(nil)\r\n\t\to.dirStack = o.dirStack[:len(o.dirStack)-1]\r\n\t\tparent := o.dirStack[len(o.dirStack)-1]\r\n\t\tparent.hash.Write([]byte(fmt.Sprintf(\"%s:%s:\", child.nodeProto.Name, child.nodeProto.Hash)))\r\n\t\tparent.nodeProto.SubtreeSize += child.nodeProto.SubtreeSize\r\n\t}\r\n\to.fs[0].nodeProto.Hash = o.fs[0].hash.Sum(nil)\r\n\tfor _, n := range o.fs {\r\n\t\tif err := w.Write(&MergeNode{\r\n\t\t\tk:         b(n.path),\r\n\t\t\tnodeProto: n.nodeProto,\r\n\t\t}); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":303,"reference":"\/\/ Serialize serializes an ordered hashtree.","result":"Serialize the Ordered object.","score":[0.1938,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewUnordered(root string) *Unordered {\r\n\treturn &Unordered{\r\n\t\tfs:   make(map[string]*NodeProto),\r\n\t\troot: clean(root),\r\n\t}\r\n}","code-length":62,"reference":"\/\/ NewUnordered creates a new unordered hashtree.","result":"Create a new unordered file system.","score":[0.3366,0.5752]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *Unordered) Ordered() *Ordered {\r\n\tpaths := make([]string, len(u.fs))\r\n\ti := 0\r\n\tfor path := range u.fs {\r\n\t\tpaths[i] = path\r\n\t\ti++\r\n\t}\r\n\tsort.Strings(paths)\r\n\to := NewOrdered(\"\")\r\n\tfor i := 1; i < len(paths); i++ {\r\n\t\tpath := paths[i]\r\n\t\tn := u.fs[path]\r\n\t\tif n.DirNode != nil {\r\n\t\t\to.putDir(path, n)\r\n\t\t} else {\r\n\t\t\to.putFile(path, n)\r\n\t\t}\r\n\t}\r\n\treturn o\r\n}","code-length":193,"reference":"\/\/ Ordered converts an unordered hashtree into an ordered hashtree.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc revokeUserCredentials(ctx context.Context, pachdAddress string, userToken string, adminToken string) error {\r\n\t\r\n\tclient, err := pclient.NewFromAddress(pachdAddress)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer client.Close()\r\n\tclient = client.WithCtx(ctx)\r\n\tclient.SetAuthToken(adminToken)\r\n\t_, err = client.AuthAPIClient.RevokeAuthToken(client.Ctx(), &auth.RevokeAuthTokenRequest{\r\n\t\tToken: userToken,\r\n\t})\r\n\treturn err\r\n}","code-length":153,"reference":"\/\/ revokeUserCredentials revokes the Pachyderm authentication token 'userToken'\n\/\/ using the vault plugin's Admin credentials.","result":"Revoke user credentials.","score":[0.0075,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewAPIServer(version *pb.Version, options APIServerOptions) pb.APIServer {\r\n\treturn newAPIServer(version, options)\r\n}","code-length":42,"reference":"\/\/ NewAPIServer creates a new APIServer for the given Version.","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc String(v *pb.Version) string {\r\n\treturn fmt.Sprintf(\"%d.%d.%d%s\", v.Major, v.Minor, v.Micro, v.Additional)\r\n}","code-length":56,"reference":"\/\/ String returns a string representation of the Version.","result":"Generate the version string.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getPipelineInfo(pachClient *client.APIClient, env *serviceenv.ServiceEnv) (*pps.PipelineInfo, error) {\r\n\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\r\n\tdefer cancel()\r\n\tresp, err := env.GetEtcdClient().Get(ctx, path.Join(env.PPSEtcdPrefix, \"pipelines\", env.PPSPipelineName))\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif len(resp.Kvs) != 1 {\r\n\t\treturn nil, fmt.Errorf(\"expected to find 1 pipeline (%s), got %d: %v\", env.PPSPipelineName, len(resp.Kvs), resp)\r\n\t}\r\n\tvar pipelinePtr pps.EtcdPipelineInfo\r\n\tif err := pipelinePtr.Unmarshal(resp.Kvs[0].Value); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tpachClient.SetAuthToken(pipelinePtr.AuthToken)\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tpipelinePtr.SpecCommit.ID = env.PPSSpecCommitID\r\n\treturn ppsutil.GetPipelineInfo(pachClient, &pipelinePtr, true)\r\n}","code-length":306,"reference":"\/\/ getPipelineInfo gets the PipelineInfo proto describing the pipeline that this\n\/\/ worker is part of.\n\/\/ getPipelineInfo has the side effect of adding auth to the passed pachClient\n\/\/ which is necessary to get the PipelineInfo from pfs.","result":"Get the pipeline info from etcd.","score":[0.0012,0.0884]}
{"code":"\/*is used to<extra_id_0>\r\nfunc removeStr(ss *[]string, s string) bool {\r\n\tidx := sort.SearchStrings(*ss, s)\r\n\tif idx == len(*ss) {\r\n\t\treturn false\r\n\t}\r\n\tcopy((*ss)[idx:], (*ss)[idx+1:])\r\n\t*ss = (*ss)[:len(*ss)-1]\r\n\treturn true\r\n}","code-length":103,"reference":"\/\/ removeStr removes 's' from 'ss', preserving the sorted order of 'ss' (for\n\/\/ removing child strings from DirectoryNodes.","result":"Remove a string from a string array.","score":[0.0291,0.0843]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PublicCertToPEM(cert *tls.Certificate) []byte {\r\n\treturn pem.EncodeToMemory(&pem.Block{\r\n\t\tType:  \"CERTIFICATE\",\r\n\t\tBytes: cert.Certificate[0],\r\n\t})\r\n}","code-length":69,"reference":"\/\/ PublicCertToPEM serializes the public x509 cert in 'cert' to a PEM-formatted\n\/\/ block","result":"Convert public certificates to PEM.","score":[0.0472,0.0763]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GenerateSelfSignedCert(address string, name *pkix.Name, ipAddresses ...string) (*tls.Certificate, error) {\r\n\t\r\n\tif name == nil {\r\n\t\tname = &pkix.Name{}\r\n\t}\r\n\tswitch {\r\n\tcase address == \"\" && name.CommonName == \"\":\r\n\t\treturn nil, errors.New(\"must set either \\\"address\\\" or \\\"name.CommonName\\\"\")\r\n\tcase address != \"\" && name.CommonName == \"\":\r\n\t\tname.CommonName = address\r\n\tcase address != \"\" && name.CommonName != \"\" && name.CommonName != address:\r\n\t\treturn nil, fmt.Errorf(\"set address to \\\"%s\\\" but name.CommonName to \\\"%s\\\"\", address, name.CommonName)\r\n\tdefault:\r\n\t\t\r\n\t}\r\n\t\r\n\tparsedIPs := []net.IP{}\r\n\tfor _, strIP := range ipAddresses {\r\n\t\tnextParsedIP := net.ParseIP(strIP)\r\n\t\tif nextParsedIP == nil {\r\n\t\t\treturn nil, fmt.Errorf(\"invalid IP: %s\", strIP)\r\n\t\t}\r\n\t\tparsedIPs = append(parsedIPs, nextParsedIP)\r\n\t}\r\n\t\r\n\trn nil, fmt.Errorf(\"could not generate RSA private key: %v\", err)\r\n\t}\r\n\t\r\n\tcert := x509.Certificate{\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tSerialNumber: big.NewInt(atomic.AddInt64(&serialNumber, 1)),\r\n\t\tSubject:      *name,\r\n\t\tNotBefore:    time.Now().Add(-1 * time.Second),\r\n\t\tNotAfter:     time.Now().Add(validDur),\r\n\t\tKeyUsage: x509.KeyUsageCertSign |\r\n\t\t\tx509.KeyUsageKeyEncipherment |\r\n\t\t\tx509.KeyUsageKeyAgreement,\r\n\t\tExtKeyUsage: []x509.ExtKeyUsage{x509.ExtKeyUsageServerAuth},\r\n\t\tIsCA:                  true,\r\n\t\tBasicConstraintsValid: true,\r\n\t\tMaxPathLenZero:        true,\r\n\t\tIPAddresses:           parsedIPs,\r\n\t\tDNSNames:              []string{address},\r\n\t}\r\n\t\r\n\tsignedCertDER, err := x509.CreateCertificate(rand.Reader, &cert, &cert, &key.PublicKey, key)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"could not self-sign certificate: %v\", err)\r\n\t}\r\n\tsignedCert, err := x509.ParseCertificate(signedCertDER)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"could not parse the just-generated signed certificate: %v\", err)\r\n\t}\r\n\treturn &tls.Certificate{\r\n\t\tCertificate: [][]byte{signedCertDER},\r\n\t\tLeaf:        signedCert,\r\n\t\tPrivateKey:  key,\r\n\t}, nil\r\n}","code-length":722,"reference":"\/\/ GenerateSelfSignedCert generates a self-signed TLS cert for the domain name\n\/\/ 'address', with a private key. Other attributes of the subject can be set in\n\/\/ 'name' and ip addresses can be set in 'ipAddresses'","result":"Code too long,keep in 512.","score":[0.0005,0.0152]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ActivateCmd(noMetrics, noPortForwarding *bool) *cobra.Command {\r\n\tvar initialAdmin string\r\n\tactivate := &cobra.Command{\r\n\t\tShort: \"Activate Pachyderm's auth system\",\r\n\t\tLong: `\r\nActivate Pachyderm's auth system, and restrict access to existing data to the\r\nuser running the command (or the argument to --initial-admin), who will be the\r\nfirst cluster admin`[1:],\r\n\t\tRun: cmdutil.Run(func(args []string) error {\r\n\t\t\tvar token string\r\n\t\t\tvar err error\r\n\t\t\tif !strings.HasPrefix(initialAdmin, auth.RobotPrefix) {\r\n\t\t\t\ttoken, err = githubLogin()\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tfmt.Println(\"Retrieving Pachyderm token...\")\r\n\t\t\t\r\n\t\t\tc, err := client.NewOnUserMachine(!*noMetrics, !*noPortForwarding, \"user\")\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"could not connect: %v\", err)\r\n\t\t\t}\r\n\t\t\tdefer c.Close()\r\n\t\t\tresp, err := c.Activate(c.Ctx(),\r\n\t\t\t\t&auth.ActivateRequest{\r\n\t\t\t\t\tGitHubToken: token,\r\n\t\t\t\t\tSubject:     initialAdmin,\r\n\t\t\t\t})\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"error activating Pachyderm auth: %v\",\r\n\t\t\t\t\tgrpcutil.ScrubGRPC(err))\r\n\t\t\t}\r\n\t\t\tif err := writePachTokenToCfg(resp.PachToken); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif strings.HasPrefix(initialAdmin, auth.RobotPrefix) {\r\n\t\t\t\tfmt.Println(\"WARNING: DO NOT LOSE THE ROBOT TOKEN BELOW WITHOUT \" +\r\n\t\t\t\t\t\"ADDING OTHER ADMINS.\\nIF YOU DO, YOU WILL BE PERMANENTLY LOCKED OUT \" +\r\n\t\t\t\t\t\"OF YOUR CLUSTER!\")\r\n\t\t\t\tfmt.Printf(\"Pachyderm token for \\\"%s\\\":\\n%s\\n\", initialAdmin, resp.PachToken)\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t}),\r\n\t}\r\n\tactivate.PersistentFlags().StringVar(&initialAdmin, \"initial-admin\", \"\", `\r\nThe subject (robot user or github user) who\r\nwill be the first cluster admin; the user running 'activate' will identify as\r\nthis user once auth is active.  If you set 'initial-admin' to a robot\r\nuser, pachctl will print that robot user's Pachyderm token; this token is\r\neffectively a root token, and if it's lost you will be locked out of your\r\ncluster`[1:])\r\n\treturn cmdutil.CreateAlias(activate, \"auth activate\")\r\n}","code-length":721,"reference":"\/\/ ActivateCmd returns a cobra.Command to activate Pachyderm's auth system","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DeactivateCmd(noMetrics, noPortForwarding *bool) *cobra.Command {\r\n\tdeactivate := &cobra.Command{\r\n\t\tShort: \"Delete all ACLs, tokens, and admins, and deactivate Pachyderm auth\",\r\n\t\tLong: \"Deactivate Pachyderm's auth system, which will delete ALL auth \" +\r\n\t\t\t\"tokens, ACLs and admins, and expose all data in the cluster to any \" +\r\n\t\t\t\"user with cluster access. Use with caution.\",\r\n\t\tRun: cmdutil.Run(func(args []string) error {\r\n\t\t\tfmt.Println(\"Are you sure you want to delete ALL auth information \" +\r\n\t\t\t\t\"(ACLs, tokens, and admins) in this cluster, and expose ALL data? yN\")\r\n\t\t\tconfirm, err := bufio.NewReader(os.Stdin).ReadString('\\n')\r\n\t\t\tif !strings.Contains(\"yY\", confirm[:1]) {\r\n\t\t\t\treturn fmt.Errorf(\"operation aborted\")\r\n\t\t\t}\r\n\t\t\tc, err := client.NewOnUserMachine(!*noMetrics, !*noPortForwarding, \"user\")\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"could not connect: %v\", err)\r\n\t\t\t}\r\n\t\t\tdefer c.Close()\r\n\t\t\t_, err = c.Deactivate(c.Ctx(), &auth.DeactivateRequest{})\r\n\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t}),\r\n\t}\r\n\treturn cmdutil.CreateAlias(deactivate, \"auth deactivate\")\r\n}","code-length":395,"reference":"\/\/ DeactivateCmd returns a cobra.Command to delete all ACLs, tokens, and admins,\n\/\/ deactivating Pachyderm's auth system","result":"Deactivate a Pachyderm auth system.","score":[0.0259,0.0949]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoginCmd(noMetrics, noPortForwarding *bool) *cobra.Command {\r\n\tvar useOTP bool\r\n\tlogin := &cobra.Command{\r\n\t\tShort: \"Log in to Pachyderm\",\r\n\t\tLong: \"Login to Pachyderm. Any resources that have been restricted to \" +\r\n\t\t\t\"the account you have with your ID provider (e.g. GitHub, Okta) \" +\r\n\t\t\t\"account will subsequently be accessible.\",\r\n\t\tRun: cmdutil.Run(func([]string) error {\r\n\t\t\tc, err := client.NewOnUserMachine(!*noMetrics, !*noPortForwarding, \"user\")\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"could not connect: %v\", err)\r\n\t\t\t}\r\n\t\t\tdefer c.Close()\r\n\t\t\t\r\n\t\t\tvar resp *auth.AuthenticateResponse\r\n\t\t\tvar authErr error\r\n\t\t\tif useOTP {\r\n\t\t\t\t\r\n\t\t\t\tfmt.Println(\"Please enter your Pachyderm One-Time Password:\")\r\n\t\t\t\tcode, err := bufio.NewReader(os.Stdin).ReadString('\\n')\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn fmt.Errorf(\"error reading One-Time Password: %v\", err)\r\n\t\t\t\t}\r\n\t\t\t\tcode = strings.TrimSpace(code)\r\n\t\t\t\tresp, authErr = c.Authenticate(\r\n\t\t\t\t\tc.Ctx(),\r\n\t\t\t\t\t&auth.AuthenticateRequest{OneTimePassword: code})\r\n\t\t\t} else {\r\n\t\t\t\t\r\n\t\t\t\ttoken, err := githubLogin()\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t\tfmt.Println(\"Retrieving Pachyderm token...\")\r\n\t\t\t\tresp, authErr = c.Authenticate(\r\n\t\t\t\t\tc.Ctx(),\r\n\t\t\t\t\t&auth.AuthenticateRequest{GitHubToken: token})\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif authErr != nil {\r\n\t\t\t\tif auth.IsErrPartiallyActivated(authErr) {\r\n\t\t\t\t\treturn fmt.Errorf(\"%v: if pachyderm is stuck in this state, you \"+\r\n\t\t\t\t\t\t\"can revert by running 'pachctl auth deactivate' or retry by \"+\r\n\t\t\t\t\t\t\"running 'pachctl auth activate' again\", authErr)\r\n\t\t\t\t}\r\n\t\t\t\treturn fmt.Errorf(\"error authenticating with Pachyderm cluster: %v\",\r\n\t\t\t\t\tgrpcutil.ScrubGRPC(authErr))\r\n\t\t\t}\r\n\t\t\treturn writePachTokenToCfg(resp.PachToken)\r\n\t\t}),\r\n\t}\r\n\tlogin.PersistentFlags().BoolVarP(&useOTP, \"one-time-password\", \"o\", false,\r\n\t\t\"If set, authenticate with a Dash-provided One-Time Password, rather than \"+\r\n\t\t\t\"via GitHub\")\r\n\treturn cmdutil.CreateAlias(login, \"auth login\")\r\n}","code-length":725,"reference":"\/\/ LoginCmd returns a cobra.Command to login to a Pachyderm cluster with your\n\/\/ GitHub account. Any resources that have been restricted to the email address\n\/\/ registered with your GitHub account will subsequently be accessible.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LogoutCmd() *cobra.Command {\r\n\tlogout := &cobra.Command{\r\n\t\tShort: \"Log out of Pachyderm by deleting your local credential\",\r\n\t\tLong: \"Log out of Pachyderm by deleting your local credential. Note that \" +\r\n\t\t\t\"it's not necessary to log out before logging in with another account \" +\r\n\t\t\t\"(simply run 'pachctl auth login' twice) but 'logout' can be useful on \" +\r\n\t\t\t\"shared workstations.\",\r\n\t\tRun: cmdutil.Run(func([]string) error {\r\n\t\t\tcfg, err := config.Read()\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"error reading Pachyderm config (for cluster \"+\r\n\t\t\t\t\t\"address): %v\", err)\r\n\t\t\t}\r\n\t\t\tif cfg.V1 == nil {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\tcfg.V1.SessionToken = \"\"\r\n\t\t\treturn cfg.Write()\r\n\t\t}),\r\n\t}\r\n\treturn cmdutil.CreateAlias(logout, \"auth logout\")\r\n}","code-length":285,"reference":"\/\/ LogoutCmd returns a cobra.Command that deletes your local Pachyderm\n\/\/ credential, logging you out of your cluster. Note that this is not necessary\n\/\/ to do before logging in as another user, but is useful for testing.","result":"Logout a cluster.","score":[0.0,0.029]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WhoamiCmd(noMetrics, noPortForwarding *bool) *cobra.Command {\r\n\twhoami := &cobra.Command{\r\n\t\tShort: \"Print your Pachyderm identity\",\r\n\t\tLong:  \"Print your Pachyderm identity.\",\r\n\t\tRun: cmdutil.Run(func([]string) error {\r\n\t\t\tc, err := client.NewOnUserMachine(!*noMetrics, !*noPortForwarding, \"user\")\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"could not connect: %v\", err)\r\n\t\t\t}\r\n\t\t\tdefer c.Close()\r\n\t\t\tresp, err := c.WhoAmI(c.Ctx(), &auth.WhoAmIRequest{})\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"error: %v\", grpcutil.ScrubGRPC(err))\r\n\t\t\t}\r\n\t\t\tfmt.Printf(\"You are \\\"%s\\\"\\n\", resp.Username)\r\n\t\t\tif resp.TTL > 0 {\r\n\t\t\t\tfmt.Printf(\"session expires: %v\\n\", time.Now().Add(time.Duration(resp.TTL)*time.Second).Format(time.RFC822))\r\n\t\t\t}\r\n\t\t\tif resp.IsAdmin {\r\n\t\t\t\tfmt.Println(\"You are an administrator of this Pachyderm cluster\")\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t}),\r\n\t}\r\n\treturn cmdutil.CreateAlias(whoami, \"auth whoami\")\r\n}","code-length":382,"reference":"\/\/ WhoamiCmd returns a cobra.Command that deletes your local Pachyderm\n\/\/ credential, logging you out of your cluster. Note that this is not necessary\n\/\/ to do before logging in as another user, but is useful for testing.","result":"Print your Pachyderm identity.","score":[0.0001,0.0289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CheckCmd(noMetrics, noPortForwarding *bool) *cobra.Command {\r\n\tcheck := &cobra.Command{\r\n\t\tUse:   \"{{alias}} (none|reader|writer|owner) <repo>\",\r\n\t\tShort: \"Check whether you have reader\/writer\/etc-level access to 'repo'\",\r\n\t\tLong: \"Check whether you have reader\/writer\/etc-level access to 'repo'. \" +\r\n\t\t\t\"For example, 'pachctl auth check reader private-data' prints \\\"true\\\" \" +\r\n\t\t\t\"if the you have at least \\\"reader\\\" access to the repo \" +\r\n\t\t\t\"\\\"private-data\\\" (you could be a reader, writer, or owner). Unlike \" +\r\n\t\t\t\"`pachctl auth get`, you do not need to have access to 'repo' to \" +\r\n\t\t\t\"discover your own access level.\",\r\n\t\tRun: cmdutil.RunFixedArgs(2, func(args []string) error {\r\n\t\t\tscope, err := auth.ParseScope(args[0])\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\trepo := args[1]\r\n\t\t\tc, err := client.NewOnUserMachine(!*noMetrics, !*noPortForwarding, \"user\")\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"could not connect: %v\", err)\r\n\t\t\t}\r\n\t\t\tdefer c.Close()\r\n\t\t\tresp, err := c.Authorize(c.Ctx(), &auth.AuthorizeRequest{\r\n\t\t\t\tRepo:  repo,\r\n\t\t\t\tScope: scope,\r\n\t\t\t})\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t\t}\r\n\t\t\tfmt.Printf(\"%t\\n\", resp.Authorized)\r\n\t\t\treturn nil\r\n\t\t}),\r\n\t}\r\n\treturn cmdutil.CreateAlias(check, \"auth check\")\r\n}","code-length":482,"reference":"\/\/ CheckCmd returns a cobra command that sends an \"Authorize\" RPC to Pachd, to\n\/\/ determine whether the specified user has access to the specified repo.","result":"Check access to a repository.","score":[0.0056,0.1069]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetCmd(noMetrics, noPortForwarding *bool) *cobra.Command {\r\n\tget := &cobra.Command{\r\n\t\tUse:   \"{{alias}} [<username>] <repo>\",\r\n\t\tShort: \"Get the ACL for 'repo' or the access that 'username' has to 'repo'\",\r\n\t\tLong: \"Get the ACL for 'repo' or the access that 'username' has to \" +\r\n\t\t\t\"'repo'. For example, 'pachctl auth get github-alice private-data' \" +\r\n\t\t\t\"prints \\\"reader\\\", \\\"writer\\\", \\\"owner\\\", or \\\"none\\\", depending on \" +\r\n\t\t\t\"the privileges that \\\"github-alice\\\" has in \\\"repo\\\". Currently all \" +\r\n\t\t\t\"Pachyderm authentication uses GitHub OAuth, so 'username' must be a \" +\r\n\t\t\t\"GitHub username\",\r\n\t\tRun: cmdutil.RunBoundedArgs(1, 2, func(args []string) error {\r\n\t\t\tc, err := client.NewOnUserMachine(!*noMetrics, !*noPortForwarding, \"user\")\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"could not connect: %v\", err)\r\n\t\t\t}\r\n\t\t\tdefer c.Close()\r\n\t\t\tif len(args) == 1 {\r\n\t\t\t\t\r\n\t\t\t\trepo := args[0]\r\n\t\t\t\tresp, err := c.GetACL(c.Ctx(), &auth.GetACLRequest{\r\n\t\t\t\t\tRepo: repo,\r\n\t\t\t\t})\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t\t\t}\r\n\t\t\t\tt := template.Must(template.New(\"ACLEntries\").Parse(\r\n\t\t\t\t\t\"{{range .}}{{.Username }}: {{.Scope}}\\n{{end}}\"))\r\n\t\t\t\treturn t.Execute(os.Stdout, resp.Entries)\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tusername, repo := args[0], args[1]\r\n\t\t\tresp, err := c.GetScope(c.Ctx(), &auth.GetScopeRequest{\r\n\t\t\t\tRepos:    []string{repo},\r\n\t\t\t\tUsername: username,\r\n\t\t\t})\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t\t}\r\n\t\t\tfmt.Println(resp.Scopes[0].String())\r\n\t\t\treturn nil\r\n\t\t}),\r\n\t}\r\n\treturn cmdutil.CreateAlias(get, \"auth get\")\r\n}","code-length":616,"reference":"\/\/ GetCmd returns a cobra command that gets either the ACL for a Pachyderm\n\/\/ repo or another user's scope of access to that repo","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetScopeCmd(noMetrics, noPortForwarding *bool) *cobra.Command {\r\n\tsetScope := &cobra.Command{\r\n\t\tUse:   \"{{alias}} <username> (none|reader|writer|owner) <repo>\",\r\n\t\tShort: \"Set the scope of access that 'username' has to 'repo'\",\r\n\t\tLong: \"Set the scope of access that 'username' has to 'repo'. For \" +\r\n\t\t\t\"example, 'pachctl auth set github-alice none private-data' prevents \" +\r\n\t\t\t\"\\\"github-alice\\\" from interacting with the \\\"private-data\\\" repo in any \" +\r\n\t\t\t\"way (the default). Similarly, 'pachctl auth set github-alice reader \" +\r\n\t\t\t\"private-data' would let \\\"github-alice\\\" read from \\\"private-data\\\" but \" +\r\n\t\t\t\"not create commits (writer) or modify the repo's access permissions \" +\r\n\t\t\t\"(owner). Currently all Pachyderm authentication uses GitHub OAuth, so \" +\r\n\t\t\t\"'username' must be a GitHub username\",\r\n\t\tRun: cmdutil.RunFixedArgs(3, func(args []string) error {\r\n\t\t\tscope, err := auth.ParseScope(args[1])\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tusername, repo := args[0], args[2]\r\n\t\t\tc, err := client.NewOnUserMachine(!*noMetrics, !*noPortForwarding, \"user\")\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"could not connect: %v\", err)\r\n\t\t\t}\r\n\t\t\tdefer c.Close()\r\n\t\t\t_, err = c.SetScope(c.Ctx(), &auth.SetScopeRequest{\r\n\t\t\t\tRepo:     repo,\r\n\t\t\t\tScope:    scope,\r\n\t\t\t\tUsername: username,\r\n\t\t\t})\r\n\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t}),\r\n\t}\r\n\treturn cmdutil.CreateAlias(setScope, \"auth set\")\r\n}","code-length":518,"reference":"\/\/ SetScopeCmd returns a cobra command that lets a user set the level of access\n\/\/ that another user has to a repo","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ListAdminsCmd(noMetrics, noPortForwarding *bool) *cobra.Command {\r\n\tlistAdmins := &cobra.Command{\r\n\t\tShort: \"List the current cluster admins\",\r\n\t\tLong:  \"List the current cluster admins\",\r\n\t\tRun: cmdutil.Run(func([]string) error {\r\n\t\t\tc, err := client.NewOnUserMachine(!*noMetrics, !*noPortForwarding, \"user\")\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tdefer c.Close()\r\n\t\t\tresp, err := c.GetAdmins(c.Ctx(), &auth.GetAdminsRequest{})\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t\t}\r\n\t\t\tfor _, user := range resp.Admins {\r\n\t\t\t\tfmt.Println(user)\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t}),\r\n\t}\r\n\treturn cmdutil.CreateAlias(listAdmins, \"auth list-admins\")\r\n}","code-length":271,"reference":"\/\/ ListAdminsCmd returns a cobra command that lists the current cluster admins","result":"List the current cluster admins.","score":[0.122,0.3512]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ModifyAdminsCmd(noMetrics, noPortForwarding *bool) *cobra.Command {\r\n\tvar add []string\r\n\tvar remove []string\r\n\tmodifyAdmins := &cobra.Command{\r\n\t\tShort: \"Modify the current cluster admins\",\r\n\t\tLong: \"Modify the current cluster admins. --add accepts a comma-\" +\r\n\t\t\t\"separated list of users to grant admin status, and --remove accepts a \" +\r\n\t\t\t\"comma-separated list of users to revoke admin status\",\r\n\t\tRun: cmdutil.Run(func([]string) error {\r\n\t\t\tc, err := client.NewOnUserMachine(!*noMetrics, !*noPortForwarding, \"user\")\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tdefer c.Close()\r\n\t\t\t_, err = c.ModifyAdmins(c.Ctx(), &auth.ModifyAdminsRequest{\r\n\t\t\t\tAdd:    add,\r\n\t\t\t\tRemove: remove,\r\n\t\t\t})\r\n\t\t\tif auth.IsErrPartiallyActivated(err) {\r\n\t\t\t\treturn fmt.Errorf(\"%v: if pachyderm is stuck in this state, you \"+\r\n\t\t\t\t\t\"can revert by running 'pachctl auth deactivate' or retry by \"+\r\n\t\t\t\t\t\"running 'pachctl auth activate' again\", err)\r\n\t\t\t}\r\n\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t}),\r\n\t}\r\n\tmodifyAdmins.PersistentFlags().StringSliceVar(&add, \"add\", []string{},\r\n\t\t\"Comma-separated list of users to grant admin status\")\r\n\tmodifyAdmins.PersistentFlags().StringSliceVar(&remove, \"remove\", []string{},\r\n\t\t\"Comma-separated list of users revoke admin status\")\r\n\treturn cmdutil.CreateAlias(modifyAdmins, \"auth modify-admins\")\r\n}","code-length":461,"reference":"\/\/ ModifyAdminsCmd returns a cobra command that modifies the set of current\n\/\/ cluster admins","result":"Modify cluster admins.","score":[0.0075,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetAuthTokenCmd(noMetrics, noPortForwarding *bool) *cobra.Command {\r\n\tvar quiet bool\r\n\tgetAuthToken := &cobra.Command{\r\n\t\tUse:   \"{{alias}} <username>\",\r\n\t\tShort: \"Get an auth token that authenticates the holder as \\\"username\\\"\",\r\n\t\tLong: \"Get an auth token that authenticates the holder as \\\"username\\\"; \" +\r\n\t\t\t\"this can only be called by cluster admins\",\r\n\t\tRun: cmdutil.RunFixedArgs(1, func(args []string) error {\r\n\t\t\tsubject := args[0]\r\n\t\t\tc, err := client.NewOnUserMachine(!*noMetrics, !*noPortForwarding, \"user\")\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"could not connect: %v\", err)\r\n\t\t\t}\r\n\t\t\tdefer c.Close()\r\n\t\t\tresp, err := c.GetAuthToken(c.Ctx(), &auth.GetAuthTokenRequest{\r\n\t\t\t\tSubject: subject,\r\n\t\t\t})\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t\t}\r\n\t\t\tif quiet {\r\n\t\t\t\tfmt.Println(resp.Token)\r\n\t\t\t} else {\r\n\t\t\t\tfmt.Printf(\"New credentials:\\n  Subject: %s\\n  Token: %s\\n\", resp.Subject, resp.Token)\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t}),\r\n\t}\r\n\tgetAuthToken.PersistentFlags().BoolVarP(&quiet, \"quiet\", \"q\", false, \"if \"+\r\n\t\t\"set, only print the resulting token (if successful). This is useful for \"+\r\n\t\t\"scripting, as the output can be piped to use-auth-token\")\r\n\treturn cmdutil.CreateAlias(getAuthToken, \"auth get-auth-token\")\r\n}","code-length":464,"reference":"\/\/ GetAuthTokenCmd returns a cobra command that lets a user get a pachyderm\n\/\/ token on behalf of themselves or another user","result":"Generate the auth token .","score":[0.008,0.0246]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UseAuthTokenCmd() *cobra.Command {\r\n\tuseAuthToken := &cobra.Command{\r\n\t\tShort: \"Read a Pachyderm auth token from stdin, and write it to the \" +\r\n\t\t\t\"current user's Pachyderm config file\",\r\n\t\tLong: \"Read a Pachyderm auth token from stdin, and write it to the \" +\r\n\t\t\t\"current user's Pachyderm config file\",\r\n\t\tRun: cmdutil.RunFixedArgs(0, func(args []string) error {\r\n\t\t\tfmt.Println(\"Please paste your Pachyderm auth token:\")\r\n\t\t\ttoken, err := bufio.NewReader(os.Stdin).ReadString('\\n')\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"error reading token: %v\", err)\r\n\t\t\t}\r\n\t\t\twritePachTokenToCfg(strings.TrimSpace(token))\r\n\t\t\treturn nil\r\n\t\t}),\r\n\t}\r\n\treturn cmdutil.CreateAlias(useAuthToken, \"auth use-auth-token\")\r\n}","code-length":274,"reference":"\/\/ UseAuthTokenCmd returns a cobra command that lets a user get a pachyderm\n\/\/ token on behalf of themselves or another user","result":"Generate the auth token file.","score":[0.008,0.0246]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Cmds(noMetrics, noPortForwarding *bool) []*cobra.Command {\r\n\tvar commands []*cobra.Command\r\n\tauth := &cobra.Command{\r\n\t\tShort: \"Auth commands manage access to data in a Pachyderm cluster\",\r\n\t\tLong:  \"Auth commands manage access to data in a Pachyderm cluster\",\r\n\t}\r\n\tcommands = append(commands, cmdutil.CreateAlias(auth, \"auth\"))\r\n\tcommands = append(commands, ActivateCmd(noMetrics, noPortForwarding))\r\n\tcommands = append(commands, DeactivateCmd(noMetrics, noPortForwarding))\r\n\tcommands = append(commands, LoginCmd(noMetrics, noPortForwarding))\r\n\tcommands = append(commands, LogoutCmd())\r\n\tcommands = append(commands, WhoamiCmd(noMetrics, noPortForwarding))\r\n\tcommands = append(commands, CheckCmd(noMetrics, noPortForwarding))\r\n\tcommands = append(commands, SetScopeCmd(noMetrics, noPortForwarding))\r\n\tcommands = append(commands, GetCmd(noMetrics, noPortForwarding))\r\n\tcommands = append(commands, ListAdminsCmd(noMetrics, noPortForwarding))\r\n\tcommands = append(commands, ModifyAdminsCmd(noMetrics, noPortForwarding))\r\n\tcommands = append(commands, GetAuthTokenCmd(noMetrics, noPortForwarding))\r\n\tcommands = append(commands, UseAuthTokenCmd())\r\n\tcommands = append(commands, GetConfigCmd(noPortForwarding))\r\n\tcommands = append(commands, SetConfigCmd(noPortForwarding))\r\n\treturn commands\r\n}","code-length":388,"reference":"\/\/ Cmds returns a list of cobra commands for authenticating and authorizing\n\/\/ users in an auth-enabled Pachyderm cluster.","result":"Generate the commands.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseScope(s string) (Scope, error) {\r\n\tfor name, value := range Scope_value {\r\n\t\tif strings.EqualFold(s, name) {\r\n\t\t\treturn Scope(value), nil\r\n\t\t}\r\n\t}\r\n\treturn Scope_NONE, fmt.Errorf(\"unrecognized scope: %s\", s)\r\n}","code-length":93,"reference":"\/\/ ParseScope parses the string 's' to a scope (for example, parsing a command-\n\/\/ line argument.","result":"Parse the scope.","score":[0.0038,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsErrNotActivated(err error) bool {\r\n\tif err == nil {\r\n\t\treturn false\r\n\t}\r\n\t\r\n\t\r\n\treturn strings.Contains(err.Error(), status.Convert(ErrNotActivated).Message())\r\n}","code-length":69,"reference":"\/\/ IsErrNotActivated checks if an error is a ErrNotActivated","result":"Detect errors that are not activated.","score":[0,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsErrPartiallyActivated(err error) bool {\r\n\tif err == nil {\r\n\t\treturn false\r\n\t}\r\n\t\r\n\t\r\n\treturn strings.Contains(err.Error(), status.Convert(ErrPartiallyActivated).Message())\r\n}","code-length":71,"reference":"\/\/ IsErrPartiallyActivated checks if an error is a ErrPartiallyActivated","result":"Detect the error that is partially activated.","score":[0.1443,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsErrNotSignedIn(err error) bool {\r\n\tif err == nil {\r\n\t\treturn false\r\n\t}\r\n\t\r\n\t\r\n\treturn strings.Contains(err.Error(), status.Convert(ErrNotSignedIn).Message())\r\n}","code-length":71,"reference":"\/\/ IsErrNotSignedIn returns true if 'err' is a ErrNotSignedIn","result":"Test the error .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsErrBadToken(err error) bool {\r\n\tif err == nil {\r\n\t\treturn false\r\n\t}\r\n\treturn strings.Contains(err.Error(), status.Convert(ErrBadToken).Message())\r\n}","code-length":63,"reference":"\/\/ IsErrBadToken returns true if 'err' is a ErrBadToken","result":"Validate the token.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsErrNotAuthorized(err error) bool {\r\n\tif err == nil {\r\n\t\treturn false\r\n\t}\r\n\t\r\n\t\r\n\treturn strings.Contains(err.Error(), errNotAuthorizedMsg)\r\n}","code-length":64,"reference":"\/\/ IsErrNotAuthorized checks if an error is a ErrNotAuthorized","result":"Test the error .","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsErrInvalidPrincipal(err error) bool {\r\n\tif err == nil {\r\n\t\treturn false\r\n\t}\r\n\treturn strings.Contains(err.Error(), \"invalid principal \\\"\") &&\r\n\t\tstrings.Contains(err.Error(), \"\\\"; must start with one of \\\"pipeline:\\\", \\\"github:\\\", or \\\"robot:\\\", or have no \\\":\\\"\")\r\n}","code-length":98,"reference":"\/\/ IsErrInvalidPrincipal returns true if 'err' is an ErrInvalidPrincipal","result":"Detect invalid principals.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsErrTooShortTTL(err error) bool {\r\n\tif err == nil {\r\n\t\treturn false\r\n\t}\r\n\terrMsg := err.Error()\r\n\treturn strings.Contains(errMsg, \"provided TTL (\") &&\r\n\t\tstrings.Contains(errMsg, \") is shorter than token's existing TTL (\") &&\r\n\t\tstrings.Contains(errMsg, \")\")\r\n}","code-length":104,"reference":"\/\/ IsErrTooShortTTL returns true if 'err' is a ErrTooShortTTL","result":"Validate token.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDatumFactory(pachClient *client.APIClient, input *pps.Input) (DatumFactory, error) {\r\n\tswitch {\r\n\tcase input.Pfs != nil:\r\n\t\treturn newPFSDatumFactory(pachClient, input.Pfs)\r\n\tcase input.Union != nil:\r\n\t\treturn newUnionDatumFactory(pachClient, input.Union)\r\n\tcase input.Cross != nil:\r\n\t\treturn newCrossDatumFactory(pachClient, input.Cross)\r\n\tcase input.Cron != nil:\r\n\t\treturn newCronDatumFactory(pachClient, input.Cron)\r\n\tcase input.Git != nil:\r\n\t\treturn newGitDatumFactory(pachClient, input.Git)\r\n\t}\r\n\treturn nil, fmt.Errorf(\"unrecognized input type\")\r\n}","code-length":206,"reference":"\/\/ NewDatumFactory creates a datumFactory for an input.","result":"Create a new datum factory.","score":[0.1319,0.2435]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCollection(etcdClient *etcd.Client, prefix string, indexes []*Index, template proto.Message, keyCheck func(string) error, valCheck func(proto.Message) error) Collection {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif len(prefix) > 0 && prefix[len(prefix)-1] != '\/' {\r\n\t\tprefix = prefix + \"\/\"\r\n\t}\r\n\treturn &collection{\r\n\t\tprefix:     prefix,\r\n\t\tetcdClient: etcdClient,\r\n\t\tindexes:    indexes,\r\n\t\tlimit:      defaultLimit,\r\n\t\ttemplate:   template,\r\n\t\tkeyCheck:   keyCheck,\r\n\t\tvalCheck:   valCheck,\r\n\t}\r\n}","code-length":186,"reference":"\/\/ NewCollection creates a new collection.","result":"Create a new collection.","score":[0.3991,0.6843]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *collection) Path(key string) string {\r\n\treturn path.Join(c.prefix, key)\r\n}","code-length":39,"reference":"\/\/ Path returns the full path of a key in the etcd namespace","result":"Generate the generated code.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *readWriteCollection) getIndexPath(val interface{}, index *Index, key string) string {\r\n\treflVal := reflect.ValueOf(val)\r\n\tfield := reflect.Indirect(reflVal).FieldByName(index.Field).Interface()\r\n\treturn c.indexPath(index, field, key)\r\n}","code-length":87,"reference":"\/\/ Giving a value, an index, and the key of the item, return the path\n\/\/ under which the new index item should be stored.","result":"Get the index path for a given value.","score":[0.0235,0.1073]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *readWriteCollection) getMultiIndexPaths(val interface{}, index *Index, key string) []string {\r\n\tvar indexPaths []string\r\n\tfield := reflect.Indirect(reflect.ValueOf(val)).FieldByName(index.Field)\r\n\tfor i := 0; i < field.Len(); i++ {\r\n\t\tindexPaths = append(indexPaths, c.indexPath(index, field.Index(i).Interface(), key))\r\n\t}\r\n\treturn indexPaths\r\n}","code-length":127,"reference":"\/\/ Giving a value, a multi-index, and the key of the item, return the\n\/\/ paths under which the multi-index items should be stored.","result":"Generate the index paths.","score":[0.0022,0.0227]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *readWriteCollection) Upsert(key string, val proto.Message, f func() error) error {\r\n\tif err := watch.CheckType(c.template, val); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := c.Get(key, val); err != nil && !IsErrNotFound(err) {\r\n\t\treturn err\r\n\t}\r\n\tif err := f(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn c.Put(key, val)\r\n}","code-length":138,"reference":"\/\/ Upsert is like Update but 'key' is not required to be present","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *readonlyCollection) get(key string, opts ...etcd.OpOption) (*etcd.GetResponse, error) {\r\n\tspan, ctx := tracing.AddSpanToAnyExisting(c.ctx, \"etcd.Get\")\r\n\tdefer tracing.FinishAnySpan(span)\r\n\tresp, err := c.etcdClient.Get(ctx, key, opts...)\r\n\treturn resp, err\r\n}","code-length":108,"reference":"\/\/ get is an internal wrapper around etcdClient.Get that wraps the call in a\n\/\/ trace","result":"Get a value from a collection.","score":[0.0365,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *readonlyCollection) List(val proto.Message, opts *Options, f func(string) error) error {\r\n\tif err := watch.CheckType(c.template, val); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn c.list(c.prefix, &c.limit, opts, func(kv *mvccpb.KeyValue) error {\r\n\t\tif err := proto.Unmarshal(kv.Value, val); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn f(strings.TrimPrefix(string(kv.Key), c.prefix))\r\n\t})\r\n}","code-length":159,"reference":"\/\/ List returns objects sorted based on the options passed in. f will be called with each key, val will contain the\n\/\/ corresponding value. Val is not an argument to f because that would require\n\/\/ f to perform a cast before it could be used.\n\/\/ You can break out of iteration by returning errutil.ErrBreak.","result":"List the collection.","score":[0.0,0.0194]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *readonlyCollection) Watch(opts ...watch.OpOption) (watch.Watcher, error) {\r\n\treturn watch.NewWatcher(c.ctx, c.etcdClient, c.prefix, c.prefix, c.template, opts...)\r\n}","code-length":69,"reference":"\/\/ Watch a collection, returning the current content of the collection as\n\/\/ well as any future additions.","result":"Watch the collection.","score":[0.0033,0.0606]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *readonlyCollection) WatchByIndex(index *Index, val interface{}) (watch.Watcher, error) {\r\n\teventCh := make(chan *watch.Event)\r\n\tdone := make(chan struct{})\r\n\twatcher, err := watch.NewWatcher(c.ctx, c.etcdClient, c.prefix, c.indexDir(index, val), c.template)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tgo func() (retErr error) {\r\n\t\tdefer func() {\r\n\t\t\tif retErr != nil {\r\n\t\t\t\teventCh <- &watch.Event{\r\n\t\t\t\t\tType: watch.EventError,\r\n\t\t\t\t\tErr:  retErr,\r\n\t\t\t\t}\r\n\t\t\t\twatcher.Close()\r\n\t\t\t}\r\n\t\t\tclose(eventCh)\r\n\t\t}()\r\n\t\tfor {\r\n\t\t\tvar ev *watch.Event\r\n\t\t\tvar ok bool\r\n\t\t\tselect {\r\n\t\t\tcase ev, ok = <-watcher.Watch():\r\n\t\t\tcase <-done:\r\n\t\t\t\twatcher.Close()\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\tif !ok {\r\n\t\t\t\twatcher.Close()\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\tvar directEv *watch.Event\r\n\t\t\tswitch ev.Type {\r\n\t\t\tcase watch.EventError:\r\n\t\t\t\t\r\n\t\t\t\treturn ev.Err\r\n\t\t\tcase watch.EventPut:\r\n\t\t\t\tresp, err := c.get(c.Path(path.Base(string(ev.Key))))\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t\tif len(resp.Kvs) == 0 {\r\n\t\t\t\t\t\r\n\t\t\t\t\t\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\tdirectEv = &watch.Event{\r\n\t\t\t\t\tKey:      []byte(path.Base(string(ev.Key))),\r\n\t\t\t\t\tValue:    resp.Kvs[0].Value,\r\n\t\t\t\t\tType:     ev.Type,\r\n\t\t\t\t\tTemplate: c.template,\r\n\t\t\t\t}\r\n\t\t\tcase watch.EventDelete:\r\n\t\t\t\tdirectEv = &watch.Event{\r\n\t\t\t\t\tKey:      []byte(path.Base(string(ev.Key))),\r\n\t\t\t\t\tType:     ev.Type,\r\n\t\t\t\t\tTemplate: c.template,\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\teventCh <- directEv\r\n\t\t}\r\n\t}()\r\n\treturn watch.MakeWatcher(eventCh, done), nil\r\n}","code-length":627,"reference":"\/\/ WatchByIndex watches items in a collection that match a particular index","result":"Code too long,keep in 512.","score":[0.0593,0.0442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *readonlyCollection) WatchOne(key string) (watch.Watcher, error) {\r\n\treturn watch.NewWatcher(c.ctx, c.etcdClient, c.prefix, c.Path(key), c.template)\r\n}","code-length":66,"reference":"\/\/ WatchOne watches a given item.  The first value returned from the watch\n\/\/ will be the current value of the item.","result":"Watch the collection.","score":[0.0007,0.0498]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *readonlyCollection) WatchOneF(key string, f func(e *watch.Event) error) error {\r\n\twatcher, err := watch.NewWatcher(c.ctx, c.etcdClient, c.prefix, c.Path(key), c.template)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer watcher.Close()\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase e := <-watcher.Watch():\r\n\t\t\tif err := f(e); err != nil {\r\n\t\t\t\tif err == errutil.ErrBreak {\r\n\t\t\t\t\treturn nil\r\n\t\t\t\t}\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\tcase <-c.ctx.Done():\r\n\t\t\treturn c.ctx.Err()\r\n\t\t}\r\n\t}\r\n}","code-length":206,"reference":"\/\/ WatchOneF watches a given item and executes a callback function each time an event occurs.\n\/\/ The first value returned from the watch will be the current value of the item.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cache) Get(key string) (io.ReadCloser, error) {\r\n\tc.mu.Lock()\r\n\tdefer c.mu.Unlock()\r\n\tif !c.keys[key] {\r\n\t\treturn nil, fmt.Errorf(\"key %v not found in cache\", key)\r\n\t}\r\n\tf, err := os.Open(filepath.Join(c.root, key))\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn f, nil\r\n}","code-length":136,"reference":"\/\/ Get gets a key's value by returning an io.ReadCloser that should be closed when done.","result":"Get a value from a cache.","score":[0.048,0.1]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cache) Keys() []string {\r\n\tc.mu.Lock()\r\n\tdefer c.mu.Unlock()\r\n\tvar keys []string\r\n\tfor key := range c.keys {\r\n\t\tkeys = append(keys, key)\r\n\t}\r\n\tsort.Strings(keys)\r\n\treturn keys\r\n}","code-length":90,"reference":"\/\/ Keys returns the keys in sorted order.","result":"Return the keys of the cache.","score":[0.1956,0.1923]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cache) Clear() error {\r\n\tc.mu.Lock()\r\n\tdefer c.mu.Unlock()\r\n\tdefer func() {\r\n\t\tc.keys = make(map[string]bool)\r\n\t}()\r\n\tfor key := range c.keys {\r\n\t\tif err := os.Remove(filepath.Join(c.root, key)); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":125,"reference":"\/\/ Clear clears the cache.","result":"Clear the cache.","score":[0.328,0.5324]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewHTTPServer(address string) (http.Handler, error) {\r\n\trouter := httprouter.New()\r\n\ts := &server{\r\n\t\trouter:     router,\r\n\t\taddress:    address,\r\n\t\thttpClient: &http.Client{},\r\n\t}\r\n\trouter.GET(getFilePath, s.getFileHandler)\r\n\trouter.GET(servicePath, s.serviceHandler)\r\n\trouter.POST(loginPath, s.authLoginHandler)\r\n\trouter.POST(logoutPath, s.authLogoutHandler)\r\n\trouter.POST(servicePath, s.serviceHandler)\r\n\trouter.NotFound = http.HandlerFunc(notFound)\r\n\treturn s, nil\r\n}","code-length":181,"reference":"\/\/ NewHTTPServer returns a Pachyderm HTTP server.","result":"Create a new HTTP server.","score":[0.2521,0.3758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDeployServer(kubeClient *kube.Clientset, kubeNamespace string) deploy.APIServer {\r\n\treturn &apiServer{\r\n\t\tkubeClient:    kubeClient,\r\n\t\tkubeNamespace: kubeNamespace,\r\n\t}\r\n}","code-length":70,"reference":"\/\/ NewDeployServer creates a deploy server","result":"Create a new deployment server.","score":[0.1967,0.4331]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Export(opts *assets.AssetOpts, out io.Writer) error {\r\n\tclient, err := docker.NewClientFromEnv()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tauthConfigs, err := docker.NewAuthConfigurationsFromDockerCfg()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"error parsing auth: %s, try running `docker login`\", err.Error())\r\n\t}\r\n\tif len(authConfigs.Configs) == 0 {\r\n\t\treturn fmt.Errorf(\"didn't find any valid auth configurations\")\r\n\t}\r\n\timages := assets.Images(opts)\r\n\tfor _, image := range images {\r\n\t\trepository, tag := docker.ParseRepositoryTag(image)\r\n\t\tpulled := false\r\n\t\tvar loopErr []error\r\n\t\tfor registry, authConfig := range authConfigs.Configs {\r\n\t\t\tif err := client.PullImage(\r\n\t\t\t\tdocker.PullImageOptions{\r\n\t\t\t\t\tRepository:        repository,\r\n\t\t\t\t\tTag:               tag,\r\n\t\t\t\t\tInactivityTimeout: 5 * time.Second,\r\n\t\t\t\t},\r\n\t\t\t\tauthConfig,\r\n\t\t\t); err != nil {\r\n\t\t\t\tloopErr = append(loopErr, fmt.Errorf(\"error pulling from %s: %v\", registry, err))\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tpulled = true\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif !pulled {\r\n\t\t\terrStr := \"\"\r\n\t\t\tfor _, err := range loopErr {\r\n\t\t\t\terrStr += err.Error() + \"\\n\"\r\n\t\t\t}\r\n\t\t\treturn fmt.Errorf(\"errors pulling image %s:%s:\\n%s\", repository, tag, errStr)\r\n\t\t}\r\n\t}\r\n\treturn client.ExportImages(docker.ExportImagesOptions{\r\n\t\tNames:        images,\r\n\t\tOutputStream: out,\r\n\t})\r\n}","code-length":483,"reference":"\/\/ Export a tarball of the images needed by a deployment.","result":"Export assets to a file.","score":[0.0861,0.0962]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Import(opts *assets.AssetOpts, in io.Reader) error {\r\n\tclient, err := docker.NewClientFromEnv()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tauthConfigs, err := docker.NewAuthConfigurationsFromDockerCfg()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"error parsing auth: %s, try running `docker login`\", err.Error())\r\n\t}\r\n\tif len(authConfigs.Configs) == 0 {\r\n\t\treturn fmt.Errorf(\"didn't find any valid auth configurations\")\r\n\t}\r\n\tif err := client.LoadImage(docker.LoadImageOptions{\r\n\t\tInputStream: in,\r\n\t}); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tregistry := opts.Registry\r\n\topts.Registry = \"\"\r\n\timages := assets.Images(opts)\r\n\topts.Registry = registry\r\n\tfor _, image := range images {\r\n\t\trepository, tag := docker.ParseRepositoryTag(image)\r\n\t\tregistryRepo := assets.AddRegistry(opts.Registry, repository)\r\n\t\tif err := client.TagImage(image, docker.TagImageOptions{\r\n\t\t\tRepo: registryRepo,\r\n\t\t\tTag:  tag,\r\n\t\t},\r\n\t\t); err != nil {\r\n\t\t\treturn fmt.Errorf(\"error tagging image: %v\", err)\r\n\t\t}\r\n\t\tpushed := false\r\n\t\tvar loopErr []error\r\n\t\tfor registry, authConfig := range authConfigs.Configs {\r\n\t\t\tif err := client.PushImage(\r\n\t\t\t\tdocker.PushImageOptions{\r\n\t\t\t\t\tName:              registryRepo,\r\n\t\t\t\t\tTag:               tag,\r\n\t\t\t\t\tRegistry:          opts.Registry,\r\n\t\t\t\t\tInactivityTimeout: 5 * time.Second,\r\n\t\t\t\t},\r\n\t\t\t\tauthConfig,\r\n\t\t\t); err != nil {\r\n\t\t\t\tloopErr = append(loopErr, fmt.Errorf(\"error pushing to %s: %v\", registry, err))\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tpushed = true\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif !pushed {\r\n\t\t\terrStr := \"\"\r\n\t\t\tfor _, err := range loopErr {\r\n\t\t\t\terrStr += err.Error() + \"\\n\"\r\n\t\t\t}\r\n\t\t\treturn fmt.Errorf(\"errors pushing image %s:%s:\\n%s\", registryRepo, tag, errStr)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":623,"reference":"\/\/ Import a tarball of the images needed by a deployment such as the one\n\/\/ created by Export and push those images to the registry specific in opts.","result":"Code too long,keep in 512.","score":[0.002,0.0188]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DatumTagPrefix(salt string) string {\r\n\t\r\n\t\r\n\th := sha256.New()\r\n\th.Write([]byte(salt))\r\n\treturn hex.EncodeToString(h.Sum(nil))[:4]\r\n}","code-length":68,"reference":"\/\/ DatumTagPrefix hashes a pipeline salt to a string of a fixed size for use as\n\/\/ the prefix for datum output trees. This prefix allows us to do garbage\n\/\/ collection correctly.","result":"Generate the tag prefix.","score":[0.0002,0.0166]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPFSInput(repo string, glob string) *pps.Input {\r\n\treturn &pps.Input{\r\n\t\tPfs: &pps.PFSInput{\r\n\t\t\tRepo: repo,\r\n\t\t\tGlob: glob,\r\n\t\t},\r\n\t}\r\n}","code-length":80,"reference":"\/\/ NewPFSInput returns a new PFS input. It only includes required options.","result":"Create a new input.","score":[0.0677,0.2282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPFSInputOpts(name string, repo string, branch string, glob string, lazy bool) *pps.Input {\r\n\treturn &pps.Input{\r\n\t\tPfs: &pps.PFSInput{\r\n\t\t\tName:   name,\r\n\t\t\tRepo:   repo,\r\n\t\t\tBranch: branch,\r\n\t\t\tGlob:   glob,\r\n\t\t\tLazy:   lazy,\r\n\t\t},\r\n\t}\r\n}","code-length":118,"reference":"\/\/ NewPFSInputOpts returns a new PFS input. It includes all options.","result":"Create a PFSInputOpts object.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewJobInput(repoName string, commitID string, glob string) *pps.JobInput {\r\n\treturn &pps.JobInput{\r\n\t\tCommit: NewCommit(repoName, commitID),\r\n\t\tGlob:   glob,\r\n\t}\r\n}","code-length":71,"reference":"\/\/ NewJobInput creates a pps.JobInput.","result":"Create a new Job object.","score":[0.2403,0.375]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPipelineInput(repoName string, glob string) *pps.PipelineInput {\r\n\treturn &pps.PipelineInput{\r\n\t\tRepo: NewRepo(repoName),\r\n\t\tGlob: glob,\r\n\t}\r\n}","code-length":66,"reference":"\/\/ NewPipelineInput creates a new pps.PipelineInput","result":"Create a new pipeline input.","score":[0.2782,0.4991]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) CreateJob(pipeline string, outputCommit *pfs.Commit) (*pps.Job, error) {\r\n\tjob, err := c.PpsAPIClient.CreateJob(\r\n\t\tc.Ctx(),\r\n\t\t&pps.CreateJobRequest{\r\n\t\t\tPipeline:     NewPipeline(pipeline),\r\n\t\t\tOutputCommit: outputCommit,\r\n\t\t},\r\n\t)\r\n\treturn job, grpcutil.ScrubGRPC(err)\r\n}","code-length":123,"reference":"\/\/ CreateJob creates and runs a job in PPS.\n\/\/ This function is mostly useful internally, users should generally run work\n\/\/ by creating pipelines as well.","result":"Create a new job.","score":[0.001,0.0405]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) ListJob(pipelineName string, inputCommit []*pfs.Commit, outputCommit *pfs.Commit) ([]*pps.JobInfo, error) {\r\n\tvar result []*pps.JobInfo\r\n\tif err := c.ListJobF(pipelineName, inputCommit, outputCommit, func(ji *pps.JobInfo) error {\r\n\t\tresult = append(result, ji)\r\n\t\treturn nil\r\n\t}); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn result, nil\r\n}","code-length":144,"reference":"\/\/ ListJob returns info about all jobs.\n\/\/ If pipelineName is non empty then only jobs that were started by the named pipeline will be returned\n\/\/ If inputCommit is non-nil then only jobs which took the specific commits as inputs will be returned.\n\/\/ The order of the inputCommits doesn't matter.\n\/\/ If outputCommit is non-nil then only the job which created that commit as output will be returned.","result":"List jobs in a.","score":[0.0,0.0158]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) ListJobF(pipelineName string, inputCommit []*pfs.Commit, outputCommit *pfs.Commit, f func(*pps.JobInfo) error) error {\r\n\tvar pipeline *pps.Pipeline\r\n\tif pipelineName != \"\" {\r\n\t\tpipeline = NewPipeline(pipelineName)\r\n\t}\r\n\tclient, err := c.PpsAPIClient.ListJobStream(\r\n\t\tc.Ctx(),\r\n\t\t&pps.ListJobRequest{\r\n\t\t\tPipeline:     pipeline,\r\n\t\t\tInputCommit:  inputCommit,\r\n\t\t\tOutputCommit: outputCommit,\r\n\t\t})\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tfor {\r\n\t\tji, err := client.Recv()\r\n\t\tif err == io.EOF {\r\n\t\t\treturn nil\r\n\t\t} else if err != nil {\r\n\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\t\tif err := f(ji); err != nil {\r\n\t\t\tif err == errutil.ErrBreak {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n}","code-length":306,"reference":"\/\/ ListJobF returns info about all jobs, calling f with each JobInfo.\n\/\/ If f returns an error iteration of jobs will stop and ListJobF will return\n\/\/ that error, unless the error is errutil.ErrBreak in which case it will\n\/\/ return nil.\n\/\/ If pipelineName is non empty then only jobs that were started by the named pipeline will be returned\n\/\/ If inputCommit is non-nil then only jobs which took the specific commits as inputs will be returned.\n\/\/ The order of the inputCommits doesn't matter.\n\/\/ If outputCommit is non-nil then only the job which created that commit as output will be returned.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) FlushJob(commits []*pfs.Commit, toPipelines []string, f func(*pps.JobInfo) error) error {\r\n\treq := &pps.FlushJobRequest{\r\n\t\tCommits: commits,\r\n\t}\r\n\tfor _, pipeline := range toPipelines {\r\n\t\treq.ToPipelines = append(req.ToPipelines, NewPipeline(pipeline))\r\n\t}\r\n\tclient, err := c.PpsAPIClient.FlushJob(c.Ctx(), req)\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tfor {\r\n\t\tjobInfo, err := client.Recv()\r\n\t\tif err != nil {\r\n\t\t\tif err == io.EOF {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\t\tif err := f(jobInfo); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n}","code-length":259,"reference":"\/\/ FlushJob calls f with all the jobs which were triggered by commits.\n\/\/ If toPipelines is non-nil then only the jobs between commits and those\n\/\/ pipelines in the DAG will be returned.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) FlushJobAll(commits []*pfs.Commit, toPipelines []string) ([]*pps.JobInfo, error) {\r\n\tvar result []*pps.JobInfo\r\n\tif err := c.FlushJob(commits, toPipelines, func(ji *pps.JobInfo) error {\r\n\t\tresult = append(result, ji)\r\n\t\treturn nil\r\n\t}); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn result, nil\r\n}","code-length":134,"reference":"\/\/ FlushJobAll returns all the jobs which were triggered by commits.\n\/\/ If toPipelines is non-nil then only the jobs between commits and those\n\/\/ pipelines in the DAG will be returned.","result":"Flush all jobs.","score":[0.0,0.0172]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) DeleteJob(jobID string) error {\r\n\t_, err := c.PpsAPIClient.DeleteJob(\r\n\t\tc.Ctx(),\r\n\t\t&pps.DeleteJobRequest{\r\n\t\t\tJob: NewJob(jobID),\r\n\t\t},\r\n\t)\r\n\treturn grpcutil.ScrubGRPC(err)\r\n}","code-length":96,"reference":"\/\/ DeleteJob deletes a job.","result":"Delete a job.","score":[0.2964,0.6134]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) StopJob(jobID string) error {\r\n\t_, err := c.PpsAPIClient.StopJob(\r\n\t\tc.Ctx(),\r\n\t\t&pps.StopJobRequest{\r\n\t\t\tJob: NewJob(jobID),\r\n\t\t},\r\n\t)\r\n\treturn grpcutil.ScrubGRPC(err)\r\n}","code-length":96,"reference":"\/\/ StopJob stops a job.","result":"Stop a running job.","score":[0.2959,0.5215]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) RestartDatum(jobID string, datumFilter []string) error {\r\n\t_, err := c.PpsAPIClient.RestartDatum(\r\n\t\tc.Ctx(),\r\n\t\t&pps.RestartDatumRequest{\r\n\t\t\tJob:         NewJob(jobID),\r\n\t\t\tDataFilters: datumFilter,\r\n\t\t},\r\n\t)\r\n\treturn grpcutil.ScrubGRPC(err)\r\n}","code-length":113,"reference":"\/\/ RestartDatum restarts a datum that's being processed as part of a job.\n\/\/ datumFilter is a slice of strings which are matched against either the Path\n\/\/ or Hash of the datum, the order of the strings in datumFilter is irrelevant.","result":"Restart datums.","score":[0,0.0132]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) ListDatum(jobID string, pageSize int64, page int64) (*pps.ListDatumResponse, error) {\r\n\tclient, err := c.PpsAPIClient.ListDatumStream(\r\n\t\tc.Ctx(),\r\n\t\t&pps.ListDatumRequest{\r\n\t\t\tJob:      NewJob(jobID),\r\n\t\t\tPageSize: pageSize,\r\n\t\t\tPage:     page,\r\n\t\t},\r\n\t)\r\n\tif err != nil {\r\n\t\treturn nil, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tresp := &pps.ListDatumResponse{}\r\n\tfirst := true\r\n\tfor {\r\n\t\tr, err := client.Recv()\r\n\t\tif err == io.EOF {\r\n\t\t\tbreak\r\n\t\t} else if err != nil {\r\n\t\t\treturn nil, grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\t\tif first {\r\n\t\t\tresp.TotalPages = r.TotalPages\r\n\t\t\tresp.Page = r.Page\r\n\t\t\tfirst = false\r\n\t\t}\r\n\t\tresp.DatumInfos = append(resp.DatumInfos, r.DatumInfo)\r\n\t}\r\n\treturn resp, nil\r\n}","code-length":308,"reference":"\/\/ ListDatum returns info about all datums in a Job","result":"Stream job data.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) ListDatumF(jobID string, pageSize int64, page int64, f func(di *pps.DatumInfo) error) error {\r\n\tclient, err := c.PpsAPIClient.ListDatumStream(\r\n\t\tc.Ctx(),\r\n\t\t&pps.ListDatumRequest{\r\n\t\t\tJob:      NewJob(jobID),\r\n\t\t\tPageSize: pageSize,\r\n\t\t\tPage:     page,\r\n\t\t},\r\n\t)\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tfor {\r\n\t\tresp, err := client.Recv()\r\n\t\tif err == io.EOF {\r\n\t\t\treturn nil\r\n\t\t} else if err != nil {\r\n\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\t\tif err := f(resp.DatumInfo); err != nil {\r\n\t\t\tif err == errutil.ErrBreak {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n}","code-length":272,"reference":"\/\/ ListDatumF returns info about all datums in a Job, calling f with each datum info.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) InspectDatum(jobID string, datumID string) (*pps.DatumInfo, error) {\r\n\tdatumInfo, err := c.PpsAPIClient.InspectDatum(\r\n\t\tc.Ctx(),\r\n\t\t&pps.InspectDatumRequest{\r\n\t\t\tDatum: &pps.Datum{\r\n\t\t\t\tID:  datumID,\r\n\t\t\t\tJob: NewJob(jobID),\r\n\t\t\t},\r\n\t\t},\r\n\t)\r\n\tif err != nil {\r\n\t\treturn nil, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn datumInfo, nil\r\n}","code-length":162,"reference":"\/\/ InspectDatum returns info about a single datum","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *LogsIter) Next() bool {\r\n\tif l.err != nil {\r\n\t\tl.msg = nil\r\n\t\treturn false\r\n\t}\r\n\tl.msg, l.err = l.logsClient.Recv()\r\n\tif l.err != nil {\r\n\t\treturn false\r\n\t}\r\n\treturn true\r\n}","code-length":95,"reference":"\/\/ Next retrieves the next relevant log message from pachd","result":"Iterate over the logs.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) InspectPipeline(pipelineName string) (*pps.PipelineInfo, error) {\r\n\tpipelineInfo, err := c.PpsAPIClient.InspectPipeline(\r\n\t\tc.Ctx(),\r\n\t\t&pps.InspectPipelineRequest{\r\n\t\t\tPipeline: NewPipeline(pipelineName),\r\n\t\t},\r\n\t)\r\n\treturn pipelineInfo, grpcutil.ScrubGRPC(err)\r\n}","code-length":110,"reference":"\/\/ InspectPipeline returns info about a specific pipeline.","result":"Call the client to get pipeline information.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) ListPipeline() ([]*pps.PipelineInfo, error) {\r\n\tpipelineInfos, err := c.PpsAPIClient.ListPipeline(\r\n\t\tc.Ctx(),\r\n\t\t&pps.ListPipelineRequest{},\r\n\t)\r\n\tif err != nil {\r\n\t\treturn nil, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn pipelineInfos.PipelineInfo, nil\r\n}","code-length":113,"reference":"\/\/ ListPipeline returns info about all pipelines.","result":"List the pipeline in the current context.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) DeletePipeline(name string, force bool) error {\r\n\t_, err := c.PpsAPIClient.DeletePipeline(\r\n\t\tc.Ctx(),\r\n\t\t&pps.DeletePipelineRequest{\r\n\t\t\tPipeline: NewPipeline(name),\r\n\t\t\tForce:    force,\r\n\t\t},\r\n\t)\r\n\treturn grpcutil.ScrubGRPC(err)\r\n}","code-length":107,"reference":"\/\/ DeletePipeline deletes a pipeline along with its output Repo.","result":"Delete a pipeline.","score":[0.0396,0.2016]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) StartPipeline(name string) error {\r\n\t_, err := c.PpsAPIClient.StartPipeline(\r\n\t\tc.Ctx(),\r\n\t\t&pps.StartPipelineRequest{\r\n\t\t\tPipeline: NewPipeline(name),\r\n\t\t},\r\n\t)\r\n\treturn grpcutil.ScrubGRPC(err)\r\n}","code-length":95,"reference":"\/\/ StartPipeline restarts a stopped pipeline.","result":"Start a pipeline.","score":[0.1786,0.1754]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) StopPipeline(name string) error {\r\n\t_, err := c.PpsAPIClient.StopPipeline(\r\n\t\tc.Ctx(),\r\n\t\t&pps.StopPipelineRequest{\r\n\t\t\tPipeline: NewPipeline(name),\r\n\t\t},\r\n\t)\r\n\treturn grpcutil.ScrubGRPC(err)\r\n}","code-length":95,"reference":"\/\/ StopPipeline prevents a pipeline from processing things, it can be restarted\n\/\/ with StartPipeline.","result":"Stop a pipeline.","score":[0.0075,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) RerunPipeline(name string, include []*pfs.Commit, exclude []*pfs.Commit) error {\r\n\t_, err := c.PpsAPIClient.RerunPipeline(\r\n\t\tc.Ctx(),\r\n\t\t&pps.RerunPipelineRequest{\r\n\t\t\tPipeline: NewPipeline(name),\r\n\t\t\tInclude:  include,\r\n\t\t\tExclude:  exclude,\r\n\t\t},\r\n\t)\r\n\treturn grpcutil.ScrubGRPC(err)\r\n}","code-length":132,"reference":"\/\/ RerunPipeline reruns a pipeline over a given set of commits. Exclude and\n\/\/ include are filters that either include or exclude the ancestors of the\n\/\/ given commits.  A commit is considered the ancestor of itself. The behavior\n\/\/ is the same as that of ListCommit.","result":"Run a pipeline.","score":[0.0,0.0117]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) CreatePipelineService(\r\n\tname string,\r\n\timage string,\r\n\tcmd []string,\r\n\tstdin []string,\r\n\tparallelismSpec *pps.ParallelismSpec,\r\n\tinput *pps.Input,\r\n\tupdate bool,\r\n\tinternalPort int32,\r\n\texternalPort int32,\r\n) error {\r\n\t_, err := c.PpsAPIClient.CreatePipeline(\r\n\t\tc.Ctx(),\r\n\t\t&pps.CreatePipelineRequest{\r\n\t\t\tPipeline: NewPipeline(name),\r\n\t\t\tTransform: &pps.Transform{\r\n\t\t\t\tImage: image,\r\n\t\t\t\tCmd:   cmd,\r\n\t\t\t\tStdin: stdin,\r\n\t\t\t},\r\n\t\t\tParallelismSpec: parallelismSpec,\r\n\t\t\tInput:           input,\r\n\t\t\tUpdate:          update,\r\n\t\t\tService: &pps.Service{\r\n\t\t\t\tInternalPort: internalPort,\r\n\t\t\t\tExternalPort: externalPort,\r\n\t\t\t},\r\n\t\t},\r\n\t)\r\n\treturn grpcutil.ScrubGRPC(err)\r\n}","code-length":275,"reference":"\/\/ CreatePipelineService creates a new pipeline service.","result":"Create a new pipeline service.","score":[0.5042,0.7324]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetDatumTotalTime(s *pps.ProcessStats) time.Duration {\r\n\ttotalDuration := time.Duration(0)\r\n\tduration, _ := types.DurationFromProto(s.DownloadTime)\r\n\ttotalDuration += duration\r\n\tduration, _ = types.DurationFromProto(s.ProcessTime)\r\n\ttotalDuration += duration\r\n\tduration, _ = types.DurationFromProto(s.UploadTime)\r\n\ttotalDuration += duration\r\n\treturn totalDuration\r\n}","code-length":123,"reference":"\/\/ GetDatumTotalTime sums the timing stats from a DatumInfo","result":"Calculate the total time of all the data sets.","score":[0.1219,0.1667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Mount(c *client.APIClient, mountPoint string, opts *Options) error {\r\n\tnfs := pathfs.NewPathNodeFs(newFileSystem(c, opts.getCommits()), nil)\r\n\tserver, _, err := nodefs.MountRoot(mountPoint, nfs.Root(), opts.getFuse())\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"nodefs.MountRoot: %v\", err)\r\n\t}\r\n\tsigChan := make(chan os.Signal, 1)\r\n\tsignal.Notify(sigChan, os.Interrupt)\r\n\tgo func() {\r\n\t\tselect {\r\n\t\tcase <-sigChan:\r\n\t\tcase <-opts.getUnmount():\r\n\t\t}\r\n\t\tserver.Unmount()\r\n\t}()\r\n\tserver.Serve()\r\n\treturn nil\r\n}","code-length":213,"reference":"\/\/ Mount pfs to mountPoint, opts may be left nil.","result":"Mount a filesystem.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewBufPool(size int) *BufPool {\r\n\treturn &BufPool{sync.Pool{\r\n\t\tNew: func() interface{} { return make([]byte, size) },\r\n\t}}\r\n}","code-length":60,"reference":"\/\/ NewBufPool creates a new BufPool that returns buffers of the given size.","result":"Create a new buffer pool.","score":[0.0686,0.3074]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StorageRootFromEnv() (string, error) {\r\n\tstorageRoot, ok := os.LookupEnv(PachRootEnvVar)\r\n\tif !ok {\r\n\t\treturn \"\", fmt.Errorf(\"%s not found\", PachRootEnvVar)\r\n\t}\r\n\tstorageBackend, ok := os.LookupEnv(StorageBackendEnvVar)\r\n\tif !ok {\r\n\t\treturn \"\", fmt.Errorf(\"%s not found\", StorageBackendEnvVar)\r\n\t}\r\n\t\r\n\tswitch storageBackend {\r\n\tcase Amazon:\r\n\t\tfallthrough\r\n\tcase Minio:\r\n\t\tif len(storageRoot) > 0 && storageRoot[0] == '\/' {\r\n\t\t\tstorageRoot = storageRoot[1:]\r\n\t\t}\r\n\t}\r\n\treturn storageRoot, nil\r\n}","code-length":201,"reference":"\/\/ StorageRootFromEnv gets the storage root based on environment variables.","result":"Get the storage root from the environment.","score":[0.2167,0.3254]}
{"code":"\/*is used to<extra_id_0>\r\nfunc BlockPathFromEnv(block *pfs.Block) (string, error) {\r\n\tstorageRoot, err := StorageRootFromEnv()\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn filepath.Join(storageRoot, \"block\", block.Hash), nil\r\n}","code-length":82,"reference":"\/\/ BlockPathFromEnv gets the path to an object storage block based on environment variables.","result":"Generate the block path from the environment.","score":[0.0782,0.1128]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewGoogleClient(bucket string, opts []option.ClientOption) (Client, error) {\r\n\treturn newGoogleClient(bucket, opts)\r\n}","code-length":45,"reference":"\/\/ NewGoogleClient creates a google client with the given bucket name.","result":"Create a new Google client.","score":[0.0724,0.2457]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewGoogleClientFromSecret(bucket string) (Client, error) {\r\n\tvar err error\r\n\tif bucket == \"\" {\r\n\t\tbucket, err = readSecretFile(\"\/google-bucket\")\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"google-bucket not found\")\r\n\t\t}\r\n\t}\r\n\tcred, err := readSecretFile(\"\/google-cred\")\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"google-cred not found\")\r\n\t}\r\n\tvar opts []option.ClientOption\r\n\tif cred != \"\" {\r\n\t\topts = append(opts, option.WithCredentialsFile(secretFile(\"\/google-cred\")))\r\n\t} else {\r\n\t\topts = append(opts, option.WithTokenSource(google.ComputeTokenSource(\"\")))\r\n\t}\r\n\treturn NewGoogleClient(bucket, opts)\r\n}","code-length":228,"reference":"\/\/ NewGoogleClientFromSecret creates a google client by reading credentials\n\/\/ from a mounted GoogleSecret. You may pass \"\" for bucket in which case it\n\/\/ will read the bucket from the secret.","result":"Create a client from a secret file.","score":[0.0076,0.1261]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewGoogleClientFromEnv() (Client, error) {\r\n\tbucket, ok := os.LookupEnv(GoogleBucketEnvVar)\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"%s not found\", GoogleBucketEnvVar)\r\n\t}\r\n\tcreds, ok := os.LookupEnv(GoogleCredEnvVar)\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"%s not found\", GoogleCredEnvVar)\r\n\t}\r\n\topts := []option.ClientOption{option.WithCredentialsJSON([]byte(creds))}\r\n\treturn NewGoogleClient(bucket, opts)\r\n}","code-length":156,"reference":"\/\/ NewGoogleClientFromEnv creates a Google client based on environment variables.","result":"Create a new client from environment variables.","score":[0.1769,0.4598]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMicrosoftClientFromSecret(container string) (Client, error) {\r\n\tvar err error\r\n\tif container == \"\" {\r\n\t\tcontainer, err = readSecretFile(\"\/microsoft-container\")\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"microsoft-container not found\")\r\n\t\t}\r\n\t}\r\n\tid, err := readSecretFile(\"\/microsoft-id\")\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"microsoft-id not found\")\r\n\t}\r\n\tsecret, err := readSecretFile(\"\/microsoft-secret\")\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"microsoft-secret not found\")\r\n\t}\r\n\treturn NewMicrosoftClient(container, id, secret)\r\n}","code-length":198,"reference":"\/\/ NewMicrosoftClientFromSecret creates a microsoft client by reading\n\/\/ credentials from a mounted MicrosoftSecret. You may pass \"\" for container in\n\/\/ which case it will read the container from the secret.","result":"Create a new client from a secret file.","score":[0.0116,0.1257]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMicrosoftClientFromEnv() (Client, error) {\r\n\tcontainer, ok := os.LookupEnv(MicrosoftContainerEnvVar)\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"%s not found\", MicrosoftContainerEnvVar)\r\n\t}\r\n\tid, ok := os.LookupEnv(MicrosoftIDEnvVar)\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"%s not found\", MicrosoftIDEnvVar)\r\n\t}\r\n\tsecret, ok := os.LookupEnv(MicrosoftSecretEnvVar)\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"%s not found\", MicrosoftSecretEnvVar)\r\n\t}\r\n\treturn NewMicrosoftClient(container, id, secret)\r\n}","code-length":183,"reference":"\/\/ NewMicrosoftClientFromEnv creates a Microsoft client based on environment variables.","result":"Create a client from environment variables.","score":[0.1667,0.4646]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMinioClientFromSecret(bucket string) (Client, error) {\r\n\tvar err error\r\n\tif bucket == \"\" {\r\n\t\tbucket, err = readSecretFile(\"\/minio-bucket\")\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\tendpoint, err := readSecretFile(\"\/minio-endpoint\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tid, err := readSecretFile(\"\/minio-id\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tsecret, err := readSecretFile(\"\/minio-secret\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tsecure, err := readSecretFile(\"\/minio-secure\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tisS3V2, err := readSecretFile(\"\/minio-signature\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn NewMinioClient(endpoint, bucket, id, secret, secure == \"1\", isS3V2 == \"1\")\r\n}","code-length":306,"reference":"\/\/ NewMinioClientFromSecret constructs an s3 compatible client by reading\n\/\/ credentials from a mounted AmazonSecret. You may pass \"\" for bucket in which case it\n\/\/ will read the bucket from the secret.","result":"Create a new MinioClient from a secret file.","score":[0.0086,0.0328]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMinioClientFromEnv() (Client, error) {\r\n\tbucket, ok := os.LookupEnv(MinioBucketEnvVar)\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"%s not found\", MinioBucketEnvVar)\r\n\t}\r\n\tendpoint, ok := os.LookupEnv(MinioEndpointEnvVar)\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"%s not found\", MinioEndpointEnvVar)\r\n\t}\r\n\tid, ok := os.LookupEnv(MinioIDEnvVar)\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"%s not found\", MinioIDEnvVar)\r\n\t}\r\n\tsecret, ok := os.LookupEnv(MinioSecretEnvVar)\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"%s not found\", MinioSecretEnvVar)\r\n\t}\r\n\tsecure, ok := os.LookupEnv(MinioSecureEnvVar)\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"%s not found\", MinioSecureEnvVar)\r\n\t}\r\n\tisS3V2, ok := os.LookupEnv(MinioSignatureEnvVar)\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"%s not found\", MinioSignatureEnvVar)\r\n\t}\r\n\treturn NewMinioClient(endpoint, bucket, id, secret, secure == \"1\", isS3V2 == \"1\")\r\n}","code-length":360,"reference":"\/\/ NewMinioClientFromEnv creates a Minio client based on environment variables.","result":"Create a new MinioClient from environment variables.","score":[0.1647,0.3866]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewAmazonClientFromSecret(bucket string, reversed ...bool) (Client, error) {\r\n\t\r\n\tregion, err := readSecretFile(\"\/amazon-region\")\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"amazon-region not found\")\r\n\t}\r\n\t\r\n\tif bucket == \"\" {\r\n\t\tbucket, err = readSecretFile(\"\/amazon-bucket\")\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\tvar creds AmazonCreds\r\n\tcreds.ID, err = readSecretFile(\"\/amazon-id\")\r\n\tif err != nil && !os.IsNotExist(err) {\r\n\t\treturn nil, err\r\n\t}\r\n\tcreds.Secret, err = readSecretFile(\"\/amazon-secret\")\r\n\tif err != nil && !os.IsNotExist(err) {\r\n\t\treturn nil, err\r\n\t}\r\n\tcreds.Token, err = readSecretFile(\"\/amazon-token\")\r\n\tif err != nil && !os.IsNotExist(err) {\r\n\t\treturn nil, err\r\n\t}\r\n\tcreds.VaultAddress, err = readSecretFile(\"\/amazon-vault-addr\")\r\n\tif err != nil && !os.IsNotExist(err) {\r\n\t\treturn nil, err\r\n\t}\r\n\tcreds.VaultRole, err = readSecretFile(\"\/amazon-vault-role\")\r\n\tif err != nil && !os.IsNotExist(err) {\r\n\t\treturn nil, err\r\n\t}\r\n\tcreds.VaultToken, err = readSecretFile(\"\/amazon-vault-token\")\r\n\tif err != nil && !os.IsNotExist(err) {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tdistribution, err := readSecretFile(\"\/amazon-distribution\")\r\n\treturn NewAmazonClient(region, bucket, &creds, distribution, reversed...)\r\n}","code-length":476,"reference":"\/\/ NewAmazonClientFromSecret constructs an amazon client by reading credentials\n\/\/ from a mounted AmazonSecret. You may pass \"\" for bucket in which case it\n\/\/ will read the bucket from the secret.","result":"Create an Amazon client from a secret file.","score":[0.0116,0.1507]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewAmazonClientFromEnv() (Client, error) {\r\n\tregion, ok := os.LookupEnv(AmazonRegionEnvVar)\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"%s not found\", AmazonRegionEnvVar)\r\n\t}\r\n\tbucket, ok := os.LookupEnv(AmazonBucketEnvVar)\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"%s not found\", AmazonBucketEnvVar)\r\n\t}\r\n\tvar creds AmazonCreds\r\n\tcreds.ID, _ = os.LookupEnv(AmazonIDEnvVar)\r\n\tcreds.Secret, _ = os.LookupEnv(AmazonSecretEnvVar)\r\n\tcreds.Token, _ = os.LookupEnv(AmazonTokenEnvVar)\r\n\tcreds.VaultAddress, _ = os.LookupEnv(AmazonVaultAddrEnvVar)\r\n\tcreds.VaultRole, _ = os.LookupEnv(AmazonVaultRoleEnvVar)\r\n\tcreds.VaultToken, _ = os.LookupEnv(AmazonVaultTokenEnvVar)\r\n\tdistribution, _ := os.LookupEnv(AmazonDistributionEnvVar)\r\n\treturn NewAmazonClient(region, bucket, &creds, distribution)\r\n}","code-length":282,"reference":"\/\/ NewAmazonClientFromEnv creates a Amazon client based on environment variables.","result":"Create an AmazonClient from environment variables.","score":[0.1402,0.2662]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClientFromURLAndSecret(url *ObjectStoreURL, reversed ...bool) (c Client, err error) {\r\n\tswitch url.Store {\r\n\tcase \"s3\":\r\n\t\tc, err = NewAmazonClientFromSecret(url.Bucket, reversed...)\r\n\tcase \"gcs\":\r\n\t\tfallthrough\r\n\tcase \"gs\":\r\n\t\tc, err = NewGoogleClientFromSecret(url.Bucket)\r\n\tcase \"as\":\r\n\t\tfallthrough\r\n\tcase \"wasb\":\r\n\t\t\r\n\t\tc, err = NewMicrosoftClientFromSecret(url.Bucket)\r\n\tcase \"local\":\r\n\t\tc, err = NewLocalClient(\"\/\" + url.Bucket)\r\n\t}\r\n\tswitch {\r\n\tcase err != nil:\r\n\t\treturn nil, err\r\n\tcase c != nil:\r\n\t\treturn TracingObjClient(url.Store, c), nil\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"unrecognized object store: %s\", url.Bucket)\r\n\t}\r\n}","code-length":260,"reference":"\/\/ NewClientFromURLAndSecret constructs a client by parsing `URL` and then\n\/\/ constructing the correct client for that URL using secrets.","result":"Create a new object store client.","score":[0.0187,0.0269]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseURL(urlStr string) (*ObjectStoreURL, error) {\r\n\turl, err := url.Parse(urlStr)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error parsing url %v: %v\", urlStr, err)\r\n\t}\r\n\tswitch url.Scheme {\r\n\tcase \"s3\", \"gcs\", \"gs\", \"local\":\r\n\t\treturn &ObjectStoreURL{\r\n\t\t\tStore:  url.Scheme,\r\n\t\t\tBucket: url.Host,\r\n\t\t\tObject: strings.Trim(url.Path, \"\/\"),\r\n\t\t}, nil\r\n\tcase \"as\", \"wasb\":\r\n\t\t\r\n\t\tparts := strings.Split(strings.Trim(url.Path, \"\/\"), \"\/\")\r\n\t\tif len(parts) < 1 {\r\n\t\t\treturn nil, fmt.Errorf(\"malformed Azure URI: %v\", urlStr)\r\n\t\t}\r\n\t\treturn &ObjectStoreURL{\r\n\t\t\tStore:  url.Scheme,\r\n\t\t\tBucket: parts[0],\r\n\t\t\tObject: strings.Trim(path.Join(parts[1:]...), \"\/\"),\r\n\t\t}, nil\r\n\t}\r\n\treturn nil, fmt.Errorf(\"unrecognized object store: %s\", url.Scheme)\r\n}","code-length":317,"reference":"\/\/ ParseURL parses an URL into ObjectStoreURL.","result":"Parse an object store URL.","score":[0.1611,0.2757]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClientFromEnv(storageRoot string) (c Client, err error) {\r\n\tstorageBackend, ok := os.LookupEnv(StorageBackendEnvVar)\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"storage backend environment variable not found\")\r\n\t}\r\n\tswitch storageBackend {\r\n\tcase Amazon:\r\n\t\tc, err = NewAmazonClientFromEnv()\r\n\tcase Google:\r\n\t\tc, err = NewGoogleClientFromEnv()\r\n\tcase Microsoft:\r\n\t\tc, err = NewMicrosoftClientFromEnv()\r\n\tcase Minio:\r\n\t\tc, err = NewMinioClientFromEnv()\r\n\tcase Local:\r\n\t\tc, err = NewLocalClient(storageRoot)\r\n\t}\r\n\tswitch {\r\n\tcase err != nil:\r\n\t\treturn nil, err\r\n\tcase c != nil:\r\n\t\treturn TracingObjClient(storageBackend, c), nil\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"unrecognized storage backend: %s\", storageBackend)\r\n\t}\r\n}","code-length":265,"reference":"\/\/ NewClientFromEnv creates a client based on environment variables.","result":"Create a new client from environment variables.","score":[0.2041,0.5068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewExponentialBackOffConfig() *backoff.ExponentialBackOff {\r\n\tconfig := backoff.NewExponentialBackOff()\r\n\t\r\n\tconfig.InitialInterval = 1 * time.Second\r\n\tconfig.Multiplier = 2\r\n\tconfig.MaxInterval = 15 * time.Minute\r\n\treturn config\r\n}","code-length":84,"reference":"\/\/ NewExponentialBackOffConfig creates an exponential back-off config with\n\/\/ longer wait times than the default.","result":"Create a new backoff config.","score":[0,0.0357]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *BackoffReadCloser) Close() error {\r\n\tspan, _ := tracing.AddSpanToAnyExisting(b.ctx, \"obj\/BackoffReadCloser.Close\")\r\n\tdefer tracing.FinishAnySpan(span)\r\n\treturn b.reader.Close()\r\n}","code-length":74,"reference":"\/\/ Close closes the ReaderCloser contained in b.","result":"Close the backoff reader.","score":[0.1398,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *BackoffWriteCloser) Close() error {\r\n\tspan, _ := tracing.AddSpanToAnyExisting(b.ctx, \"obj\/BackoffWriteCloser.Close\")\r\n\tdefer tracing.FinishAnySpan(span)\r\n\terr := b.writer.Close()\r\n\tif b.client.IsIgnorable(err) {\r\n\t\treturn nil\r\n\t}\r\n\treturn err\r\n}","code-length":106,"reference":"\/\/ Close closes the WriteCloser contained in b.","result":"Close the backing file.","score":[0.1398,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsRetryable(client Client, err error) bool {\r\n\treturn isNetRetryable(err) || client.IsRetryable(err)\r\n}","code-length":45,"reference":"\/\/ IsRetryable determines if an operation should be retried given an error","result":"Avoid panic.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RunStdin(stdin io.Reader, args ...string) error {\r\n\treturn RunIO(IO{Stdin: stdin}, args...)\r\n}","code-length":44,"reference":"\/\/ RunStdin runs the command with the given stdin and arguments.","result":"Run the command .","score":[0.0785,0.1456]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RunIODirPath(ioObj IO, dirPath string, args ...string) error {\r\n\tvar debugStderr io.ReadWriter = bytes.NewBuffer(nil)\r\n\tvar stderr io.Writer = debugStderr\r\n\tif ioObj.Stderr != nil {\r\n\t\tstderr = io.MultiWriter(debugStderr, ioObj.Stderr)\r\n\t}\r\n\tcmd := exec.Command(args[0], args[1:]...)\r\n\tcmd.Stdin = ioObj.Stdin\r\n\tcmd.Stdout = ioObj.Stdout\r\n\tcmd.Stderr = stderr\r\n\tcmd.Dir = dirPath\r\n\tif err := cmd.Run(); err != nil {\r\n\t\tdata, _ := ioutil.ReadAll(debugStderr)\r\n\t\tif data != nil && len(data) > 0 {\r\n\t\t\treturn fmt.Errorf(\"%s: %s\\n%s\", strings.Join(args, \" \"), err.Error(), string(data))\r\n\t\t}\r\n\t\treturn fmt.Errorf(\"%s: %s\", strings.Join(args, \" \"), err.Error())\r\n\t}\r\n\treturn nil\r\n}","code-length":274,"reference":"\/\/ RunIODirPath runs the command with the given IO and arguments in the given directory specified by dirPath.","result":"Run a command on a directory.","score":[0.0261,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewAuthServer(env *serviceenv.ServiceEnv, etcdPrefix string, public bool) (authclient.APIServer, error) {\r\n\ts := &apiServer{\r\n\t\tenv:        env,\r\n\t\tpachLogger: log.NewLogger(\"authclient.API\"),\r\n\t\tadminCache: make(map[string]struct{}),\r\n\t\ttokens: col.NewCollection(\r\n\t\t\tenv.GetEtcdClient(),\r\n\t\t\tpath.Join(etcdPrefix, tokensPrefix),\r\n\t\t\tnil,\r\n\t\t\t&authclient.TokenInfo{},\r\n\t\t\tnil,\r\n\t\t\tnil,\r\n\t\t),\r\n\t\tauthenticationCodes: col.NewCollection(\r\n\t\t\tenv.GetEtcdClient(),\r\n\t\t\tpath.Join(etcdPrefix, authenticationCodesPrefix),\r\n\t\t\tnil,\r\n\t\t\t&authclient.OTPInfo{},\r\n\t\t\tnil,\r\n\t\t\tnil,\r\n\t\t),\r\n\t\tacls: col.NewCollection(\r\n\t\t\tenv.GetEtcdClient(),\r\n\t\t\tpath.Join(etcdPrefix, aclsPrefix),\r\n\t\t\tnil,\r\n\t\t\t&authclient.ACL{},\r\n\t\t\tnil,\r\n\t\t\tnil,\r\n\t\t),\r\n\t\tadmins: col.NewCollection(\r\n\t\t\tenv.GetEtcdClient(),\r\n\t\t\tpath.Join(etcdPrefix, adminsPrefix),\r\n\t\t\tnil,\r\n\t\t\t&types.BoolValue{},\r\n\t\t\tnil,\r\n\t\t\tnil,\r\n\t\t),\r\n\t\tmembers: col.NewCollection(\r\n\t\t\tenv.GetEtcdClient(),\r\n\t\t\tpath.Join(etcdPrefix, membersPrefix),\r\n\t\t\tnil,\r\n\t\t\t&authclient.Groups{},\r\n\t\t\tnil,\r\n\t\t\tnil,\r\n\t\t),\r\n\t\tgroups: col.NewCollection(\r\n\t\t\tenv.GetEtcdClient(),\r\n\t\t\tpath.Join(etcdPrefix, groupsPrefix),\r\n\t\t\tnil,\r\n\t\t\t&authclient.Users{},\r\n\t\t\tnil,\r\n\t\t\tnil,\r\n\t\t),\r\n\t\tauthConfig: col.NewCollection(\r\n\t\t\tenv.GetEtcdClient(),\r\n\t\t\tpath.Join(etcdPrefix, configKey),\r\n\t\t\tnil,\r\n\t\t\t&authclient.AuthConfig{},\r\n\t\t\tnil,\r\n\t\t\tnil,\r\n\t\t),\r\n\t\tpublic: public,\r\n\t}\r\n\tgo s.retrieveOrGeneratePPSToken()\r\n\tgo s.watchAdmins(path.Join(etcdPrefix, adminsPrefix))\r\n\tif public {\r\n\t\t\r\n\t\t\r\n\t\tgo s.serveSAML()\r\n\t}\r\n\t\r\n\tgo s.watchConfig()\r\n\treturn s, nil\r\n}","code-length":682,"reference":"\/\/ NewAuthServer returns an implementation of authclient.APIServer.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *apiServer) expiredClusterAdminCheck(ctx context.Context, username string) error {\r\n\tstate, err := a.getEnterpriseTokenState()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"error confirming Pachyderm Enterprise token: %v\", err)\r\n\t}\r\n\tisAdmin, err := a.isAdmin(ctx, username)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif state != enterpriseclient.State_ACTIVE && !isAdmin {\r\n\t\treturn errors.New(\"Pachyderm Enterprise is not active in this \" +\r\n\t\t\t\"cluster (until Pachyderm Enterprise is re-activated or Pachyderm \" +\r\n\t\t\t\"auth is deactivated, only cluster admins can perform any operations)\")\r\n\t}\r\n\treturn nil\r\n}","code-length":216,"reference":"\/\/ expiredClusterAdminCheck enforces that if the cluster's enterprise token is\n\/\/ expired, only admins may log in.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *apiServer) getOneTimePassword(ctx context.Context, username string, expiration time.Time) (code string, err error) {\r\n\t\r\n\totpInfo := &authclient.OTPInfo{\r\n\t\tSubject: username,\r\n\t}\r\n\tif !expiration.IsZero() {\r\n\t\texpirationProto, err := types.TimestampProto(expiration)\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"could not create OTP with expiration time %s: %v\",\r\n\t\t\t\texpiration.String(), err)\r\n\t\t}\r\n\t\totpInfo.SessionExpiration = expirationProto\r\n\t}\r\n\t\r\n\tcode = \"auth_code:\" + uuid.NewWithoutDashes()\r\n\tif _, err = col.NewSTM(ctx, a.env.GetEtcdClient(), func(stm col.STM) error {\r\n\t\treturn a.authenticationCodes.ReadWrite(stm).PutTTL(hashToken(code),\r\n\t\t\totpInfo, defaultAuthCodeTTLSecs)\r\n\t}); err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn code, nil\r\n}","code-length":285,"reference":"\/\/ getOneTimePassword contains the implementation of GetOneTimePassword,\n\/\/ but is also called directly by handleSAMLREsponse. It generates a\n\/\/ short-lived authentication code for 'username', writes it to\n\/\/ a.authenticationCodes, and returns it","result":"Generate code.","score":[0,0.0172]}
{"code":"\/*is used to<extra_id_0>\r\nfunc hashToken(token string) string {\r\n\tsum := sha256.Sum256([]byte(token))\r\n\treturn fmt.Sprintf(\"%x\", sum)\r\n}","code-length":50,"reference":"\/\/ hashToken converts a token to a cryptographic hash.\n\/\/ We don't want to store tokens verbatim in the database, as then whoever\n\/\/ that has access to the database has access to all tokens.","result":"Generate a token.","score":[0.0,0.0157]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getAuthToken(ctx context.Context) (string, error) {\r\n\tmd, ok := metadata.FromIncomingContext(ctx)\r\n\tif !ok {\r\n\t\treturn \"\", authclient.ErrNoMetadata\r\n\t}\r\n\tif len(md[authclient.ContextTokenKey]) > 1 {\r\n\t\treturn \"\", fmt.Errorf(\"multiple authentication token keys found in context\")\r\n\t} else if len(md[authclient.ContextTokenKey]) == 0 {\r\n\t\treturn \"\", authclient.ErrNotSignedIn\r\n\t}\r\n\treturn md[authclient.ContextTokenKey][0], nil\r\n}","code-length":154,"reference":"\/\/ getAuthToken extracts the auth token embedded in 'ctx', if there is on","result":"Generate the auth token.","score":[0.0476,0.155]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *apiServer) canonicalizeSubjects(ctx context.Context, subjects []string) ([]string, error) {\r\n\tif subjects == nil {\r\n\t\treturn []string{}, nil\r\n\t}\r\n\teg := &errgroup.Group{}\r\n\tcanonicalizedSubjects := make([]string, len(subjects))\r\n\tfor i, subject := range subjects {\r\n\t\ti, subject := i, subject\r\n\t\teg.Go(func() error {\r\n\t\t\tsubject, err := a.canonicalizeSubject(ctx, subject)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tcanonicalizedSubjects[i] = subject\r\n\t\t\treturn nil\r\n\t\t})\r\n\t}\r\n\tif err := eg.Wait(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn canonicalizedSubjects, nil\r\n}","code-length":226,"reference":"\/\/ canonicalizeSubjects applies canonicalizeSubject to a list","result":"Canonicalize the subject.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Matches(tb testing.TB, expectedMatch string, actual string, msgAndArgs ...interface{}) {\r\n\ttb.Helper()\r\n\tr, err := regexp.Compile(expectedMatch)\r\n\tif err != nil {\r\n\t\tfatal(tb, msgAndArgs, \"Match string provided (%v) is invalid\", expectedMatch)\r\n\t}\r\n\tif !r.MatchString(actual) {\r\n\t\tfatal(tb, msgAndArgs, \"Actual string (%v) does not match pattern (%v)\", actual, expectedMatch)\r\n\t}\r\n}","code-length":141,"reference":"\/\/ Matches checks that a string matches a regular-expression.","result":"Test the matches function.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OneOfMatches(tb testing.TB, expectedMatch string, actuals []string, msgAndArgs ...interface{}) {\r\n\ttb.Helper()\r\n\tr, err := regexp.Compile(expectedMatch)\r\n\tif err != nil {\r\n\t\tfatal(tb, msgAndArgs, \"Match string provided (%v) is invalid\", expectedMatch)\r\n\t}\r\n\tfor _, actual := range actuals {\r\n\t\tif r.MatchString(actual) {\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n\tfatal(tb, msgAndArgs, \"None of actual strings (%v) match pattern (%v)\", actuals, expectedMatch)\r\n}","code-length":167,"reference":"\/\/ OneOfMatches checks whether one element of a slice matches a regular-expression.","result":"Test the tests.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Equal(tb testing.TB, expected interface{}, actual interface{}, msgAndArgs ...interface{}) {\r\n\ttb.Helper()\r\n\teV, aV := reflect.ValueOf(expected), reflect.ValueOf(actual)\r\n\tif eV.Type() != aV.Type() {\r\n\t\tfatal(\r\n\t\t\ttb,\r\n\t\t\tmsgAndArgs,\r\n\t\t\t\"Not equal: %T(%#v) (expected)\\n\"+\r\n\t\t\t\t\"        != %T(%#v) (actual)\", expected, expected, actual, actual)\r\n\t}\r\n\tif !reflect.DeepEqual(expected, actual) {\r\n\t\tfatal(\r\n\t\t\ttb,\r\n\t\t\tmsgAndArgs,\r\n\t\t\t\"Not equal: %#v (expected)\\n\"+\r\n\t\t\t\t\"        != %#v (actual)\", expected, actual)\r\n\t}\r\n}","code-length":226,"reference":"\/\/ Equal checks equality of two values.","result":"Assert equality of objects.","score":[0.2134,0.2799]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NotEqual(tb testing.TB, expected interface{}, actual interface{}, msgAndArgs ...interface{}) {\r\n\ttb.Helper()\r\n\tif reflect.DeepEqual(expected, actual) {\r\n\t\tfatal(\r\n\t\t\ttb,\r\n\t\t\tmsgAndArgs,\r\n\t\t\t\"Equal: %#v (expected)\\n\"+\r\n\t\t\t\t\"    == %#v (actual)\", expected, actual)\r\n\t}\r\n}","code-length":116,"reference":"\/\/ NotEqual checks inequality of two values.","result":"Assert deep equality.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc oneOfEquals(sliceName string, slice interface{}, elem interface{}) (bool, error) {\r\n\te := reflect.ValueOf(elem)\r\n\tsl := reflect.ValueOf(slice)\r\n\tif slice == nil || sl.IsNil() {\r\n\t\tsl = reflect.MakeSlice(reflect.SliceOf(e.Type()), 0, 0)\r\n\t}\r\n\tif sl.Kind() != reflect.Slice {\r\n\t\treturn false, fmt.Errorf(\"\\\"%s\\\" must a be a slice, but instead was %s\", sliceName, sl.Type().String())\r\n\t}\r\n\tif e.Type() != sl.Type().Elem() {\r\n\t\treturn false, nil\r\n\t}\r\n\tarePtrs := e.Kind() == reflect.Ptr\r\n\tfor i := 0; i < sl.Len(); i++ {\r\n\t\tif !arePtrs && reflect.DeepEqual(e.Interface(), sl.Index(i).Interface()) {\r\n\t\t\treturn true, nil\r\n\t\t} else if arePtrs && reflect.DeepEqual(e.Elem().Interface(), sl.Index(i).Elem().Interface()) {\r\n\t\t\treturn true, nil\r\n\t\t}\r\n\t}\r\n\treturn false, nil\r\n}","code-length":309,"reference":"\/\/ oneOfEquals is a helper function for EqualOneOf, OneOfEquals and NoneEquals, that simply\n\/\/ returns a bool indicating whether 'elem' is in 'slice'. 'sliceName' is used for errors","result":"Test for arrays of different types.","score":[0.0049,0.0194]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NoneEquals(tb testing.TB, expected interface{}, actuals interface{}, msgAndArgs ...interface{}) {\r\n\ttb.Helper()\r\n\tequal, err := oneOfEquals(\"actuals\", actuals, expected)\r\n\tif err != nil {\r\n\t\tfatal(tb, msgAndArgs, err.Error())\r\n\t}\r\n\tif equal {\r\n\t\tfatal(tb, msgAndArgs,\r\n\t\t\t\"Equal : %#v (expected)\\n == one of %#v (actuals)\", expected, actuals)\r\n\t}\r\n}","code-length":144,"reference":"\/\/ NoneEquals checks one element of a slice equals a value. Like\n\/\/ EqualsOneOf, NoneEquals unwraps pointers.","result":"Test none equality.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NoError(tb testing.TB, err error, msgAndArgs ...interface{}) {\r\n\ttb.Helper()\r\n\tif err != nil {\r\n\t\tfatal(tb, msgAndArgs, \"No error is expected but got %s\", err.Error())\r\n\t}\r\n}","code-length":77,"reference":"\/\/ NoError checks for no error.","result":"Test the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NoErrorWithinT(tb testing.TB, t time.Duration, f func() error, msgAndArgs ...interface{}) {\r\n\ttb.Helper()\r\n\terrCh := make(chan error)\r\n\tgo func() {\r\n\t\t\r\n\t\t\r\n\t\terrCh <- f()\r\n\t}()\r\n\tselect {\r\n\tcase err := <-errCh:\r\n\t\tif err != nil {\r\n\t\t\tfatal(tb, msgAndArgs, \"No error is expected but got %s\", err.Error())\r\n\t\t}\r\n\tcase <-time.After(t):\r\n\t\tfatal(tb, msgAndArgs, \"operation did not finish within %s\", t.String())\r\n\t}\r\n}","code-length":181,"reference":"\/\/ NoErrorWithinT checks that 'f' finishes within time 't' and does not emit an\n\/\/ error","result":"Test the tests .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NoErrorWithinTRetry(tb testing.TB, t time.Duration, f func() error, msgAndArgs ...interface{}) {\r\n\ttb.Helper()\r\n\tdoneCh := make(chan struct{})\r\n\ttimeout := false\r\n\tvar err error\r\n\tgo func() {\r\n\t\tfor !timeout {\r\n\t\t\tif err = f(); err == nil {\r\n\t\t\t\tclose(doneCh)\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t}()\r\n\tselect {\r\n\tcase <-doneCh:\r\n\tcase <-time.After(t):\r\n\t\ttimeout = true\r\n\t\tfatal(tb, msgAndArgs, \"operation did not finish within %s - last error: %v\", t.String(), err)\r\n\t}\r\n}","code-length":198,"reference":"\/\/ NoErrorWithinTRetry checks that 'f' finishes within time 't' and does not\n\/\/ emit an error. Unlike NoErrorWithinT if f does error, it will retry it.","result":"Test the tests.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc YesError(tb testing.TB, err error, msgAndArgs ...interface{}) {\r\n\ttb.Helper()\r\n\tif err == nil {\r\n\t\tfatal(tb, msgAndArgs, \"Error is expected but got %v\", err)\r\n\t}\r\n}","code-length":74,"reference":"\/\/ YesError checks for an error.","result":"Test the error .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NotNil(tb testing.TB, object interface{}, msgAndArgs ...interface{}) {\r\n\ttb.Helper()\r\n\tsuccess := true\r\n\tif object == nil {\r\n\t\tsuccess = false\r\n\t} else {\r\n\t\tvalue := reflect.ValueOf(object)\r\n\t\tkind := value.Kind()\r\n\t\tif kind >= reflect.Chan && kind <= reflect.Slice && value.IsNil() {\r\n\t\t\tsuccess = false\r\n\t\t}\r\n\t}\r\n\tif !success {\r\n\t\tfatal(tb, msgAndArgs, \"Expected value not to be nil.\")\r\n\t}\r\n}","code-length":161,"reference":"\/\/ NotNil checks a value is non-nil.","result":"Assert nil values.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Nil(tb testing.TB, object interface{}, msgAndArgs ...interface{}) {\r\n\ttb.Helper()\r\n\tif object == nil {\r\n\t\treturn\r\n\t}\r\n\tvalue := reflect.ValueOf(object)\r\n\tkind := value.Kind()\r\n\tif kind >= reflect.Chan && kind <= reflect.Slice && value.IsNil() {\r\n\t\treturn\r\n\t}\r\n\tfatal(tb, msgAndArgs, \"Expected value to be nil, but was %v\", object)\r\n}","code-length":133,"reference":"\/\/ Nil checks a value is nil.","result":"Assert nil values.","score":[0,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc False(tb testing.TB, value bool, msgAndArgs ...interface{}) {\r\n\ttb.Helper()\r\n\tif value {\r\n\t\tfatal(tb, msgAndArgs, \"Should be false.\")\r\n\t}\r\n}","code-length":66,"reference":"\/\/ False checks a value is false.","result":"Test false.","score":[0.041,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSTM(ctx context.Context, c *v3.Client, apply func(STM) error) (*v3.TxnResponse, error) {\r\n\treturn newSTMSerializable(ctx, c, apply, false)\r\n}","code-length":65,"reference":"\/\/ NewSTM intiates a new STM operation. It uses a serializable model.","result":"Create STM objects.","score":[0.0203,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDryrunSTM(ctx context.Context, c *v3.Client, apply func(STM) error) error {\r\n\t_, err := newSTMSerializable(ctx, c, apply, true)\r\n\treturn err\r\n}","code-length":67,"reference":"\/\/ NewDryrunSTM intiates a new STM operation, but the final commit is skipped.\n\/\/ It uses a serializable model.","result":"Create the Dryrun STM.","score":[0.0075,0.0286]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newSTMRepeatable(ctx context.Context, c *v3.Client, apply func(STM) error) (*v3.TxnResponse, error) {\r\n\ts := &stm{client: c, ctx: ctx, getOpts: []v3.OpOption{v3.WithSerializable()}}\r\n\treturn runSTM(s, apply, false)\r\n}","code-length":98,"reference":"\/\/ newSTMRepeatable initiates new repeatable read transaction; reads within\n\/\/ the same transaction attempt to always return the same data.","result":"Create a new STMRepeatable .","score":[0.012,0.027]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newSTMSerializable(ctx context.Context, c *v3.Client, apply func(STM) error, dryrun bool) (*v3.TxnResponse, error) {\r\n\ts := &stmSerializable{\r\n\t\tstm:      stm{client: c, ctx: ctx},\r\n\t\tprefetch: make(map[string]*v3.GetResponse),\r\n\t}\r\n\treturn runSTM(s, apply, dryrun)\r\n}","code-length":119,"reference":"\/\/ newSTMSerializable initiates a new serialized transaction; reads within the\n\/\/ same transaction attempt to return data from the revision of the first read.","result":"Create a new STMSerializable object.","score":[0.0076,0.0848]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newSTMReadCommitted(ctx context.Context, c *v3.Client, apply func(STM) error) (*v3.TxnResponse, error) {\r\n\ts := &stmReadCommitted{stm{client: c, ctx: ctx, getOpts: []v3.OpOption{v3.WithSerializable()}}}\r\n\treturn runSTM(s, apply, true)\r\n}","code-length":104,"reference":"\/\/ newSTMReadCommitted initiates a new read committed transaction.","result":"Create new STMReadCommitted objects.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *stmReadCommitted) commit() *v3.TxnResponse {\r\n\ts.rset = nil\r\n\treturn s.stm.commit()\r\n}","code-length":50,"reference":"\/\/ commit always goes through when read committed","result":"Commit the read committed.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Pipelines(etcdClient *etcd.Client, etcdPrefix string) col.Collection {\r\n\treturn col.NewCollection(\r\n\t\tetcdClient,\r\n\t\tpath.Join(etcdPrefix, pipelinesPrefix),\r\n\t\tnil,\r\n\t\t&pps.EtcdPipelineInfo{},\r\n\t\tnil,\r\n\t\tnil,\r\n\t)\r\n}","code-length":100,"reference":"\/\/ Pipelines returns a Collection of pipelines","result":"Create the collection.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Jobs(etcdClient *etcd.Client, etcdPrefix string) col.Collection {\r\n\treturn col.NewCollection(\r\n\t\tetcdClient,\r\n\t\tpath.Join(etcdPrefix, jobsPrefix),\r\n\t\t[]*col.Index{JobsPipelineIndex, JobsOutputIndex},\r\n\t\t&pps.EtcdJobInfo{},\r\n\t\tnil,\r\n\t\tnil,\r\n\t)\r\n}","code-length":111,"reference":"\/\/ Jobs returns a Collection of jobs","result":"Create the collection.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTicker(b BackOff) *Ticker {\r\n\tc := make(chan time.Time)\r\n\tt := &Ticker{\r\n\t\tC:    c,\r\n\t\tc:    c,\r\n\t\tb:    b,\r\n\t\tstop: make(chan struct{}),\r\n\t}\r\n\tgo t.run()\r\n\truntime.SetFinalizer(t, (*Ticker).Stop)\r\n\treturn t\r\n}","code-length":115,"reference":"\/\/ NewTicker returns a new Ticker containing a channel that will send the time at times\n\/\/ specified by the BackOff argument. Ticker is guaranteed to tick at least once.\n\/\/ The channel is closed when Stop method is called or BackOff stops.","result":"Create a new ticker.","score":[0.0,0.0256]}
{"code":"\/*is used to<extra_id_0>\r\nfunc nodeToMap(node *etcd.Node, out map[string]string) bool {\r\n\tkey := strings.TrimPrefix(node.Key, \"\/\")\r\n\tif !node.Dir {\r\n\t\tif node.Value == \"\" {\r\n\t\t\tif _, ok := out[key]; ok {\r\n\t\t\t\tdelete(out, key)\r\n\t\t\t\treturn true\r\n\t\t\t}\r\n\t\t\treturn false\r\n\t\t}\r\n\t\tif value, ok := out[key]; !ok || value != node.Value {\r\n\t\t\tout[key] = node.Value\r\n\t\t\treturn true\r\n\t\t}\r\n\t\treturn false\r\n\t}\r\n\tchanged := false\r\n\tfor _, node := range node.Nodes {\r\n\t\tchanged = nodeToMap(node, out) || changed\r\n\t}\r\n\treturn changed\r\n}","code-length":213,"reference":"\/\/ nodeToMap translates the contents of a node into a map\n\/\/ nodeToMap can be called on the same map with successive results from watch\n\/\/ to accumulate a value\n\/\/ nodeToMap returns true if out was modified","result":"Map nodes to map values.","score":[0.0004,0.0576]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ServiceAccount(opts *AssetOpts) *v1.ServiceAccount {\r\n\treturn &v1.ServiceAccount{\r\n\t\tTypeMeta: metav1.TypeMeta{\r\n\t\t\tKind:       \"ServiceAccount\",\r\n\t\t\tAPIVersion: \"v1\",\r\n\t\t},\r\n\t\tObjectMeta: objectMeta(ServiceAccountName, labels(\"\"), nil, opts.Namespace),\r\n\t}\r\n}","code-length":102,"reference":"\/\/ ServiceAccount returns a kubernetes service account for use with Pachyderm.","result":"Generate the service account name.","score":[0.1023,0.1803]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ClusterRole(opts *AssetOpts) *rbacv1.ClusterRole {\r\n\treturn &rbacv1.ClusterRole{\r\n\t\tTypeMeta: metav1.TypeMeta{\r\n\t\t\tKind:       \"ClusterRole\",\r\n\t\t\tAPIVersion: \"rbac.authorization.k8s.io\/v1\",\r\n\t\t},\r\n\t\tObjectMeta: objectMeta(roleName, labels(\"\"), nil, opts.Namespace),\r\n\t\tRules:      rolePolicyRules,\r\n\t}\r\n}","code-length":132,"reference":"\/\/ ClusterRole returns a ClusterRole that should be bound to the Pachyderm service account.","result":"Generate the cluster role.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RoleBinding(opts *AssetOpts) *rbacv1.RoleBinding {\r\n\treturn &rbacv1.RoleBinding{\r\n\t\tTypeMeta: metav1.TypeMeta{\r\n\t\t\tKind:       \"RoleBinding\",\r\n\t\t\tAPIVersion: \"rbac.authorization.k8s.io\/v1\",\r\n\t\t},\r\n\t\tObjectMeta: objectMeta(roleBindingName, labels(\"\"), nil, opts.Namespace),\r\n\t\tSubjects: []rbacv1.Subject{{\r\n\t\t\tKind:      \"ServiceAccount\",\r\n\t\t\tName:      ServiceAccountName,\r\n\t\t\tNamespace: opts.Namespace,\r\n\t\t}},\r\n\t\tRoleRef: rbacv1.RoleRef{\r\n\t\t\tKind: \"Role\",\r\n\t\t\tName: roleName,\r\n\t\t},\r\n\t}\r\n}","code-length":205,"reference":"\/\/ RoleBinding returns a RoleBinding that binds Pachyderm's Role to its\n\/\/ ServiceAccount.","result":"Generate the role binding .","score":[0,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetSecretEnvVars(storageBackend string) []v1.EnvVar {\r\n\tvar envVars []v1.EnvVar\r\n\tif storageBackend != \"\" {\r\n\t\tenvVars = append(envVars, v1.EnvVar{\r\n\t\t\tName:  obj.StorageBackendEnvVar,\r\n\t\t\tValue: storageBackend,\r\n\t\t})\r\n\t}\r\n\ttrueVal := true\r\n\tfor envVar, secretKey := range obj.EnvVarToSecretKey {\r\n\t\tenvVars = append(envVars, v1.EnvVar{\r\n\t\t\tName: envVar,\r\n\t\t\tValueFrom: &v1.EnvVarSource{\r\n\t\t\t\tSecretKeyRef: &v1.SecretKeySelector{\r\n\t\t\t\t\tLocalObjectReference: v1.LocalObjectReference{\r\n\t\t\t\t\t\tName: client.StorageSecretName,\r\n\t\t\t\t\t},\r\n\t\t\t\t\tKey:      secretKey,\r\n\t\t\t\t\tOptional: &trueVal,\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t})\r\n\t}\r\n\treturn envVars\r\n}","code-length":254,"reference":"\/\/ GetSecretEnvVars returns the environment variable specs for the storage secret.","result":"Get the secret env vars from the secret store.","score":[0.116,0.0926]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PachdService(opts *AssetOpts) *v1.Service {\r\n\tprometheusAnnotations := map[string]string{\r\n\t\t\"prometheus.io\/scrape\": \"true\",\r\n\t\t\"prometheus.io\/port\":   strconv.Itoa(PrometheusPort),\r\n\t}\r\n\treturn &v1.Service{\r\n\t\tTypeMeta: metav1.TypeMeta{\r\n\t\t\tKind:       \"Service\",\r\n\t\t\tAPIVersion: \"v1\",\r\n\t\t},\r\n\t\tObjectMeta: objectMeta(pachdName, labels(pachdName), prometheusAnnotations, opts.Namespace),\r\n\t\tSpec: v1.ServiceSpec{\r\n\t\t\tType: v1.ServiceTypeNodePort,\r\n\t\t\tSelector: map[string]string{\r\n\t\t\t\t\"app\": pachdName,\r\n\t\t\t},\r\n\t\t\tPorts: []v1.ServicePort{\r\n\t\t\t\t{\r\n\t\t\t\t\tPort:     600,\r\n\t\t\t\t\tName:     \"s3gateway-port\",\r\n\t\t\t\t\tNodePort: 30600,\r\n\t\t\t\t},\r\n\t\t\t\t{\r\n\t\t\t\t\tPort:     650,\r\n\t\t\t\t\tName:     \"api-grpc-port\",\r\n\t\t\t\t\tNodePort: 30650,\r\n\t\t\t\t},\r\n\t\t\t\t{\r\n\t\t\t\t\tPort:     651,\r\n\t\t\t\t\tName:     \"trace-port\",\r\n\t\t\t\t\tNodePort: 30651,\r\n\t\t\t\t},\r\n\t\t\t\t{\r\n\t\t\t\t\tPort:     652,\r\n\t\t\t\t\tName:     \"api-http-port\",\r\n\t\t\t\t\tNodePort: 30652,\r\n\t\t\t\t},\r\n\t\t\t\t{\r\n\t\t\t\t\tPort:     auth.SamlPort,\r\n\t\t\t\t\tName:     \"saml-port\",\r\n\t\t\t\t\tNodePort: 30000 + auth.SamlPort,\r\n\t\t\t\t},\r\n\t\t\t\t{\r\n\t\t\t\t\tPort:     githook.GitHookPort,\r\n\t\t\t\t\tName:     \"api-git-port\",\r\n\t\t\t\t\tNodePort: githook.NodePort(),\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n}","code-length":522,"reference":"\/\/ PachdService returns a pachd service.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GithookService(namespace string) *v1.Service {\r\n\tname := \"githook\"\r\n\treturn &v1.Service{\r\n\t\tTypeMeta: metav1.TypeMeta{\r\n\t\t\tKind:       \"Service\",\r\n\t\t\tAPIVersion: \"v1\",\r\n\t\t},\r\n\t\tObjectMeta: objectMeta(name, labels(name), nil, namespace),\r\n\t\tSpec: v1.ServiceSpec{\r\n\t\t\tType: v1.ServiceTypeLoadBalancer,\r\n\t\t\tSelector: map[string]string{\r\n\t\t\t\t\"app\": pachdName,\r\n\t\t\t},\r\n\t\t\tPorts: []v1.ServicePort{\r\n\t\t\t\t{\r\n\t\t\t\t\tTargetPort: intstr.FromInt(githook.GitHookPort),\r\n\t\t\t\t\tName:       \"api-git-port\",\r\n\t\t\t\t\tPort:       githook.ExternalPort(),\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n}","code-length":246,"reference":"\/\/ GithookService returns a k8s service that exposes a public IP","result":"Create a service to manage the health of the service.","score":[0.1168,0.0917]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EtcdDeployment(opts *AssetOpts, hostPath string) *apps.Deployment {\r\n\tcpu := resource.MustParse(opts.EtcdCPURequest)\r\n\tmem := resource.MustParse(opts.EtcdMemRequest)\r\n\tvar volumes []v1.Volume\r\n\tif hostPath == \"\" {\r\n\t\tvolumes = []v1.Volume{\r\n\t\t\t{\r\n\t\t\t\tName: \"etcd-storage\",\r\n\t\t\t\tVolumeSource: v1.VolumeSource{\r\n\t\t\t\t\tPersistentVolumeClaim: &v1.PersistentVolumeClaimVolumeSource{\r\n\t\t\t\t\t\tClaimName: etcdVolumeClaimName,\r\n\t\t\t\t\t},\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t}\r\n\t} else {\r\n\t\tvolumes = []v1.Volume{\r\n\t\t\t{\r\n\t\t\t\tName: \"etcd-storage\",\r\n\t\t\t\tVolumeSource: v1.VolumeSource{\r\n\t\t\t\t\tHostPath: &v1.HostPathVolumeSource{\r\n\t\t\t\t\t\tPath: filepath.Join(hostPath, \"etcd\"),\r\n\t\t\t\t\t},\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t}\r\n\t}\r\n\tresourceRequirements := v1.ResourceRequirements{\r\n\t\tRequests: v1.ResourceList{\r\n\t\t\tv1.ResourceCPU:    cpu,\r\n\t\t\tv1.ResourceMemory: mem,\r\n\t\t},\r\n\t}\r\n\tif !opts.NoGuaranteed {\r\n\t\tresourceRequirements.Limits = v1.ResourceList{\r\n\t\t\tv1.ResourceCPU:    cpu,\r\n\t\t\tv1.ResourceMemory: mem,\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\timage := etcdImage\r\n\tif opts.Registry != \"\" {\r\n\t\timage = AddRegistry(opts.Registry, etcdImage)\r\n\t}\r\n\treturn &apps.Deployment{\r\n\t\tTypeMeta: metav1.TypeMeta{\r\n\t\t\tKind:       \"Deployment\",\r\n\t\t\tAPIVersion: \"apps\/v1beta1\",\r\n\t\t},\r\n\t\tObjectMeta: objectMeta(etcdName, labels(etcdName), nil, opts.Namespace),\r\n\t\tSpec: apps.DeploymentSpec{\r\n\t\t\tReplicas: replicas(1),\r\n\t\t\tSelector: &metav1.LabelSelector{\r\n\t\t\t\tMatchLabels: labels(etcdName),\r\n\t\t\t},\r\n\t\t\tTemplate: v1.PodTemplateSpec{\r\n\t\t\t\tObjectMeta: objectMeta(etcdName, labels(etcdName), nil, opts.Namespace),\r\n\t\t\t\tSpec: v1.PodSpec{\r\n\t\t\t\t\tContainers: []v1.Container{\r\n\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\tName:  etcdName,\r\n\t\t\t\t\t\t\tImage: image,\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tCommand: etcdCmd,\r\n\t\t\t\t\t\t\tPorts: []v1.ContainerPort{\r\n\t\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\t\tContainerPort: 2379,\r\n\t\t\t\t\t\t\t\t\tName:          \"client-port\",\r\n\t\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\t\tContainerPort: 2380,\r\n\t\t\t\t\t\t\t\t\tName:          \"peer-port\",\r\n\t\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\tVolumeMounts: []v1.VolumeMount{\r\n\t\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\t\tName:      \"etcd-storage\",\r\n\t\t\t\t\t\t\t\t\tMountPath: \"\/var\/data\/etcd\",\r\n\t\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\tImagePullPolicy: \"IfNotPresent\",\r\n\t\t\t\t\t\t\tResources:       resourceRequirements,\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t},\r\n\t\t\t\t\tVolumes:          volumes,\r\n\t\t\t\t\tImagePullSecrets: imagePullSecrets(opts),\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n}","code-length":899,"reference":"\/\/ EtcdDeployment returns an etcd k8s Deployment.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EtcdStorageClass(opts *AssetOpts, backend backend) (interface{}, error) {\r\n\tsc := map[string]interface{}{\r\n\t\t\"apiVersion\": \"storage.k8s.io\/v1beta1\",\r\n\t\t\"kind\":       \"StorageClass\",\r\n\t\t\"metadata\": map[string]interface{}{\r\n\t\t\t\"name\":      defaultEtcdStorageClassName,\r\n\t\t\t\"labels\":    labels(etcdName),\r\n\t\t\t\"namespace\": opts.Namespace,\r\n\t\t},\r\n\t}\r\n\tswitch backend {\r\n\tcase googleBackend:\r\n\t\tsc[\"provisioner\"] = \"kubernetes.io\/gce-pd\"\r\n\t\tsc[\"parameters\"] = map[string]string{\r\n\t\t\t\"type\": \"pd-ssd\",\r\n\t\t}\r\n\tcase amazonBackend:\r\n\t\tsc[\"provisioner\"] = \"kubernetes.io\/aws-ebs\"\r\n\t\tsc[\"parameters\"] = map[string]string{\r\n\t\t\t\"type\": \"gp2\",\r\n\t\t}\r\n\tdefault:\r\n\t\treturn nil, nil\r\n\t}\r\n\treturn sc, nil\r\n}","code-length":288,"reference":"\/\/ EtcdStorageClass creates a storage class used for dynamic volume\n\/\/ provisioning.  Currently dynamic volume provisioning only works\n\/\/ on AWS and GCE.","result":"Generate the storage class.","score":[0.0028,0.0237]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EtcdVolume(persistentDiskBackend backend, opts *AssetOpts,\r\n\thostPath string, name string, size int) (*v1.PersistentVolume, error) {\r\n\tspec := &v1.PersistentVolume{\r\n\t\tTypeMeta: metav1.TypeMeta{\r\n\t\t\tKind:       \"PersistentVolume\",\r\n\t\t\tAPIVersion: \"v1\",\r\n\t\t},\r\n\t\tObjectMeta: objectMeta(etcdVolumeName, labels(etcdName), nil, opts.Namespace),\r\n\t\tSpec: v1.PersistentVolumeSpec{\r\n\t\t\tCapacity: map[v1.ResourceName]resource.Quantity{\r\n\t\t\t\t\"storage\": resource.MustParse(fmt.Sprintf(\"%vGi\", size)),\r\n\t\t\t},\r\n\t\t\tAccessModes:                   []v1.PersistentVolumeAccessMode{v1.ReadWriteOnce},\r\n\t\t\tPersistentVolumeReclaimPolicy: v1.PersistentVolumeReclaimRetain,\r\n\t\t},\r\n\t}\r\n\tswitch persistentDiskBackend {\r\n\tcase amazonBackend:\r\n\t\tspec.Spec.PersistentVolumeSource = v1.PersistentVolumeSource{\r\n\t\t\tAWSElasticBlockStore: &v1.AWSElasticBlockStoreVolumeSource{\r\n\t\t\t\tFSType:   \"ext4\",\r\n\t\t\t\tVolumeID: name,\r\n\t\t\t},\r\n\t\t}\r\n\tcase googleBackend:\r\n\t\tspec.Spec.PersistentVolumeSource = v1.PersistentVolumeSource{\r\n\t\t\tGCEPersistentDisk: &v1.GCEPersistentDiskVolumeSource{\r\n\t\t\t\tFSType: \"ext4\",\r\n\t\t\t\tPDName: name,\r\n\t\t\t},\r\n\t\t}\r\n\tcase microsoftBackend:\r\n\t\tdataDiskURI := name\r\n\t\tsplit := strings.Split(name, \"\/\")\r\n\t\tdiskName := split[len(split)-1]\r\n\t\tspec.Spec.PersistentVolumeSource = v1.PersistentVolumeSource{\r\n\t\t\tAzureDisk: &v1.AzureDiskVolumeSource{\r\n\t\t\t\tDiskName:    diskName,\r\n\t\t\t\tDataDiskURI: dataDiskURI,\r\n\t\t\t},\r\n\t\t}\r\n\tcase minioBackend:\r\n\t\tfallthrough\r\n\tcase localBackend:\r\n\t\tspec.Spec.PersistentVolumeSource = v1.PersistentVolumeSource{\r\n\t\t\tHostPath: &v1.HostPathVolumeSource{\r\n\t\t\t\tPath: filepath.Join(hostPath, \"etcd\"),\r\n\t\t\t},\r\n\t\t}\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"cannot generate volume spec for unknown backend \\\"%v\\\"\", persistentDiskBackend)\r\n\t}\r\n\treturn spec, nil\r\n}","code-length":633,"reference":"\/\/ EtcdVolume creates a persistent volume backed by a volume with name \"name\"","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EtcdNodePortService(local bool, opts *AssetOpts) *v1.Service {\r\n\tvar clientNodePort int32\r\n\tif local {\r\n\t\tclientNodePort = 32379\r\n\t}\r\n\treturn &v1.Service{\r\n\t\tTypeMeta: metav1.TypeMeta{\r\n\t\t\tKind:       \"Service\",\r\n\t\t\tAPIVersion: \"v1\",\r\n\t\t},\r\n\t\tObjectMeta: objectMeta(etcdName, labels(etcdName), nil, opts.Namespace),\r\n\t\tSpec: v1.ServiceSpec{\r\n\t\t\tType: v1.ServiceTypeNodePort,\r\n\t\t\tSelector: map[string]string{\r\n\t\t\t\t\"app\": etcdName,\r\n\t\t\t},\r\n\t\t\tPorts: []v1.ServicePort{\r\n\t\t\t\t{\r\n\t\t\t\t\tPort:     2379,\r\n\t\t\t\t\tName:     \"client-port\",\r\n\t\t\t\t\tNodePort: clientNodePort,\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n}","code-length":261,"reference":"\/\/ EtcdNodePortService returns a NodePort etcd service. This will let non-etcd\n\/\/ pods talk to etcd","result":"Generate the service spec.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EtcdHeadlessService(opts *AssetOpts) *v1.Service {\r\n\treturn &v1.Service{\r\n\t\tTypeMeta: metav1.TypeMeta{\r\n\t\t\tKind:       \"Service\",\r\n\t\t\tAPIVersion: \"v1\",\r\n\t\t},\r\n\t\tObjectMeta: objectMeta(etcdHeadlessServiceName, labels(etcdName), nil, opts.Namespace),\r\n\t\tSpec: v1.ServiceSpec{\r\n\t\t\tSelector: map[string]string{\r\n\t\t\t\t\"app\": etcdName,\r\n\t\t\t},\r\n\t\t\tClusterIP: \"None\",\r\n\t\t\tPorts: []v1.ServicePort{\r\n\t\t\t\t{\r\n\t\t\t\t\tName: \"peer-port\",\r\n\t\t\t\t\tPort: 2380,\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n}","code-length":212,"reference":"\/\/ EtcdHeadlessService returns a headless etcd service, which is only for DNS\n\/\/ resolution.","result":"Generate the service.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EtcdStatefulSet(opts *AssetOpts, backend backend, diskSpace int) interface{} {\r\n\tmem := resource.MustParse(opts.EtcdMemRequest)\r\n\tcpu := resource.MustParse(opts.EtcdCPURequest)\r\n\tinitialCluster := make([]string, 0, opts.EtcdNodes)\r\n\tfor i := 0; i < opts.EtcdNodes; i++ {\r\n\t\turl := fmt.Sprintf(\"http:\r\n\t\tinitialCluster = append(initialCluster, fmt.Sprintf(\"etcd-%d=%s\", i, url))\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tetcdCmd := append(etcdCmd,\r\n\t\t\"--listen-peer-urls=http:\r\n\t\t\"--initial-cluster-token=pach-cluster\",\r\n\t\t\"--initial-advertise-peer-urls=http:\r\n\t\t\"--initial-cluster=\"+strings.Join(initialCluster, \",\"),\r\n\t)\r\n\tfor i, str := range etcdCmd {\r\n\t\tetcdCmd[i] = fmt.Sprintf(\"\\\"%s\\\"\", str)\r\n\t}\r\n\tvar pvcTemplates []interface{}\r\n\tswitch backend {\r\n\tcase googleBackend, amazonBackend:\r\n\t\tstorageClassName := opts.EtcdStorageClassName\r\n\t\tif storageClassName == \"\" {\r\n\t\t\tstorageClassName = defaultEtcdStorageClassName\r\n\t\t}\r\n\t\tpvcTemplates = []interface{}{\r\n\t\t\tmap[string]interface{}{\r\n\t\t\t\t\"metadata\": map[string]interface{}{\r\n\t\t\t\t\t\"name\":   etcdVolumeClaimName,\r\n\t\t\t\t\t\"labels\": labels(etcdName),\r\n\t\t\t\t\t\"annotations\": map[string]string{\r\n\t\t\t\t\t\t\"volume.beta.kubernetes.io\/storage-class\": storageClassName,\r\n\t\t\t\t\t},\r\n\t\t\t\t\t\"namespace\": opts.Namespace,\r\n\t\t\t\t},\r\n\t\t\t\t\"spec\": map[string]interface{}{\r\n\t\t\t\t\t\"resources\": map[string]interface{}{\r\n\t\t\t\t\t\t\"requests\": map[string]interface{}{\r\n\t\t\t\t\t\t\t\"storage\": resource.MustParse(fmt.Sprintf(\"%vGi\", diskSpace)),\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t},\r\n\t\t\t\t\t\"accessModes\": []string{\"ReadWriteOnce\"},\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t}\r\n\tdefault:\r\n\t\tpvcTemplates = []interface{}{\r\n\t\t\tmap[string]interface{}{\r\n\t\t\t\t\"metadata\": map[string]interface{}{\r\n\t\t\t\t\t\"name\":      etcdVolumeClaimName,\r\n\t\t\t\t\t\"labels\":    labels(etcdName),\r\n\t\t\t\t\t\"namespace\": opts.Namespace,\r\n\t\t\t\t},\r\n\t\t\t\t\"spec\": map[string]interface{}{\r\n\t\t\t\t\t\"resources\": map[string]interface{}{\r\n\t\t\t\t\t\t\"requests\": map[string]interface{}{\r\n\t\t\t\t\t\t\t\"storage\": resource.MustParse(fmt.Sprintf(\"%vGi\", diskSpace)),\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t},\r\n\t\t\t\t\t\"accessModes\": []string{\"ReadWriteOnce\"},\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t}\r\n\t}\r\n\tvar imagePullSecrets []map[string]string\r\n\tif opts.ImagePullSecret != \"\" {\r\n\t\timagePullSecrets = append(imagePullSecrets, map[string]string{\"name\": opts.ImagePullSecret})\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\timage := etcdImage\r\n\tif opts.Registry != \"\" {\r\n\t\timage = AddRegistry(opts.Registry, etcdImage)\r\n\t}\r\n\treturn map[string]interface{}{\r\n\t\t\"apiVersion\": \"apps\/v1beta1\",\r\n\t\t\"kind\":       \"StatefulSet\",\r\n\t\t\"metadata\": map[string]interface{}{\r\n\t\t\t\"name\":      etcdName,\r\n\t\t\t\"labels\":    labels(etcdName),\r\n\t\t\t\"namespace\": opts.Namespace,\r\n\t\t},\r\n\t\t\"spec\": map[string]interface{}{\r\n\t\t\t\r\n\t\t\t\"serviceName\": etcdHeadlessServiceName,\r\n\t\t\t\"replicas\":    int(opts.EtcdNodes),\r\n\t\t\t\"selector\": map[string]interface{}{\r\n\t\t\t\t\"matchLabels\": labels(etcdName),\r\n\t\t\t},\r\n\t\t\t\r\n\t\t\t\"template\": map[string]interface{}{\r\n\t\t\t\t\"metadata\": map[string]interface{}{\r\n\t\t\t\t\t\"name\":      etcdName,\r\n\t\t\t\t\t\"labels\":    labels(etcdName),\r\n\t\t\t\t\t\"namespace\": opts.Namespace,\r\n\t\t\t\t},\r\n\t\t\t\t\"spec\": map[string]interface{}{\r\n\t\t\t\t\t\"imagePullSecrets\": imagePullSecrets,\r\n\t\t\t\t\t\"containers\": []interface{}{\r\n\t\t\t\t\t\tmap[string]interface{}{\r\n\t\t\t\t\t\t\t\"name\":    etcdName,\r\n\t\t\t\t\t\t\t\"image\":   image,\r\n\t\t\t\t\t\t\t\"command\": []string{\"\/bin\/sh\", \"-c\"},\r\n\t\t\t\t\t\t\t\"args\":    []string{strings.Join(etcdCmd, \" \")},\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\t\"env\": []map[string]interface{}{{\r\n\t\t\t\t\t\t\t\t\"name\": \"ETCD_NAME\",\r\n\t\t\t\t\t\t\t\t\"valueFrom\": map[string]interface{}{\r\n\t\t\t\t\t\t\t\t\t\"fieldRef\": map[string]interface{}{\r\n\t\t\t\t\t\t\t\t\t\t\"apiVersion\": \"v1\",\r\n\t\t\t\t\t\t\t\t\t\t\"fieldPath\":  \"metadata.name\",\r\n\t\t\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t}, {\r\n\t\t\t\t\t\t\t\t\"name\": \"NAMESPACE\",\r\n\t\t\t\t\t\t\t\t\"valueFrom\": map[string]interface{}{\r\n\t\t\t\t\t\t\t\t\t\"fieldRef\": map[string]interface{}{\r\n\t\t\t\t\t\t\t\t\t\t\"apiVersion\": \"v1\",\r\n\t\t\t\t\t\t\t\t\t\t\"fieldPath\":  \"metadata.namespace\",\r\n\t\t\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t}},\r\n\t\t\t\t\t\t\t\"ports\": []interface{}{\r\n\t\t\t\t\t\t\t\tmap[string]interface{}{\r\n\t\t\t\t\t\t\t\t\t\"containerPort\": 2379,\r\n\t\t\t\t\t\t\t\t\t\"name\":          \"client-port\",\r\n\t\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t\tmap[string]interface{}{\r\n\t\t\t\t\t\t\t\t\t\"containerPort\": 2380,\r\n\t\t\t\t\t\t\t\t\t\"name\":          \"peer-port\",\r\n\t\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t\"volumeMounts\": []interface{}{\r\n\t\t\t\t\t\t\t\tmap[string]interface{}{\r\n\t\t\t\t\t\t\t\t\t\"name\":      etcdVolumeClaimName,\r\n\t\t\t\t\t\t\t\t\t\"mountPath\": \"\/var\/data\/etcd\",\r\n\t\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t\"imagePullPolicy\": \"IfNotPresent\",\r\n\t\t\t\t\t\t\t\"resources\": map[string]interface{}{\r\n\t\t\t\t\t\t\t\t\"requests\": map[string]interface{}{\r\n\t\t\t\t\t\t\t\t\tstring(v1.ResourceCPU):    cpu.String(),\r\n\t\t\t\t\t\t\t\t\tstring(v1.ResourceMemory): mem.String(),\r\n\t\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t},\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t\t\"volumeClaimTemplates\": pvcTemplates,\r\n\t\t},\r\n\t}\r\n}","code-length":1741,"reference":"\/\/ EtcdStatefulSet returns a stateful set that manages an etcd cluster","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DashDeployment(opts *AssetOpts) *apps.Deployment {\r\n\treturn &apps.Deployment{\r\n\t\tTypeMeta: metav1.TypeMeta{\r\n\t\t\tKind:       \"Deployment\",\r\n\t\t\tAPIVersion: \"apps\/v1beta1\",\r\n\t\t},\r\n\t\tObjectMeta: objectMeta(dashName, labels(dashName), nil, opts.Namespace),\r\n\t\tSpec: apps.DeploymentSpec{\r\n\t\t\tSelector: &metav1.LabelSelector{\r\n\t\t\t\tMatchLabels: labels(dashName),\r\n\t\t\t},\r\n\t\t\tTemplate: v1.PodTemplateSpec{\r\n\t\t\t\tObjectMeta: objectMeta(dashName, labels(dashName), nil, opts.Namespace),\r\n\t\t\t\tSpec: v1.PodSpec{\r\n\t\t\t\t\tContainers: []v1.Container{\r\n\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\tName:  dashName,\r\n\t\t\t\t\t\t\tImage: AddRegistry(opts.Registry, opts.DashImage),\r\n\t\t\t\t\t\t\tPorts: []v1.ContainerPort{\r\n\t\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\t\tContainerPort: 8080,\r\n\t\t\t\t\t\t\t\t\tName:          \"dash-http\",\r\n\t\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\tImagePullPolicy: \"IfNotPresent\",\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\tName:  grpcProxyName,\r\n\t\t\t\t\t\t\tImage: AddRegistry(opts.Registry, grpcProxyImage),\r\n\t\t\t\t\t\t\tPorts: []v1.ContainerPort{\r\n\t\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\t\tContainerPort: 8081,\r\n\t\t\t\t\t\t\t\t\tName:          \"grpc-proxy-http\",\r\n\t\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\tImagePullPolicy: \"IfNotPresent\",\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t},\r\n\t\t\t\t\tImagePullSecrets: imagePullSecrets(opts),\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n}","code-length":465,"reference":"\/\/ DashDeployment creates a Deployment for the pachyderm dashboard.","result":"Create a dash deployment.","score":[0.0915,0.2206]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DashService(opts *AssetOpts) *v1.Service {\r\n\treturn &v1.Service{\r\n\t\tTypeMeta: metav1.TypeMeta{\r\n\t\t\tKind:       \"Service\",\r\n\t\t\tAPIVersion: \"v1\",\r\n\t\t},\r\n\t\tObjectMeta: objectMeta(dashName, labels(dashName), nil, opts.Namespace),\r\n\t\tSpec: v1.ServiceSpec{\r\n\t\t\tType:     v1.ServiceTypeNodePort,\r\n\t\t\tSelector: labels(dashName),\r\n\t\t\tPorts: []v1.ServicePort{\r\n\t\t\t\t{\r\n\t\t\t\t\tPort:     8080,\r\n\t\t\t\t\tName:     \"dash-http\",\r\n\t\t\t\t\tNodePort: 30080,\r\n\t\t\t\t},\r\n\t\t\t\t{\r\n\t\t\t\t\tPort:     8081,\r\n\t\t\t\t\tName:     \"grpc-proxy-http\",\r\n\t\t\t\t\tNodePort: 30081,\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n}","code-length":253,"reference":"\/\/ DashService creates a Service for the pachyderm dashboard.","result":"Generate a service for the dash assets.","score":[0.1899,0.451]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WriteSecret(encoder Encoder, data map[string][]byte, opts *AssetOpts) error {\r\n\tif opts.DashOnly {\r\n\t\treturn nil\r\n\t}\r\n\tsecret := &v1.Secret{\r\n\t\tTypeMeta: metav1.TypeMeta{\r\n\t\t\tKind:       \"Secret\",\r\n\t\t\tAPIVersion: \"v1\",\r\n\t\t},\r\n\t\tObjectMeta: objectMeta(client.StorageSecretName, labels(client.StorageSecretName), nil, opts.Namespace),\r\n\t\tData:       data,\r\n\t}\r\n\treturn encoder.Encode(secret)\r\n}","code-length":156,"reference":"\/\/ WriteSecret writes a JSON-encoded k8s secret to the given writer.\n\/\/ The secret uses the given map as data.","result":"Write secret to a file.","score":[0.0187,0.1081]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GoogleSecret(bucket string, cred string) map[string][]byte {\r\n\treturn map[string][]byte{\r\n\t\t\"google-bucket\": []byte(bucket),\r\n\t\t\"google-cred\":   []byte(cred),\r\n\t}\r\n}","code-length":73,"reference":"\/\/ GoogleSecret creates a google secret with a bucket name.","result":"Generate secret.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WriteDashboardAssets(encoder Encoder, opts *AssetOpts) error {\r\n\tif err := encoder.Encode(DashService(opts)); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn encoder.Encode(DashDeployment(opts))\r\n}","code-length":69,"reference":"\/\/ WriteDashboardAssets writes the k8s config for deploying the Pachyderm\n\/\/ dashboard to 'encoder'","result":"Write the dashboard assets.","score":[0.0312,0.1154]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WriteLocalAssets(encoder Encoder, opts *AssetOpts, hostPath string) error {\r\n\tif err := WriteAssets(encoder, opts, localBackend, localBackend, 1 , hostPath); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif secretErr := WriteSecret(encoder, LocalSecret(), opts); secretErr != nil {\r\n\t\treturn secretErr\r\n\t}\r\n\treturn nil\r\n}","code-length":107,"reference":"\/\/ WriteLocalAssets writes assets to a local backend.","result":"Write local assets.","score":[0.0771,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WriteCustomAssets(encoder Encoder, opts *AssetOpts, args []string, objectStoreBackend string,\r\n\tpersistentDiskBackend string, secure, isS3V2 bool) error {\r\n\tswitch objectStoreBackend {\r\n\tcase \"s3\":\r\n\t\tif len(args) != s3CustomArgs {\r\n\t\t\treturn fmt.Errorf(\"Expected %d arguments for disk+s3 backend\", s3CustomArgs)\r\n\t\t}\r\n\t\tvolumeSize, err := strconv.Atoi(args[1])\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"volume size needs to be an integer; instead got %v\", args[1])\r\n\t\t}\r\n\t\tswitch persistentDiskBackend {\r\n\t\tcase \"aws\":\r\n\t\t\tif err := WriteAssets(encoder, opts, minioBackend, amazonBackend, volumeSize, \"\"); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\tcase \"google\":\r\n\t\t\tif err := WriteAssets(encoder, opts, minioBackend, googleBackend, volumeSize, \"\"); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\tcase \"azure\":\r\n\t\t\tif err := WriteAssets(encoder, opts, minioBackend, microsoftBackend, volumeSize, \"\"); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\tdefault:\r\n\t\t\treturn fmt.Errorf(\"Did not recognize the choice of persistent-disk\")\r\n\t\t}\r\n\t\treturn WriteSecret(encoder, MinioSecret(args[2], args[3], args[4], args[5], secure, isS3V2), opts)\r\n\tdefault:\r\n\t\treturn fmt.Errorf(\"Did not recognize the choice of object-store\")\r\n\t}\r\n}","code-length":420,"reference":"\/\/ WriteCustomAssets writes assets to a custom combination of object-store and persistent disk.","result":"Write custom assets to the bucket.","score":[0.0941,0.2566]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WriteAmazonAssets(encoder Encoder, opts *AssetOpts, region string, bucket string, volumeSize int, creds *AmazonCreds, cloudfrontDistro string) error {\r\n\tif err := WriteAssets(encoder, opts, amazonBackend, amazonBackend, volumeSize, \"\"); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tvar secret map[string][]byte\r\n\tif creds == nil {\r\n\t\tsecret = AmazonIAMRoleSecret(region, bucket, cloudfrontDistro)\r\n\t} else if creds.ID != \"\" {\r\n\t\tsecret = AmazonSecret(region, bucket, creds.ID, creds.Secret, creds.Token, cloudfrontDistro)\r\n\t} else if creds.VaultAddress != \"\" {\r\n\t\tsecret = AmazonVaultSecret(region, bucket, creds.VaultAddress, creds.VaultRole, creds.VaultToken, cloudfrontDistro)\r\n\t}\r\n\treturn WriteSecret(encoder, secret, opts)\r\n}","code-length":231,"reference":"\/\/ WriteAmazonAssets writes assets to an amazon backend.","result":"Write assets to the backend.","score":[0.2064,0.487]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WriteGoogleAssets(encoder Encoder, opts *AssetOpts, bucket string, cred string, volumeSize int) error {\r\n\tif err := WriteAssets(encoder, opts, googleBackend, googleBackend, volumeSize, \"\"); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn WriteSecret(encoder, GoogleSecret(bucket, cred), opts)\r\n}","code-length":93,"reference":"\/\/ WriteGoogleAssets writes assets to a google backend.","result":"Write assets to the storage backend.","score":[0.2165,0.4808]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WriteMicrosoftAssets(encoder Encoder, opts *AssetOpts, container string, id string, secret string, volumeSize int) error {\r\n\tif err := WriteAssets(encoder, opts, microsoftBackend, microsoftBackend, volumeSize, \"\"); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn WriteSecret(encoder, MicrosoftSecret(container, id, secret), opts)\r\n}","code-length":100,"reference":"\/\/ WriteMicrosoftAssets writes assets to a microsoft backend","result":"Write assets.","score":[0,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Images(opts *AssetOpts) []string {\r\n\treturn []string{\r\n\t\tversionedWorkerImage(opts),\r\n\t\tetcdImage,\r\n\t\tgrpcProxyImage,\r\n\t\tpauseImage,\r\n\t\tversionedPachdImage(opts),\r\n\t\topts.DashImage,\r\n\t}\r\n}","code-length":88,"reference":"\/\/ Images returns a list of all the images that are used by a pachyderm deployment.","result":"Generate the images.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AddRegistry(registry string, imageName string) string {\r\n\tif registry == \"\" {\r\n\t\treturn imageName\r\n\t}\r\n\tparts := strings.Split(imageName, \"\/\")\r\n\tif len(parts) == 3 {\r\n\t\tparts = parts[1:]\r\n\t}\r\n\treturn path.Join(registry, parts[0], parts[1])\r\n}","code-length":99,"reference":"\/\/ AddRegistry switches the registry that an image is targeting, unless registry is blank","result":"Add a registry.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *ExponentialBackOff) withCanonicalRandomizationFactor() *ExponentialBackOff {\r\n\tif b.RandomizationFactor < 0 {\r\n\t\tb.RandomizationFactor = 0\r\n\t} else if b.RandomizationFactor > 1 {\r\n\t\tb.RandomizationFactor = 1\r\n\t}\r\n\treturn b\r\n}","code-length":90,"reference":"\/\/ withCanonicalRandomizationFactor is a utility function used by all\n\/\/ NewXYZBackoff functions to clamp b.RandomizationFactor to either 0 or 1","result":"Set the canonical randomization factor.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *ExponentialBackOff) Reset() {\r\n\tb.currentInterval = b.InitialInterval\r\n\tb.startTime = b.Clock.Now()\r\n}","code-length":50,"reference":"\/\/ Reset the interval back to the initial retry interval and restarts the timer.","result":"Reset the backoff.","score":[0.0148,0.0775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *ExponentialBackOff) incrementCurrentInterval() {\r\n\t\r\n\tif float64(b.currentInterval) >= float64(b.MaxInterval)\/b.Multiplier {\r\n\t\tb.currentInterval = b.MaxInterval\r\n\t} else {\r\n\t\tb.currentInterval = time.Duration(float64(b.currentInterval) * b.Multiplier)\r\n\t}\r\n}","code-length":103,"reference":"\/\/ Increments the current interval by multiplying it with the multiplier.","result":"Increment the current interval.","score":[0.0785,0.1456]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewBlockAPIServer(dir string, cacheBytes int64, backend string, etcdAddress string) (BlockAPIServer, error) {\r\n\tswitch backend {\r\n\tcase MinioBackendEnvVar:\r\n\t\t\r\n\t\tif len(dir) > 0 && dir[0] == '\/' {\r\n\t\t\tdir = dir[1:]\r\n\t\t}\r\n\t\tblockAPIServer, err := newMinioBlockAPIServer(dir, cacheBytes, etcdAddress)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn blockAPIServer, nil\r\n\tcase AmazonBackendEnvVar:\r\n\t\t\r\n\t\tif len(dir) > 0 && dir[0] == '\/' {\r\n\t\t\tdir = dir[1:]\r\n\t\t}\r\n\t\tblockAPIServer, err := newAmazonBlockAPIServer(dir, cacheBytes, etcdAddress)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn blockAPIServer, nil\r\n\tcase GoogleBackendEnvVar:\r\n\t\t\r\n\t\tblockAPIServer, err := newGoogleBlockAPIServer(dir, cacheBytes, etcdAddress)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn blockAPIServer, nil\r\n\tcase MicrosoftBackendEnvVar:\r\n\t\tblockAPIServer, err := newMicrosoftBlockAPIServer(dir, cacheBytes, etcdAddress)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn blockAPIServer, nil\r\n\tcase LocalBackendEnvVar:\r\n\t\tfallthrough\r\n\tdefault:\r\n\t\tblockAPIServer, err := newLocalBlockAPIServer(dir, cacheBytes, etcdAddress)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn blockAPIServer, nil\r\n\t}\r\n}","code-length":449,"reference":"\/\/ NewBlockAPIServer creates a BlockAPIServer using the credentials it finds in\n\/\/ the environment","result":"Create a new block server.","score":[0.0397,0.1431]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LocalStorage(tb testing.TB) (obj.Client, *Storage) {\r\n\twd, err := os.Getwd()\r\n\trequire.NoError(tb, err)\r\n\tobjC, err := obj.NewLocalClient(wd)\r\n\trequire.NoError(tb, err)\r\n\treturn objC, NewStorage(objC, Prefix)\r\n}","code-length":97,"reference":"\/\/ LocalStorage creates a local chunk storage instance.\n\/\/ Useful for storage layer tests.","result":"Store local objects.","score":[0.0104,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *APIServer) deleteJob(stm col.STM, jobPtr *pps.EtcdJobInfo) error {\r\n\tpipelinePtr := &pps.EtcdPipelineInfo{}\r\n\tif err := a.pipelines.ReadWrite(stm).Update(jobPtr.Pipeline.Name, pipelinePtr, func() error {\r\n\t\tif pipelinePtr.JobCounts == nil {\r\n\t\t\tpipelinePtr.JobCounts = make(map[int32]int32)\r\n\t\t}\r\n\t\tif pipelinePtr.JobCounts[int32(jobPtr.State)] != 0 {\r\n\t\t\tpipelinePtr.JobCounts[int32(jobPtr.State)]--\r\n\t\t}\r\n\t\treturn nil\r\n\t}); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn a.jobs.ReadWrite(stm).Delete(jobPtr.Job.ID)\r\n}","code-length":218,"reference":"\/\/ deleteJob is identical to updateJobState, except that jobPtr points to a job\n\/\/ that should be deleted rather than marked failed. Jobs may be deleted if\n\/\/ their output commit is deleted.","result":"Delete the job from the server.","score":[0.0021,0.033]}
{"code":"\/*is used to<extra_id_0>\r\nfunc writeXML(w http.ResponseWriter, r *http.Request, code int, v interface{}) {\r\n\tw.Header().Set(\"Content-Type\", \"application\/xml\")\r\n\tw.WriteHeader(code)\r\n\tencoder := xml.NewEncoder(w)\r\n\tif err := encoder.Encode(v); err != nil {\r\n\t\t\r\n\t\t\r\n\t\trequestLogger(r).Errorf(\"could not encode xml response: %v\", err)\r\n\t}\r\n}","code-length":124,"reference":"\/\/ writeXML serializes a struct to a response as XML","result":"Write the response XML.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc clean1_7HashtreePath(p string) string {\r\n\tif !strings.HasPrefix(p, \"\/\") {\r\n\t\tp = \"\/\" + p\r\n\t}\r\n\treturn default1_7HashtreeRoot(pathlib.Clean(p))\r\n}","code-length":75,"reference":"\/\/ clean canonicalizes 'path' for a Pachyderm 1.7 hashtree","result":"Clean the path.","score":[0,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFromAddress(addr string, options ...Option) (*APIClient, error) {\r\n\t\r\n\tsettings := clientSettings{\r\n\t\tmaxConcurrentStreams: DefaultMaxConcurrentStreams,\r\n\t\tdialTimeout:          DefaultDialTimeout,\r\n\t}\r\n\tfor _, option := range options {\r\n\t\tif err := option(&settings); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\tc := &APIClient{\r\n\t\taddr:    addr,\r\n\t\tcaCerts: settings.caCerts,\r\n\t\tlimiter: limit.New(settings.maxConcurrentStreams),\r\n\t}\r\n\tif err := c.connect(settings.dialTimeout); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn c, nil\r\n}","code-length":203,"reference":"\/\/ NewFromAddress constructs a new APIClient for the server at addr.","result":"Create a new client from an address.","score":[0.129,0.1769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getUserMachineAddrAndOpts(cfg *config.Config) (string, []Option, error) {\r\n\t\r\n\tif envAddr, ok := os.LookupEnv(\"PACHD_ADDRESS\"); ok {\r\n\t\tif !strings.Contains(envAddr, \":\") {\r\n\t\t\tenvAddr = fmt.Sprintf(\"%s:%s\", envAddr, DefaultPachdNodePort)\r\n\t\t}\r\n\t\toptions, err := getCertOptionsFromEnv()\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", nil, err\r\n\t\t}\r\n\t\treturn envAddr, options, nil\r\n\t}\r\n\t\r\n\tif cfg != nil && cfg.V1 != nil && cfg.V1.PachdAddress != \"\" {\r\n\t\t\r\n\t\tif cfg.V1.ServerCAs != \"\" {\r\n\t\t\tpemBytes, err := base64.StdEncoding.DecodeString(cfg.V1.ServerCAs)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn \"\", nil, fmt.Errorf(\"could not decode server CA certs in config: %v\", err)\r\n\t\t\t}\r\n\t\t\treturn cfg.V1.PachdAddress, []Option{WithAdditionalRootCAs(pemBytes)}, nil\r\n\t\t}\r\n\t\treturn cfg.V1.PachdAddress, nil, nil\r\n\t}\r\n\t\r\n\toptions, err := getCertOptionsFromEnv()\r\n\tif err != nil {\r\n\t\treturn \"\", nil, err\r\n\t}\r\n\treturn \"\", options, nil\r\n}","code-length":372,"reference":"\/\/ getUserMachineAddrAndOpts is a helper for NewOnUserMachine that uses\n\/\/ environment variables, config files, etc to figure out which address a user\n\/\/ running a command should connect to.","result":"Determine the user machine address and options.","score":[0.0083,0.0373]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewInCluster(options ...Option) (*APIClient, error) {\r\n\thost, ok := os.LookupEnv(\"PACHD_SERVICE_HOST\")\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"PACHD_SERVICE_HOST not set\")\r\n\t}\r\n\tport, ok := os.LookupEnv(\"PACHD_SERVICE_PORT\")\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"PACHD_SERVICE_PORT not set\")\r\n\t}\r\n\t\r\n\treturn NewFromAddress(fmt.Sprintf(\"%s:%s\", host, port), options...)\r\n}","code-length":158,"reference":"\/\/ NewInCluster constructs a new APIClient using env vars that Kubernetes creates.\n\/\/ This should be used to access Pachyderm from within a Kubernetes cluster\n\/\/ with Pachyderm running on it.","result":"Create a new client in cluster.","score":[0.0042,0.0351]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *APIClient) Close() error {\r\n\tif err := c.clientConn.Close(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif c.portForwarder != nil {\r\n\t\tc.portForwarder.Close()\r\n\t}\r\n\treturn nil\r\n}","code-length":80,"reference":"\/\/ Close the connection to gRPC","result":"Close the client.","score":[0.2124,0.3289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) DeleteAll() error {\r\n\tif _, err := c.AuthAPIClient.Deactivate(\r\n\t\tc.Ctx(),\r\n\t\t&auth.DeactivateRequest{},\r\n\t); err != nil && !auth.IsErrNotActivated(err) {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tif _, err := c.PpsAPIClient.DeleteAll(\r\n\t\tc.Ctx(),\r\n\t\t&types.Empty{},\r\n\t); err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tif _, err := c.PfsAPIClient.DeleteAll(\r\n\t\tc.Ctx(),\r\n\t\t&types.Empty{},\r\n\t); err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn nil\r\n}","code-length":223,"reference":"\/\/ DeleteAll deletes everything in the cluster.\n\/\/ Use with caution, there is no undo.","result":"Delete all files.","score":[0,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) SetMaxConcurrentStreams(n int) {\r\n\tc.limiter = limit.New(n)\r\n}","code-length":40,"reference":"\/\/ SetMaxConcurrentStreams Sets the maximum number of concurrent streams the\n\/\/ client can have. It is not safe to call this operations while operations are\n\/\/ outstanding.","result":"Set the limit on the number of concurrent streams.","score":[0.0386,0.2232]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *APIClient) WithCtx(ctx context.Context) *APIClient {\r\n\tresult := *c\r\n\tresult.ctx = ctx\r\n\treturn &result\r\n}","code-length":50,"reference":"\/\/ WithCtx returns a new APIClient that uses ctx for requests it sends. Note\n\/\/ that the new APIClient will still use the authentication token and metrics\n\/\/ metadata of this client, so this is only useful for propagating other\n\/\/ context-associated metadata.","result":"Create a new API.","score":[0.0,0.0256]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDLock(client *etcd.Client, prefix string) DLock {\r\n\treturn &etcdImpl{\r\n\t\tclient: client,\r\n\t\tprefix: prefix,\r\n\t}\r\n}","code-length":59,"reference":"\/\/ NewDLock attempts to acquire a distributed lock that locks a given prefix\n\/\/ in the data store.","result":"Create a new DLock.","score":[0.0096,0.0301]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *APIServer) DatumID(data []*Input) string {\r\n\thash := sha256.New()\r\n\tfor _, d := range data {\r\n\t\thash.Write([]byte(d.FileInfo.File.Path))\r\n\t\thash.Write(d.FileInfo.Hash)\r\n\t}\r\n\t\r\n\t\r\n\treturn hex.EncodeToString(hash.Sum(nil))\r\n}","code-length":107,"reference":"\/\/ DatumID computes the id for a datum, this value is used in ListDatum and\n\/\/ InspectDatum.","result":"Generate the DatumID.","score":[0.0038,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *APIServer) runUserErrorHandlingCode(ctx context.Context, logger *taggedLogger, environ []string, stats *pps.ProcessStats, rawDatumTimeout *types.Duration) (retErr error) {\r\n\tlogger.Logf(\"beginning to run user error handling code\")\r\n\tdefer func(start time.Time) {\r\n\t\tif retErr != nil {\r\n\t\t\tlogger.Logf(\"errored running user error handling code after %v: %v\", time.Since(start), retErr)\r\n\t\t} else {\r\n\t\t\tlogger.Logf(\"finished running user error handling code after %v\", time.Since(start))\r\n\t\t}\r\n\t}(time.Now())\r\n\tcmd := exec.CommandContext(ctx, a.pipelineInfo.Transform.ErrCmd[0], a.pipelineInfo.Transform.ErrCmd[1:]...)\r\n\tif a.pipelineInfo.Transform.ErrStdin != nil {\r\n\t\tcmd.Stdin = strings.NewReader(strings.Join(a.pipelineInfo.Transform.ErrStdin, \"\\n\") + \"\\n\")\r\n\t}\r\n\tcmd.Stdout = logger.userLogger()\r\n\tcmd.Stderr = logger.userLogger()\r\n\tcmd.Env = environ\r\n\tif a.uid != nil && a.gid != nil {\r\n\t\tcmd.SysProcAttr = &syscall.SysProcAttr{\r\n\t\t\tCredential: &syscall.Credential{\r\n\t\t\t\tUid: *a.uid,\r\n\t\t\t\tGid: *a.gid,\r\n\t\t\t},\r\n\t\t}\r\n\t}\r\n\tcmd.Dir = a.pipelineInfo.Transform.WorkingDir\r\n\terr := cmd.Start()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"error cmd.Start: %v\", err)\r\n\t}\r\n\t\r\n\t\r\n\tstate, err := cmd.Process.Wait()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"error cmd.Wait: %v\", err)\r\n\t}\r\n\tif isDone(ctx) {\r\n\t\tif err = ctx.Err(); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\trr)\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif err != nil && !strings.Contains(err.Error(), \"broken pipe\") {\r\n\t\t\r\n\t\tif exiterr, ok := err.(*exec.ExitError); ok {\r\n\t\t\tif status, ok := exiterr.Sys().(syscall.WaitStatus); ok {\r\n\t\t\t\tfor _, returnCode := range a.pipelineInfo.Transform.AcceptReturnCode {\r\n\t\t\t\t\tif int(returnCode) == status.ExitStatus() {\r\n\t\t\t\t\t\treturn nil\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn fmt.Errorf(\"error cmd.WaitIO: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":710,"reference":"\/\/ Run user error code and return the combined output of stdout and stderr.","result":"Code too long,keep in 512.","score":[0,0.0382]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HashDatum(pipelineName string, pipelineSalt string, data []*Input) string {\r\n\thash := sha256.New()\r\n\tfor _, datum := range data {\r\n\t\thash.Write([]byte(datum.Name))\r\n\t\thash.Write([]byte(datum.FileInfo.File.Path))\r\n\t\thash.Write(datum.FileInfo.Hash)\r\n\t}\r\n\thash.Write([]byte(pipelineName))\r\n\thash.Write([]byte(pipelineSalt))\r\n\treturn client.DatumTagPrefix(pipelineSalt) + hex.EncodeToString(hash.Sum(nil))\r\n}","code-length":158,"reference":"\/\/ HashDatum computes and returns the hash of datum + pipeline, with a\n\/\/ pipeline-specific prefix.","result":"Generate the hash of the data.","score":[0.0751,0.1704]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HashDatum15(pipelineInfo *pps.PipelineInfo, data []*Input) (string, error) {\r\n\thash := sha256.New()\r\n\tfor _, datum := range data {\r\n\t\thash.Write([]byte(datum.Name))\r\n\t\thash.Write([]byte(datum.FileInfo.File.Path))\r\n\t\thash.Write(datum.FileInfo.Hash)\r\n\t}\r\n\t\r\n\t\r\n\tenv := pipelineInfo.Transform.Env\r\n\tpipelineInfo.Transform.Env = nil\r\n\tdefer func() {\r\n\t\tpipelineInfo.Transform.Env = env\r\n\t}()\r\n\tbytes, err := pipelineInfo.Transform.Marshal()\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\thash.Write(bytes)\r\n\thash.Write([]byte(pipelineInfo.Pipeline.Name))\r\n\thash.Write([]byte(pipelineInfo.ID))\r\n\thash.Write([]byte(strconv.Itoa(int(pipelineInfo.Version))))\r\n\t\r\n\t\r\n\treturn client.DatumTagPrefix(pipelineInfo.ID) + hex.EncodeToString(hash.Sum(nil)), nil\r\n}","code-length":298,"reference":"\/\/ HashDatum15 computes and returns the hash of datum + pipeline for version <= 1.5.0, with a\n\/\/ pipeline-specific prefix.","result":"Generate the hash of the datum .","score":[0.0558,0.1688]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *APIServer) Status(ctx context.Context, _ *types.Empty) (*pps.WorkerStatus, error) {\r\n\ta.statusMu.Lock()\r\n\tdefer a.statusMu.Unlock()\r\n\tstarted, err := types.TimestampProto(a.started)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tresult := &pps.WorkerStatus{\r\n\t\tJobID:     a.jobID,\r\n\t\tWorkerID:  a.workerName,\r\n\t\tStarted:   started,\r\n\t\tData:      a.datum(),\r\n\t\tQueueSize: atomic.LoadInt64(&a.queueSize),\r\n\t}\r\n\treturn result, nil\r\n}","code-length":188,"reference":"\/\/ Status returns the status of the current worker.","result":"Get worker status from the worker.","score":[0.1541,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *APIServer) Cancel(ctx context.Context, request *CancelRequest) (*CancelResponse, error) {\r\n\ta.statusMu.Lock()\r\n\tdefer a.statusMu.Unlock()\r\n\tif request.JobID != a.jobID {\r\n\t\treturn &CancelResponse{Success: false}, nil\r\n\t}\r\n\tif !MatchDatum(request.DataFilters, a.datum()) {\r\n\t\treturn &CancelResponse{Success: false}, nil\r\n\t}\r\n\ta.cancel()\r\n\t\r\n\ta.jobID = \"\"\r\n\ta.data = nil\r\n\ta.started = time.Time{}\r\n\ta.cancel = nil\r\n\treturn &CancelResponse{Success: true}, nil\r\n}","code-length":187,"reference":"\/\/ Cancel cancels the currently running datum","result":"Cancel a job.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc mergeStats(x, y *pps.ProcessStats) error {\r\n\tvar err error\r\n\tif x.DownloadTime, err = plusDuration(x.DownloadTime, y.DownloadTime); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif x.ProcessTime, err = plusDuration(x.ProcessTime, y.ProcessTime); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif x.UploadTime, err = plusDuration(x.UploadTime, y.UploadTime); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tx.DownloadBytes += y.DownloadBytes\r\n\tx.UploadBytes += y.UploadBytes\r\n\treturn nil\r\n}","code-length":177,"reference":"\/\/ mergeStats merges y into x","result":"Merge two stats objects.","score":[0,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *APIServer) mergeChunk(logger *taggedLogger, high int64, result *processResult) (retErr error) {\r\n\tlogger.Logf(\"starting to merge chunk\")\r\n\tdefer func(start time.Time) {\r\n\t\tif retErr != nil {\r\n\t\t\tlogger.Logf(\"errored merging chunk after %v: %v\", time.Since(start), retErr)\r\n\t\t} else {\r\n\t\t\tlogger.Logf(\"finished merging chunk after %v\", time.Since(start))\r\n\t\t}\r\n\t}(time.Now())\r\n\tbuf := &bytes.Buffer{}\r\n\tif result.datumsFailed <= 0 {\r\n\t\tif err := a.datumCache.Merge(hashtree.NewWriter(buf), nil, nil); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tif err := a.chunkCache.Put(high, buf); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif a.pipelineInfo.EnableStats {\r\n\t\tbuf.Reset()\r\n\t\tif err := a.datumStatsCache.Merge(hashtree.NewWriter(buf), nil, nil); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn a.chunkStatsCache.Put(high, buf)\r\n\t}\r\n\treturn nil\r\n}","code-length":339,"reference":"\/\/ mergeChunk merges the datum hashtrees into a chunk hashtree and stores it.","result":"Merge chunks.","score":[0,0.042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsCommitNotFoundErr(err error) bool {\r\n\tif err == nil {\r\n\t\treturn false\r\n\t}\r\n\treturn commitNotFoundRe.MatchString(grpcutil.ScrubGRPC(err).Error())\r\n}","code-length":63,"reference":"\/\/ IsCommitNotFoundErr returns true if 'err' has an error message that matches\n\/\/ ErrCommitNotFound","result":"Detect commit not found errors.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsCommitDeletedErr(err error) bool {\r\n\tif err == nil {\r\n\t\treturn false\r\n\t}\r\n\treturn commitDeletedRe.MatchString(grpcutil.ScrubGRPC(err).Error())\r\n}","code-length":63,"reference":"\/\/ IsCommitDeletedErr returns true if 'err' has an error message that matches\n\/\/ ErrCommitDeleted","result":"Detect commit deleted errors.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsCommitFinishedErr(err error) bool {\r\n\tif err == nil {\r\n\t\treturn false\r\n\t}\r\n\treturn commitFinishedRe.MatchString(grpcutil.ScrubGRPC(err).Error())\r\n}","code-length":63,"reference":"\/\/ IsCommitFinishedErr returns true of 'err' has an error message that matches\n\/\/ ErrCommitFinished","result":"Detect commit finished errors.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsRepoNotFoundErr(err error) bool {\r\n\tif err == nil {\r\n\t\treturn false\r\n\t}\r\n\treturn repoNotFoundRe.MatchString(err.Error())\r\n}","code-length":56,"reference":"\/\/ IsRepoNotFoundErr returns true if 'err' is an error message about a repo\n\/\/ not being found","result":"Generate a file .","score":[0.0124,0.0318]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsBranchNotFoundErr(err error) bool {\r\n\tif err == nil {\r\n\t\treturn false\r\n\t}\r\n\treturn branchNotFoundRe.MatchString(err.Error())\r\n}","code-length":56,"reference":"\/\/ IsBranchNotFoundErr returns true if 'err' is an error message about a\n\/\/ branch not being found","result":"Generate a file with a comment.","score":[0.0309,0.0314]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsFileNotFoundErr(err error) bool {\r\n\tif err == nil {\r\n\t\treturn false\r\n\t}\r\n\treturn fileNotFoundRe.MatchString(err.Error())\r\n}","code-length":56,"reference":"\/\/ IsFileNotFoundErr returns true if 'err' is an error message about a PFS\n\/\/ file not being found","result":"Parse the file .","score":[0.0096,0.0301]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) Version() (string, error) {\r\n\tv, err := c.VersionAPIClient.GetVersion(c.Ctx(), &types.Empty{})\r\n\tif err != nil {\r\n\t\treturn \"\", grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn version.PrettyPrintVersion(v), nil\r\n}","code-length":91,"reference":"\/\/ Version returns the version of pachd as a string.","result":"Generate the version string.","score":[0.1116,0.2719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc validateRepoName(name string) error {\r\n\tmatch, _ := regexp.MatchString(\"^[a-zA-Z0-9_-]+$\", name)\r\n\tif !match {\r\n\t\treturn fmt.Errorf(\"repo name (%v) invalid: only alphanumeric characters, underscores, and dashes are allowed\", name)\r\n\t}\r\n\treturn nil\r\n}","code-length":95,"reference":"\/\/ validateRepoName determines if a repo name is valid","result":"Validate repo name.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newDriver(env *serviceenv.ServiceEnv, etcdPrefix string, treeCache *hashtree.Cache, storageRoot string, memoryRequest int64) (*driver, error) {\r\n\t\r\n\tif treeCache == nil {\r\n\t\treturn nil, fmt.Errorf(\"cannot initialize driver with nil treeCache\")\r\n\t}\r\n\t\r\n\tetcdClient := env.GetEtcdClient()\r\n\td := &driver{\r\n\t\tetcdClient:     etcdClient,\r\n\t\tprefix:         etcdPrefix,\r\n\t\trepos:          pfsdb.Repos(etcdClient, etcdPrefix),\r\n\t\tputFileRecords: pfsdb.PutFileRecords(etcdClient, etcdPrefix),\r\n\t\tcommits: func(repo string) col.Collection {\r\n\t\t\treturn pfsdb.Commits(etcdClient, etcdPrefix, repo)\r\n\t\t},\r\n\t\tbranches: func(repo string) col.Collection {\r\n\t\t\treturn pfsdb.Branches(etcdClient, etcdPrefix, repo)\r\n\t\t},\r\n\t\topenCommits: pfsdb.OpenCommits(etcdClient, etcdPrefix),\r\n\t\ttreeCache:   treeCache,\r\n\t\tstorageRoot: storageRoot,\r\n\t\t\r\n\t\tmemoryLimiter: semaphore.NewWeighted(memoryRequest \/ 3),\r\n\t}\r\n\t\r\n\trepo := client.NewRepo(ppsconsts.SpecRepo)\r\n\trepoInfo := &pfs.RepoInfo{\r\n\t\tRepo:    repo,\r\n\t\tCreated: now(),\r\n\t}\r\n\tif _, err := col.NewSTM(context.Background(), etcdClient, func(stm col.STM) error {\r\n\t\trepos := d.repos.ReadWrite(stm)\r\n\t\treturn repos.Create(repo.Name, repoInfo)\r\n\t}); err != nil && !col.IsErrExists(err) {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn d, nil\r\n}","code-length":480,"reference":"\/\/ newDriver is used to create a new Driver instance","result":"Initialize the driver.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *driver) inspectCommit(pachClient *client.APIClient, commit *pfs.Commit, blockState pfs.CommitState) (*pfs.CommitInfo, error) {\r\n\tctx := pachClient.Ctx()\r\n\tif commit == nil {\r\n\t\treturn nil, fmt.Errorf(\"cannot inspect nil commit\")\r\n\t}\r\n\tif err := d.checkIsAuthorized(pachClient, commit.Repo, auth.Scope_READER); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tvar commitInfo *pfs.CommitInfo\r\n\tif _, err := col.NewSTM(ctx, d.etcdClient, func(stm col.STM) error {\r\n\t\tvar err error\r\n\t\tcommitInfo, err = d.resolveCommit(stm, commit)\r\n\t\treturn err\r\n\t}); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tcommits := d.commits(commit.Repo.Name).ReadOnly(ctx)\r\n\tif blockState == pfs.CommitState_READY {\r\n\t\t\r\n\t\tfor _, p := range commitInfo.Provenance {\r\n\t\t\td.inspectCommit(pachClient, p.Commit, pfs.CommitState_FINISHED)\r\n\t\t}\r\n\t}\r\n\tif blockState == pfs.CommitState_FINISHED {\r\n\t\t\r\n\t\tif err := func() error {\r\n\t\t\tcommitInfoWatcher, err := commits.WatchOne(commit.ID)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tdefer commitInfoWatcher.Close()\r\n\t\t\tfor {\r\n\t\t\t\tvar commitID string\r\n\t\t\t\t_commitInfo := new(pfs.CommitInfo)\r\n\t\t\t\tevent := <-commitInfoWatcher.Watch()\r\n\t\t\t\tswitch event.Type {\r\n\t\t\t\tcase watch.EventError:\r\n\t\t\t\t\treturn event.Err\r\n\t\t\t\tcase watch.EventPut:\r\n\t\t\t\t\tif err := event.Unmarshal(&commitID, _commitInfo); err != nil {\r\n\t\t\t\t\t\treturn fmt.Errorf(\"Unmarshal: %v\", err)\r\n\t\t\t\t\t}\r\n\t\t\t\tcase watch.EventDelete:\r\n\t\t\t\t\treturn pfsserver.ErrCommitDeleted{commit}\r\n\t\t\t\t}\r\n\t\t\t\tif _commitInfo.Finished != nil {\r\n\t\t\t\t\tcommitInfo = _commitInfo\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t}(); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\treturn commitInfo, nil\r\n}","code-length":638,"reference":"\/\/ inspectCommit takes a Commit and returns the corresponding CommitInfo.\n\/\/\n\/\/ As a side effect, this function also replaces the ID in the given commit\n\/\/ with a real commit ID.","result":"Code too long,keep in 512.","score":[0.0011,0.0341]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *driver) scratchCommitPrefix(commit *pfs.Commit) string {\r\n\t\r\n\t\r\n\t\r\n\treturn path.Join(commit.Repo.Name, commit.ID)\r\n}","code-length":58,"reference":"\/\/ scratchCommitPrefix returns an etcd prefix that's used to temporarily\n\/\/ store the state of a file in an open commit.  Once the commit is finished,\n\/\/ the scratch space is removed.","result":"Generate scratch commit prefix.","score":[0.0003,0.0342]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *driver) scratchFilePrefix(file *pfs.File) (string, error) {\r\n\treturn path.Join(d.scratchCommitPrefix(file.Commit), file.Path), nil\r\n}","code-length":59,"reference":"\/\/ scratchFilePrefix returns an etcd prefix that's used to temporarily\n\/\/ store the state of a file in an open commit.  Once the commit is finished,\n\/\/ the scratch space is removed.","result":"Generate scratch file prefix.","score":[0.0003,0.0342]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *driver) getTreeForFile(pachClient *client.APIClient, file *pfs.File) (hashtree.HashTree, error) {\r\n\tif file.Commit == nil {\r\n\t\tt, err := hashtree.NewDBHashTree(d.storageRoot)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn t, nil\r\n\t}\r\n\tcommitInfo, err := d.inspectCommit(pachClient, file.Commit, pfs.CommitState_STARTED)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif commitInfo.Finished != nil {\r\n\t\ttree, err := d.getTreeForCommit(pachClient, file.Commit)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn tree, nil\r\n\t}\r\n\tparentTree, err := d.getTreeForCommit(pachClient, commitInfo.ParentCommit)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn d.getTreeForOpenCommit(pachClient, file, parentTree)\r\n}","code-length":298,"reference":"\/\/ getTreeForFile is like getTreeForCommit except that it can handle open commits.\n\/\/ It takes a file instead of a commit so that it can apply the changes for\n\/\/ that path to the tree before it returns it.","result":"Generate code for the generated code.","score":[0.0009,0.028]}
{"code":"\/*is used to<extra_id_0>\r\nfunc provenantOnInput(provenance []*pfs.CommitProvenance) bool {\r\n\tprovenanceCount := len(provenance)\r\n\tfor _, p := range provenance {\r\n\t\t\r\n\t\tif p.Commit.Repo.Name == ppsconsts.SpecRepo {\r\n\t\t\tprovenanceCount--\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\treturn provenanceCount > 0\r\n}","code-length":105,"reference":"\/\/ this is a helper function to check if the given provenance has provenance on an input branch","result":"Check if input is provenant.","score":[0.0235,0.189]}
{"code":"\/*is used to<extra_id_0>\r\nfunc nodeToFileInfo(ci *pfs.CommitInfo, path string, node *hashtree.NodeProto, full bool) *pfs.FileInfo {\r\n\tfileInfo := &pfs.FileInfo{\r\n\t\tFile: &pfs.File{\r\n\t\t\tCommit: ci.Commit,\r\n\t\t\tPath:   path,\r\n\t\t},\r\n\t\tSizeBytes: uint64(node.SubtreeSize),\r\n\t\tHash:      node.Hash,\r\n\t\tCommitted: ci.Finished,\r\n\t}\r\n\tif node.FileNode != nil {\r\n\t\tfileInfo.FileType = pfs.FileType_FILE\r\n\t\tif full {\r\n\t\t\tfileInfo.Objects = node.FileNode.Objects\r\n\t\t\tfileInfo.BlockRefs = node.FileNode.BlockRefs\r\n\t\t}\r\n\t} else if node.DirNode != nil {\r\n\t\tfileInfo.FileType = pfs.FileType_DIR\r\n\t\tif full {\r\n\t\t\tfileInfo.Children = node.DirNode.Children\r\n\t\t}\r\n\t}\r\n\treturn fileInfo\r\n}","code-length":268,"reference":"\/\/ If full is false, exclude potentially large fields such as `Objects`\n\/\/ and `Children`","result":"Convert a hashtree.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *driver) fileHistory(pachClient *client.APIClient, file *pfs.File, history int64, f func(*pfs.FileInfo) error) error {\r\n\tvar fi *pfs.FileInfo\r\n\tfor {\r\n\t\t_fi, err := d.inspectFile(pachClient, file)\r\n\t\tif err != nil {\r\n\t\t\tif _, ok := err.(pfsserver.ErrFileNotFound); ok {\r\n\t\t\t\treturn f(fi)\r\n\t\t\t}\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif fi != nil && bytes.Compare(fi.Hash, _fi.Hash) != 0 {\r\n\t\t\tif err := f(fi); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif history > 0 {\r\n\t\t\t\thistory--\r\n\t\t\t\tif history == 0 {\r\n\t\t\t\t\treturn nil\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\tfi = _fi\r\n\t\tci, err := d.inspectCommit(pachClient, file.Commit, pfs.CommitState_STARTED)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif ci.ParentCommit == nil {\r\n\t\t\treturn f(fi)\r\n\t\t}\r\n\t\tfile.Commit = ci.ParentCommit\r\n\t}\r\n}","code-length":339,"reference":"\/\/ fileHistory calls f with FileInfos for the file, starting with how it looked\n\/\/ at the referenced commit and then all past versions that are different.","result":"Generate the code.","score":[0.0001,0.0203]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *driver) upsertPutFileRecords(pachClient *client.APIClient, file *pfs.File, newRecords *pfs.PutFileRecords) error {\r\n\tprefix, err := d.scratchFilePrefix(file)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tctx := pachClient.Ctx()\r\n\t_, err = col.NewSTM(ctx, d.etcdClient, func(stm col.STM) error {\r\n\t\tcommitsCol := d.openCommits.ReadOnly(ctx)\r\n\t\tvar commit pfs.Commit\r\n\t\terr := commitsCol.Get(file.Commit.ID, &commit)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tif commit.ID != file.Commit.ID {\r\n\t\t\treturn fmt.Errorf(\"commit %v is not open\", file.Commit.ID)\r\n\t\t}\r\n\t\trecordsCol := d.putFileRecords.ReadWrite(stm)\r\n\t\tvar existingRecords pfs.PutFileRecords\r\n\t\treturn recordsCol.Upsert(prefix, &existingRecords, func() error {\r\n\t\t\tif newRecords.Tombstone {\r\n\t\t\t\texistingRecords.Tombstone = true\r\n\t\t\t\texistingRecords.Records = nil\r\n\t\t\t}\r\n\t\t\texistingRecords.Split = newRecords.Split\r\n\t\t\texistingRecords.Records = append(existingRecords.Records, newRecords.Records...)\r\n\t\t\texistingRecords.Header = newRecords.Header\r\n\t\t\texistingRecords.Footer = newRecords.Footer\r\n\t\t\treturn nil\r\n\t\t})\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn err\r\n}","code-length":430,"reference":"\/\/ Put the tree into the blob store\n\/\/ Only write the records to etcd if the commit does exist and is open.\n\/\/ To check that a key exists in etcd, we assert that its CreateRevision\n\/\/ is greater than zero.","result":"Update the records in the file.","score":[0.0008,0.0822]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *PGDumpReader) ReadRow() ([]byte, error) {\r\n\tif len(r.Header) == 0 {\r\n\t\terr := r.readHeader()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\tendLine := \"\\\\.\\n\"\r\n\trow, err := r.rd.ReadBytes('\\n')\r\n\tif err != nil && err != io.EOF {\r\n\t\treturn nil, fmt.Errorf(\"error reading pgdump row: %v\", err)\r\n\t}\r\n\t\r\n\t\r\n\tif len(row) >= 2 && row[len(row)-2] == '\\r' {\r\n\t\trow[len(row)-2] = '\\n'\r\n\t\trow = row[:len(row)-1]\r\n\t}\r\n\tif string(row) == endLine {\r\n\t\tr.Footer = append(r.Footer, row...)\r\n\t\terr = r.readFooter()\r\n\t\trow = nil\r\n\t}\r\n\tif err == io.EOF && len(r.Footer) == 0 {\r\n\t\treturn nil, fmt.Errorf(\"invalid pgdump - missing footer\")\r\n\t}\r\n\treturn row, err\r\n}","code-length":308,"reference":"\/\/ ReadRow parses the pgdump file and populates the header and the footer\n\/\/ It returns EOF when done, and at that time both the Header and Footer will\n\/\/ be populated. Both header and footer are required. If either are missing, an\n\/\/ error is returned","result":"Read the row from the reader.","score":[0.0002,0.0233]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewReporter(clusterID string, kubeClient *kube.Clientset) *Reporter {\r\n\treporter := &Reporter{\r\n\t\tsegmentClient: newPersistentClient(),\r\n\t\tclusterID:     clusterID,\r\n\t\tkubeClient:    kubeClient,\r\n\t}\r\n\tgo reporter.reportClusterMetrics()\r\n\treturn reporter\r\n}","code-length":94,"reference":"\/\/ NewReporter creates a new reporter and kicks off the loop to report cluster\n\/\/ metrics","result":"Create a new reporter.","score":[0.0225,0.1989]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReportUserAction(ctx context.Context, r *Reporter, action string) func(time.Time, error) {\r\n\tif r == nil {\r\n\t\t\r\n\t\treturn func(time.Time, error) {}\r\n\t}\r\n\t\r\n\tr.reportUserAction(ctx, fmt.Sprintf(\"%vStarted\", action), 1)\r\n\treturn func(start time.Time, err error) {\r\n\t\tif err == nil {\r\n\t\t\tr.reportUserAction(ctx, fmt.Sprintf(\"%vFinished\", action), time.Since(start).Seconds())\r\n\t\t} else {\r\n\t\t\tr.reportUserAction(ctx, fmt.Sprintf(\"%vErrored\", action), err.Error())\r\n\t\t}\r\n\t}\r\n}","code-length":190,"reference":"\/\/ReportUserAction pushes the action into a queue for reporting,\n\/\/ and reports the start, finish, and error conditions","result":"Report user actions.","score":[0,0.0303]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FinishReportAndFlushUserAction(action string, err error, start time.Time) func() {\r\n\tvar wait func()\r\n\tif err != nil {\r\n\t\twait = reportAndFlushUserAction(fmt.Sprintf(\"%vErrored\", action), err)\r\n\t} else {\r\n\t\twait = reportAndFlushUserAction(fmt.Sprintf(\"%vFinished\", action), time.Since(start).Seconds())\r\n\t}\r\n\treturn wait\r\n}","code-length":119,"reference":"\/\/ FinishReportAndFlushUserAction immediately reports the metric but does\n\/\/ not block execution. It returns a wait function which waits or times\n\/\/ out after 5s.\n\/\/ It is used by the pachctl binary and runs on users' machines","result":"Report and flush user actions.","score":[0.0003,0.0288]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Reader) Read(data []byte) (int, error) {\r\n\tvar totalRead int\r\n\tfor len(data) > 0 {\r\n\t\tn, err := r.r.Read(data)\r\n\t\tdata = data[n:]\r\n\t\ttotalRead += n\r\n\t\tif err != nil {\r\n\t\t\t\r\n\t\t\tif len(r.dataRefs) == 0 {\r\n\t\t\t\treturn totalRead, io.EOF\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif r.curr == nil || r.curr.Chunk.Hash != r.dataRefs[0].Chunk.Hash {\r\n\t\t\t\tif err := r.readChunk(r.dataRefs[0].Chunk); err != nil {\r\n\t\t\t\t\treturn totalRead, err\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tr.curr = r.dataRefs[0]\r\n\t\t\tr.dataRefs = r.dataRefs[1:]\r\n\t\t\tr.r = bytes.NewReader(r.buf.Bytes()[r.curr.OffsetBytes : r.curr.OffsetBytes+r.curr.SizeBytes])\r\n\t\t}\r\n\t}\r\n\treturn totalRead, nil\r\n}","code-length":291,"reference":"\/\/ Read reads from the byte stream produced by the set of DataRefs.","result":"Read from a file.","score":[0.04,0.0826]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ActivateCmd(noMetrics, noPortForwarding *bool) *cobra.Command {\r\n\tvar expires string\r\n\tactivate := &cobra.Command{\r\n\t\tUse: \"{{alias}} <activation-code>\",\r\n\t\tShort: \"Activate the enterprise features of Pachyderm with an activation \" +\r\n\t\t\t\"code\",\r\n\t\tLong: \"Activate the enterprise features of Pachyderm with an activation \" +\r\n\t\t\t\"code\",\r\n\t\tRun: cmdutil.RunFixedArgs(1, func(args []string) error {\r\n\t\t\tc, err := client.NewOnUserMachine(!*noMetrics, !*noPortForwarding, \"user\")\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"could not connect: %s\", err.Error())\r\n\t\t\t}\r\n\t\t\tdefer c.Close()\r\n\t\t\treq := &enterprise.ActivateRequest{}\r\n\t\t\treq.ActivationCode = args[0]\r\n\t\t\tif expires != \"\" {\r\n\t\t\t\tt, err := parseISO8601(expires)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn fmt.Errorf(\"could not parse the timestamp \\\"%s\\\": %s\", expires, err.Error())\r\n\t\t\t\t}\r\n\t\t\t\treq.Expires, err = types.TimestampProto(t)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn fmt.Errorf(\"error converting expiration time \\\"%s\\\"; %s\", t.String(), err.Error())\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tresp, err := c.Enterprise.Activate(c.Ctx(), req)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tts, err := types.TimestampFromProto(resp.Info.Expires)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"Activation request succeeded, but could not \"+\r\n\t\t\t\t\t\"convert token expiration time to a timestamp: %s\", err.Error())\r\n\t\t\t}\r\n\t\t\tfmt.Printf(\"Activation succeeded. Your Pachyderm Enterprise token \"+\r\n\t\t\t\t\"expires %s\\n\", ts.String())\r\n\t\t\treturn nil\r\n\t\t}),\r\n\t}\r\n\tactivate.PersistentFlags().StringVar(&expires, \"expires\", \"\", \"A timestamp \"+\r\n\t\t\"indicating when the token provided above should expire (formatted as an \"+\r\n\t\t\"RFC 3339\/ISO 8601 datetime). This is only applied if it's earlier than \"+\r\n\t\t\"the signed expiration time encoded in 'activation-code', and therefore \"+\r\n\t\t\"is only useful for testing.\")\r\n\treturn cmdutil.CreateAlias(activate, \"enterprise activate\")\r\n}","code-length":645,"reference":"\/\/ ActivateCmd returns a cobra.Command to activate the enterprise features of\n\/\/ Pachyderm within a Pachyderm cluster. All repos will go from\n\/\/ publicly-accessible to accessible only by the owner, who can subsequently add\n\/\/ users","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetStateCmd(noMetrics, noPortForwarding *bool) *cobra.Command {\r\n\tgetState := &cobra.Command{\r\n\t\tShort: \"Check whether the Pachyderm cluster has enterprise features \" +\r\n\t\t\t\"activated\",\r\n\t\tLong: \"Check whether the Pachyderm cluster has enterprise features \" +\r\n\t\t\t\"activated\",\r\n\t\tRun: cmdutil.Run(func(args []string) error {\r\n\t\t\tc, err := client.NewOnUserMachine(!*noMetrics, !*noPortForwarding, \"user\")\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"could not connect: %s\", err.Error())\r\n\t\t\t}\r\n\t\t\tdefer c.Close()\r\n\t\t\tresp, err := c.Enterprise.GetState(c.Ctx(), &enterprise.GetStateRequest{})\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif resp.State == enterprise.State_NONE {\r\n\t\t\t\tfmt.Println(\"No Pachyderm Enterprise token was found\")\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\tts, err := types.TimestampFromProto(resp.Info.Expires)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"Activation request succeeded, but could not \"+\r\n\t\t\t\t\t\"convert token expiration time to a timestamp: %s\", err.Error())\r\n\t\t\t}\r\n\t\t\tfmt.Printf(\"Pachyderm Enterprise token state: %s\\nExpiration: %s\\n\",\r\n\t\t\t\tresp.State.String(), ts.String())\r\n\t\t\treturn nil\r\n\t\t}),\r\n\t}\r\n\treturn cmdutil.CreateAlias(getState, \"enterprise get-state\")\r\n}","code-length":434,"reference":"\/\/ GetStateCmd returns a cobra.Command to activate the enterprise features of\n\/\/ Pachyderm within a Pachyderm cluster. All repos will go from\n\/\/ publicly-accessible to accessible only by the owner, who can subsequently add\n\/\/ users","result":"Check whether the Pachyderm cluster has enterprise features activated.","score":[0.0102,0.0948]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Cmds(noMetrics, noPortForwarding *bool) []*cobra.Command {\r\n\tvar commands []*cobra.Command\r\n\tenterprise := &cobra.Command{\r\n\t\tShort: \"Enterprise commands enable Pachyderm Enterprise features\",\r\n\t\tLong:  \"Enterprise commands enable Pachyderm Enterprise features\",\r\n\t}\r\n\tcommands = append(commands, cmdutil.CreateAlias(enterprise, \"enterprise\"))\r\n\tcommands = append(commands, ActivateCmd(noMetrics, noPortForwarding))\r\n\tcommands = append(commands, GetStateCmd(noMetrics, noPortForwarding))\r\n\treturn commands\r\n}","code-length":165,"reference":"\/\/ Cmds returns pachctl commands related to Pachyderm Enterprise","result":"Generate the commands.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewConfiguration(config interface{}) *Configuration {\r\n\tconfiguration := &Configuration{}\r\n\tswitch config.(type) {\r\n\tcase *GlobalConfiguration:\r\n\t\tconfiguration.GlobalConfiguration = config.(*GlobalConfiguration)\r\n\t\treturn configuration\r\n\tcase *PachdFullConfiguration:\r\n\t\tconfiguration.GlobalConfiguration = &config.(*PachdFullConfiguration).GlobalConfiguration\r\n\t\tconfiguration.PachdSpecificConfiguration = &config.(*PachdFullConfiguration).PachdSpecificConfiguration\r\n\t\treturn configuration\r\n\tcase *WorkerFullConfiguration:\r\n\t\tconfiguration.GlobalConfiguration = &config.(*WorkerFullConfiguration).GlobalConfiguration\r\n\t\tconfiguration.WorkerSpecificConfiguration = &config.(*WorkerFullConfiguration).WorkerSpecificConfiguration\r\n\t\treturn configuration\r\n\tdefault:\r\n\t\treturn nil\r\n\t}\r\n}","code-length":205,"reference":"\/\/ NewConfiguration creates a generic configuration from a specific type of configuration.","result":"Create a new configuration object.","score":[0.0705,0.1327]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Repos(etcdClient *etcd.Client, etcdPrefix string) col.Collection {\r\n\treturn col.NewCollection(\r\n\t\tetcdClient,\r\n\t\tpath.Join(etcdPrefix, reposPrefix),\r\n\t\tnil,\r\n\t\t&pfs.RepoInfo{},\r\n\t\tnil,\r\n\t\tnil,\r\n\t)\r\n}","code-length":99,"reference":"\/\/ Repos returns a collection of repos","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PutFileRecords(etcdClient *etcd.Client, etcdPrefix string) col.Collection {\r\n\treturn col.NewCollection(\r\n\t\tetcdClient,\r\n\t\tpath.Join(etcdPrefix, putFileRecordsPrefix),\r\n\t\tnil,\r\n\t\t&pfs.PutFileRecords{},\r\n\t\tnil,\r\n\t\tnil,\r\n\t)\r\n}","code-length":103,"reference":"\/\/ PutFileRecords returns a collection of putFileRecords","result":"Create the collection.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Commits(etcdClient *etcd.Client, etcdPrefix string, repo string) col.Collection {\r\n\treturn col.NewCollection(\r\n\t\tetcdClient,\r\n\t\tpath.Join(etcdPrefix, commitsPrefix, repo),\r\n\t\t[]*col.Index{ProvenanceIndex},\r\n\t\t&pfs.CommitInfo{},\r\n\t\tnil,\r\n\t\tnil,\r\n\t)\r\n}","code-length":112,"reference":"\/\/ Commits returns a collection of commits","result":"Create the collection.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Branches(etcdClient *etcd.Client, etcdPrefix string, repo string) col.Collection {\r\n\treturn col.NewCollection(\r\n\t\tetcdClient,\r\n\t\tpath.Join(etcdPrefix, branchesPrefix, repo),\r\n\t\tnil,\r\n\t\t&pfs.BranchInfo{},\r\n\t\tfunc(key string) error {\r\n\t\t\tif uuid.IsUUIDWithoutDashes(key) {\r\n\t\t\t\treturn fmt.Errorf(\"branch name cannot be a UUID V4\")\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t},\r\n\t\tnil,\r\n\t)\r\n}","code-length":159,"reference":"\/\/ Branches returns a collection of branches","result":"Create a collection of branches.","score":[0.3318,0.433]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OpenCommits(etcdClient *etcd.Client, etcdPrefix string) col.Collection {\r\n\treturn col.NewCollection(\r\n\t\tetcdClient,\r\n\t\tpath.Join(etcdPrefix, openCommitsPrefix),\r\n\t\tnil,\r\n\t\t&pfs.Commit{},\r\n\t\tnil,\r\n\t\tnil,\r\n\t)\r\n}","code-length":99,"reference":"\/\/ OpenCommits returns a collection of open commits","result":"Create the collection.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDAG(nodes map[string][]string) *DAG {\r\n\tresult := &DAG{\r\n\t\tparents:  make(map[string][]string),\r\n\t\tchildren: make(map[string][]string),\r\n\t\tleaves:   make(map[string]bool),\r\n\t}\r\n\tfor id, parents := range nodes {\r\n\t\tresult.NewNode(id, parents)\r\n\t}\r\n\treturn result\r\n}","code-length":122,"reference":"\/\/ NewDAG creates a DAG and populates it with the given nodes.","result":"Create a new DAG.","score":[0.0432,0.1674]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DAG) NewNode(id string, parents []string) {\r\n\td.parents[id] = parents\r\n\tfor _, parentID := range parents {\r\n\t\td.children[parentID] = append(d.children[parentID], id)\r\n\t\td.leaves[parentID] = false\r\n\t}\r\n\tif _, ok := d.leaves[id]; !ok {\r\n\t\td.leaves[id] = true\r\n\t}\r\n}","code-length":129,"reference":"\/\/ NewNode adds a node to d.","result":"Create a new node in the DAG.","score":[0.1921,0.1429]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DAG) Sorted() []string {\r\n\tseen := make(map[string]bool)\r\n\tvar result []string\r\n\tfor id := range d.parents {\r\n\t\tresult = append(result, dfs(id, d.parents, seen)...)\r\n\t}\r\n\treturn result\r\n}","code-length":85,"reference":"\/\/ Sorted returns all nodes in a topologically sorted order","result":"Sort the DAG.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DAG) Leaves() []string {\r\n\tvar result []string\r\n\tfor id, isLeaf := range d.leaves {\r\n\t\t\r\n\t\tif isLeaf {\r\n\t\t\tresult = append(result, id)\r\n\t\t}\r\n\t}\r\n\treturn result\r\n}","code-length":82,"reference":"\/\/ Leaves returns a slice containing all leaves in d.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DAG) Ancestors(id string, from []string) []string {\r\n\tseen := make(map[string]bool)\r\n\tfor _, fromID := range from {\r\n\t\tseen[fromID] = true\r\n\t}\r\n\treturn dfs(id, d.parents, seen)\r\n}","code-length":86,"reference":"\/\/ Ancestors returns a slice containing all ancestors of a node, 'id',\n\/\/ in d which are a descendant of at least one of the nodes in 'from'.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DAG) Descendants(id string, to []string) []string {\r\n\tseen := make(map[string]bool)\r\n\tfor _, toID := range to {\r\n\t\tseen[toID] = true\r\n\t}\r\n\treturn bfs(id, d.children, seen)\r\n}","code-length":88,"reference":"\/\/ Descendants returns a slice containing all descendants of a node, 'id',\n\/\/ in d which are an ancestor of at least one of the nodes in 'to'.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DAG) Ghosts() []string {\r\n\tvar result []string\r\n\tfor id := range d.children {\r\n\t\tif _, ok := d.parents[id]; !ok {\r\n\t\t\tresult = append(result, id)\r\n\t\t}\r\n\t}\r\n\treturn result\r\n}","code-length":87,"reference":"\/\/ Ghosts returns nodes that were referenced as parents but never created.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPortForwarder(namespace string) (*PortForwarder, error) {\r\n\tif namespace == \"\" {\r\n\t\tnamespace = \"default\"\r\n\t}\r\n\trules := clientcmd.NewDefaultClientConfigLoadingRules()\r\n\toverrides := &clientcmd.ConfigOverrides{}\r\n\tkubeConfig := clientcmd.NewNonInteractiveDeferredLoadingClientConfig(rules, overrides)\r\n\tconfig, err := kubeConfig.ClientConfig()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tclient, err := kubernetes.NewForConfig(config)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tcore := client.CoreV1()\r\n\treturn &PortForwarder{\r\n\t\tcore:          core,\r\n\t\tclient:        core.RESTClient(),\r\n\t\tconfig:        config,\r\n\t\tnamespace:     namespace,\r\n\t\tlogger:        log.StandardLogger().Writer(),\r\n\t\tstopChansLock: &sync.Mutex{},\r\n\t\tstopChans:     []chan struct{}{},\r\n\t\tshutdown:      false,\r\n\t}, nil\r\n}","code-length":278,"reference":"\/\/ NewPortForwarder creates a new port forwarder","result":"Create a port.","score":[0.1076,0.2841]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *PortForwarder) Run(appName string, localPort, remotePort uint16) error {\r\n\tpodNameSelector := map[string]string{\r\n\t\t\"suite\": \"pachyderm\",\r\n\t\t\"app\":   appName,\r\n\t}\r\n\tpodList, err := f.core.Pods(f.namespace).List(metav1.ListOptions{\r\n\t\tLabelSelector: metav1.FormatLabelSelector(metav1.SetAsLabelSelector(podNameSelector)),\r\n\t\tTypeMeta: metav1.TypeMeta{\r\n\t\t\tKind:       \"ListOptions\",\r\n\t\t\tAPIVersion: \"v1\",\r\n\t\t},\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif len(podList.Items) == 0 {\r\n\t\treturn fmt.Errorf(\"No pods found for app %s\", appName)\r\n\t}\r\n\t\r\n\tpodName := podList.Items[rand.Intn(len(podList.Items))].Name\r\n\turl := f.client.Post().\r\n\t\tResource(\"pods\").\r\n\t\tNamespace(f.namespace).\r\n\t\tName(podName).\r\n\t\tSubResource(\"portforward\").\r\n\t\tURL()\r\n\ttransport, upgrader, err := spdy.RoundTripperFor(f.config)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdialer := spdy.NewDialer(upgrader, &http.Client{Transport: transport}, \"POST\", url)\r\n\tports := []string{fmt.Sprintf(\"%d:%d\", localPort, remotePort)}\r\n\treadyChan := make(chan struct{}, 1)\r\n\tstopChan := make(chan struct{}, 1)\r\n\t\r\n\t\r\n\tf.stopChansLock.Lock()\r\n\tif f.shutdown {\r\n\t\tf.stopChansLock.Unlock()\r\n\t\treturn fmt.Errorf(\"port forwarder is shutdown\")\r\n\t}\r\n\tf.stopChans = append(f.stopChans, stopChan)\r\n\tf.stopChansLock.Unlock()\r\n\tfw, err := portforward.New(dialer, ports, stopChan, readyChan, ioutil.Discard, f.logger)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terrChan := make(chan error, 1)\r\n\tgo func() { errChan <- fw.ForwardPorts() }()\r\n\tselect {\r\n\tcase err = <-errChan:\r\n\t\treturn fmt.Errorf(\"port forwarding failed: %v\", err)\r\n\tcase <-fw.Ready:\r\n\t\treturn nil\r\n\t}\r\n}","code-length":650,"reference":"\/\/ Run starts the port forwarder. Returns after initialization is begun,\n\/\/ returning any initialization errors.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *PortForwarder) RunForDaemon(localPort, remotePort uint16) error {\r\n\tif localPort == 0 {\r\n\t\tlocalPort = pachdLocalPort\r\n\t}\r\n\tif remotePort == 0 {\r\n\t\tremotePort = pachdRemotePort\r\n\t}\r\n\treturn f.Run(\"pachd\", localPort, remotePort)\r\n}","code-length":101,"reference":"\/\/ RunForDaemon creates a port forwarder for the pachd daemon.","result":"Forward ports to the daemon.","score":[0.1051,0.2105]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *PortForwarder) RunForSAMLACS(localPort uint16) error {\r\n\tif localPort == 0 {\r\n\t\tlocalPort = samlAcsLocalPort\r\n\t}\r\n\treturn f.Run(\"pachd\", localPort, 654)\r\n}","code-length":75,"reference":"\/\/ RunForSAMLACS creates a port forwarder for SAML ACS.","result":"Generate code for generated code.","score":[0.108,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *PortForwarder) RunForDashUI(localPort uint16) error {\r\n\tif localPort == 0 {\r\n\t\tlocalPort = dashUILocalPort\r\n\t}\r\n\treturn f.Run(\"dash\", localPort, 8080)\r\n}","code-length":71,"reference":"\/\/ RunForDashUI creates a port forwarder for the dash UI.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *PortForwarder) RunForDashWebSocket(localPort uint16) error {\r\n\tif localPort == 0 {\r\n\t\tlocalPort = dashWebSocketLocalPort\r\n\t}\r\n\treturn f.Run(\"dash\", localPort, 8081)\r\n}","code-length":72,"reference":"\/\/ RunForDashWebSocket creates a port forwarder for the dash websocket.","result":"Run the dash websocket.","score":[0.1468,0.3132]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *PortForwarder) RunForPFS(localPort uint16) error {\r\n\tif localPort == 0 {\r\n\t\tlocalPort = pfsLocalPort\r\n\t}\r\n\treturn f.Run(\"pachd\", localPort, 30652)\r\n}","code-length":74,"reference":"\/\/ RunForPFS creates a port forwarder for PFS over HTTP.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *PortForwarder) RunForS3Gateway(localPort uint16) error {\r\n\tif localPort == 0 {\r\n\t\tlocalPort = s3gatewayLocalPort\r\n\t}\r\n\treturn f.Run(\"pachd\", localPort, 600)\r\n}","code-length":74,"reference":"\/\/ RunForS3Gateway creates a port forwarder for the s3gateway.","result":"Generate code for generated code.","score":[0.108,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *PortForwarder) Lock() error {\r\n\tpidfile.SetPidfilePath(path.Join(os.Getenv(\"HOME\"), \".pachyderm\/port-forward.pid\"))\r\n\treturn pidfile.Write()\r\n}","code-length":67,"reference":"\/\/ Lock uses pidfiles to ensure that only one port forwarder is running across\n\/\/ one or more `pachctl` instances","result":"Lock the port.","score":[0.0014,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *PortForwarder) Close() {\r\n\tdefer f.logger.Close()\r\n\tf.stopChansLock.Lock()\r\n\tdefer f.stopChansLock.Unlock()\r\n\tif f.shutdown {\r\n\t\tpanic(\"port forwarder already shutdown\")\r\n\t}\r\n\tf.shutdown = true\r\n\tfor _, stopChan := range f.stopChans {\r\n\t\tclose(stopChan)\r\n\t}\r\n}","code-length":119,"reference":"\/\/ Close shuts down port forwarding.","result":"Close the port forwarder.","score":[0.2304,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Event) Unmarshal(key *string, val proto.Message) error {\r\n\tif err := CheckType(e.Template, val); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t*key = string(e.Key)\r\n\treturn proto.Unmarshal(e.Value, val)\r\n}","code-length":86,"reference":"\/\/ Unmarshal unmarshals the item in an event into a protobuf message.","result":"Unmarshal proto.","score":[0.0034,0.0455]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Event) UnmarshalPrev(key *string, val proto.Message) error {\r\n\tif err := CheckType(e.Template, val); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t*key = string(e.PrevKey)\r\n\treturn proto.Unmarshal(e.PrevValue, val)\r\n}","code-length":89,"reference":"\/\/ UnmarshalPrev unmarshals the prev item in an event into a protobuf\n\/\/ message.","result":"Unmarshal the previous value of an event.","score":[0.0707,0.1921]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MakeWatcher(eventCh chan *Event, done chan struct{}) Watcher {\r\n\treturn &watcher{\r\n\t\teventCh: eventCh,\r\n\t\tdone:    done,\r\n\t}\r\n}","code-length":59,"reference":"\/\/ MakeWatcher returns a Watcher that uses the given event channel and done\n\/\/ channel internally to deliver events and signal closure, respectively.","result":"Create a watcher .","score":[0.0028,0.0889]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CheckType(template proto.Message, val interface{}) error {\r\n\tif template != nil {\r\n\t\tvalType, templateType := reflect.TypeOf(val), reflect.TypeOf(template)\r\n\t\tif valType != templateType {\r\n\t\t\treturn fmt.Errorf(\"invalid type, got: %s, expected: %s\", valType, templateType)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":112,"reference":"\/\/ CheckType checks to make sure val has the same type as template, unless\n\/\/ template is nil in which case it always returns nil.","result":"Check the type of a proto message.","score":[0.0147,0.0647]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPool(kubeClient *kube.Clientset, namespace string, serviceName string, port int, queueSize int64, opts ...grpc.DialOption) (*Pool, error) {\r\n\tendpointsInterface := kubeClient.CoreV1().Endpoints(namespace)\r\n\twatch, err := endpointsInterface.Watch(metav1.ListOptions{\r\n\t\tLabelSelector: metav1.FormatLabelSelector(metav1.SetAsLabelSelector(\r\n\t\t\tmap[string]string{\"app\": serviceName},\r\n\t\t)),\r\n\t\tWatch: true,\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tpool := &Pool{\r\n\t\tport:           port,\r\n\t\tendpointsWatch: watch,\r\n\t\topts:           opts,\r\n\t\tdone:           make(chan struct{}),\r\n\t\tqueueSize:      queueSize,\r\n\t}\r\n\tpool.connsCond = sync.NewCond(&pool.connsLock)\r\n\tgo pool.watchEndpoints()\r\n\treturn pool, nil\r\n}","code-length":264,"reference":"\/\/ NewPool creates a new connection pool with connections to pods in the\n\/\/ given service.","result":"Create a new connection pool.","score":[0.0548,0.2664]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Pool) Do(ctx context.Context, f func(cc *grpc.ClientConn) error) error {\r\n\tvar conn *connCount\r\n\tif err := func() error {\r\n\t\tp.connsLock.Lock()\r\n\t\tdefer p.connsLock.Unlock()\r\n\t\tfor {\r\n\t\t\tfor addr, mapConn := range p.conns {\r\n\t\t\t\tif mapConn.cc == nil {\r\n\t\t\t\t\tcc, err := grpc.DialContext(ctx, addr, p.opts...)\r\n\t\t\t\t\tif err != nil {\r\n\t\t\t\t\t\treturn fmt.Errorf(\"failed to connect to %s: %+v\", addr, err)\r\n\t\t\t\t\t}\r\n\t\t\t\t\tmapConn.cc = cc\r\n\t\t\t\t\tconn = mapConn\r\n\t\t\t\t\t\r\n\t\t\t\t\t\r\n\t\t\t\t\tbreak\r\n\t\t\t\t} else {\r\n\t\t\t\t\tmapConnCount := atomic.LoadInt64(&mapConn.count)\r\n\t\t\t\t\tif mapConnCount < p.queueSize && (conn == nil || mapConnCount < atomic.LoadInt64(&conn.count)) {\r\n\t\t\t\t\t\tconn = mapConn\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tif conn == nil {\r\n\t\t\t\tp.connsCond.Wait()\r\n\t\t\t} else {\r\n\t\t\t\tatomic.AddInt64(&conn.count, 1)\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil\r\n\t}(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer p.connsCond.Broadcast()\r\n\tdefer atomic.AddInt64(&conn.count, -1)\r\n\treturn f(conn.cc)\r\n}","code-length":414,"reference":"\/\/ Do allows you to do something with a grpc.ClientConn.\n\/\/ Errors returned from f will be returned by Do.","result":"Connect to a server.","score":[0.007,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Pool) Close() error {\r\n\tclose(p.done)\r\n\tvar retErr error\r\n\tfor _, conn := range p.conns {\r\n\t\tif conn.cc != nil {\r\n\t\t\tif err := conn.cc.Close(); err != nil {\r\n\t\t\t\tretErr = err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn retErr\r\n}","code-length":108,"reference":"\/\/ Close closes all connections stored in the pool, it returns an error if any\n\/\/ of the calls to Close error.","result":"Close the pool.","score":[0.0009,0.0498]}
{"code":"\/*is used to<extra_id_0>\r\nfunc buildImage(client *docker.Client, repo string, contextDir string, dockerfile string, destTag string) error {\r\n\tdestImage := fmt.Sprintf(\"%s:%s\", repo, destTag)\r\n\tfmt.Printf(\"Building %s, this may take a while.\\n\", destImage)\r\n\terr := client.BuildImage(docker.BuildImageOptions{\r\n\t\tName:         destImage,\r\n\t\tContextDir:   contextDir,\r\n\t\tDockerfile:   dockerfile,\r\n\t\tOutputStream: os.Stdout,\r\n\t})\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"could not build docker image: %s\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":180,"reference":"\/\/ buildImage builds a new docker image.","result":"Build a docker image.","score":[0.2362,0.5597]}
{"code":"\/*is used to<extra_id_0>\r\nfunc pushImage(client *docker.Client, authConfig docker.AuthConfiguration, repo string, sourceTag string, destTag string) (string, error) {\r\n\tsourceImage := fmt.Sprintf(\"%s:%s\", repo, sourceTag)\r\n\tdestImage := fmt.Sprintf(\"%s:%s\", repo, destTag)\r\n\tfmt.Printf(\"Tagging\/pushing %s, this may take a while.\\n\", destImage)\r\n\tif err := client.TagImage(sourceImage, docker.TagImageOptions{\r\n\t\tRepo:    repo,\r\n\t\tTag:     destTag,\r\n\t\tContext: context.Background(),\r\n\t}); err != nil {\r\n\t\terr = fmt.Errorf(\"could not tag docker image: %s\", err)\r\n\t\treturn \"\", err\r\n\t}\r\n\tif err := client.PushImage(\r\n\t\tdocker.PushImageOptions{\r\n\t\t\tName: repo,\r\n\t\t\tTag:  destTag,\r\n\t\t},\r\n\t\tauthConfig,\r\n\t); err != nil {\r\n\t\terr = fmt.Errorf(\"could not push docker image: %s\", err)\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn destImage, nil\r\n}","code-length":300,"reference":"\/\/ pushImage pushes a docker image.","result":"DestTag string.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newMinioClient(endpoint, bucket, id, secret string, secure bool) (*minioClient, error) {\r\n\tmclient, err := minio.New(endpoint, id, secret, secure)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &minioClient{\r\n\t\tbucket: bucket,\r\n\t\tClient: mclient,\r\n\t}, nil\r\n}","code-length":110,"reference":"\/\/ Creates a new minioClient structure and returns","result":"Create new client.","score":[0.0771,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newMinioClientV2(endpoint, bucket, id, secret string, secure bool) (*minioClient, error) {\r\n\tmclient, err := minio.NewV2(endpoint, id, secret, secure)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &minioClient{\r\n\t\tbucket: bucket,\r\n\t\tClient: mclient,\r\n\t}, nil\r\n}","code-length":114,"reference":"\/\/ Creates a new minioClient S3V2 structure and returns","result":"Create new client objects.","score":[0.0915,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newMinioWriter(ctx context.Context, client *minioClient, name string) *minioWriter {\r\n\treader, writer := io.Pipe()\r\n\tw := &minioWriter{\r\n\t\tctx:     ctx,\r\n\t\terrChan: make(chan error),\r\n\t\tpipe:    writer,\r\n\t}\r\n\tgo func() {\r\n\t\t_, err := client.PutObject(client.bucket, name, reader, \"application\/octet-stream\")\r\n\t\tif err != nil {\r\n\t\t\treader.CloseWithError(err)\r\n\t\t}\r\n\t\tw.errChan <- err\r\n\t}()\r\n\treturn w\r\n}","code-length":172,"reference":"\/\/ Creates a new minio writer and a go routine to upload objects to minio server","result":"Create a new minioWriter.","score":[0.0225,0.1014]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *minioWriter) Close() error {\r\n\tspan, _ := tracing.AddSpanToAnyExisting(w.ctx, \"minioWriter.Close\")\r\n\tdefer tracing.FinishAnySpan(span)\r\n\tif err := w.pipe.Close(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn <-w.errChan\r\n}","code-length":97,"reference":"\/\/ This will block till upload is done","result":"Close the writer.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PipelineRepo(pipeline *ppsclient.Pipeline) *pfs.Repo {\r\n\treturn &pfs.Repo{Name: pipeline.Name}\r\n}","code-length":46,"reference":"\/\/ PipelineRepo creates a pfs repo for a given pipeline.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PipelineRcName(name string, version uint64) string {\r\n\t\r\n\t\r\n\t\r\n\tname = strings.Replace(name, \"_\", \"-\", -1)\r\n\treturn fmt.Sprintf(\"pipeline-%s-v%d\", strings.ToLower(name), version)\r\n}","code-length":79,"reference":"\/\/ PipelineRcName generates the name of the k8s replication controller that\n\/\/ manages a pipeline's workers","result":"Generate the pipeline.","score":[0.0054,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetRequestsResourceListFromPipeline(pipelineInfo *pps.PipelineInfo) (*v1.ResourceList, error) {\r\n\treturn getResourceListFromSpec(pipelineInfo.ResourceRequests, pipelineInfo.CacheSize)\r\n}","code-length":60,"reference":"\/\/ GetRequestsResourceListFromPipeline returns a list of resources that the pipeline,\n\/\/ minimally requires.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetLimitsResourceListFromPipeline(pipelineInfo *pps.PipelineInfo) (*v1.ResourceList, error) {\r\n\treturn getResourceListFromSpec(pipelineInfo.ResourceLimits, pipelineInfo.CacheSize)\r\n}","code-length":60,"reference":"\/\/ GetLimitsResourceListFromPipeline returns a list of resources that the pipeline,\n\/\/ maximally is limited to.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getNumNodes(kubeClient *kube.Clientset) (int, error) {\r\n\tnodeList, err := kubeClient.CoreV1().Nodes().List(metav1.ListOptions{})\r\n\tif err != nil {\r\n\t\treturn 0, fmt.Errorf(\"unable to retrieve node list from k8s to determine parallelism: %v\", err)\r\n\t}\r\n\tif len(nodeList.Items) == 0 {\r\n\t\treturn 0, fmt.Errorf(\"pachyderm.pps.jobserver: no k8s nodes found\")\r\n\t}\r\n\treturn len(nodeList.Items), nil\r\n}","code-length":159,"reference":"\/\/ getNumNodes attempts to retrieve the number of nodes in the current k8s\n\/\/ cluster","result":"Determine the number of nodes in the cluster.","score":[0.2999,0.4186]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetExpectedNumWorkers(kubeClient *kube.Clientset, spec *ppsclient.ParallelismSpec) (int, error) {\r\n\tif spec == nil || (spec.Constant == 0 && spec.Coefficient == 0) {\r\n\t\treturn 1, nil\r\n\t} else if spec.Constant > 0 && spec.Coefficient == 0 {\r\n\t\treturn int(spec.Constant), nil\r\n\t} else if spec.Constant == 0 && spec.Coefficient > 0 {\r\n\t\t\r\n\t\tnumNodes, err := getNumNodes(kubeClient)\r\n\t\tif err != nil {\r\n\t\t\treturn 0, err\r\n\t\t}\r\n\t\tresult := math.Floor(spec.Coefficient * float64(numNodes))\r\n\t\treturn int(math.Max(result, 1)), nil\r\n\t}\r\n\treturn 0, fmt.Errorf(\"Unable to interpret ParallelismSpec %+v\", spec)\r\n}","code-length":230,"reference":"\/\/ GetExpectedNumWorkers computes the expected number of workers that\n\/\/ pachyderm will start given the ParallelismSpec 'spec'.\n\/\/\n\/\/ This is only exported for testing","result":"Determine the expected number of workers to use.","score":[0.069,0.2077]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetExpectedNumHashtrees(spec *ppsclient.HashtreeSpec) (int64, error) {\r\n\tif spec == nil || spec.Constant == 0 {\r\n\t\treturn 1, nil\r\n\t} else if spec.Constant > 0 {\r\n\t\treturn int64(spec.Constant), nil\r\n\t}\r\n\treturn 0, fmt.Errorf(\"unable to interpret HashtreeSpec %+v\", spec)\r\n}","code-length":112,"reference":"\/\/ GetExpectedNumHashtrees computes the expected number of hashtrees that\n\/\/ Pachyderm will create given the HashtreeSpec 'spec'.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FailPipeline(ctx context.Context, etcdClient *etcd.Client, pipelinesCollection col.Collection, pipelineName string, reason string) error {\r\n\t_, err := col.NewSTM(ctx, etcdClient, func(stm col.STM) error {\r\n\t\tpipelines := pipelinesCollection.ReadWrite(stm)\r\n\t\tpipelinePtr := new(pps.EtcdPipelineInfo)\r\n\t\tif err := pipelines.Get(pipelineName, pipelinePtr); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tpipelinePtr.State = pps.PipelineState_PIPELINE_FAILURE\r\n\t\tpipelinePtr.Reason = reason\r\n\t\tpipelines.Put(pipelineName, pipelinePtr)\r\n\t\treturn nil\r\n\t})\r\n\treturn err\r\n}","code-length":196,"reference":"\/\/ FailPipeline updates the pipeline's state to failed and sets the failure reason","result":"Fail a pipeline.","score":[0,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc JobInput(pipelineInfo *pps.PipelineInfo, outputCommitInfo *pfs.CommitInfo) *pps.Input {\r\n\t\r\n\tbranchToCommit := make(map[string]*pfs.Commit)\r\n\tkey := path.Join\r\n\tfor _, prov := range outputCommitInfo.Provenance {\r\n\t\tbranchToCommit[key(prov.Commit.Repo.Name, prov.Branch.Name)] = prov.Commit\r\n\t}\r\n\tjobInput := proto.Clone(pipelineInfo.Input).(*pps.Input)\r\n\tpps.VisitInput(jobInput, func(input *pps.Input) {\r\n\t\tif input.Pfs != nil {\r\n\t\t\tif commit, ok := branchToCommit[key(input.Pfs.Repo, input.Pfs.Branch)]; ok {\r\n\t\t\t\tinput.Pfs.Commit = commit.ID\r\n\t\t\t}\r\n\t\t}\r\n\t\tif input.Cron != nil {\r\n\t\t\tif commit, ok := branchToCommit[key(input.Cron.Repo, \"master\")]; ok {\r\n\t\t\t\tinput.Cron.Commit = commit.ID\r\n\t\t\t}\r\n\t\t}\r\n\t\tif input.Git != nil {\r\n\t\t\tif commit, ok := branchToCommit[key(input.Git.Name, input.Git.Branch)]; ok {\r\n\t\t\t\tinput.Git.Commit = commit.ID\r\n\t\t\t}\r\n\t\t}\r\n\t})\r\n\treturn jobInput\r\n}","code-length":364,"reference":"\/\/ JobInput fills in the commits for a JobInfo","result":"Generate the JobInput function.","score":[0.1088,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PipelineReqFromInfo(pipelineInfo *ppsclient.PipelineInfo) *ppsclient.CreatePipelineRequest {\r\n\treturn &ppsclient.CreatePipelineRequest{\r\n\t\tPipeline:           pipelineInfo.Pipeline,\r\n\t\tTransform:          pipelineInfo.Transform,\r\n\t\tParallelismSpec:    pipelineInfo.ParallelismSpec,\r\n\t\tHashtreeSpec:       pipelineInfo.HashtreeSpec,\r\n\t\tEgress:             pipelineInfo.Egress,\r\n\t\tOutputBranch:       pipelineInfo.OutputBranch,\r\n\t\tScaleDownThreshold: pipelineInfo.ScaleDownThreshold,\r\n\t\tResourceRequests:   pipelineInfo.ResourceRequests,\r\n\t\tResourceLimits:     pipelineInfo.ResourceLimits,\r\n\t\tInput:              pipelineInfo.Input,\r\n\t\tDescription:        pipelineInfo.Description,\r\n\t\tCacheSize:          pipelineInfo.CacheSize,\r\n\t\tEnableStats:        pipelineInfo.EnableStats,\r\n\t\tBatch:              pipelineInfo.Batch,\r\n\t\tMaxQueueSize:       pipelineInfo.MaxQueueSize,\r\n\t\tService:            pipelineInfo.Service,\r\n\t\tChunkSpec:          pipelineInfo.ChunkSpec,\r\n\t\tDatumTimeout:       pipelineInfo.DatumTimeout,\r\n\t\tJobTimeout:         pipelineInfo.JobTimeout,\r\n\t\tSalt:               pipelineInfo.Salt,\r\n\t}\r\n}","code-length":323,"reference":"\/\/ PipelineReqFromInfo converts a PipelineInfo into a CreatePipelineRequest.","result":"Create a pipeline request.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPipelineManifestReader(path string) (result *PipelineManifestReader, retErr error) {\r\n\tresult = &PipelineManifestReader{}\r\n\tvar pipelineReader io.Reader\r\n\tif path == \"-\" {\r\n\t\tpipelineReader = io.TeeReader(os.Stdin, &result.buf)\r\n\t\tfmt.Print(\"Reading from stdin.\\n\")\r\n\t} else if url, err := url.Parse(path); err == nil && url.Scheme != \"\" {\r\n\t\tresp, err := http.Get(url.String())\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tdefer func() {\r\n\t\t\tif err := resp.Body.Close(); err != nil && retErr == nil {\r\n\t\t\t\tretErr = err\r\n\t\t\t}\r\n\t\t}()\r\n\t\trawBytes, err := ioutil.ReadAll(resp.Body)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tpipelineReader = io.TeeReader(strings.NewReader(string(rawBytes)), &result.buf)\r\n\t} else {\r\n\t\trawBytes, err := ioutil.ReadFile(path)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tpipelineReader = io.TeeReader(strings.NewReader(string(rawBytes)), &result.buf)\r\n\t}\r\n\tresult.decoder = json.NewDecoder(pipelineReader)\r\n\treturn result, nil\r\n}","code-length":378,"reference":"\/\/ NewPipelineManifestReader creates a new manifest reader from a path.","result":"Create a pipeline manifest reader.","score":[0.1051,0.1579]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *PipelineManifestReader) NextCreatePipelineRequest() (*ppsclient.CreatePipelineRequest, error) {\r\n\tvar result ppsclient.CreatePipelineRequest\r\n\tif err := jsonpb.UnmarshalNext(r.decoder, &result); err != nil {\r\n\t\tif err == io.EOF {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn nil, fmt.Errorf(\"malformed pipeline spec: %s\", err)\r\n\t}\r\n\treturn &result, nil\r\n}","code-length":130,"reference":"\/\/ NextCreatePipelineRequest gets the next request from the manifest reader.","result":"Read the next create pipeline.","score":[0.125,0.1053]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DescribeSyntaxError(originalErr error, parsedBuffer bytes.Buffer) error {\r\n\tsErr, ok := originalErr.(*json.SyntaxError)\r\n\tif !ok {\r\n\t\treturn originalErr\r\n\t}\r\n\tbuffer := make([]byte, sErr.Offset)\r\n\tparsedBuffer.Read(buffer)\r\n\tlineOffset := strings.LastIndex(string(buffer[:len(buffer)-1]), \"\\n\")\r\n\tif lineOffset == -1 {\r\n\t\tlineOffset = 0\r\n\t}\r\n\tlines := strings.Split(string(buffer[:len(buffer)-1]), \"\\n\")\r\n\tlineNumber := len(lines)\r\n\tdescriptiveErrorString := fmt.Sprintf(\"Syntax Error on line %v:\\n%v\\n%v^\\n%v\\n\",\r\n\t\tlineNumber,\r\n\t\tstring(buffer[lineOffset:]),\r\n\t\tstrings.Repeat(\" \", int(sErr.Offset)-2-lineOffset),\r\n\t\toriginalErr,\r\n\t)\r\n\treturn errors.New(descriptiveErrorString)\r\n}","code-length":265,"reference":"\/\/ DescribeSyntaxError describes a syntax error encountered parsing json.","result":"Describe syntax errors.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UpdateJobState(pipelines col.ReadWriteCollection, jobs col.ReadWriteCollection, jobPtr *pps.EtcdJobInfo, state pps.JobState, reason string) error {\r\n\t\r\n\tpipelinePtr := &pps.EtcdPipelineInfo{}\r\n\tif err := pipelines.Get(jobPtr.Pipeline.Name, pipelinePtr); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif pipelinePtr.JobCounts == nil {\r\n\t\tpipelinePtr.JobCounts = make(map[int32]int32)\r\n\t}\r\n\tif pipelinePtr.JobCounts[int32(jobPtr.State)] != 0 {\r\n\t\tpipelinePtr.JobCounts[int32(jobPtr.State)]--\r\n\t}\r\n\tpipelinePtr.JobCounts[int32(state)]++\r\n\tpipelinePtr.LastJobState = state\r\n\tif err := pipelines.Put(jobPtr.Pipeline.Name, pipelinePtr); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tvar err error\r\n\tif state == pps.JobState_JOB_STARTING {\r\n\t\tjobPtr.Started, err = types.TimestampProto(time.Now())\r\n\t} else if IsTerminal(state) {\r\n\t\tjobPtr.Finished, err = types.TimestampProto(time.Now())\r\n\t}\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tjobPtr.State = state\r\n\tjobPtr.Reason = reason\r\n\treturn jobs.Put(jobPtr.Job.ID, jobPtr)\r\n}","code-length":382,"reference":"\/\/ UpdateJobState performs the operations involved with a job state transition.","result":"Update the job state in the database.","score":[0.1427,0.2411]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New() string {\r\n\tvar result string\r\n\tbackoff.RetryNotify(func() error {\r\n\t\tuuid, err := uuid.NewV4()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tresult = uuid.String()\r\n\t\treturn nil\r\n\t}, backoff.NewInfiniteBackOff(), func(err error, d time.Duration) error {\r\n\t\tfmt.Printf(\"error from uuid.NewV4: %v\", err)\r\n\t\treturn nil\r\n\t})\r\n\treturn result\r\n}","code-length":146,"reference":"\/\/ New returns a new uuid.","result":"Generate a new UUID.","score":[0.274,0.5077]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *HTTPError) Code() int {\r\n\tif h == nil {\r\n\t\treturn http.StatusOK\r\n\t}\r\n\treturn h.code\r\n}","code-length":51,"reference":"\/\/ Code returns the HTTP error code associated with 'h'","result":"Generate code from a file.","score":[0.0884,0.0526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewHTTPError(code int, formatStr string, args ...interface{}) *HTTPError {\r\n\treturn &HTTPError{\r\n\t\tcode: code,\r\n\t\terr:  fmt.Sprintf(formatStr, args...),\r\n\t}\r\n}","code-length":71,"reference":"\/\/ NewHTTPError returns a new HTTPError where the HTTP error code is 'code' and\n\/\/ the error message is based on 'formatStr' and 'args'","result":"Create a new error object.","score":[0.0084,0.1156]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewStorage(objC obj.Client, prefix string) *Storage {\r\n\treturn &Storage{\r\n\t\tobjC:   objC,\r\n\t\tprefix: prefix,\r\n\t}\r\n}","code-length":58,"reference":"\/\/ NewStorage creates a new Storage.","result":"Create a new object.","score":[0.274,0.5077]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) DeleteAll(ctx context.Context) error {\r\n\treturn s.objC.Walk(ctx, s.prefix, func(hash string) error {\r\n\t\treturn s.objC.Delete(ctx, hash)\r\n\t})\r\n}","code-length":72,"reference":"\/\/ DeleteAll deletes all of the chunks in object storage.","result":"Delete all objects.","score":[0.0396,0.2016]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Chunk(data []byte, chunkSize int) [][]byte {\r\n\tvar result [][]byte\r\n\tfor i := 0; i < len(data); i += chunkSize {\r\n\t\tend := i + chunkSize\r\n\t\tif end > len(data) {\r\n\t\t\tend = len(data)\r\n\t\t}\r\n\t\tresult = append(result, data[i:end])\r\n\t}\r\n\treturn result\r\n}","code-length":113,"reference":"\/\/ Chunk splits a piece of data up, this is useful for splitting up data that's\n\/\/ bigger than MaxMsgSize","result":"Create a chunk function.","score":[0.0059,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ChunkReader(r io.Reader, f func([]byte) error) (int, error) {\r\n\tvar total int\r\n\tbuf := GetBuffer()\r\n\tdefer PutBuffer(buf)\r\n\tfor {\r\n\t\tn, err := r.Read(buf)\r\n\t\tif n == 0 && err != nil {\r\n\t\t\tif err == io.EOF {\r\n\t\t\t\treturn total, nil\r\n\t\t\t}\r\n\t\t\treturn total, err\r\n\t\t}\r\n\t\tif err := f(buf[:n]); err != nil {\r\n\t\t\treturn total, err\r\n\t\t}\r\n\t\ttotal += n\r\n\t}\r\n}","code-length":168,"reference":"\/\/ ChunkReader splits a reader into reasonably sized chunks for the purpose\n\/\/ of transmitting the chunks over gRPC. For each chunk, it calls the given\n\/\/ function.","result":"Read a chunk of data.","score":[0.0029,0.0584]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewStreamingBytesReader(streamingBytesClient StreamingBytesClient, cancel context.CancelFunc) io.ReadCloser {\r\n\treturn &streamingBytesReader{streamingBytesClient: streamingBytesClient, cancel: cancel}\r\n}","code-length":60,"reference":"\/\/ NewStreamingBytesReader returns an io.Reader for a StreamingBytesClient.","result":"StreamingBytesClient.","score":[0.0005,0.0685]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WriteToStreamingBytesServer(reader io.Reader, streamingBytesServer StreamingBytesServer) error {\r\n\tbuf := GetBuffer()\r\n\tdefer PutBuffer(buf)\r\n\t_, err := io.CopyBuffer(NewStreamingBytesWriter(streamingBytesServer), ReaderWrapper{reader}, buf)\r\n\treturn err\r\n}","code-length":83,"reference":"\/\/ WriteToStreamingBytesServer writes the data from the io.Reader to the StreamingBytesServer.","result":"Invoke the streaming bytes.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WriteFromStreamingBytesClient(streamingBytesClient StreamingBytesClient, writer io.Writer) error {\r\n\tfor bytesValue, err := streamingBytesClient.Recv(); err != io.EOF; bytesValue, err = streamingBytesClient.Recv() {\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif _, err = writer.Write(bytesValue.Value); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":129,"reference":"\/\/ WriteFromStreamingBytesClient writes from the StreamingBytesClient to the io.Writer.","result":"Write to a writer.","score":[0.0915,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSidecarAPIServer(\r\n\tenv *serviceenv.ServiceEnv,\r\n\tetcdPrefix string,\r\n\tiamRole string,\r\n\treporter *metrics.Reporter,\r\n\tworkerGrpcPort uint16,\r\n\tpprofPort uint16,\r\n\thttpPort uint16,\r\n\tpeerPort uint16,\r\n) (ppsclient.APIServer, error) {\r\n\tapiServer := &apiServer{\r\n\t\tLogger:         log.NewLogger(\"pps.API\"),\r\n\t\tenv:            env,\r\n\t\tetcdPrefix:     etcdPrefix,\r\n\t\tiamRole:        iamRole,\r\n\t\treporter:       reporter,\r\n\t\tworkerUsesRoot: true,\r\n\t\tpipelines:      ppsdb.Pipelines(env.GetEtcdClient(), etcdPrefix),\r\n\t\tjobs:           ppsdb.Jobs(env.GetEtcdClient(), etcdPrefix),\r\n\t\tworkerGrpcPort: workerGrpcPort,\r\n\t\tpprofPort:      pprofPort,\r\n\t\thttpPort:       httpPort,\r\n\t\tpeerPort:       peerPort,\r\n\t}\r\n\treturn apiServer, nil\r\n}","code-length":289,"reference":"\/\/ NewSidecarAPIServer creates an APIServer that has limited functionalities\n\/\/ and is meant to be run as a worker sidecar.  It cannot, for instance,\n\/\/ create pipelines.","result":"Create a new sidecar server.","score":[0.003,0.0403]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewEnterpriseServer(env *serviceenv.ServiceEnv, etcdPrefix string) (ec.APIServer, error) {\r\n\ts := &apiServer{\r\n\t\tpachLogger: log.NewLogger(\"enterprise.API\"),\r\n\t\tenv:        env,\r\n\t\tenterpriseToken: col.NewCollection(\r\n\t\t\tenv.GetEtcdClient(),\r\n\t\t\tetcdPrefix,\r\n\t\t\tnil,\r\n\t\t\t&ec.EnterpriseRecord{},\r\n\t\t\tnil,\r\n\t\t\tnil,\r\n\t\t),\r\n\t}\r\n\ts.enterpriseExpiration.Store(time.Time{})\r\n\tgo s.watchEnterpriseToken(etcdPrefix)\r\n\treturn s, nil\r\n}","code-length":180,"reference":"\/\/ NewEnterpriseServer returns an implementation of ec.APIServer.","result":"Create the enterprise token collection.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc validateActivationCode(code string) (expiration time.Time, err error) {\r\n\t\r\n\t\r\n\tblock, _ := pem.Decode([]byte(publicKey))\r\n\tif block == nil {\r\n\t\treturn time.Time{}, fmt.Errorf(\"failed to pem decode public key\")\r\n\t}\r\n\tpub, err := x509.ParsePKIXPublicKey(block.Bytes)\r\n\tif err != nil {\r\n\t\treturn time.Time{}, fmt.Errorf(\"failed to parse DER encoded public key: %s\", err.Error())\r\n\t}\r\n\trsaPub, ok := pub.(*rsa.PublicKey)\r\n\tif !ok {\r\n\t\treturn time.Time{}, fmt.Errorf(\"public key isn't an RSA key\")\r\n\t}\r\n\t\r\n\tdecodedActivationCode, err := base64.StdEncoding.DecodeString(code)\r\n\tif err != nil {\r\n\t\treturn time.Time{}, fmt.Errorf(\"activation code is not base64 encoded\")\r\n\t}\r\n\tactivationCode := &activationCode{}\r\n\tif err := json.Unmarshal(decodedActivationCode, &activationCode); err != nil {\r\n\t\treturn time.Time{}, fmt.Errorf(\"activation code is not valid JSON\")\r\n\t}\r\n\t\r\n\tdecodedSignature, err := base64.StdEncoding.DecodeString(activationCode.Signature)\r\n\tif err != nil {\r\n\t\treturn time.Time{}, fmt.Errorf(\"signature is not base64 encoded\")\r\n\t}\r\n\t\r\n\thashedToken := sha256.Sum256([]byte(activationCode.Token))\r\n\t\r\n\tif err := rsa.VerifyPKCS1v15(rsaPub, crypto.SHA256, hashedToken[:], decodedSignature); err != nil {\r\n\t\treturn time.Time{}, fmt.Errorf(\"invalid signature in activation code\")\r\n\t}\r\n\t\r\n\ttoken := token{}\r\n\tif err := json.Unmarshal([]byte(activationCode.Token), &token); err != nil {\r\n\t\treturn time.Time{}, fmt.Errorf(\"token is not valid JSON\")\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\texpiration, err = time.Parse(time.RFC3339, token.Expiry)\r\n\tif err != nil {\r\n\t\treturn time.Time{}, fmt.Errorf(\"expiration is not valid ISO 8601 string\")\r\n\t}\r\n\t\r\n\tif time.Now().After(expiration) {\r\n\t\treturn time.Time{}, fmt.Errorf(\"the activation code has expired\")\r\n\t}\r\n\treturn expiration, nil\r\n}","code-length":622,"reference":"\/\/ validateActivationCode checks the validity of an activation code","result":"Code too long,keep in 512.","score":[0,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *apiServer) Activate(ctx context.Context, req *ec.ActivateRequest) (resp *ec.ActivateResponse, retErr error) {\r\n\ta.LogReq(req)\r\n\tdefer func(start time.Time) { a.pachLogger.Log(req, resp, retErr, time.Since(start)) }(time.Now())\r\n\t\r\n\texpiration, err := validateActivationCode(req.ActivationCode)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error validating activation code: %s\", err.Error())\r\n\t}\r\n\t\r\n\tif req.Expires != nil {\r\n\t\tcustomExpiration, err := types.TimestampFromProto(req.Expires)\r\n\t\tif err == nil && expiration.After(customExpiration) {\r\n\t\t\texpiration = customExpiration\r\n\t\t}\r\n\t}\r\n\texpirationProto, err := types.TimestampProto(expiration)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"could not convert expiration time \\\"%s\\\" to proto: %s\", expiration.String(), err.Error())\r\n\t}\r\n\tif _, err := col.NewSTM(ctx, a.env.GetEtcdClient(), func(stm col.STM) error {\r\n\t\te := a.enterpriseToken.ReadWrite(stm)\r\n\t\t\r\n\t\treturn e.Put(enterpriseTokenKey, &ec.EnterpriseRecord{\r\n\t\t\tActivationCode: req.ActivationCode,\r\n\t\t\tExpires:        expirationProto,\r\n\t\t})\r\n\t}); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tif err := backoff.Retry(func() error {\r\n\t\tif t := a.enterpriseExpiration.Load().(time.Time); t.IsZero() {\r\n\t\t\treturn fmt.Errorf(\"enterprise not activated\")\r\n\t\t}\r\n\t\treturn nil\r\n\t}, backoff.RetryEvery(time.Second)); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\ttime.Sleep(time.Second)\r\n\treturn &ec.ActivateResponse{\r\n\t\tInfo: &ec.TokenInfo{\r\n\t\t\tExpires: expirationProto,\r\n\t\t},\r\n\t}, nil\r\n}","code-length":547,"reference":"\/\/ Activate implements the Activate RPC","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *apiServer) Deactivate(ctx context.Context, req *ec.DeactivateRequest) (resp *ec.DeactivateResponse, retErr error) {\r\n\ta.LogReq(req)\r\n\tdefer func(start time.Time) { a.pachLogger.Log(req, resp, retErr, time.Since(start)) }(time.Now())\r\n\tpachClient := a.env.GetPachClient(ctx)\r\n\tif err := pachClient.DeleteAll(); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"could not delete all pachyderm data: %v\", err)\r\n\t}\r\n\tif _, err := col.NewSTM(ctx, a.env.GetEtcdClient(), func(stm col.STM) error {\r\n\t\t\r\n\t\treturn a.enterpriseToken.ReadWrite(stm).Delete(enterpriseTokenKey)\r\n\t}); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tif err := backoff.Retry(func() error {\r\n\t\tif t := a.enterpriseExpiration.Load().(time.Time); !t.IsZero() {\r\n\t\t\treturn fmt.Errorf(\"enterprise still activated\")\r\n\t\t}\r\n\t\treturn nil\r\n\t}, backoff.RetryEvery(time.Second)); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\ttime.Sleep(time.Second)\r\n\treturn &ec.DeactivateResponse{}, nil\r\n}","code-length":368,"reference":"\/\/ Deactivate deletes the current cluster's enterprise token, and puts the\n\/\/ cluster in the \"NONE\" enterprise state. It also deletes all data in the\n\/\/ cluster, to avoid invalid cluster states. This call only makes sense for\n\/\/ testing","result":"Avoid the need for the following code.","score":[0.0019,0.0545]}
{"code":"\/*is used to<extra_id_0>\r\nfunc lookExtensions(path, dir string) (string, error) {\r\n\tif filepath.Base(path) == path {\r\n\t\tpath = filepath.Join(\".\", path)\r\n\t}\r\n\tif dir == \"\" {\r\n\t\treturn exec.LookPath(path)\r\n\t}\r\n\tif filepath.VolumeName(path) != \"\" {\r\n\t\treturn exec.LookPath(path)\r\n\t}\r\n\tif len(path) > 1 && os.IsPathSeparator(path[0]) {\r\n\t\treturn exec.LookPath(path)\r\n\t}\r\n\tdirandpath := filepath.Join(dir, path)\r\n\t\r\n\tlp, err := exec.LookPath(dirandpath)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\text := strings.TrimPrefix(lp, dirandpath)\r\n\treturn path + ext, nil\r\n}","code-length":228,"reference":"\/\/ lookExtensions finds windows executable by its dir and path.\n\/\/ It uses LookPath to try appropriate extensions.\n\/\/ lookExtensions does not search PATH, instead it converts `prog` into `.\\prog`.","result":"Find the file extensions.","score":[0.0005,0.0365]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cmd) Start() error {\r\n\tif c.lookPathErr != nil {\r\n\t\tc.closeDescriptors(c.closeAfterStart)\r\n\t\tc.closeDescriptors(c.closeAfterWait)\r\n\t\treturn c.lookPathErr\r\n\t}\r\n\tif runtime.GOOS == \"windows\" {\r\n\t\tlp, err := lookExtensions(c.Path, c.Dir)\r\n\t\tif err != nil {\r\n\t\t\tc.closeDescriptors(c.closeAfterStart)\r\n\t\t\tc.closeDescriptors(c.closeAfterWait)\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tc.Path = lp\r\n\t}\r\n\tif c.Process != nil {\r\n\t\treturn errors.New(\"exec: already started\")\r\n\t}\r\n\tif c.ctx != nil {\r\n\t\tselect {\r\n\t\tcase <-c.ctx.Done():\r\n\t\t\tc.closeDescriptors(c.closeAfterStart)\r\n\t\t\tc.closeDescriptors(c.closeAfterWait)\r\n\t\t\treturn c.ctx.Err()\r\n\t\tdefault:\r\n\t\t}\r\n\t}\r\n\ttype F func(*Cmd) (*os.File, error)\r\n\tfor _, setupFd := range []F{(*Cmd).stdin, (*Cmd).stdout, (*Cmd).stderr} {\r\n\t\tfd, err := setupFd(c)\r\n\t\tif err != nil {\r\n\t\t\tc.closeDescriptors(c.closeAfterStart)\r\n\t\t\tc.closeDescriptors(c.closeAfterWait)\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tc.childFiles = append(c.childFiles, fd)\r\n\t}\r\n\tc.childFiles = append(c.childFiles, c.ExtraFiles...)\r\n\tvar err error\r\n\tc.Process, err = os.StartProcess(c.Path, c.argv(), &os.ProcAttr{\r\n\t\tDir:   c.Dir,\r\n\t\tFiles: c.childFiles,\r\n\t\tEnv:   dedupEnv(c.envv()),\r\n\t\tSys:   c.SysProcAttr,\r\n\t})\r\n\tif err != nil {\r\n\t\tc.closeDescriptors(c.closeAfterStart)\r\n\t\tc.closeDescriptors(c.closeAfterWait)\r\n\t\treturn err\r\n\t}\r\n\tc.closeDescriptors(c.closeAfterStart)\r\n\tc.errch = make(chan error, len(c.goroutine))\r\n\tfor _, fn := range c.goroutine {\r\n\t\tgo func(fn func() error) {\r\n\t\t\tc.errch <- fn()\r\n\t\t}(fn)\r\n\t}\r\n\tif c.ctx != nil {\r\n\t\tc.waitDone = make(chan struct{})\r\n\t\tgo func() {\r\n\t\t\tselect {\r\n\t\t\tcase <-c.ctx.Done():\r\n\t\t\t\tc.Process.Kill()\r\n\t\t\tcase <-c.waitDone:\r\n\t\t\t}\r\n\t\t}()\r\n\t}\r\n\treturn nil\r\n}","code-length":751,"reference":"\/\/ Start starts the specified command but does not wait for it to complete.\n\/\/\n\/\/ The Wait method will return the exit code and release associated resources\n\/\/ once the command exits.","result":"Code too long,keep in 512.","score":[0,0.0166]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cmd) CombinedOutput() ([]byte, error) {\r\n\tif c.Stdout != nil {\r\n\t\treturn nil, errors.New(\"exec: Stdout already set\")\r\n\t}\r\n\tif c.Stderr != nil {\r\n\t\treturn nil, errors.New(\"exec: Stderr already set\")\r\n\t}\r\n\tvar b bytes.Buffer\r\n\tc.Stdout = &b\r\n\tc.Stderr = &b\r\n\terr := c.Run()\r\n\treturn b.Bytes(), err\r\n}","code-length":134,"reference":"\/\/ CombinedOutput runs the command and returns its combined standard\n\/\/ output and standard error.","result":"Get the combined output of the command.","score":[0.0678,0.1056]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cmd) StdinPipe() (io.WriteCloser, error) {\r\n\tif c.Stdin != nil {\r\n\t\treturn nil, errors.New(\"exec: Stdin already set\")\r\n\t}\r\n\tif c.Process != nil {\r\n\t\treturn nil, errors.New(\"exec: StdinPipe after process started\")\r\n\t}\r\n\tpr, pw, err := os.Pipe()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tc.Stdin = pr\r\n\tc.closeAfterStart = append(c.closeAfterStart, pr)\r\n\twc := &closeOnce{File: pw}\r\n\tc.closeAfterWait = append(c.closeAfterWait, closerFunc(wc.safeClose))\r\n\treturn wc, nil\r\n}","code-length":201,"reference":"\/\/ StdinPipe returns a pipe that will be connected to the command's\n\/\/ standard input when the command starts.\n\/\/ The pipe will be closed automatically after Wait sees the command exit.\n\/\/ A caller need only call Close to force the pipe to close sooner.\n\/\/ For example, if the command being run will not exit until standard input\n\/\/ is closed, the caller must close the pipe.","result":"Set the pipe to the process.","score":[0.0,0.0503]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cmd) StdoutPipe() (io.ReadCloser, error) {\r\n\tif c.Stdout != nil {\r\n\t\treturn nil, errors.New(\"exec: Stdout already set\")\r\n\t}\r\n\tif c.Process != nil {\r\n\t\treturn nil, errors.New(\"exec: StdoutPipe after process started\")\r\n\t}\r\n\tpr, pw, err := os.Pipe()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tc.Stdout = pw\r\n\tc.closeAfterStart = append(c.closeAfterStart, pw)\r\n\tc.closeAfterWait = append(c.closeAfterWait, pr)\r\n\treturn pr, nil\r\n}","code-length":180,"reference":"\/\/ StdoutPipe returns a pipe that will be connected to the command's\n\/\/ standard output when the command starts.\n\/\/\n\/\/ Wait will close the pipe after seeing the command exit, so most callers\n\/\/ need not close the pipe themselves; however, an implication is that\n\/\/ it is incorrect to call Wait before all reads from the pipe have completed.\n\/\/ For the same reason, it is incorrect to call Run when using StdoutPipe.\n\/\/ See the example for idiomatic usage.","result":"Create a new function to set the stdout of the command.","score":[0.0002,0.0334]}
{"code":"\/*is used to<extra_id_0>\r\nfunc dedupEnvCase(caseInsensitive bool, env []string) []string {\r\n\tout := make([]string, 0, len(env))\r\n\tsaw := map[string]int{}\r\n\tfor _, kv := range env {\r\n\t\teq := strings.Index(kv, \"=\")\r\n\t\tif eq < 0 {\r\n\t\t\tout = append(out, kv)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tk := kv[:eq]\r\n\t\tif caseInsensitive {\r\n\t\t\tk = strings.ToLower(k)\r\n\t\t}\r\n\t\tif dupIdx, isDup := saw[k]; isDup {\r\n\t\t\tout[dupIdx] = kv\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tsaw[k] = len(out)\r\n\t\tout = append(out, kv)\r\n\t}\r\n\treturn out\r\n}","code-length":222,"reference":"\/\/ dedupEnvCase is dedupEnv with a case option for testing.\n\/\/ If caseInsensitive is true, the case of keys is ignored.","result":"Dedupe env case.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc InputName(input *Input) string {\r\n\tswitch {\r\n\tcase input == nil:\r\n\t\treturn \"\"\r\n\tcase input.Pfs != nil:\r\n\t\treturn input.Pfs.Name\r\n\tcase input.Cross != nil:\r\n\t\tif len(input.Cross) > 0 {\r\n\t\t\treturn InputName(input.Cross[0])\r\n\t\t}\r\n\tcase input.Union != nil:\r\n\t\tif len(input.Union) > 0 {\r\n\t\t\treturn InputName(input.Union[0])\r\n\t\t}\r\n\t}\r\n\treturn \"\"\r\n}","code-length":158,"reference":"\/\/ InputName computes the name of an Input.","result":"Generate the name of the input.","score":[0.2849,0.4046]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SortInput(input *Input) {\r\n\tVisitInput(input, func(input *Input) {\r\n\t\tSortInputs := func(inputs []*Input) {\r\n\t\t\tsort.SliceStable(inputs, func(i, j int) bool { return InputName(inputs[i]) < InputName(inputs[j]) })\r\n\t\t}\r\n\t\tswitch {\r\n\t\tcase input.Cross != nil:\r\n\t\t\tSortInputs(input.Cross)\r\n\t\tcase input.Union != nil:\r\n\t\t\tSortInputs(input.Union)\r\n\t\t}\r\n\t})\r\n}","code-length":153,"reference":"\/\/ SortInput sorts an Input.","result":"Sort the inputs.","score":[0,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc InputBranches(input *Input) []*pfs.Branch {\r\n\tvar result []*pfs.Branch\r\n\tVisitInput(input, func(input *Input) {\r\n\t\tif input.Pfs != nil {\r\n\t\t\tresult = append(result, &pfs.Branch{\r\n\t\t\t\tRepo: &pfs.Repo{Name: input.Pfs.Repo},\r\n\t\t\t\tName: input.Pfs.Branch,\r\n\t\t\t})\r\n\t\t}\r\n\t\tif input.Cron != nil {\r\n\t\t\tresult = append(result, &pfs.Branch{\r\n\t\t\t\tRepo: &pfs.Repo{Name: input.Cron.Repo},\r\n\t\t\t\tName: \"master\",\r\n\t\t\t})\r\n\t\t}\r\n\t\tif input.Git != nil {\r\n\t\t\tresult = append(result, &pfs.Branch{\r\n\t\t\t\tRepo: &pfs.Repo{Name: input.Git.Name},\r\n\t\t\t\tName: input.Git.Branch,\r\n\t\t\t})\r\n\t\t}\r\n\t})\r\n\treturn result\r\n}","code-length":269,"reference":"\/\/ InputBranches returns the branches in an Input.","result":"Generate the input branches .","score":[0.1568,0.1299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ValidateGitCloneURL(url string) error {\r\n\texampleURL := \"https:\r\n\tif url == \"\" {\r\n\t\treturn fmt.Errorf(\"clone URL is missing (example clone URL %v)\", exampleURL)\r\n\t}\r\n\t\r\n\to := &git.CloneOptions{\r\n\t\tURL: url,\r\n\t}\r\n\tif err := o.Validate(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t\r\n\ts.HasSuffix(url, \".git\") {\r\n\t\t\r\n\t\treturn invalidErr\r\n\t}\r\n\tif !strings.HasPrefix(url, \"https:\r\n\t\t\r\n\t\treturn invalidErr\r\n\t}\r\n\treturn nil\r\n}","code-length":186,"reference":"\/\/ ValidateGitCloneURL returns an error if the provided URL is invalid","result":"Validate the git clone URL.","score":[0.0724,0.0481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc containsEmpty(vals []string) bool {\r\n\tfor _, val := range vals {\r\n\t\tif val == \"\" {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":62,"reference":"\/\/ containsEmpty is a helper function used for validation (particularly for\n\/\/ validating that creds arguments aren't empty","result":"Check if the values are empty .","score":[0.0336,0.0296]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewAPIServer(address string, storageRoot string, clusterInfo *admin.ClusterInfo) APIServer {\r\n\treturn &apiServer{\r\n\t\tLogger:      log.NewLogger(\"admin.API\"),\r\n\t\taddress:     address,\r\n\t\tstorageRoot: storageRoot,\r\n\t\tclusterInfo: clusterInfo,\r\n\t}\r\n}","code-length":92,"reference":"\/\/ NewAPIServer returns a new admin.APIServer","result":"Create a new API server.","score":[0.2782,0.3178]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Ago(timestamp *types.Timestamp) string {\r\n\tt, _ := types.TimestampFromProto(timestamp)\r\n\tif t.Equal(time.Time{}) {\r\n\t\treturn \"\"\r\n\t}\r\n\treturn fmt.Sprintf(\"%s ago\", units.HumanDuration(time.Since(t)))\r\n}","code-length":86,"reference":"\/\/ Ago pretty-prints the amount of time that has passed\n\/\/ since timestamp as a human-readable string.","result":"Generate the Ago function.","score":[0.0147,0.0637]}
{"code":"\/*is used to<extra_id_0>\r\nfunc TimeDifference(from *types.Timestamp, to *types.Timestamp) string {\r\n\ttFrom, _ := types.TimestampFromProto(from)\r\n\ttTo, _ := types.TimestampFromProto(to)\r\n\treturn units.HumanDuration(tTo.Sub(tFrom))\r\n}","code-length":79,"reference":"\/\/ TimeDifference pretty-prints the duration of time between from\n\/\/ and to as a human-reabable string.","result":"Generate the code.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Duration(d *types.Duration) string {\r\n\tduration, _ := types.DurationFromProto(d)\r\n\treturn units.HumanDuration(duration)\r\n}","code-length":49,"reference":"\/\/ Duration pretty prints a duration in a human readable way.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) InspectCluster() (*admin.ClusterInfo, error) {\r\n\tclusterInfo, err := c.AdminAPIClient.InspectCluster(c.Ctx(), &types.Empty{})\r\n\tif err != nil {\r\n\t\treturn nil, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\treturn clusterInfo, nil\r\n}","code-length":93,"reference":"\/\/ InspectCluster retrieves cluster state","result":"Get the cluster info.","score":[0.2488,0.102]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) Extract(objects bool, f func(op *admin.Op) error) error {\r\n\textractClient, err := c.AdminAPIClient.Extract(c.Ctx(), &admin.ExtractRequest{NoObjects: !objects})\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tfor {\r\n\t\top, err := extractClient.Recv()\r\n\t\tif err == io.EOF {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\t\tif err := f(op); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":195,"reference":"\/\/ Extract all cluster state, call f with each operation.","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) ExtractAll(objects bool) ([]*admin.Op, error) {\r\n\tvar result []*admin.Op\r\n\tif err := c.Extract(objects, func(op *admin.Op) error {\r\n\t\tresult = append(result, op)\r\n\t\treturn nil\r\n\t}); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn result, nil\r\n}","code-length":110,"reference":"\/\/ ExtractAll cluster state as a slice of operations.","result":"Extract all objects.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) ExtractWriter(objects bool, w io.Writer) error {\r\n\twriter := pbutil.NewWriter(w)\r\n\treturn c.Extract(objects, func(op *admin.Op) error {\r\n\t\t_, err := writer.Write(op)\r\n\t\treturn err\r\n\t})\r\n}","code-length":88,"reference":"\/\/ ExtractWriter extracts all cluster state and marshals it to w.","result":"Call the ExtractWriter function.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) ExtractURL(url string) error {\r\n\textractClient, err := c.AdminAPIClient.Extract(c.Ctx(), &admin.ExtractRequest{URL: url})\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tresp, err := extractClient.Recv()\r\n\tif err == nil {\r\n\t\treturn fmt.Errorf(\"unexpected response from extract: %v\", resp)\r\n\t}\r\n\tif err != io.EOF {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":149,"reference":"\/\/ ExtractURL extracts all cluster state and marshalls it to object storage.","result":"Call the Extract API.","score":[0,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) ExtractPipeline(pipelineName string) (*pps.CreatePipelineRequest, error) {\r\n\top, err := c.AdminAPIClient.ExtractPipeline(c.Ctx(), &admin.ExtractPipelineRequest{Pipeline: NewPipeline(pipelineName)})\r\n\tif err != nil {\r\n\t\treturn nil, grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tif op.Op1_9 == nil || op.Op1_9.Pipeline == nil {\r\n\t\treturn nil, fmt.Errorf(\"malformed response is missing pipeline\")\r\n\t}\r\n\treturn op.Op1_9.Pipeline, nil\r\n}","code-length":160,"reference":"\/\/ ExtractPipeline extracts a single pipeline.","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) Restore(ops []*admin.Op) (retErr error) {\r\n\trestoreClient, err := c.AdminAPIClient.Restore(c.Ctx())\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tdefer func() {\r\n\t\tif _, err := restoreClient.CloseAndRecv(); err != nil && retErr == nil {\r\n\t\t\tretErr = grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\t}()\r\n\tfor _, op := range ops {\r\n\t\tif err := restoreClient.Send(&admin.RestoreRequest{Op: op}); err != nil {\r\n\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":201,"reference":"\/\/ Restore cluster state from an extract series of operations.","result":"Restore a database.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) RestoreReader(r io.Reader) (retErr error) {\r\n\trestoreClient, err := c.AdminAPIClient.Restore(c.Ctx())\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tdefer func() {\r\n\t\tif _, err := restoreClient.CloseAndRecv(); err != nil && retErr == nil {\r\n\t\t\tretErr = grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\t}()\r\n\treader := pbutil.NewReader(r)\r\n\top := &admin.Op{}\r\n\tfor {\r\n\t\tif err := reader.Read(op); err != nil {\r\n\t\t\tif err == io.EOF {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif err := restoreClient.Send(&admin.RestoreRequest{Op: op}); err != nil {\r\n\t\t\treturn grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":266,"reference":"\/\/ RestoreReader restores cluster state from a reader containing marshaled ops.\n\/\/ Such as those written by ExtractWriter.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) RestoreFrom(objects bool, otherC *APIClient) (retErr error) {\r\n\trestoreClient, err := c.AdminAPIClient.Restore(c.Ctx())\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tdefer func() {\r\n\t\tif _, err := restoreClient.CloseAndRecv(); err != nil && retErr == nil {\r\n\t\t\tretErr = grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\t}()\r\n\treturn otherC.Extract(objects, func(op *admin.Op) error {\r\n\t\treturn restoreClient.Send(&admin.RestoreRequest{Op: op})\r\n\t})\r\n}","code-length":183,"reference":"\/\/ RestoreFrom restores state from another cluster which can be access through otherC.","result":"Restore from otherC.","score":[0.0173,0.125]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c APIClient) RestoreURL(url string) (retErr error) {\r\n\trestoreClient, err := c.AdminAPIClient.Restore(c.Ctx())\r\n\tif err != nil {\r\n\t\treturn grpcutil.ScrubGRPC(err)\r\n\t}\r\n\tdefer func() {\r\n\t\tif _, err := restoreClient.CloseAndRecv(); err != nil && retErr == nil {\r\n\t\t\tretErr = grpcutil.ScrubGRPC(err)\r\n\t\t}\r\n\t}()\r\n\treturn grpcutil.ScrubGRPC(restoreClient.Send(&admin.RestoreRequest{URL: url}))\r\n}","code-length":159,"reference":"\/\/ RestoreURL restures cluster state from object storage.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IgnoreTypes(typs ...interface{}) cmp.Option {\r\n\ttf := newTypeFilter(typs...)\r\n\treturn cmp.FilterPath(tf.filter, cmp.Ignore())\r\n}","code-length":54,"reference":"\/\/ IgnoreTypes returns an Option that ignores all values assignable to\n\/\/ certain types, which are specified by passing in a value of each type.","result":"Ignore types.","score":[0,0.022]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *textList) AppendEllipsis(ds diffStats) {\r\n\thasStats := ds != diffStats{}\r\n\tif len(*s) == 0 || !(*s)[len(*s)-1].Value.Equal(textEllipsis) {\r\n\t\tif hasStats {\r\n\t\t\t*s = append(*s, textRecord{Value: textEllipsis, Comment: ds})\r\n\t\t} else {\r\n\t\t\t*s = append(*s, textRecord{Value: textEllipsis})\r\n\t\t}\r\n\t\treturn\r\n\t}\r\n\tif hasStats {\r\n\t\t(*s)[len(*s)-1].Comment = (*s)[len(*s)-1].Comment.(diffStats).Append(ds)\r\n\t}\r\n}","code-length":188,"reference":"\/\/ AppendEllipsis appends a new ellipsis node to the list if none already\n\/\/ exists at the end. If cs is non-zero it coalesces the statistics with the\n\/\/ previous diffStats.","result":"Append ellipsis to a list of strings.","score":[0.0074,0.0874]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsType(t reflect.Type, ft funcType) bool {\r\n\tif t == nil || t.Kind() != reflect.Func || t.IsVariadic() {\r\n\t\treturn false\r\n\t}\r\n\tni, no := t.NumIn(), t.NumOut()\r\n\tswitch ft {\r\n\tcase tbFunc:\r\n\t\tif ni == 1 && no == 1 && t.Out(0) == boolType {\r\n\t\t\treturn true\r\n\t\t}\r\n\tcase ttbFunc:\r\n\t\tif ni == 2 && no == 1 && t.In(0) == t.In(1) && t.Out(0) == boolType {\r\n\t\t\treturn true\r\n\t\t}\r\n\tcase trbFunc:\r\n\t\tif ni == 2 && no == 1 && t.Out(0) == boolType {\r\n\t\t\treturn true\r\n\t\t}\r\n\tcase tibFunc:\r\n\t\tif ni == 2 && no == 1 && t.In(0).AssignableTo(t.In(1)) && t.Out(0) == boolType {\r\n\t\t\treturn true\r\n\t\t}\r\n\tcase trFunc:\r\n\t\tif ni == 1 && no == 1 {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":321,"reference":"\/\/ IsType reports whether the reflect.Type is of the specified function type.","result":"Check if a type is assignable to a type in the current context.","score":[0.0973,0.0826]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NameOf(v reflect.Value) string {\r\n\tfnc := runtime.FuncForPC(v.Pointer())\r\n\tif fnc == nil {\r\n\t\treturn \"<unknown>\"\r\n\t}\r\n\tfullName := fnc.Name()\r\n\t\r\n\tfullName = strings.TrimSuffix(fullName, \"-fm\")\r\n\tvar name string\r\n\tfor len(fullName) > 0 {\r\n\t\tinParen := strings.HasSuffix(fullName, \")\")\r\n\t\tfullName = strings.TrimSuffix(fullName, \")\")\r\n\t\ts := lastIdentRx.FindString(fullName)\r\n\t\tif s == \"\" {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tname = s + \".\" + name\r\n\t\tfullName = strings.TrimSuffix(fullName, s)\r\n\t\tif i := strings.LastIndexByte(fullName, '('); inParen && i >= 0 {\r\n\t\t\tfullName = fullName[:i]\r\n\t\t}\r\n\t\tfullName = strings.TrimSuffix(fullName, \".\")\r\n\t}\r\n\treturn strings.TrimSuffix(name, \".\")\r\n}","code-length":281,"reference":"\/\/ NameOf returns the name of the function value.","result":"Generate the name of the function .","score":[0.5051,0.5659]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PointerOf(v reflect.Value) Pointer {\r\n\t\r\n\t\r\n\treturn Pointer{unsafe.Pointer(v.Pointer()), v.Type()}\r\n}","code-length":49,"reference":"\/\/ PointerOf returns a Pointer from v, which must be a\n\/\/ reflect.Ptr, reflect.Slice, or reflect.Map.","result":"Create pointer.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (es EditScript) String() string {\r\n\tb := make([]byte, len(es))\r\n\tfor i, e := range es {\r\n\t\tswitch e {\r\n\t\tcase Identity:\r\n\t\t\tb[i] = '.'\r\n\t\tcase UniqueX:\r\n\t\t\tb[i] = 'X'\r\n\t\tcase UniqueY:\r\n\t\t\tb[i] = 'Y'\r\n\t\tcase Modified:\r\n\t\t\tb[i] = 'M'\r\n\t\tdefault:\r\n\t\t\tpanic(\"invalid edit-type\")\r\n\t\t}\r\n\t}\r\n\treturn string(b)\r\n}","code-length":165,"reference":"\/\/ String returns a human-readable string representing the edit-script where\n\/\/ Identity, UniqueX, UniqueY, and Modified are represented by the\n\/\/ '.', 'X', 'Y', and 'M' characters, respectively.","result":"Generate the string representation of the edit script.","score":[0.015,0.0577]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (es EditScript) stats() (s struct{ NI, NX, NY, NM int }) {\r\n\tfor _, e := range es {\r\n\t\tswitch e {\r\n\t\tcase Identity:\r\n\t\t\ts.NI++\r\n\t\tcase UniqueX:\r\n\t\t\ts.NX++\r\n\t\tcase UniqueY:\r\n\t\t\ts.NY++\r\n\t\tcase Modified:\r\n\t\t\ts.NM++\r\n\t\tdefault:\r\n\t\t\tpanic(\"invalid edit-type\")\r\n\t\t}\r\n\t}\r\n\treturn\r\n}","code-length":152,"reference":"\/\/ stats returns a histogram of the number of each type of edit operation.","result":"Calculate the edit script stats.","score":[0.0472,0.0763]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *path) connect(dst point, f EqualFunc) {\r\n\tif p.dir > 0 {\r\n\t\t\r\n\t\tfor dst.X > p.X && dst.Y > p.Y {\r\n\t\t\tswitch r := f(p.X, p.Y); {\r\n\t\t\tcase r.Equal():\r\n\t\t\t\tp.append(Identity)\r\n\t\t\tcase r.Similar():\r\n\t\t\t\tp.append(Modified)\r\n\t\t\tcase dst.X-p.X >= dst.Y-p.Y:\r\n\t\t\t\tp.append(UniqueX)\r\n\t\t\tdefault:\r\n\t\t\t\tp.append(UniqueY)\r\n\t\t\t}\r\n\t\t}\r\n\t\tfor dst.X > p.X {\r\n\t\t\tp.append(UniqueX)\r\n\t\t}\r\n\t\tfor dst.Y > p.Y {\r\n\t\t\tp.append(UniqueY)\r\n\t\t}\r\n\t} else {\r\n\t\t\r\n\t\tfor p.X > dst.X && p.Y > dst.Y {\r\n\t\t\tswitch r := f(p.X-1, p.Y-1); {\r\n\t\t\tcase r.Equal():\r\n\t\t\t\tp.append(Identity)\r\n\t\t\tcase r.Similar():\r\n\t\t\t\tp.append(Modified)\r\n\t\t\tcase p.Y-dst.Y >= p.X-dst.X:\r\n\t\t\t\tp.append(UniqueY)\r\n\t\t\tdefault:\r\n\t\t\t\tp.append(UniqueX)\r\n\t\t\t}\r\n\t\t}\r\n\t\tfor p.X > dst.X {\r\n\t\t\tp.append(UniqueX)\r\n\t\t}\r\n\t\tfor p.Y > dst.Y {\r\n\t\t\tp.append(UniqueY)\r\n\t\t}\r\n\t}\r\n}","code-length":446,"reference":"\/\/ connect appends any necessary Identity, Modified, UniqueX, or UniqueY types\n\/\/ to the edit-script to connect p.point to dst.","result":"Connect two points to a given point .","score":[0.031,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EquateNaNs() cmp.Option {\r\n\treturn cmp.Options{\r\n\t\tcmp.FilterValues(areNaNsF64s, cmp.Comparer(equateAlways)),\r\n\t\tcmp.FilterValues(areNaNsF32s, cmp.Comparer(equateAlways)),\r\n\t}\r\n}","code-length":86,"reference":"\/\/ EquateNaNs returns a Comparer option that determines float32 and float64\n\/\/ NaN values to be equal.\n\/\/\n\/\/ EquateNaNs can be used in conjunction with EquateApprox.","result":"Determine whether or not to use NaNs.","score":[0.0093,0.06]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa Path) Index(i int) PathStep {\r\n\tif i < 0 {\r\n\t\ti = len(pa) + i\r\n\t}\r\n\tif i < 0 || i >= len(pa) {\r\n\t\treturn pathStep{}\r\n\t}\r\n\treturn pa[i]\r\n}","code-length":84,"reference":"\/\/ Index returns the ith step in the Path and supports negative indexing.\n\/\/ A negative index starts counting from the tail of the Path such that -1\n\/\/ refers to the last step, -2 refers to the second-to-last step, and so on.\n\/\/ If index is invalid, this returns a non-nil PathStep that reports a nil Type.","result":"\treturn pa[i].","score":[0,0.0095]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (si SliceIndex) Key() int {\r\n\tif si.xkey != si.ykey {\r\n\t\treturn -1\r\n\t}\r\n\treturn si.xkey\r\n}","code-length":55,"reference":"\/\/ Key is the index key; it may return -1 if in a split state","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *defaultReporter) String() string {\r\n\tassert(r.root != nil && r.curr == nil)\r\n\tif r.root.NumDiff == 0 {\r\n\t\treturn \"\"\r\n\t}\r\n\treturn formatOptions{}.FormatDiff(r.root).String()\r\n}","code-length":79,"reference":"\/\/ String provides a full report of the differences detected as a structured\n\/\/ literal in pseudo-Go syntax. String may only be called after the entire tree\n\/\/ has been traversed.","result":"Generate the string representation of the reporter.","score":[0.0082,0.0874]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (opts formatOptions) FormatType(t reflect.Type, s textNode) textNode {\r\n\t\r\n\tswitch opts.TypeMode {\r\n\tcase autoType:\r\n\t\tswitch t.Kind() {\r\n\t\tcase reflect.Struct, reflect.Slice, reflect.Array, reflect.Map:\r\n\t\t\tif s.Equal(textNil) {\r\n\t\t\t\treturn s\r\n\t\t\t}\r\n\t\tdefault:\r\n\t\t\treturn s\r\n\t\t}\r\n\tcase elideType:\r\n\t\treturn s\r\n\t}\r\n\t\r\n\ttypeName := t.String()\r\n\tif t.Name() == \"\" {\r\n\t\t\r\n\t\t\r\n\t\tswitch t.Kind() {\r\n\t\tcase reflect.Chan, reflect.Func, reflect.Ptr:\r\n\t\t\ttypeName = \"(\" + typeName + \")\"\r\n\t\t}\r\n\t\ttypeName = strings.Replace(typeName, \"struct {\", \"struct{\", -1)\r\n\t\ttypeName = strings.Replace(typeName, \"interface {\", \"interface{\", -1)\r\n\t}\r\n\t\r\n\tif s, ok := s.(textWrap); ok {\r\n\t\thasParens := strings.HasPrefix(s.Prefix, \"(\") && strings.HasSuffix(s.Suffix, \")\")\r\n\t\thasBraces := strings.HasPrefix(s.Prefix, \"{\") && strings.HasSuffix(s.Suffix, \"}\")\r\n\t\tif hasParens || hasBraces {\r\n\t\t\treturn textWrap{typeName, s, \"\"}\r\n\t\t}\r\n\t}\r\n\treturn textWrap{typeName + \"(\", s, \")\"}\r\n}","code-length":406,"reference":"\/\/ FormatType prints the type as if it were wrapping s.\n\/\/ This may return s as-is depending on the current type and TypeMode mode.","result":"Format the type .","score":[0.0024,0.0437]}
{"code":"\/*is used to<extra_id_0>\r\nfunc formatMapKey(v reflect.Value) string {\r\n\tvar opts formatOptions\r\n\topts.TypeMode = elideType\r\n\topts.AvoidStringer = true\r\n\topts.ShallowPointers = true\r\n\ts := opts.FormatValue(v, visitedPointers{}).String()\r\n\treturn strings.TrimSpace(s)\r\n}","code-length":92,"reference":"\/\/ formatMapKey formats v as if it were a map key.\n\/\/ The result is guaranteed to be a single line.","result":"Format map keys.","score":[0.001,0.0521]}
{"code":"\/*is used to<extra_id_0>\r\nfunc formatString(s string) string {\r\n\t\r\n\t\r\n\tqs := strconv.Quote(s)\r\n\tif len(qs) == 1+len(s)+1 {\r\n\t\treturn qs\r\n\t}\r\n\t\r\n\t\r\n\trawInvalid := func(r rune) bool {\r\n\t\treturn r == '`' || r == '\\n' || !(unicode.IsPrint(r) || r == '\\t')\r\n\t}\r\n\tif strings.IndexFunc(s, rawInvalid) < 0 {\r\n\t\treturn \"`\" + s + \"`\"\r\n\t}\r\n\treturn qs\r\n}","code-length":155,"reference":"\/\/ formatString prints s as a double-quoted or backtick-quoted string.","result":"Format strings .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc formatHex(u uint64) string {\r\n\tvar f string\r\n\tswitch {\r\n\tcase u <= 0xff:\r\n\t\tf = \"0x%02x\"\r\n\tcase u <= 0xffff:\r\n\t\tf = \"0x%04x\"\r\n\tcase u <= 0xffffff:\r\n\t\tf = \"0x%06x\"\r\n\tcase u <= 0xffffffff:\r\n\t\tf = \"0x%08x\"\r\n\tcase u <= 0xffffffffff:\r\n\t\tf = \"0x%010x\"\r\n\tcase u <= 0xffffffffffff:\r\n\t\tf = \"0x%012x\"\r\n\tcase u <= 0xffffffffffffff:\r\n\t\tf = \"0x%014x\"\r\n\tcase u <= 0xffffffffffffffff:\r\n\t\tf = \"0x%016x\"\r\n\t}\r\n\treturn fmt.Sprintf(f, u)\r\n}","code-length":239,"reference":"\/\/ formatHex prints u as a hexadecimal integer in Go notation.","result":"Format hex strings .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc formatPointer(v reflect.Value) string {\r\n\tp := v.Pointer()\r\n\tif flags.Deterministic {\r\n\t\tp = 0xdeadf00f\r\n\t}\r\n\treturn fmt.Sprintf(\"\u27ea0x%x\u27eb\", p)\r\n}","code-length":79,"reference":"\/\/ formatPointer prints the address of the pointer.","result":"Format pointers in the generated code.","score":[0.1383,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m visitedPointers) Visit(v reflect.Value) bool {\r\n\tp := value.PointerOf(v)\r\n\t_, visited := m[p]\r\n\tm[p] = struct{}{}\r\n\treturn visited\r\n}","code-length":66,"reference":"\/\/ Visit inserts pointer v into the visited map and reports whether it had\n\/\/ already been visited before.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc retrieveUnexportedField(v reflect.Value, f reflect.StructField) reflect.Value {\r\n\treturn reflect.NewAt(f.Type, unsafe.Pointer(v.UnsafeAddr()+f.Offset)).Elem()\r\n}","code-length":64,"reference":"\/\/ retrieveUnexportedField uses unsafe to forcibly retrieve any field from\n\/\/ a struct such that the value has read-write permissions.\n\/\/\n\/\/ The parent struct, v, must be addressable, while f must be a StructField\n\/\/ describing the field to retrieve.","result":"Retrieve unexported fields.","score":[0,0.0134]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ft *fieldTree) insert(cname []string) {\r\n\tif ft.sub == nil {\r\n\t\tft.sub = make(map[string]fieldTree)\r\n\t}\r\n\tif len(cname) == 0 {\r\n\t\tft.ok = true\r\n\t\treturn\r\n\t}\r\n\tsub := ft.sub[cname[0]]\r\n\tsub.insert(cname[1:])\r\n\tft.sub[cname[0]] = sub\r\n}","code-length":129,"reference":"\/\/ insert inserts a sequence of field accesses into the tree.","result":"Insert fields in the tree.","score":[0.1023,0.3035]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ft fieldTree) matchPrefix(p cmp.Path) bool {\r\n\tfor _, ps := range p {\r\n\t\tswitch ps := ps.(type) {\r\n\t\tcase cmp.StructField:\r\n\t\t\tft = ft.sub[ps.Name()]\r\n\t\t\tif ft.ok {\r\n\t\t\t\treturn true\r\n\t\t\t}\r\n\t\t\tif len(ft.sub) == 0 {\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\tcase cmp.Indirect:\r\n\t\tdefault:\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":157,"reference":"\/\/ matchPrefix reports whether any selector in the fieldTree matches\n\/\/ the start of path p.","result":"Match the path.","score":[0.0054,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc canonicalName(t reflect.Type, sel string) ([]string, error) {\r\n\tvar name string\r\n\tsel = strings.TrimPrefix(sel, \".\")\r\n\tif sel == \"\" {\r\n\t\treturn nil, fmt.Errorf(\"name must not be empty\")\r\n\t}\r\n\tif i := strings.IndexByte(sel, '.'); i < 0 {\r\n\t\tname, sel = sel, \"\"\r\n\t} else {\r\n\t\tname, sel = sel[:i], sel[i:]\r\n\t}\r\n\t\r\n\tif t.Kind() == reflect.Ptr {\r\n\t\tt = t.Elem()\r\n\t}\r\n\tif t.Kind() != reflect.Struct {\r\n\t\treturn nil, fmt.Errorf(\"%v must be a struct\", t)\r\n\t}\r\n\t\r\n\t\r\n\tif !isExported(name) {\r\n\t\t\r\n\t\t\r\n\t\t, fmt.Errorf(\"name must be exported\")\r\n\t}\r\n\tsf, ok := t.FieldByName(name)\r\n\tif !ok {\r\n\t\treturn []string{name}, fmt.Errorf(\"does not exist\")\r\n\t}\r\n\tvar ss []string\r\n\tfor i := range sf.Index {\r\n\t\tss = append(ss, t.FieldByIndex(sf.Index[:i+1]).Name)\r\n\t}\r\n\tif sel == \"\" {\r\n\t\treturn ss, nil\r\n\t}\r\n\tssPost, err := canonicalName(sf.Type, sel)\r\n\treturn append(ss, ssPost...), err\r\n}","code-length":384,"reference":"\/\/ canonicalName returns a list of identifiers where any struct field access\n\/\/ through an embedded field is expanded to include the names of the embedded\n\/\/ types themselves.\n\/\/\n\/\/ For example, suppose field \"Foo\" is not directly in the parent struct,\n\/\/ but actually from an embedded struct of type \"Bar\". Then, the canonical name\n\/\/ of \"Foo\" is actually \"Bar.Foo\".\n\/\/\n\/\/ Suppose field \"Foo\" is not directly in the parent struct, but actually\n\/\/ a field in two different embedded structs of types \"Bar\" and \"Baz\".\n\/\/ Then the selector \"Foo\" causes a panic since it is ambiguous which one it\n\/\/ refers to. The user must specify either \"Bar.Foo\" or \"Baz.Foo\".","result":"Get the canonical name of a struct field.","score":[0.0,0.0405]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FilterPath(f func(Path) bool, opt Option) Option {\r\n\tif f == nil {\r\n\t\tpanic(\"invalid path filter function\")\r\n\t}\r\n\tif opt := normalizeOption(opt); opt != nil {\r\n\t\treturn &pathFilter{fnc: f, opt: opt}\r\n\t}\r\n\treturn nil\r\n}","code-length":94,"reference":"\/\/ FilterPath returns a new Option where opt is only evaluated if filter f\n\/\/ returns true for the current Path in the value tree.\n\/\/\n\/\/ This filter is called even if a slice element or map entry is missing and\n\/\/ provides an opportunity to ignore such cases. The filter function must be\n\/\/ symmetric such that the filter result is identical regardless of whether the\n\/\/ missing value is from x or y.\n\/\/\n\/\/ The option passed in may be an Ignore, Transformer, Comparer, Options, or\n\/\/ a previously filtered Option.","result":"Filter paths.","score":[0,0.0058]}
{"code":"\/*is used to<extra_id_0>\r\nfunc normalizeOption(src Option) Option {\r\n\tswitch opts := flattenOptions(nil, Options{src}); len(opts) {\r\n\tcase 0:\r\n\t\treturn nil\r\n\tcase 1:\r\n\t\treturn opts[0]\r\n\tdefault:\r\n\t\treturn opts\r\n\t}\r\n}","code-length":83,"reference":"\/\/ normalizeOption normalizes the input options such that all Options groups\n\/\/ are flattened and groups with a single element are reduced to that element.\n\/\/ Only coreOptions and Options containing coreOptions are allowed.","result":"Normalize option.","score":[0,0.0162]}
{"code":"\/*is used to<extra_id_0>\r\nfunc flattenOptions(dst, src Options) Options {\r\n\tfor _, opt := range src {\r\n\t\tswitch opt := opt.(type) {\r\n\t\tcase nil:\r\n\t\t\tcontinue\r\n\t\tcase Options:\r\n\t\t\tdst = flattenOptions(dst, opt)\r\n\t\tcase coreOption:\r\n\t\t\tdst = append(dst, opt)\r\n\t\tdefault:\r\n\t\t\tpanic(fmt.Sprintf(\"invalid option type: %T\", opt))\r\n\t\t}\r\n\t}\r\n\treturn dst\r\n}","code-length":140,"reference":"\/\/ flattenOptions copies all options in src to dst as a flat list.\n\/\/ Only coreOptions and Options containing coreOptions are allowed.","result":"Flatten nested options.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (opts formatOptions) CanFormatDiffSlice(v *valueNode) bool {\r\n\tswitch {\r\n\tcase opts.DiffMode != diffUnknown:\r\n\t\treturn false\r\n\tcase v.NumDiff == 0:\r\n\t\treturn false\r\n\tcase v.NumIgnored+v.NumCompared+v.NumTransformed > 0:\r\n\t\t\r\n\t\treturn false\r\n\tcase !v.ValueX.IsValid() || !v.ValueY.IsValid():\r\n\t\treturn false\r\n\t}\r\n\tswitch t := v.Type; t.Kind() {\r\n\tcase reflect.String:\r\n\tcase reflect.Array, reflect.Slice:\r\n\t\t\r\n\t\tswitch t.Elem().Kind() {\r\n\t\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64,\r\n\t\t\treflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64, reflect.Uintptr,\r\n\t\t\treflect.Bool, reflect.Float32, reflect.Float64, reflect.Complex64, reflect.Complex128:\r\n\t\tdefault:\r\n\t\t\treturn false\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tif v.NumDiff > v.NumSame {\r\n\t\t\treturn true\r\n\t\t}\r\n\tdefault:\r\n\t\treturn false\r\n\t}\r\n\t\r\n\tconst minLength = 64\r\n\treturn v.ValueX.Len() >= minLength && v.ValueY.Len() >= minLength\r\n}","code-length":372,"reference":"\/\/ CanFormatDiffSlice reports whether we support custom formatting for nodes\n\/\/ that are slices of primitive kinds or strings.","result":"Format diff slices.","score":[0,0.0287]}
{"code":"\/*is used to<extra_id_0>\r\nfunc formatASCII(s string) string {\r\n\tb := bytes.Repeat([]byte{'.'}, len(s))\r\n\tfor i := 0; i < len(s); i++ {\r\n\t\tif ' ' <= s[i] && s[i] <= '~' {\r\n\t\t\tb[i] = s[i]\r\n\t\t}\r\n\t}\r\n\treturn string(b)\r\n}","code-length":106,"reference":"\/\/ formatASCII formats s as an ASCII string.\n\/\/ This is useful for printing binary strings in a semi-legible way.","result":"Format ASCII strings.","score":[0.0014,0.0546]}
{"code":"\/*is used to<extra_id_0>\r\nfunc coalesceAdjacentEdits(name string, es diff.EditScript) (groups []diffStats) {\r\n\tvar prevCase int\r\n\tlastStats := func(i int) *diffStats {\r\n\t\tif prevCase != i {\r\n\t\t\tgroups = append(groups, diffStats{Name: name})\r\n\t\t\tprevCase = i\r\n\t\t}\r\n\t\treturn &groups[len(groups)-1]\r\n\t}\r\n\tfor _, e := range es {\r\n\t\tswitch e {\r\n\t\tcase diff.Identity:\r\n\t\t\tlastStats(1).NumIdentical++\r\n\t\tcase diff.UniqueX:\r\n\t\t\tlastStats(2).NumRemoved++\r\n\t\tcase diff.UniqueY:\r\n\t\t\tlastStats(2).NumInserted++\r\n\t\tcase diff.Modified:\r\n\t\t\tlastStats(2).NumModified++\r\n\t\t}\r\n\t}\r\n\treturn groups\r\n}","code-length":235,"reference":"\/\/ coalesceAdjacentEdits coalesces the list of edits into groups of adjacent\n\/\/ equal or unequal counts.","result":"Coalesce adjacent edits.","score":[0.0054,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SortKeys(vs []reflect.Value) []reflect.Value {\r\n\tif len(vs) == 0 {\r\n\t\treturn vs\r\n\t}\r\n\t\r\n\tsort.Slice(vs, func(i, j int) bool { return isLess(vs[i], vs[j]) })\r\n\t\r\n\tvs2 := vs[:1]\r\n\tfor _, v := range vs[1:] {\r\n\t\tif isLess(vs2[len(vs2)-1], v) {\r\n\t\t\tvs2 = append(vs2, v)\r\n\t\t}\r\n\t}\r\n\treturn vs2\r\n}","code-length":162,"reference":"\/\/ SortKeys sorts a list of map keys, deduplicating keys if necessary.\n\/\/ The type of each value must be comparable.","result":"Sort keys in the generated code.","score":[0.0158,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (opts formatOptions) FormatDiff(v *valueNode) textNode {\r\n\t\r\n\t\r\n\tif opts.CanFormatDiffSlice(v) {\r\n\t\treturn opts.FormatDiffSlice(v)\r\n\t}\r\n\t\r\n\tif v.MaxDepth == 0 {\r\n\t\tswitch opts.DiffMode {\r\n\t\tcase diffUnknown, diffIdentical:\r\n\t\t\t\r\n\t\t\tif v.NumDiff == 0 {\r\n\t\t\t\toutx := opts.FormatValue(v.ValueX, visitedPointers{})\r\n\t\t\t\touty := opts.FormatValue(v.ValueY, visitedPointers{})\r\n\t\t\t\tif v.NumIgnored > 0 && v.NumSame == 0 {\r\n\t\t\t\t\treturn textEllipsis\r\n\t\t\t\t} else if outx.Len() < outy.Len() {\r\n\t\t\t\t\treturn outx\r\n\t\t\t\t} else {\r\n\t\t\t\t\treturn outy\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tassert(opts.DiffMode == diffUnknown)\r\n\t\t\tvar list textList\r\n\t\t\toutx := opts.WithTypeMode(elideType).FormatValue(v.ValueX, visitedPointers{})\r\n\t\t\touty := opts.WithTypeMode(elideType).FormatValue(v.ValueY, visitedPointers{})\r\n\t\t\tif outx != nil {\r\n\t\t\t\tlist = append(list, textRecord{Diff: '-', Value: outx})\r\n\t\t\t}\r\n\t\t\tif outy != nil {\r\n\t\t\t\tlist = append(list, textRecord{Diff: '+', Value: outy})\r\n\t\t\t}\r\n\t\t\treturn opts.WithTypeMode(emitType).FormatType(v.Type, list)\r\n\t\tcase diffRemoved:\r\n\t\t\treturn opts.FormatValue(v.ValueX, visitedPointers{})\r\n\t\tcase diffInserted:\r\n\t\t\treturn opts.FormatValue(v.ValueY, visitedPointers{})\r\n\t\tdefault:\r\n\t\t\tpanic(\"invalid diff mode\")\r\n\t\t}\r\n\t}\r\n\t\r\n\tif v.TransformerName != \"\" {\r\n\t\tout := opts.WithTypeMode(emitType).FormatDiff(v.Value)\r\n\t\tout = textWrap{\"Inverse(\" + v.TransformerName + \", \", out, \")\"}\r\n\t\treturn opts.FormatType(v.Type, out)\r\n\t} else {\r\n\t\tswitch k := v.Type.Kind(); k {\r\n\t\tcase reflect.Struct, reflect.Array, reflect.Slice, reflect.Map:\r\n\t\t\treturn opts.FormatType(v.Type, opts.formatDiffList(v.Records, k))\r\n\t\tcase reflect.Ptr:\r\n\t\t\treturn textWrap{\"&\", opts.FormatDiff(v.Value), \"\"}\r\n\t\tcase reflect.Interface:\r\n\t\t\treturn opts.WithTypeMode(emitType).FormatDiff(v.Value)\r\n\t\tdefault:\r\n\t\t\tpanic(fmt.Sprintf(\"%v cannot have children\", k))\r\n\t\t}\r\n\t}\r\n}","code-length":733,"reference":"\/\/ FormatDiff converts a valueNode tree into a textNode tree, where the later\n\/\/ is a textual representation of the differences detected in the former.","result":"Code too long,keep in 512.","score":[0.0044,0.0217]}
{"code":"\/*is used to<extra_id_0>\r\nfunc coalesceAdjacentRecords(name string, recs []reportRecord) (groups []diffStats) {\r\n\tvar prevCase int\r\n\tlastStats := func(i int) *diffStats {\r\n\t\tif prevCase != i {\r\n\t\t\tgroups = append(groups, diffStats{Name: name})\r\n\t\t\tprevCase = i\r\n\t\t}\r\n\t\treturn &groups[len(groups)-1]\r\n\t}\r\n\tfor _, r := range recs {\r\n\t\tswitch rv := r.Value; {\r\n\t\tcase rv.NumIgnored > 0 && rv.NumSame+rv.NumDiff == 0:\r\n\t\t\tlastStats(1).NumIgnored++\r\n\t\tcase rv.NumDiff == 0:\r\n\t\t\tlastStats(1).NumIdentical++\r\n\t\tcase rv.NumDiff > 0 && !rv.ValueY.IsValid():\r\n\t\t\tlastStats(2).NumRemoved++\r\n\t\tcase rv.NumDiff > 0 && !rv.ValueX.IsValid():\r\n\t\t\tlastStats(2).NumInserted++\r\n\t\tdefault:\r\n\t\t\tlastStats(2).NumModified++\r\n\t\t}\r\n\t}\r\n\treturn groups\r\n}","code-length":294,"reference":"\/\/ coalesceAdjacentRecords coalesces the list of records into groups of\n\/\/ adjacent equal, or unequal counts.","result":"Coalesce adjacent records .","score":[0.0189,0.1014]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Diff(x, y interface{}, opts ...Option) string {\r\n\tr := new(defaultReporter)\r\n\teq := Equal(x, y, Options(opts), Reporter(r))\r\n\td := r.String()\r\n\tif (d == \"\") != eq {\r\n\t\tpanic(\"inconsistent difference and equality results\")\r\n\t}\r\n\treturn d\r\n}","code-length":100,"reference":"\/\/ Diff returns a human-readable report of the differences between two values.\n\/\/ It returns an empty string if and only if Equal returns true for the same\n\/\/ input values and options.\n\/\/\n\/\/ The output is displayed as a literal in pseudo-Go syntax.\n\/\/ At the start of each line, a \"-\" prefix indicates an element removed from x,\n\/\/ a \"+\" prefix to indicates an element added to y, and the lack of a prefix\n\/\/ indicates an element common to both x and y. If possible, the output\n\/\/ uses fmt.Stringer.String or error.Error methods to produce more humanly\n\/\/ readable outputs. In such cases, the string is prefixed with either an\n\/\/ 's' or 'e' character, respectively, to indicate that the method was called.\n\/\/\n\/\/ Do not depend on this output being stable. If you need the ability to\n\/\/ programmatically interpret the difference, consider using a custom Reporter.","result":"Compare two objects.","score":[5.642e-23,0.0036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *state) statelessCompare(step PathStep) diff.Result {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\toldResult, oldReporters := s.result, s.reporters\r\n\ts.result = diff.Result{}\r\n\ts.reporters = nil\r\n\ts.compareAny(step)\r\n\tres := s.result\r\n\ts.result, s.reporters = oldResult, oldReporters\r\n\treturn res\r\n}","code-length":126,"reference":"\/\/ statelessCompare compares two values and returns the result.\n\/\/ This function is stateless in that it does not alter the current result,\n\/\/ or output to any registered reporters.","result":"Compare stateless paths.","score":[0.0001,0.0366]}
{"code":"\/*is used to<extra_id_0>\r\nfunc sanitizeValue(v reflect.Value, t reflect.Type) reflect.Value {\r\n\t\r\n\t\tif v.Kind() == reflect.Interface && v.IsNil() && v.Type() != t {\r\n\t\t\treturn reflect.New(t).Elem()\r\n\t\t}\r\n\t}\r\n\treturn v\r\n}","code-length":87,"reference":"\/\/ sanitizeValue converts nil interfaces of type T to those of type R,\n\/\/ assuming that T is assignable to R.\n\/\/ Otherwise, it returns the input value as is.","result":"Sanitize the value.","score":[0.0001,0.0183]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rc *recChecker) Check(p Path) {\r\n\tconst minLen = 1 << 16\r\n\tif rc.next == 0 {\r\n\t\trc.next = minLen\r\n\t}\r\n\tif len(p) < rc.next {\r\n\t\treturn\r\n\t}\r\n\trc.next <<= 1\r\n\t\r\n\tvar ss []string\r\n\tm := map[Option]int{}\r\n\tfor _, ps := range p {\r\n\t\tif t, ok := ps.(Transform); ok {\r\n\t\t\tt := t.Option()\r\n\t\t\tif m[t] == 1 {\r\n\t\t\t\ttf := t.(*transformer).fnc.Type()\r\n\t\t\t\tss = append(ss, fmt.Sprintf(\"%v: %v => %v\", t, tf.In(0), tf.Out(0)))\r\n\t\t\t}\r\n\t\t\tm[t]++\r\n\t\t}\r\n\t}\r\n\tif len(ss) > 0 {\r\n\t\tconst warning = \"recursive set of Transformers detected\"\r\n\t\tconst help = \"consider using cmpopts.AcyclicTransformer\"\r\n\t\tset := strings.Join(ss, \"\\n\\t\")\r\n\t\tpanic(fmt.Sprintf(\"%s:\\n\\t%s\\n%s\", warning, set, help))\r\n\t}\r\n}","code-length":331,"reference":"\/\/ Check scans the Path for any recursive transformers and panics when any\n\/\/ recursive transformers are detected. Note that the presence of a\n\/\/ recursive Transformer does not necessarily imply an infinite cycle.\n\/\/ As such, this check only activates after some minimal number of path steps.","result":"Check recursive set of Transformers.","score":[0.0001,0.0343]}
{"code":"\/*is used to<extra_id_0>\r\nfunc makeAddressable(v reflect.Value) reflect.Value {\r\n\tif v.CanAddr() {\r\n\t\treturn v\r\n\t}\r\n\tvc := reflect.New(v.Type()).Elem()\r\n\tvc.Set(v)\r\n\treturn vc\r\n}","code-length":76,"reference":"\/\/ makeAddressable returns a value that is always addressable.\n\/\/ It returns the input verbatim if it is already addressable,\n\/\/ otherwise it creates a new value and returns an addressable copy.","result":"Make addressable values .","score":[0.0003,0.0342]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lf Field) Marshal(visitor Encoder) {\r\n\tswitch lf.fieldType {\r\n\tcase stringType:\r\n\t\tvisitor.EmitString(lf.key, lf.stringVal)\r\n\tcase boolType:\r\n\t\tvisitor.EmitBool(lf.key, lf.numericVal != 0)\r\n\tcase intType:\r\n\t\tvisitor.EmitInt(lf.key, int(lf.numericVal))\r\n\tcase int32Type:\r\n\t\tvisitor.EmitInt32(lf.key, int32(lf.numericVal))\r\n\tcase int64Type:\r\n\t\tvisitor.EmitInt64(lf.key, int64(lf.numericVal))\r\n\tcase uint32Type:\r\n\t\tvisitor.EmitUint32(lf.key, uint32(lf.numericVal))\r\n\tcase uint64Type:\r\n\t\tvisitor.EmitUint64(lf.key, uint64(lf.numericVal))\r\n\tcase float32Type:\r\n\t\tvisitor.EmitFloat32(lf.key, math.Float32frombits(uint32(lf.numericVal)))\r\n\tcase float64Type:\r\n\t\tvisitor.EmitFloat64(lf.key, math.Float64frombits(uint64(lf.numericVal)))\r\n\tcase errorType:\r\n\t\tif err, ok := lf.interfaceVal.(error); ok {\r\n\t\t\tvisitor.EmitString(lf.key, err.Error())\r\n\t\t} else {\r\n\t\t\tvisitor.EmitString(lf.key, \"<nil>\")\r\n\t\t}\r\n\tcase objectType:\r\n\t\tvisitor.EmitObject(lf.key, lf.interfaceVal)\r\n\tcase lazyLoggerType:\r\n\t\tvisitor.EmitLazyLogger(lf.interfaceVal.(LazyLogger))\r\n\tcase noopType:\r\n\t\t\r\n\t}\r\n}","code-length":456,"reference":"\/\/ Marshal passes a Field instance through to the appropriate\n\/\/ field-type-specific method of an Encoder.","result":"Marshal the field .","score":[0.0189,0.1014]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lf Field) String() string {\r\n\treturn fmt.Sprint(lf.key, \":\", lf.Value())\r\n}","code-length":40,"reference":"\/\/ String returns a string representation of the key and value.","result":"Generate the generated code.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t Tag) Set(s Span) {\r\n\ts.SetTag(t.Key, t.Value)\r\n}","code-length":39,"reference":"\/\/ Set applies the tag to an existing Span.","result":"Set tags in the code.","score":[0.1284,0.1744]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *TextMapPropagator) Inject(spanContext MockSpanContext, carrier interface{}) error {\r\n\twriter, ok := carrier.(opentracing.TextMapWriter)\r\n\tif !ok {\r\n\t\treturn opentracing.ErrInvalidCarrier\r\n\t}\r\n\t\r\n\twriter.Set(mockTextMapIdsPrefix+\"traceid\", strconv.Itoa(spanContext.TraceID))\r\n\twriter.Set(mockTextMapIdsPrefix+\"spanid\", strconv.Itoa(spanContext.SpanID))\r\n\twriter.Set(mockTextMapIdsPrefix+\"sampled\", fmt.Sprint(spanContext.Sampled))\r\n\t\r\n\tfor baggageKey, baggageVal := range spanContext.Baggage {\r\n\t\tsafeVal := baggageVal\r\n\t\tif t.HTTPHeaders {\r\n\t\t\tsafeVal = url.QueryEscape(baggageVal)\r\n\t\t}\r\n\t\twriter.Set(mockTextMapBaggagePrefix+baggageKey, safeVal)\r\n\t}\r\n\treturn nil\r\n}","code-length":258,"reference":"\/\/ Inject implements the Injector interface","result":"Inject mock span context into the carrier.","score":[0.1921,0.1639]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *TextMapPropagator) Extract(carrier interface{}) (MockSpanContext, error) {\r\n\treader, ok := carrier.(opentracing.TextMapReader)\r\n\tif !ok {\r\n\t\treturn emptyContext, opentracing.ErrInvalidCarrier\r\n\t}\r\n\trval := MockSpanContext{0, 0, true, nil}\r\n\terr := reader.ForeachKey(func(key, val string) error {\r\n\t\tlowerKey := strings.ToLower(key)\r\n\t\tswitch {\r\n\t\tcase lowerKey == mockTextMapIdsPrefix+\"traceid\":\r\n\t\t\t\r\n\t\t\ti, err := strconv.Atoi(val)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\trval.TraceID = i\r\n\t\tcase lowerKey == mockTextMapIdsPrefix+\"spanid\":\r\n\t\t\t\r\n\t\t\ti, err := strconv.Atoi(val)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\trval.SpanID = i\r\n\t\tcase lowerKey == mockTextMapIdsPrefix+\"sampled\":\r\n\t\t\tb, err := strconv.ParseBool(val)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\trval.Sampled = b\r\n\t\tcase strings.HasPrefix(lowerKey, mockTextMapBaggagePrefix):\r\n\t\t\t\r\n\t\t\tif rval.Baggage == nil {\r\n\t\t\t\trval.Baggage = make(map[string]string)\r\n\t\t\t}\r\n\t\t\tsafeVal := val\r\n\t\t\tif t.HTTPHeaders {\r\n\t\t\t\t\r\n\t\t\t\tif rawVal, err := url.QueryUnescape(val); err == nil {\r\n\t\t\t\t\tsafeVal = rawVal\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\trval.Baggage[lowerKey[len(mockTextMapBaggagePrefix):]] = safeVal\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif rval.TraceID == 0 || rval.SpanID == 0 {\r\n\t\treturn emptyContext, opentracing.ErrSpanContextNotFound\r\n\t}\r\n\tif err != nil {\r\n\t\treturn emptyContext, err\r\n\t}\r\n\treturn rval, nil\r\n}","code-length":560,"reference":"\/\/ Extract implements the Extractor interface","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ld *LogData) ToLogRecord() LogRecord {\r\n\tvar literalTimestamp time.Time\r\n\tif ld.Timestamp.IsZero() {\r\n\t\tliteralTimestamp = time.Now()\r\n\t} else {\r\n\t\tliteralTimestamp = ld.Timestamp\r\n\t}\r\n\trval := LogRecord{\r\n\t\tTimestamp: literalTimestamp,\r\n\t}\r\n\tif ld.Payload == nil {\r\n\t\trval.Fields = []log.Field{\r\n\t\t\tlog.String(\"event\", ld.Event),\r\n\t\t}\r\n\t} else {\r\n\t\trval.Fields = []log.Field{\r\n\t\t\tlog.String(\"event\", ld.Event),\r\n\t\t\tlog.Object(\"payload\", ld.Payload),\r\n\t\t}\r\n\t}\r\n\treturn rval\r\n}","code-length":202,"reference":"\/\/ ToLogRecord converts a deprecated LogData to a non-deprecated LogRecord","result":"Convert LogData to LogRecord.","score":[0.1008,0.2719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New() *MockTracer {\r\n\tt := &MockTracer{\r\n\t\tfinishedSpans: []*MockSpan{},\r\n\t\tinjectors:     make(map[interface{}]Injector),\r\n\t\textractors:    make(map[interface{}]Extractor),\r\n\t}\r\n\t\r\n\ttextPropagator := new(TextMapPropagator)\r\n\tt.RegisterInjector(opentracing.TextMap, textPropagator)\r\n\tt.RegisterExtractor(opentracing.TextMap, textPropagator)\r\n\thttpPropagator := &TextMapPropagator{HTTPHeaders: true}\r\n\tt.RegisterInjector(opentracing.HTTPHeaders, httpPropagator)\r\n\tt.RegisterExtractor(opentracing.HTTPHeaders, httpPropagator)\r\n\treturn t\r\n}","code-length":191,"reference":"\/\/ New returns a MockTracer opentracing.Tracer implementation that's intended\n\/\/ to facilitate tests of OpenTracing instrumentation.","result":"Create a new mock tracer.","score":[0.0266,0.0671]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *MockTracer) StartSpan(operationName string, opts ...opentracing.StartSpanOption) opentracing.Span {\r\n\tsso := opentracing.StartSpanOptions{}\r\n\tfor _, o := range opts {\r\n\t\to.Apply(&sso)\r\n\t}\r\n\treturn newMockSpan(t, operationName, sso)\r\n}","code-length":90,"reference":"\/\/ StartSpan belongs to the Tracer interface.","result":"Test if the span is not created by the mock tracer.","score":[0.0979,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *MockTracer) RegisterInjector(format interface{}, injector Injector) {\r\n\tt.injectors[format] = injector\r\n}","code-length":42,"reference":"\/\/ RegisterInjector registers injector for given format","result":"Test the tests.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *MockTracer) RegisterExtractor(format interface{}, extractor Extractor) {\r\n\tt.extractors[format] = extractor\r\n}","code-length":43,"reference":"\/\/ RegisterExtractor registers extractor for given format","result":"Test the mock tracing.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *MockTracer) Inject(sm opentracing.SpanContext, format interface{}, carrier interface{}) error {\r\n\tspanContext, ok := sm.(MockSpanContext)\r\n\tif !ok {\r\n\t\treturn opentracing.ErrInvalidCarrier\r\n\t}\r\n\tinjector, ok := t.injectors[format]\r\n\tif !ok {\r\n\t\treturn opentracing.ErrUnsupportedFormat\r\n\t}\r\n\treturn injector.Inject(spanContext, carrier)\r\n}","code-length":121,"reference":"\/\/ Inject belongs to the Tracer interface.","result":"Test if the span is not in the trace.","score":[0.1219,0.0694]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *MockTracer) Extract(format interface{}, carrier interface{}) (opentracing.SpanContext, error) {\r\n\textractor, ok := t.extractors[format]\r\n\tif !ok {\r\n\t\treturn nil, opentracing.ErrUnsupportedFormat\r\n\t}\r\n\treturn extractor.Extract(carrier)\r\n}","code-length":87,"reference":"\/\/ Extract belongs to the Tracer interface.","result":"Test the code.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ContextWithSpan(ctx context.Context, span Span) context.Context {\r\n\treturn context.WithValue(ctx, activeSpanKey, span)\r\n}","code-length":46,"reference":"\/\/ ContextWithSpan returns a new `context.Context` that holds a reference to\n\/\/ `span`'s SpanContext.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tag uint32TagName) Set(span opentracing.Span, value uint32) {\r\n\tspan.SetTag(string(tag), value)\r\n}","code-length":45,"reference":"\/\/ Set adds a uint32 tag to the `span`","result":"Tags in the tracing.","score":[0.0915,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tag uint16TagName) Set(span opentracing.Span, value uint16) {\r\n\tspan.SetTag(string(tag), value)\r\n}","code-length":45,"reference":"\/\/ Set adds a uint16 tag to the `span`","result":"Set tags in the span.","score":[0.1284,0.1744]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tag boolTagName) Set(span opentracing.Span, value bool) {\r\n\tspan.SetTag(string(tag), value)\r\n}","code-length":43,"reference":"\/\/ Add adds a bool tag to the `span`","result":"Set tags in functions.","score":[0,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tag ipv4Tag) SetString(span opentracing.Span, value string) {\r\n\tspan.SetTag(string(tag), value)\r\n}","code-length":45,"reference":"\/\/ SetString records IP v4 host address of the peer as a .-separated tuple to the `span`. E.g., \"127.0.0.1\"","result":"Generate the code.","score":[0.002,0.0287]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *MockKeyValue) EmitString(key, value string) {\r\n\tm.Key = key\r\n\tm.ValueKind = reflect.TypeOf(value).Kind()\r\n\tm.ValueString = fmt.Sprint(value)\r\n}","code-length":68,"reference":"\/\/ EmitString belongs to the log.Encoder interface","result":"Test the mock .","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *MockKeyValue) EmitLazyLogger(value log.LazyLogger) {\r\n\tvar meta MockKeyValue\r\n\tvalue(&meta)\r\n\tm.Key = meta.Key\r\n\tm.ValueKind = meta.ValueKind\r\n\tm.ValueString = meta.ValueString\r\n}","code-length":79,"reference":"\/\/ EmitLazyLogger belongs to the log.Encoder interface","result":"Test the mock .","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RunAPIChecks(\r\n\tt *testing.T,\r\n\tnewTracer func() (tracer opentracing.Tracer, closer func()),\r\n\topts ...APICheckOption,\r\n) {\r\n\ts := &APICheckSuite{newTracer: newTracer}\r\n\tfor _, opt := range opts {\r\n\t\topt(s)\r\n\t}\r\n\tsuite.Run(t, s)\r\n}","code-length":108,"reference":"\/\/ RunAPIChecks runs a test suite to check a Tracer against the OpenTracing API.\n\/\/ It is provided a function that will be executed to create and destroy a tracer for each test\n\/\/ in the suite, and the given APICheckOption functional options `opts`.","result":"Test APICheckSuite.","score":[0,0.0126]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CheckBaggageValues(val bool) APICheckOption {\r\n\treturn func(s *APICheckSuite) {\r\n\t\ts.opts.CheckBaggageValues = val\r\n\t}\r\n}","code-length":58,"reference":"\/\/ CheckBaggageValues returns an option that sets whether to check for propagation of baggage values.","result":"Check baggage values.","score":[0.0106,0.1852]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CheckExtract(val bool) APICheckOption {\r\n\treturn func(s *APICheckSuite) {\r\n\t\ts.opts.CheckExtract = val\r\n\t}\r\n}","code-length":52,"reference":"\/\/ CheckExtract returns an option that sets whether to check if extracting contexts from carriers works.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CheckInject(val bool) APICheckOption {\r\n\treturn func(s *APICheckSuite) {\r\n\t\ts.opts.CheckInject = val\r\n\t}\r\n}","code-length":52,"reference":"\/\/ CheckInject returns an option that sets whether to check if injecting contexts works.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CheckEverything() APICheckOption {\r\n\treturn func(s *APICheckSuite) {\r\n\t\ts.opts.CheckBaggageValues = true\r\n\t\ts.opts.CheckExtract = true\r\n\t\ts.opts.CheckInject = true\r\n\t}\r\n}","code-length":77,"reference":"\/\/ CheckEverything returns an option that enables all API checks.","result":"Check everything.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UseProbe(probe APICheckProbe) APICheckOption {\r\n\treturn func(s *APICheckSuite) {\r\n\t\ts.opts.Probe = probe\r\n\t}\r\n}","code-length":53,"reference":"\/\/ UseProbe returns an option that specifies an APICheckProbe implementation to use.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c MockSpanContext) WithBaggageItem(key, value string) MockSpanContext {\r\n\tvar newBaggage map[string]string\r\n\tif c.Baggage == nil {\r\n\t\tnewBaggage = map[string]string{key: value}\r\n\t} else {\r\n\t\tnewBaggage = make(map[string]string, len(c.Baggage)+1)\r\n\t\tfor k, v := range c.Baggage {\r\n\t\t\tnewBaggage[k] = v\r\n\t\t}\r\n\t\tnewBaggage[key] = value\r\n\t}\r\n\t\r\n\treturn MockSpanContext{c.TraceID, c.SpanID, c.Sampled, newBaggage}\r\n}","code-length":193,"reference":"\/\/ WithBaggageItem creates a new context with an extra baggage item.","result":"Set the baggage of the span.","score":[0.0839,0.0476]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MockSpan) Tags() map[string]interface{} {\r\n\ts.RLock()\r\n\tdefer s.RUnlock()\r\n\ttags := make(map[string]interface{})\r\n\tfor k, v := range s.tags {\r\n\t\ttags[k] = v\r\n\t}\r\n\treturn tags\r\n}","code-length":91,"reference":"\/\/ Tags returns a copy of tags accumulated by the span so far","result":"Test tags in tests.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MockSpan) Tag(k string) interface{} {\r\n\ts.RLock()\r\n\tdefer s.RUnlock()\r\n\treturn s.tags[k]\r\n}","code-length":54,"reference":"\/\/ Tag returns a single tag","result":"Test the mock span tags.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MockSpan) Logs() []MockLogRecord {\r\n\ts.RLock()\r\n\tdefer s.RUnlock()\r\n\tlogs := make([]MockLogRecord, len(s.logs))\r\n\tcopy(logs, s.logs)\r\n\treturn logs\r\n}","code-length":75,"reference":"\/\/ Logs returns a copy of logs accumulated in the span so far","result":"Test the code.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MockSpan) Context() opentracing.SpanContext {\r\n\ts.Lock()\r\n\tdefer s.Unlock()\r\n\treturn s.SpanContext\r\n}","code-length":49,"reference":"\/\/ Context belongs to the Span interface","result":"Test the mock span context.","score":[0.1611,0.1471]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MockSpan) SetTag(key string, value interface{}) opentracing.Span {\r\n\ts.Lock()\r\n\tdefer s.Unlock()\r\n\tif key == string(ext.SamplingPriority) {\r\n\t\tif v, ok := value.(uint16); ok {\r\n\t\t\ts.SpanContext.Sampled = v > 0\r\n\t\t\treturn s\r\n\t\t}\r\n\t\tif v, ok := value.(int); ok {\r\n\t\t\ts.SpanContext.Sampled = v > 0\r\n\t\t\treturn s\r\n\t\t}\r\n\t}\r\n\ts.tags[key] = value\r\n\treturn s\r\n}","code-length":167,"reference":"\/\/ SetTag belongs to the Span interface","result":"Set tags on the span.","score":[0.1611,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MockSpan) SetBaggageItem(key, val string) opentracing.Span {\r\n\ts.Lock()\r\n\tdefer s.Unlock()\r\n\ts.SpanContext = s.SpanContext.WithBaggageItem(key, val)\r\n\treturn s\r\n}","code-length":77,"reference":"\/\/ SetBaggageItem belongs to the Span interface","result":"Set baggage items.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MockSpan) BaggageItem(key string) string {\r\n\ts.RLock()\r\n\tdefer s.RUnlock()\r\n\treturn s.SpanContext.Baggage[key]\r\n}","code-length":61,"reference":"\/\/ BaggageItem belongs to the Span interface","result":"Test the code.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MockSpan) Finish() {\r\n\ts.Lock()\r\n\ts.FinishTime = time.Now()\r\n\ts.Unlock()\r\n\ts.tracer.recordSpan(s)\r\n}","code-length":61,"reference":"\/\/ Finish belongs to the Span interface","result":"Test the Finish method.","score":[0.1795,0.1493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MockSpan) FinishWithOptions(opts opentracing.FinishOptions) {\r\n\ts.Lock()\r\n\ts.FinishTime = opts.FinishTime\r\n\ts.Unlock()\r\n\t\r\n\tfor _, lr := range opts.LogRecords {\r\n\t\ts.logFieldsWithTimestamp(lr.Timestamp, lr.Fields...)\r\n\t}\r\n\t\r\n\tfor _, ld := range opts.BulkLogData {\r\n\t\tif ld.Payload != nil {\r\n\t\t\ts.logFieldsWithTimestamp(\r\n\t\t\t\tld.Timestamp,\r\n\t\t\t\tlog.String(\"event\", ld.Event),\r\n\t\t\t\tlog.Object(\"payload\", ld.Payload))\r\n\t\t} else {\r\n\t\t\ts.logFieldsWithTimestamp(\r\n\t\t\t\tld.Timestamp,\r\n\t\t\t\tlog.String(\"event\", ld.Event))\r\n\t\t}\r\n\t}\r\n\ts.tracer.recordSpan(s)\r\n}","code-length":233,"reference":"\/\/ FinishWithOptions belongs to the Span interface","result":"Test if the span is already finished.","score":[0.1615,0.2679]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MockSpan) String() string {\r\n\treturn fmt.Sprintf(\r\n\t\t\"traceId=%d, spanId=%d, parentId=%d, sampled=%t, name=%s\",\r\n\t\ts.SpanContext.TraceID, s.SpanContext.SpanID, s.ParentID,\r\n\t\ts.SpanContext.Sampled, s.OperationName)\r\n}","code-length":100,"reference":"\/\/ String allows printing span for debugging","result":"Test the mock span string format.","score":[0.1634,0.1449]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MockSpan) LogFields(fields ...log.Field) {\r\n\ts.logFieldsWithTimestamp(time.Now(), fields...)\r\n}","code-length":45,"reference":"\/\/ LogFields belongs to the Span interface","result":"Test the tests.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MockSpan) logFieldsWithTimestamp(ts time.Time, fields ...log.Field) {\r\n\tlr := MockLogRecord{\r\n\t\tTimestamp: ts,\r\n\t\tFields:    make([]MockKeyValue, len(fields)),\r\n\t}\r\n\tfor i, f := range fields {\r\n\t\toutField := &(lr.Fields[i])\r\n\t\tf.Marshal(outField)\r\n\t}\r\n\ts.Lock()\r\n\tdefer s.Unlock()\r\n\ts.logs = append(s.logs, lr)\r\n}","code-length":145,"reference":"\/\/ The caller MUST NOT hold s.Lock","result":"Test the log fields with timestamp.","score":[0,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MockSpan) LogKV(keyValues ...interface{}) {\r\n\tif len(keyValues)%2 != 0 {\r\n\t\ts.LogFields(log.Error(fmt.Errorf(\"Non-even keyValues len: %v\", len(keyValues))))\r\n\t\treturn\r\n\t}\r\n\tfields, err := log.InterleavedKVToFields(keyValues...)\r\n\tif err != nil {\r\n\t\ts.LogFields(log.Error(err), log.String(\"function\", \"LogKV\"))\r\n\t\treturn\r\n\t}\r\n\ts.LogFields(fields...)\r\n}","code-length":156,"reference":"\/\/ LogKV belongs to the Span interface.\n\/\/\n\/\/ This implementations coerces all \"values\" to strings, though that is not\n\/\/ something all implementations need to do. Indeed, a motivated person can and\n\/\/ probably should have this do a typed switch on the values.","result":"Test if the span is not started.","score":[0.0011,0.0766]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MockSpan) LogEvent(event string) {\r\n\ts.LogFields(log.String(\"event\", event))\r\n}","code-length":42,"reference":"\/\/ LogEvent belongs to the Span interface","result":"Test the tests.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MockSpan) LogEventWithPayload(event string, payload interface{}) {\r\n\ts.LogFields(log.String(\"event\", event), log.Object(\"payload\", payload))\r\n}","code-length":56,"reference":"\/\/ LogEventWithPayload belongs to the Span interface","result":"Test the code.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MockSpan) SetOperationName(operationName string) opentracing.Span {\r\n\ts.Lock()\r\n\tdefer s.Unlock()\r\n\ts.OperationName = operationName\r\n\treturn s\r\n}","code-length":60,"reference":"\/\/ SetOperationName belongs to the Span interface","result":"Set the operationName of the span.","score":[0.1634,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc registriesDirPath(sys *types.SystemContext) string {\r\n\tif sys != nil {\r\n\t\tif sys.RegistriesDirPath != \"\" {\r\n\t\t\treturn sys.RegistriesDirPath\r\n\t\t}\r\n\t\tif sys.RootForImplicitAbsolutePaths != \"\" {\r\n\t\t\treturn filepath.Join(sys.RootForImplicitAbsolutePaths, systemRegistriesDirPath)\r\n\t\t}\r\n\t}\r\n\treturn systemRegistriesDirPath\r\n}","code-length":116,"reference":"\/\/ registriesDirPath returns a path to registries.d","result":"Generate the registries directory path.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc loadAndMergeConfig(dirPath string) (*registryConfiguration, error) {\r\n\tmergedConfig := registryConfiguration{Docker: map[string]registryNamespace{}}\r\n\tdockerDefaultMergedFrom := \"\"\r\n\tnsMergedFrom := map[string]string{}\r\n\tdir, err := os.Open(dirPath)\r\n\tif err != nil {\r\n\t\tif os.IsNotExist(err) {\r\n\t\t\treturn &mergedConfig, nil\r\n\t\t}\r\n\t\treturn nil, err\r\n\t}\r\n\tconfigNames, err := dir.Readdirnames(0)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tfor _, configName := range configNames {\r\n\t\tif !strings.HasSuffix(configName, \".yaml\") {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tconfigPath := filepath.Join(dirPath, configName)\r\n\t\tconfigBytes, err := ioutil.ReadFile(configPath)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tvar config registryConfiguration\r\n\t\terr = yaml.Unmarshal(configBytes, &config)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, errors.Wrapf(err, \"Error parsing %s\", configPath)\r\n\t\t}\r\n\t\tif config.DefaultDocker != nil {\r\n\t\t\tif mergedConfig.DefaultDocker != nil {\r\n\t\t\t\treturn nil, errors.Errorf(`Error parsing signature storage configuration: \"default-docker\" defined both in \"%s\" and \"%s\"`,\r\n\t\t\t\t\tdockerDefaultMergedFrom, configPath)\r\n\t\t\t}\r\n\t\t\tmergedConfig.DefaultDocker = config.DefaultDocker\r\n\t\t\tdockerDefaultMergedFrom = configPath\r\n\t\t}\r\n\t\tfor nsName, nsConfig := range config.Docker {\r\n\t\t\tif _, ok := mergedConfig.Docker[nsName]; ok {\r\n\t\t\t\treturn nil, errors.Errorf(`Error parsing signature storage configuration: \"docker\" namespace \"%s\" defined both in \"%s\" and \"%s\"`,\r\n\t\t\t\t\tnsName, nsMergedFrom[nsName], configPath)\r\n\t\t\t}\r\n\t\t\tmergedConfig.Docker[nsName] = nsConfig\r\n\t\t\tnsMergedFrom[nsName] = configPath\r\n\t\t}\r\n\t}\r\n\treturn &mergedConfig, nil\r\n}","code-length":566,"reference":"\/\/ loadAndMergeConfig loads configuration files in dirPath","result":"Code too long,keep in 512.","score":[0.1611,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseReference(ref string) (types.ImageReference, error) {\r\n\tr, err := reference.ParseNormalizedNamed(ref)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrapf(err, \"failed to parse image reference %q\", ref)\r\n\t}\r\n\ttagged, ok := r.(reference.NamedTagged)\r\n\tif !ok {\r\n\t\treturn nil, errors.Errorf(\"invalid image reference %s, expected format: 'hostname\/namespace\/stream:tag'\", ref)\r\n\t}\r\n\treturn NewReference(tagged)\r\n}","code-length":147,"reference":"\/\/ ParseReference converts a string, which should not start with the ImageTransport.Name prefix, into an OpenShift ImageReference.","result":"Parse the image reference.","score":[0.0124,0.0318]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewReference(dockerRef reference.NamedTagged) (types.ImageReference, error) {\r\n\tr := strings.SplitN(reference.Path(dockerRef), \"\/\", 3)\r\n\tif len(r) != 2 {\r\n\t\treturn nil, errors.Errorf(\"invalid image reference: %s, expected format: 'hostname\/namespace\/stream:tag'\",\r\n\t\t\treference.FamiliarString(dockerRef))\r\n\t}\r\n\treturn openshiftReference{\r\n\t\tnamespace:       r[0],\r\n\t\tstream:          r[1],\r\n\t\tdockerReference: dockerRef,\r\n\t}, nil\r\n}","code-length":159,"reference":"\/\/ NewReference returns an OpenShift reference for a reference.NamedTagged","result":"Create a new reference.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CheckAuth(ctx context.Context, sys *types.SystemContext, username, password, registry string) error {\r\n\tclient, err := newDockerClient(sys, registry, registry)\r\n\tif err != nil {\r\n\t\treturn errors.Wrapf(err, \"error creating new docker client\")\r\n\t}\r\n\tclient.username = username\r\n\tclient.password = password\r\n\tresp, err := client.makeRequest(ctx, \"GET\", \"\/v2\/\", nil, nil, v2Auth, nil)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\tswitch resp.StatusCode {\r\n\tcase http.StatusOK:\r\n\t\treturn nil\r\n\tcase http.StatusUnauthorized:\r\n\t\treturn ErrUnauthorizedForCredentials\r\n\tdefault:\r\n\t\treturn errors.Errorf(\"error occured with status code %d (%s)\", resp.StatusCode, http.StatusText(resp.StatusCode))\r\n\t}\r\n}","code-length":244,"reference":"\/\/ CheckAuth validates the credentials by attempting to log into the registry\n\/\/ returns an error if an error occurred while making the http request or the status code received was 401","result":"Check if the user is authenticated with the registry.","score":[0.0125,0.0505]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dockerClient) doHTTP(req *http.Request) (*http.Response, error) {\r\n\ttr := tlsclientconfig.NewTransport()\r\n\ttr.TLSClientConfig = c.tlsClientConfig\r\n\thttpClient := &http.Client{Transport: tr}\r\n\treturn httpClient.Do(req)\r\n}","code-length":87,"reference":"\/\/ doHttp uses the clients internal TLS configuration for doing the\n\/\/ provided HTTP request.  It returns the response and an error on failure.","result":"Create a new client.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dockerClient) detectPropertiesHelper(ctx context.Context) error {\r\n\tif c.scheme != \"\" {\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\t\r\n\tif c.sys != nil && c.sys.DockerInsecureSkipTLSVerify != types.OptionalBoolUndefined {\r\n\t\tc.tlsClientConfig.InsecureSkipVerify = c.sys.DockerInsecureSkipTLSVerify == types.OptionalBoolTrue\r\n\t}\r\n\tping := func(scheme string) error {\r\n\t\turl := fmt.Sprintf(resolvedPingV2URL, scheme, c.registry)\r\n\t\tresp, err := c.makeRequestToResolvedURL(ctx, \"GET\", url, nil, nil, -1, noAuth, nil)\r\n\t\tif err != nil {\r\n\t\t\tlogrus.Debugf(\"Ping %s err %s (%#v)\", url, err.Error(), err)\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdefer resp.Body.Close()\r\n\t\tlogrus.Debugf(\"Ping %s status %d\", url, resp.StatusCode)\r\n\t\tif resp.StatusCode != http.StatusOK && resp.StatusCode != http.StatusUnauthorized {\r\n\t\t\treturn errors.Errorf(\"error pinging registry %s, response code %d (%s)\", c.registry, resp.StatusCode, http.StatusText(resp.StatusCode))\r\n\t\t}\r\n\t\tc.challenges = parseAuthHeader(resp.Header)\r\n\t\tc.scheme = scheme\r\n\t\tc.supportsSignatures = resp.Header.Get(\"X-Registry-Supports-Signatures\") == \"1\"\r\n\t\treturn nil\r\n\t}\r\n\terr := ping(\"https\")\r\n\tif err != nil && c.tlsClientConfig.InsecureSkipVerify {\r\n\t\terr = ping(\"http\")\r\n\t}\r\n\tif err != nil {\r\n\t\terr = errors.Wrap(err, \"pinging docker registry returned\")\r\n\t\tif c.sys != nil && c.sys.DockerDisableV1Ping {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\tpingV1 := func(scheme string) bool {\r\n\t\t\turl := fmt.Sprintf(resolvedPingV1URL, scheme, c.registry)\r\n\t\t\tresp, err := c.makeRequestToResolvedURL(ctx, \"GET\", url, nil, nil, -1, noAuth, nil)\r\n\t\t\tif err != nil {\r\n\t\t\t\tlogrus.Debugf(\"Ping %s err %s (%#v)\", url, err.Error(), err)\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\t\tdefer resp.Body.Close()\r\n\t\t\tlogrus.Debugf(\"Ping %s status %d\", url, resp.StatusCode)\r\n\t\t\tif resp.StatusCode != http.StatusOK && resp.StatusCode != http.StatusUnauthorized {\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\t\treturn true\r\n\t\t}\r\n\t\tisV1 := pingV1(\"https\")\r\n\t\tif !isV1 && c.tlsClientConfig.InsecureSkipVerify {\r\n\t\t\tisV1 = pingV1(\"http\")\r\n\t\t}\r\n\t\tif isV1 {\r\n\t\t\terr = ErrV1NotSupported\r\n\t\t}\r\n\t}\r\n\treturn err\r\n}","code-length":786,"reference":"\/\/ detectPropertiesHelper performs the work of detectProperties which executes\n\/\/ it at most once.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dockerClient) detectProperties(ctx context.Context) error {\r\n\tc.detectPropertiesOnce.Do(func() { c.detectPropertiesError = c.detectPropertiesHelper(ctx) })\r\n\treturn c.detectPropertiesError\r\n}","code-length":68,"reference":"\/\/ detectProperties detects various properties of the registry.\n\/\/ See the dockerClient documentation for members which are affected by this.","result":"Detect properties.","score":[0,0.0275]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dockerClient) getExtensionsSignatures(ctx context.Context, ref dockerReference, manifestDigest digest.Digest) (*extensionSignatureList, error) {\r\n\tpath := fmt.Sprintf(extensionsSignaturePath, reference.Path(ref.ref), manifestDigest)\r\n\tres, err := c.makeRequest(ctx, \"GET\", path, nil, nil, v2Auth, nil)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer res.Body.Close()\r\n\tif res.StatusCode != http.StatusOK {\r\n\t\treturn nil, errors.Wrapf(client.HandleErrorResponse(res), \"Error downloading signatures for %s in %s\", manifestDigest, ref.ref.Name())\r\n\t}\r\n\tbody, err := ioutil.ReadAll(res.Body)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar parsedBody extensionSignatureList\r\n\tif err := json.Unmarshal(body, &parsedBody); err != nil {\r\n\t\treturn nil, errors.Wrapf(err, \"Error decoding signature list\")\r\n\t}\r\n\treturn &parsedBody, nil\r\n}","code-length":285,"reference":"\/\/ getExtensionsSignatures returns signatures from the X-Registry-Supports-Signatures API extension,\n\/\/ using the original data structures.","result":"Get signatures for extensions in a given manifest.","score":[0.0579,0.0699]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTransport() *http.Transport {\r\n\tdirect := &net.Dialer{\r\n\t\tTimeout:   30 * time.Second,\r\n\t\tKeepAlive: 30 * time.Second,\r\n\t\tDualStack: true,\r\n\t}\r\n\ttr := &http.Transport{\r\n\t\tProxy:               http.ProxyFromEnvironment,\r\n\t\tDial:                direct.Dial,\r\n\t\tTLSHandshakeTimeout: 10 * time.Second,\r\n\t\t\r\n\t\tDisableKeepAlives: true,\r\n\t}\r\n\tproxyDialer, err := sockets.DialerFromEnvironment(direct)\r\n\tif err == nil {\r\n\t\ttr.Dial = proxyDialer.Dial\r\n\t}\r\n\treturn tr\r\n}","code-length":181,"reference":"\/\/ NewTransport Creates a default transport","result":"Create a new transport.","score":[0.1938,0.3233]}
{"code":"\/*is used to<extra_id_0>\r\nfunc readRegistryConf(sys *types.SystemContext) ([]byte, error) {\r\n\treturn ioutil.ReadFile(RegistriesConfPath(sys))\r\n}","code-length":47,"reference":"\/\/ Reads the global registry file from the filesystem. Returns\n\/\/ a byte array","result":"Generate the generated code.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetRegistries(sys *types.SystemContext) ([]string, error) {\r\n\tconfig, err := loadRegistryConf(sys)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn config.Registries.Search.Registries, nil\r\n}","code-length":79,"reference":"\/\/ GetRegistries returns an array of strings that contain the names\n\/\/ of the registries as defined in the system-wide\n\/\/ registries file.  it returns an empty array if none are\n\/\/ defined","result":"Get the list of registries.","score":[0.0011,0.0497]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetInsecureRegistries(sys *types.SystemContext) ([]string, error) {\r\n\tconfig, err := loadRegistryConf(sys)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn config.Registries.Insecure.Registries, nil\r\n}","code-length":82,"reference":"\/\/ GetInsecureRegistries returns an array of strings that contain the names\n\/\/ of the insecure registries as defined in the system-wide\n\/\/ registries file.  it returns an empty array if none are\n\/\/ defined","result":"Get the registry configuration.","score":[0.0002,0.0323]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegistriesConfPath(ctx *types.SystemContext) string {\r\n\tpath := systemRegistriesConfPath\r\n\tif ctx != nil {\r\n\t\tif ctx.SystemRegistriesConfPath != \"\" {\r\n\t\t\tpath = ctx.SystemRegistriesConfPath\r\n\t\t} else if ctx.RootForImplicitAbsolutePaths != \"\" {\r\n\t\t\tpath = filepath.Join(ctx.RootForImplicitAbsolutePaths, systemRegistriesConfPath)\r\n\t\t}\r\n\t}\r\n\treturn path\r\n}","code-length":128,"reference":"\/\/ RegistriesConfPath is the path to the system-wide registry configuration file","result":"Generate the registries configuration path.","score":[0.0861,0.2457]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewOptionalBool(b bool) OptionalBool {\r\n\to := OptionalBoolFalse\r\n\tif b == true {\r\n\t\to = OptionalBoolTrue\r\n\t}\r\n\treturn o\r\n}","code-length":57,"reference":"\/\/ NewOptionalBool converts the input bool into either OptionalBoolTrue or\n\/\/ OptionalBoolFalse.  The function is meant to avoid boilerplate code of users.","result":"Create a new OptionalBool.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pc *PolicyContext) changeState(expected, new policyContextState) error {\r\n\tif pc.state != expected {\r\n\t\treturn errors.Errorf(`\"Invalid PolicyContext state, expected \"%s\", found \"%s\"`, expected, pc.state)\r\n\t}\r\n\tpc.state = new\r\n\treturn nil\r\n}","code-length":88,"reference":"\/\/ changeContextState changes pc.state, or fails if the state is unexpected","result":"Change the state of the PolicyContext.","score":[0.1187,0.1429]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pc *PolicyContext) Destroy() error {\r\n\tif err := pc.changeState(pcReady, pcDestroying); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\treturn pc.changeState(pcDestroying, pcDestroyed)\r\n}","code-length":74,"reference":"\/\/ Destroy should be called when the user of the context is done with it.","result":"Destroy policy context.","score":[0.0075,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc policyIdentityLogName(ref types.ImageReference) string {\r\n\treturn ref.Transport().Name() + \":\" + ref.PolicyConfigurationIdentity()\r\n}","code-length":45,"reference":"\/\/ policyIdentityLogName returns a string description of the image identity for policy purposes.\n\/\/ ONLY use this for log messages, not for any decisions!","result":"Log policy identity log names.","score":[0.0071,0.0679]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pc *PolicyContext) requirementsForImageRef(ref types.ImageReference) PolicyRequirements {\r\n\t\r\n\ttransportName := ref.Transport().Name()\r\n\tif transportScopes, ok := pc.Policy.Transports[transportName]; ok {\r\n\t\t\r\n\t\tidentity := ref.PolicyConfigurationIdentity()\r\n\t\tif req, ok := transportScopes[identity]; ok {\r\n\t\t\tlogrus.Debugf(` Using transport \"%s\" policy section %s`, transportName, identity)\r\n\t\t\treturn req\r\n\t\t}\r\n\t\t\r\n\t\tfor _, name := range ref.PolicyConfigurationNamespaces() {\r\n\t\t\tif req, ok := transportScopes[name]; ok {\r\n\t\t\t\tlogrus.Debugf(` Using transport \"%s\" specific policy section %s`, transportName, name)\r\n\t\t\t\treturn req\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tif req, ok := transportScopes[\"\"]; ok {\r\n\t\t\tlogrus.Debugf(` Using transport \"%s\" policy section \"\"`, transportName)\r\n\t\t\treturn req\r\n\t\t}\r\n\t}\r\n\tlogrus.Debugf(\" Using default policy section\")\r\n\treturn pc.Policy.Default\r\n}","code-length":292,"reference":"\/\/ requirementsForImageRef selects the appropriate requirements for ref.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseImageName(imgName string) (types.ImageReference, error) {\r\n\tparts := strings.SplitN(imgName, \":\", 2)\r\n\tif len(parts) != 2 {\r\n\t\treturn nil, errors.Errorf(`Invalid image name \"%s\", expected colon-separated transport:reference`, imgName)\r\n\t}\r\n\ttransport := transports.Get(parts[0])\r\n\tif transport == nil {\r\n\t\treturn nil, errors.Errorf(`Invalid image name \"%s\", unknown transport \"%s\"`, imgName, parts[0])\r\n\t}\r\n\treturn transport.ParseReference(parts[1])\r\n}","code-length":160,"reference":"\/\/ ParseImageName converts a URL-like image name to a types.ImageReference.","result":"Parse image names.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc BlobInfoFromOCI1Descriptor(desc imgspecv1.Descriptor) types.BlobInfo {\r\n\treturn types.BlobInfo{\r\n\t\tDigest:      desc.Digest,\r\n\t\tSize:        desc.Size,\r\n\t\tURLs:        desc.URLs,\r\n\t\tAnnotations: desc.Annotations,\r\n\t\tMediaType:   desc.MediaType,\r\n\t}\r\n}","code-length":100,"reference":"\/\/ BlobInfoFromOCI1Descriptor returns a types.BlobInfo based on the input OCI1 descriptor.","result":"Create a blob info from the descriptor.","score":[0.12,0.1415]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OCI1FromManifest(manifest []byte) (*OCI1, error) {\r\n\toci1 := OCI1{}\r\n\tif err := json.Unmarshal(manifest, &oci1); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &oci1, nil\r\n}","code-length":80,"reference":"\/\/ OCI1FromManifest creates an OCI1 manifest instance from a manifest blob.","result":"From the manifest.","score":[0,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OCI1FromComponents(config imgspecv1.Descriptor, layers []imgspecv1.Descriptor) *OCI1 {\r\n\treturn &OCI1{\r\n\t\timgspecv1.Manifest{\r\n\t\t\tVersioned: specs.Versioned{SchemaVersion: 2},\r\n\t\t\tConfig:    config,\r\n\t\t\tLayers:    layers,\r\n\t\t},\r\n\t}\r\n}","code-length":102,"reference":"\/\/ OCI1FromComponents creates an OCI1 manifest instance from the supplied data.","result":"From components.","score":[0,0.0495]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newReference(ref reference.Named) (dockerReference, error) {\r\n\tif reference.IsNameOnly(ref) {\r\n\t\treturn dockerReference{}, errors.Errorf(\"Docker reference %s has neither a tag nor a digest\", reference.FamiliarString(ref))\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t_, isTagged := ref.(reference.NamedTagged)\r\n\t_, isDigested := ref.(reference.Canonical)\r\n\tif isTagged && isDigested {\r\n\t\treturn dockerReference{}, errors.Errorf(\"Docker references with both a tag and digest are currently not supported\")\r\n\t}\r\n\treturn dockerReference{\r\n\t\tref: ref,\r\n\t}, nil\r\n}","code-length":188,"reference":"\/\/ newReference returns a dockerReference for a named reference.","result":"Create a new reference.","score":[0.1088,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ref dockerReference) tagOrDigest() (string, error) {\r\n\tif ref, ok := ref.ref.(reference.Canonical); ok {\r\n\t\treturn ref.Digest().String(), nil\r\n\t}\r\n\tif ref, ok := ref.ref.(reference.NamedTagged); ok {\r\n\t\treturn ref.Tag(), nil\r\n\t}\r\n\t\r\n\treturn \"\", errors.Errorf(\"Internal inconsistency: Reference %s unexpectedly has neither a digest nor a tag\", reference.FamiliarString(ref.ref))\r\n}","code-length":138,"reference":"\/\/ tagOrDigest returns a tag or digest from the reference.","result":"Digest of a reference.","score":[0.0848,0.1596]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ic *imageCopier) updateEmbeddedDockerReference() error {\r\n\tif ic.c.dest.IgnoresEmbeddedDockerReference() {\r\n\t\treturn nil\r\n\t}\r\n\tdestRef := ic.c.dest.Reference().DockerReference()\r\n\tif destRef == nil {\r\n\t\treturn nil\r\n\t}\r\n\tif !ic.src.EmbeddedDockerReferenceConflicts(destRef) {\r\n\t\treturn nil\r\n\t}\r\n\tif !ic.canModifyManifest {\r\n\t\treturn errors.Errorf(\"Copying a schema1 image with an embedded Docker reference to %s (Docker reference %s) would invalidate existing signatures. Explicitly enable signature removal to proceed anyway\",\r\n\t\t\ttransports.ImageName(ic.c.dest.Reference()), destRef.String())\r\n\t}\r\n\tic.manifestUpdates.EmbeddedDockerReference = destRef\r\n\treturn nil\r\n}","code-length":220,"reference":"\/\/ updateEmbeddedDockerReference handles the Docker reference embedded in Docker schema1 manifests.","result":"Update the embedded Docker reference in the manifest.","score":[0.1697,0.2336]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isTTY(w io.Writer) bool {\r\n\tif f, ok := w.(*os.File); ok {\r\n\t\treturn terminal.IsTerminal(int(f.Fd()))\r\n\t}\r\n\treturn false\r\n}","code-length":66,"reference":"\/\/ isTTY returns true if the io.Writer is a file and a tty.","result":"Check if the writer is a tty.","score":[0.1449,0.3597]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ic *imageCopier) copyUpdatedConfigAndManifest(ctx context.Context) ([]byte, error) {\r\n\tpendingImage := ic.src\r\n\tif !reflect.DeepEqual(*ic.manifestUpdates, types.ManifestUpdateOptions{InformationOnly: ic.manifestUpdates.InformationOnly}) {\r\n\t\tif !ic.canModifyManifest {\r\n\t\t\treturn nil, errors.Errorf(\"Internal error: copy needs an updated manifest but that was known to be forbidden\")\r\n\t\t}\r\n\t\tif !ic.diffIDsAreNeeded && ic.src.UpdatedImageNeedsLayerDiffIDs(*ic.manifestUpdates) {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\treturn nil, errors.Errorf(\"Can not convert image to %s, preparing DiffIDs for this case is not supported\", ic.manifestUpdates.ManifestMIMEType)\r\n\t\t}\r\n\t\tpi, err := ic.src.UpdatedImage(ctx, *ic.manifestUpdates)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, errors.Wrap(err, \"Error creating an updated image manifest\")\r\n\t\t}\r\n\t\tpendingImage = pi\r\n\t}\r\n\tmanifest, _, err := pendingImage.Manifest(ctx)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Error reading manifest\")\r\n\t}\r\n\tif err := ic.c.copyConfig(ctx, pendingImage); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tic.c.Printf(\"Writing manifest to image destination\\n\")\r\n\tif err := ic.c.dest.PutManifest(ctx, manifest); err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Error writing manifest\")\r\n\t}\r\n\treturn manifest, nil\r\n}","code-length":436,"reference":"\/\/ copyUpdatedConfigAndManifest updates the image per ic.manifestUpdates, if necessary,\n\/\/ stores the resulting config and manifest to the destination, and returns the stored manifest.","result":"Copy updated config and manifest to destination.","score":[0.0446,0.1668]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *copier) createProgressBar(pool *mpb.Progress, info types.BlobInfo, kind string, onComplete string) *mpb.Bar {\r\n\t\r\n\tconst shortDigestLen = 12\r\n\tprefix := fmt.Sprintf(\"Copying %s %s\", kind, info.Digest.Encoded())\r\n\t\r\n\tmaxPrefixLen := len(\"Copying blob \") + shortDigestLen\r\n\tif len(prefix) > maxPrefixLen {\r\n\t\tprefix = prefix[:maxPrefixLen]\r\n\t}\r\n\tbar := pool.AddBar(info.Size,\r\n\t\tmpb.BarClearOnComplete(),\r\n\t\tmpb.PrependDecorators(\r\n\t\t\tdecor.Name(prefix),\r\n\t\t),\r\n\t\tmpb.AppendDecorators(\r\n\t\t\tdecor.OnComplete(decor.CountersKibiByte(\"%.1f \/ %.1f\"), \" \"+onComplete),\r\n\t\t),\r\n\t)\r\n\tif c.progressOutput == ioutil.Discard {\r\n\t\tc.Printf(\"Copying %s %s\\n\", kind, info.Digest)\r\n\t}\r\n\treturn bar\r\n}","code-length":281,"reference":"\/\/ createProgressBar creates a mpb.Bar in pool.  Note that if the copier's reportWriter\n\/\/ is ioutil.Discard, the progress bar's output will be discarded","result":"Create a progress bar for the copy process.","score":[0.028,0.1468]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *copier) copyConfig(ctx context.Context, src types.Image) error {\r\n\tsrcInfo := src.ConfigInfo()\r\n\tif srcInfo.Digest != \"\" {\r\n\t\tconfigBlob, err := src.ConfigBlob(ctx)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"Error reading config blob %s\", srcInfo.Digest)\r\n\t\t}\r\n\t\tdestInfo, err := func() (types.BlobInfo, error) {\r\n\t\t\tprogressPool, progressCleanup := c.newProgressPool(ctx)\r\n\t\t\tdefer progressCleanup()\r\n\t\t\tbar := c.createProgressBar(progressPool, srcInfo, \"config\", \"done\")\r\n\t\t\tdestInfo, err := c.copyBlobFromStream(ctx, bytes.NewReader(configBlob), srcInfo, nil, false, true, bar)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn types.BlobInfo{}, err\r\n\t\t\t}\r\n\t\t\tbar.SetTotal(int64(len(configBlob)), true)\r\n\t\t\treturn destInfo, nil\r\n\t\t}()\r\n\t\tif err != nil {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tif destInfo.Digest != srcInfo.Digest {\r\n\t\t\treturn errors.Errorf(\"Internal error: copying uncompressed config blob %s changed digest to %s\", srcInfo.Digest, destInfo.Digest)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":361,"reference":"\/\/ copyConfig copies config.json, if any, from src to dest.","result":"Copy the config blob.","score":[0,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc diffIDComputationGoroutine(dest chan<- diffIDResult, layerStream io.ReadCloser, decompressor compression.DecompressorFunc) {\r\n\tresult := diffIDResult{\r\n\t\tdigest: \"\",\r\n\t\terr:    errors.New(\"Internal error: unexpected panic in diffIDComputationGoroutine\"),\r\n\t}\r\n\tdefer func() { dest <- result }()\r\n\tdefer layerStream.Close()\r\n\tresult.digest, result.err = computeDiffID(layerStream, decompressor)\r\n}","code-length":134,"reference":"\/\/ diffIDComputationGoroutine reads all input from layerStream, uncompresses using decompressor if necessary, and sends its digest, and status, if any, to dest.","result":"Avoid panic.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc computeDiffID(stream io.Reader, decompressor compression.DecompressorFunc) (digest.Digest, error) {\r\n\tif decompressor != nil {\r\n\t\ts, err := decompressor(stream)\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", err\r\n\t\t}\r\n\t\tdefer s.Close()\r\n\t\tstream = s\r\n\t}\r\n\treturn digest.Canonical.FromReader(stream)\r\n}","code-length":115,"reference":"\/\/ computeDiffID reads all input from layerStream, uncompresses it using decompressor if necessary, and returns its digest.","result":"Compute the diff ID.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc compressGoroutine(dest *io.PipeWriter, src io.Reader) {\r\n\terr := errors.New(\"Internal error: unexpected panic in compressGoroutine\")\r\n\tdefer func() {\r\n\t\tdest.CloseWithError(err)\r\n\t}()\r\n\tzipper := pgzip.NewWriter(dest)\r\n\tdefer zipper.Close()\r\n\t_, err = io.Copy(zipper, src)\r\n}","code-length":113,"reference":"\/\/ compressGoroutine reads all input from src and writes its compressed equivalent to dest.","result":"Compress goroutine.","score":[0,0.0391]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newDockerClient(sys *types.SystemContext) (*dockerclient.Client, error) {\r\n\thost := dockerclient.DefaultDockerHost\r\n\tif sys != nil && sys.DockerDaemonHost != \"\" {\r\n\t\thost = sys.DockerDaemonHost\r\n\t}\r\n\tient *http.Client\r\n\tif url.Scheme != \"unix\" {\r\n\t\tif url.Scheme == \"http\" {\r\n\t\t\thttpClient = httpConfig()\r\n\t\t} else {\r\n\t\t\thc, err := tlsConfig(sys)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\thttpClient = hc\r\n\t\t}\r\n\t}\r\n\treturn dockerclient.NewClient(host, defaultAPIVersion, httpClient, nil)\r\n}","code-length":196,"reference":"\/\/ NewDockerClient initializes a new API client based on the passed SystemContext.","result":"Create a new client.","score":[0.0611,0.1674]}
{"code":"\/*is used to<extra_id_0>\r\nfunc defaultPolicyPath(sys *types.SystemContext) string {\r\n\tif sys != nil {\r\n\t\tif sys.SignaturePolicyPath != \"\" {\r\n\t\t\treturn sys.SignaturePolicyPath\r\n\t\t}\r\n\t\tif sys.RootForImplicitAbsolutePaths != \"\" {\r\n\t\t\treturn filepath.Join(sys.RootForImplicitAbsolutePaths, systemDefaultPolicyPath)\r\n\t\t}\r\n\t}\r\n\treturn systemDefaultPolicyPath\r\n}","code-length":116,"reference":"\/\/ defaultPolicyPath returns a path to the default policy of the system.","result":"Generate the default policy path.","score":[0.122,0.2262]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPolicyFromFile(fileName string) (*Policy, error) {\r\n\tcontents, err := ioutil.ReadFile(fileName)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tpolicy, err := NewPolicyFromBytes(contents)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrapf(err, \"invalid policy in %q\", fileName)\r\n\t}\r\n\treturn policy, nil\r\n}","code-length":116,"reference":"\/\/ NewPolicyFromFile returns a policy configured in the specified file.","result":"Create a new policy from a file.","score":[0.1385,0.1546]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPolicyFromBytes(data []byte) (*Policy, error) {\r\n\tp := Policy{}\r\n\tif err := json.Unmarshal(data, &p); err != nil {\r\n\t\treturn nil, InvalidPolicyFormatError(err.Error())\r\n\t}\r\n\treturn &p, nil\r\n}","code-length":81,"reference":"\/\/ NewPolicyFromBytes returns a policy parsed from the specified blob.\n\/\/ Use this function instead of calling json.Unmarshal directly.","result":"Create a new policy from a byte array.","score":[0.0462,0.0838]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newPolicyRequirementFromJSON(data []byte) (PolicyRequirement, error) {\r\n\tvar typeField prCommon\r\n\tif err := json.Unmarshal(data, &typeField); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar res PolicyRequirement\r\n\tswitch typeField.Type {\r\n\tcase prTypeInsecureAcceptAnything:\r\n\t\tres = &prInsecureAcceptAnything{}\r\n\tcase prTypeReject:\r\n\t\tres = &prReject{}\r\n\tcase prTypeSignedBy:\r\n\t\tres = &prSignedBy{}\r\n\tcase prTypeSignedBaseLayer:\r\n\t\tres = &prSignedBaseLayer{}\r\n\tdefault:\r\n\t\treturn nil, InvalidPolicyFormatError(fmt.Sprintf(\"Unknown policy requirement type \\\"%s\\\"\", typeField.Type))\r\n\t}\r\n\tif err := json.Unmarshal(data, &res); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn res, nil\r\n}","code-length":248,"reference":"\/\/ newPolicyRequirementFromJSON parses JSON data into a PolicyRequirement implementation.","result":"Create a new PolicyRequirement from a JSON string.","score":[0.1613,0.1685]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newPRSignedBy(keyType sbKeyType, keyPath string, keyData []byte, signedIdentity PolicyReferenceMatch) (*prSignedBy, error) {\r\n\tif !keyType.IsValid() {\r\n\t\treturn nil, InvalidPolicyFormatError(fmt.Sprintf(\"invalid keyType \\\"%s\\\"\", keyType))\r\n\t}\r\n\tif len(keyPath) > 0 && len(keyData) > 0 {\r\n\t\treturn nil, InvalidPolicyFormatError(\"keyType and keyData cannot be used simultaneously\")\r\n\t}\r\n\tif signedIdentity == nil {\r\n\t\treturn nil, InvalidPolicyFormatError(\"signedIdentity not specified\")\r\n\t}\r\n\treturn &prSignedBy{\r\n\t\tprCommon:       prCommon{Type: prTypeSignedBy},\r\n\t\tKeyType:        keyType,\r\n\t\tKeyPath:        keyPath,\r\n\t\tKeyData:        keyData,\r\n\t\tSignedIdentity: signedIdentity,\r\n\t}, nil\r\n}","code-length":232,"reference":"\/\/ newPRSignedBy returns a new prSignedBy if parameters are valid.","result":"Create a PR object to represent the signed by policy.","score":[0.1086,0.05]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newPRSignedByKeyPath(keyType sbKeyType, keyPath string, signedIdentity PolicyReferenceMatch) (*prSignedBy, error) {\r\n\treturn newPRSignedBy(keyType, keyPath, nil, signedIdentity)\r\n}","code-length":61,"reference":"\/\/ newPRSignedByKeyPath is NewPRSignedByKeyPath, except it returns the private type.","result":"Create a new PRSignedBy.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPRSignedByKeyPath(keyType sbKeyType, keyPath string, signedIdentity PolicyReferenceMatch) (PolicyRequirement, error) {\r\n\treturn newPRSignedByKeyPath(keyType, keyPath, signedIdentity)\r\n}","code-length":58,"reference":"\/\/ NewPRSignedByKeyPath returns a new \"signedBy\" PolicyRequirement using a KeyPath","result":"Create a new PR signed by path.","score":[0.1488,0.1031]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newPRSignedByKeyData(keyType sbKeyType, keyData []byte, signedIdentity PolicyReferenceMatch) (*prSignedBy, error) {\r\n\treturn newPRSignedBy(keyType, \"\", keyData, signedIdentity)\r\n}","code-length":63,"reference":"\/\/ newPRSignedByKeyData is NewPRSignedByKeyData, except it returns the private type.","result":"Create a new PRSignedBy object.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPRSignedByKeyData(keyType sbKeyType, keyData []byte, signedIdentity PolicyReferenceMatch) (PolicyRequirement, error) {\r\n\treturn newPRSignedByKeyData(keyType, keyData, signedIdentity)\r\n}","code-length":61,"reference":"\/\/ NewPRSignedByKeyData returns a new \"signedBy\" PolicyRequirement using a KeyData","result":"Create a new PR signed by data.","score":[0.1488,0.1031]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (kt sbKeyType) IsValid() bool {\r\n\tswitch kt {\r\n\tcase SBKeyTypeGPGKeys, SBKeyTypeSignedByGPGKeys,\r\n\t\tSBKeyTypeX509Certificates, SBKeyTypeSignedByX509CAs:\r\n\t\treturn true\r\n\tdefault:\r\n\t\treturn false\r\n\t}\r\n}","code-length":89,"reference":"\/\/ IsValid returns true iff kt is a recognized value","result":"Validate the signature of the signature of the signature function.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newPRSignedBaseLayer(baseLayerIdentity PolicyReferenceMatch) (*prSignedBaseLayer, error) {\r\n\tif baseLayerIdentity == nil {\r\n\t\treturn nil, InvalidPolicyFormatError(\"baseLayerIdentity not specified\")\r\n\t}\r\n\treturn &prSignedBaseLayer{\r\n\t\tprCommon:          prCommon{Type: prTypeSignedBaseLayer},\r\n\t\tBaseLayerIdentity: baseLayerIdentity,\r\n\t}, nil\r\n}","code-length":113,"reference":"\/\/ newPRSignedBaseLayer is NewPRSignedBaseLayer, except it returns the private type.","result":"Create a new PR.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newPolicyReferenceMatchFromJSON(data []byte) (PolicyReferenceMatch, error) {\r\n\tvar typeField prmCommon\r\n\tif err := json.Unmarshal(data, &typeField); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar res PolicyReferenceMatch\r\n\tswitch typeField.Type {\r\n\tcase prmTypeMatchExact:\r\n\t\tres = &prmMatchExact{}\r\n\tcase prmTypeMatchRepoDigestOrExact:\r\n\t\tres = &prmMatchRepoDigestOrExact{}\r\n\tcase prmTypeMatchRepository:\r\n\t\tres = &prmMatchRepository{}\r\n\tcase prmTypeExactReference:\r\n\t\tres = &prmExactReference{}\r\n\tcase prmTypeExactRepository:\r\n\t\tres = &prmExactRepository{}\r\n\tdefault:\r\n\t\treturn nil, InvalidPolicyFormatError(fmt.Sprintf(\"Unknown policy reference match type \\\"%s\\\"\", typeField.Type))\r\n\t}\r\n\tif err := json.Unmarshal(data, &res); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn res, nil\r\n}","code-length":283,"reference":"\/\/ newPolicyReferenceMatchFromJSON parses JSON data into a PolicyReferenceMatch implementation.","result":"Create a new PolicyReferenceMatch from JSON.","score":[0.1392,0.1149]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newPRMExactReference(dockerReference string) (*prmExactReference, error) {\r\n\tref, err := reference.ParseNormalizedNamed(dockerReference)\r\n\tif err != nil {\r\n\t\treturn nil, InvalidPolicyFormatError(fmt.Sprintf(\"Invalid format of dockerReference %s: %s\", dockerReference, err.Error()))\r\n\t}\r\n\tif reference.IsNameOnly(ref) {\r\n\t\treturn nil, InvalidPolicyFormatError(fmt.Sprintf(\"dockerReference %s contains neither a tag nor digest\", dockerReference))\r\n\t}\r\n\treturn &prmExactReference{\r\n\t\tprmCommon:       prmCommon{Type: prmTypeExactReference},\r\n\t\tDockerReference: dockerReference,\r\n\t}, nil\r\n}","code-length":189,"reference":"\/\/ newPRMExactReference is NewPRMExactReference, except it resturns the private type.","result":"Create a PRMExactReference object.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newPRMExactRepository(dockerRepository string) (*prmExactRepository, error) {\r\n\tif _, err := reference.ParseNormalizedNamed(dockerRepository); err != nil {\r\n\t\treturn nil, InvalidPolicyFormatError(fmt.Sprintf(\"Invalid format of dockerRepository %s: %s\", dockerRepository, err.Error()))\r\n\t}\r\n\treturn &prmExactRepository{\r\n\t\tprmCommon:        prmCommon{Type: prmTypeExactRepository},\r\n\t\tDockerRepository: dockerRepository,\r\n\t}, nil\r\n}","code-length":139,"reference":"\/\/ newPRMExactRepository is NewPRMExactRepository, except it resturns the private type.","result":"Create a PRMExactRepository.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newImageSource(imageRef storageReference) (*storageImageSource, error) {\r\n\t\r\n\timg, err := imageRef.resolveImage()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\timage := &storageImageSource{\r\n\t\timageRef:       imageRef,\r\n\t\timage:          img,\r\n\t\tlayerPosition:  make(map[digest.Digest]int),\r\n\t\tSignatureSizes: []int{},\r\n\t}\r\n\tif img.Metadata != \"\" {\r\n\t\tif err := json.Unmarshal([]byte(img.Metadata), image); err != nil {\r\n\t\t\treturn nil, errors.Wrap(err, \"error decoding metadata for source image\")\r\n\t\t}\r\n\t}\r\n\treturn image, nil\r\n}","code-length":204,"reference":"\/\/ newImageSource sets up an image for reading.","result":"Create a new image source.","score":[0.1319,0.0649]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageImageSource) getBlobAndLayerID(info types.BlobInfo) (rc io.ReadCloser, n int64, layerID string, err error) {\r\n\tvar layer storage.Layer\r\n\tvar diffOptions *storage.DiffOptions\r\n\t\r\n\terr = info.Digest.Validate()\r\n\tif err != nil {\r\n\t\treturn nil, -1, \"\", err\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tlayers, err := s.imageRef.transport.store.LayersByUncompressedDigest(info.Digest)\r\n\t\r\n\tif len(layers) == 0 {\r\n\t\tb, err := s.imageRef.transport.store.ImageBigData(s.image.ID, info.Digest.String())\r\n\t\tif err != nil {\r\n\t\t\treturn nil, -1, \"\", err\r\n\t\t}\r\n\t\tr := bytes.NewReader(b)\r\n\t\tlogrus.Debugf(\"exporting opaque data as blob %q\", info.Digest.String())\r\n\t\treturn ioutil.NopCloser(r), int64(r.Len()), \"\", nil\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\ts.getBlobMutex.Lock()\r\n\ti := s.layerPosition[info.Digest]\r\n\ts.layerPosition[info.Digest] = i + 1\r\n\ts.getBlobMutex.Unlock()\r\n\tif len(layers) > 0 {\r\n\t\tlayer = layers[i%len(layers)]\r\n\t}\r\n\t\r\n\t\r\n\tnoCompression := archive.Uncompressed\r\n\tdiffOptions = &storage.DiffOptions{\r\n\t\tCompression: &noCompression,\r\n\t}\r\n\tif layer.UncompressedSize < 0 {\r\n\t\tn = -1\r\n\t} else {\r\n\t\tn = layer.UncompressedSize\r\n\t}\r\n\tlogrus.Debugf(\"exporting filesystem layer %q without compression for blob %q\", layer.ID, info.Digest)\r\n\trc, err = s.imageRef.transport.store.Diff(\"\", layer.ID, diffOptions)\r\n\tif err != nil {\r\n\t\treturn nil, -1, \"\", err\r\n\t}\r\n\treturn rc, n, layer.ID, err\r\n}","code-length":545,"reference":"\/\/ getBlobAndLayer reads the data blob or filesystem layer which matches the digest and size, if given.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageImageDestination) computeID(m manifest.Manifest) string {\r\n\t\r\n\t\r\n\t\r\n\tvar diffIDs []digest.Digest\r\n\tswitch m := m.(type) {\r\n\tcase *manifest.Schema1:\r\n\t\t\r\n\t\t\r\n\t\tfor i, compat := range m.ExtractedV1Compatibility {\r\n\t\t\tif compat.ThrowAway {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tblobSum := m.FSLayers[i].BlobSum\r\n\t\t\tdiffID, ok := s.blobDiffIDs[blobSum]\r\n\t\t\tif !ok {\r\n\t\t\t\tlogrus.Infof(\"error looking up diffID for layer %q\", blobSum.String())\r\n\t\t\t\treturn \"\"\r\n\t\t\t}\r\n\t\t\tdiffIDs = append([]digest.Digest{diffID}, diffIDs...)\r\n\t\t}\r\n\tcase *manifest.Schema2, *manifest.OCI1:\r\n\t\t\r\n\t\t\r\n\tdefault:\r\n\t\treturn \"\"\r\n\t}\r\n\tid, err := m.ImageID(diffIDs)\r\n\tif err != nil {\r\n\t\treturn \"\"\r\n\t}\r\n\treturn id\r\n}","code-length":295,"reference":"\/\/ computeID computes a recommended image ID based on information we have so far.  If\n\/\/ the manifest is not of a type that we recognize, we return an empty value, indicating\n\/\/ that since we don't have a recommendation, a random ID should be used if one needs\n\/\/ to be allocated.","result":"Compute the image ID.","score":[0.0,0.0312]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageImageDestination) PutManifest(ctx context.Context, manifestBlob []byte) error {\r\n\tif s.imageRef.named != nil {\r\n\t\tif digested, ok := s.imageRef.named.(reference.Digested); ok {\r\n\t\t\tmatches, err := manifest.MatchesDigest(manifestBlob, digested.Digest())\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif !matches {\r\n\t\t\t\treturn fmt.Errorf(\"Manifest does not match expected digest %s\", digested.Digest())\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\ts.manifest = make([]byte, len(manifestBlob))\r\n\tcopy(s.manifest, manifestBlob)\r\n\treturn nil\r\n}","code-length":193,"reference":"\/\/ PutManifest writes the manifest to the destination.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageImageDestination) PutSignatures(ctx context.Context, signatures [][]byte) error {\r\n\tsizes := []int{}\r\n\tsigblob := []byte{}\r\n\tfor _, sig := range signatures {\r\n\t\tsizes = append(sizes, len(sig))\r\n\t\tnewblob := make([]byte, len(sigblob)+len(sig))\r\n\t\tcopy(newblob, sigblob)\r\n\t\tcopy(newblob[len(sigblob):], sig)\r\n\t\tsigblob = newblob\r\n\t}\r\n\ts.signatures = sigblob\r\n\ts.SignatureSizes = sizes\r\n\treturn nil\r\n}","code-length":163,"reference":"\/\/ PutSignatures records the image's signatures for committing as a single data blob.","result":"Generate the code.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newImage(ctx context.Context, sys *types.SystemContext, s storageReference) (types.ImageCloser, error) {\r\n\tsrc, err := newImageSource(s)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\timg, err := image.FromSource(ctx, sys, src)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tsize, err := src.getSize()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &storageImageCloser{ImageCloser: img, size: size}, nil\r\n}","code-length":163,"reference":"\/\/ newImage creates an image that also knows its size","result":"Create a new image.","score":[0,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newImageSource(ctx context.Context, sys *types.SystemContext, ref ociArchiveReference) (types.ImageSource, error) {\r\n\ttempDirRef, err := createUntarTempDir(ref)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"error creating temp directory\")\r\n\t}\r\n\tunpackedSrc, err := tempDirRef.ociRefExtracted.NewImageSource(ctx, sys)\r\n\tif err != nil {\r\n\t\tif err := tempDirRef.deleteTempDir(); err != nil {\r\n\t\t\treturn nil, errors.Wrapf(err, \"error deleting temp directory %q\", tempDirRef.tempDirectory)\r\n\t\t}\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &ociArchiveImageSource{ref: ref,\r\n\t\tunpackedSrc: unpackedSrc,\r\n\t\ttempDirRef:  tempDirRef}, nil\r\n}","code-length":226,"reference":"\/\/ newImageSource returns an ImageSource for reading from an existing directory.\n\/\/ newImageSource untars the file and saves it in a temp directory","result":"Create a new image source.","score":[0.0066,0.0236]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadManifestDescriptor(imgRef types.ImageReference) (imgspecv1.Descriptor, error) {\r\n\tociArchRef, ok := imgRef.(ociArchiveReference)\r\n\tif !ok {\r\n\t\treturn imgspecv1.Descriptor{}, errors.Errorf(\"error typecasting, need type ociArchiveReference\")\r\n\t}\r\n\ttempDirRef, err := createUntarTempDir(ociArchRef)\r\n\tif err != nil {\r\n\t\treturn imgspecv1.Descriptor{}, errors.Wrap(err, \"error creating temp directory\")\r\n\t}\r\n\tdefer tempDirRef.deleteTempDir()\r\n\tdescriptor, err := ocilayout.LoadManifestDescriptor(tempDirRef.ociRefExtracted)\r\n\tif err != nil {\r\n\t\treturn imgspecv1.Descriptor{}, errors.Wrap(err, \"error loading index\")\r\n\t}\r\n\treturn descriptor, nil\r\n}","code-length":227,"reference":"\/\/ LoadManifestDescriptor loads the manifest","result":"Load the manifest descriptor.","score":[0.3519,0.6009]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *ociArchiveImageSource) Close() error {\r\n\tdefer s.tempDirRef.deleteTempDir()\r\n\treturn s.unpackedSrc.Close()\r\n}","code-length":51,"reference":"\/\/ Close removes resources associated with an initialized ImageSource, if any.\n\/\/ Close deletes the temporary directory at dst","result":"Generate the generated code.","score":[0.0075,0.0286]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (os *orderedSet) append(s string) {\r\n\tif _, ok := os.included[s]; !ok {\r\n\t\tos.list = append(os.list, s)\r\n\t\tos.included[s] = struct{}{}\r\n\t}\r\n}","code-length":76,"reference":"\/\/ append adds s to the end of os, only if it is not included already.","result":"Append to an orderedSet.","score":[0.0159,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isMultiImage(ctx context.Context, img types.UnparsedImage) (bool, error) {\r\n\t_, mt, err := img.Manifest(ctx)\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\treturn manifest.MIMETypeIsMultiImage(mt), nil\r\n}","code-length":84,"reference":"\/\/ isMultiImage returns true if img is a list of images","result":"Detect multi.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc lockPath(path string) {\r\n\tpl := func() *pathLock {\r\n\t\tpathLocksMutex.Lock()\r\n\t\tdefer pathLocksMutex.Unlock()\r\n\t\tpl, ok := pathLocks[path]\r\n\t\tif ok {\r\n\t\t\tpl.refCount++\r\n\t\t} else {\r\n\t\t\tpl = &pathLock{refCount: 1, mutex: sync.Mutex{}}\r\n\t\t\tpathLocks[path] = pl\r\n\t\t}\r\n\t\treturn pl\r\n\t}()\r\n\tpl.mutex.Lock()\r\n}","code-length":146,"reference":"\/\/ lockPath obtains the pathLock for path.\n\/\/ The caller must call unlockPath eventually.","result":"Lock a path.","score":[0.0104,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc unlockPath(path string) {\r\n\tpathLocksMutex.Lock()\r\n\tdefer pathLocksMutex.Unlock()\r\n\tpl, ok := pathLocks[path]\r\n\tif !ok {\r\n\t\t\r\n\t\tpanic(fmt.Sprintf(\"Internal error: unlocking nonexistent lock for path %s\", path))\r\n\t}\r\n\tpl.mutex.Unlock()\r\n\tpl.refCount--\r\n\tif pl.refCount == 0 {\r\n\t\tdelete(pathLocks, path)\r\n\t}\r\n}","code-length":135,"reference":"\/\/ unlockPath releases the pathLock for path.","result":"Unlock a path.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (bdc *cache) view(fn func(tx *bolt.Tx) error) (retErr error) {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif _, err := os.Lstat(bdc.path); err != nil && os.IsNotExist(err) {\r\n\t\treturn err\r\n\t}\r\n\tlockPath(bdc.path)\r\n\tdefer unlockPath(bdc.path)\r\n\tdb, err := bolt.Open(bdc.path, 0600, &bolt.Options{ReadOnly: true})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer func() {\r\n\t\tif err := db.Close(); retErr == nil && err != nil {\r\n\t\t\tretErr = err\r\n\t\t}\r\n\t}()\r\n\treturn db.View(fn)\r\n}","code-length":219,"reference":"\/\/ view returns runs the specified fn within a read-only transaction on the database.","result":"Generate the code.","score":[0.0104,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (bdc *cache) update(fn func(tx *bolt.Tx) error) (retErr error) {\r\n\tlockPath(bdc.path)\r\n\tdefer unlockPath(bdc.path)\r\n\tdb, err := bolt.Open(bdc.path, 0600, nil)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer func() {\r\n\t\tif err := db.Close(); retErr == nil && err != nil {\r\n\t\t\tretErr = err\r\n\t\t}\r\n\t}()\r\n\treturn db.Update(fn)\r\n}","code-length":156,"reference":"\/\/ update returns runs the specified fn within a read-write transaction on the database.","result":"Update the cache.","score":[0.0104,0.0775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (bdc *cache) uncompressedDigest(tx *bolt.Tx, anyDigest digest.Digest) digest.Digest {\r\n\tif b := tx.Bucket(uncompressedDigestBucket); b != nil {\r\n\t\tif uncompressedBytes := b.Get([]byte(anyDigest.String())); uncompressedBytes != nil {\r\n\t\t\td, err := digest.Parse(string(uncompressedBytes))\r\n\t\t\tif err == nil {\r\n\t\t\t\treturn d\r\n\t\t\t}\r\n\t\t\t\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tif b := tx.Bucket(digestByUncompressedBucket); b != nil {\r\n\t\tif b = b.Bucket([]byte(anyDigest.String())); b != nil {\r\n\t\t\tc := b.Cursor()\r\n\t\t\tif k, _ := c.First(); k != nil {\r\n\t\t\t\treturn anyDigest\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn \"\"\r\n}","code-length":242,"reference":"\/\/ uncompressedDigest implements BlobInfoCache.UncompressedDigest within the provided read-only transaction.","result":"Find the digest by uncompressedDigest.","score":[0.108,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (bdc *cache) appendReplacementCandidates(candidates []prioritize.CandidateWithTime, scopeBucket *bolt.Bucket, digest digest.Digest) []prioritize.CandidateWithTime {\r\n\tb := scopeBucket.Bucket([]byte(digest.String()))\r\n\tif b == nil {\r\n\t\treturn candidates\r\n\t}\r\n\t_ = b.ForEach(func(k, v []byte) error {\r\n\t\tt := time.Time{}\r\n\t\tif err := t.UnmarshalBinary(v); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tcandidates = append(candidates, prioritize.CandidateWithTime{\r\n\t\t\tCandidate: types.BICReplacementCandidate{\r\n\t\t\t\tDigest:   digest,\r\n\t\t\t\tLocation: types.BICLocationReference{Opaque: string(k)},\r\n\t\t\t},\r\n\t\t\tLastSeen: t,\r\n\t\t})\r\n\t\treturn nil\r\n\t})\r\n\treturn candidates\r\n}","code-length":244,"reference":"\/\/ appendReplacementCandiates creates prioritize.CandidateWithTime values for digest in scopeBucket, and returns the result of appending them to candidates.","result":"Append replacement candidates to the cache.","score":[0.0311,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc indexExists(ref ociReference) bool {\r\n\t_, err := os.Stat(ref.indexPath())\r\n\tif err == nil {\r\n\t\treturn true\r\n\t}\r\n\tif os.IsNotExist(err) {\r\n\t\treturn false\r\n\t}\r\n\treturn true\r\n}","code-length":83,"reference":"\/\/ indexExists checks whether the index location specified in the OCI reference exists.\n\/\/ The implementation is opinionated, since in case of unexpected errors false is returned","result":"Check if the index exists .","score":[0.0082,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *copier) createSignature(manifest []byte, keyIdentity string) ([]byte, error) {\r\n\tmech, err := signature.NewGPGSigningMechanism()\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Error initializing GPG\")\r\n\t}\r\n\tdefer mech.Close()\r\n\tif err := mech.SupportsSigning(); err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Signing not supported\")\r\n\t}\r\n\tdockerReference := c.dest.Reference().DockerReference()\r\n\tif dockerReference == nil {\r\n\t\treturn nil, errors.Errorf(\"Cannot determine canonical Docker reference for destination %s\", transports.ImageName(c.dest.Reference()))\r\n\t}\r\n\tc.Printf(\"Signing manifest\\n\")\r\n\tnewSig, err := signature.SignDockerManifest(manifest, dockerReference.String(), mech, keyIdentity)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Error creating signature\")\r\n\t}\r\n\treturn newSig, nil\r\n}","code-length":268,"reference":"\/\/ createSignature creates a new signature of manifest using keyIdentity.","result":"Generate the signature for the copy.","score":[0.0991,0.0521]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseReference(reference string) (types.ImageReference, error) {\r\n\tdir, image := internal.SplitPathAndImage(reference)\r\n\treturn NewReference(dir, image)\r\n}","code-length":55,"reference":"\/\/ ParseReference converts a string, which should not start with the ImageTransport.Name prefix, into an OCI ImageReference.","result":"Parse reference.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewReference(dir, image string) (types.ImageReference, error) {\r\n\tresolved, err := explicitfilepath.ResolvePathToFullyExplicit(dir)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err := internal.ValidateOCIPath(dir); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err = internal.ValidateImageName(image); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn ociReference{dir: dir, resolvedDir: resolved, image: image}, nil\r\n}","code-length":149,"reference":"\/\/ NewReference returns an OCI reference for a directory and a image.\n\/\/\n\/\/ We do not expose an API supplying the resolvedDir; we could, but recomputing it\n\/\/ is generally cheap enough that we prefer being confident about the properties of resolvedDir.","result":"Create a new reference.","score":[0.0,0.0128]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ref ociReference) getIndex() (*imgspecv1.Index, error) {\r\n\tindexJSON, err := os.Open(ref.indexPath())\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer indexJSON.Close()\r\n\tindex := &imgspecv1.Index{}\r\n\tif err := json.NewDecoder(indexJSON).Decode(index); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn index, nil\r\n}","code-length":134,"reference":"\/\/ getIndex returns a pointer to the index references by this ociReference. If an error occurs opening an index nil is returned together\n\/\/ with an error.","result":"Get the index of the image.","score":[0.0082,0.0402]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadManifestDescriptor(imgRef types.ImageReference) (imgspecv1.Descriptor, error) {\r\n\tociRef, ok := imgRef.(ociReference)\r\n\tif !ok {\r\n\t\treturn imgspecv1.Descriptor{}, errors.Errorf(\"error typecasting, need type ociRef\")\r\n\t}\r\n\treturn ociRef.getManifestDescriptor()\r\n}","code-length":100,"reference":"\/\/ LoadManifestDescriptor loads the manifest descriptor to be used to retrieve the image name\n\/\/ when pulling an image","result":"Load the manifest descriptor.","score":[0.0106,0.0857]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ref ociReference) blobPath(digest digest.Digest, sharedBlobDir string) (string, error) {\r\n\tif err := digest.Validate(); err != nil {\r\n\t\treturn \"\", errors.Wrapf(err, \"unexpected digest reference %s\", digest)\r\n\t}\r\n\tblobDir := filepath.Join(ref.dir, \"blobs\")\r\n\tif sharedBlobDir != \"\" {\r\n\t\tblobDir = sharedBlobDir\r\n\t}\r\n\treturn filepath.Join(blobDir, digest.Algorithm().String(), digest.Hex()), nil\r\n}","code-length":142,"reference":"\/\/ blobPath returns a path for a blob within a directory using OCI image-layout conventions.","result":"Generate the blob path.","score":[0.0204,0.036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SignDockerManifest(m []byte, dockerReference string, mech SigningMechanism, keyIdentity string) ([]byte, error) {\r\n\tmanifestDigest, err := manifest.Digest(m)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tsig := newUntrustedSignature(manifestDigest, dockerReference)\r\n\treturn sig.sign(mech, keyIdentity)\r\n}","code-length":105,"reference":"\/\/ SignDockerManifest returns a signature for manifest as the specified dockerReference,\n\/\/ using mech and keyIdentity.","result":"Sign the manifest.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc VerifyDockerManifestSignature(unverifiedSignature, unverifiedManifest []byte,\r\n\texpectedDockerReference string, mech SigningMechanism, expectedKeyIdentity string) (*Signature, error) {\r\n\texpectedRef, err := reference.ParseNormalizedNamed(expectedDockerReference)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tsig, err := verifyAndExtractSignature(mech, unverifiedSignature, signatureAcceptanceRules{\r\n\t\tvalidateKeyIdentity: func(keyIdentity string) error {\r\n\t\t\tif keyIdentity != expectedKeyIdentity {\r\n\t\t\t\treturn InvalidSignatureError{msg: fmt.Sprintf(\"Signature by %s does not match expected fingerprint %s\", keyIdentity, expectedKeyIdentity)}\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t},\r\n\t\tvalidateSignedDockerReference: func(signedDockerReference string) error {\r\n\t\t\tsignedRef, err := reference.ParseNormalizedNamed(signedDockerReference)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn InvalidSignatureError{msg: fmt.Sprintf(\"Invalid docker reference %s in signature\", signedDockerReference)}\r\n\t\t\t}\r\n\t\t\tif signedRef.String() != expectedRef.String() {\r\n\t\t\t\treturn InvalidSignatureError{msg: fmt.Sprintf(\"Docker reference %s does not match %s\",\r\n\t\t\t\t\tsignedDockerReference, expectedDockerReference)}\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t},\r\n\t\tvalidateSignedDockerManifestDigest: func(signedDockerManifestDigest digest.Digest) error {\r\n\t\t\tmatches, err := manifest.MatchesDigest(unverifiedManifest, signedDockerManifestDigest)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif !matches {\r\n\t\t\t\treturn InvalidSignatureError{msg: fmt.Sprintf(\"Signature for docker digest %q does not match\", signedDockerManifestDigest)}\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t},\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn sig, nil\r\n}","code-length":494,"reference":"\/\/ VerifyDockerManifestSignature checks that unverifiedSignature uses expectedKeyIdentity to sign unverifiedManifest as expectedDockerReference,\n\/\/ using mech.","result":"Verify signatures for the manifest.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newOpenshiftClient(ref openshiftReference) (*openshiftClient, error) {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tcmdConfig := defaultClientConfig()\r\n\tlogrus.Debugf(\"cmdConfig: %#v\", cmdConfig)\r\n\trestConfig, err := cmdConfig.ClientConfig()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tlogrus.Debugf(\"restConfig: %#v\", restConfig)\r\n\tbaseURL, httpClient, err := restClientFor(restConfig)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tlogrus.Debugf(\"URL: %#v\", *baseURL)\r\n\tif httpClient == nil {\r\n\t\thttpClient = http.DefaultClient\r\n\t}\r\n\treturn &openshiftClient{\r\n\t\tref:         ref,\r\n\t\tbaseURL:     baseURL,\r\n\t\thttpClient:  httpClient,\r\n\t\tbearerToken: restConfig.BearerToken,\r\n\t\tusername:    restConfig.Username,\r\n\t\tpassword:    restConfig.Password,\r\n\t}, nil\r\n}","code-length":289,"reference":"\/\/ newOpenshiftClient creates a new openshiftClient for the specified reference.","result":"Create a new OpenshiftClient.","score":[0.1008,0.3132]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *openshiftClient) doRequest(ctx context.Context, method, path string, requestBody []byte) ([]byte, error) {\r\n\turl := *c.baseURL\r\n\turl.Path = path\r\n\tvar requestBodyReader io.Reader\r\n\tif requestBody != nil {\r\n\t\tlogrus.Debugf(\"Will send body: %s\", requestBody)\r\n\t\trequestBodyReader = bytes.NewReader(requestBody)\r\n\t}\r\n\treq, err := http.NewRequest(method, url.String(), requestBodyReader)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treq = req.WithContext(ctx)\r\n\tif len(c.bearerToken) != 0 {\r\n\t\treq.Header.Set(\"Authorization\", \"Bearer \"+c.bearerToken)\r\n\t} else if len(c.username) != 0 {\r\n\t\treq.SetBasicAuth(c.username, c.password)\r\n\t}\r\n\treq.Header.Set(\"Accept\", \"application\/json, *\/*\")\r\n\treq.Header.Set(\"User-Agent\", fmt.Sprintf(\"skopeo\/%s\", version.Version))\r\n\tif requestBody != nil {\r\n\t\treq.Header.Set(\"Content-Type\", \"application\/json\")\r\n\t}\r\n\tlogrus.Debugf(\"%s %s\", method, url.String())\r\n\tres, err := c.httpClient.Do(req)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer res.Body.Close()\r\n\tbody, err := ioutil.ReadAll(res.Body)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tlogrus.Debugf(\"Got body: %s\", body)\r\n\t\r\n\tlogrus.Debugf(\"Got content-type: %s\", res.Header.Get(\"Content-Type\"))\r\n\tvar status status\r\n\tstatusValid := false\r\n\tif err := json.Unmarshal(body, &status); err == nil && len(status.Status) > 0 {\r\n\t\tstatusValid = true\r\n\t}\r\n\tswitch {\r\n\tcase res.StatusCode == http.StatusSwitchingProtocols:\r\n\t\tif statusValid && status.Status != \"Success\" {\r\n\t\t\treturn nil, errors.New(status.Message)\r\n\t\t}\r\n\tcase res.StatusCode >= http.StatusOK && res.StatusCode <= http.StatusPartialContent:\r\n\t\t\r\n\tdefault:\r\n\t\tif statusValid {\r\n\t\t\treturn nil, errors.New(status.Message)\r\n\t\t}\r\n\t\treturn nil, errors.Errorf(\"HTTP error: status code: %d (%s), body: %s\", res.StatusCode, http.StatusText(res.StatusCode), string(body))\r\n\t}\r\n\treturn body, nil\r\n}","code-length":687,"reference":"\/\/ doRequest performs a correctly authenticated request to a specified path, and returns response body or an error object.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *openshiftClient) getImage(ctx context.Context, imageStreamImageName string) (*image, error) {\r\n\t\r\n\tpath := fmt.Sprintf(\"\/oapi\/v1\/namespaces\/%s\/imagestreamimages\/%s@%s\", c.ref.namespace, c.ref.stream, imageStreamImageName)\r\n\tbody, err := c.doRequest(ctx, \"GET\", path, nil)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tvar isi imageStreamImage\r\n\tif err := json.Unmarshal(body, &isi); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &isi.Image, nil\r\n}","code-length":186,"reference":"\/\/ getImage loads the specified image object.","result":"Fetch the image from the image stream.","score":[0.1921,0.1429]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *openshiftClient) convertDockerImageReference(ref string) (string, error) {\r\n\tparts := strings.SplitN(ref, \"\/\", 2)\r\n\tif len(parts) != 2 {\r\n\t\treturn \"\", errors.Errorf(\"Invalid format of docker reference %s: missing '\/'\", ref)\r\n\t}\r\n\treturn reference.Domain(c.ref.dockerReference) + \"\/\" + parts[1], nil\r\n}","code-length":111,"reference":"\/\/ convertDockerImageReference takes an image API DockerImageReference value and returns a reference we can actually use;\n\/\/ currently OpenShift stores the cluster-internal service IPs here, which are unusable from the outside.","result":"Convert docker image references.","score":[0.0004,0.0177]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *openshiftImageSource) ensureImageIsResolved(ctx context.Context) error {\r\n\tif s.docker != nil {\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\tpath := fmt.Sprintf(\"\/oapi\/v1\/namespaces\/%s\/imagestreams\/%s\", s.client.ref.namespace, s.client.ref.stream)\r\n\tbody, err := s.client.doRequest(ctx, \"GET\", path, nil)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tvar is imageStream\r\n\tif err := json.Unmarshal(body, &is); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tvar te *tagEvent\r\n\tfor _, tag := range is.Status.Tags {\r\n\t\tif tag.Tag != s.client.ref.dockerReference.Tag() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif len(tag.Items) > 0 {\r\n\t\t\tte = &tag.Items[0]\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif te == nil {\r\n\t\treturn errors.Errorf(\"No matching tag found\")\r\n\t}\r\n\tlogrus.Debugf(\"tag event %#v\", te)\r\n\tdockerRefString, err := s.client.convertDockerImageReference(te.DockerImageReference)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tlogrus.Debugf(\"Resolved reference %#v\", dockerRefString)\r\n\tdockerRef, err := docker.ParseReference(\"\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\td, err := dockerRef.NewImageSource(ctx, s.sys)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ts.docker = d\r\n\ts.imageStreamImageName = te.Image\r\n\treturn nil\r\n}","code-length":471,"reference":"\/\/ ensureImageIsResolved sets up s.docker and s.imageStreamImageName","result":"Resolve images.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newImageDestination(ctx context.Context, sys *types.SystemContext, ref openshiftReference) (types.ImageDestination, error) {\r\n\tclient, err := newOpenshiftClient(ref)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tdockerRefString := fmt.Sprintf(\"\r\n\tdockerRef, err := docker.ParseReference(dockerRefString)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdocker, err := dockerRef.NewImageDestination(ctx, sys)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &openshiftImageDestination{\r\n\t\tclient: client,\r\n\t\tdocker: docker,\r\n\t}, nil\r\n}","code-length":204,"reference":"\/\/ newImageDestination creates a new ImageDestination for the specified reference.","result":"Create an image destination.","score":[0,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newUntrustedSignature(dockerManifestDigest digest.Digest, dockerReference string) untrustedSignature {\r\n\t\r\n\t\r\n\tcreatorID := \"atomic \" + version.Version\r\n\ttimestamp := time.Now().Unix()\r\n\treturn untrustedSignature{\r\n\t\tUntrustedDockerManifestDigest: dockerManifestDigest,\r\n\t\tUntrustedDockerReference:      dockerReference,\r\n\t\tUntrustedCreatorID:            &creatorID,\r\n\t\tUntrustedTimestamp:            &timestamp,\r\n\t}\r\n}","code-length":128,"reference":"\/\/ newUntrustedSignature returns an untrustedSignature object with\n\/\/ the specified primary contents and appropriate metadata.","result":"Generate the signature.","score":[0.0075,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s untrustedSignature) MarshalJSON() ([]byte, error) {\r\n\tif s.UntrustedDockerManifestDigest == \"\" || s.UntrustedDockerReference == \"\" {\r\n\t\treturn nil, errors.New(\"Unexpected empty signature content\")\r\n\t}\r\n\tcritical := map[string]interface{}{\r\n\t\t\"type\":     signatureType,\r\n\t\t\"image\":    map[string]string{\"docker-manifest-digest\": s.UntrustedDockerManifestDigest.String()},\r\n\t\t\"identity\": map[string]string{\"docker-reference\": s.UntrustedDockerReference},\r\n\t}\r\n\toptional := map[string]interface{}{}\r\n\tif s.UntrustedCreatorID != nil {\r\n\t\toptional[\"creator\"] = *s.UntrustedCreatorID\r\n\t}\r\n\tif s.UntrustedTimestamp != nil {\r\n\t\toptional[\"timestamp\"] = *s.UntrustedTimestamp\r\n\t}\r\n\tsignature := map[string]interface{}{\r\n\t\t\"critical\": critical,\r\n\t\t\"optional\": optional,\r\n\t}\r\n\treturn json.Marshal(signature)\r\n}","code-length":273,"reference":"\/\/ MarshalJSON implements the json.Marshaler interface.","result":"Serialize the untrusted signature content.","score":[0.1967,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *untrustedSignature) UnmarshalJSON(data []byte) error {\r\n\terr := s.strictUnmarshalJSON(data)\r\n\tif err != nil {\r\n\t\tif _, ok := err.(jsonFormatError); ok {\r\n\t\t\terr = InvalidSignatureError{msg: err.Error()}\r\n\t\t}\r\n\t}\r\n\treturn err\r\n}","code-length":95,"reference":"\/\/ UnmarshalJSON implements the json.Unmarshaler interface","result":"Unmarshal the untrusted signature.","score":[0.1938,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc verifyAndExtractSignature(mech SigningMechanism, unverifiedSignature []byte, rules signatureAcceptanceRules) (*Signature, error) {\r\n\tsigned, keyIdentity, err := mech.Verify(unverifiedSignature)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err := rules.validateKeyIdentity(keyIdentity); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar unmatchedSignature untrustedSignature\r\n\tif err := json.Unmarshal(signed, &unmatchedSignature); err != nil {\r\n\t\treturn nil, InvalidSignatureError{msg: err.Error()}\r\n\t}\r\n\tif err := rules.validateSignedDockerManifestDigest(unmatchedSignature.UntrustedDockerManifestDigest); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err := rules.validateSignedDockerReference(unmatchedSignature.UntrustedDockerReference); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\treturn &Signature{\r\n\t\tDockerManifestDigest: unmatchedSignature.UntrustedDockerManifestDigest,\r\n\t\tDockerReference:      unmatchedSignature.UntrustedDockerReference,\r\n\t}, nil\r\n}","code-length":289,"reference":"\/\/ verifyAndExtractSignature verifies that unverifiedSignature has been signed, and that its principial components\n\/\/ match expected values, both as specified by rules, and returns it","result":"Verify and extract signature.","score":[0.0017,0.0437]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Endpoint) RewriteReference(ref reference.Named, prefix string) (reference.Named, error) {\r\n\tif ref == nil {\r\n\t\treturn nil, fmt.Errorf(\"provided reference is nil\")\r\n\t}\r\n\tif prefix == \"\" {\r\n\t\treturn ref, nil\r\n\t}\r\n\trefString := ref.String()\r\n\tif refMatchesPrefix(refString, prefix) {\r\n\t\tnewNamedRef := strings.Replace(refString, prefix, e.Location, 1)\r\n\t\tnewParsedRef, err := reference.ParseNamed(newNamedRef)\r\n\t\tif newParsedRef != nil {\r\n\t\t\tlogrus.Debugf(\"reference rewritten from '%v' to '%v'\", refString, newParsedRef.String())\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn nil, errors.Wrapf(err, \"error rewriting reference\")\r\n\t\t}\r\n\t\treturn newParsedRef, nil\r\n\t}\r\n\treturn nil, fmt.Errorf(\"invalid prefix '%v' for reference '%v'\", prefix, refString)\r\n}","code-length":270,"reference":"\/\/ RewriteReference will substitute the provided reference `prefix` to the\n\/\/ endpoints `location` from the `ref` and creates a new named reference from it.\n\/\/ The function errors if the newly created reference is not parsable.","result":"Rewrite the reference.","score":[0.0,0.0153]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getV1Registries(config *tomlConfig) ([]Registry, error) {\r\n\tregMap := make(map[string]*Registry)\r\n\t\r\n\t\r\n\t\r\n\tregistryOrder := []string{}\r\n\tgetRegistry := func(location string) (*Registry, error) {\r\n\t\tvar err error\r\n\t\tlocation, err = parseLocation(location)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treg, exists := regMap[location]\r\n\t\tif !exists {\r\n\t\t\treg = &Registry{\r\n\t\t\t\tEndpoint: Endpoint{Location: location},\r\n\t\t\t\tMirrors:  []Endpoint{},\r\n\t\t\t\tPrefix:   location,\r\n\t\t\t}\r\n\t\t\tregMap[location] = reg\r\n\t\t\tregistryOrder = append(registryOrder, location)\r\n\t\t}\r\n\t\treturn reg, nil\r\n\t}\r\n\t\r\n\t\r\n\tfor _, search := range config.V1TOMLConfig.Search.Registries {\r\n\t\treg, err := getRegistry(search)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treg.Search = true\r\n\t}\r\n\tfor _, blocked := range config.V1TOMLConfig.Block.Registries {\r\n\t\treg, err := getRegistry(blocked)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treg.Blocked = true\r\n\t}\r\n\tfor _, insecure := range config.V1TOMLConfig.Insecure.Registries {\r\n\t\treg, err := getRegistry(insecure)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treg.Insecure = true\r\n\t}\r\n\tregistries := []Registry{}\r\n\tfor _, location := range registryOrder {\r\n\t\treg := regMap[location]\r\n\t\tregistries = append(registries, *reg)\r\n\t}\r\n\treturn registries, nil\r\n}","code-length":508,"reference":"\/\/ getV1Registries transforms v1 registries in the config into an array of v2\n\/\/ registries of type Registry.","result":"Registry configuration.","score":[0,0.0305]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getConfigPath(ctx *types.SystemContext) string {\r\n\tconfPath := systemRegistriesConfPath\r\n\tif ctx != nil {\r\n\t\tif ctx.SystemRegistriesConfPath != \"\" {\r\n\t\t\tconfPath = ctx.SystemRegistriesConfPath\r\n\t\t} else if ctx.RootForImplicitAbsolutePaths != \"\" {\r\n\t\t\tconfPath = filepath.Join(ctx.RootForImplicitAbsolutePaths, systemRegistriesConfPath)\r\n\t\t}\r\n\t}\r\n\treturn confPath\r\n}","code-length":130,"reference":"\/\/ getConfigPath returns the system-registries config path if specified.\n\/\/ Otherwise, systemRegistriesConfPath is returned.","result":"Get the config path from the system context.","score":[0.1027,0.1907]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetRegistries(ctx *types.SystemContext) ([]Registry, error) {\r\n\tconfigPath := getConfigPath(ctx)\r\n\tconfigMutex.Lock()\r\n\tdefer configMutex.Unlock()\r\n\t\r\n\tif registries, inCache := configCache[configPath]; inCache {\r\n\t\treturn registries, nil\r\n\t}\r\n\t\r\n\tconfig, err := loadRegistryConf(configPath)\r\n\tif err != nil {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif os.IsNotExist(err) && (ctx == nil || ctx.SystemRegistriesConfPath == \"\") {\r\n\t\t\treturn []Registry{}, nil\r\n\t\t}\r\n\t\treturn nil, err\r\n\t}\r\n\tregistries := config.Registries\r\n\t\r\n\tv1Registries, err := getV1Registries(config)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif len(v1Registries) > 0 {\r\n\t\tif len(registries) > 0 {\r\n\t\t\treturn nil, &InvalidRegistries{s: \"mixing sysregistry v1\/v2 is not supported\"}\r\n\t\t}\r\n\t\tregistries = v1Registries\r\n\t}\r\n\tregistries, err = postProcessRegistries(registries)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tconfigCache[configPath] = registries\r\n\treturn registries, err\r\n}","code-length":372,"reference":"\/\/ GetRegistries loads and returns the registries specified in the config.\n\/\/ Note the parsed content of registry config files is cached.  For reloading,\n\/\/ use `InvalidateCache` and re-call `GetRegistries`.","result":"Get the list of registries from the system.","score":[0.0126,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc readRegistryConf(configPath string) ([]byte, error) {\r\n\tconfigBytes, err := ioutil.ReadFile(configPath)\r\n\treturn configBytes, err\r\n}","code-length":52,"reference":"\/\/ Reads the global registry file from the filesystem. Returns a byte array.","result":"Read registry configuration.","score":[0.0146,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *sourcedImage) Manifest(ctx context.Context) ([]byte, string, error) {\r\n\treturn i.manifestBlob, i.manifestMIMEType, nil\r\n}","code-length":52,"reference":"\/\/ Manifest overrides the UnparsedImage.Manifest to always use the fields which we have already fetched.","result":"Generate the manifest file.","score":[0.0204,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *tarballReference) ConfigUpdate(config imgspecv1.Image, annotations map[string]string) error {\r\n\tr.config = config\r\n\tif r.annotations == nil {\r\n\t\tr.annotations = make(map[string]string)\r\n\t}\r\n\tfor k, v := range annotations {\r\n\t\tr.annotations[k] = v\r\n\t}\r\n\treturn nil\r\n}","code-length":110,"reference":"\/\/ ConfigUpdate updates the image's default configuration and adds annotations\n\/\/ which will be visible in source images created using this reference.","result":"Update the config in the tarball.","score":[0.016,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc parseImageAndDockerReference(image types.UnparsedImage, s2 string) (reference.Named, reference.Named, error) {\r\n\tr1 := image.Reference().DockerReference()\r\n\tif r1 == nil {\r\n\t\treturn nil, nil, PolicyRequirementError(fmt.Sprintf(\"Docker reference match attempted on image %s with no known Docker reference identity\",\r\n\t\t\ttransports.ImageName(image.Reference())))\r\n\t}\r\n\tr2, err := reference.ParseNormalizedNamed(s2)\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\treturn r1, r2, nil\r\n}","code-length":166,"reference":"\/\/ parseImageAndDockerReference converts an image and a reference string into two parsed entities, failing on any error and handling unidentified images.","result":"Parse the image and its Docker reference.","score":[0.0309,0.0765]}
{"code":"\/*is used to<extra_id_0>\r\nfunc parseDockerReferences(s1, s2 string) (reference.Named, reference.Named, error) {\r\n\tr1, err := reference.ParseNormalizedNamed(s1)\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\tr2, err := reference.ParseNormalizedNamed(s2)\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\treturn r1, r2, nil\r\n}","code-length":125,"reference":"\/\/ parseDockerReferences converts two reference strings into parsed entities, failing on any error","result":"Parse docker references.","score":[0,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ListNames() []string {\r\n\tkt.mu.Lock()\r\n\tdefer kt.mu.Unlock()\r\n\tdeprecated := map[string]bool{\r\n\t\t\"atomic\": true,\r\n\t}\r\n\tvar names []string\r\n\tfor _, transport := range kt.transports {\r\n\t\tif !deprecated[transport.Name()] {\r\n\t\t\tnames = append(names, transport.Name())\r\n\t\t}\r\n\t}\r\n\tsort.Strings(names)\r\n\treturn names\r\n}","code-length":136,"reference":"\/\/ ListNames returns a list of non deprecated transport names.\n\/\/ Deprecated transports can be used, but are not presented to users.","result":"List the names of all the transports.","score":[0.0189,0.0488]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewReference(image string, repo string) (types.ImageReference, error) {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tostreeImage, err := reference.ParseNormalizedNamed(image)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif reference.IsNameOnly(ostreeImage) {\r\n\t\timage = image + \":latest\"\r\n\t}\r\n\tresolved, err := explicitfilepath.ResolvePathToFullyExplicit(repo)\r\n\tif err != nil {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif os.IsNotExist(err) && repo == defaultOSTreeRepo {\r\n\t\t\tresolved = repo\r\n\t\t} else {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\tif strings.Contains(resolved, \":\") {\r\n\t\treturn nil, errors.Errorf(\"Invalid OSTree reference %s@%s: path %s contains a colon\", image, repo, resolved)\r\n\t}\r\n\treturn ostreeReference{\r\n\t\timage:      image,\r\n\t\tbranchName: encodeOStreeRef(image),\r\n\t\trepo:       resolved,\r\n\t}, nil\r\n}","code-length":307,"reference":"\/\/ NewReference returns an OSTree reference for a specified repo and image.","result":"Create a new reference.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ref ostreeReference) signaturePath(index int) string {\r\n\treturn filepath.Join(\"manifest\", fmt.Sprintf(\"signature-%d\", index+1))\r\n}","code-length":51,"reference":"\/\/ signaturePath returns a path for a signature within a ostree using our conventions.","result":"Generate the manifest.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ValidateImageName(image string) error {\r\n\tif len(image) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\tvar err error\r\n\tif !refRegexp.MatchString(image) {\r\n\t\terr = errors.Errorf(\"Invalid image %s\", image)\r\n\t}\r\n\treturn err\r\n}","code-length":89,"reference":"\/\/ ValidateImageName returns nil if the image name is empty or matches the open-containers image name specs.\n\/\/ In any other case an error is returned.","result":"Validate image name.","score":[0.0002,0.0211]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SplitPathAndImage(reference string) (string, string) {\r\n\tif runtime.GOOS == \"windows\" {\r\n\t\treturn splitPathAndImageWindows(reference)\r\n\t}\r\n\treturn splitPathAndImageNonWindows(reference)\r\n}","code-length":70,"reference":"\/\/ SplitPathAndImage tries to split the provided OCI reference into the OCI path and image.\n\/\/ Neither path nor image parts are validated at this stage.","result":"Split images in windows.","score":[0,0.042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ValidateOCIPath(path string) error {\r\n\tif runtime.GOOS == \"windows\" {\r\n\t\t\r\n\t\tif strings.Count(path, \":\") > 1 {\r\n\t\t\treturn errors.Errorf(\"Invalid OCI reference: path %s contains more than one colon\", path)\r\n\t\t}\r\n\t} else {\r\n\t\tif strings.Contains(path, \":\") {\r\n\t\t\treturn errors.Errorf(\"Invalid OCI reference: path %s contains a colon\", path)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":139,"reference":"\/\/ ValidateOCIPath takes the OCI path and validates it.","result":"Validate the path.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ValidateScope(scope string) error {\r\n\tvar err error\r\n\tif runtime.GOOS == \"windows\" {\r\n\t\terr = validateScopeWindows(scope)\r\n\t} else {\r\n\t\terr = validateScopeNonWindows(scope)\r\n\t}\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tcleaned := filepath.Clean(scope)\r\n\tif cleaned != scope {\r\n\t\treturn errors.Errorf(`Invalid scope %s: Uses non-canonical path format, perhaps try with path %s`, scope, cleaned)\r\n\t}\r\n\treturn nil\r\n}","code-length":155,"reference":"\/\/ ValidateScope validates a policy configuration scope for an OCI transport.","result":"Validate the scope.","score":[0,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc BlobInfoFromSchema2Descriptor(desc Schema2Descriptor) types.BlobInfo {\r\n\treturn types.BlobInfo{\r\n\t\tDigest:    desc.Digest,\r\n\t\tSize:      desc.Size,\r\n\t\tURLs:      desc.URLs,\r\n\t\tMediaType: desc.MediaType,\r\n\t}\r\n}","code-length":86,"reference":"\/\/ BlobInfoFromSchema2Descriptor returns a types.BlobInfo based on the input schema 2 descriptor.","result":"Generate the blob info from the schema.","score":[0.0791,0.0435]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Schema2FromManifest(manifest []byte) (*Schema2, error) {\r\n\ts2 := Schema2{}\r\n\tif err := json.Unmarshal(manifest, &s2); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &s2, nil\r\n}","code-length":80,"reference":"\/\/ Schema2FromManifest creates a Schema2 manifest instance from a manifest blob.","result":"Create a schema.","score":[0.0284,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Schema2FromComponents(config Schema2Descriptor, layers []Schema2Descriptor) *Schema2 {\r\n\treturn &Schema2{\r\n\t\tSchemaVersion:     2,\r\n\t\tMediaType:         DockerV2Schema2MediaType,\r\n\t\tConfigDescriptor:  config,\r\n\t\tLayersDescriptors: layers,\r\n\t}\r\n}","code-length":88,"reference":"\/\/ Schema2FromComponents creates an Schema2 manifest instance from the supplied data.","result":"Create a schema.","score":[0,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetAuthentication(sys *types.SystemContext, registry, username, password string) error {\r\n\treturn modifyJSON(sys, func(auths *dockerConfigFile) (bool, error) {\r\n\t\tif ch, exists := auths.CredHelpers[registry]; exists {\r\n\t\t\treturn false, setAuthToCredHelper(ch, registry, username, password)\r\n\t\t}\r\n\t\tcreds := base64.StdEncoding.EncodeToString([]byte(username + \":\" + password))\r\n\t\tnewCreds := dockerAuthConfig{Auth: creds}\r\n\t\tauths.AuthConfigs[registry] = newCreds\r\n\t\treturn true, nil\r\n\t})\r\n}","code-length":166,"reference":"\/\/ SetAuthentication stores the username and password in the auth.json file","result":"Set the auth config in the dockerfile.","score":[0.1427,0.2411]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RemoveAuthentication(sys *types.SystemContext, registry string) error {\r\n\treturn modifyJSON(sys, func(auths *dockerConfigFile) (bool, error) {\r\n\t\t\r\n\t\tif ch, exists := auths.CredHelpers[registry]; exists {\r\n\t\t\treturn false, deleteAuthFromCredHelper(ch, registry)\r\n\t\t}\r\n\t\tif _, ok := auths.AuthConfigs[registry]; ok {\r\n\t\t\tdelete(auths.AuthConfigs, registry)\r\n\t\t} else if _, ok := auths.AuthConfigs[normalizeRegistry(registry)]; ok {\r\n\t\t\tdelete(auths.AuthConfigs, normalizeRegistry(registry))\r\n\t\t} else {\r\n\t\t\treturn false, ErrNotLoggedIn\r\n\t\t}\r\n\t\treturn true, nil\r\n\t})\r\n}","code-length":203,"reference":"\/\/ RemoveAuthentication deletes the credentials stored in auth.json","result":"Remove authentication from a Dockerfile.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RemoveAllAuthentication(sys *types.SystemContext) error {\r\n\treturn modifyJSON(sys, func(auths *dockerConfigFile) (bool, error) {\r\n\t\tauths.CredHelpers = make(map[string]string)\r\n\t\tauths.AuthConfigs = make(map[string]dockerAuthConfig)\r\n\t\treturn true, nil\r\n\t})\r\n}","code-length":98,"reference":"\/\/ RemoveAllAuthentication deletes all the credentials stored in auth.json","result":"Remove all authentication.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc readJSONFile(path string, legacyFormat bool) (dockerConfigFile, error) {\r\n\tvar auths dockerConfigFile\r\n\traw, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\tif os.IsNotExist(err) {\r\n\t\t\tauths.AuthConfigs = map[string]dockerAuthConfig{}\r\n\t\t\treturn auths, nil\r\n\t\t}\r\n\t\treturn dockerConfigFile{}, err\r\n\t}\r\n\tif legacyFormat {\r\n\t\tif err = json.Unmarshal(raw, &auths.AuthConfigs); err != nil {\r\n\t\t\treturn dockerConfigFile{}, errors.Wrapf(err, \"error unmarshaling JSON at %q\", path)\r\n\t\t}\r\n\t\treturn auths, nil\r\n\t}\r\n\tif err = json.Unmarshal(raw, &auths); err != nil {\r\n\t\treturn dockerConfigFile{}, errors.Wrapf(err, \"error unmarshaling JSON at %q\", path)\r\n\t}\r\n\treturn auths, nil\r\n}","code-length":255,"reference":"\/\/ readJSONFile unmarshals the authentications stored in the auth.json file and returns it\n\/\/ or returns an empty dockerConfigFile data structure if auth.json does not exist\n\/\/ if the file exists and is empty, readJSONFile returns an error","result":"Read a JSON file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc modifyJSON(sys *types.SystemContext, editor func(auths *dockerConfigFile) (bool, error)) error {\r\n\tpath, err := getPathToAuth(sys)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdir := filepath.Dir(path)\r\n\tif _, err := os.Stat(dir); os.IsNotExist(err) {\r\n\t\tif err = os.MkdirAll(dir, 0700); err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"error creating directory %q\", dir)\r\n\t\t}\r\n\t}\r\n\tauths, err := readJSONFile(path, false)\r\n\tif err != nil {\r\n\t\treturn errors.Wrapf(err, \"error reading JSON file %q\", path)\r\n\t}\r\n\tupdated, err := editor(&auths)\r\n\tif err != nil {\r\n\t\treturn errors.Wrapf(err, \"error updating %q\", path)\r\n\t}\r\n\tif updated {\r\n\t\tnewData, err := json.MarshalIndent(auths, \"\", \"\\t\")\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"error marshaling JSON %q\", path)\r\n\t\t}\r\n\t\tif err = ioutil.WriteFile(path, newData, 0755); err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"error writing to file %q\", path)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":371,"reference":"\/\/ modifyJSON writes to auth.json if the dockerConfigFile has been updated","result":"Modify the Docker config file.","score":[0.0724,0.0481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc findAuthentication(registry, path string, legacyFormat bool) (string, string, error) {\r\n\tauths, err := readJSONFile(path, legacyFormat)\r\n\tif err != nil {\r\n\t\treturn \"\", \"\", errors.Wrapf(err, \"error reading JSON file %q\", path)\r\n\t}\r\n\t\r\n\tif ch, exists := auths.CredHelpers[registry]; exists {\r\n\t\treturn getAuthFromCredHelper(ch, registry)\r\n\t}\r\n\t\r\n\tif val, exists := auths.AuthConfigs[registry]; exists {\r\n\t\treturn decodeDockerAuth(val.Auth)\r\n\t}\r\n\t\r\n\tregistry = normalizeRegistry(registry)\r\n\tnormalizedAuths := map[string]dockerAuthConfig{}\r\n\tfor k, v := range auths.AuthConfigs {\r\n\t\tnormalizedAuths[normalizeRegistry(k)] = v\r\n\t}\r\n\tif val, exists := normalizedAuths[registry]; exists {\r\n\t\treturn decodeDockerAuth(val.Auth)\r\n\t}\r\n\treturn \"\", \"\", nil\r\n}","code-length":265,"reference":"\/\/ findAuthentication looks for auth of registry in path","result":"Find the authentication for a given registry.","score":[0.1214,0.0568]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDestination(dest io.Writer, ref reference.NamedTagged) *Destination {\r\n\trepoTags := []reference.NamedTagged{}\r\n\tif ref != nil {\r\n\t\trepoTags = append(repoTags, ref)\r\n\t}\r\n\treturn &Destination{\r\n\t\twriter:   dest,\r\n\t\ttar:      tar.NewWriter(dest),\r\n\t\trepoTags: repoTags,\r\n\t\tblobs:    make(map[digest.Digest]types.BlobInfo),\r\n\t}\r\n}","code-length":133,"reference":"\/\/ NewDestination returns a tarfile.Destination for the specified io.Writer.","result":"Create a new destination.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *Destination) AddRepoTags(tags []reference.NamedTagged) {\r\n\td.repoTags = append(d.repoTags, tags...)\r\n}","code-length":47,"reference":"\/\/ AddRepoTags adds the specified tags to the destination's repoTags.","result":"Generate the code.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *Destination) writeLegacyLayerMetadata(layerDescriptors []manifest.Schema2Descriptor) (layerPaths []string, lastLayerID string, err error) {\r\n\tvar chainID digest.Digest\r\n\tlastLayerID = \"\"\r\n\tfor i, l := range layerDescriptors {\r\n\t\t\r\n\t\tif chainID == \"\" {\r\n\t\t\tchainID = l.Digest\r\n\t\t} else {\r\n\t\t\tchainID = digest.Canonical.FromString(chainID.String() + \" \" + l.Digest.String())\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tlayerID := chainID.Hex()\r\n\t\tphysicalLayerPath := l.Digest.Hex() + \".tar\"\r\n\t\t\r\n\t\t\r\n\t\tlayerPaths = append(layerPaths, physicalLayerPath)\r\n\t\t\r\n\t\tif err := d.sendSymlink(filepath.Join(layerID, legacyLayerFileName), filepath.Join(\"..\", physicalLayerPath)); err != nil {\r\n\t\t\treturn nil, \"\", errors.Wrap(err, \"Error creating layer symbolic link\")\r\n\t\t}\r\n\t\tb := []byte(\"1.0\")\r\n\t\tif err := d.sendBytes(filepath.Join(layerID, legacyVersionFileName), b); err != nil {\r\n\t\t\treturn nil, \"\", errors.Wrap(err, \"Error writing VERSION file\")\r\n\t\t}\r\n\t\t\r\n\t\tlayerConfig := make(map[string]interface{})\r\n\t\tlayerConfig[\"id\"] = layerID\r\n\t\t\r\n\t\tif lastLayerID != \"\" {\r\n\t\t\tlayerConfig[\"parent\"] = lastLayerID\r\n\t\t}\r\n\t\t\r\n\t\tif i == len(layerDescriptors)-1 {\r\n\t\t\tvar config map[string]*json.RawMessage\r\n\t\t\terr := json.Unmarshal(d.config, &config)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, \"\", errors.Wrap(err, \"Error unmarshaling config\")\r\n\t\t\t}\r\n\t\t\tfor _, attr := range [7]string{\"architecture\", \"config\", \"container\", \"container_config\", \"created\", \"docker_version\", \"os\"} {\r\n\t\t\t\tlayerConfig[attr] = config[attr]\r\n\t\t\t}\r\n\t\t}\r\n\t\tb, err := json.Marshal(layerConfig)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, \"\", errors.Wrap(err, \"Error marshaling layer config\")\r\n\t\t}\r\n\t\tif err := d.sendBytes(filepath.Join(layerID, legacyConfigFileName), b); err != nil {\r\n\t\t\treturn nil, \"\", errors.Wrap(err, \"Error writing config json file\")\r\n\t\t}\r\n\t\tlastLayerID = layerID\r\n\t}\r\n\treturn layerPaths, lastLayerID, nil\r\n}","code-length":690,"reference":"\/\/ writeLegacyLayerMetadata writes legacy VERSION and configuration files for all layers","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *Destination) sendSymlink(path string, target string) error {\r\n\thdr, err := tar.FileInfoHeader(&tarFI{path: path, size: 0, isSymlink: true}, target)\r\n\tif err != nil {\r\n\t\treturn nil\r\n\t}\r\n\tlogrus.Debugf(\"Sending as tar link %s -> %s\", path, target)\r\n\treturn d.tar.WriteHeader(hdr)\r\n}","code-length":113,"reference":"\/\/ sendSymlink sends a symlink into the tar stream.","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *Destination) sendBytes(path string, b []byte) error {\r\n\treturn d.sendFile(path, int64(len(b)), bytes.NewReader(b))\r\n}","code-length":56,"reference":"\/\/ sendBytes sends a path into the tar stream.","result":"Send bytes to a destination.","score":[0.108,0.1163]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *Destination) sendFile(path string, expectedSize int64, stream io.Reader) error {\r\n\thdr, err := tar.FileInfoHeader(&tarFI{path: path, size: expectedSize}, \"\")\r\n\tif err != nil {\r\n\t\treturn nil\r\n\t}\r\n\tlogrus.Debugf(\"Sending as tar file %s\", path)\r\n\tif err := d.tar.WriteHeader(hdr); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tsize, err := io.Copy(d.tar, stream)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif size != expectedSize {\r\n\t\treturn errors.Errorf(\"Size mismatch when copying %s, expected %d, got %d\", path, expectedSize, size)\r\n\t}\r\n\treturn nil\r\n}","code-length":214,"reference":"\/\/ sendFile sends a file into the tar stream.","result":"Send files to the destination.","score":[0.108,0.1744]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *Destination) Commit(ctx context.Context) error {\r\n\treturn d.tar.Close()\r\n}","code-length":37,"reference":"\/\/ Commit finishes writing data to the underlying io.Writer.\n\/\/ It is the caller's responsibility to close it, if necessary.","result":"Commit the commit.","score":[0.0017,0.0546]}
{"code":"\/*is used to<extra_id_0>\r\nfunc imageMatchesRepo(image *storage.Image, ref reference.Named) bool {\r\n\trepo := ref.Name()\r\n\tfor _, name := range image.Names {\r\n\t\tif named, err := reference.ParseNormalizedNamed(name); err == nil {\r\n\t\t\tif named.Name() == repo {\r\n\t\t\t\treturn true\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":110,"reference":"\/\/ imageMatchesRepo returns true iff image.Names contains an element with the same repo as ref","result":"Match images by name.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *storageReference) resolveImage() (*storage.Image, error) {\r\n\tvar loadedImage *storage.Image\r\n\tif s.id == \"\" && s.named != nil {\r\n\t\t\r\n\t\timage, err := s.transport.store.Image(s.named.String())\r\n\t\tif image != nil && err == nil {\r\n\t\t\tloadedImage = image\r\n\t\t\ts.id = image.ID\r\n\t\t}\r\n\t}\r\n\tif s.id == \"\" && s.named != nil {\r\n\t\tif digested, ok := s.named.(reference.Digested); ok {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\timages, err := s.transport.store.ImagesByDigest(digested.Digest())\r\n\t\t\tif err == nil && len(images) > 0 {\r\n\t\t\t\tfor _, image := range images {\r\n\t\t\t\t\tif imageMatchesRepo(image, s.named) {\r\n\t\t\t\t\t\tloadedImage = image\r\n\t\t\t\t\t\ts.id = image.ID\r\n\t\t\t\t\t\tbreak\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif s.id == \"\" {\r\n\t\tlogrus.Debugf(\"reference %q does not resolve to an image ID\", s.StringWithinTransport())\r\n\t\treturn nil, errors.Wrapf(ErrNoSuchImage, \"reference %q does not resolve to an image ID\", s.StringWithinTransport())\r\n\t}\r\n\tif loadedImage == nil {\r\n\t\timg, err := s.transport.store.Image(s.id)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, errors.Wrapf(err, \"error reading image %q\", s.id)\r\n\t\t}\r\n\t\tloadedImage = img\r\n\t}\r\n\tif s.named != nil {\r\n\t\tif !imageMatchesRepo(loadedImage, s.named) {\r\n\t\t\tlogrus.Errorf(\"no image matching reference %q found\", s.StringWithinTransport())\r\n\t\t\treturn nil, ErrNoSuchImage\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\tif digest, ok := loadedImage.BigDataDigests[storage.ImageDigestBigDataKey]; ok {\r\n\t\tloadedImage.Digest = digest\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tif s.named != nil {\r\n\t\tif digested, ok := s.named.(reference.Digested); ok {\r\n\t\t\tfor _, digest := range loadedImage.Digests {\r\n\t\t\t\tif digest == digested.Digest() {\r\n\t\t\t\t\tloadedImage.Digest = digest\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn loadedImage, nil\r\n}","code-length":666,"reference":"\/\/ Resolve the reference's name to an image ID in the store, if there's already\n\/\/ one present with the same name or ID, and return the image.","result":"Code too long,keep in 512.","score":[0.0024,0.0195]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s storageReference) Transport() types.ImageTransport {\r\n\treturn &storageTransport{\r\n\t\tstore:         s.transport.store,\r\n\t\tdefaultUIDMap: s.transport.defaultUIDMap,\r\n\t\tdefaultGIDMap: s.transport.defaultGIDMap,\r\n\t}\r\n}","code-length":82,"reference":"\/\/ Return a Transport object that defaults to using the same store that we used\n\/\/ to build this reference object.","result":"Create storage references.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s storageReference) StringWithinTransport() string {\r\n\toptionsList := \"\"\r\n\toptions := s.transport.store.GraphOptions()\r\n\tif len(options) > 0 {\r\n\t\toptionsList = \":\" + strings.Join(options, \",\")\r\n\t}\r\n\tres := \"[\" + s.transport.store.GraphDriverName() + \"@\" + s.transport.store.GraphRoot() + \"+\" + s.transport.store.RunRoot() + optionsList + \"]\"\r\n\tif s.named != nil {\r\n\t\tres = res + s.named.String()\r\n\t}\r\n\tif s.id != \"\" {\r\n\t\tres = res + \"@\" + s.id\r\n\t}\r\n\treturn res\r\n}","code-length":183,"reference":"\/\/ Return a name with a tag, prefixed with the graph root and driver name, to\n\/\/ disambiguate between images which may be present in multiple stores and\n\/\/ share only their names.","result":"Generate the storage reference string for the storage reference.","score":[0.0085,0.0327]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s storageReference) PolicyConfigurationNamespaces() []string {\r\n\tstoreSpec := \"[\" + s.transport.store.GraphDriverName() + \"@\" + s.transport.store.GraphRoot() + \"]\"\r\n\tdriverlessStoreSpec := \"[\" + s.transport.store.GraphRoot() + \"]\"\r\n\tnamespaces := []string{}\r\n\tif s.named != nil {\r\n\t\tif s.id != \"\" {\r\n\t\t\t\r\n\t\t\tnamespaces = append(namespaces, storeSpec+s.named.String())\r\n\t\t}\r\n\t\ttagged, isTagged := s.named.(reference.Tagged)\r\n\t\t_, isDigested := s.named.(reference.Digested)\r\n\t\tif isTagged && isDigested {\r\n\t\t\tnamespaces = append(namespaces, storeSpec+s.named.Name()+\":\"+tagged.Tag())\r\n\t\t}\r\n\t\tcomponents := strings.Split(s.named.Name(), \"\/\")\r\n\t\tfor len(components) > 0 {\r\n\t\t\tnamespaces = append(namespaces, storeSpec+strings.Join(components, \"\/\"))\r\n\t\t\tcomponents = components[:len(components)-1]\r\n\t\t}\r\n\t}\r\n\tnamespaces = append(namespaces, storeSpec)\r\n\tnamespaces = append(namespaces, driverlessStoreSpec)\r\n\treturn namespaces\r\n}","code-length":320,"reference":"\/\/ Also accept policy that's tied to the combination of the graph root and\n\/\/ driver name, to apply to all images stored in the Store, and to just the\n\/\/ graph root, in case we're using multiple drivers in the same directory for\n\/\/ some reason.","result":"Generate the policy configuration namespaces.","score":[0.0001,0.0234]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GzipDecompressor(r io.Reader) (io.ReadCloser, error) {\r\n\treturn pgzip.NewReader(r)\r\n}","code-length":44,"reference":"\/\/ GzipDecompressor is a DecompressorFunc for the gzip compression algorithm.","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Bzip2Decompressor(r io.Reader) (io.ReadCloser, error) {\r\n\treturn ioutil.NopCloser(bzip2.NewReader(r)), nil\r\n}","code-length":55,"reference":"\/\/ Bzip2Decompressor is a DecompressorFunc for the bzip2 compression algorithm.","result":"Decompress the file.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc XzDecompressor(r io.Reader) (io.ReadCloser, error) {\r\n\tr, err := xz.NewReader(r)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn ioutil.NopCloser(r), nil\r\n}","code-length":80,"reference":"\/\/ XzDecompressor is a DecompressorFunc for the xz compression algorithm.","result":"Decompress Xz files.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DetectCompression(input io.Reader) (DecompressorFunc, io.Reader, error) {\r\n\tbuffer := [8]byte{}\r\n\tn, err := io.ReadAtLeast(input, buffer[:], len(buffer))\r\n\tif err != nil && err != io.EOF && err != io.ErrUnexpectedEOF {\r\n\t\t\r\n\t\t\r\n\t\treturn nil, nil, err\r\n\t}\r\n\tvar decompressor DecompressorFunc\r\n\tfor name, algo := range compressionAlgos {\r\n\t\tif bytes.HasPrefix(buffer[:n], algo.prefix) {\r\n\t\t\tlogrus.Debugf(\"Detected compression format %s\", name)\r\n\t\t\tdecompressor = algo.decompressor\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif decompressor == nil {\r\n\t\tlogrus.Debugf(\"No compression detected\")\r\n\t}\r\n\treturn decompressor, io.MultiReader(bytes.NewReader(buffer[:n]), input), nil\r\n}","code-length":244,"reference":"\/\/ DetectCompression returns a DecompressorFunc if the input is recognized as a compressed format, nil otherwise.\n\/\/ Because it consumes the start of input, other consumers must use the returned io.Reader instead to also read from the beginning.","result":"Detect compression.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newImageDestination(sys *types.SystemContext, ref dockerReference) (types.ImageDestination, error) {\r\n\tc, err := newDockerClientFromRef(sys, ref, true, \"pull,push\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &dockerImageDestination{\r\n\t\tref: ref,\r\n\t\tc:   c,\r\n\t}, nil\r\n}","code-length":112,"reference":"\/\/ newImageDestination creates a new ImageDestination for the specified image reference.","result":"Create a new image destination.","score":[0.1133,0.3606]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *dockerImageDestination) mountBlob(ctx context.Context, srcRepo reference.Named, srcDigest digest.Digest, extraScope *authScope) error {\r\n\tu := url.URL{\r\n\t\tPath: fmt.Sprintf(blobUploadPath, reference.Path(d.ref.ref)),\r\n\t\tRawQuery: url.Values{\r\n\t\t\t\"mount\": {srcDigest.String()},\r\n\t\t\t\"from\":  {reference.Path(srcRepo)},\r\n\t\t}.Encode(),\r\n\t}\r\n\tmountPath := u.String()\r\n\tlogrus.Debugf(\"Trying to mount %s\", mountPath)\r\n\tres, err := d.c.makeRequest(ctx, \"POST\", mountPath, nil, nil, v2Auth, extraScope)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer res.Body.Close()\r\n\tswitch res.StatusCode {\r\n\tcase http.StatusCreated:\r\n\t\tlogrus.Debugf(\"... mount OK\")\r\n\t\treturn nil\r\n\tcase http.StatusAccepted:\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tuploadLocation, err := res.Location()\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Error determining upload URL after a mount attempt\")\r\n\t\t}\r\n\t\tlogrus.Debugf(\"... started an upload instead of mounting, trying to cancel at %s\", uploadLocation.String())\r\n\t\tres2, err := d.c.makeRequestToResolvedURL(ctx, \"DELETE\", uploadLocation.String(), nil, nil, -1, v2Auth, extraScope)\r\n\t\tif err != nil {\r\n\t\t\tlogrus.Debugf(\"Error trying to cancel an inadvertent upload: %s\", err)\r\n\t\t} else {\r\n\t\t\tdefer res2.Body.Close()\r\n\t\t\tif res2.StatusCode != http.StatusNoContent {\r\n\t\t\t\tlogrus.Debugf(\"Error trying to cancel an inadvertent upload, status %s\", http.StatusText(res.StatusCode))\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\treturn fmt.Errorf(\"Mounting %s from %s to %s started an upload instead\", srcDigest, srcRepo.Name(), d.ref.ref.Name())\r\n\tdefault:\r\n\t\tlogrus.Debugf(\"Error mounting, response %#v\", *res)\r\n\t\treturn errors.Wrapf(client.HandleErrorResponse(res), \"Error mounting %s from %s to %s\", srcDigest, srcRepo.Name(), d.ref.ref.Name())\r\n\t}\r\n}","code-length":630,"reference":"\/\/ mountBlob tries to mount blob srcDigest from srcRepo to the current destination.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc bicTransportScope(ref dockerReference) types.BICTransportScope {\r\n\t\r\n\treturn types.BICTransportScope{Opaque: reference.Domain(ref.ref)}\r\n}","code-length":54,"reference":"\/\/ bicTransportScope returns a BICTransportScope appropriate for ref.","result":"Create a new scope.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newBICLocationReference(ref dockerReference) types.BICLocationReference {\r\n\t\r\n\treturn types.BICLocationReference{Opaque: ref.ref.Name()}\r\n}","code-length":53,"reference":"\/\/ newBICLocationReference returns a BICLocationReference appropriate for ref.","result":"Create a new BIC location reference.","score":[0.1383,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc parseBICLocationReference(lr types.BICLocationReference) (reference.Named, error) {\r\n\treturn reference.ParseNormalizedNamed(lr.Opaque)\r\n}","code-length":50,"reference":"\/\/ parseBICLocationReference returns a repository for encoded lr.","result":"Parse the file .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSourceFromStream(inputStream io.Reader) (*Source, error) {\r\n\t\r\n\t\r\n\ttarCopyFile, err := ioutil.TempFile(tmpdir.TemporaryDirectoryForBigFiles(), \"docker-tar\")\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"error creating temporary file\")\r\n\t}\r\n\tdefer tarCopyFile.Close()\r\n\tsucceeded := false\r\n\tdefer func() {\r\n\t\tif !succeeded {\r\n\t\t\tos.Remove(tarCopyFile.Name())\r\n\t\t}\r\n\t}()\r\n\t\r\n\t\r\n\t\r\n\tuncompressedStream, _, err := compression.AutoDecompress(inputStream)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Error auto-decompressing input\")\r\n\t}\r\n\tdefer uncompressedStream.Close()\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif _, err := io.Copy(tarCopyFile, uncompressedStream); err != nil {\r\n\t\treturn nil, errors.Wrapf(err, \"error copying contents to temporary file %q\", tarCopyFile.Name())\r\n\t}\r\n\tsucceeded = true\r\n\treturn &Source{\r\n\t\ttarPath:              tarCopyFile.Name(),\r\n\t\tremoveTarPathOnClose: true,\r\n\t}, nil\r\n}","code-length":339,"reference":"\/\/ NewSourceFromStream returns a tarfile.Source for the specified inputStream,\n\/\/ which can be either compressed or uncompressed. The caller can close the\n\/\/ inputStream immediately after NewSourceFromFile returns.","result":"Create a source from a stream.","score":[0.0049,0.0194]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Source) readTarComponent(path string) ([]byte, error) {\r\n\tfile, err := s.openTarComponent(path)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrapf(err, \"Error loading tar component %s\", path)\r\n\t}\r\n\tdefer file.Close()\r\n\tbytes, err := ioutil.ReadAll(file)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn bytes, nil\r\n}","code-length":132,"reference":"\/\/ readTarComponent returns full contents of componentPath.","result":"Read the tar component.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Source) ensureCachedDataIsPresent() error {\r\n\ts.cacheDataLock.Do(func() {\r\n\t\t\r\n\t\ttarManifest, err := s.loadTarManifest()\r\n\t\tif err != nil {\r\n\t\t\ts.cacheDataResult = err\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\tif len(tarManifest) != 1 {\r\n\t\t\ts.cacheDataResult = errors.Errorf(\"Unexpected tar manifest.json: expected 1 item, got %d\", len(tarManifest))\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\tconfigBytes, err := s.readTarComponent(tarManifest[0].Config)\r\n\t\tif err != nil {\r\n\t\t\ts.cacheDataResult = err\r\n\t\t\treturn\r\n\t\t}\r\n\t\tvar parsedConfig manifest.Schema2Image\r\n\t\tif err := json.Unmarshal(configBytes, &parsedConfig); err != nil {\r\n\t\t\ts.cacheDataResult = errors.Wrapf(err, \"Error decoding tar config %s\", tarManifest[0].Config)\r\n\t\t\treturn\r\n\t\t}\r\n\t\tknownLayers, err := s.prepareLayerData(&tarManifest[0], &parsedConfig)\r\n\t\tif err != nil {\r\n\t\t\ts.cacheDataResult = err\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\ts.tarManifest = &tarManifest[0]\r\n\t\ts.configBytes = configBytes\r\n\t\ts.configDigest = digest.FromBytes(configBytes)\r\n\t\ts.orderedDiffIDList = parsedConfig.RootFS.DiffIDs\r\n\t\ts.knownLayers = knownLayers\r\n\t})\r\n\treturn s.cacheDataResult\r\n}","code-length":420,"reference":"\/\/ ensureCachedDataIsPresent loads data necessary for any of the public accessors.","result":"Generate the source code .","score":[0.0724,0.0481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Source) loadTarManifest() ([]ManifestItem, error) {\r\n\t\r\n\tbytes, err := s.readTarComponent(manifestFileName)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar items []ManifestItem\r\n\tif err := json.Unmarshal(bytes, &items); err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Error decoding tar manifest.json\")\r\n\t}\r\n\treturn items, nil\r\n}","code-length":128,"reference":"\/\/ loadTarManifest loads and decodes the manifest.json.","result":"Load the tar manifest.","score":[0.1509,0.1493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Source) Close() error {\r\n\tif s.removeTarPathOnClose {\r\n\t\treturn os.Remove(s.tarPath)\r\n\t}\r\n\treturn nil\r\n}","code-length":57,"reference":"\/\/ Close removes resources associated with an initialized Source, if any.","result":"Close the source.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newImageDestination(ctx context.Context, sys *types.SystemContext, ref daemonReference) (types.ImageDestination, error) {\r\n\tif ref.ref == nil {\r\n\t\treturn nil, errors.Errorf(\"Invalid destination docker-daemon:%s: a destination must be a name:tag\", ref.StringWithinTransport())\r\n\t}\r\n\tnamedTaggedRef, ok := ref.ref.(reference.NamedTagged)\r\n\tif !ok {\r\n\t\treturn nil, errors.Errorf(\"Invalid destination docker-daemon:%s: a destination must be a name:tag\", ref.StringWithinTransport())\r\n\t}\r\n\tvar mustMatchRuntimeOS = true\r\n\tif sys != nil && sys.DockerDaemonHost != client.DefaultDockerHost {\r\n\t\tmustMatchRuntimeOS = false\r\n\t}\r\n\tc, err := newDockerClient(sys)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Error initializing docker engine client\")\r\n\t}\r\n\treader, writer := io.Pipe()\r\n\t\r\n\tstatusChannel := make(chan error, 1)\r\n\tgoroutineContext, goroutineCancel := context.WithCancel(ctx)\r\n\tgo imageLoadGoroutine(goroutineContext, c, reader, statusChannel)\r\n\treturn &daemonImageDestination{\r\n\t\tref:                ref,\r\n\t\tmustMatchRuntimeOS: mustMatchRuntimeOS,\r\n\t\tDestination:        tarfile.NewDestination(writer, namedTaggedRef),\r\n\t\tgoroutineCancel:    goroutineCancel,\r\n\t\tstatusChannel:      statusChannel,\r\n\t\twriter:             writer,\r\n\t\tcommitted:          false,\r\n\t}, nil\r\n}","code-length":405,"reference":"\/\/ newImageDestination returns a types.ImageDestination for the specified image reference.","result":"Create a new image destination.","score":[0.1051,0.1053]}
{"code":"\/*is used to<extra_id_0>\r\nfunc imageLoadGoroutine(ctx context.Context, c *client.Client, reader *io.PipeReader, statusChannel chan<- error) {\r\n\terr := errors.New(\"Internal error: unexpected panic in imageLoadGoroutine\")\r\n\tdefer func() {\r\n\t\tlogrus.Debugf(\"docker-daemon: sending done, status %v\", err)\r\n\t\tstatusChannel <- err\r\n\t}()\r\n\tdefer func() {\r\n\t\tif err == nil {\r\n\t\t\treader.Close()\r\n\t\t} else {\r\n\t\t\treader.CloseWithError(err)\r\n\t\t}\r\n\t}()\r\n\tresp, err := c.ImageLoad(ctx, reader, true)\r\n\tif err != nil {\r\n\t\terr = errors.Wrap(err, \"Error saving image to docker engine\")\r\n\t\treturn\r\n\t}\r\n\tdefer resp.Body.Close()\r\n}","code-length":225,"reference":"\/\/ imageLoadGoroutine accepts tar stream on reader, sends it to c, and reports error or success by writing to statusChannel","result":"Run the image load goroutine.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewReference(file, image string) (types.ImageReference, error) {\r\n\tresolved, err := explicitfilepath.ResolvePathToFullyExplicit(file)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err := internal.ValidateOCIPath(file); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err := internal.ValidateImageName(image); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn ociArchiveReference{file: file, resolvedFile: resolved, image: image}, nil\r\n}","code-length":150,"reference":"\/\/ NewReference returns an OCI reference for a file and a image.","result":"Create a new reference.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc createOCIRef(image string) (tempDirOCIRef, error) {\r\n\tdir, err := ioutil.TempDir(tmpdir.TemporaryDirectoryForBigFiles(), \"oci\")\r\n\tif err != nil {\r\n\t\treturn tempDirOCIRef{}, errors.Wrapf(err, \"error creating temp directory\")\r\n\t}\r\n\tociRef, err := ocilayout.NewReference(dir, image)\r\n\tif err != nil {\r\n\t\treturn tempDirOCIRef{}, err\r\n\t}\r\n\ttempDirRef := tempDirOCIRef{tempDirectory: dir, ociRefExtracted: ociRef}\r\n\treturn tempDirRef, nil\r\n}","code-length":162,"reference":"\/\/ createOCIRef creates the oci reference of the image","result":"Create a reference to an OCI image.","score":[0.1214,0.1705]}
{"code":"\/*is used to<extra_id_0>\r\nfunc createUntarTempDir(ref ociArchiveReference) (tempDirOCIRef, error) {\r\n\ttempDirRef, err := createOCIRef(ref.image)\r\n\tif err != nil {\r\n\t\treturn tempDirOCIRef{}, errors.Wrap(err, \"error creating oci reference\")\r\n\t}\r\n\tsrc := ref.resolvedFile\r\n\tdst := tempDirRef.tempDirectory\r\n\t\r\n\tif err := archive.UntarPath(src, dst); err != nil {\r\n\t\tif err := tempDirRef.deleteTempDir(); err != nil {\r\n\t\t\treturn tempDirOCIRef{}, errors.Wrapf(err, \"error deleting temp directory %q\", tempDirRef.tempDirectory)\r\n\t\t}\r\n\t\treturn tempDirOCIRef{}, errors.Wrapf(err, \"error untarring file %q\", tempDirRef.tempDirectory)\r\n\t}\r\n\treturn tempDirRef, nil\r\n}","code-length":227,"reference":"\/\/ creates the temporary directory and copies the tarred content to it","result":"Create a temporary directory for the archive.","score":[0.1237,0.2745]}
{"code":"\/*is used to<extra_id_0>\r\nfunc destructivelyPrioritizeReplacementCandidatesWithMax(cs []CandidateWithTime, primaryDigest, uncompressedDigest digest.Digest, maxCandidates int) []types.BICReplacementCandidate {\r\n\t\r\n\t\r\n\tsort.Sort(&candidateSortState{\r\n\t\tcs:                 cs,\r\n\t\tprimaryDigest:      primaryDigest,\r\n\t\tuncompressedDigest: uncompressedDigest,\r\n\t})\r\n\tresLength := len(cs)\r\n\tif resLength > maxCandidates {\r\n\t\tresLength = maxCandidates\r\n\t}\r\n\tres := make([]types.BICReplacementCandidate, resLength)\r\n\tfor i := range res {\r\n\t\tres[i] = cs[i].Candidate\r\n\t}\r\n\treturn res\r\n}","code-length":187,"reference":"\/\/ destructivelyPrioritizeReplacementCandidatesWithMax is destructivelyPrioritizeReplacementCandidates with a parameter for the\n\/\/ number of entries to limit, only to make testing simpler.","result":"Sort the candidates.","score":[0.0014,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newImageDestination(ref ostreeReference, tmpDirPath string) (types.ImageDestination, error) {\r\n\ttmpDirPath = filepath.Join(tmpDirPath, ref.branchName)\r\n\tif err := ensureDirectoryExists(tmpDirPath); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &ostreeImageDestination{ref, \"\", manifestSchema{}, tmpDirPath, map[string]*blobToImport{}, \"\", 0, nil}, nil\r\n}","code-length":118,"reference":"\/\/ newImageDestination returns an ImageDestination for writing to an existing ostree.","result":"Create a new image destination.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc resolveExistingPathToFullyExplicit(path string) (string, error) {\r\n\tresolved, err := filepath.Abs(path)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tresolved, err = filepath.EvalSymlinks(resolved)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn filepath.Clean(resolved), nil\r\n}","code-length":106,"reference":"\/\/ resolveExistingPathToFullyExplicit is the same as ResolvePathToFullyExplicit,\n\/\/ but without the special case for missing final component.","result":"Resolve existing path to fully explicit.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newImageDestination(ref dirReference, compress bool) (types.ImageDestination, error) {\r\n\td := &dirImageDestination{ref: ref, compress: compress}\r\n\t\r\n\t\r\n\t\r\n\tdirExists, err := pathExists(d.ref.resolvedPath)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrapf(err, \"error checking for path %q\", d.ref.resolvedPath)\r\n\t}\r\n\tif dirExists {\r\n\t\tisEmpty, err := isDirEmpty(d.ref.resolvedPath)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tif !isEmpty {\r\n\t\t\tversionExists, err := pathExists(d.ref.versionPath())\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, errors.Wrapf(err, \"error checking if path exists %q\", d.ref.versionPath())\r\n\t\t\t}\r\n\t\t\tif versionExists {\r\n\t\t\t\tcontents, err := ioutil.ReadFile(d.ref.versionPath())\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn nil, err\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\tif string(contents) != version {\r\n\t\t\t\t\treturn nil, ErrNotContainerImageDir\r\n\t\t\t\t}\r\n\t\t\t} else {\r\n\t\t\t\treturn nil, ErrNotContainerImageDir\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif err = removeDirContents(d.ref.resolvedPath); err != nil {\r\n\t\t\t\treturn nil, errors.Wrapf(err, \"error erasing contents in %q\", d.ref.resolvedPath)\r\n\t\t\t}\r\n\t\t\tlogrus.Debugf(\"overwriting existing container image directory %q\", d.ref.resolvedPath)\r\n\t\t}\r\n\t} else {\r\n\t\t\r\n\t\tif err := os.MkdirAll(d.ref.resolvedPath, 0755); err != nil {\r\n\t\t\treturn nil, errors.Wrapf(err, \"unable to create directory %q\", d.ref.resolvedPath)\r\n\t\t}\r\n\t}\r\n\t\r\n\terr = ioutil.WriteFile(d.ref.versionPath(), []byte(version), 0644)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrapf(err, \"error creating version file %q\", d.ref.versionPath())\r\n\t}\r\n\treturn d, nil\r\n}","code-length":581,"reference":"\/\/ newImageDestination returns an ImageDestination for writing to a directory.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isDirEmpty(path string) (bool, error) {\r\n\tfiles, err := ioutil.ReadDir(path)\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\treturn len(files) == 0, nil\r\n}","code-length":71,"reference":"\/\/ returns true if directory is empty","result":"Check if a directory is empty.","score":[0.2558,0.3704]}
{"code":"\/*is used to<extra_id_0>\r\nfunc removeDirContents(path string) error {\r\n\tfiles, err := ioutil.ReadDir(path)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfor _, file := range files {\r\n\t\tif err := os.RemoveAll(filepath.Join(path, file.Name())); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":112,"reference":"\/\/ deletes the contents of a directory","result":"Remove directory contents.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetRepositoryTags(ctx context.Context, sys *types.SystemContext, ref types.ImageReference) ([]string, error) {\r\n\tdr, ok := ref.(dockerReference)\r\n\tif !ok {\r\n\t\treturn nil, errors.Errorf(\"ref must be a dockerReference\")\r\n\t}\r\n\tpath := fmt.Sprintf(tagsPath, reference.Path(dr.ref))\r\n\tclient, err := newDockerClientFromRef(sys, dr, false, \"pull\")\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"failed to create client\")\r\n\t}\r\n\ttags := make([]string, 0)\r\n\tfor {\r\n\t\tres, err := client.makeRequest(ctx, \"GET\", path, nil, nil, v2Auth, nil)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tdefer res.Body.Close()\r\n\t\tif res.StatusCode != http.StatusOK {\r\n\t\t\t\r\n\t\t\treturn nil, errors.Errorf(\"Invalid status code returned when fetching tags list %d (%s)\", res.StatusCode, http.StatusText(res.StatusCode))\r\n\t\t}\r\n\t\tvar tagsHolder struct {\r\n\t\t\tTags []string\r\n\t\t}\r\n\t\tif err = json.NewDecoder(res.Body).Decode(&tagsHolder); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\ttags = append(tags, tagsHolder.Tags...)\r\n\t\tlink := res.Header.Get(\"Link\")\r\n\t\tif link == \"\" {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tlinkURLStr := strings.Trim(strings.Split(link, \";\")[0], \"<>\")\r\n\t\tlinkURL, err := url.Parse(linkURLStr)\r\n\t\tif err != nil {\r\n\t\t\treturn tags, err\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tpath = linkURL.Path\r\n\t\tif linkURL.RawQuery != \"\" {\r\n\t\t\tpath += \"?\"\r\n\t\t\tpath += linkURL.RawQuery\r\n\t\t}\r\n\t}\r\n\treturn tags, nil\r\n}","code-length":533,"reference":"\/\/ GetRepositoryTags list all tags available in the repository. The tag\n\/\/ provided inside the ImageReference will be ignored.","result":"Code too long,keep in 512.","score":[0.0146,0.0284]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DefaultCache(sys *types.SystemContext) types.BlobInfoCache {\r\n\tdir, err := blobInfoCacheDir(sys, getRootlessUID())\r\n\tif err != nil {\r\n\t\tlogrus.Debugf(\"Error determining a location for %s, using a memory-only cache\", blobInfoCacheFilename)\r\n\t\treturn memory.New()\r\n\t}\r\n\tpath := filepath.Join(dir, blobInfoCacheFilename)\r\n\tif err := os.MkdirAll(dir, 0700); err != nil {\r\n\t\tlogrus.Debugf(\"Error creating parent directories for %s, using a memory-only cache: %v\", blobInfoCacheFilename, err)\r\n\t\treturn memory.New()\r\n\t}\r\n\tlogrus.Debugf(\"Using blob info cache at %s\", path)\r\n\treturn boltdb.New(path)\r\n}","code-length":209,"reference":"\/\/ DefaultCache returns the default BlobInfoCache implementation appropriate for sys.","result":"Create a default cache.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mem *cache) uncompressedDigestLocked(anyDigest digest.Digest) digest.Digest {\r\n\tif d, ok := mem.uncompressedDigests[anyDigest]; ok {\r\n\t\treturn d\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tif m, ok := mem.digestsByUncompressed[anyDigest]; ok && len(m) > 0 {\r\n\t\treturn anyDigest\r\n\t}\r\n\treturn \"\"\r\n}","code-length":116,"reference":"\/\/ uncompressedDigestLocked implements types.BlobInfoCache.UncompressedDigest, but must be called only with mem.mutex held.","result":"Lock the cache.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *ociArchiveImageDestination) Close() error {\r\n\tdefer d.tempDirRef.deleteTempDir()\r\n\treturn d.unpackedDest.Close()\r\n}","code-length":51,"reference":"\/\/ Close removes resources associated with an initialized ImageDestination, if any\n\/\/ Close deletes the temp directory of the oci-archive image","result":"Generate the generated code.","score":[0.0046,0.0259]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *ociArchiveImageDestination) PutManifest(ctx context.Context, m []byte) error {\r\n\treturn d.unpackedDest.PutManifest(ctx, m)\r\n}","code-length":52,"reference":"\/\/ PutManifest writes manifest to the destination","result":"Generate the generated code.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *ociArchiveImageDestination) Commit(ctx context.Context) error {\r\n\tif err := d.unpackedDest.Commit(ctx); err != nil {\r\n\t\treturn errors.Wrapf(err, \"error storing image %q\", d.ref.image)\r\n\t}\r\n\t\r\n\tsrc := d.tempDirRef.tempDirectory\r\n\t\r\n\tdst := d.ref.resolvedFile\r\n\treturn tarDirectory(src, dst)\r\n}","code-length":120,"reference":"\/\/ Commit marks the process of storing the image as successful and asks for the image to be persisted\n\/\/ after the directory is made, it is tarred up into a file and the directory is deleted","result":"Store the image in the archive.","score":[0.0017,0.059]}
{"code":"\/*is used to<extra_id_0>\r\nfunc tarDirectory(src, dst string) error {\r\n\t\r\n\tinput, err := archive.Tar(src, archive.Uncompressed)\r\n\tif err != nil {\r\n\t\treturn errors.Wrapf(err, \"error retrieving stream of bytes from %q\", src)\r\n\t}\r\n\t\r\n\toutFile, err := os.Create(dst)\r\n\tif err != nil {\r\n\t\treturn errors.Wrapf(err, \"error creating tar file %q\", dst)\r\n\t}\r\n\tdefer outFile.Close()\r\n\t\r\n\t\r\n\t_, err = io.Copy(outFile, input)\r\n\treturn err\r\n}","code-length":166,"reference":"\/\/ tar converts the directory at src and saves it to dst","result":"Create a directory tar file.","score":[0.0705,0.0885]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s storageTransport) ParseStoreReference(store storage.Store, ref string) (*storageReference, error) {\r\n\tif ref == \"\" {\r\n\t\treturn nil, errors.Wrapf(ErrInvalidReference, \"%q is an empty reference\", ref)\r\n\t}\r\n\tif ref[0] == '[' {\r\n\t\t\r\n\t\tcloseIndex := strings.IndexRune(ref, ']')\r\n\t\tif closeIndex < 1 {\r\n\t\t\treturn nil, errors.Wrapf(ErrInvalidReference, \"store specifier in %q did not end\", ref)\r\n\t\t}\r\n\t\tref = ref[closeIndex+1:]\r\n\t}\r\n\t\r\n\t\r\n\tsplit := strings.LastIndex(ref, \"@\")\r\n\tid := \"\"\r\n\tif split != -1 {\r\n\t\tpossibleID := ref[split+1:]\r\n\t\tif possibleID == \"\" {\r\n\t\t\treturn nil, errors.Wrapf(ErrInvalidReference, \"empty trailing digest or ID in %q\", ref)\r\n\t\t}\r\n\t\t\r\n\t\tif _, err := digest.Parse(possibleID); err != nil {\r\n\t\t\t\r\n\t\t\tif idSum, err := digest.Parse(\"sha256:\" + possibleID); err == nil && idSum.Validate() == nil {\r\n\t\t\t\tid = possibleID\r\n\t\t\t} else if img, err := store.Image(possibleID); err == nil && img != nil && len(possibleID) >= minimumTruncatedIDLength && strings.HasPrefix(img.ID, possibleID) {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tid = img.ID\r\n\t\t\t} else {\r\n\t\t\t\treturn nil, errors.Wrapf(ErrInvalidReference, \"%q does not look like an image ID or digest\", possibleID)\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tref = ref[:split]\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tif id == \"\" && len(ref) >= minimumTruncatedIDLength && !strings.ContainsAny(ref, \"@:\") {\r\n\t\tif img, err := store.Image(ref); err == nil && img != nil && strings.HasPrefix(img.ID, ref) {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tid = img.ID\r\n\t\t\tref = \"\"\r\n\t\t}\r\n\t}\r\n\tvar named reference.Named\r\n\t\r\n\t\r\n\tif ref != \"\" {\r\n\t\tvar err error\r\n\t\tnamed, err = reference.ParseNormalizedNamed(ref)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, errors.Wrapf(err, \"error parsing named reference %q\", ref)\r\n\t\t}\r\n\t\tnamed = reference.TagNameOnly(named)\r\n\t}\r\n\tresult, err := newReference(storageTransport{store: store, defaultUIDMap: s.defaultUIDMap, defaultGIDMap: s.defaultGIDMap}, named, id)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tlogrus.Debugf(\"parsed reference into %q\", result.StringWithinTransport())\r\n\treturn result, nil\r\n}","code-length":746,"reference":"\/\/ ParseStoreReference takes a name or an ID, tries to figure out which it is\n\/\/ relative to the given store, and returns it in a reference object.","result":"Code too long,keep in 512.","score":[0.0024,0.0195]}
{"code":"\/*is used to<extra_id_0>\r\nfunc chooseDigestFromManifestList(sys *types.SystemContext, blob []byte) (digest.Digest, error) {\r\n\twantedArch := runtime.GOARCH\r\n\tif sys != nil && sys.ArchitectureChoice != \"\" {\r\n\t\twantedArch = sys.ArchitectureChoice\r\n\t}\r\n\twantedOS := runtime.GOOS\r\n\tif sys != nil && sys.OSChoice != \"\" {\r\n\t\twantedOS = sys.OSChoice\r\n\t}\r\n\tlist := manifestList{}\r\n\tif err := json.Unmarshal(blob, &list); err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tfor _, d := range list.Manifests {\r\n\t\tif d.Platform.Architecture == wantedArch && d.Platform.OS == wantedOS {\r\n\t\t\treturn d.Digest, nil\r\n\t\t}\r\n\t}\r\n\treturn \"\", fmt.Errorf(\"no image found in manifest list for architecture %s, OS %s\", wantedArch, wantedOS)\r\n}","code-length":245,"reference":"\/\/ chooseDigestFromManifestList parses blob as a schema2 manifest list,\n\/\/ and returns the digest of the image appropriate for the current environment.","result":"Generate a manifest list from a manifest list.","score":[0.0287,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ChooseManifestInstanceFromManifestList(ctx context.Context, sys *types.SystemContext, src types.UnparsedImage) (digest.Digest, error) {\r\n\t\r\n\t\r\n\tblob, mt, err := src.Manifest(ctx)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tif mt != manifest.DockerV2ListMediaType {\r\n\t\treturn \"\", fmt.Errorf(\"Internal error: Trying to select an image from a non-manifest-list manifest type %s\", mt)\r\n\t}\r\n\treturn chooseDigestFromManifestList(sys, blob)\r\n}","code-length":152,"reference":"\/\/ ChooseManifestInstanceFromManifestList returns a digest of a manifest appropriate\n\/\/ for the current system from the manifest available from src.","result":"Select an image from a manifest list.","score":[0.0395,0.0802]}
{"code":"\/*is used to<extra_id_0>\r\nfunc manifestSchema1FromComponents(ref reference.Named, fsLayers []manifest.Schema1FSLayers, history []manifest.Schema1History, architecture string) (genericManifest, error) {\r\n\tm, err := manifest.Schema1FromComponents(ref, fsLayers, history, architecture)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &manifestSchema1{m: m}, nil\r\n}","code-length":110,"reference":"\/\/ manifestSchema1FromComponents builds a new manifestSchema1 from the supplied data.","result":"Generate the manifest.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *dockerImageSource) manifestDigest(ctx context.Context, instanceDigest *digest.Digest) (digest.Digest, error) {\r\n\tif instanceDigest != nil {\r\n\t\treturn *instanceDigest, nil\r\n\t}\r\n\tif digested, ok := s.ref.ref.(reference.Digested); ok {\r\n\t\td := digested.Digest()\r\n\t\tif d.Algorithm() == digest.Canonical {\r\n\t\t\treturn d, nil\r\n\t\t}\r\n\t}\r\n\tif err := s.ensureManifestIsLoaded(ctx); err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn manifest.Digest(s.cachedManifest)\r\n}","code-length":174,"reference":"\/\/ manifestDigest returns a digest of the manifest, from instanceDigest if non-nil; or from the supplied reference,\n\/\/ or finally, from a fetched manifest.","result":"Generate the generated code.","score":[0.0022,0.0227]}
{"code":"\/*is used to<extra_id_0>\r\nfunc deleteImage(ctx context.Context, sys *types.SystemContext, ref dockerReference) error {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tc, err := newDockerClientFromRef(sys, ref, true, \"*\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t\r\n\theaders := make(map[string][]string)\r\n\theaders[\"Accept\"] = []string{manifest.DockerV2Schema2MediaType}\r\n\trefTail, err := ref.tagOrDigest()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tgetPath := fmt.Sprintf(manifestPath, reference.Path(ref.ref), refTail)\r\n\tget, err := c.makeRequest(ctx, \"GET\", getPath, headers, nil, v2Auth, nil)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer get.Body.Close()\r\n\tmanifestBody, err := ioutil.ReadAll(get.Body)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tswitch get.StatusCode {\r\n\tcase http.StatusOK:\r\n\tcase http.StatusNotFound:\r\n\t\treturn errors.Errorf(\"Unable to delete %v. Image may not exist or is not stored with a v2 Schema in a v2 registry\", ref.ref)\r\n\tdefault:\r\n\t\treturn errors.Errorf(\"Failed to delete %v: %s (%v)\", ref.ref, manifestBody, get.Status)\r\n\t}\r\n\tdigest := get.Header.Get(\"Docker-Content-Digest\")\r\n\tdeletePath := fmt.Sprintf(manifestPath, reference.Path(ref.ref), digest)\r\n\t\r\n\t\r\n\tdelete, err := c.makeRequest(ctx, \"DELETE\", deletePath, headers, nil, v2Auth, nil)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer delete.Body.Close()\r\n\tbody, err := ioutil.ReadAll(delete.Body)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif delete.StatusCode != http.StatusAccepted {\r\n\t\treturn errors.Errorf(\"Failed to delete %v: %s (%v)\", deletePath, string(body), delete.Status)\r\n\t}\r\n\tif c.signatureBase != nil {\r\n\t\tmanifestDigest, err := manifest.Digest(manifestBody)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tfor i := 0; ; i++ {\r\n\t\t\turl := signatureStorageURL(c.signatureBase, manifestDigest, i)\r\n\t\t\tif url == nil {\r\n\t\t\t\treturn errors.Errorf(\"Internal error: signatureStorageURL with non-nil base returned nil\")\r\n\t\t\t}\r\n\t\t\tmissing, err := c.deleteOneSignature(url)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif missing {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":760,"reference":"\/\/ deleteImage deletes the named image from the registry, if supported.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Schema1FromComponents(ref reference.Named, fsLayers []Schema1FSLayers, history []Schema1History, architecture string) (*Schema1, error) {\r\n\tvar name, tag string\r\n\tif ref != nil {\r\n\t\tname = reference.Path(ref)\r\n\t\tif tagged, ok := ref.(reference.NamedTagged); ok {\r\n\t\t\ttag = tagged.Tag()\r\n\t\t}\r\n\t}\r\n\ts1 := Schema1{\r\n\t\tName:          name,\r\n\t\tTag:           tag,\r\n\t\tArchitecture:  architecture,\r\n\t\tFSLayers:      fsLayers,\r\n\t\tHistory:       history,\r\n\t\tSchemaVersion: 1,\r\n\t}\r\n\tif err := s1.initialize(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &s1, nil\r\n}","code-length":222,"reference":"\/\/ Schema1FromComponents creates an Schema1 manifest instance from the supplied data.","result":"Create a schema.","score":[0,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Schema1) initialize() error {\r\n\tif len(m.FSLayers) != len(m.History) {\r\n\t\treturn errors.New(\"length of history not equal to number of layers\")\r\n\t}\r\n\tif len(m.FSLayers) == 0 {\r\n\t\treturn errors.New(\"no FSLayers in manifest\")\r\n\t}\r\n\tm.ExtractedV1Compatibility = make([]Schema1V1Compatibility, len(m.History))\r\n\tfor i, h := range m.History {\r\n\t\tif err := json.Unmarshal([]byte(h.V1Compatibility), &m.ExtractedV1Compatibility[i]); err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"Error parsing v2s1 history entry %d\", i)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":215,"reference":"\/\/ initialize initializes ExtractedV1Compatibility and verifies invariants, so that the rest of this code can assume a minimally healthy manifest.","result":"Generate the generated code.","score":[0.0059,0.0272]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Schema1) ToSchema2Config(diffIDs []digest.Digest) ([]byte, error) {\r\n\t\r\n\t\r\n\tif len(m.History) == 0 {\r\n\t\treturn nil, errors.New(\"image has no layers\")\r\n\t}\r\n\ts1 := Schema2V1Image{}\r\n\tconfig := []byte(m.History[0].V1Compatibility)\r\n\terr := json.Unmarshal(config, &s1)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrapf(err, \"error decoding configuration\")\r\n\t}\r\n\t\r\n\t\r\n\tif s1.DockerVersion != \"\" && versions.LessThan(s1.DockerVersion, \"1.8.3\") {\r\n\t\tconfig, err = json.Marshal(&s1)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, errors.Wrapf(err, \"error re-encoding compat image config %#v\", s1)\r\n\t\t}\r\n\t}\r\n\t\r\n\tconvertedHistory := []Schema2History{}\r\n\tfor _, compat := range m.ExtractedV1Compatibility {\r\n\t\thitem := Schema2History{\r\n\t\t\tCreated:    compat.Created,\r\n\t\t\tCreatedBy:  strings.Join(compat.ContainerConfig.Cmd, \" \"),\r\n\t\t\tAuthor:     compat.Author,\r\n\t\t\tComment:    compat.Comment,\r\n\t\t\tEmptyLayer: compat.ThrowAway,\r\n\t\t}\r\n\t\tconvertedHistory = append([]Schema2History{hitem}, convertedHistory...)\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\trootFS := &Schema2RootFS{\r\n\t\tType:    \"layers\",\r\n\t\tDiffIDs: diffIDs,\r\n\t}\r\n\t\r\n\traw := make(map[string]*json.RawMessage)\r\n\terr = json.Unmarshal(config, &raw)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrapf(err, \"error re-decoding compat image config %#v\", s1)\r\n\t}\r\n\t\r\n\tdelete(raw, \"id\")\r\n\tdelete(raw, \"parent\")\r\n\tdelete(raw, \"parent_id\")\r\n\tdelete(raw, \"layer_id\")\r\n\tdelete(raw, \"throwaway\")\r\n\tdelete(raw, \"Size\")\r\n\t\r\n\trootfs, err := json.Marshal(rootFS)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Errorf(\"error encoding rootfs information %#v: %v\", rootFS, err)\r\n\t}\r\n\trawRootfs := json.RawMessage(rootfs)\r\n\traw[\"rootfs\"] = &rawRootfs\r\n\thistory, err := json.Marshal(convertedHistory)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Errorf(\"error encoding history information %#v: %v\", convertedHistory, err)\r\n\t}\r\n\trawHistory := json.RawMessage(history)\r\n\traw[\"history\"] = &rawHistory\r\n\t\r\n\tconfig, err = json.Marshal(raw)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Errorf(\"error re-encoding compat image config %#v: %v\", s1, err)\r\n\t}\r\n\treturn config, nil\r\n}","code-length":813,"reference":"\/\/ ToSchema2Config builds a schema2-style configuration blob using the supplied diffIDs.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Digest(manifest []byte) (digest.Digest, error) {\r\n\tif GuessMIMEType(manifest) == DockerV2Schema1SignedMediaType {\r\n\t\tsig, err := libtrust.ParsePrettySignature(manifest, \"signatures\")\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", err\r\n\t\t}\r\n\t\tmanifest, err = sig.Payload()\r\n\t\tif err != nil {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\treturn \"\", err\r\n\t\t}\r\n\t}\r\n\treturn digest.FromBytes(manifest), nil\r\n}","code-length":141,"reference":"\/\/ Digest returns the a digest of a docker manifest, with any necessary implied transformations like stripping v1s1 signatures.","result":"Generate digests.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MatchesDigest(manifest []byte, expectedDigest digest.Digest) (bool, error) {\r\n\t\r\n\tactualDigest, err := Digest(manifest)\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\treturn expectedDigest == actualDigest, nil\r\n}","code-length":78,"reference":"\/\/ MatchesDigest returns true iff the manifest matches expectedDigest.\n\/\/ Error may be set if this returns false.\n\/\/ Note that this is not doing ConstantTimeCompare; by the time we get here, the cryptographic signature must already have been verified,\n\/\/ or we are not using a cryptographic channel and the attacker can modify the digest along with the manifest blob.","result":"Match digests.","score":[0,0.0091]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NormalizedMIMEType(input string) string {\r\n\tswitch input {\r\n\tase DockerV2Schema1MediaType, DockerV2Schema1SignedMediaType,\r\n\t\timgspecv1.MediaTypeImageManifest,\r\n\t\tDockerV2Schema2MediaType,\r\n\t\tDockerV2ListMediaType:\r\n\t\treturn input\r\n\tdefault:\r\n\t\t\r\n\t\t","code-length":97,"reference":"\/\/ NormalizedMIMEType returns the effective MIME type of a manifest MIME type returned by a server,\n\/\/ centralizing various workarounds.","result":"Normalize the MIME type.","score":[0.007,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FromBlob(manblob []byte, mt string) (Manifest, error) {\r\n\tswitch NormalizedMIMEType(mt) {\r\n\tcase DockerV2Schema1MediaType, DockerV2Schema1SignedMediaType:\r\n\t\treturn Schema1FromManifest(manblob)\r\n\tcase imgspecv1.MediaTypeImageManifest:\r\n\t\treturn OCI1FromManifest(manblob)\r\n\tcase DockerV2Schema2MediaType:\r\n\t\treturn Schema2FromManifest(manblob)\r\n\tcase DockerV2ListMediaType:\r\n\t\treturn nil, fmt.Errorf(\"Treating manifest lists as individual manifests is not implemented\")\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"Unimplemented manifest MIME type %s\", mt)\r\n\t}\r\n}","code-length":187,"reference":"\/\/ FromBlob returns a Manifest instance for the specified manifest blob and the corresponding MIME type","result":"Create a manifest from a blob.","score":[0.0434,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewReference(path string) (types.ImageReference, error) {\r\n\tresolved, err := explicitfilepath.ResolvePathToFullyExplicit(path)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn dirReference{path: path, resolvedPath: resolved}, nil\r\n}","code-length":83,"reference":"\/\/ There is no directory.ParseReference because it is rather pointless.\n\/\/ Callers who need a transport-independent interface will go through\n\/\/ dirTransport.ParseReference; callers who intentionally deal with directories\n\/\/ can use directory.NewReference.\n\/\/ NewReference returns a directory reference for a specified path.\n\/\/\n\/\/ We do not expose an API supplying the resolvedPath; we could, but recomputing it\n\/\/ is generally cheap enough that we prefer being confident about the properties of resolvedPath.","result":"Create a new reference.","score":[0.0,0.0076]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ref dirReference) layerPath(digest digest.Digest) string {\r\n\t\r\n\treturn filepath.Join(ref.path, digest.Hex())\r\n}","code-length":47,"reference":"\/\/ layerPath returns a path for a layer tarball within a directory using our conventions.","result":"Generate the layer path.","score":[0.0204,0.036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ref dirReference) signaturePath(index int) string {\r\n\treturn filepath.Join(ref.path, fmt.Sprintf(\"signature-%d\", index+1))\r\n}","code-length":51,"reference":"\/\/ signaturePath returns a path for a signature within a directory using our conventions.","result":"Generate the signature.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(n int, ctor func() Worker) *Pool {\r\n\tp := &Pool{\r\n\t\tctor:    ctor,\r\n\t\treqChan: make(chan workRequest),\r\n\t}\r\n\tp.SetSize(n)\r\n\treturn p\r\n}","code-length":75,"reference":"\/\/ New creates a new Pool of workers that starts with n workers. You must\n\/\/ provide a constructor function that creates new Worker types and when you\n\/\/ change the size of the pool the constructor will be called to create each new\n\/\/ Worker.","result":"Create a new pool.","score":[0.0,0.0359]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFunc(n int, f func(interface{}) interface{}) *Pool {\r\n\treturn New(n, func() Worker {\r\n\t\treturn &closureWorker{\r\n\t\t\tprocessor: f,\r\n\t\t}\r\n\t})\r\n}","code-length":69,"reference":"\/\/ NewFunc creates a new Pool of workers where each worker will process using\n\/\/ the provided func.","result":"Create a closure closure pool.","score":[0.0178,0.1123]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Pool) ProcessTimed(\r\n\tpayload interface{},\r\n\ttimeout time.Duration,\r\n) (interface{}, error) {\r\n\tatomic.AddInt64(&p.queuedJobs, 1)\r\n\tdefer atomic.AddInt64(&p.queuedJobs, -1)\r\n\ttout := time.NewTimer(timeout)\r\n\tvar request workRequest\r\n\tvar open bool\r\n\tselect {\r\n\tcase request, open = <-p.reqChan:\r\n\t\tif !open {\r\n\t\t\treturn nil, ErrPoolNotRunning\r\n\t\t}\r\n\tcase <-tout.C:\r\n\t\treturn nil, ErrJobTimedOut\r\n\t}\r\n\tselect {\r\n\tcase request.jobChan <- payload:\r\n\tcase <-tout.C:\r\n\t\trequest.interruptFunc()\r\n\t\treturn nil, ErrJobTimedOut\r\n\t}\r\n\tselect {\r\n\tcase payload, open = <-request.retChan:\r\n\t\tif !open {\r\n\t\t\treturn nil, ErrWorkerClosed\r\n\t\t}\r\n\tcase <-tout.C:\r\n\t\trequest.interruptFunc()\r\n\t\treturn nil, ErrJobTimedOut\r\n\t}\r\n\ttout.Stop()\r\n\treturn payload, nil\r\n}","code-length":314,"reference":"\/\/ ProcessTimed will use the Pool to process a payload and synchronously return\n\/\/ the result. If the timeout occurs before the job has finished the worker will\n\/\/ be interrupted and ErrJobTimedOut will be returned. ProcessTimed can be\n\/\/ called safely by any goroutines.","result":"Process jobs in the pool.","score":[0.0001,0.0366]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Pool) SetSize(n int) {\r\n\tp.workerMut.Lock()\r\n\tdefer p.workerMut.Unlock()\r\n\tlWorkers := len(p.workers)\r\n\tif lWorkers == n {\r\n\t\treturn\r\n\t}\r\n\t\r\n\tfor i := lWorkers; i < n; i++ {\r\n\t\tp.workers = append(p.workers, newWorkerWrapper(p.reqChan, p.ctor()))\r\n\t}\r\n\t\r\n\tfor i := n; i < lWorkers; i++ {\r\n\t\tp.workers[i].stop()\r\n\t}\r\n\t\r\n\tfor i := n; i < lWorkers; i++ {\r\n\t\tp.workers[i].join()\r\n\t}\r\n\t\r\n\tp.workers = p.workers[:n]\r\n}","code-length":213,"reference":"\/\/ SetSize changes the total number of workers in the Pool. This can be called\n\/\/ by any goroutine at any time unless the Pool has been stopped, in which case\n\/\/ a panic will occur.","result":"Set the size of the pool.","score":[0.0017,0.0606]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Pool) GetSize() int {\r\n\tp.workerMut.Lock()\r\n\tdefer p.workerMut.Unlock()\r\n\treturn len(p.workers)\r\n}","code-length":54,"reference":"\/\/ GetSize returns the current size of the pool.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Rect) TL() Point {\r\n\treturn Point{int(r.x), int(r.y)}\r\n}","code-length":40,"reference":"\/\/ Returns the Top-Left Point of the rectangle","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Rect) BR() Point {\r\n\treturn Point{int(r.x) + int(r.width), int(r.y) + int(r.height)}\r\n}","code-length":54,"reference":"\/\/ Returns the Bottom-Right Point of the rectangle","result":"Create a new function.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (box *Box2D) CVBox() C.CvBox2D {\r\n\tvar cvBox C.CvBox2D\r\n\tcvBox.angle = C.float(box.angle)\r\n\tcvBox.center.x = C.float(box.center.X)\r\n\tcvBox.center.y = C.float(box.center.Y)\r\n\tcvBox.size.width = C.float(box.size.Width)\r\n\tcvBox.size.height = C.float(box.size.Height)\r\n\treturn cvBox\r\n}","code-length":147,"reference":"\/\/ Returns a CvBox2D","result":"Generate the CVBox function.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (box *Box2D) Points() []Point2D32f {\r\n\tvar pts [4]C.CvPoint2D32f\r\n\tC.cvBoxPoints(\r\n\t\tbox.CVBox(),\r\n\t\t(*C.CvPoint2D32f)(unsafe.Pointer(&pts[0])),\r\n\t)\r\n\toutPts := make([]Point2D32f, 4)\r\n\tfor i, p := range pts {\r\n\t\toutPts[i].X = float32(p.x)\r\n\t\toutPts[i].Y = float32(p.y)\r\n\t}\r\n\treturn outPts\r\n}","code-length":168,"reference":"\/\/ Finds box vertices","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FOURCC(c1, c2, c3, c4 int8) uint32 {\r\n\trv := C.GoOpenCV_FOURCC_(C.int(c1), C.int(c2), C.int(c3), C.int(c4))\r\n\treturn uint32(rv)\r\n}","code-length":87,"reference":"\/\/ Prototype for CV_FOURCC so that swig can generate wrapper without mixing up the define","result":"Generate the FOURCC function.","score":[0.0204,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Merge(imgBlue, imgGreen, imgRed, imgAlpha, dst *IplImage) {\r\n\tC.cvMerge(\r\n\t\tunsafe.Pointer(imgBlue),\r\n\t\tunsafe.Pointer(imgGreen),\r\n\t\tunsafe.Pointer(imgRed),\r\n\t\tunsafe.Pointer(imgAlpha),\r\n\t\tunsafe.Pointer(dst),\r\n\t)\r\n}","code-length":105,"reference":"\/\/ Merge creates one multichannel array out of several single-channel ones.","result":"Merge images.","score":[0.0056,0.0495]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Split(src, imgBlue, imgGreen, imgRed, imgAlpha *IplImage) {\r\n\tC.cvSplit(\r\n\t\tunsafe.Pointer(src),\r\n\t\tunsafe.Pointer(imgBlue),\r\n\t\tunsafe.Pointer(imgGreen),\r\n\t\tunsafe.Pointer(imgRed),\r\n\t\tunsafe.Pointer(imgAlpha),\r\n\t)\r\n}","code-length":105,"reference":"\/\/ Split divides a multi-channel array into several single-channel arrays.","result":"Split the image .","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AddWeighted(src1 *IplImage, alpha float64, src2 *IplImage, beta float64, gamma float64, dst *IplImage) {\r\n\tC.cvAddWeighted(\r\n\t\tunsafe.Pointer(src1),\r\n\t\tC.double(alpha),\r\n\t\tunsafe.Pointer(src2),\r\n\t\tC.double(beta),\r\n\t\tC.double(gamma),\r\n\t\tunsafe.Pointer(dst),\r\n\t)\r\n}","code-length":129,"reference":"\/\/ AddWeighted calculates the weighted sum of two images.","result":"Add weighted images.","score":[0.0657,0.1786]}
{"code":"\/*is used to<extra_id_0>\r\nfunc And(src1, src2, dst *IplImage) {\r\n\tAndWithMask(src1, src2, dst, nil)\r\n}","code-length":45,"reference":"\/\/ Calculates the per-element bit-wise conjunction of two arrays.","result":"Create a new image.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AndWithMask(src1, src2, dst, mask *IplImage) {\r\n\tC.cvAnd(\r\n\t\tunsafe.Pointer(src1),\r\n\t\tunsafe.Pointer(src2),\r\n\t\tunsafe.Pointer(dst),\r\n\t\tunsafe.Pointer(mask),\r\n\t)\r\n}","code-length":90,"reference":"\/\/ Calculates the per-element bit-wise conjunction of two arrays with a mask.","result":"Create a function to do the actual and operation.","score":[0.1038,0.0855]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AndScalar(src *IplImage, value Scalar, dst *IplImage) {\r\n\tAndScalarWithMask(src, value, dst, nil)\r\n}","code-length":48,"reference":"\/\/ Calculates the per-element bit-wise conjunction of an array and a scalar.","result":"Generate the generated code.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AndScalarWithMask(src *IplImage, value Scalar, dst, mask *IplImage) {\r\n\tC.cvAndS(\r\n\t\tunsafe.Pointer(src),\r\n\t\t(C.CvScalar)(value),\r\n\t\tunsafe.Pointer(dst),\r\n\t\tunsafe.Pointer(mask),\r\n\t)\r\n}","code-length":95,"reference":"\/\/ Calculates the per-element bit-wise conjunction of an array and a scalar with a mask.","result":"Create a function to do the same thing.","score":[0.0688,0.0699]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Or(src1, src2, dst *IplImage) {\r\n\tOrWithMask(src1, src2, dst, nil)\r\n}","code-length":45,"reference":"\/\/ Calculates the per-element bit-wise disjunction of two arrays.","result":"Create the image.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OrWithMask(src1, src2, dst, mask *IplImage) {\r\n\tC.cvOr(\r\n\t\tunsafe.Pointer(src1),\r\n\t\tunsafe.Pointer(src2),\r\n\t\tunsafe.Pointer(dst),\r\n\t\tunsafe.Pointer(mask),\r\n\t)\r\n}","code-length":90,"reference":"\/\/ Calculates the per-element bit-wise disjunction of two arrays with a mask.","result":"Create a function to create the image .","score":[0.1002,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OrScalar(src *IplImage, value Scalar, dst *IplImage) {\r\n\tOrScalarWithMask(src, value, dst, nil)\r\n}","code-length":48,"reference":"\/\/ Calculates the per-element bit-wise disjunction of an array and a scalar.","result":"Generate the code.","score":[0.0203,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OrScalarWithMask(src *IplImage, value Scalar, dst, mask *IplImage) {\r\n\tC.cvOrS(\r\n\t\tunsafe.Pointer(src),\r\n\t\t(C.CvScalar)(value),\r\n\t\tunsafe.Pointer(dst),\r\n\t\tunsafe.Pointer(mask),\r\n\t)\r\n}","code-length":95,"reference":"\/\/ Calculates the per-element bit-wise disjunction of an array and a scalar with a mask.","result":"Create the image .","score":[0.0204,0.036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AddWithMask(src1, src2, dst, mask *IplImage) {\r\n\tC.cvAdd(\r\n\t\tunsafe.Pointer(src1),\r\n\t\tunsafe.Pointer(src2),\r\n\t\tunsafe.Pointer(dst),\r\n\t\tunsafe.Pointer(mask),\r\n\t)\r\n}","code-length":90,"reference":"\/\/ Calculates the per-element sum of two arrays with a mask.\n\/\/   dst = src1 + src2","result":"Add images with mask.","score":[0.0147,0.0955]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AddScalar(src *IplImage, value Scalar, dst *IplImage) {\r\n\tAddScalarWithMask(src, value, dst, nil)\r\n}","code-length":48,"reference":"\/\/ Calculates the per-element sum of an array and a scalar.\n\/\/   dst = src + value","result":"Generate the generated code.","score":[0.0124,0.0318]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AddScalarWithMask(src *IplImage, value Scalar, dst, mask *IplImage) {\r\n\tC.cvAddS(\r\n\t\tunsafe.Pointer(src),\r\n\t\t(C.CvScalar)(value),\r\n\t\tunsafe.Pointer(dst),\r\n\t\tunsafe.Pointer(mask),\r\n\t)\r\n}","code-length":95,"reference":"\/\/ Calculates the per-element sum of an array and a scalar with a mask.\n\/\/   dst = src + value","result":"Add a scalar with mask.","score":[0.0265,0.2011]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Subtract(src1, src2, dst *IplImage) {\r\n\tSubtractWithMask(src1, src2, dst, nil)\r\n}","code-length":46,"reference":"\/\/ Calculates the per-element difference between two arrays.\n\/\/   dst = src1 - src2","result":"Create a new function .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SubtractWithMask(src1, src2, dst, mask *IplImage) {\r\n\tC.cvSub(\r\n\t\tunsafe.Pointer(src1),\r\n\t\tunsafe.Pointer(src2),\r\n\t\tunsafe.Pointer(dst),\r\n\t\tunsafe.Pointer(mask),\r\n\t)\r\n}","code-length":91,"reference":"\/\/ Calculates the per-element difference between two arrays with a mask.\n\/\/   dst = src1 - src2","result":"Create a function to perform the subtraction.","score":[0.046,0.0625]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SubScalar(src *IplImage, value Scalar, dst *IplImage) {\r\n\tSubScalarWithMask(src, value, dst, nil)\r\n}","code-length":48,"reference":"\/\/ Calculates the per-element difference between an array and a scalar.\n\/\/   dst = src - value","result":"Generate the code.","score":[0.0038,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SubScalarWithMask(src *IplImage, value Scalar, dst, mask *IplImage) {\r\n\tC.cvSubS(\r\n\t\tunsafe.Pointer(src),\r\n\t\t(C.CvScalar)(value),\r\n\t\tunsafe.Pointer(dst),\r\n\t\tunsafe.Pointer(mask),\r\n\t)\r\n}","code-length":95,"reference":"\/\/ Calculates the per-element difference between an array and a scalar with a mask.\n\/\/   dst = src - value","result":"Create a function to sub.","score":[0.012,0.027]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SubScalarRev(value Scalar, src, dst *IplImage) {\r\n\tSubScalarWithMaskRev(value, src, dst, nil)\r\n}","code-length":46,"reference":"\/\/ Calculates the per-element difference between a scalar and an array.\n\/\/   dst = value - src","result":"Generate the code.","score":[0.0038,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SubScalarWithMaskRev(value Scalar, src, dst, mask *IplImage) {\r\n\tC.cvSubRS(\r\n\t\tunsafe.Pointer(src),\r\n\t\t(C.CvScalar)(value),\r\n\t\tunsafe.Pointer(dst),\r\n\t\tunsafe.Pointer(mask),\r\n\t)\r\n}","code-length":92,"reference":"\/\/ Calculates the per-element difference between a scalar and an array with a mask.\n\/\/   dst = value - src","result":"SubScalarWithMaskRev.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AbsDiff(src1, src2, dst *IplImage) {\r\n\tC.cvAbsDiff(\r\n\t\tunsafe.Pointer(src1),\r\n\t\tunsafe.Pointer(src2),\r\n\t\tunsafe.Pointer(dst),\r\n\t)\r\n}","code-length":77,"reference":"\/\/ Calculates the per-element absolute difference between two arrays.","result":"Compute the absolute difference of two images.","score":[0.2041,0.3587]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AbsDiffScalar(src *IplImage, value Scalar, dst *IplImage) {\r\n\tC.cvAbsDiffS(\r\n\t\tunsafe.Pointer(src),\r\n\t\tunsafe.Pointer(dst),\r\n\t\t(C.CvScalar)(value),\r\n\t)\r\n}","code-length":82,"reference":"\/\/ Calculates the per-element absolute difference between an array and a scalar.","result":"Compute the abs difference in the image.","score":[0.094,0.087]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MeanStdDevWithMask(src, mask *IplImage) (Scalar, Scalar) {\r\n\tvar mean, stdDev Scalar\r\n\tC.cvAvgSdv(\r\n\t\tunsafe.Pointer(src),\r\n\t\t(*C.CvScalar)(&mean),\r\n\t\t(*C.CvScalar)(&stdDev),\r\n\t\tunsafe.Pointer(mask),\r\n\t)\r\n\treturn mean, stdDev\r\n}","code-length":115,"reference":"\/\/ MeanStdDevWithMask calculates mean and standard deviation of pixel values with mask","result":"Compute the mean and std dev of the image .","score":[0.1391,0.2166]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CreateSeq(seq_flags, elem_size int) *Seq {\r\n\treturn (*Seq)(C.cvCreateSeq(\r\n\t\tC.int(seq_flags),\r\n\t\tC.size_t(unsafe.Sizeof(Seq{})),\r\n\t\tC.size_t(elem_size),\r\n\t\tC.cvCreateMemStorage(C.int(0)),\r\n\t))\r\n}","code-length":110,"reference":"\/\/ Creates a new sequence.","result":"Create a new Seq.","score":[0.3519,0.6009]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (seq *Seq) Push(element unsafe.Pointer) unsafe.Pointer {\r\n\treturn unsafe.Pointer(C.cvSeqPush((*C.struct_CvSeq)(seq), element))\r\n}","code-length":56,"reference":"\/\/ Adds an element to the sequence end.\n\/\/ Returns a pointer to the element added.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (seq *Seq) Pop(element unsafe.Pointer) {\r\n\tC.cvSeqPop((*C.struct_CvSeq)(seq), element)\r\n}","code-length":48,"reference":"\/\/ Removes element from the sequence end.\n\/\/ Copies the element into the paramter element.","result":"Generate the code.","score":[0.0075,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (seq *Seq) PushFront(element unsafe.Pointer) unsafe.Pointer {\r\n\treturn unsafe.Pointer((C.cvSeqPushFront((*C.struct_CvSeq)(seq), element)))\r\n}","code-length":58,"reference":"\/\/ Adds an element to the sequence beginning.\n\/\/ Returns a pointer to the element added.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (seq *Seq) PopFront(element unsafe.Pointer) {\r\n\tC.cvSeqPopFront((*C.struct_CvSeq)(seq), element)\r\n}","code-length":50,"reference":"\/\/ Removes element from the sequence beginning.\n\/\/ Copies the element into the paramter element.","result":"Generate the code.","score":[0.0075,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (seq *Seq) GetElemAt(index int) unsafe.Pointer {\r\n\treturn (unsafe.Pointer)(C.cvGetSeqElem(\r\n\t\t(*C.struct_CvSeq)(seq),\r\n\t\tC.int(index),\r\n\t))\r\n}","code-length":75,"reference":"\/\/ Gets a pointer to the element at the index","result":"Get the element at index.","score":[0.1821,0.3322]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (seq *Seq) RemoveAt(index int) {\r\n\tC.cvSeqRemove((*C.struct_CvSeq)(seq), C.int(index))\r\n}","code-length":51,"reference":"\/\/ Removes an element from the middle of a sequence.","result":"Remove the element at index.","score":[0.1051,0.1579]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Delay(delay time.Duration) Option {\r\n\treturn func(c *Config) {\r\n\t\tc.delay = delay\r\n\t}\r\n}","code-length":46,"reference":"\/\/ Delay set delay between retry\n\/\/ default is 100ms","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc BackOffDelay(n uint, config *Config) time.Duration {\r\n\treturn config.delay * (1 << (n - 1))\r\n}","code-length":44,"reference":"\/\/ BackOffDelay is a DelayType which increases delay between consecutive retries","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e Error) Error() string {\r\n\tlogWithNumber := make([]string, lenWithoutNil(e))\r\n\tfor i, l := range e {\r\n\t\tif l != nil {\r\n\t\t\tlogWithNumber[i] = fmt.Sprintf(\"#%d: %s\", i+1, l.Error())\r\n\t\t}\r\n\t}\r\n\treturn fmt.Sprintf(\"All attempts fail:\\n%s\", strings.Join(logWithNumber, \"\\n\"))\r\n}","code-length":128,"reference":"\/\/ Error method return string representation of Error\n\/\/ It is an implementation of error interface","result":"Generate the error message.","score":[0.0159,0.0338]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *RequestBuilder) Arguments(args ...string) *RequestBuilder {\r\n\tr.args = append(r.args, args...)\r\n\treturn r\r\n}","code-length":47,"reference":"\/\/ Arguments adds the arguments to the args.","result":"Avoid recursive call to Arguments.","score":[0.1319,0.0649]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *RequestBuilder) BodyString(body string) *RequestBuilder {\r\n\treturn r.Body(strings.NewReader(body))\r\n}","code-length":42,"reference":"\/\/ BodyString sets the request body to the given string.","result":"Generate the code.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *RequestBuilder) BodyBytes(body []byte) *RequestBuilder {\r\n\treturn r.Body(bytes.NewReader(body))\r\n}","code-length":43,"reference":"\/\/ BodyBytes sets the request body to the given buffer.","result":"Generate the code.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *RequestBuilder) Body(body io.Reader) *RequestBuilder {\r\n\tr.body = body\r\n\treturn r\r\n}","code-length":41,"reference":"\/\/ Body sets the request body to the given reader.","result":"Generate the code.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *RequestBuilder) Option(key string, value interface{}) *RequestBuilder {\r\n\tvar s string\r\n\tswitch v := value.(type) {\r\n\tcase bool:\r\n\t\ts = strconv.FormatBool(v)\r\n\tcase string:\r\n\t\ts = v\r\n\tcase []byte:\r\n\t\ts = string(v)\r\n\tdefault:\r\n\t\t\r\n\t\ts = fmt.Sprint(value)\r\n\t}\r\n\tif r.opts == nil {\r\n\t\tr.opts = make(map[string]string, 1)\r\n\t}\r\n\tr.opts[key] = s\r\n\treturn r\r\n}","code-length":170,"reference":"\/\/ Option sets the given option.","result":"Set options.","score":[0,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *RequestBuilder) Header(name, value string) *RequestBuilder {\r\n\tif r.headers == nil {\r\n\t\tr.headers = make(map[string]string, 1)\r\n\t}\r\n\tr.headers[name] = value\r\n\treturn r\r\n}","code-length":76,"reference":"\/\/ Header sets the given header.","result":"Set the header value.","score":[0.1938,0.4406]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *RequestBuilder) Send(ctx context.Context) (*Response, error) {\r\n\treq := NewRequest(ctx, r.shell.url, r.command, r.args...)\r\n\treq.Opts = r.opts\r\n\treq.Headers = r.headers\r\n\treq.Body = r.body\r\n\treturn req.Send(&r.shell.httpcli)\r\n}","code-length":102,"reference":"\/\/ Send sends the request and return the response.","result":"Send the request.","score":[0.0657,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *RequestBuilder) Exec(ctx context.Context, res interface{}) error {\r\n\thttpRes, err := r.Send(ctx)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif res == nil {\r\n\t\tlateErr := httpRes.Close()\r\n\t\tif httpRes.Error != nil {\r\n\t\t\treturn httpRes.Error\r\n\t\t}\r\n\t\treturn lateErr\r\n\t}\r\n\treturn httpRes.Decode(res)\r\n}","code-length":131,"reference":"\/\/ Exec sends the request a request and decodes the response.","result":"Execute the request.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *PubSubSubscription) Next() (*Message, error) {\r\n\tif s.resp.Error != nil {\r\n\t\treturn nil, s.resp.Error\r\n\t}\r\n\td := json.NewDecoder(s.resp.Output)\r\n\tvar r struct {\r\n\t\tFrom     []byte   `json:\"from,omitempty\"`\r\n\t\tData     []byte   `json:\"data,omitempty\"`\r\n\t\tSeqno    []byte   `json:\"seqno,omitempty\"`\r\n\t\tTopicIDs []string `json:\"topicIDs,omitempty\"`\r\n\t}\r\n\terr := d.Decode(&r)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tfrom, err := peer.IDFromBytes(r.From)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &Message{\r\n\t\tFrom:     from,\r\n\t\tData:     r.Data,\r\n\t\tSeqno:    r.Seqno,\r\n\t\tTopicIDs: r.TopicIDs,\r\n\t}, nil\r\n}","code-length":274,"reference":"\/\/ Next waits for the next record and returns that.","result":"Receive next message from the peer.","score":[0.1179,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *PubSubSubscription) Cancel() error {\r\n\tif s.resp.Output == nil {\r\n\t\treturn nil\r\n\t}\r\n\treturn s.resp.Output.Close()\r\n}","code-length":57,"reference":"\/\/ Cancel cancels the given subscription.","result":"Cancel a PubSubSubscription.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Shell) FileList(path string) (*UnixLsObject, error) {\r\n\tvar out lsOutput\r\n\tif err := s.Request(\"file\/ls\", path).Exec(context.Background(), &out); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tfor _, object := range out.Objects {\r\n\t\treturn object, nil\r\n\t}\r\n\treturn nil, fmt.Errorf(\"no object in results\")\r\n}","code-length":122,"reference":"\/\/ FileList entries at the given path using the UnixFS commands","result":"List files in a directory.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Shell) Cat(path string) (io.ReadCloser, error) {\r\n\tresp, err := s.Request(\"cat\", path).Send(context.Background())\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif resp.Error != nil {\r\n\t\treturn nil, resp.Error\r\n\t}\r\n\treturn resp.Output, nil\r\n}","code-length":107,"reference":"\/\/ Cat the content at the given path. Callers need to drain and close the returned reader after usage.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Shell) List(path string) ([]*LsLink, error) {\r\n\tvar out struct{ Objects []LsObject }\r\n\terr := s.Request(\"ls\", path).Exec(context.Background(), &out)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif len(out.Objects) != 1 {\r\n\t\treturn nil, errors.New(\"bad response from server\")\r\n\t}\r\n\treturn out.Objects[0].Links, nil\r\n}","code-length":133,"reference":"\/\/ List entries at the given path","result":"List files in a directory.","score":[0.1611,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Shell) Pin(path string) error {\r\n\treturn s.Request(\"pin\/add\", path).\r\n\t\tOption(\"recursive\", true).\r\n\t\tExec(context.Background(), nil)\r\n}","code-length":61,"reference":"\/\/ Pin the given path","result":"Generate code for the code generated by the code.","score":[0.1219,0.0926]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Shell) Pins() (map[string]PinInfo, error) {\r\n\tvar raw struct{ Keys map[string]PinInfo }\r\n\treturn raw.Keys, s.Request(\"pin\/ls\").Exec(context.Background(), &raw)\r\n}","code-length":72,"reference":"\/\/ Pins returns a map of the pin hashes to their info (currently just the\n\/\/ pin type, one of DirectPin, RecursivePin, or IndirectPin. A map is returned\n\/\/ instead of a slice because it is easier to do existence lookup by map key\n\/\/ than unordered array searching. The map is likely to be more useful to a\n\/\/ client than a flat list.","result":"Get the list of all available pins.","score":[0.0,0.0169]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Shell) Version() (string, string, error) {\r\n\tver := struct {\r\n\t\tVersion string\r\n\t\tCommit  string\r\n\t}{}\r\n\tif err := s.Request(\"version\").Exec(context.Background(), &ver); err != nil {\r\n\t\treturn \"\", \"\", err\r\n\t}\r\n\treturn ver.Version, ver.Commit, nil\r\n}","code-length":103,"reference":"\/\/ returns ipfs version and commit sha","result":"Get the version of the shell.","score":[0.1634,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Shell) SwarmPeers(ctx context.Context) (*SwarmConnInfos, error) {\r\n\tv := &SwarmConnInfos{}\r\n\terr := s.Request(\"swarm\/peers\").Exec(ctx, &v)\r\n\treturn v, err\r\n}","code-length":76,"reference":"\/\/ SwarmPeers gets all the swarm peers","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Shell) SwarmConnect(ctx context.Context, addr ...string) error {\r\n\tvar conn *swarmConnection\r\n\terr := s.Request(\"swarm\/connect\").\r\n\t\tArguments(addr...).\r\n\t\tExec(ctx, &conn)\r\n\treturn err\r\n}","code-length":81,"reference":"\/\/ SwarmConnect opens a swarm connection to a specific address.","result":"Connect to swarm.","score":[0.0396,0.2016]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DagPutOptions(opts ...DagPutOption) (*DagPutSettings, error) {\r\n\toptions := &DagPutSettings{\r\n\t\tInputEnc: \"json\",\r\n\t\tKind:     \"cbor\",\r\n\t\tPin:      \"false\",\r\n\t\tHash:     \"sha2-256\",\r\n\t}\r\n\tfor _, opt := range opts {\r\n\t\terr := opt(options)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\treturn options, nil\r\n}","code-length":148,"reference":"\/\/ DagPutOptions applies the given options to a DagPutSettings instance.","result":"Create a dag.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (dagOpts) Pin(pin string) DagPutOption {\r\n\treturn func(opts *DagPutSettings) error {\r\n\t\topts.Pin = pin\r\n\t\treturn nil\r\n\t}\r\n}","code-length":61,"reference":"\/\/ Pin is an option for Dag.Put which specifies whether to pin the added\n\/\/ dags. Default is \"false\".","result":"Generate code for the generated code.","score":[0.0263,0.0565]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (dagOpts) Kind(kind string) DagPutOption {\r\n\treturn func(opts *DagPutSettings) error {\r\n\t\topts.Kind = kind\r\n\t\treturn nil\r\n\t}\r\n}","code-length":61,"reference":"\/\/ Kind is an option for Dag.Put which specifies the format that the dag\n\/\/ will be added as. Default is \"cbor\".","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (dagOpts) Hash(hash string) DagPutOption {\r\n\treturn func(opts *DagPutSettings) error {\r\n\t\topts.Hash = hash\r\n\t\treturn nil\r\n\t}\r\n}","code-length":61,"reference":"\/\/ Hash is an option for Dag.Put which specifies the hash function to use","result":"Generate the generated code.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Shell) AddDir(dir string) (string, error) {\r\n\tstat, err := os.Lstat(dir)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tsf, err := files.NewSerialFile(dir, false, stat)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tslf := files.NewSliceDirectory([]files.DirEntry{files.FileEntry(filepath.Base(dir), sf)})\r\n\treader := files.NewMultiFileReader(slf, true)\r\n\tresp, err := s.Request(\"add\").\r\n\t\tOption(\"recursive\", true).\r\n\t\tBody(reader).\r\n\t\tSend(context.Background())\r\n\tif err != nil {\r\n\t\treturn \"\", nil\r\n\t}\r\n\tdefer resp.Close()\r\n\tif resp.Error != nil {\r\n\t\treturn \"\", resp.Error\r\n\t}\r\n\tdec := json.NewDecoder(resp.Output)\r\n\tvar final string\r\n\tfor {\r\n\t\tvar out object\r\n\t\terr = dec.Decode(&out)\r\n\t\tif err != nil {\r\n\t\t\tif err == io.EOF {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\treturn \"\", err\r\n\t\t}\r\n\t\tfinal = out.Hash\r\n\t}\r\n\tif final == \"\" {\r\n\t\treturn \"\", errors.New(\"no results received\")\r\n\t}\r\n\treturn final, nil\r\n}","code-length":373,"reference":"\/\/ AddDir adds a directory recursively with all of the files under it","result":"Add a directory.","score":[0.0146,0.1563]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Shell) Publish(node string, value string) error {\r\n\tvar pubResp PublishResponse\r\n\treq := s.Request(\"name\/publish\")\r\n\tif node != \"\" {\r\n\t\treq.Arguments(node)\r\n\t}\r\n\treq.Arguments(value)\r\n\treturn req.Exec(context.Background(), &pubResp)\r\n}","code-length":96,"reference":"\/\/ Publish updates a mutable name to point to a given value","result":"Publish a node.","score":[0.0242,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Shell) PublishWithDetails(contentHash, key string, lifetime, ttl time.Duration, resolve bool) (*PublishResponse, error) {\r\n\tvar pubResp PublishResponse\r\n\treq := s.Request(\"name\/publish\", contentHash).Option(\"resolve\", resolve)\r\n\tif key != \"\" {\r\n\t\treq.Option(\"key\", key)\r\n\t}\r\n\tif lifetime != 0 {\r\n\t\treq.Option(\"lifetime\", lifetime)\r\n\t}\r\n\tif ttl.Seconds() > 0 {\r\n\t\treq.Option(\"ttl\", ttl)\r\n\t}\r\n\terr := req.Exec(context.Background(), &pubResp)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &pubResp, nil\r\n}","code-length":197,"reference":"\/\/ PublishWithDetails is used for fine grained control over record publishing","result":"Publish a file.","score":[0,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pv PlanValue) ResolveValue(bindVars map[string]*querypb.BindVariable) (Value, error) {\r\n\tswitch {\r\n\tcase pv.Key != \"\":\r\n\t\tbv, err := pv.lookupValue(bindVars)\r\n\t\tif err != nil {\r\n\t\t\treturn NULL, err\r\n\t\t}\r\n\t\treturn MakeTrusted(bv.Type, bv.Value), nil\r\n\tcase !pv.Value.IsNull():\r\n\t\treturn pv.Value, nil\r\n\tcase pv.ListKey != \"\" || pv.Values != nil:\r\n\t\t\r\n\t\t\r\n\t\treturn NULL, errors.New(\"a list was supplied where a single value was expected\")\r\n\t}\r\n\treturn NULL, nil\r\n}","code-length":189,"reference":"\/\/ ResolveValue resolves a PlanValue as a single value based on the supplied bindvars.","result":"Resolve the value of a statement.","score":[0.067,0.1515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pq *ParsedQuery) GenerateQuery(bindVariables map[string]*querypb.BindVariable, extras map[string]Encodable) ([]byte, error) {\r\n\tif len(pq.bindLocations) == 0 {\r\n\t\treturn []byte(pq.Query), nil\r\n\t}\r\n\tbuf := bytes.NewBuffer(make([]byte, 0, len(pq.Query)))\r\n\tcurrent := 0\r\n\tfor _, loc := range pq.bindLocations {\r\n\t\tbuf.WriteString(pq.Query[current:loc.offset])\r\n\t\tname := pq.Query[loc.offset : loc.offset+loc.length]\r\n\t\tif encodable, ok := extras[name[1:]]; ok {\r\n\t\t\tencodable.EncodeSQL(buf)\r\n\t\t} else {\r\n\t\t\tsupplied, _, err := FetchBindVar(name, bindVariables)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\tEncodeValue(buf, supplied)\r\n\t\t}\r\n\t\tcurrent = loc.offset + loc.length\r\n\t}\r\n\tbuf.WriteString(pq.Query[current:])\r\n\treturn buf.Bytes(), nil\r\n}","code-length":309,"reference":"\/\/ GenerateQuery generates a query by substituting the specified\n\/\/ bindVariables. The extras parameter specifies special parameters\n\/\/ that can perform custom encoding.","result":"Generate the query.","score":[0.0005,0.0476]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EncodeValue(buf *bytes.Buffer, value *querypb.BindVariable) {\r\n\tif value.Type != querypb.Type_TUPLE {\r\n\t\t\r\n\t\tv, _ := sqltypes.BindVariableToValue(value)\r\n\t\tv.EncodeSQL(buf)\r\n\t\treturn\r\n\t}\r\n\t\r\n\tbuf.WriteByte('(')\r\n\tfor i, bv := range value.Values {\r\n\t\tif i != 0 {\r\n\t\t\tbuf.WriteString(\", \")\r\n\t\t}\r\n\t\tsqltypes.ProtoToValue(bv).EncodeSQL(buf)\r\n\t}\r\n\tbuf.WriteByte(')')\r\n}","code-length":169,"reference":"\/\/ EncodeValue encodes one bind variable value into the query.","result":"Encode bind variables.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tkn *Tokenizer) Lex(lval *yySymType) int {\r\n\ttyp, val := tkn.Scan()\r\n\tfor typ == COMMENT {\r\n\t\tif tkn.AllowComments {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\ttyp, val = tkn.Scan()\r\n\t}\r\n\tlval.bytes = val\r\n\ttkn.lastToken = val\r\n\treturn typ\r\n}","code-length":112,"reference":"\/\/ Lex returns the next token form the Tokenizer.\n\/\/ This function is used by go yacc.","result":"Generate the lexing code.","score":[0.0124,0.0637]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tkn *Tokenizer) skipStatement() {\r\n\tch := tkn.lastChar\r\n\tfor ch != ';' && ch != eofChar {\r\n\t\ttkn.next()\r\n\t\tch = tkn.lastChar\r\n\t}\r\n}","code-length":70,"reference":"\/\/ skipStatement scans until the EOF, or end of statement is encountered.","result":"Skip statement.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tkn *Tokenizer) reset() {\r\n\ttkn.ParseTree = nil\r\n\ttkn.partialDDL = nil\r\n\ttkn.specialComment = nil\r\n\ttkn.posVarIndex = 0\r\n\ttkn.nesting = 0\r\n\ttkn.ForceEOF = false\r\n}","code-length":83,"reference":"\/\/ reset clears any internal state.","result":"Reset the tokenizer.","score":[0,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Preview(sql string) int {\r\n\ttrimmed := StripLeadingComments(sql)\r\n\tfirstWord := trimmed\r\n\tif end := strings.IndexFunc(trimmed, unicode.IsSpace); end != -1 {\r\n\t\tfirstWord = trimmed[:end]\r\n\t}\r\n\tfirstWord = strings.TrimLeftFunc(firstWord, func(r rune) bool { return !unicode.IsLetter(r) })\r\n\t\r\n\tloweredFirstWord := strings.ToLower(firstWord)\r\n\tswitch loweredFirstWord {\r\n\tcase \"select\":\r\n\t\treturn StmtSelect\r\n\tcase \"stream\":\r\n\t\treturn StmtStream\r\n\tcase \"insert\":\r\n\t\treturn StmtInsert\r\n\tcase \"replace\":\r\n\t\treturn StmtReplace\r\n\tcase \"update\":\r\n\t\treturn StmtUpdate\r\n\tcase \"delete\":\r\n\t\treturn StmtDelete\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\ttrimmedNoComments, _ := SplitMarginComments(trimmed)\r\n\tswitch strings.ToLower(trimmedNoComments) {\r\n\tcase \"begin\", \"start transaction\":\r\n\t\treturn StmtBegin\r\n\tcase \"commit\":\r\n\t\treturn StmtCommit\r\n\tcase \"rollback\":\r\n\t\treturn StmtRollback\r\n\t}\r\n\tswitch loweredFirstWord {\r\n\tcase \"create\", \"alter\", \"rename\", \"drop\", \"truncate\":\r\n\t\treturn StmtDDL\r\n\tcase \"set\":\r\n\t\treturn StmtSet\r\n\tcase \"show\":\r\n\t\treturn StmtShow\r\n\tcase \"use\":\r\n\t\treturn StmtUse\r\n\tcase \"analyze\", \"describe\", \"desc\", \"explain\", \"repair\", \"optimize\":\r\n\t\treturn StmtOther\r\n\t}\r\n\tif strings.Index(trimmed, \"\/*!\") == 0 {\r\n\t\treturn StmtComment\r\n\t}\r\n\treturn StmtUnknown\r\n}","code-length":472,"reference":"\/\/ Preview analyzes the beginning of the query using a simpler and faster\n\/\/ textual comparison to identify the statement type.","result":"Generate the preview statement.","score":[0.0046,0.0518]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPlanValue(node Expr) (sqltypes.PlanValue, error) {\r\n\tswitch node := node.(type) {\r\n\tcase *SQLVal:\r\n\t\tswitch node.Type {\r\n\t\tcase ValArg:\r\n\t\t\treturn sqltypes.PlanValue{Key: string(node.Val[1:])}, nil\r\n\t\tcase IntVal:\r\n\t\t\tn, err := sqltypes.NewIntegral(string(node.Val))\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn sqltypes.PlanValue{}, fmt.Errorf(\"%v\", err)\r\n\t\t\t}\r\n\t\t\treturn sqltypes.PlanValue{Value: n}, nil\r\n\t\tcase StrVal:\r\n\t\t\treturn sqltypes.PlanValue{Value: sqltypes.MakeTrusted(sqltypes.VarBinary, node.Val)}, nil\r\n\t\tcase HexVal:\r\n\t\t\tv, err := node.HexDecode()\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn sqltypes.PlanValue{}, fmt.Errorf(\"%v\", err)\r\n\t\t\t}\r\n\t\t\treturn sqltypes.PlanValue{Value: sqltypes.MakeTrusted(sqltypes.VarBinary, v)}, nil\r\n\t\t}\r\n\tcase ListArg:\r\n\t\treturn sqltypes.PlanValue{ListKey: string(node[2:])}, nil\r\n\tcase ValTuple:\r\n\t\tpv := sqltypes.PlanValue{\r\n\t\t\tValues: make([]sqltypes.PlanValue, 0, len(node)),\r\n\t\t}\r\n\t\tfor _, val := range node {\r\n\t\t\tinnerpv, err := NewPlanValue(val)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn sqltypes.PlanValue{}, err\r\n\t\t\t}\r\n\t\t\tif innerpv.ListKey != \"\" || innerpv.Values != nil {\r\n\t\t\t\treturn sqltypes.PlanValue{}, errors.New(\"unsupported: nested lists\")\r\n\t\t\t}\r\n\t\t\tpv.Values = append(pv.Values, innerpv)\r\n\t\t}\r\n\t\treturn pv, nil\r\n\tcase *NullVal:\r\n\t\treturn sqltypes.PlanValue{}, nil\r\n\t}\r\n\treturn sqltypes.PlanValue{}, fmt.Errorf(\"expression is too complex '%v'\", String(node))\r\n}","code-length":541,"reference":"\/\/ NewPlanValue builds a sqltypes.PlanValue from an Expr.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StringIn(str string, values ...string) bool {\r\n\tfor _, val := range values {\r\n\t\tif str == val {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":65,"reference":"\/\/ StringIn is a convenience function that returns\n\/\/ true if str matches any of the values.","result":"Test the string in .","score":[0.0218,0.0316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTrackedBuffer(nodeFormatter NodeFormatter) *TrackedBuffer {\r\n\treturn &TrackedBuffer{\r\n\t\tBuffer:        new(bytes.Buffer),\r\n\t\tnodeFormatter: nodeFormatter,\r\n\t}\r\n}","code-length":64,"reference":"\/\/ NewTrackedBuffer creates a new TrackedBuffer.","result":"Create a new tracked buffer.","score":[0.2782,0.4991]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewStringArena(size int) *StringArena {\r\n\tsa := &StringArena{buf: make([]byte, 0, size)}\r\n\tpbytes := (*reflect.SliceHeader)(unsafe.Pointer(&sa.buf))\r\n\tpstring := (*reflect.StringHeader)(unsafe.Pointer(&sa.str))\r\n\tpstring.Data = pbytes.Data\r\n\tpstring.Len = pbytes.Cap\r\n\treturn sa\r\n}","code-length":126,"reference":"\/\/ NewStringArena creates an arena of the specified size.","result":"Create a new StringArena.","score":[0,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (sa *StringArena) NewString(b []byte) string {\r\n\tif len(b) == 0 {\r\n\t\treturn \"\"\r\n\t}\r\n\tif len(sa.buf)+len(b) > cap(sa.buf) {\r\n\t\treturn string(b)\r\n\t}\r\n\tstart := len(sa.buf)\r\n\tsa.buf = append(sa.buf, b...)\r\n\treturn sa.str[start : start+len(b)]\r\n}","code-length":127,"reference":"\/\/ NewString copies a byte slice into the arena and returns it as a string.\n\/\/ If the arena is full, it returns a traditional go string.","result":"Create a new string .","score":[0.003,0.0202]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (sa *StringArena) SpaceLeft() int {\r\n\treturn cap(sa.buf) - len(sa.buf)\r\n}","code-length":43,"reference":"\/\/ SpaceLeft returns the amount of space left in the arena.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseStrictDDL(sql string) (Statement, error) {\r\n\ttokenizer := NewStringTokenizer(sql)\r\n\tif yyParse(tokenizer) != 0 {\r\n\t\treturn nil, tokenizer.LastError\r\n\t}\r\n\treturn tokenizer.ParseTree, nil\r\n}","code-length":75,"reference":"\/\/ ParseStrictDDL is the same as Parse except it errors on\n\/\/ partially parsed DDL statements.","result":"Parse strict DDL.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseNext(tokenizer *Tokenizer) (Statement, error) {\r\n\tif tokenizer.lastChar == ';' {\r\n\t\ttokenizer.next()\r\n\t\ttokenizer.skipBlank()\r\n\t}\r\n\tif tokenizer.lastChar == eofChar {\r\n\t\treturn nil, io.EOF\r\n\t}\r\n\ttokenizer.reset()\r\n\ttokenizer.multi = true\r\n\tif yyParse(tokenizer) != 0 {\r\n\t\tif tokenizer.partialDDL != nil {\r\n\t\t\ttokenizer.ParseTree = tokenizer.partialDDL\r\n\t\t\treturn tokenizer.ParseTree, nil\r\n\t\t}\r\n\t\treturn nil, tokenizer.LastError\r\n\t}\r\n\treturn tokenizer.ParseTree, nil\r\n}","code-length":184,"reference":"\/\/ ParseNext parses a single SQL statement from the tokenizer\n\/\/ returning a Statement which is the AST representation of the query.\n\/\/ The tokenizer will always read up to the end of the statement, allowing for\n\/\/ the next call to ParseNext to parse any subsequent SQL statements. When\n\/\/ there are no more statements to parse, a error of io.EOF is returned.","result":"Parse the next statement.","score":[0.0,0.0441]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Append(buf *bytes.Buffer, node SQLNode) {\r\n\ttbuf := &TrackedBuffer{\r\n\t\tBuffer: buf,\r\n\t}\r\n\tnode.Format(tbuf)\r\n}","code-length":59,"reference":"\/\/ Append appends the SQLNode to the buffer.","result":"Append to a buffer.","score":[0.1547,0.1974]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ExprFromValue(value sqltypes.Value) (Expr, error) {\r\n\t\r\n\tswitch {\r\n\tcase value.Type() == sqltypes.Null:\r\n\t\treturn &NullVal{}, nil\r\n\tcase value.IsIntegral():\r\n\t\treturn NewIntVal(value.ToBytes()), nil\r\n\tcase value.IsFloat() || value.Type() == sqltypes.Decimal:\r\n\t\treturn NewFloatVal(value.ToBytes()), nil\r\n\tcase value.IsQuoted():\r\n\t\treturn NewStrVal(value.ToBytes()), nil\r\n\tdefault:\r\n\t\t\r\n\t\treturn nil, fmt.Errorf(\"cannot convert value %v to AST\", value)\r\n\t}\r\n}","code-length":175,"reference":"\/\/ ExprFromValue converts the given Value into an Expr or returns an error.","result":"Create an AST from value.","score":[0.0485,0.041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Backtick(in string) string {\r\n\tvar buf bytes.Buffer\r\n\tbuf.WriteByte('`')\r\n\tfor _, c := range in {\r\n\t\tbuf.WriteRune(c)\r\n\t\tif c == '`' {\r\n\t\t\tbuf.WriteByte('`')\r\n\t\t}\r\n\t}\r\n\tbuf.WriteByte('`')\r\n\treturn buf.String()\r\n}","code-length":108,"reference":"\/\/ Backtick produces a backticked literal given an input string.","result":"Backtick the string.","score":[0.0471,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewValue(typ querypb.Type, val []byte) (v Value, err error) {\r\n\tswitch {\r\n\tcase IsSigned(typ):\r\n\t\tif _, err := strconv.ParseInt(string(val), 0, 64); err != nil {\r\n\t\t\treturn NULL, err\r\n\t\t}\r\n\t\treturn MakeTrusted(typ, val), nil\r\n\tcase IsUnsigned(typ):\r\n\t\tif _, err := strconv.ParseUint(string(val), 0, 64); err != nil {\r\n\t\t\treturn NULL, err\r\n\t\t}\r\n\t\treturn MakeTrusted(typ, val), nil\r\n\tcase IsFloat(typ) || typ == Decimal:\r\n\t\tif _, err := strconv.ParseFloat(string(val), 64); err != nil {\r\n\t\t\treturn NULL, err\r\n\t\t}\r\n\t\treturn MakeTrusted(typ, val), nil\r\n\tcase IsQuoted(typ) || typ == Null:\r\n\t\treturn MakeTrusted(typ, val), nil\r\n\t}\r\n\t\r\n\treturn NULL, fmt.Errorf(\"invalid type specified for MakeValue: %v\", typ)\r\n}","code-length":279,"reference":"\/\/ NewValue builds a Value using typ and val. If the value and typ\n\/\/ don't match, it returns an error.","result":"Create a new value .","score":[0.0116,0.0515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v Value) String() string {\r\n\tif v.typ == Null {\r\n\t\treturn \"NULL\"\r\n\t}\r\n\tif v.IsQuoted() {\r\n\t\treturn fmt.Sprintf(\"%v(%q)\", v.typ, v.val)\r\n\t}\r\n\treturn fmt.Sprintf(\"%v(%s)\", v.typ, v.val)\r\n}","code-length":102,"reference":"\/\/ String returns a printable version of the value.","result":"Generate the code.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v Value) EncodeSQL(b BinWriter) {\r\n\tswitch {\r\n\tcase v.typ == Null:\r\n\t\tb.Write(nullstr)\r\n\tcase v.IsQuoted():\r\n\t\tencodeBytesSQL(v.val, b)\r\n\tdefault:\r\n\t\tb.Write(v.val)\r\n\t}\r\n}","code-length":95,"reference":"\/\/ EncodeSQL encodes the value into an SQL statement. Can be binary.","result":"Encode values.","score":[0,0.0455]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (iv InsertValues) EncodeSQL(buf *bytes.Buffer) {\r\n\tfor i, rows := range iv {\r\n\t\tif i != 0 {\r\n\t\t\tbuf.WriteString(\", \")\r\n\t\t}\r\n\t\tbuf.WriteByte('(')\r\n\t\tfor j, bv := range rows {\r\n\t\t\tif j != 0 {\r\n\t\t\t\tbuf.WriteString(\", \")\r\n\t\t\t}\r\n\t\t\tbv.EncodeSQL(buf)\r\n\t\t}\r\n\t\tbuf.WriteByte(')')\r\n\t}\r\n}","code-length":144,"reference":"\/\/ EncodeSQL performs the SQL encoding for InsertValues.","result":"Encode insert values.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tpl *TupleEqualityList) EncodeSQL(buf *bytes.Buffer) {\r\n\tif len(tpl.Columns) == 1 {\r\n\t\ttpl.encodeAsIn(buf)\r\n\t\treturn\r\n\t}\r\n\ttpl.encodeAsEquality(buf)\r\n}","code-length":75,"reference":"\/\/ EncodeSQL generates the where clause constraints for the tuple\n\/\/ equality.","result":"Generate generated code.","score":[0,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (nz *normalizer) WalkStatement(node SQLNode) (bool, error) {\r\n\tswitch node := node.(type) {\r\n\tcase *Select:\r\n\t\t_ = Walk(nz.WalkSelect, node)\r\n\t\t\r\n\t\treturn false, nil\r\n\tcase *SQLVal:\r\n\t\tnz.convertSQLVal(node)\r\n\tcase *ComparisonExpr:\r\n\t\tnz.convertComparison(node)\r\n\t}\r\n\treturn true, nil\r\n}","code-length":131,"reference":"\/\/ WalkStatement is the top level walk function.\n\/\/ If it encounters a Select, it switches to a mode\n\/\/ where variables are deduped.","result":"Normalize the statement .","score":[0.0022,0.0227]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (nz *normalizer) WalkSelect(node SQLNode) (bool, error) {\r\n\tswitch node := node.(type) {\r\n\tcase *SQLVal:\r\n\t\tnz.convertSQLValDedup(node)\r\n\tcase *ComparisonExpr:\r\n\t\tnz.convertComparison(node)\r\n\t}\r\n\treturn true, nil\r\n}","code-length":99,"reference":"\/\/ WalkSelect normalizes the AST in Select mode.","result":"Normalize the select .","score":[0.1175,0.3363]}
{"code":"\/*is used to<extra_id_0>\r\nfunc BindVariablesEqual(x, y map[string]*querypb.BindVariable) bool {\r\n\treturn reflect.DeepEqual(&querypb.BoundQuery{BindVariables: x}, &querypb.BoundQuery{BindVariables: y})\r\n}","code-length":65,"reference":"\/\/ BindVariablesEqual compares two maps of bind variables.","result":"Compare bind variables.","score":[0.109,0.3407]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(options ...Options) *JWTMiddleware {\r\n\tvar opts Options\r\n\tif len(options) == 0 {\r\n\t\topts = Options{}\r\n\t} else {\r\n\t\topts = options[0]\r\n\t}\r\n\tif opts.UserProperty == \"\" {\r\n\t\topts.UserProperty = \"user\"\r\n\t}\r\n\tif opts.ErrorHandler == nil {\r\n\t\topts.ErrorHandler = OnError\r\n\t}\r\n\tif opts.Extractor == nil {\r\n\t\topts.Extractor = FromAuthHeader\r\n\t}\r\n\treturn &JWTMiddleware{\r\n\t\tOptions: opts,\r\n\t}\r\n}","code-length":164,"reference":"\/\/ New constructs a new Secure instance with supplied options.","result":"Create a new JWTMiddleware.","score":[0.1008,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *JWTMiddleware) HandlerWithNext(w http.ResponseWriter, r *http.Request, next http.HandlerFunc) {\r\n\terr := m.CheckJWT(w, r)\r\n\t\r\n\tif err == nil && next != nil {\r\n\t\tnext(w, r)\r\n\t}\r\n}","code-length":85,"reference":"\/\/ Special implementation for Negroni, but could be used elsewhere.","result":"Protect against multiple JWTs.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FromAuthHeader(r *http.Request) (string, error) {\r\n\tauthHeader := r.Header.Get(\"Authorization\")\r\n\tif authHeader == \"\" {\r\n\t\treturn \"\", nil\r\n\t}\r\n\t\r\n\tauthHeaderParts := strings.Split(authHeader, \" \")\r\n\tif len(authHeaderParts) != 2 || strings.ToLower(authHeaderParts[0]) != \"bearer\" {\r\n\t\treturn \"\", errors.New(\"Authorization header format must be Bearer {token}\")\r\n\t}\r\n\treturn authHeaderParts[1], nil\r\n}","code-length":148,"reference":"\/\/ FromAuthHeader is a \"TokenExtractor\" that takes a give request and extracts\n\/\/ the JWT token from the Authorization header.","result":"Create a new function to create a new token.","score":[0.0427,0.0529]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FromParameter(param string) TokenExtractor {\r\n\treturn func(r *http.Request) (string, error) {\r\n\t\treturn r.URL.Query().Get(param), nil\r\n\t}\r\n}","code-length":60,"reference":"\/\/ FromParameter returns a function that extracts the token from the specified\n\/\/ query string parameter","result":"Extract tokens from query parameters.","score":[0.0317,0.2118]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FromFirst(extractors ...TokenExtractor) TokenExtractor {\r\n\treturn func(r *http.Request) (string, error) {\r\n\t\tfor _, ex := range extractors {\r\n\t\t\ttoken, err := ex(r)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn \"\", err\r\n\t\t\t}\r\n\t\t\tif token != \"\" {\r\n\t\t\t\treturn token, nil\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn \"\", nil\r\n\t}\r\n}","code-length":127,"reference":"\/\/ FromFirst returns a function that runs multiple token extractors and takes the\n\/\/ first token it finds","result":"Extract tokens from the request.","score":[0.0178,0.0599]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PubSub) getHelloPacket() *RPC {\r\n\tvar rpc RPC\r\n\tfor t := range p.myTopics {\r\n\t\tas := &pb.RPC_SubOpts{\r\n\t\t\tTopicid:   proto.String(t),\r\n\t\t\tSubscribe: proto.Bool(true),\r\n\t\t}\r\n\t\trpc.Subscriptions = append(rpc.Subscriptions, as)\r\n\t}\r\n\treturn &rpc\r\n}","code-length":114,"reference":"\/\/ get the initial RPC containing all of our subscriptions to send to new peers","result":"Generate the hello packet.","score":[0.0204,0.036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFloodsubWithProtocols(ctx context.Context, h host.Host, ps []protocol.ID, opts ...Option) (*PubSub, error) {\r\n\trt := &FloodSubRouter{\r\n\t\tprotocols: ps,\r\n\t}\r\n\treturn NewPubSub(ctx, h, rt, opts...)\r\n}","code-length":87,"reference":"\/\/ NewFloodsubWithProtocols returns a new floodsub-enabled PubSub objecting using the protocols specified in ps.","result":"Create a new Floodsub router.","score":[0.0562,0.1431]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFloodSub(ctx context.Context, h host.Host, opts ...Option) (*PubSub, error) {\r\n\treturn NewFloodsubWithProtocols(ctx, h, []protocol.ID{FloodSubID}, opts...)\r\n}","code-length":69,"reference":"\/\/ NewFloodSub returns a new PubSub object using the FloodSubRouter.","result":"Create a new FloodSub .","score":[0.125,0.1974]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLRUBlacklist(cap int) (Blacklist, error) {\r\n\tc, err := lru.New(cap)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tb := &LRUBlacklist{lru: c}\r\n\treturn b, nil\r\n}","code-length":86,"reference":"\/\/ NewLRUBlacklist creates a new LRUBlacklist with capacity cap","result":"Create a new LRU cache.","score":[0.1527,0.3424]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRandomSub(ctx context.Context, h host.Host, opts ...Option) (*PubSub, error) {\r\n\trt := &RandomSubRouter{\r\n\t\tpeers: make(map[peer.ID]protocol.ID),\r\n\t}\r\n\treturn NewPubSub(ctx, h, rt, opts...)\r\n}","code-length":85,"reference":"\/\/ NewRandomSub returns a new PubSub object using RandomSubRouter as the router.","result":"Create a random sub router.","score":[0.0705,0.0885]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewGossipSub(ctx context.Context, h host.Host, opts ...Option) (*PubSub, error) {\r\n\trt := &GossipSubRouter{\r\n\t\tpeers:   make(map[peer.ID]protocol.ID),\r\n\t\tmesh:    make(map[string]map[peer.ID]struct{}),\r\n\t\tfanout:  make(map[string]map[peer.ID]struct{}),\r\n\t\tlastpub: make(map[string]int64),\r\n\t\tgossip:  make(map[peer.ID][]*pb.ControlIHave),\r\n\t\tcontrol: make(map[peer.ID]*pb.ControlMessage),\r\n\t\tmcache:  NewMessageCache(GossipSubHistoryGossip, GossipSubHistoryLength),\r\n\t}\r\n\treturn NewPubSub(ctx, h, rt, opts...)\r\n}","code-length":216,"reference":"\/\/ NewGossipSub returns a new PubSub object using GossipSubRouter as the router.","result":"Create a new gossip sub.","score":[0.0838,0.1659]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPubSub(ctx context.Context, h host.Host, rt PubSubRouter, opts ...Option) (*PubSub, error) {\r\n\tps := &PubSub{\r\n\t\thost:             h,\r\n\t\tctx:              ctx,\r\n\t\trt:               rt,\r\n\t\tsignID:           h.ID(),\r\n\t\tsignKey:          h.Peerstore().PrivKey(h.ID()),\r\n\t\tsignStrict:       true,\r\n\t\tincoming:         make(chan *RPC, 32),\r\n\t\tpublish:          make(chan *Message),\r\n\t\tnewPeers:         make(chan peer.ID),\r\n\t\tnewPeerStream:    make(chan inet.Stream),\r\n\t\tnewPeerError:     make(chan peer.ID),\r\n\t\tpeerDead:         make(chan peer.ID),\r\n\t\tcancelCh:         make(chan *Subscription),\r\n\t\tgetPeers:         make(chan *listPeerReq),\r\n\t\taddSub:           make(chan *addSubReq),\r\n\t\tgetTopics:        make(chan *topicReq),\r\n\t\tsendMsg:          make(chan *sendReq, 32),\r\n\t\taddVal:           make(chan *addValReq),\r\n\t\trmVal:            make(chan *rmValReq),\r\n\t\tvalidateThrottle: make(chan struct{}, defaultValidateThrottle),\r\n\t\teval:             make(chan func()),\r\n\t\tmyTopics:         make(map[string]map[*Subscription]struct{}),\r\n\t\ttopics:           make(map[string]map[peer.ID]struct{}),\r\n\t\tpeers:            make(map[peer.ID]chan *RPC),\r\n\t\ttopicVals:        make(map[string]*topicVal),\r\n\t\tblacklist:        NewMapBlacklist(),\r\n\t\tblacklistPeer:    make(chan peer.ID),\r\n\t\tseenMessages:     timecache.NewTimeCache(TimeCacheDuration),\r\n\t\tcounter:          uint64(time.Now().UnixNano()),\r\n\t}\r\n\tfor _, opt := range opts {\r\n\t\terr := opt(ps)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\tif ps.signStrict && ps.signKey == nil {\r\n\t\treturn nil, fmt.Errorf(\"strict signature verification enabled but message signing is disabled\")\r\n\t}\r\n\trt.Attach(ps)\r\n\tfor _, id := range rt.Protocols() {\r\n\t\th.SetStreamHandler(id, ps.handleNewStream)\r\n\t}\r\n\th.Network().Notify((*PubSubNotif)(ps))\r\n\tgo ps.processLoop(ctx)\r\n\treturn ps, nil\r\n}","code-length":663,"reference":"\/\/ NewPubSub returns a new PubSub management object.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WithValidateThrottle(n int) Option {\r\n\treturn func(ps *PubSub) error {\r\n\t\tps.validateThrottle = make(chan struct{}, n)\r\n\t\treturn nil\r\n\t}\r\n}","code-length":61,"reference":"\/\/ WithValidateThrottle sets the upper bound on the number of active validation\n\/\/ goroutines.","result":"Validate the throttle.","score":[0.0104,0.0775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WithBlacklist(b Blacklist) Option {\r\n\treturn func(p *PubSub) error {\r\n\t\tp.blacklist = b\r\n\t\treturn nil\r\n\t}\r\n}","code-length":53,"reference":"\/\/ WithBlacklist provides an implementation of the blacklist; the default is a\n\/\/ MapBlacklist","result":"Filter out the .","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PubSub) handleRemoveSubscription(sub *Subscription) {\r\n\tsubs := p.myTopics[sub.topic]\r\n\tif subs == nil {\r\n\t\treturn\r\n\t}\r\n\tsub.err = fmt.Errorf(\"subscription cancelled by calling sub.Cancel()\")\r\n\tclose(sub.ch)\r\n\tdelete(subs, sub)\r\n\tif len(subs) == 0 {\r\n\t\tdelete(p.myTopics, sub.topic)\r\n\t\tp.announce(sub.topic, false)\r\n\t\tp.rt.Leave(sub.topic)\r\n\t}\r\n}","code-length":155,"reference":"\/\/ handleRemoveSubscription removes Subscription sub from bookeeping.\n\/\/ If this was the last Subscription for a given topic, it will also announce\n\/\/ that this node is not subscribing to this topic anymore.\n\/\/ Only called from processLoop.","result":"Remove a subscription.","score":[0.0,0.029]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PubSub) handleAddSubscription(req *addSubReq) {\r\n\tsub := req.sub\r\n\tsubs := p.myTopics[sub.topic]\r\n\t\r\n\tif len(subs) == 0 {\r\n\t\tp.announce(sub.topic, true)\r\n\t\tp.rt.Join(sub.topic)\r\n\t}\r\n\t\r\n\tif subs == nil {\r\n\t\tp.myTopics[sub.topic] = make(map[*Subscription]struct{})\r\n\t\tsubs = p.myTopics[sub.topic]\r\n\t}\r\n\tsub.ch = make(chan *Message, 32)\r\n\tsub.cancelCh = p.cancelCh\r\n\tp.myTopics[sub.topic][sub] = struct{}{}\r\n\treq.resp <- sub\r\n}","code-length":205,"reference":"\/\/ handleAddSubscription adds a Subscription for a particular topic. If it is\n\/\/ the first Subscription for the topic, it will announce that this node\n\/\/ subscribes to the topic.\n\/\/ Only called from processLoop.","result":"Handle the subscriptions.","score":[0.0,0.0157]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PubSub) announce(topic string, sub bool) {\r\n\tsubopt := &pb.RPC_SubOpts{\r\n\t\tTopicid:   &topic,\r\n\t\tSubscribe: &sub,\r\n\t}\r\n\tout := rpcWithSubs(subopt)\r\n\tfor pid, peer := range p.peers {\r\n\t\tselect {\r\n\t\tcase peer <- out:\r\n\t\tdefault:\r\n\t\t\tlog.Infof(\"Can't send announce message to peer %s: queue full; scheduling retry\", pid)\r\n\t\t\tgo p.announceRetry(pid, topic, sub)\r\n\t\t}\r\n\t}\r\n}","code-length":164,"reference":"\/\/ announce announces whether or not this node is interested in a given topic\n\/\/ Only called from processLoop.","result":"Send an announce message to all peers.","score":[0.0291,0.0281]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PubSub) notifySubs(msg *pb.Message) {\r\n\tfor _, topic := range msg.GetTopicIDs() {\r\n\t\tsubs := p.myTopics[topic]\r\n\t\tfor f := range subs {\r\n\t\t\tselect {\r\n\t\t\tcase f.ch <- &Message{msg}:\r\n\t\t\tdefault:\r\n\t\t\t\tlog.Infof(\"Can't deliver message to subscription for topic %s; subscriber too slow\", topic)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":133,"reference":"\/\/ notifySubs sends a given message to all corresponding subscribers.\n\/\/ Only called from processLoop.","result":"Notify subscribers.","score":[0.0008,0.0365]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PubSub) seenMessage(id string) bool {\r\n\treturn p.seenMessages.Has(id)\r\n}","code-length":39,"reference":"\/\/ seenMessage returns whether we already saw this message before","result":"Test the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PubSub) subscribedToMsg(msg *pb.Message) bool {\r\n\tif len(p.myTopics) == 0 {\r\n\t\treturn false\r\n\t}\r\n\tfor _, t := range msg.GetTopicIDs() {\r\n\t\tif _, ok := p.myTopics[t]; ok {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":108,"reference":"\/\/ subscribedToMessage returns whether we are subscribed to one of the topics\n\/\/ of a given message","result":"Check if the message is subscribed to a topic.","score":[0.0891,0.2296]}
{"code":"\/*is used to<extra_id_0>\r\nfunc msgID(pmsg *pb.Message) string {\r\n\treturn string(pmsg.GetFrom()) + string(pmsg.GetSeqno())\r\n}","code-length":47,"reference":"\/\/ msgID returns a unique ID of the passed Message","result":"Generate the msgID .","score":[0.0848,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PubSub) pushMsg(vals []*topicVal, src peer.ID, msg *Message) {\r\n\t\r\n\tif p.blacklist.Contains(src) {\r\n\t\tlog.Warningf(\"dropping message from blacklisted peer %s\", src)\r\n\t\treturn\r\n\t}\r\n\t\r\n\tif p.blacklist.Contains(msg.GetFrom()) {\r\n\t\tlog.Warningf(\"dropping message from blacklisted source %s\", src)\r\n\t\treturn\r\n\t}\r\n\t\r\n\tif p.signStrict && msg.Signature == nil {\r\n\t\tlog.Debugf(\"dropping unsigned message from %s\", src)\r\n\t\treturn\r\n\t}\r\n\t\r\n\tid := msgID(msg.Message)\r\n\tif p.seenMessage(id) {\r\n\t\treturn\r\n\t}\r\n\tif len(vals) > 0 || msg.Signature != nil {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tselect {\r\n\t\tcase p.validateThrottle <- struct{}{}:\r\n\t\t\tgo func() {\r\n\t\t\t\tp.validate(vals, src, msg)\r\n\t\t\t\t<-p.validateThrottle\r\n\t\t\t}()\r\n\t\tdefault:\r\n\t\t\tlog.Warningf(\"message validation throttled; dropping message from %s\", src)\r\n\t\t}\r\n\t\treturn\r\n\t}\r\n\tp.publishMessage(src, msg.Message)\r\n}","code-length":354,"reference":"\/\/ pushMsg pushes a message performing validation as necessary","result":"Validate the message.","score":[0,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PubSub) validate(vals []*topicVal, src peer.ID, msg *Message) {\r\n\tif msg.Signature != nil {\r\n\t\tif !p.validateSignature(msg) {\r\n\t\t\tlog.Warningf(\"message signature validation failed; dropping message from %s\", src)\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n\tif len(vals) > 0 {\r\n\t\tif !p.validateTopic(vals, src, msg) {\r\n\t\t\tlog.Warningf(\"message validation failed; dropping message from %s\", src)\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n\t\r\n\tp.sendMsg <- &sendReq{\r\n\t\tfrom: src,\r\n\t\tmsg:  msg,\r\n\t}\r\n}","code-length":198,"reference":"\/\/ validate performs validation and only sends the message if all validators succeed","result":"Validate the message.","score":[0.0146,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PubSub) validateSingleTopic(val *topicVal, src peer.ID, msg *Message) bool {\r\n\tselect {\r\n\tcase val.validateThrottle <- struct{}{}:\r\n\t\tctx, cancel := context.WithCancel(p.ctx)\r\n\t\tdefer cancel()\r\n\t\tres := val.validateMsg(ctx, src, msg)\r\n\t\t<-val.validateThrottle\r\n\t\treturn res\r\n\tdefault:\r\n\t\tlog.Debugf(\"validation throttled for topic %s\", val.topic)\r\n\t\treturn false\r\n\t}\r\n}","code-length":147,"reference":"\/\/ fast path for single topic validation that avoids the extra goroutine","result":"Validate the topic.","score":[0.0203,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PubSub) getValidators(msg *Message) []*topicVal {\r\n\tvar vals []*topicVal\r\n\tfor _, topic := range msg.GetTopicIDs() {\r\n\t\tval, ok := p.topicVals[topic]\r\n\t\tif !ok {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvals = append(vals, val)\r\n\t}\r\n\treturn vals\r\n}","code-length":109,"reference":"\/\/ getValidators returns all validators that apply to a given message","result":"Get the topic validators.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PubSub) Subscribe(topic string, opts ...SubOpt) (*Subscription, error) {\r\n\ttd := pb.TopicDescriptor{Name: &topic}\r\n\treturn p.SubscribeByTopicDescriptor(&td, opts...)\r\n}","code-length":66,"reference":"\/\/ Subscribe returns a new Subscription for the given topic.\n\/\/ Note that subscription is not an instanteneous operation. It may take some time\n\/\/ before the subscription is processed by the pubsub main loop and propagated to our peers.","result":"Subscribe to a topic.","score":[0.0001,0.0549]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PubSub) SubscribeByTopicDescriptor(td *pb.TopicDescriptor, opts ...SubOpt) (*Subscription, error) {\r\n\tif td.GetAuth().GetMode() != pb.TopicDescriptor_AuthOpts_NONE {\r\n\t\treturn nil, fmt.Errorf(\"auth mode not yet supported\")\r\n\t}\r\n\tif td.GetEnc().GetMode() != pb.TopicDescriptor_EncOpts_NONE {\r\n\t\treturn nil, fmt.Errorf(\"encryption mode not yet supported\")\r\n\t}\r\n\tsub := &Subscription{\r\n\t\ttopic: td.GetName(),\r\n\t}\r\n\tfor _, opt := range opts {\r\n\t\terr := opt(sub)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\tout := make(chan *Subscription, 1)\r\n\tp.addSub <- &addSubReq{\r\n\t\tsub:  sub,\r\n\t\tresp: out,\r\n\t}\r\n\treturn <-out, nil\r\n}","code-length":255,"reference":"\/\/ SubscribeByTopicDescriptor lets you subscribe a topic using a pb.TopicDescriptor.","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PubSub) GetTopics() []string {\r\n\tout := make(chan []string, 1)\r\n\tp.getTopics <- &topicReq{resp: out}\r\n\treturn <-out\r\n}","code-length":59,"reference":"\/\/ GetTopics returns the topics this node is subscribed to.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PubSub) Publish(topic string, data []byte) error {\r\n\tseqno := p.nextSeqno()\r\n\tm := &pb.Message{\r\n\t\tData:     data,\r\n\t\tTopicIDs: []string{topic},\r\n\t\tFrom:     []byte(p.host.ID()),\r\n\t\tSeqno:    seqno,\r\n\t}\r\n\tif p.signKey != nil {\r\n\t\tm.From = []byte(p.signID)\r\n\t\terr := signMessage(p.signID, p.signKey, m)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tp.publish <- &Message{m}\r\n\treturn nil\r\n}","code-length":192,"reference":"\/\/ Publish publishes data to the given topic.","result":"Publish messages.","score":[0.0249,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PubSub) ListPeers(topic string) []peer.ID {\r\n\tout := make(chan []peer.ID)\r\n\tp.getPeers <- &listPeerReq{\r\n\t\tresp:  out,\r\n\t\ttopic: topic,\r\n\t}\r\n\treturn <-out\r\n}","code-length":82,"reference":"\/\/ ListPeers returns a list of peers we are connected to in the given topic.","result":"List peers in a topic.","score":[0.046,0.1786]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WithValidatorTimeout(timeout time.Duration) ValidatorOpt {\r\n\treturn func(addVal *addValReq) error {\r\n\t\taddVal.timeout = timeout\r\n\t\treturn nil\r\n\t}\r\n}","code-length":60,"reference":"\/\/ WithValidatorTimeout is an option that sets the topic validator timeout.","result":"Validate the file.","score":[0.0284,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WithValidatorConcurrency(n int) ValidatorOpt {\r\n\treturn func(addVal *addValReq) error {\r\n\t\taddVal.throttle = n\r\n\t\treturn nil\r\n\t}\r\n}","code-length":59,"reference":"\/\/ WithValidatorConcurrency is an option that sets topic validator throttle.","result":"Validate the schema.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PubSub) RegisterTopicValidator(topic string, val Validator, opts ...ValidatorOpt) error {\r\n\taddVal := &addValReq{\r\n\t\ttopic:    topic,\r\n\t\tvalidate: val,\r\n\t\tresp:     make(chan error, 1),\r\n\t}\r\n\tfor _, opt := range opts {\r\n\t\terr := opt(addVal)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tp.addVal <- addVal\r\n\treturn <-addVal.resp\r\n}","code-length":146,"reference":"\/\/ RegisterTopicValidator registers a validator for topic.","result":"Register a topic validator.","score":[0.1509,0.2799]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PubSub) UnregisterTopicValidator(topic string) error {\r\n\trmVal := &rmValReq{\r\n\t\ttopic: topic,\r\n\t\tresp:  make(chan error, 1),\r\n\t}\r\n\tp.rmVal <- rmVal\r\n\treturn <-rmVal.resp\r\n}","code-length":84,"reference":"\/\/ UnregisterTopicValidator removes a validator from a topic.\n\/\/ Returns an error if there was no validator registered with the topic.","result":"Unregister topic validator.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DefaultMetricPrefix(name string, tags map[string]string) string {\r\n\treturn MetricWithPrefix(\"tchannel.\", name, tags)\r\n}","code-length":45,"reference":"\/\/ DefaultMetricPrefix is the default mapping for metrics to statsd keys.\n\/\/ It uses a \"tchannel\" prefix for all stats.","result":"Collect metrics from the file.","score":[0.0142,0.0541]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MetricWithPrefix(prefix, name string, tags map[string]string) string {\r\n\tbuf := bufPool.Get().(*bytes.Buffer)\r\n\tbuf.Reset()\r\n\tif prefix != \"\" {\r\n\t\tbuf.WriteString(prefix)\r\n\t}\r\n\tbuf.WriteString(name)\r\n\taddKeys := make([]string, 0, 5)\r\n\tswitch {\r\n\tcase strings.HasPrefix(name, \"outbound\"):\r\n\t\taddKeys = append(addKeys, \"service\", \"target-service\", \"target-endpoint\")\r\n\t\tif strings.HasPrefix(name, \"outbound.calls.retries\") {\r\n\t\t\taddKeys = append(addKeys, \"retry-count\")\r\n\t\t}\r\n\tcase strings.HasPrefix(name, \"inbound\"):\r\n\t\taddKeys = append(addKeys, \"calling-service\", \"service\", \"endpoint\")\r\n\t}\r\n\tfor _, k := range addKeys {\r\n\t\tbuf.WriteByte('.')\r\n\t\tv, ok := tags[k]\r\n\t\tif ok {\r\n\t\t\twriteClean(buf, v)\r\n\t\t} else {\r\n\t\t\tbuf.WriteString(\"no-\")\r\n\t\t\tbuf.WriteString(k)\r\n\t\t}\r\n\t}\r\n\tm := buf.String()\r\n\tbufPool.Put(buf)\r\n\treturn m\r\n}","code-length":349,"reference":"\/\/ MetricWithPrefix is the default mapping for metrics to statsd keys.","result":"Create a metric with prefix.","score":[0,0.0481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(ch *tchannel.Channel, targetService string, opts *ClientOptions) *Client {\r\n\tclient := &Client{\r\n\t\tch:            ch,\r\n\t\ttargetService: targetService,\r\n\t}\r\n\tif opts != nil && opts.HostPort != \"\" {\r\n\t\tclient.hostPort = opts.HostPort\r\n\t}\r\n\treturn client\r\n}","code-length":100,"reference":"\/\/ NewClient returns a json.Client used to make outbound JSON calls.","result":"Create a client.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Call(ctx Context, method string, arg, resp interface{}) error {\r\n\tvar (\r\n\t\theaders = ctx.Headers()\r\n\t\trespHeaders map[string]string\r\n\t\trespErr     ErrApplication\r\n\t\terrAt       string\r\n\t\tisOK        bool\r\n\t)\r\n\terr := c.ch.RunWithRetry(ctx, func(ctx context.Context, rs *tchannel.RequestState) error {\r\n\t\trespHeaders, respErr, isOK = nil, nil, false\r\n\t\terrAt = \"connect\"\r\n\t\tcall, err := c.startCall(ctx, method, &tchannel.CallOptions{\r\n\t\t\tFormat:       tchannel.JSON,\r\n\t\t\tRequestState: rs,\r\n\t\t})\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tisOK, errAt, err = makeCall(call, headers, arg, &respHeaders, resp, &respErr)\r\n\t\treturn err\r\n\t})\r\n\tif err != nil {\r\n\t\t\r\n\t\treturn fmt.Errorf(\"%s: %v\", errAt, err)\r\n\t}\r\n\tif !isOK {\r\n\t\treturn respErr\r\n\t}\r\n\treturn nil\r\n}","code-length":318,"reference":"\/\/ Call makes a JSON call, with retries.","result":"Call a method on the client.","score":[0.1645,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CallPeer(ctx Context, peer *tchannel.Peer, serviceName, method string, arg, resp interface{}) error {\r\n\tcall, err := peer.BeginCall(ctx, serviceName, method, &tchannel.CallOptions{Format: tchannel.JSON})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn wrapCall(ctx, call, method, arg, resp)\r\n}","code-length":106,"reference":"\/\/ CallPeer makes a JSON call using the given peer.","result":"Call peer methods.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CallSC(ctx Context, sc *tchannel.SubChannel, method string, arg, resp interface{}) error {\r\n\tcall, err := sc.BeginCall(ctx, method, &tchannel.CallOptions{Format: tchannel.JSON})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn wrapCall(ctx, call, method, arg, resp)\r\n}","code-length":103,"reference":"\/\/ CallSC makes a JSON call using the given subchannel.","result":"Call the CallSC function.","score":[0.0848,0.1596]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReadResponse(call tchannel.ArgReadable) (*http.Response, error) {\r\n\tvar arg2 []byte\r\n\tif err := tchannel.NewArgReader(call.Arg2Reader()).Read(&arg2); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\trb := typed.NewReadBuffer(arg2)\r\n\tstatusCode := rb.ReadUint16()\r\n\tmessage := readVarintString(rb)\r\n\tresponse := &http.Response{\r\n\t\tStatusCode: int(statusCode),\r\n\t\tStatus:     fmt.Sprintf(\"%v %v\", statusCode, message),\r\n\t\tProto:      \"HTTP\/1.1\",\r\n\t\tProtoMajor: 1,\r\n\t\tProtoMinor: 1,\r\n\t\tHeader:     make(http.Header),\r\n\t}\r\n\treadHeaders(rb, response.Header)\r\n\tif err := rb.Err(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\targ3Reader, err := call.Arg3Reader()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tresponse.Body = arg3Reader\r\n\treturn response, nil\r\n}","code-length":297,"reference":"\/\/ ReadResponse reads a http.Response from the given readers.","result":"Read the response body.","score":[0.0915,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *tchanResponseWriter) writeHeaders() {\r\n\t\r\n\twb := typed.NewWriteBufferWithSize(10000)\r\n\twb.WriteUint16(uint16(w.statusCode))\r\n\twriteVarintString(wb, http.StatusText(w.statusCode))\r\n\twriteHeaders(wb, w.headers)\r\n\targ2Writer, err := w.response.Arg2Writer()\r\n\tif err != nil {\r\n\t\tw.err = err\r\n\t\treturn\r\n\t}\r\n\tif _, w.err = wb.FlushTo(arg2Writer); w.err != nil {\r\n\t\treturn\r\n\t}\r\n\tif w.err = arg2Writer.Close(); w.err != nil {\r\n\t\treturn\r\n\t}\r\n\tw.arg3Writer, w.err = w.response.Arg3Writer()\r\n}","code-length":216,"reference":"\/\/ writeHeaders writes out the HTTP headers as arg2, and creates the arg3 writer.","result":"Write the response body.","score":[0.0262,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ResponseWriter(response tchannel.ArgWritable) (http.ResponseWriter, func() error) {\r\n\tresponseWriter := newTChanResponseWriter(response)\r\n\treturn responseWriter, responseWriter.finish\r\n}","code-length":58,"reference":"\/\/ ResponseWriter returns a http.ResponseWriter that will write to an underlying writer.\n\/\/ It also returns a function that should be called once the handler has completed.","result":"Create a TChannelResponseWriter.","score":[0.0001,0.0203]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReadHeaders(r io.Reader) (map[string]string, error) {\r\n\treader := typed.NewReader(r)\r\n\tm, err := readHeaders(reader)\r\n\treader.Release()\r\n\treturn m, err\r\n}","code-length":69,"reference":"\/\/ ReadHeaders reads key-value pairs encoded using WriteHeaders.","result":"Parse the headers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTCPRawRelay(dests []string) (Relay, error) {\r\n\treturn newTCPRelay(dests, func(_ bool, src, dst net.Conn) {\r\n\t\tio.Copy(src, dst)\r\n\t})\r\n}","code-length":68,"reference":"\/\/ NewTCPRawRelay creates a relay that just pipes data from one connection\n\/\/ to another directly.","result":"Create raw relay.","score":[0,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(ch *tchannel.Channel, config Configuration, opts *ClientOptions) (*Client, error) {\r\n\tclient := &Client{tchan: ch, quit: make(chan struct{})}\r\n\tif opts != nil {\r\n\t\tclient.opts = *opts\r\n\t}\r\n\tif client.opts.Timeout == 0 {\r\n\t\tclient.opts.Timeout = 3 * time.Second\r\n\t}\r\n\tif client.opts.TimeoutPerAttempt == 0 {\r\n\t\tclient.opts.TimeoutPerAttempt = time.Second\r\n\t}\r\n\tif client.opts.Handler == nil {\r\n\t\tclient.opts.Handler = nullHandler{}\r\n\t}\r\n\tif client.opts.TimeSleep == nil {\r\n\t\tclient.opts.TimeSleep = time.Sleep\r\n\t}\r\n\tif err := parseConfig(&config); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tfor _, node := range config.InitialNodes {\r\n\t\taddPeer(ch, node)\r\n\t}\r\n\tclient.jsonClient = tjson.NewClient(ch, hyperbahnServiceName, nil)\r\n\tthriftClient := tthrift.NewClient(ch, hyperbahnServiceName, nil)\r\n\tclient.hyperbahnClient = htypes.NewTChanHyperbahnClient(thriftClient)\r\n\treturn client, nil\r\n}","code-length":344,"reference":"\/\/ NewClient creates a new Hyperbahn client using the given channel.\n\/\/ config is the environment-specific configuration for Hyperbahn such as the list of initial nodes.\n\/\/ opts are optional, and are used to customize the client.","result":"Creates a client.","score":[0.0,0.0761]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Advertise(otherServices ...tchannel.Registrar) error {\r\n\tc.getServiceNames(otherServices)\r\n\tif err := c.initialAdvertise(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tc.opts.Handler.On(Advertised)\r\n\tgo c.advertiseLoop()\r\n\treturn nil\r\n}","code-length":99,"reference":"\/\/ Advertise advertises the service with Hyperbahn, and returns any errors on initial advertisement.\n\/\/ Advertise can register multiple services hosted on the same endpoint.\n\/\/ If the advertisement succeeds, a goroutine is started to re-advertise periodically.","result":"Create a new function.","score":[0.0001,0.0148]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *handler) Handle(tctx context.Context, call *tchannel.InboundCall) error {\r\n\tvar headers map[string]string\r\n\tif err := tchannel.NewArgReader(call.Arg2Reader()).ReadJSON(&headers); err != nil {\r\n\t\treturn fmt.Errorf(\"arg2 read failed: %v\", err)\r\n\t}\r\n\ttctx = tchannel.ExtractInboundSpan(tctx, call, headers, h.tracer())\r\n\tctx := WithHeaders(tctx, headers)\r\n\tvar arg3 reflect.Value\r\n\tvar callArg reflect.Value\r\n\tif h.isArgMap {\r\n\t\targ3 = reflect.New(h.argType)\r\n\t\t\r\n\t\tcallArg = arg3.Elem()\r\n\t} else {\r\n\t\targ3 = reflect.New(h.argType.Elem())\r\n\t\tcallArg = arg3\r\n\t}\r\n\tif err := tchannel.NewArgReader(call.Arg3Reader()).ReadJSON(arg3.Interface()); err != nil {\r\n\t\treturn fmt.Errorf(\"arg3 read failed: %v\", err)\r\n\t}\r\n\targs := []reflect.Value{reflect.ValueOf(ctx), callArg}\r\n\tresults := h.handler.Call(args)\r\n\tres := results[0].Interface()\r\n\terr := results[1].Interface()\r\n\t\r\n\tif err != nil {\r\n\t\t\r\n\t\tif serr, ok := err.(tchannel.SystemError); ok {\r\n\t\t\treturn call.Response().SendSystemError(serr)\r\n\t\t}\r\n\t\tcall.Response().SetApplicationError()\r\n\t\t\r\n\t\tres = struct {\r\n\t\t\tType    string `json:\"type\"`\r\n\t\t\tMessage string `json:\"message\"`\r\n\t\t}{\r\n\t\t\tType:    \"error\",\r\n\t\t\tMessage: err.(error).Error(),\r\n\t\t}\r\n\t}\r\n\tif err := tchannel.NewArgWriter(call.Response().Arg2Writer()).WriteJSON(ctx.ResponseHeaders()); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn tchannel.NewArgWriter(call.Response().Arg3Writer()).WriteJSON(res)\r\n}","code-length":553,"reference":"\/\/ Handle deserializes the JSON arguments and calls the underlying handler.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Server) Start() error {\r\n\tif s.HostPort == \"\" {\r\n\t\ts.HostPort = \":\" + common.DefaultServerPort\r\n\t}\r\n\tchannelOpts := &tchannel.ChannelOptions{\r\n\t\tTracer: s.Tracer,\r\n\t}\r\n\tch, err := tchannel.NewChannel(common.DefaultServiceName, channelOpts)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := ch.ListenAndServe(s.HostPort); err != nil {\r\n\t\treturn err\r\n\t}\r\n\ts.HostPort = ch.PeerInfo().HostPort\r\n\tlog.Printf(\"Started tchannel server at %s\\n\", s.HostPort)\r\n\ts.Ch = ch\r\n\treturn nil\r\n}","code-length":193,"reference":"\/\/ Start starts the test server called by the Client and other upstream servers.","result":"Start the server.","score":[0.0124,0.0775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Server) Port() string {\r\n\thostPortSplit := strings.Split(s.HostPort, \":\")\r\n\tport := hostPortSplit[len(hostPortSplit)-1]\r\n\treturn port\r\n}","code-length":60,"reference":"\/\/ Port returns the actual port the server listens to","result":"Generate the port number.","score":[0.0848,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *PeerList) SetStrategy(sc ScoreCalculator) {\r\n\tl.Lock()\r\n\tdefer l.Unlock()\r\n\tl.scoreCalculator = sc\r\n\tfor _, ps := range l.peersByHostPort {\r\n\t\tnewScore := l.scoreCalculator.GetScore(ps.Peer)\r\n\t\tl.updatePeer(ps, newScore)\r\n\t}\r\n}","code-length":103,"reference":"\/\/ SetStrategy sets customized peer selection strategy.","result":"Set the strategy of the peer list.","score":[0.1615,0.1429]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *PeerList) Add(hostPort string) *Peer {\r\n\tif ps, ok := l.exists(hostPort); ok {\r\n\t\treturn ps.Peer\r\n\t}\r\n\tl.Lock()\r\n\tdefer l.Unlock()\r\n\tif p, ok := l.peersByHostPort[hostPort]; ok {\r\n\t\treturn p.Peer\r\n\t}\r\n\tp := l.parent.Add(hostPort)\r\n\tp.addSC()\r\n\tps := newPeerScore(p, l.scoreCalculator.GetScore(p))\r\n\tl.peersByHostPort[hostPort] = ps\r\n\tl.peerHeap.addPeer(ps)\r\n\treturn p\r\n}","code-length":178,"reference":"\/\/ Add adds a peer to the list if it does not exist, or returns any existing peer.","result":"Add a new peer to the peerHeap.","score":[0.0785,0.2639]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *PeerList) GetNew(prevSelected map[string]struct{}) (*Peer, error) {\r\n\tl.Lock()\r\n\tdefer l.Unlock()\r\n\tif l.peerHeap.Len() == 0 {\r\n\t\treturn nil, ErrNoPeers\r\n\t}\r\n\t\r\n\t\r\n\tpeer := l.choosePeer(prevSelected, true )\r\n\tif peer == nil {\r\n\t\tpeer = l.choosePeer(prevSelected, false )\r\n\t}\r\n\tif peer == nil {\r\n\t\treturn nil, ErrNoNewPeers\r\n\t}\r\n\treturn peer, nil\r\n}","code-length":158,"reference":"\/\/ GetNew returns a new, previously unselected peer from the peer list, or nil,\n\/\/ if no new unselected peer can be found.","result":"Get a new peer from the.","score":[0.0191,0.0939]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *PeerList) Get(prevSelected map[string]struct{}) (*Peer, error) {\r\n\tpeer, err := l.GetNew(prevSelected)\r\n\tif err == ErrNoNewPeers {\r\n\t\tl.Lock()\r\n\t\tpeer = l.choosePeer(nil, false )\r\n\t\tl.Unlock()\r\n\t} else if err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif peer == nil {\r\n\t\treturn nil, ErrNoPeers\r\n\t}\r\n\treturn peer, nil\r\n}","code-length":143,"reference":"\/\/ Get returns a peer from the peer list, or nil if none can be found,\n\/\/ will avoid previously selected peers if possible.","result":"Get the peer from the peer list.","score":[0.0471,0.217]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *PeerList) Remove(hostPort string) error {\r\n\tl.Lock()\r\n\tdefer l.Unlock()\r\n\tp, ok := l.peersByHostPort[hostPort]\r\n\tif !ok {\r\n\t\treturn ErrPeerNotFound\r\n\t}\r\n\tp.delSC()\r\n\tdelete(l.peersByHostPort, hostPort)\r\n\tl.peerHeap.removePeer(p)\r\n\treturn nil\r\n}","code-length":116,"reference":"\/\/ Remove removes a peer from the peer list. It returns an error if the peer cannot be found.\n\/\/ Remove does not affect connections to the peer in any way.","result":"Remove a peer from the peer list.","score":[0.0282,0.1677]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *PeerList) Copy() map[string]*Peer {\r\n\tl.RLock()\r\n\tdefer l.RUnlock()\r\n\tlistCopy := make(map[string]*Peer)\r\n\tfor k, v := range l.peersByHostPort {\r\n\t\tlistCopy[k] = v.Peer\r\n\t}\r\n\treturn listCopy\r\n}","code-length":96,"reference":"\/\/ Copy returns a copy of the PeerList as a map from hostPort to peer.","result":"Copy peers.","score":[0.0008,0.0365]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *PeerList) Len() int {\r\n\tl.RLock()\r\n\tdefer l.RUnlock()\r\n\treturn l.peerHeap.Len()\r\n}","code-length":51,"reference":"\/\/ Len returns the length of the PeerList.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *PeerList) exists(hostPort string) (*peerScore, bool) {\r\n\tl.RLock()\r\n\tps, ok := l.peersByHostPort[hostPort]\r\n\tl.RUnlock()\r\n\treturn ps, ok\r\n}","code-length":72,"reference":"\/\/ exists checks if a hostport exists in the peer list.","result":"Check if a peer exists.","score":[0.1133,0.3606]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *PeerList) getPeerScore(hostPort string) (*peerScore, uint64, bool) {\r\n\tps, ok := l.peersByHostPort[hostPort]\r\n\tif !ok {\r\n\t\treturn nil, 0, false\r\n\t}\r\n\treturn ps, ps.score, ok\r\n}","code-length":85,"reference":"\/\/ getPeerScore is called to find the peer and its score from a host port key.\n\/\/ Note that at least a Read lock must be held to call this function.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *PeerList) onPeerChange(p *Peer) {\r\n\tl.RLock()\r\n\tps, psScore, ok := l.getPeerScore(p.hostPort)\r\n\tsc := l.scoreCalculator\r\n\tl.RUnlock()\r\n\tif !ok {\r\n\t\treturn\r\n\t}\r\n\tnewScore := sc.GetScore(ps.Peer)\r\n\tif newScore == psScore {\r\n\t\treturn\r\n\t}\r\n\tl.Lock()\r\n\tl.updatePeer(ps, newScore)\r\n\tl.Unlock()\r\n}","code-length":151,"reference":"\/\/ onPeerChange is called when there is a change that may cause the peer's score to change.\n\/\/ The new score is calculated, and the peer heap is updated with the new score if the score changes.","result":"Listen to peer change events.","score":[0.0005,0.0444]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *PeerList) updatePeer(ps *peerScore, newScore uint64) {\r\n\tif ps.score == newScore {\r\n\t\treturn\r\n\t}\r\n\tps.score = newScore\r\n\tl.peerHeap.updatePeer(ps)\r\n}","code-length":75,"reference":"\/\/ updatePeer is called to update the score of the peer given the existing score.\n\/\/ Note that a Write lock must be held to call this function.","result":"Update the peer score.","score":[0.0012,0.0781]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Peer) getConn(i int) *Connection {\r\n\tinboundLen := len(p.inboundConnections)\r\n\tif i < inboundLen {\r\n\t\treturn p.inboundConnections[i]\r\n\t}\r\n\treturn p.outboundConnections[i-inboundLen]\r\n}","code-length":84,"reference":"\/\/ getConn treats inbound and outbound connections as a single virtual list\n\/\/ that can be indexed. The peer must be read-locked.","result":"Get the connection from the peer.","score":[0,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Peer) GetConnection(ctx context.Context) (*Connection, error) {\r\n\tif activeConn, ok := p.getActiveConn(); ok {\r\n\t\treturn activeConn, nil\r\n\t}\r\n\t\r\n\tp.newConnLock.Lock()\r\n\tdefer p.newConnLock.Unlock()\r\n\t\r\n\tif activeConn, ok := p.getActiveConn(); ok {\r\n\t\treturn activeConn, nil\r\n\t}\r\n\t\r\n\treturn p.Connect(ctx)\r\n}","code-length":135,"reference":"\/\/ GetConnection returns an active connection to this peer. If no active connections\n\/\/ are found, it will create a new outbound connection and return it.","result":"Get the connection from the peer.","score":[0.0082,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Peer) getConnectionRelay(timeout time.Duration) (*Connection, error) {\r\n\tif conn, ok := p.getActiveConn(); ok {\r\n\t\treturn conn, nil\r\n\t}\r\n\t\r\n\tp.newConnLock.Lock()\r\n\tdefer p.newConnLock.Unlock()\r\n\t\r\n\tif activeConn, ok := p.getActiveConn(); ok {\r\n\t\treturn activeConn, nil\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tctx, cancel := NewContextBuilder(timeout).HideListeningOnOutbound().Build()\r\n\tdefer cancel()\r\n\treturn p.Connect(ctx)\r\n}","code-length":167,"reference":"\/\/ getConnectionRelay gets a connection, and uses the given timeout to lazily\n\/\/ create a context if a new connection is required.","result":"Create a new connection relay.","score":[0.0165,0.1847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Peer) canRemove() bool {\r\n\tp.RLock()\r\n\tcount := len(p.inboundConnections) + len(p.outboundConnections) + int(p.scCount)\r\n\tp.RUnlock()\r\n\treturn count == 0\r\n}","code-length":76,"reference":"\/\/ canRemove returns whether this peer can be safely removed from the root peer list.","result":"Check if peer can remove.","score":[0.046,0.0714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Peer) addConnection(c *Connection, direction connectionDirection) error {\r\n\tconns := p.connectionsFor(direction)\r\n\tif c.readState() != connectionActive {\r\n\t\treturn ErrInvalidConnectionState\r\n\t}\r\n\tp.Lock()\r\n\t*conns = append(*conns, c)\r\n\tp.Unlock()\r\n\t\r\n\tp.onStatusChanged(p)\r\n\treturn nil\r\n}","code-length":116,"reference":"\/\/ addConnection adds an active connection to the peer's connection list.\n\/\/ If a connection is not active, returns ErrInvalidConnectionState.","result":"Add a connection to a peer.","score":[0.0324,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Peer) removeConnection(connsPtr *[]*Connection, changed *Connection) bool {\r\n\tconns := *connsPtr\r\n\tfor i, c := range conns {\r\n\t\tif c == changed {\r\n\t\t\t\r\n\t\t\tlast := len(conns) - 1\r\n\t\t\tconns[i], conns[last] = conns[last], nil\r\n\t\t\t*connsPtr = conns[:last]\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":133,"reference":"\/\/ removeConnection will check remove the connection if it exists on connsPtr\n\/\/ and returns whether it removed the connection.","result":"Remove connections from the peer.","score":[0.012,0.0811]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Peer) connectionCloseStateChange(changed *Connection) {\r\n\tif changed.IsActive() {\r\n\t\treturn\r\n\t}\r\n\tp.Lock()\r\n\tfound := p.removeConnection(&p.inboundConnections, changed)\r\n\tif !found {\r\n\t\tfound = p.removeConnection(&p.outboundConnections, changed)\r\n\t}\r\n\tp.Unlock()\r\n\tif found {\r\n\t\tp.onClosedConnRemoved(p)\r\n\t\t\r\n\t\tp.onStatusChanged(p)\r\n\t}\r\n}","code-length":148,"reference":"\/\/ connectionStateChanged is called when one of the peers' connections states changes.\n\/\/ All non-active connections are removed from the peer. The connection will\n\/\/ still be tracked by the channel until it's completely closed.","result":"Set the connectionCloseStateChange function in the peer.","score":[0.0046,0.0466]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Peer) Connect(ctx context.Context) (*Connection, error) {\r\n\treturn p.channel.Connect(ctx, p.hostPort)\r\n}","code-length":49,"reference":"\/\/ Connect adds a new outbound connection to the peer.","result":"Connect to a peer.","score":[0.1008,0.2128]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Peer) BeginCall(ctx context.Context, serviceName, methodName string, callOptions *CallOptions) (*OutboundCall, error) {\r\n\tif callOptions == nil {\r\n\t\tcallOptions = defaultCallOptions\r\n\t}\r\n\tcallOptions.RequestState.AddSelectedPeer(p.HostPort())\r\n\tif err := validateCall(ctx, serviceName, methodName, callOptions); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tconn, err := p.GetConnection(ctx)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tcall, err := conn.beginCall(ctx, serviceName, methodName, callOptions)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn call, err\r\n}","code-length":201,"reference":"\/\/ BeginCall starts a new call to this specific peer, returning an OutboundCall that can\n\/\/ be used to write the arguments of the call.","result":"Begin call on a peer.","score":[0.0052,0.0652]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Peer) NumConnections() (inbound int, outbound int) {\r\n\tp.RLock()\r\n\tinbound = len(p.inboundConnections)\r\n\toutbound = len(p.outboundConnections)\r\n\tp.RUnlock()\r\n\treturn inbound, outbound\r\n}","code-length":81,"reference":"\/\/ NumConnections returns the number of inbound and outbound connections for this peer.","result":"Get the number of connections in the peer.","score":[0.174,0.2976]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Peer) NumPendingOutbound() int {\r\n\tcount := 0\r\n\tp.RLock()\r\n\tfor _, c := range p.outboundConnections {\r\n\t\tcount += c.outbound.count()\r\n\t}\r\n\tfor _, c := range p.inboundConnections {\r\n\t\tcount += c.outbound.count()\r\n\t}\r\n\tp.RUnlock()\r\n\treturn count\r\n}","code-length":115,"reference":"\/\/ NumPendingOutbound returns the number of pending outbound calls.","result":"Count the number of pending outbound connections.","score":[0.5051,0.5659]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isEphemeralHostPort(hostPort string) bool {\r\n\treturn hostPort == \"\" || hostPort == ephemeralHostPort || strings.HasSuffix(hostPort, \":0\")\r\n}","code-length":47,"reference":"\/\/ isEphemeralHostPort returns if hostPort is the default ephemeral hostPort.","result":"Check ephemeral hostnames.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *kvHandler) Get(ctx thrift.Context, key string) (string, error) {\r\n\tif err := isValidKey(key); err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\th.RLock()\r\n\tdefer h.RUnlock()\r\n\tif val, ok := h.vals[key]; ok {\r\n\t\treturn val, nil\r\n\t}\r\n\treturn \"\", &keyvalue.KeyNotFound{Key: key}\r\n}","code-length":122,"reference":"\/\/ Get returns the value stored for the given key.","result":"Get a value from.","score":[0.0848,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *kvHandler) Set(ctx thrift.Context, key, value string) error {\r\n\tif err := isValidKey(key); err != nil {\r\n\t\treturn err\r\n\t}\r\n\th.Lock()\r\n\tdefer h.Unlock()\r\n\th.vals[key] = value\r\n\t\r\n\tctx.SetResponseHeaders(map[string]string{\"count\": fmt.Sprint(len(h.vals))})\r\n\treturn nil\r\n}","code-length":121,"reference":"\/\/ Set sets the value for a given key.","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *kvHandler) ClearAll(ctx thrift.Context) error {\r\n\tif !isAdmin(ctx) {\r\n\t\treturn &keyvalue.NotAuthorized{}\r\n\t}\r\n\th.Lock()\r\n\tdefer h.Unlock()\r\n\th.vals = make(map[string]string)\r\n\treturn nil\r\n}","code-length":91,"reference":"\/\/ ClearAll clears all the keys.","result":"Clear all keys.","score":[0.1786,0.4483]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewChannel(serviceName string, opts *ChannelOptions) (*Channel, error) {\r\n\tif serviceName == \"\" {\r\n\t\treturn nil, ErrNoServiceName\r\n\t}\r\n\tif opts == nil {\r\n\t\topts = &ChannelOptions{}\r\n\t}\r\n\tprocessName := opts.ProcessName\r\n\tif processName == \"\" {\r\n\t\tprocessName = fmt.Sprintf(\"%s[%d]\", filepath.Base(os.Args[0]), os.Getpid())\r\n\t}\r\n\tlogger := opts.Logger\r\n\tif logger == nil {\r\n\t\tlogger = NullLogger\r\n\t}\r\n\tstatsReporter := opts.StatsReporter\r\n\tif statsReporter == nil {\r\n\t\tstatsReporter = NullStatsReporter\r\n\t}\r\n\ttimeNow := opts.TimeNow\r\n\tif timeNow == nil {\r\n\t\ttimeNow = time.Now\r\n\t}\r\n\ttimeTicker := opts.TimeTicker\r\n\tif timeTicker == nil {\r\n\t\ttimeTicker = time.NewTicker\r\n\t}\r\n\tchID := _nextChID.Inc()\r\n\tlogger = logger.WithFields(\r\n\t\tLogField{\"serviceName\", serviceName},\r\n\t\tLogField{\"process\", processName},\r\n\t\tLogField{\"chID\", chID},\r\n\t)\r\n\tif err := opts.validateIdleCheck(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tch := &Channel{\r\n\t\tchannelConnectionCommon: channelConnectionCommon{\r\n\t\t\tlog:           logger,\r\n\t\t\trelayLocal:    toStringSet(opts.RelayLocalHandlers),\r\n\t\t\tstatsReporter: statsReporter,\r\n\t\t\tsubChannels:   &subChannelMap{},\r\n\t\t\ttimeNow:       timeNow,\r\n\t\t\ttimeTicker:    timeTicker,\r\n\t\t\ttracer:        opts.Tracer,\r\n\t\t},\r\n\t\tchID:              chID,\r\n\t\tconnectionOptions: opts.DefaultConnectionOptions.withDefaults(),\r\n\t\trelayHost:         opts.RelayHost,\r\n\t\trelayMaxTimeout:   validateRelayMaxTimeout(opts.RelayMaxTimeout, logger),\r\n\t\trelayTimerVerify:  opts.RelayTimerVerification,\r\n\t\tclosed:            make(chan struct{}),\r\n\t}\r\n\tch.peers = newRootPeerList(ch, opts.OnPeerStatusChanged).newChild()\r\n\tif opts.Handler != nil {\r\n\t\tch.handler = opts.Handler\r\n\t} else {\r\n\t\tch.handler = channelHandler{ch}\r\n\t}\r\n\tch.mutable.peerInfo = LocalPeerInfo{\r\n\t\tPeerInfo: PeerInfo{\r\n\t\t\tProcessName: processName,\r\n\t\t\tHostPort:    ephemeralHostPort,\r\n\t\t\tIsEphemeral: true,\r\n\t\t\tVersion: PeerVersion{\r\n\t\t\t\tLanguage:        \"go\",\r\n\t\t\t\tLanguageVersion: strings.TrimPrefix(runtime.Version(), \"go\"),\r\n\t\t\t\tTChannelVersion: VersionInfo,\r\n\t\t\t},\r\n\t\t},\r\n\t\tServiceName: serviceName,\r\n\t}\r\n\tch.mutable.state = ChannelClient\r\n\tch.mutable.conns = make(map[uint32]*Connection)\r\n\tch.createCommonStats()\r\n\t\r\n\t\r\n\tif opts.Handler == nil {\r\n\t\tch.registerInternal()\r\n\t}\r\n\tregisterNewChannel(ch)\r\n\tif opts.RelayHost != nil {\r\n\t\topts.RelayHost.SetChannel(ch)\r\n\t}\r\n\t\r\n\tch.mutable.idleSweep = startIdleSweep(ch, opts)\r\n\treturn ch, nil\r\n}","code-length":885,"reference":"\/\/ NewChannel creates a new Channel.  The new channel can be used to send outbound requests\n\/\/ to peers, but will not listen or handling incoming requests until one of ListenAndServe\n\/\/ or Serve is called. The local service name should be passed to serviceName.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ch *Channel) Serve(l net.Listener) error {\r\n\tmutable := &ch.mutable\r\n\tmutable.Lock()\r\n\tdefer mutable.Unlock()\r\n\tif mutable.l != nil {\r\n\t\treturn errAlreadyListening\r\n\t}\r\n\tmutable.l = tnet.Wrap(l)\r\n\tif mutable.state != ChannelClient {\r\n\t\treturn errInvalidStateForOp\r\n\t}\r\n\tmutable.state = ChannelListening\r\n\tmutable.peerInfo.HostPort = l.Addr().String()\r\n\tmutable.peerInfo.IsEphemeral = false\r\n\tch.log = ch.log.WithFields(LogField{\"hostPort\", mutable.peerInfo.HostPort})\r\n\tch.log.Info(\"Channel is listening.\")\r\n\tgo ch.serve()\r\n\treturn nil\r\n}","code-length":202,"reference":"\/\/ Serve serves incoming requests using the provided listener.\n\/\/ The local peer info is set synchronously, but the actual socket listening is done in\n\/\/ a separate goroutine.","result":"Serve the channel.","score":[0.0001,0.0379]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ch *Channel) ListenAndServe(hostPort string) error {\r\n\tmutable := &ch.mutable\r\n\tmutable.RLock()\r\n\tif mutable.l != nil {\r\n\t\tmutable.RUnlock()\r\n\t\treturn errAlreadyListening\r\n\t}\r\n\tl, err := net.Listen(\"tcp\", hostPort)\r\n\tif err != nil {\r\n\t\tmutable.RUnlock()\r\n\t\treturn err\r\n\t}\r\n\tmutable.RUnlock()\r\n\treturn ch.Serve(l)\r\n}","code-length":135,"reference":"\/\/ ListenAndServe listens on the given address and serves incoming requests.\n\/\/ The port may be 0, in which case the channel will use an OS assigned port\n\/\/ This method does not block as the handling of connections is done in a goroutine.","result":"Listen on a given host port.","score":[0.0005,0.0785]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ch *Channel) Register(h Handler, methodName string) {\r\n\tif _, ok := ch.handler.(channelHandler); !ok {\r\n\t\tpanic(\"can't register handler when channel configured with alternate root handler\")\r\n\t}\r\n\tch.GetSubChannel(ch.PeerInfo().ServiceName).Register(h, methodName)\r\n}","code-length":91,"reference":"\/\/ Register registers a handler for a method.\n\/\/\n\/\/ The handler is registered with the service name used when the Channel was\n\/\/ created. To register a handler with a different service name, obtain a\n\/\/ SubChannel for that service with GetSubChannel, and Register a handler\n\/\/ under that. You may also use SetHandler on a SubChannel to set up a\n\/\/ catch-all Handler for that service. See the docs for SetHandler for more\n\/\/ information.\n\/\/\n\/\/ Register panics if the channel was constructed with an alternate root\n\/\/ handler.","result":"Register handler in channel.","score":[0.0,0.012]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ch *Channel) PeerInfo() LocalPeerInfo {\r\n\tch.mutable.RLock()\r\n\tpeerInfo := ch.mutable.peerInfo\r\n\tch.mutable.RUnlock()\r\n\treturn peerInfo\r\n}","code-length":63,"reference":"\/\/ PeerInfo returns the current peer info for the channel","result":"Get the peer info from the channel.","score":[0.1769,0.3254]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ch *Channel) GetSubChannel(serviceName string, opts ...SubChannelOption) *SubChannel {\r\n\tsub, added := ch.subChannels.getOrAdd(serviceName, ch)\r\n\tif added {\r\n\t\tfor _, opt := range opts {\r\n\t\t\topt(sub)\r\n\t\t}\r\n\t}\r\n\treturn sub\r\n}","code-length":95,"reference":"\/\/ GetSubChannel returns a SubChannel for the given service name. If the subchannel does not\n\/\/ exist, it is created.","result":"Get the sub channel.","score":[0.0059,0.0272]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ch *Channel) serve() {\r\n\tacceptBackoff := 0 * time.Millisecond\r\n\tfor {\r\n\t\tnetConn, err := ch.mutable.l.Accept()\r\n\t\tif err != nil {\r\n\t\t\t\r\n\t\t\tif ne, ok := err.(net.Error); ok && ne.Temporary() {\r\n\t\t\t\tif acceptBackoff == 0 {\r\n\t\t\t\t\tacceptBackoff = 5 * time.Millisecond\r\n\t\t\t\t} else {\r\n\t\t\t\t\tacceptBackoff *= 2\r\n\t\t\t\t}\r\n\t\t\t\tif max := 1 * time.Second; acceptBackoff > max {\r\n\t\t\t\t\tacceptBackoff = max\r\n\t\t\t\t}\r\n\t\t\t\tch.log.WithFields(\r\n\t\t\t\t\tErrField(err),\r\n\t\t\t\t\tLogField{\"backoff\", acceptBackoff},\r\n\t\t\t\t).Warn(\"Accept error, will wait and retry.\")\r\n\t\t\t\ttime.Sleep(acceptBackoff)\r\n\t\t\t\tcontinue\r\n\t\t\t} else {\r\n\t\t\t\t\r\n\t\t\t\tif ch.State() >= ChannelStartClose {\r\n\t\t\t\t\treturn\r\n\t\t\t\t}\r\n\t\t\t\tch.log.WithFields(ErrField(err)).Fatal(\"Unrecoverable accept error, closing server.\")\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t}\r\n\t\tacceptBackoff = 0\r\n\t\t\r\n\t\tgo func() {\r\n\t\t\t\r\n\t\t\tevents := connectionEvents{\r\n\t\t\t\tOnActive:           ch.inboundConnectionActive,\r\n\t\t\t\tOnCloseStateChange: ch.connectionCloseStateChange,\r\n\t\t\t\tOnExchangeUpdated:  ch.exchangeUpdated,\r\n\t\t\t}\r\n\t\t\tif _, err := ch.inboundHandshake(context.Background(), netConn, events); err != nil {\r\n\t\t\t\tnetConn.Close()\r\n\t\t\t}\r\n\t\t}()\r\n\t}\r\n}","code-length":439,"reference":"\/\/ serve runs the listener to accept and manage new incoming connections, blocking\n\/\/ until the channel is closed.","result":"Serve the server.","score":[0.002,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ch *Channel) Ping(ctx context.Context, hostPort string) error {\r\n\tpeer := ch.RootPeers().GetOrAdd(hostPort)\r\n\tconn, err := peer.GetConnection(ctx)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn conn.ping(ctx)\r\n}","code-length":89,"reference":"\/\/ Ping sends a ping message to the given hostPort and waits for a response.","result":"Ping the channel.","score":[0.0089,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ch *Channel) StatsTags() map[string]string {\r\n\tm := make(map[string]string)\r\n\tfor k, v := range ch.commonStatsTags {\r\n\t\tm[k] = v\r\n\t}\r\n\treturn m\r\n}","code-length":74,"reference":"\/\/ StatsTags returns the common tags that should be used when reporting stats.\n\/\/ It returns a new map for each call.","result":"Generate the stats tags for the channel.","score":[0.0249,0.0732]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ch *Channel) Connect(ctx context.Context, hostPort string) (*Connection, error) {\r\n\tswitch state := ch.State(); state {\r\n\tcase ChannelClient, ChannelListening:\r\n\t\tbreak\r\n\tdefault:\r\n\t\tch.log.Debugf(\"Connect rejecting new connection as state is %v\", state)\r\n\t\treturn nil, errInvalidStateForOp\r\n\t}\r\n\t\r\n\t\r\n\tif params := getTChannelParams(ctx); params != nil && params.connectTimeout > 0 {\r\n\t\tvar cancel context.CancelFunc\r\n\t\tctx, cancel = context.WithTimeout(ctx, params.connectTimeout)\r\n\t\tdefer cancel()\r\n\t}\r\n\tevents := connectionEvents{\r\n\t\tOnActive:           ch.outboundConnectionActive,\r\n\t\tOnCloseStateChange: ch.connectionCloseStateChange,\r\n\t\tOnExchangeUpdated:  ch.exchangeUpdated,\r\n\t}\r\n\tif err := ctx.Err(); err != nil {\r\n\t\treturn nil, GetContextError(err)\r\n\t}\r\n\ttimeout := getTimeout(ctx)\r\n\ttcpConn, err := dialContext(ctx, hostPort)\r\n\tif err != nil {\r\n\t\tif ne, ok := err.(net.Error); ok && ne.Timeout() {\r\n\t\t\tch.log.WithFields(\r\n\t\t\t\tLogField{\"remoteHostPort\", hostPort},\r\n\t\t\t\tLogField{\"timeout\", timeout},\r\n\t\t\t).Info(\"Outbound net.Dial timed out.\")\r\n\t\t\terr = ErrTimeout\r\n\t\t} else if ctx.Err() == context.Canceled {\r\n\t\t\tch.log.WithFields(\r\n\t\t\t\tLogField{\"remoteHostPort\", hostPort},\r\n\t\t\t).Info(\"Outbound net.Dial was cancelled.\")\r\n\t\t\terr = GetContextError(ErrRequestCancelled)\r\n\t\t} else {\r\n\t\t\tch.log.WithFields(\r\n\t\t\t\tErrField(err),\r\n\t\t\t\tLogField{\"remoteHostPort\", hostPort},\r\n\t\t\t).Info(\"Outbound net.Dial failed.\")\r\n\t\t}\r\n\t\treturn nil, err\r\n\t}\r\n\tconn, err := ch.outboundHandshake(ctx, tcpConn, hostPort, events)\r\n\tif conn != nil {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif hostPort != conn.remotePeerInfo.HostPort {\r\n\t\t\tconn.log.Debugf(\"Outbound connection host:port mismatch, adding to peer %v\", conn.remotePeerInfo.HostPort)\r\n\t\t\tch.addConnectionToPeer(hostPort, conn, outbound)\r\n\t\t}\r\n\t}\r\n\treturn conn, err\r\n}","code-length":642,"reference":"\/\/ Connect creates a new outbound connection to hostPort.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ch *Channel) exchangeUpdated(c *Connection) {\r\n\tif c.remotePeerInfo.HostPort == \"\" {\r\n\t\t\r\n\t\treturn\r\n\t}\r\n\tp, ok := ch.RootPeers().Get(c.remotePeerInfo.HostPort)\r\n\tif !ok {\r\n\t\treturn\r\n\t}\r\n\tch.updatePeer(p)\r\n}","code-length":100,"reference":"\/\/ exchangeUpdated updates the peer heap.","result":"Trigger the exchangeUpdated event.","score":[0.2304,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ch *Channel) updatePeer(p *Peer) {\r\n\tch.peers.onPeerChange(p)\r\n\tch.subChannels.updatePeer(p)\r\n\tp.callOnUpdateComplete()\r\n}","code-length":62,"reference":"\/\/ updatePeer updates the score of the peer and update it's position in heap as well.","result":"Update peers in subchannels.","score":[0.0159,0.1014]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ch *Channel) addConnection(c *Connection, direction connectionDirection) bool {\r\n\tch.mutable.Lock()\r\n\tdefer ch.mutable.Unlock()\r\n\tif c.readState() != connectionActive {\r\n\t\treturn false\r\n\t}\r\n\tswitch state := ch.mutable.state; state {\r\n\tcase ChannelClient, ChannelListening:\r\n\t\tbreak\r\n\tdefault:\r\n\t\treturn false\r\n\t}\r\n\tch.mutable.conns[c.connID] = c\r\n\treturn true\r\n}","code-length":139,"reference":"\/\/ addConnection adds the connection to the channel's list of connection\n\/\/ if the channel is in a valid state to accept this connection. It returns\n\/\/ whether the connection was added.","result":"Add a connection to a channel.","score":[0.004,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ch *Channel) removeClosedConn(c *Connection) {\r\n\tif c.readState() != connectionClosed {\r\n\t\treturn\r\n\t}\r\n\tch.mutable.Lock()\r\n\tdelete(ch.mutable.conns, c.connID)\r\n\tch.mutable.Unlock()\r\n}","code-length":84,"reference":"\/\/ removeClosedConn removes a connection if it's closed.\n\/\/ Until a connection is fully closed, the channel must keep track of it.","result":"Remove closed connections from channel.","score":[0,0.0493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ch *Channel) connectionCloseStateChange(c *Connection) {\r\n\tch.removeClosedConn(c)\r\n\tif peer, ok := ch.RootPeers().Get(c.remotePeerInfo.HostPort); ok {\r\n\t\tpeer.connectionCloseStateChange(c)\r\n\t\tch.updatePeer(peer)\r\n\t}\r\n\tif c.outboundHP != \"\" && c.outboundHP != c.remotePeerInfo.HostPort {\r\n\t\t\r\n\t\tif peer, ok := ch.RootPeers().Get(c.outboundHP); ok {\r\n\t\t\tpeer.connectionCloseStateChange(c)\r\n\t\t\tch.updatePeer(peer)\r\n\t\t}\r\n\t}\r\n\tchState := ch.State()\r\n\tif chState != ChannelStartClose && chState != ChannelInboundClosed {\r\n\t\treturn\r\n\t}\r\n\tch.mutable.RLock()\r\n\tminState := ch.getMinConnectionState()\r\n\tch.mutable.RUnlock()\r\n\tvar updateTo ChannelState\r\n\tif minState >= connectionClosed {\r\n\t\tupdateTo = ChannelClosed\r\n\t} else if minState >= connectionInboundClosed && chState == ChannelStartClose {\r\n\t\tupdateTo = ChannelInboundClosed\r\n\t}\r\n\tvar updatedToState ChannelState\r\n\tif updateTo > 0 {\r\n\t\tch.mutable.Lock()\r\n\t\t\r\n\t\t\r\n\t\tif ch.mutable.state == chState {\r\n\t\t\tch.mutable.state = updateTo\r\n\t\t\tupdatedToState = updateTo\r\n\t\t}\r\n\t\tch.mutable.Unlock()\r\n\t\tchState = updateTo\r\n\t}\r\n\tc.log.Debugf(\"ConnectionCloseStateChange channel state = %v connection minState = %v\",\r\n\t\tchState, minState)\r\n\tif updatedToState == ChannelClosed {\r\n\t\tch.onClosed()\r\n\t}\r\n}","code-length":462,"reference":"\/\/ connectionCloseStateChange is called when a connection's close state changes.","result":"Avoid circular references.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ch *Channel) State() ChannelState {\r\n\tch.mutable.RLock()\r\n\tstate := ch.mutable.state\r\n\tch.mutable.RUnlock()\r\n\treturn state\r\n}","code-length":58,"reference":"\/\/ State returns the current channel state.","result":"Get the state of the channel.","score":[0.1634,0.1449]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewReader(reader io.Reader) *Reader {\r\n\tr := readerPool.Get().(*Reader)\r\n\tr.reader = reader\r\n\tr.err = nil\r\n\treturn r\r\n}","code-length":57,"reference":"\/\/ NewReader returns a reader that reads typed values from the reader.","result":"Create a reader.","score":[0.0242,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Reader) ReadUint16() uint16 {\r\n\tif r.err != nil {\r\n\t\treturn 0\r\n\t}\r\n\tbuf := r.buf[:2]\r\n\tvar readN int\r\n\treadN, r.err = io.ReadFull(r.reader, buf)\r\n\tif readN < 2 {\r\n\t\treturn 0\r\n\t}\r\n\treturn binary.BigEndian.Uint16(buf)\r\n}","code-length":117,"reference":"\/\/ ReadUint16 reads a uint16.","result":"Avoid recursion.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Reader) ReadString(n int) string {\r\n\tif r.err != nil {\r\n\t\treturn \"\"\r\n\t}\r\n\tvar buf []byte\r\n\tif n <= maxPoolStringLen {\r\n\t\tbuf = r.buf[:n]\r\n\t} else {\r\n\t\tbuf = make([]byte, n)\r\n\t}\r\n\tvar readN int\r\n\treadN, r.err = io.ReadFull(r.reader, buf)\r\n\tif readN < n {\r\n\t\treturn \"\"\r\n\t}\r\n\ts := string(buf)\r\n\treturn s\r\n}","code-length":160,"reference":"\/\/ ReadString reads a string of length n.","result":"Avoid the need for the following code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Reader) ReadLen16String() string {\r\n\tlen := r.ReadUint16()\r\n\treturn r.ReadString(int(len))\r\n}","code-length":49,"reference":"\/\/ ReadLen16String reads a uint16-length prefixed string.","result":"Parse the file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Behavior) Register(ch *tchannel.Channel) {\r\n\tb.registerThrift(ch)\r\n\tb.registerJSON(ch)\r\n}","code-length":48,"reference":"\/\/ Register function adds JSON and Thrift handlers to the server channel ch","result":"Register the behavior.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Behavior) Run(t crossdock.T) {\r\n\tlogParams(t)\r\n\tsampled, err := strconv.ParseBool(t.Param(sampledParam))\r\n\tif err != nil {\r\n\t\tt.Fatalf(\"Malformed param %s: %s\", sampledParam, err)\r\n\t}\r\n\tbaggage := randomBaggage()\r\n\tlevel1 := &Request{\r\n\t\tServerRole: RoleS1,\r\n\t}\r\n\tserver1 := t.Param(server1NameParam)\r\n\tlevel2 := &Downstream{\r\n\t\tServiceName: t.Param(server2NameParam),\r\n\t\tServerRole:  RoleS2,\r\n\t\tHostPort: fmt.Sprintf(\"%s:%s\",\r\n\t\t\tb.serviceToHost(t.Param(server2NameParam)),\r\n\t\t\tb.ServerPort,\r\n\t\t),\r\n\t\tEncoding: t.Param(server2EncodingParam),\r\n\t}\r\n\tlevel1.Downstream = level2\r\n\tlevel3 := &Downstream{\r\n\t\tServiceName: t.Param(server3NameParam),\r\n\t\tServerRole:  RoleS3,\r\n\t\tHostPort: fmt.Sprintf(\"%s:%s\",\r\n\t\t\tb.serviceToHost(t.Param(server3NameParam)),\r\n\t\t\tb.ServerPort,\r\n\t\t),\r\n\t\tEncoding: t.Param(server3EncodingParam),\r\n\t}\r\n\tlevel2.Downstream = level3\r\n\tresp, err := b.startTrace(t, level1, sampled, baggage)\r\n\tif err != nil {\r\n\t\tt.Errorf(\"Failed to startTrace in S1(%s): %s\", server1, err.Error())\r\n\t\treturn\r\n\t}\r\n\tlog.Printf(\"Response: span=%+v, downstream=%+v\", resp.Span, resp.Downstream)\r\n\ttraceID := resp.Span.TraceID\r\n\trequire := crossdock.Require(t)\r\n\trequire.NotEmpty(traceID, \"Trace ID should not be empty in S1(%s)\", server1)\r\n\tif validateTrace(t, level1.Downstream, resp, server1, 1, traceID, sampled, baggage) {\r\n\t\tt.Successf(\"trace checks out\")\r\n\t\tlog.Println(\"PASS\")\r\n\t} else {\r\n\t\tlog.Println(\"FAIL\")\r\n\t}\r\n}","code-length":599,"reference":"\/\/ Run executes the trace behavior","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tp *relayTimerPool) Get() *relayTimer {\r\n\ttimer, ok := tp.pool.Get().(*relayTimer)\r\n\tif ok {\r\n\t\ttimer.released = false\r\n\t\treturn timer\r\n\t}\r\n\trt := &relayTimer{\r\n\t\tpool: tp,\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\trt.timer = time.AfterFunc(time.Duration(math.MaxInt64), rt.OnTimer)\r\n\tif !rt.timer.Stop() {\r\n\t\tpanic(\"relayTimer requires timers in stopped state, but failed to stop underlying timer\")\r\n\t}\r\n\treturn rt\r\n}","code-length":177,"reference":"\/\/ Get returns a relay timer that has not started. Timers must be started explicitly\n\/\/ using the Start function.","result":"Get a timer from the pool.","score":[0.0265,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tp *relayTimerPool) Put(rt *relayTimer) {\r\n\tif tp.verify {\r\n\t\t\r\n\t\t\r\n\t\treturn\r\n\t}\r\n\ttp.pool.Put(rt)\r\n}","code-length":64,"reference":"\/\/ Put returns a relayTimer back to the pool.","result":"Verify the verification flag.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rt *relayTimer) Start(d time.Duration, items *relayItems, id uint32, isOriginator bool) {\r\n\trt.verifyNotReleased()\r\n\tif rt.active {\r\n\t\tpanic(\"Tried to start an already-active timer\")\r\n\t}\r\n\trt.active = true\r\n\trt.items = items\r\n\trt.id = id\r\n\trt.isOriginator = isOriginator\r\n\tif wasActive := rt.timer.Reset(d); wasActive {\r\n\t\tpanic(\"relayTimer's underlying timer was Started multiple times without Stop\")\r\n\t}\r\n}","code-length":158,"reference":"\/\/ Start starts a timer with the given duration for the specified ID.","result":"Start the timer.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rt *relayTimer) Release() {\r\n\trt.verifyNotReleased()\r\n\tif rt.active {\r\n\t\tpanic(\"only stopped or completed timers can be released\")\r\n\t}\r\n\trt.released = true\r\n\trt.pool.Put(rt)\r\n}","code-length":80,"reference":"\/\/ Release releases a timer back to the timer pool. The timer MUST have run or be\n\/\/ stopped before Release is called.","result":"Release timer in the future.","score":[0.0086,0.0708]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLogger(writer io.Writer, fields ...LogField) Logger {\r\n\treturn &writerLogger{writer, fields}\r\n}","code-length":40,"reference":"\/\/ NewLogger returns a Logger that writes to the given writer.","result":"Create a new logger.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTCPFrameRelay(dests []string, modifier func(bool, *tchannel.Frame) *tchannel.Frame) (Relay, error) {\r\n\tvar err error\r\n\tr := &tcpFrameRelay{modifier: modifier}\r\n\tr.tcpRelay, err = newTCPRelay(dests, r.handleConnFrameRelay)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn r, nil\r\n}","code-length":117,"reference":"\/\/ NewTCPFrameRelay relays frames from one connection to another. It reads\n\/\/ and writes frames using the TChannel frame functions.","result":"Create a new TCPFrameRelay.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (kt knownTags) tallyTags() map[string]string {\r\n\ttallyTags := make(map[string]string, 5)\r\n\tif kt.dest != \"\" {\r\n\t\ttallyTags[\"dest\"] = kt.dest\r\n\t}\r\n\tif kt.source != \"\" {\r\n\t\ttallyTags[\"source\"] = kt.source\r\n\t}\r\n\tif kt.procedure != \"\" {\r\n\t\ttallyTags[\"procedure\"] = kt.procedure\r\n\t}\r\n\tif kt.retryCount != \"\" {\r\n\t\ttallyTags[\"retry-count\"] = kt.retryCount\r\n\t}\r\n\treturn tallyTags\r\n}","code-length":179,"reference":"\/\/ Create a sub-scope for this set of known tags.","result":"Generate the tallyTags function.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Isolated(s *SubChannel) {\r\n\ts.Lock()\r\n\ts.peers = s.topChannel.peers.newSibling()\r\n\ts.peers.SetStrategy(newLeastPendingCalculator())\r\n\ts.Unlock()\r\n}","code-length":68,"reference":"\/\/ Isolated is a SubChannelOption that creates an isolated subchannel.","result":"Isolate subchannels.","score":[0,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *SubChannel) Isolated() bool {\r\n\tc.RLock()\r\n\tdefer c.RUnlock()\r\n\treturn c.topChannel.Peers() != c.peers\r\n}","code-length":56,"reference":"\/\/ Isolated returns whether this subchannel is an isolated subchannel.","result":"Check if channel is isolated.","score":[0.0884,0.0526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *SubChannel) Register(h Handler, methodName string) {\r\n\thandlers, ok := c.handler.(*handlerMap)\r\n\tif !ok {\r\n\t\tpanic(fmt.Sprintf(\r\n\t\t\t\"handler for SubChannel(%v) was changed to disallow method registration\",\r\n\t\t\tc.ServiceName(),\r\n\t\t))\r\n\t}\r\n\thandlers.register(h, methodName)\r\n}","code-length":109,"reference":"\/\/ Register registers a handler on the subchannel for the given method.\n\/\/\n\/\/ This function panics if the Handler for the SubChannel was overwritten with\n\/\/ SetHandler.","result":"Register method handlers.","score":[0.0001,0.0196]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *SubChannel) GetHandlers() map[string]Handler {\r\n\thandlers, ok := c.handler.(*handlerMap)\r\n\tif !ok {\r\n\t\tpanic(fmt.Sprintf(\r\n\t\t\t\"handler for SubChannel(%v) was changed to disallow method registration\",\r\n\t\t\tc.ServiceName(),\r\n\t\t))\r\n\t}\r\n\thandlers.RLock()\r\n\thandlersMap := make(map[string]Handler, len(handlers.handlers))\r\n\tfor k, v := range handlers.handlers {\r\n\t\thandlersMap[k] = v\r\n\t}\r\n\thandlers.RUnlock()\r\n\treturn handlersMap\r\n}","code-length":168,"reference":"\/\/ GetHandlers returns all handlers registered on this subchannel by method name.\n\/\/\n\/\/ This function panics if the Handler for the SubChannel was overwritten with\n\/\/ SetHandler.","result":"Get handlers from the subchannel.","score":[0.0029,0.0389]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *SubChannel) StatsTags() map[string]string {\r\n\ttags := c.topChannel.StatsTags()\r\n\ttags[\"subchannel\"] = c.serviceName\r\n\treturn tags\r\n}","code-length":58,"reference":"\/\/ StatsTags returns the stats tags for this subchannel.","result":"Get the stats tags from the subchannel.","score":[0.2686,0.3587]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (subChMap *subChannelMap) registerNewSubChannel(serviceName string, ch *Channel) (_ *SubChannel, added bool) {\r\n\tsubChMap.Lock()\r\n\tdefer subChMap.Unlock()\r\n\tif subChMap.subchannels == nil {\r\n\t\tsubChMap.subchannels = make(map[string]*SubChannel)\r\n\t}\r\n\tif sc, ok := subChMap.subchannels[serviceName]; ok {\r\n\t\treturn sc, false\r\n\t}\r\n\tsc := newSubChannel(serviceName, ch)\r\n\tsubChMap.subchannels[serviceName] = sc\r\n\treturn sc, true\r\n}","code-length":165,"reference":"\/\/ Register a new subchannel for the given serviceName","result":"Register new subChannel .","score":[0.1088,0.3007]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (subChMap *subChannelMap) get(serviceName string) (*SubChannel, bool) {\r\n\tsubChMap.RLock()\r\n\tsc, ok := subChMap.subchannels[serviceName]\r\n\tsubChMap.RUnlock()\r\n\treturn sc, ok\r\n}","code-length":78,"reference":"\/\/ Get subchannel if, we have one","result":"Get the subChannel from the subChannelMap.","score":[0.1634,0.1449]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (subChMap *subChannelMap) getOrAdd(serviceName string, ch *Channel) (_ *SubChannel, added bool) {\r\n\tif sc, ok := subChMap.get(serviceName); ok {\r\n\t\treturn sc, false\r\n\t}\r\n\treturn subChMap.registerNewSubChannel(serviceName, ch)\r\n}","code-length":89,"reference":"\/\/ GetOrAdd a subchannel for the given serviceName on the map","result":"Store the channel in the subChannelMap.","score":[0.0998,0.0952]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Discover(serviceName string) ([]string, error) {\r\n\tctx, cancel := thrift.NewContext(time.Second)\r\n\tdefer cancel()\r\n\tresult, err := c.hyperbahnClient.Discover(ctx, &hyperbahn.DiscoveryQuery{ServiceName: serviceName})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar hostPorts []string\r\n\tfor _, peer := range result.GetPeers() {\r\n\t\thostPorts = append(hostPorts, servicePeerToHostPort(peer))\r\n\t}\r\n\treturn hostPorts, nil\r\n}","code-length":158,"reference":"\/\/ Discover queries Hyperbahn for a list of peers that are currently\n\/\/ advertised with the specified service name.","result":"Discover a service.","score":[0.0023,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Start() error {\r\n\tif err := c.listen(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tgo func() {\r\n\t\thttp.Serve(c.listener, c.mux)\r\n\t}()\r\n\treturn nil\r\n}","code-length":80,"reference":"\/\/ Start begins a Crossdock client in the background.","result":"Start the client.","score":[0.0657,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) listen() error {\r\n\tc.setDefaultPort(&c.ClientHostPort, \":\"+common.DefaultClientPortHTTP)\r\n\tc.setDefaultPort(&c.ServerPort, common.DefaultServerPort)\r\n\tc.mux = http.NewServeMux()\r\n\tc.mux.Handle(\"\/\", crossdock.Handler(c.Behaviors, true))\r\n\tlistener, err := net.Listen(\"tcp\", c.ClientHostPort)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tc.listener = listener\r\n\tc.ClientHostPort = listener.Addr().String()\r\n\treturn nil\r\n}","code-length":168,"reference":"\/\/ Listen initializes the server","result":"Listen on the client port.","score":[0.2857,0.2]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WriteRequest(call tchannel.ArgWritable, req *http.Request) error {\r\n\t\r\n\twb := typed.NewWriteBufferWithSize(10000)\r\n\twb.WriteLen8String(req.Method)\r\n\twriteVarintString(wb, req.URL.String())\r\n\twriteHeaders(wb, req.Header)\r\n\targ2Writer, err := call.Arg2Writer()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif _, err := wb.FlushTo(arg2Writer); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := arg2Writer.Close(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\targ3Writer, err := call.Arg3Writer()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif req.Body != nil {\r\n\t\tif _, err = io.Copy(arg3Writer, req.Body); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn arg3Writer.Close()\r\n}","code-length":273,"reference":"\/\/ WriteRequest writes a http.Request to the given writers.","result":"Write the request to the channel.","score":[0.1656,0.2937]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReadRequest(call tchannel.ArgReadable) (*http.Request, error) {\r\n\tvar arg2 []byte\r\n\tif err := tchannel.NewArgReader(call.Arg2Reader()).Read(&arg2); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\trb := typed.NewReadBuffer(arg2)\r\n\tmethod := rb.ReadLen8String()\r\n\turl := readVarintString(rb)\r\n\tr, err := http.NewRequest(method, url, nil)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treadHeaders(rb, r.Header)\r\n\tif err := rb.Err(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tr.Body, err = call.Arg3Reader()\r\n\treturn r, err\r\n}","code-length":217,"reference":"\/\/ ReadRequest reads a http.Request from the given readers.","result":"Read a request from a channel.","score":[0.1392,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewReadBufferWithSize(size int) *ReadBuffer {\r\n\treturn &ReadBuffer{buffer: make([]byte, size), remaining: nil}\r\n}","code-length":47,"reference":"\/\/ NewReadBufferWithSize returns a ReadBuffer with a given capacity","result":"Create a new ReadBuffer.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ReadBuffer) ReadByte() (byte, error) {\r\n\tif r.err != nil {\r\n\t\treturn 0, r.err\r\n\t}\r\n\tif len(r.remaining) < 1 {\r\n\t\tr.err = ErrEOF\r\n\t\treturn 0, r.err\r\n\t}\r\n\tb := r.remaining[0]\r\n\tr.remaining = r.remaining[1:]\r\n\treturn b, nil\r\n}","code-length":120,"reference":"\/\/ ReadByte returns the next byte from the buffer.","result":"Read a byte from the buffer.","score":[0.3665,0.4562]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ReadBuffer) ReadBytes(n int) []byte {\r\n\tif r.err != nil {\r\n\t\treturn nil\r\n\t}\r\n\tif len(r.remaining) < n {\r\n\t\tr.err = ErrEOF\r\n\t\treturn nil\r\n\t}\r\n\tb := r.remaining[0:n]\r\n\tr.remaining = r.remaining[n:]\r\n\treturn b\r\n}","code-length":112,"reference":"\/\/ ReadBytes returns the next n bytes from the buffer","result":"Read bytes from a buffer.","score":[0.125,0.1974]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ReadBuffer) ReadString(n int) string {\r\n\tif b := r.ReadBytes(n); b != nil {\r\n\t\t\r\n\t\treturn string(b)\r\n\t}\r\n\treturn \"\"\r\n}","code-length":65,"reference":"\/\/ ReadString returns a string of size n from the buffer","result":"Create a string.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ReadBuffer) ReadUint16() uint16 {\r\n\tif b := r.ReadBytes(2); b != nil {\r\n\t\treturn binary.BigEndian.Uint16(b)\r\n\t}\r\n\treturn 0\r\n}","code-length":67,"reference":"\/\/ ReadUint16 returns the next value in the buffer as a uint16","result":"Avoid recursion.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ReadBuffer) ReadUint32() uint32 {\r\n\tif b := r.ReadBytes(4); b != nil {\r\n\t\treturn binary.BigEndian.Uint32(b)\r\n\t}\r\n\treturn 0\r\n}","code-length":67,"reference":"\/\/ ReadUint32 returns the next value in the buffer as a uint32","result":"Avoid panic.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ReadBuffer) ReadUint64() uint64 {\r\n\tif b := r.ReadBytes(8); b != nil {\r\n\t\treturn binary.BigEndian.Uint64(b)\r\n\t}\r\n\treturn 0\r\n}","code-length":67,"reference":"\/\/ ReadUint64 returns the next value in the buffer as a uint64","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ReadBuffer) ReadUvarint() uint64 {\r\n\tv, _ := binary.ReadUvarint(r)\r\n\treturn v\r\n}","code-length":46,"reference":"\/\/ ReadUvarint reads an unsigned varint from the buffer.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ReadBuffer) ReadLen8String() string {\r\n\tn := r.ReadSingleByte()\r\n\treturn r.ReadString(int(n))\r\n}","code-length":50,"reference":"\/\/ ReadLen8String reads an 8-bit length preceded string value","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ReadBuffer) ReadLen16String() string {\r\n\tn := r.ReadUint16()\r\n\treturn r.ReadString(int(n))\r\n}","code-length":50,"reference":"\/\/ ReadLen16String reads a 16-bit length preceded string value","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ReadBuffer) FillFrom(ior io.Reader, n int) (int, error) {\r\n\tif len(r.buffer) < n {\r\n\t\treturn 0, ErrEOF\r\n\t}\r\n\tr.err = nil\r\n\tr.remaining = r.buffer[:n]\r\n\treturn io.ReadFull(ior, r.remaining)\r\n}","code-length":98,"reference":"\/\/ FillFrom fills the buffer from a reader","result":"Fill the buffer.","score":[0.0771,0.25]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ReadBuffer) Wrap(b []byte) {\r\n\tr.buffer = b\r\n\tr.remaining = b\r\n\tr.err = nil\r\n}","code-length":50,"reference":"\/\/ Wrap initializes the buffer to read from the given byte slice","result":"Wrap the buffer.","score":[0.0242,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WriteBuffer) WriteSingleByte(n byte) {\r\n\tif w.err != nil {\r\n\t\treturn\r\n\t}\r\n\tif len(w.remaining) == 0 {\r\n\t\tw.setErr(ErrBufferFull)\r\n\t\treturn\r\n\t}\r\n\tw.remaining[0] = n\r\n\tw.remaining = w.remaining[1:]\r\n}","code-length":105,"reference":"\/\/ WriteSingleByte writes a single byte to the buffer","result":"Write a single byte to the buffer.","score":[0.5051,0.6802]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WriteBuffer) WriteBytes(in []byte) {\r\n\tif b := w.reserve(len(in)); b != nil {\r\n\t\tcopy(b, in)\r\n\t}\r\n}","code-length":60,"reference":"\/\/ WriteBytes writes a slice of bytes to the buffer","result":"Write bytes to the buffer.","score":[0.1821,0.3947]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WriteBuffer) WriteUint16(n uint16) {\r\n\tif b := w.reserve(2); b != nil {\r\n\t\tbinary.BigEndian.PutUint16(b, n)\r\n\t}\r\n}","code-length":66,"reference":"\/\/ WriteUint16 writes a big endian encoded uint16 value to the buffer","result":"Write a function to the buffer.","score":[0.1112,0.3289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WriteBuffer) WriteUint32(n uint32) {\r\n\tif b := w.reserve(4); b != nil {\r\n\t\tbinary.BigEndian.PutUint32(b, n)\r\n\t}\r\n}","code-length":66,"reference":"\/\/ WriteUint32 writes a big endian uint32 value to the buffer","result":"Write the bytes to the buffer.","score":[0.1187,0.2434]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WriteBuffer) WriteUint64(n uint64) {\r\n\tif b := w.reserve(8); b != nil {\r\n\t\tbinary.BigEndian.PutUint64(b, n)\r\n\t}\r\n}","code-length":66,"reference":"\/\/ WriteUint64 writes a big endian uint64 to the buffer","result":"Write the bytes to the buffer.","score":[0.1402,0.2662]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WriteBuffer) WriteUvarint(n uint64) {\r\n\t\r\n\tbuf := make([]byte, 10)\r\n\tvarBytes := binary.PutUvarint(buf, n)\r\n\tif b := w.reserve(varBytes); b != nil {\r\n\t\tcopy(b, buf[0:varBytes])\r\n\t}\r\n}","code-length":96,"reference":"\/\/ WriteUvarint writes an unsigned varint to the buffer","result":"Values to the buffer.","score":[0.1294,0.2206]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WriteBuffer) WriteString(s string) {\r\n\t\r\n\t\r\n\tif b := w.reserve(len(s)); b != nil {\r\n\t\tcopy(b, s)\r\n\t}\r\n}","code-length":64,"reference":"\/\/ WriteString writes a string to the buffer","result":"Write to the buffer.","score":[0.1662,0.3363]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WriteBuffer) WriteLen8String(s string) {\r\n\tif int(byte(len(s))) != len(s) {\r\n\t\tw.setErr(errStringTooLong)\r\n\t}\r\n\tw.WriteSingleByte(byte(len(s)))\r\n\tw.WriteString(s)\r\n}","code-length":89,"reference":"\/\/ WriteLen8String writes an 8-bit length preceded string","result":"Write the string to the buffer.","score":[0.1383,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WriteBuffer) WriteLen16String(s string) {\r\n\tif int(uint16(len(s))) != len(s) {\r\n\t\tw.setErr(errStringTooLong)\r\n\t}\r\n\tw.WriteUint16(uint16(len(s)))\r\n\tw.WriteString(s)\r\n}","code-length":91,"reference":"\/\/ WriteLen16String writes a 16-bit length preceded string","result":"Write the string to the buffer.","score":[0.1383,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WriteBuffer) DeferByte() ByteRef {\r\n\tif len(w.remaining) == 0 {\r\n\t\tw.setErr(ErrBufferFull)\r\n\t\treturn ByteRef(nil)\r\n\t}\r\n\t\r\n\tw.remaining[0] = 0\r\n\tbufRef := ByteRef(w.remaining[0:])\r\n\tw.remaining = w.remaining[1:]\r\n\treturn bufRef\r\n}","code-length":115,"reference":"\/\/ DeferByte reserves space in the buffer for a single byte, and returns a\n\/\/ reference that can be used to update that byte later","result":"Defer byte to write buffer.","score":[0.0052,0.0435]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WriteBuffer) DeferBytes(n int) BytesRef {\r\n\treturn BytesRef(w.deferred(n))\r\n}","code-length":42,"reference":"\/\/ DeferBytes reserves space in the buffer for a fixed sequence of bytes, and\n\/\/ returns a reference that can be used to update those bytes","result":"Generate the code.","score":[0.0002,0.0211]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WriteBuffer) FlushTo(iow io.Writer) (int, error) {\r\n\tdirty := w.buffer[0:w.BytesWritten()]\r\n\treturn iow.Write(dirty)\r\n}","code-length":62,"reference":"\/\/ FlushTo flushes the written buffer to the given writer","result":"Flush the buffer.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WriteBuffer) Reset() {\r\n\tw.remaining = w.buffer\r\n\tw.err = nil\r\n}","code-length":40,"reference":"\/\/ Reset resets the buffer to an empty state, ready for writing","result":"Reset the buffer.","score":[0.0242,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WriteBuffer) Wrap(b []byte) {\r\n\tw.buffer = b\r\n\tw.remaining = b\r\n}","code-length":42,"reference":"\/\/ Wrap initializes the buffer to wrap the given byte slice","result":"Wrap the buffer.","score":[0.0337,0.1838]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ref Uint16Ref) Update(n uint16) {\r\n\tif ref != nil {\r\n\t\tbinary.BigEndian.PutUint16(ref, n)\r\n\t}\r\n}","code-length":55,"reference":"\/\/ Update updates the uint16 in the buffer","result":"Update the ref.","score":[0.0917,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ref Uint32Ref) Update(n uint32) {\r\n\tif ref != nil {\r\n\t\tbinary.BigEndian.PutUint32(ref, n)\r\n\t}\r\n}","code-length":55,"reference":"\/\/ Update updates the uint32 in the buffer","result":"Update the ref.","score":[0.0917,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ref Uint64Ref) Update(n uint64) {\r\n\tif ref != nil {\r\n\t\tbinary.BigEndian.PutUint64(ref, n)\r\n\t}\r\n}","code-length":55,"reference":"\/\/ Update updates the uint64 in the buffer","result":"Update the ref.","score":[0.0917,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ref BytesRef) Update(b []byte) {\r\n\tif ref != nil {\r\n\t\tcopy(ref, b)\r\n\t}\r\n}","code-length":47,"reference":"\/\/ Update updates the bytes in the buffer","result":"Update the bytesref.","score":[0.0917,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ref BytesRef) UpdateString(s string) {\r\n\tif ref != nil {\r\n\t\tcopy(ref, s)\r\n\t}\r\n}","code-length":47,"reference":"\/\/ UpdateString updates the bytes in the buffer from a string","result":"Update the string in the bytesref.","score":[0.1411,0.4248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *fragmentingReader) ArgReader(last bool) (ArgReader, error) {\r\n\tif err := r.BeginArgument(last); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn r, nil\r\n}","code-length":69,"reference":"\/\/ The ArgReader will handle fragmentation as needed. Once the argument has\n\/\/ been read, the ArgReader must be closed.","result":"Generate code for the generated code.","score":[0.0187,0.0269]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *writableFragment) finish(hasMoreFragments bool) {\r\n\tf.checksumRef.Update(f.checksum.Sum())\r\n\tif hasMoreFragments {\r\n\t\tf.flagsRef.Update(hasMoreFragmentsFlag)\r\n\t} else {\r\n\t\tf.checksum.Release()\r\n\t}\r\n}","code-length":86,"reference":"\/\/ finish finishes the fragment, updating the final checksum and fragment flags","result":"Close the fragment.","score":[0.0203,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newWritableChunk(checksum Checksum, contents *typed.WriteBuffer) *writableChunk {\r\n\treturn &writableChunk{\r\n\t\tsize:     0,\r\n\t\tsizeRef:  contents.DeferUint16(),\r\n\t\tchecksum: checksum,\r\n\t\tcontents: contents,\r\n\t}\r\n}","code-length":83,"reference":"\/\/ newWritableChunk creates a new writable chunk around a checksum and a buffer to hold data","result":"Create a new writable chunk.","score":[0.0548,0.2118]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *writableChunk) writeAsFits(b []byte) int {\r\n\tif len(b) > c.contents.BytesRemaining() {\r\n\t\tb = b[:c.contents.BytesRemaining()]\r\n\t}\r\n\tc.checksum.Add(b)\r\n\tc.contents.WriteBytes(b)\r\n\twritten := len(b)\r\n\tc.size += uint16(written)\r\n\treturn written\r\n}","code-length":116,"reference":"\/\/ writeAsFits writes as many bytes from the given slice as fits into the chunk","result":"Write as fits.","score":[0.0075,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newFragmentingWriter(logger Logger, sender fragmentSender, checksum Checksum) *fragmentingWriter {\r\n\treturn &fragmentingWriter{\r\n\t\tlogger:   logger,\r\n\t\tsender:   sender,\r\n\t\tchecksum: checksum,\r\n\t\tstate:    fragmentingWriteStart,\r\n\t}\r\n}","code-length":84,"reference":"\/\/ newFragmentingWriter creates a new fragmenting writer","result":"Create a new fragmentingWriter.","score":[0.2134,0.4395]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *fragmentingWriter) ArgWriter(last bool) (ArgWriter, error) {\r\n\tif err := w.BeginArgument(last); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn w, nil\r\n}","code-length":69,"reference":"\/\/ ArgWriter returns an ArgWriter to write an argument. The ArgWriter will handle\n\/\/ fragmentation as needed. Once the argument is written, the ArgWriter must be closed.","result":"Generate code for the generated code.","score":[0.0058,0.0201]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *fragmentingWriter) BeginArgument(last bool) error {\r\n\tif w.err != nil {\r\n\t\treturn w.err\r\n\t}\r\n\tswitch {\r\n\tcase w.state == fragmentingWriteComplete:\r\n\t\tw.err = errComplete\r\n\t\treturn w.err\r\n\tcase w.state.isWritingArgument():\r\n\t\tw.err = errAlreadyWritingArgument\r\n\t\treturn w.err\r\n\t}\r\n\t\r\n\tif w.curFragment == nil {\r\n\t\tinitial := w.state == fragmentingWriteStart\r\n\t\tif w.curFragment, w.err = w.sender.newFragment(initial, w.checksum); w.err != nil {\r\n\t\t\treturn w.err\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tif w.curFragment.contents.BytesRemaining() <= chunkHeaderSize {\r\n\t\tpanic(fmt.Errorf(\"attempting to begin an argument in a fragment with only %d bytes available\",\r\n\t\t\tw.curFragment.contents.BytesRemaining()))\r\n\t}\r\n\tw.curChunk = newWritableChunk(w.checksum, w.curFragment.contents)\r\n\tw.state = fragmentingWriteInArgument\r\n\tif last {\r\n\t\tw.state = fragmentingWriteInLastArgument\r\n\t}\r\n\treturn nil\r\n}","code-length":338,"reference":"\/\/ BeginArgument tells the writer that the caller is starting a new argument.\n\/\/ Must not be called while an existing argument is in place","result":"Write an argument to a fragmentingWriter.","score":[0.0107,0.0649]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *fragmentingWriter) Write(b []byte) (int, error) {\r\n\tif w.err != nil {\r\n\t\treturn 0, w.err\r\n\t}\r\n\tif !w.state.isWritingArgument() {\r\n\t\tw.err = errNotWritingArgument\r\n\t\treturn 0, w.err\r\n\t}\r\n\ttotalWritten := 0\r\n\tfor {\r\n\t\tbytesWritten := w.curChunk.writeAsFits(b)\r\n\t\ttotalWritten += bytesWritten\r\n\t\tif bytesWritten == len(b) {\r\n\t\t\t\r\n\t\t\treturn totalWritten, nil\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tif w.err = w.Flush(); w.err != nil {\r\n\t\t\treturn totalWritten, w.err\r\n\t\t}\r\n\t\tb = b[bytesWritten:]\r\n\t}\r\n}","code-length":220,"reference":"\/\/ Write writes argument data, breaking it into fragments as needed","result":"Write to a fragmented writer.","score":[0.0724,0.0962]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *fragmentingWriter) Flush() error {\r\n\tw.curChunk.finish()\r\n\tw.curFragment.finish(true)\r\n\tif w.err = w.sender.flushFragment(w.curFragment); w.err != nil {\r\n\t\treturn w.err\r\n\t}\r\n\tif w.curFragment, w.err = w.sender.newFragment(false, w.checksum); w.err != nil {\r\n\t\treturn w.err\r\n\t}\r\n\tw.curChunk = newWritableChunk(w.checksum, w.curFragment.contents)\r\n\treturn nil\r\n}","code-length":156,"reference":"\/\/ Flush flushes the current fragment, and starts a new fragment and chunk.","result":"Flush the fragmentingWriter.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *fragmentingWriter) Close() error {\r\n\tlast := w.state == fragmentingWriteInLastArgument\r\n\tif w.err != nil {\r\n\t\treturn w.err\r\n\t}\r\n\tif !w.state.isWritingArgument() {\r\n\t\tw.err = errNotWritingArgument\r\n\t\treturn w.err\r\n\t}\r\n\tw.curChunk.finish()\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif last {\r\n\t\t\r\n\t\tw.state = fragmentingWriteComplete\r\n\t\tw.curFragment.finish(false)\r\n\t\tw.err = w.sender.flushFragment(w.curFragment)\r\n\t\tw.sender.doneSending()\r\n\t\treturn w.err\r\n\t}\r\n\tw.state = fragmentingWriteWaitingForArgument\r\n\tif w.curFragment.contents.BytesRemaining() > chunkHeaderSize {\r\n\t\t\r\n\t\t\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\tw.curFragment.finish(true)\r\n\tif w.err = w.sender.flushFragment(w.curFragment); w.err != nil {\r\n\t\treturn w.err\r\n\t}\r\n\tif w.curFragment, w.err = w.sender.newFragment(false, w.checksum); w.err != nil {\r\n\t\treturn w.err\r\n\t}\r\n\t\r\n\tw.curFragment.contents.WriteUint16(0)\r\n\treturn nil\r\n}","code-length":379,"reference":"\/\/ Close ends the current argument.","result":"Close the writer.","score":[0.1786,0.1754]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Connection) handleCallRes(frame *Frame) bool {\r\n\tif err := c.outbound.forwardPeerFrame(frame); err != nil {\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":64,"reference":"\/\/ handleCallRes handles an incoming call req message, forwarding the\n\/\/ frame to the response channel waiting for it","result":"Handle call res.","score":[0.002,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (response *OutboundCallResponse) Arg2Reader() (ArgReader, error) {\r\n\tvar method []byte\r\n\tif err := NewArgReader(response.arg1Reader()).Read(&method); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn response.arg2Reader()\r\n}","code-length":86,"reference":"\/\/ Arg2Reader returns an ArgReader to read the second argument.\n\/\/ The ReadCloser must be closed once the argument has been read.","result":"Generate the method name.","score":[0.0035,0.0248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Connection) handleError(frame *Frame) bool {\r\n\terrMsg := errorMessage{\r\n\t\tid: frame.Header.ID,\r\n\t}\r\n\trbuf := typed.NewReadBuffer(frame.SizedPayload())\r\n\tif err := errMsg.read(rbuf); err != nil {\r\n\t\tc.log.WithFields(\r\n\t\t\tLogField{\"remotePeer\", c.remotePeerInfo},\r\n\t\t\tErrField(err),\r\n\t\t).Warn(\"Unable to read error frame.\")\r\n\t\tc.connectionError(\"parsing error frame\", err)\r\n\t\treturn true\r\n\t}\r\n\tif errMsg.errCode == ErrCodeProtocol {\r\n\t\tc.log.WithFields(\r\n\t\t\tLogField{\"remotePeer\", c.remotePeerInfo},\r\n\t\t\tLogField{\"error\", errMsg.message},\r\n\t\t).Warn(\"Peer reported protocol error.\")\r\n\t\tc.connectionError(\"received protocol error\", errMsg.AsSystemError())\r\n\t\treturn true\r\n\t}\r\n\tif err := c.outbound.forwardPeerFrame(frame); err != nil {\r\n\t\tc.log.WithFields(\r\n\t\t\tLogField{\"frameHeader\", frame.Header.String()},\r\n\t\t\tLogField{\"id\", errMsg.id},\r\n\t\t\tLogField{\"errorMessage\", errMsg.message},\r\n\t\t\tLogField{\"errorCode\", errMsg.errCode},\r\n\t\t\tErrField(err),\r\n\t\t).Info(\"Failed to forward error frame.\")\r\n\t\treturn true\r\n\t}\r\n\t\r\n\treturn false\r\n}","code-length":385,"reference":"\/\/ handleError handles an error coming back from the peer. If the error is a\n\/\/ protocol level error, the entire connection will be closed.  If the error is\n\/\/ a request specific error, it will be written to the request's response\n\/\/ channel and converted into a SystemError returned from the next reader or\n\/\/ access call.\n\/\/ The return value is whether the frame should be released immediately.","result":"Detect errors in the error frame.","score":[0.0,0.0236]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (response *OutboundCallResponse) doneReading(unexpected error) {\r\n\tnow := response.timeNow()\r\n\tisSuccess := unexpected == nil && !response.ApplicationError()\r\n\tlastAttempt := isSuccess || !response.requestState.HasRetries(unexpected)\r\n\t\r\n\tif span := response.span; span != nil {\r\n\t\tif unexpected != nil {\r\n\t\t\tspan.LogEventWithPayload(\"error\", unexpected)\r\n\t\t}\r\n\t\tif !isSuccess && lastAttempt {\r\n\t\t\text.Error.Set(span, true)\r\n\t\t}\r\n\t\tspan.FinishWithOptions(opentracing.FinishOptions{FinishTime: now})\r\n\t}\r\n\tlatency := now.Sub(response.startedAt)\r\n\tresponse.statsReporter.RecordTimer(\"outbound.calls.per-attempt.latency\", response.commonStatsTags, latency)\r\n\tif lastAttempt {\r\n\t\trequestLatency := response.requestState.SinceStart(now, latency)\r\n\t\tresponse.statsReporter.RecordTimer(\"outbound.calls.latency\", response.commonStatsTags, requestLatency)\r\n\t}\r\n\tif retryCount := response.requestState.RetryCount(); retryCount > 0 {\r\n\t\tretryTags := cloneTags(response.commonStatsTags)\r\n\t\tretryTags[\"retry-count\"] = fmt.Sprint(retryCount)\r\n\t\tresponse.statsReporter.IncCounter(\"outbound.calls.retries\", retryTags, 1)\r\n\t}\r\n\tif unexpected != nil {\r\n\t\t\r\n\t\t\r\n\t} else if response.ApplicationError() {\r\n\t\t\r\n\t\tresponse.statsReporter.IncCounter(\"outbound.calls.per-attempt.app-errors\", response.commonStatsTags, 1)\r\n\t\tif lastAttempt {\r\n\t\t\tresponse.statsReporter.IncCounter(\"outbound.calls.app-errors\", response.commonStatsTags, 1)\r\n\t\t}\r\n\t} else {\r\n\t\tresponse.statsReporter.IncCounter(\"outbound.calls.success\", response.commonStatsTags, 1)\r\n\t}\r\n\tresponse.mex.shutdown()\r\n}","code-length":511,"reference":"\/\/ doneReading shuts down the message exchange for this call.\n\/\/ For outgoing calls, the last message is reading the call response.","result":"Signal the end of the response reader.","score":[0.0225,0.1247]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *reqResWriter) newFragment(initial bool, checksum Checksum) (*writableFragment, error) {\r\n\tif err := w.mex.checkError(); err != nil {\r\n\t\treturn nil, w.failed(err)\r\n\t}\r\n\tmessage := w.messageForFragment(initial)\r\n\t\r\n\tframe := w.conn.opts.FramePool.Get()\r\n\tframe.Header.ID = w.mex.msgID\r\n\tframe.Header.messageType = message.messageType()\r\n\t\r\n\twbuf := typed.NewWriteBuffer(frame.Payload[:])\r\n\tfragment := new(writableFragment)\r\n\tfragment.frame = frame\r\n\tfragment.flagsRef = wbuf.DeferByte()\r\n\tif err := message.write(wbuf); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\twbuf.WriteSingleByte(byte(checksum.TypeCode()))\r\n\tfragment.checksumRef = wbuf.DeferBytes(checksum.Size())\r\n\tfragment.checksum = checksum\r\n\tfragment.contents = wbuf\r\n\treturn fragment, wbuf.Err()\r\n}","code-length":281,"reference":"\/\/ newFragment creates a new fragment for marshaling into","result":"Create a new fragment in the transport.","score":[0.25,0.451]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *reqResWriter) flushFragment(fragment *writableFragment) error {\r\n\tif w.err != nil {\r\n\t\treturn w.err\r\n\t}\r\n\tframe := fragment.frame.(*Frame)\r\n\tframe.Header.SetPayloadSize(uint16(fragment.contents.BytesWritten()))\r\n\tif err := w.mex.checkError(); err != nil {\r\n\t\treturn w.failed(err)\r\n\t}\r\n\tselect {\r\n\tcase <-w.mex.ctx.Done():\r\n\t\treturn w.failed(GetContextError(w.mex.ctx.Err()))\r\n\tcase <-w.mex.errCh.c:\r\n\t\treturn w.failed(w.mex.errCh.err)\r\n\tcase w.conn.sendCh <- frame:\r\n\t\treturn nil\r\n\t}\r\n}","code-length":218,"reference":"\/\/ flushFragment sends a fragment to the peer over the connection","result":"Flush the fragment.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *reqResWriter) failed(err error) error {\r\n\tw.log.Debugf(\"writer failed: %v existing err: %v\", err, w.err)\r\n\tif w.err != nil {\r\n\t\treturn w.err\r\n\t}\r\n\tw.mex.shutdown()\r\n\tw.err = err\r\n\treturn w.err\r\n}","code-length":100,"reference":"\/\/ failed marks the writer as having failed","result":"Set the failed callback.","score":[0.1398,0.3363]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *reqResReader) arg1Reader() (ArgReader, error) {\r\n\treturn r.argReader(false , reqResReaderPreArg1, reqResReaderPreArg2)\r\n}","code-length":56,"reference":"\/\/ arg1Reader returns an ArgReader to read arg1.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *reqResReader) arg2Reader() (ArgReader, error) {\r\n\treturn r.argReader(false , reqResReaderPreArg2, reqResReaderPreArg3)\r\n}","code-length":56,"reference":"\/\/ arg2Reader returns an ArgReader to read arg2.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *reqResReader) arg3Reader() (ArgReader, error) {\r\n\treturn r.argReader(true , reqResReaderPreArg3, reqResReaderComplete)\r\n}","code-length":54,"reference":"\/\/ arg3Reader returns an ArgReader to read arg3.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *reqResReader) argReader(last bool, inState reqResReaderState, outState reqResReaderState) (ArgReader, error) {\r\n\tif r.state != inState {\r\n\t\treturn nil, r.failed(errReqResReaderStateMismatch{state: r.state, expectedState: inState})\r\n\t}\r\n\targReader, err := r.contents.ArgReader(last)\r\n\tif err != nil {\r\n\t\treturn nil, r.failed(err)\r\n\t}\r\n\tr.state = outState\r\n\treturn argReader, nil\r\n}","code-length":151,"reference":"\/\/ argReader returns an ArgReader that can be used to read an argument. The\n\/\/ ReadCloser must be closed once the argument has been read.","result":"Read the contents of the.","score":[0.0044,0.0435]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *reqResReader) recvNextFragment(initial bool) (*readableFragment, error) {\r\n\tif r.initialFragment != nil {\r\n\t\tfragment := r.initialFragment\r\n\t\tr.initialFragment = nil\r\n\t\tr.previousFragment = fragment\r\n\t\treturn fragment, nil\r\n\t}\r\n\t\r\n\tmessage := r.messageForFragment(initial)\r\n\tframe, err := r.mex.recvPeerFrameOfType(message.messageType())\r\n\tif err != nil {\r\n\t\tif err, ok := err.(errorMessage); ok {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tr.err = err.AsSystemError()\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn nil, r.failed(err)\r\n\t}\r\n\t\r\n\tfragment, err := parseInboundFragment(r.mex.framePool, frame, message)\r\n\tif err != nil {\r\n\t\treturn nil, r.failed(err)\r\n\t}\r\n\tr.previousFragment = fragment\r\n\treturn fragment, nil\r\n}","code-length":268,"reference":"\/\/ recvNextFragment receives the next fragment from the underlying message exchange.","result":"Receive the next fragment.","score":[0.0785,0.1456]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *reqResReader) releasePreviousFragment() {\r\n\tfragment := r.previousFragment\r\n\tr.previousFragment = nil\r\n\tif fragment != nil {\r\n\t\tfragment.done()\r\n\t}\r\n}","code-length":63,"reference":"\/\/ releasePreviousFrament releases the last fragment returned by the reader if\n\/\/ it's still around. This operation is idempotent.","result":"Release the previous fragment.","score":[0.0075,0.0571]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *reqResReader) failed(err error) error {\r\n\tr.log.Debugf(\"reader failed: %v existing err: %v\", err, r.err)\r\n\tif r.err != nil {\r\n\t\treturn r.err\r\n\t}\r\n\tr.mex.shutdown()\r\n\tr.err = err\r\n\treturn r.err\r\n}","code-length":100,"reference":"\/\/ failed indicates the reader failed","result":"Set the failed callback .","score":[0.2339,0.1695]}
{"code":"\/*is used to<extra_id_0>\r\nfunc parseInboundFragment(framePool FramePool, frame *Frame, message message) (*readableFragment, error) {\r\n\trbuf := typed.NewReadBuffer(frame.SizedPayload())\r\n\tfragment := new(readableFragment)\r\n\tfragment.flags = rbuf.ReadSingleByte()\r\n\tif err := message.read(rbuf); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tfragment.checksumType = ChecksumType(rbuf.ReadSingleByte())\r\n\tfragment.checksum = rbuf.ReadBytes(fragment.checksumType.ChecksumSize())\r\n\tfragment.contents = rbuf\r\n\tfragment.onDone = func() {\r\n\t\tframePool.Release(frame)\r\n\t}\r\n\treturn fragment, rbuf.Err()\r\n}","code-length":193,"reference":"\/\/ parseInboundFragment parses an incoming fragment based on the given message","result":"Parse inbound fragment.","score":[0,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewContext(timeout time.Duration) (Context, context.CancelFunc) {\r\n\tctx, cancel := tchannel.NewContext(timeout)\r\n\treturn Wrap(ctx), cancel\r\n}","code-length":53,"reference":"\/\/ NewContext returns a Context that can be used to make Thrift calls.","result":"Create a context.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WithHeaders(ctx context.Context, headers map[string]string) Context {\r\n\treturn tchannel.WrapWithHeaders(ctx, headers)\r\n}","code-length":44,"reference":"\/\/ WithHeaders returns a Context that can be used to make a call with request headers.","result":"Generate the header .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Connection) healthCheck(connID uint32) {\r\n\tdefer close(c.healthCheckDone)\r\n\topts := c.opts.HealthChecks\r\n\tticker := c.timeTicker(opts.Interval)\r\n\tdefer ticker.Stop()\r\n\tconsecutiveFailures := 0\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase <-ticker.C:\r\n\t\tcase <-c.healthCheckCtx.Done():\r\n\t\t\treturn\r\n\t\t}\r\n\t\tctx, cancel := context.WithTimeout(c.healthCheckCtx, opts.Timeout)\r\n\t\terr := c.ping(ctx)\r\n\t\tcancel()\r\n\t\tc.healthCheckHistory.add(err == nil)\r\n\t\tif err == nil {\r\n\t\t\tif c.log.Enabled(LogLevelDebug) {\r\n\t\t\t\tc.log.Debug(\"Performed successful active health check.\")\r\n\t\t\t}\r\n\t\t\tconsecutiveFailures = 0\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tif GetSystemErrorCode(err) == ErrCodeCancelled || err == ErrInvalidConnectionState {\r\n\t\t\tc.log.WithFields(ErrField(err)).Debug(\"Health checker stopped.\")\r\n\t\t\treturn\r\n\t\t}\r\n\t\tconsecutiveFailures++\r\n\t\tc.log.WithFields(LogFields{\r\n\t\t\t{\"consecutiveFailures\", consecutiveFailures},\r\n\t\t\tErrField(err),\r\n\t\t\t{\"failuresToClose\", opts.FailuresToClose},\r\n\t\t}...).Warn(\"Failed active health check.\")\r\n\t\tif consecutiveFailures >= opts.FailuresToClose {\r\n\t\t\tc.close(LogFields{\r\n\t\t\t\t{\"reason\", \"health check failure\"},\r\n\t\t\t\tErrField(err),\r\n\t\t\t}...)\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":450,"reference":"\/\/ healthCheck will do periodic pings on the connection to check the state of the connection.\n\/\/ We accept connID on the stack so can more easily debug panics or leaked goroutines.","result":"Check health of a connection.","score":[0.0013,0.0512]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cb *ContextBuilder) SetTimeout(timeout time.Duration) *ContextBuilder {\r\n\tcb.Timeout = timeout\r\n\treturn cb\r\n}","code-length":44,"reference":"\/\/ SetTimeout sets the timeout for the Context.","result":"Set the timeout in the context builder.","score":[0.2191,0.4747]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cb *ContextBuilder) AddHeader(key, value string) *ContextBuilder {\r\n\tif cb.Headers == nil {\r\n\t\tcb.Headers = map[string]string{key: value}\r\n\t} else {\r\n\t\tcb.Headers[key] = value\r\n\t}\r\n\treturn cb\r\n}","code-length":86,"reference":"\/\/ AddHeader adds a single application header to the Context.","result":"Add header to the context builder.","score":[0.2042,0.3906]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cb *ContextBuilder) SetHeaders(headers map[string]string) *ContextBuilder {\r\n\tcb.Headers = headers\r\n\tcb.replaceParentHeaders = true\r\n\treturn cb\r\n}","code-length":56,"reference":"\/\/ SetHeaders sets the application headers for this Context.\n\/\/ If there is a ParentContext, its headers will be ignored after the call to this method.","result":"Set headers.","score":[0,0.0212]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cb *ContextBuilder) SetConnectTimeout(d time.Duration) *ContextBuilder {\r\n\tcb.ConnectTimeout = d\r\n\treturn cb\r\n}","code-length":46,"reference":"\/\/ SetConnectTimeout sets the ConnectionTimeout for this context.\n\/\/ The context timeout applies to the whole call, while the connect\n\/\/ timeout only applies to creating a new connection.","result":"Set the default connect timeout.","score":[0.0024,0.0564]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cb *ContextBuilder) SetRetryOptions(retryOptions *RetryOptions) *ContextBuilder {\r\n\tcb.RetryOptions = retryOptions\r\n\treturn cb\r\n}","code-length":48,"reference":"\/\/ SetRetryOptions sets RetryOptions in the context.","result":"Set the retry options.","score":[0.1509,0.1493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cb *ContextBuilder) SetTimeoutPerAttempt(timeoutPerAttempt time.Duration) *ContextBuilder {\r\n\tif cb.RetryOptions == nil {\r\n\t\tcb.RetryOptions = &RetryOptions{}\r\n\t}\r\n\tcb.RetryOptions.TimeoutPerAttempt = timeoutPerAttempt\r\n\treturn cb\r\n}","code-length":83,"reference":"\/\/ SetTimeoutPerAttempt sets TimeoutPerAttempt in RetryOptions.","result":"Set the timeout per attempt in the retry options.","score":[0.1219,0.1587]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cb *ContextBuilder) SetParentContext(ctx context.Context) *ContextBuilder {\r\n\tcb.ParentContext = ctx\r\n\treturn cb\r\n}","code-length":46,"reference":"\/\/ SetParentContext sets the parent for the Context.","result":"Set the parent context.","score":[0.1662,0.2632]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cb *ContextBuilder) Build() (ContextWithHeaders, context.CancelFunc) {\r\n\tparams := &tchannelCtxParams{\r\n\t\toptions:                 cb.CallOptions,\r\n\t\tcall:                    cb.incomingCall,\r\n\t\tretryOptions:            cb.RetryOptions,\r\n\t\tconnectTimeout:          cb.ConnectTimeout,\r\n\t\thideListeningOnOutbound: cb.hideListeningOnOutbound,\r\n\t\ttracingDisabled:         cb.TracingDisabled,\r\n\t}\r\n\tparent := cb.ParentContext\r\n\tif parent == nil {\r\n\t\tparent = context.Background()\r\n\t} else if headerCtx, ok := parent.(headerCtx); ok {\r\n\t\t\r\n\t\tparent = headerCtx.Context\r\n\t}\r\n\tvar (\r\n\t\tctx    context.Context\r\n\t\tcancel context.CancelFunc\r\n\t)\r\n\t\r\n\t\r\n\t\r\n\t_, parentHasDeadline := parent.Deadline()\r\n\tif cb.Timeout == 0 && parentHasDeadline {\r\n\t\tctx, cancel = context.WithCancel(parent)\r\n\t} else {\r\n\t\tctx, cancel = context.WithTimeout(parent, cb.Timeout)\r\n\t}\r\n\tctx = context.WithValue(ctx, contextKeyTChannel, params)\r\n\treturn WrapWithHeaders(ctx, cb.getHeaders()), cancel\r\n}","code-length":330,"reference":"\/\/ Build returns a ContextWithHeaders that can be used to make calls.","result":"Build the context.","score":[0.0203,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *CallOptions) overrideHeaders(headers transportHeaders) {\r\n\tif c.Format != \"\" {\r\n\t\theaders[ArgScheme] = c.Format.String()\r\n\t}\r\n\tif c.ShardKey != \"\" {\r\n\t\theaders[ShardKey] = c.ShardKey\r\n\t}\r\n\tif c.RoutingKey != \"\" {\r\n\t\theaders[RoutingKey] = c.RoutingKey\r\n\t}\r\n\tif c.RoutingDelegate != \"\" {\r\n\t\theaders[RoutingDelegate] = c.RoutingDelegate\r\n\t}\r\n\tif c.callerName != \"\" {\r\n\t\theaders[CallerName] = c.callerName\r\n\t}\r\n}","code-length":173,"reference":"\/\/ overrideHeaders sets headers if the call options contains non-default values.","result":"Override call options headers.","score":[0.0785,0.182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r ArgReadHelper) Read(bs *[]byte) error {\r\n\treturn r.read(func() error {\r\n\t\tvar err error\r\n\t\t*bs, err = ioutil.ReadAll(r.reader)\r\n\t\treturn err\r\n\t})\r\n}","code-length":75,"reference":"\/\/ Read reads from the reader into the byte slice.","result":"Read the reader.","score":[0.0471,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r ArgReadHelper) ReadJSON(data interface{}) error {\r\n\treturn r.read(func() error {\r\n\t\t\r\n\t\t\r\n\t\treader := bufio.NewReader(r.reader)\r\n\t\tif _, err := reader.Peek(1); err == io.EOF {\r\n\t\t\t\r\n\t\t\treturn nil\r\n\t\t} else if err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\td := json.NewDecoder(reader)\r\n\t\treturn d.Decode(data)\r\n\t})\r\n}","code-length":141,"reference":"\/\/ ReadJSON deserializes JSON from the underlying reader into data.","result":"Read a JSON string.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewArgWriter(writer io.WriteCloser, err error) ArgWriteHelper {\r\n\treturn ArgWriteHelper{writer, err}\r\n}","code-length":42,"reference":"\/\/ NewArgWriter wraps the result of calling ArgXWriter to provider a simpler\n\/\/ interface for writing arguments.","result":"Generate the package .","score":[0.0124,0.0318]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w ArgWriteHelper) Write(bs []byte) error {\r\n\treturn w.write(func() error {\r\n\t\t_, err := w.writer.Write(bs)\r\n\t\treturn err\r\n\t})\r\n}","code-length":65,"reference":"\/\/ Write writes the given bytes to the underlying writer.","result":"Write to the argument.","score":[0.1116,0.2719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w ArgWriteHelper) WriteJSON(data interface{}) error {\r\n\treturn w.write(func() error {\r\n\t\te := json.NewEncoder(w.writer)\r\n\t\treturn e.Encode(data)\r\n\t})\r\n}","code-length":70,"reference":"\/\/ WriteJSON writes the given object as JSON.","result":"Write the JSON to the writer.","score":[0.1383,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Register(registrar tchannel.Registrar) {\r\n\thandler := func(ctx context.Context, call *tchannel.InboundCall) {\r\n\t\treq, err := thttp.ReadRequest(call)\r\n\t\tif err != nil {\r\n\t\t\tregistrar.Logger().WithFields(\r\n\t\t\t\ttchannel.LogField{Key: \"err\", Value: err.Error()},\r\n\t\t\t).Warn(\"Failed to read HTTP request.\")\r\n\t\t\treturn\r\n\t\t}\r\n\t\tserveHTTP(req, call.Response())\r\n\t}\r\n\tregistrar.Register(tchannel.HandlerFunc(handler), \"_pprof\")\r\n}","code-length":167,"reference":"\/\/ Register registers pprof endpoints on the given registrar under _pprof.\n\/\/ The _pprof endpoint uses as-http and is a tunnel to the default serve mux.","result":"Register handlers.","score":[0.0,0.0212]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *relayItems) Count() int {\r\n\tr.RLock()\r\n\tn := len(r.items) - int(r.tombs)\r\n\tr.RUnlock()\r\n\treturn n\r\n}","code-length":64,"reference":"\/\/ Count returns the number of non-tombstone items in the relay.","result":"Count the number of.","score":[0.0869,0.1456]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *relayItems) Get(id uint32) (relayItem, bool) {\r\n\tr.RLock()\r\n\titem, ok := r.items[id]\r\n\tr.RUnlock()\r\n\treturn item, ok\r\n}","code-length":70,"reference":"\/\/ Get checks for a relay item by ID, returning the item and a bool indicating\n\/\/ whether the item was found.","result":"Get item from relayItems.","score":[0.0042,0.0495]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *relayItems) Add(id uint32, item relayItem) {\r\n\tr.Lock()\r\n\tr.items[id] = item\r\n\tr.Unlock()\r\n}","code-length":56,"reference":"\/\/ Add adds a relay item.","result":"Add new relay items.","score":[0.2304,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *relayItems) Entomb(id uint32, deleteAfter time.Duration) (relayItem, bool) {\r\n\tr.Lock()\r\n\tif r.tombs > _maxRelayTombs {\r\n\t\tr.Unlock()\r\n\t\tr.logger.WithFields(LogField{\"id\", id}).Warn(\"Too many tombstones, deleting relay item immediately.\")\r\n\t\treturn r.Delete(id)\r\n\t}\r\n\titem, ok := r.items[id]\r\n\tif !ok {\r\n\t\tr.Unlock()\r\n\t\tr.logger.WithFields(LogField{\"id\", id}).Warn(\"Can't find relay item to entomb.\")\r\n\t\treturn item, false\r\n\t}\r\n\tif item.tomb {\r\n\t\tr.Unlock()\r\n\t\tr.logger.WithFields(LogField{\"id\", id}).Warn(\"Re-entombing a tombstone.\")\r\n\t\treturn item, false\r\n\t}\r\n\tr.tombs++\r\n\titem.tomb = true\r\n\tr.items[id] = item\r\n\tr.Unlock()\r\n\t\r\n\t\r\n\ttime.AfterFunc(deleteAfter, func() { r.Delete(id) })\r\n\treturn item, true\r\n}","code-length":322,"reference":"\/\/ Entomb sets the tomb bit on a relayItem and schedules a garbage collection. It\n\/\/ returns the entombed item, along with a bool indicating whether we completed\n\/\/ a relayed call.","result":"Entomb the relay items.","score":[0.0003,0.0514]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRelayer(ch *Channel, conn *Connection) *Relayer {\r\n\tr := &Relayer{\r\n\t\trelayHost:    ch.RelayHost(),\r\n\t\tmaxTimeout:   ch.relayMaxTimeout,\r\n\t\tlocalHandler: ch.relayLocal,\r\n\t\toutbound:     newRelayItems(conn.log.WithFields(LogField{\"relayItems\", \"outbound\"})),\r\n\t\tinbound:      newRelayItems(conn.log.WithFields(LogField{\"relayItems\", \"inbound\"})),\r\n\t\tpeers:        ch.RootPeers(),\r\n\t\tconn:         conn,\r\n\t\trelayConn: &relay.Conn{\r\n\t\t\tRemoteAddr:        conn.conn.RemoteAddr().String(),\r\n\t\t\tRemoteProcessName: conn.RemotePeerInfo().ProcessName,\r\n\t\t\tIsOutbound:        conn.connDirection == outbound,\r\n\t\t},\r\n\t\tlogger: conn.log,\r\n\t}\r\n\tr.timeouts = newRelayTimerPool(r.timeoutRelayItem, ch.relayTimerVerify)\r\n\treturn r\r\n}","code-length":278,"reference":"\/\/ NewRelayer constructs a Relayer.","result":"Create a new Relayer instance.","score":[0.2403,0.1]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Relayer) Relay(f *Frame) error {\r\n\tif f.messageType() != messageTypeCallReq {\r\n\t\terr := r.handleNonCallReq(f)\r\n\t\tif err == errUnknownID {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tif err := r.conn.outbound.forwardPeerFrame(f); err == nil {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn err\r\n\t}\r\n\treturn r.handleCallReq(newLazyCallReq(f))\r\n}","code-length":144,"reference":"\/\/ Relay is called for each frame that is read on the connection.","result":"Avoid the need for the function to be executed.","score":[0.0929,0.0794]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Relayer) Receive(f *Frame, fType frameType) (sent bool, failureReason string) {\r\n\tid := f.Header.ID\r\n\t\r\n\t\r\n\titems := r.receiverItems(fType)\r\n\titem, ok := items.Get(id)\r\n\tif !ok {\r\n\t\tr.logger.WithFields(\r\n\t\t\tLogField{\"id\", id},\r\n\t\t).Warn(\"Received a frame without a RelayItem.\")\r\n\t\treturn false, _relayErrorNotFound\r\n\t}\r\n\tfinished := finishesCall(f)\r\n\tif item.tomb {\r\n\t\t\r\n\t\t\r\n\t\treturn true, \"\"\r\n\t}\r\n\t\r\n\t\r\n\tif fType == responseFrame {\r\n\t\t\r\n\t\t\r\n\t\tif succeeded, failMsg := determinesCallSuccess(f); succeeded {\r\n\t\t\titem.call.Succeeded()\r\n\t\t} else if len(failMsg) > 0 {\r\n\t\t\titem.call.Failed(failMsg)\r\n\t\t}\r\n\t}\r\n\tselect {\r\n\tcase r.conn.sendCh <- f:\r\n\tdefault:\r\n\t\t\r\n\t\tr.logger.WithFields(\r\n\t\t\tLogField{\"id\", id},\r\n\t\t).Warn(\"Dropping call due to slow connection.\")\r\n\t\titems := r.receiverItems(fType)\r\n\t\terr := _relayErrorDestConnSlow\r\n\t\t\r\n\t\tif fType == responseFrame {\r\n\t\t\terr = _relayErrorSourceConnSlow\r\n\t\t}\r\n\t\tr.failRelayItem(items, id, err)\r\n\t\treturn false, err\r\n\t}\r\n\tif finished {\r\n\t\tr.finishRelayItem(items, id)\r\n\t}\r\n\treturn true, \"\"\r\n}","code-length":449,"reference":"\/\/ Receive receives frames intended for this connection.\n\/\/ It returns whether the frame was sent and a reason for failure if it failed.","result":"Avoid the need for the following code.","score":[0.0169,0.0448]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Relayer) handleNonCallReq(f *Frame) error {\r\n\tframeType := frameTypeFor(f)\r\n\tfinished := finishesCall(f)\r\n\t\r\n\t\r\n\titems := r.outbound\r\n\tif frameType == responseFrame {\r\n\t\titems = r.inbound\r\n\t}\r\n\titem, ok := items.Get(f.Header.ID)\r\n\tif !ok {\r\n\t\treturn errUnknownID\r\n\t}\r\n\tif item.tomb {\r\n\t\t\r\n\t\t\r\n\t\treturn nil\r\n\t}\r\n\toriginalID := f.Header.ID\r\n\tf.Header.ID = item.remapID\r\n\tsent, failure := item.destination.Receive(f, frameType)\r\n\tif !sent {\r\n\t\tr.failRelayItem(items, originalID, failure)\r\n\t\treturn nil\r\n\t}\r\n\tif finished {\r\n\t\tr.finishRelayItem(items, originalID)\r\n\t}\r\n\treturn nil\r\n}","code-length":259,"reference":"\/\/ Handle all frames except messageTypeCallReq.","result":"Call requests.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Relayer) addRelayItem(isOriginator bool, id, remapID uint32, destination *Relayer, ttl time.Duration, span Span, call RelayCall) relayItem {\r\n\titem := relayItem{\r\n\t\tcall:        call,\r\n\t\tremapID:     remapID,\r\n\t\tdestination: destination,\r\n\t\tspan:        span,\r\n\t}\r\n\titems := r.inbound\r\n\tif isOriginator {\r\n\t\titems = r.outbound\r\n\t}\r\n\titem.timeout = r.timeouts.Get()\r\n\titems.Add(id, item)\r\n\titem.timeout.Start(ttl, items, id, isOriginator)\r\n\treturn item\r\n}","code-length":186,"reference":"\/\/ addRelayItem adds a relay item to either outbound or inbound.","result":"Add a new item to the list of relay items.","score":[0.1652,0.4092]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Relayer) failRelayItem(items *relayItems, id uint32, failure string) {\r\n\titem, ok := items.Get(id)\r\n\tif !ok {\r\n\t\titems.logger.WithFields(LogField{\"id\", id}).Warn(\"Attempted to fail non-existent relay item.\")\r\n\t\treturn\r\n\t}\r\n\t\r\n\t\r\n\tif !item.timeout.Stop() {\r\n\t\treturn\r\n\t}\r\n\t\r\n\t\r\n\titem, ok = items.Entomb(id, _relayTombTTL)\r\n\tif !ok {\r\n\t\treturn\r\n\t}\r\n\tif item.call != nil {\r\n\t\t\r\n\t\tif failure != _relayErrorSourceConnSlow {\r\n\t\t\tr.conn.SendSystemError(id, item.span, errFrameNotSent)\r\n\t\t}\r\n\t\titem.call.Failed(failure)\r\n\t\titem.call.End()\r\n\t}\r\n\tr.decrementPending()\r\n}","code-length":258,"reference":"\/\/ failRelayItem tombs the relay item so that future frames for this call are not\n\/\/ forwarded. We keep the relay item tombed, rather than delete it to ensure that\n\/\/ future frames do not cause error logs.","result":"Fail the relay item.","score":[0.0001,0.0542]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WriteStruct(writer io.Writer, s thrift.TStruct) error {\r\n\twp := getProtocolWriter(writer)\r\n\terr := s.Write(wp.protocol)\r\n\tthriftProtocolPool.Put(wp)\r\n\treturn err\r\n}","code-length":69,"reference":"\/\/ WriteStruct writes the given Thrift struct to a writer. It pools TProtocols.","result":"Write struct to a writer.","score":[0.1519,0.3967]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReadStruct(reader io.Reader, s thrift.TStruct) error {\r\n\twp := getProtocolReader(reader)\r\n\terr := s.Read(wp.protocol)\r\n\tthriftProtocolPool.Put(wp)\r\n\treturn err\r\n}","code-length":69,"reference":"\/\/ ReadStruct reads the given Thrift struct. It pools TProtocols.","result":"Parse the thrift.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EnsureEmpty(r io.Reader, stage string) error {\r\n\tbuf := _bufPool.Get().(*[]byte)\r\n\tdefer _bufPool.Put(buf)\r\n\tn, err := r.Read(*buf)\r\n\tif n > 0 {\r\n\t\treturn fmt.Errorf(\"found unexpected bytes after %s, found (upto 128 bytes): %x\", stage, (*buf)[:n])\r\n\t}\r\n\tif err == io.EOF {\r\n\t\treturn nil\r\n\t}\r\n\treturn err\r\n}","code-length":138,"reference":"\/\/ EnsureEmpty ensures that the specified reader is empty. If the reader is\n\/\/ not empty, it returns an error with the specified stage in the message.","result":"Ensure empty files.","score":[0,0.0203]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewServer(optFns ...Option) Server {\r\n\topts := getOptions(optFns)\r\n\tif opts.external {\r\n\t\treturn newExternalServer(opts)\r\n\t}\r\n\tch, err := tchannel.NewChannel(opts.svcName, &tchannel.ChannelOptions{\r\n\t\tLogger: tchannel.NewLevelLogger(tchannel.NewLogger(os.Stderr), tchannel.LogLevelWarn),\r\n\t})\r\n\tif err != nil {\r\n\t\tpanic(\"failed to create channel: \" + err.Error())\r\n\t}\r\n\tif err := ch.ListenAndServe(\"127.0.0.1:0\"); err != nil {\r\n\t\tpanic(\"failed to listen on port 0: \" + err.Error())\r\n\t}\r\n\ts := &internalServer{\r\n\t\tch:   ch,\r\n\t\topts: opts,\r\n\t}\r\n\ttServer := thrift.NewServer(ch)\r\n\ttServer.Register(gen.NewTChanSecondServiceServer(handler{calls: &s.thriftCalls}))\r\n\tch.Register(raw.Wrap(rawHandler{calls: &s.rawCalls}), \"echo\")\r\n\tif len(opts.advertiseHosts) > 0 {\r\n\t\tif err := s.Advertise(opts.advertiseHosts); err != nil {\r\n\t\t\tpanic(\"failed to advertise: \" + err.Error())\r\n\t\t}\r\n\t}\r\n\treturn s\r\n}","code-length":357,"reference":"\/\/ NewServer returns a new Server that can recieve Thrift calls or raw calls.","result":"Create a server.","score":[0.0104,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *internalServer) Advertise(hyperbahnHosts []string) error {\r\n\tconfig := hyperbahn.Configuration{InitialNodes: hyperbahnHosts}\r\n\thc, err := hyperbahn.NewClient(s.ch, config, nil)\r\n\tif err != nil {\r\n\t\tpanic(\"failed to setup Hyperbahn client: \" + err.Error())\r\n\t}\r\n\treturn hc.Advertise()\r\n}","code-length":118,"reference":"\/\/ Advertise advertises with Hyperbahn.","result":"S Advertise method.","score":[0.2096,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Connection) handleCallReqContinue(frame *Frame) bool {\r\n\tif err := c.inbound.forwardPeerFrame(frame); err != nil {\r\n\t\t\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":68,"reference":"\/\/ handleCallReqContinue handles the continuation of a call request, forwarding\n\/\/ it to the request channel for that request, where it can be pulled during\n\/\/ defragmentation","result":"Handle call requests.","score":[0.0001,0.0407]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Connection) dispatchInbound(_ uint32, _ uint32, call *InboundCall, frame *Frame) {\r\n\tif call.log.Enabled(LogLevelDebug) {\r\n\t\tcall.log.Debugf(\"Received incoming call for %s from %s\", call.ServiceName(), c.remotePeerInfo)\r\n\t}\r\n\tif err := call.readMethod(); err != nil {\r\n\t\tcall.log.WithFields(\r\n\t\t\tLogField{\"remotePeer\", c.remotePeerInfo},\r\n\t\t\tErrField(err),\r\n\t\t).Error(\"Couldn't read method.\")\r\n\t\tc.opts.FramePool.Release(frame)\r\n\t\treturn\r\n\t}\r\n\tcall.commonStatsTags[\"endpoint\"] = call.methodString\r\n\tcall.statsReporter.IncCounter(\"inbound.calls.recvd\", call.commonStatsTags, 1)\r\n\tif span := call.response.span; span != nil {\r\n\t\tspan.SetOperationName(call.methodString)\r\n\t}\r\n\t\r\n\tgo func() {\r\n\t\tselect {\r\n\t\tcase <-call.mex.ctx.Done():\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tif call.mex.ctx.Err() != nil {\r\n\t\t\t\tcall.mex.inboundExpired()\r\n\t\t\t}\r\n\t\tcase <-call.mex.errCh.c:\r\n\t\t\tif c.log.Enabled(LogLevelDebug) {\r\n\t\t\t\tcall.log.Debugf(\"Wait for timeout\/cancellation interrupted by error: %v\", call.mex.errCh.err)\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tcall.response.cancel()\r\n\t\t\tcall.mex.inboundExpired()\r\n\t\t}\r\n\t}()\r\n\tc.handler.Handle(call.mex.ctx, call)\r\n}","code-length":459,"reference":"\/\/ dispatchInbound ispatches an inbound call to the appropriate handler","result":"Dispatch inbound calls.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (call *InboundCall) CallOptions() *CallOptions {\r\n\treturn &CallOptions{\r\n\t\tcallerName:      call.CallerName(),\r\n\t\tFormat:          call.Format(),\r\n\t\tShardKey:        call.ShardKey(),\r\n\t\tRoutingDelegate: call.RoutingDelegate(),\r\n\t\tRoutingKey:      call.RoutingKey(),\r\n\t}\r\n}","code-length":100,"reference":"\/\/ CallOptions returns a CallOptions struct suitable for forwarding a request.","result":"Generate the call options.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (call *InboundCall) Response() *InboundCallResponse {\r\n\tif call.err != nil {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tcall.response.err = call.err\r\n\t}\r\n\treturn call.response\r\n}","code-length":72,"reference":"\/\/ Response provides access to the InboundCallResponse object which can be used\n\/\/ to write back to the calling peer","result":"Return the response of the call.","score":[0.0223,0.0806]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (response *InboundCallResponse) SendSystemError(err error) error {\r\n\tif response.err != nil {\r\n\t\treturn response.err\r\n\t}\r\n\t\r\n\tresponse.state = reqResWriterComplete\r\n\tresponse.systemError = true\r\n\tresponse.doneSending()\r\n\tresponse.call.releasePreviousFragment()\r\n\tspan := CurrentSpan(response.mex.ctx)\r\n\treturn response.conn.SendSystemError(response.mex.msgID, *span, err)\r\n}","code-length":133,"reference":"\/\/ SendSystemError returns a system error response to the peer.  The call is considered\n\/\/ complete after this method is called, and no further data can be written.","result":"Send error to client.","score":[0.0009,0.0391]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (response *InboundCallResponse) SetApplicationError() error {\r\n\tif response.state > reqResWriterPreArg2 {\r\n\t\treturn response.failed(errReqResWriterStateMismatch{\r\n\t\t\tstate:         response.state,\r\n\t\t\texpectedState: reqResWriterPreArg2,\r\n\t\t})\r\n\t}\r\n\tresponse.applicationError = true\r\n\treturn nil\r\n}","code-length":105,"reference":"\/\/ SetApplicationError marks the response as being an application error.  This method can\n\/\/ only be called before any arguments have been sent to the calling peer.","result":"Set the application error flag in the call response.","score":[0.0217,0.177]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (response *InboundCallResponse) Arg2Writer() (ArgWriter, error) {\r\n\tif err := NewArgWriter(response.arg1Writer()).Write(nil); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn response.arg2Writer()\r\n}","code-length":78,"reference":"\/\/ Arg2Writer returns a WriteCloser that can be used to write the second argument.\n\/\/ The returned writer must be closed once the write is complete.","result":"Generate the arg.","score":[0.0002,0.0211]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (response *InboundCallResponse) doneSending() {\r\n\t\r\n\tnow := response.timeNow()\r\n\tif span := response.span; span != nil {\r\n\t\tif response.applicationError || response.systemError {\r\n\t\t\text.Error.Set(span, true)\r\n\t\t}\r\n\t\tspan.FinishWithOptions(opentracing.FinishOptions{FinishTime: now})\r\n\t}\r\n\tlatency := now.Sub(response.calledAt)\r\n\tresponse.statsReporter.RecordTimer(\"inbound.calls.latency\", response.commonStatsTags, latency)\r\n\tif response.systemError {\r\n\t\t\r\n\t\t\r\n\t} else if response.applicationError {\r\n\t\tresponse.statsReporter.IncCounter(\"inbound.calls.app-errors\", response.commonStatsTags, 1)\r\n\t} else {\r\n\t\tresponse.statsReporter.IncCounter(\"inbound.calls.success\", response.commonStatsTags, 1)\r\n\t}\r\n\t\r\n\tresponse.cancel()\r\n\t\r\n\tif response.err == nil {\r\n\t\tresponse.mex.shutdown()\r\n\t}\r\n}","code-length":281,"reference":"\/\/ doneSending shuts down the message exchange for this call.\n\/\/ For incoming calls, the last message is sending the call response.","result":"Close the response.","score":[0.0009,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newState(v *parser.Thrift, all map[string]parseState) *State {\r\n\ttypedefs := make(map[string]*parser.Type)\r\n\tfor k, v := range v.Typedefs {\r\n\t\ttypedefs[k] = v.Type\r\n\t}\r\n\t\r\n\ti64Type := &parser.Type{Name: \"i64\"}\r\n\tfor k := range v.Enums {\r\n\t\ttypedefs[k] = i64Type\r\n\t}\r\n\treturn &State{typedefs, nil, all}\r\n}","code-length":144,"reference":"\/\/ newState parses the type information for a parsed Thrift file and returns the state.","result":"Create a new state.","score":[0.0243,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *State) rootType(thriftType *parser.Type) *parser.Type {\r\n\tif state, newType, include := s.checkInclude(thriftType); include != nil {\r\n\t\treturn state.rootType(newType)\r\n\t}\r\n\tif v, ok := s.typedefs[thriftType.Name]; ok {\r\n\t\treturn s.rootType(v)\r\n\t}\r\n\treturn thriftType\r\n}","code-length":117,"reference":"\/\/ rootType recurses through typedefs and returns the underlying type.","result":"Generate the root type .","score":[0.0884,0.0526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *State) checkInclude(thriftType *parser.Type) (*State, *parser.Type, *Include) {\r\n\tparts := strings.SplitN(thriftType.Name, \".\", 2)\r\n\tif len(parts) < 2 {\r\n\t\treturn nil, nil, nil\r\n\t}\r\n\tnewType := *thriftType\r\n\tnewType.Name = parts[1]\r\n\tinclude := s.includes[parts[0]]\r\n\tstate := s.all[include.file]\r\n\treturn state.global, &newType, include\r\n}","code-length":148,"reference":"\/\/ checkInclude will check if the type is an included type, and if so, return the\n\/\/ state and type from the state for that file.","result":"Check the type of the type in the thrift file.","score":[0.0408,0.1966]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *State) isResultPointer(thriftType *parser.Type) bool {\r\n\t_, basicGoType := thriftToGo[s.rootType(thriftType).Name]\r\n\treturn !basicGoType\r\n}","code-length":63,"reference":"\/\/ isResultPointer returns whether the result for this method is a pointer.","result":"Check if result pointer is not basic go type .","score":[0.1057,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *State) goType(thriftType *parser.Type) string {\r\n\treturn s.goTypePrefix(\"\", thriftType)\r\n}","code-length":45,"reference":"\/\/ goType returns the Go type name for the given thrift type.","result":"Generate the package.","score":[0.0203,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *State) goTypePrefix(prefix string, thriftType *parser.Type) string {\r\n\tswitch thriftType.Name {\r\n\tcase \"binary\":\r\n\t\treturn \"[]byte\"\r\n\tcase \"list\":\r\n\t\treturn \"[]\" + s.goType(thriftType.ValueType)\r\n\tcase \"set\":\r\n\t\treturn \"map[\" + s.goType(thriftType.ValueType) + \"]bool\"\r\n\tcase \"map\":\r\n\t\treturn \"map[\" + s.goType(thriftType.KeyType) + \"]\" + s.goType(thriftType.ValueType)\r\n\t}\r\n\t\r\n\tif state, newType, include := s.checkInclude(thriftType); include != nil {\r\n\t\treturn state.goTypePrefix(include.Package()+\".\", newType)\r\n\t}\r\n\t\r\n\tif goType, ok := thriftToGo[thriftType.Name]; ok {\r\n\t\treturn goType\r\n\t}\r\n\tgoThriftName := goPublicFieldName(thriftType.Name)\r\n\tgoThriftName = prefix + goThriftName\r\n\t\r\n\trootType := s.rootType(thriftType)\r\n\tif _, ok := thriftToGo[rootType.Name]; ok {\r\n\t\treturn goThriftName\r\n\t}\r\n\tif rootType.Name == \"list\" ||\r\n\t\trootType.Name == \"set\" ||\r\n\t\trootType.Name == \"map\" {\r\n\t\treturn goThriftName\r\n\t}\r\n\t\r\n\t\r\n\tif rootType != thriftType {\r\n\t\treturn goThriftName\r\n\t}\r\n\t\r\n\treturn \"*\" + goThriftName\r\n}","code-length":413,"reference":"\/\/ goTypePrefix returns the Go type name for the given thrift type with the prefix.","result":"Generate the generated code.","score":[0.0204,0.036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewContext(timeout time.Duration) (context.Context, context.CancelFunc) {\r\n\treturn NewContextBuilder(timeout).Build()\r\n}","code-length":42,"reference":"\/\/ NewContext returns a new root context used to make TChannel requests.","result":"Create a new context.","score":[0.0611,0.1674]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newIncomingContext(call IncomingCall, timeout time.Duration) (context.Context, context.CancelFunc) {\r\n\treturn NewContextBuilder(timeout).\r\n\t\tsetIncomingCall(call).\r\n\t\tBuild()\r\n}","code-length":62,"reference":"\/\/ newIncomingContext creates a new context for an incoming call with the given span.","result":"Create new incoming call.","score":[0.0312,0.1154]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CurrentCall(ctx context.Context) IncomingCall {\r\n\tif params := getTChannelParams(ctx); params != nil {\r\n\t\treturn params.call\r\n\t}\r\n\treturn nil\r\n}","code-length":57,"reference":"\/\/ CurrentCall returns the current incoming call, or nil if this is not an incoming call context.","result":"Get the current call from the context.","score":[0.0651,0.125]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(seed int64) *rand.Rand {\r\n\treturn rand.New(&lockedSource{src: rand.NewSource(seed)})\r\n}","code-length":47,"reference":"\/\/ New returns a rand.Rand that is threadsafe.","result":"Generate random numbers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *metaHandler) Health(ctx Context, req *meta.HealthRequest) (*meta.HealthStatus, error) {\r\n\tok, message := h.healthFn(ctx, metaReqToReq(req))\r\n\tif message == \"\" {\r\n\t\treturn &meta.HealthStatus{Ok: ok}, nil\r\n\t}\r\n\treturn &meta.HealthStatus{Ok: ok, Message: &message}, nil\r\n}","code-length":110,"reference":"\/\/ Health returns true as default Health endpoint.","result":"Generate the health message.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c headerCtx) Headers() map[string]string {\r\n\tif h := c.headers(); h != nil {\r\n\t\treturn h.reqHeaders\r\n\t}\r\n\treturn nil\r\n}","code-length":58,"reference":"\/\/ Headers gets application headers out of the context.","result":"Access the context.","score":[0.0781,0.2232]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c headerCtx) ResponseHeaders() map[string]string {\r\n\tif h := c.headers(); h != nil {\r\n\t\treturn h.respHeaders\r\n\t}\r\n\treturn nil\r\n}","code-length":59,"reference":"\/\/ ResponseHeaders returns the response headers.","result":"Generate the response headers.","score":[0.3991,0.5077]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c headerCtx) SetResponseHeaders(headers map[string]string) {\r\n\tif h := c.headers(); h != nil {\r\n\t\th.respHeaders = headers\r\n\t\treturn\r\n\t}\r\n\tpanic(\"SetResponseHeaders called on ContextWithHeaders not created via WrapWithHeaders\")\r\n}","code-length":82,"reference":"\/\/ SetResponseHeaders sets the response headers.","result":"Set response headers in the context.","score":[0.2296,0.25]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c headerCtx) Child() ContextWithHeaders {\r\n\tvar headersCopy headersContainer\r\n\tif h := c.headers(); h != nil {\r\n\t\theadersCopy = *h\r\n\t}\r\n\treturn Wrap(context.WithValue(c.Context, contextKeyHeaders, &headersCopy))\r\n}","code-length":81,"reference":"\/\/ Child creates a child context with a separate container for headers.","result":"Wrap the headerCtx in a new context.","score":[0.0791,0.0435]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Wrap(ctx context.Context) ContextWithHeaders {\r\n\thctx := headerCtx{Context: ctx}\r\n\tif h := hctx.headers(); h != nil {\r\n\t\treturn hctx\r\n\t}\r\n\t\r\n\treturn WrapWithHeaders(ctx, nil)\r\n}","code-length":76,"reference":"\/\/ Wrap wraps an existing context.Context into a ContextWithHeaders.\n\/\/ If the underlying context has headers, they are preserved.","result":"Wrap the context.","score":[0.0023,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WrapWithHeaders(ctx context.Context, headers map[string]string) ContextWithHeaders {\r\n\th := &headersContainer{\r\n\t\treqHeaders: headers,\r\n\t}\r\n\tnewCtx := context.WithValue(ctx, contextKeyHeaders, h)\r\n\treturn headerCtx{Context: newCtx}\r\n}","code-length":84,"reference":"\/\/ WrapWithHeaders returns a Context that can be used to make a call with request headers.\n\/\/ If the parent `ctx` is already an instance of ContextWithHeaders, its existing headers\n\/\/ will be ignored. In order to merge new headers with parent headers, use ContextBuilder.","result":"Wrap the headers in a function.","score":[0.0004,0.0487]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WithoutHeaders(ctx context.Context) context.Context {\r\n\treturn context.WithValue(context.WithValue(ctx, contextKeyTChannel, nil), contextKeyHeaders, nil)\r\n}","code-length":54,"reference":"\/\/ WithoutHeaders hides any TChannel headers from the given context.","result":"Remove headers from the tchannel.","score":[0.1821,0.3099]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *errNotifier) Notify(err error) error {\r\n\t\r\n\tif err == nil {\r\n\t\tpanic(\"cannot Notify with no error\")\r\n\t}\r\n\t\r\n\tif !e.notified.CAS(false, true) {\r\n\t\treturn fmt.Errorf(\"cannot broadcast error: %v, already have: %v\", err, e.err)\r\n\t}\r\n\te.err = err\r\n\tclose(e.c)\r\n\treturn nil\r\n}","code-length":128,"reference":"\/\/ Notify will store the error and notify all waiters on c that there's an error.","result":"Notify the notifier.","score":[0.0064,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mex *messageExchange) forwardPeerFrame(frame *Frame) error {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif err := mex.ctx.Err(); err != nil {\r\n\t\treturn GetContextError(err)\r\n\t}\r\n\tselect {\r\n\tcase mex.recvCh <- frame:\r\n\t\treturn nil\r\n\tcase <-mex.ctx.Done():\r\n\t\t\r\n\t\t\r\n\t\treturn GetContextError(mex.ctx.Err())\r\n\tcase <-mex.errCh.c:\r\n\t\t\r\n\t\t\r\n\t\tselect {\r\n\t\tcase mex.recvCh <- frame:\r\n\t\t\treturn nil\r\n\t\tdefault:\r\n\t\t}\r\n\t\treturn mex.errCh.err\r\n\t}\r\n}","code-length":208,"reference":"\/\/ forwardPeerFrame forwards a frame from a peer to the message exchange, where\n\/\/ it can be pulled by whatever application thread is handling the exchange","result":"Forward peer frames to the peer.","score":[0.0108,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mex *messageExchange) recvPeerFrame() (*Frame, error) {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif err := mex.ctx.Err(); err != nil {\r\n\t\treturn nil, GetContextError(err)\r\n\t}\r\n\tselect {\r\n\tcase frame := <-mex.recvCh:\r\n\t\tif err := mex.checkFrame(frame); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn frame, nil\r\n\tcase <-mex.ctx.Done():\r\n\t\treturn nil, GetContextError(mex.ctx.Err())\r\n\tcase <-mex.errCh.c:\r\n\t\t\r\n\t\t\r\n\t\tselect {\r\n\t\tcase frame := <-mex.recvCh:\r\n\t\t\tif err := mex.checkFrame(frame); err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\treturn frame, nil\r\n\t\tdefault:\r\n\t\t}\r\n\t\treturn nil, mex.errCh.err\r\n\t}\r\n}","code-length":279,"reference":"\/\/ recvPeerFrame waits for a new frame from the peer, or until the context\n\/\/ expires or is cancelled","result":"Receive peer frames.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mex *messageExchange) recvPeerFrameOfType(msgType messageType) (*Frame, error) {\r\n\tframe, err := mex.recvPeerFrame()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tswitch frame.Header.messageType {\r\n\tcase msgType:\r\n\t\treturn frame, nil\r\n\tcase messageTypeError:\r\n\t\t\r\n\t\tdefer mex.framePool.Release(frame)\r\n\t\terrMsg := errorMessage{\r\n\t\t\tid: frame.Header.ID,\r\n\t\t}\r\n\t\tvar rbuf typed.ReadBuffer\r\n\t\trbuf.Wrap(frame.SizedPayload())\r\n\t\tif err := errMsg.read(&rbuf); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn nil, errMsg\r\n\tdefault:\r\n\t\t\r\n\t\tmex.mexset.log.WithFields(\r\n\t\t\tLogField{\"header\", frame.Header},\r\n\t\t\tLogField{\"expectedType\", msgType},\r\n\t\t\tLogField{\"expectedID\", mex.msgID},\r\n\t\t).Warn(\"Received unexpected frame.\")\r\n\t\treturn nil, errUnexpectedFrameType\r\n\t}\r\n}","code-length":306,"reference":"\/\/ recvPeerFrameOfType waits for a new frame of a given type from the peer, failing\n\/\/ if the next frame received is not of that type.\n\/\/ If an error frame is returned, then the errorMessage is returned as the error.","result":"Check if the message is a message exchange.","score":[0.0038,0.0531]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mex *messageExchange) shutdown() {\r\n\t\r\n\t\r\n\tif !mex.shutdownAtomic.CAS(false, true) {\r\n\t\treturn\r\n\t}\r\n\tif mex.errChNotified.CAS(false, true) {\r\n\t\tmex.errCh.Notify(errMexShutdown)\r\n\t}\r\n\tmex.mexset.removeExchange(mex.msgID)\r\n}","code-length":115,"reference":"\/\/ shutdown shuts down the message exchange, removing it from the message\n\/\/ exchange set so  that it cannot receive more messages from the peer.  The\n\/\/ receive channel remains open, however, in case there are concurrent\n\/\/ goroutines sending to it.","result":"Signal the shutdown of the message exchange.","score":[0.0018,0.0519]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newMessageExchangeSet(log Logger, name string) *messageExchangeSet {\r\n\treturn &messageExchangeSet{\r\n\t\tname:             name,\r\n\t\tlog:              log.WithFields(LogField{\"exchange\", name}),\r\n\t\texchanges:        make(map[uint32]*messageExchange),\r\n\t\texpiredExchanges: make(map[uint32]struct{}),\r\n\t}\r\n}","code-length":107,"reference":"\/\/ newMessageExchangeSet creates a new messageExchangeSet with a given name.","result":"Create a new message exchange set.","score":[0.1402,0.1562]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mexset *messageExchangeSet) addExchange(mex *messageExchange) error {\r\n\tif mexset.shutdown {\r\n\t\treturn errMexSetShutdown\r\n\t}\r\n\tif _, ok := mexset.exchanges[mex.msgID]; ok {\r\n\t\treturn errDuplicateMex\r\n\t}\r\n\tmexset.exchanges[mex.msgID] = mex\r\n\treturn nil\r\n}","code-length":117,"reference":"\/\/ addExchange adds an exchange, it must be called with the mexset locked.","result":"Add exchanges to a message exchangeSet.","score":[0,0.0407]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mexset *messageExchangeSet) newExchange(ctx context.Context, framePool FramePool,\r\n\tmsgType messageType, msgID uint32, bufferSize int) (*messageExchange, error) {\r\n\tif mexset.log.Enabled(LogLevelDebug) {\r\n\t\tmexset.log.Debugf(\"Creating new %s message exchange for [%v:%d]\", mexset.name, msgType, msgID)\r\n\t}\r\n\tmex := &messageExchange{\r\n\t\tmsgType:   msgType,\r\n\t\tmsgID:     msgID,\r\n\t\tctx:       ctx,\r\n\t\trecvCh:    make(chan *Frame, bufferSize),\r\n\t\terrCh:     newErrNotifier(),\r\n\t\tmexset:    mexset,\r\n\t\tframePool: framePool,\r\n\t}\r\n\tmexset.Lock()\r\n\taddErr := mexset.addExchange(mex)\r\n\tmexset.Unlock()\r\n\tif addErr != nil {\r\n\t\tlogger := mexset.log.WithFields(\r\n\t\t\tLogField{\"msgID\", mex.msgID},\r\n\t\t\tLogField{\"msgType\", mex.msgType},\r\n\t\t\tLogField{\"exchange\", mexset.name},\r\n\t\t)\r\n\t\tif addErr == errMexSetShutdown {\r\n\t\t\tlogger.Warn(\"Attempted to create new mex after mexset shutdown.\")\r\n\t\t} else if addErr == errDuplicateMex {\r\n\t\t\tlogger.Warn(\"Duplicate msg ID for active and new mex.\")\r\n\t\t}\r\n\t\treturn nil, addErr\r\n\t}\r\n\tmexset.onAdded()\r\n\t\r\n\treturn mex, nil\r\n}","code-length":429,"reference":"\/\/ newExchange creates and adds a new message exchange to this set","result":"Create a new message exchange.","score":[0.122,0.3319]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mexset *messageExchangeSet) deleteExchange(msgID uint32) (found, timedOut bool) {\r\n\tif _, found := mexset.exchanges[msgID]; found {\r\n\t\tdelete(mexset.exchanges, msgID)\r\n\t\treturn true, false\r\n\t}\r\n\tif _, expired := mexset.expiredExchanges[msgID]; expired {\r\n\t\tdelete(mexset.expiredExchanges, msgID)\r\n\t\treturn false, true\r\n\t}\r\n\treturn false, false\r\n}","code-length":143,"reference":"\/\/ deleteExchange will delete msgID, and return whether it was found or whether it was\n\/\/ timed out. This method must be called with the lock.","result":"Delete the message exchange.","score":[0.0013,0.042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mexset *messageExchangeSet) removeExchange(msgID uint32) {\r\n\tif mexset.log.Enabled(LogLevelDebug) {\r\n\t\tmexset.log.Debugf(\"Removing %s message exchange %d\", mexset.name, msgID)\r\n\t}\r\n\tmexset.Lock()\r\n\tfound, expired := mexset.deleteExchange(msgID)\r\n\tmexset.Unlock()\r\n\tif !found && !expired {\r\n\t\tmexset.log.WithFields(\r\n\t\t\tLogField{\"msgID\", msgID},\r\n\t\t).Error(\"Tried to remove exchange multiple times\")\r\n\t\treturn\r\n\t}\r\n\t\r\n\t\r\n\tmexset.onRemoved()\r\n}","code-length":190,"reference":"\/\/ removeExchange removes a message exchange from the set, if it exists.","result":"Remove message exchange.","score":[0.0203,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mexset *messageExchangeSet) expireExchange(msgID uint32) {\r\n\tmexset.log.Debugf(\r\n\t\t\"Removing %s message exchange %d due to timeout, cancellation or blackhole\",\r\n\t\tmexset.name,\r\n\t\tmsgID,\r\n\t)\r\n\tmexset.Lock()\r\n\t\r\n\tfound, expired := mexset.deleteExchange(msgID)\r\n\tif found || expired {\r\n\t\t\r\n\t\tmexset.expiredExchanges[msgID] = struct{}{}\r\n\t}\r\n\tmexset.Unlock()\r\n\tif expired {\r\n\t\tmexset.log.WithFields(LogField{\"msgID\", msgID}).Info(\"Exchange expired already\")\r\n\t}\r\n\tmexset.onRemoved()\r\n}","code-length":205,"reference":"\/\/ expireExchange is similar to removeExchange, but it marks the exchange as\n\/\/ expired.","result":"Remove the message exchange.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mexset *messageExchangeSet) forwardPeerFrame(frame *Frame) error {\r\n\tif mexset.log.Enabled(LogLevelDebug) {\r\n\t\tmexset.log.Debugf(\"forwarding %s %s\", mexset.name, frame.Header)\r\n\t}\r\n\tmexset.RLock()\r\n\tmex := mexset.exchanges[frame.Header.ID]\r\n\tmexset.RUnlock()\r\n\tif mex == nil {\r\n\t\t\r\n\t\tmexset.log.WithFields(\r\n\t\t\tLogField{\"frameHeader\", frame.Header.String()},\r\n\t\t\tLogField{\"exchange\", mexset.name},\r\n\t\t).Info(\"Received frame for unknown message exchange.\")\r\n\t\treturn nil\r\n\t}\r\n\tif err := mex.forwardPeerFrame(frame); err != nil {\r\n\t\tmexset.log.WithFields(\r\n\t\t\tLogField{\"frameHeader\", frame.Header.String()},\r\n\t\t\tLogField{\"frameSize\", frame.Header.FrameSize()},\r\n\t\t\tLogField{\"exchange\", mexset.name},\r\n\t\t\tErrField(err),\r\n\t\t).Info(\"Failed to forward frame.\")\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":321,"reference":"\/\/ forwardPeerFrame forwards a frame from the peer to the appropriate message\n\/\/ exchange","result":"Forward frames to the message exchange.","score":[0.0796,0.2818]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mexset *messageExchangeSet) copyExchanges() (shutdown bool, exchanges map[uint32]*messageExchange) {\r\n\tif mexset.shutdown {\r\n\t\treturn true, nil\r\n\t}\r\n\texchangesCopy := make(map[uint32]*messageExchange, len(mexset.exchanges))\r\n\tfor k, mex := range mexset.exchanges {\r\n\t\texchangesCopy[k] = mex\r\n\t}\r\n\treturn false, exchangesCopy\r\n}","code-length":132,"reference":"\/\/ copyExchanges returns a copy of the exchanges if the exchange is active.\n\/\/ The caller must lock the mexset.","result":"Copy exchanges from the set.","score":[0.0142,0.0811]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mexset *messageExchangeSet) stopExchanges(err error) {\r\n\tif mexset.log.Enabled(LogLevelDebug) {\r\n\t\tmexset.log.Debugf(\"stopping %v exchanges due to error: %v\", mexset.count(), err)\r\n\t}\r\n\tmexset.Lock()\r\n\tshutdown, exchanges := mexset.copyExchanges()\r\n\tmexset.shutdown = true\r\n\tmexset.Unlock()\r\n\tif shutdown {\r\n\t\tmexset.log.Debugf(\"mexset has already been shutdown\")\r\n\t\treturn\r\n\t}\r\n\tfor _, mex := range exchanges {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif mex.errChNotified.CAS(false, true) {\r\n\t\t\tmex.errCh.Notify(err)\r\n\t\t}\r\n\t}\r\n}","code-length":236,"reference":"\/\/ stopExchanges stops all message exchanges to unblock all waiters on the mex.\n\/\/ This should only be called on connection failures.","result":"Stop exchanges in the message exchange set.","score":[0.0249,0.0976]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFrame(payloadCapacity int) *Frame {\r\n\tf := &Frame{}\r\n\tf.buffer = make([]byte, payloadCapacity+FrameHeaderSize)\r\n\tf.Payload = f.buffer[FrameHeaderSize:]\r\n\tf.headerBuffer = f.buffer[:FrameHeaderSize]\r\n\treturn f\r\n}","code-length":86,"reference":"\/\/ NewFrame allocates a new frame with the given payload capacity","result":"Create a new frame.","score":[0.0785,0.182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *Frame) ReadBody(header []byte, r io.Reader) error {\r\n\t\r\n\t\r\n\tcopy(f.buffer, header)\r\n\t\r\n\tif err := f.Header.read(typed.NewReadBuffer(header)); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tswitch payloadSize := f.Header.PayloadSize(); {\r\n\tcase payloadSize > MaxFramePayloadSize:\r\n\t\treturn fmt.Errorf(\"invalid frame size %v\", f.Header.size)\r\n\tcase payloadSize > 0:\r\n\t\t_, err := io.ReadFull(r, f.SizedPayload())\r\n\t\treturn err\r\n\tdefault:\r\n\t\t\r\n\t\treturn nil\r\n\t}\r\n}","code-length":188,"reference":"\/\/ ReadBody takes in a previously read frame header, and only reads in the body\n\/\/ based on the size specified in the header. This allows callers to defer\n\/\/ the frame allocation till the body needs to be read.","result":"Read the body of the frame.","score":[0.001,0.0546]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *Frame) WriteOut(w io.Writer) error {\r\n\tvar wbuf typed.WriteBuffer\r\n\twbuf.Wrap(f.headerBuffer)\r\n\tif err := f.Header.write(&wbuf); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfullFrame := f.buffer[:f.Header.FrameSize()]\r\n\tif _, err := w.Write(fullFrame); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":133,"reference":"\/\/ WriteOut writes the frame to the given io.Writer","result":"Write the frame to the given writer.","score":[0.5051,0.6802]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r RetryOn) CanRetry(err error) bool {\r\n\tif r == RetryNever {\r\n\t\treturn false\r\n\t}\r\n\tif r == RetryDefault {\r\n\t\tr = RetryConnectionError\r\n\t}\r\n\tcode := getErrCode(err)\r\n\tif code == ErrCodeBusy || code == ErrCodeDeclined {\r\n\t\treturn true\r\n\t}\r\n\t\r\n\tif code == ErrCodeBadRequest {\r\n\t\treturn false\r\n\t}\r\n\tswitch r {\r\n\tcase RetryConnectionError:\r\n\t\treturn code == ErrCodeNetwork\r\n\tcase RetryUnexpected:\r\n\t\treturn code == ErrCodeUnexpected\r\n\tcase RetryIdempotent:\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":188,"reference":"\/\/ CanRetry returns whether an error can be retried for the given retry option.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rs *RequestState) HasRetries(err error) bool {\r\n\tif rs == nil {\r\n\t\treturn false\r\n\t}\r\n\trOpts := rs.retryOpts\r\n\treturn rs.Attempt < rOpts.MaxAttempts && rOpts.RetryOn.CanRetry(err)\r\n}","code-length":80,"reference":"\/\/ HasRetries will return true if there are more retries left.","result":"Check if the request has retries.","score":[0.0839,0.0476]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rs *RequestState) SinceStart(now time.Time, fallback time.Duration) time.Duration {\r\n\tif rs == nil {\r\n\t\treturn fallback\r\n\t}\r\n\treturn now.Sub(rs.Start)\r\n}","code-length":66,"reference":"\/\/ SinceStart returns the time since the start of the request. If there is no request state,\n\/\/ then the fallback is returned.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rs *RequestState) AddSelectedPeer(hostPort string) {\r\n\tif rs == nil {\r\n\t\treturn\r\n\t}\r\n\thost := getHost(hostPort)\r\n\tif rs.SelectedPeers == nil {\r\n\t\trs.SelectedPeers = map[string]struct{}{\r\n\t\t\thostPort: {},\r\n\t\t\thost:     {},\r\n\t\t}\r\n\t} else {\r\n\t\trs.SelectedPeers[hostPort] = struct{}{}\r\n\t\trs.SelectedPeers[host] = struct{}{}\r\n\t}\r\n}","code-length":144,"reference":"\/\/ AddSelectedPeer adds a given peer to the set of selected peers.","result":"Add a new peer to the request state.","score":[0.1864,0.4172]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ch *Channel) RunWithRetry(runCtx context.Context, f RetriableFunc) error {\r\n\tvar err error\r\n\topts := getRetryOptions(runCtx)\r\n\trs := ch.getRequestState(opts)\r\n\tdefer requestStatePool.Put(rs)\r\n\tfor i := 0; i < opts.MaxAttempts; i++ {\r\n\t\trs.Attempt++\r\n\t\tif opts.TimeoutPerAttempt == 0 {\r\n\t\t\terr = f(runCtx, rs)\r\n\t\t} else {\r\n\t\t\tattemptCtx, cancel := context.WithTimeout(runCtx, opts.TimeoutPerAttempt)\r\n\t\t\terr = f(attemptCtx, rs)\r\n\t\t\tcancel()\r\n\t\t}\r\n\t\tif err == nil {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tif !opts.RetryOn.CanRetry(err) {\r\n\t\t\tif ch.log.Enabled(LogLevelInfo) {\r\n\t\t\t\tch.log.WithFields(ErrField(err)).Info(\"Failed after non-retriable error.\")\r\n\t\t\t}\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tch.log.WithFields(\r\n\t\t\tErrField(err),\r\n\t\t\tLogField{\"attempt\", rs.Attempt},\r\n\t\t\tLogField{\"maxAttempts\", opts.MaxAttempts},\r\n\t\t).Info(\"Retrying request after retryable error.\")\r\n\t}\r\n\t\r\n\treturn err\r\n}","code-length":358,"reference":"\/\/ RunWithRetry will take a function that makes the TChannel call, and will\n\/\/ rerun it as specifed in the RetryOptions in the Context.","result":"Run a request with retry.","score":[0.0054,0.0452]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t ChecksumType) ChecksumSize() int {\r\n\tswitch t {\r\n\tcase ChecksumTypeNone:\r\n\t\treturn 0\r\n\tcase ChecksumTypeCrc32, ChecksumTypeCrc32C:\r\n\t\treturn crc32.Size\r\n\tcase ChecksumTypeFarmhash:\r\n\t\treturn 4\r\n\tdefault:\r\n\t\treturn 0\r\n\t}\r\n}","code-length":100,"reference":"\/\/ ChecksumSize returns the size in bytes of the checksum calculation","result":"Calculate the size of the checksum.","score":[0.1562,0.4248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t ChecksumType) New() Checksum {\r\n\ts := t.pool().Get().(Checksum)\r\n\ts.Reset()\r\n\treturn s\r\n}","code-length":48,"reference":"\/\/ New creates a new Checksum of the given type","result":"Generate the code.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc parseTemplates(skipTChannel bool, templateFiles []string) ([]*Template, error) {\r\n\tvar templates []*Template\r\n\tif !skipTChannel {\r\n\t\ttemplates = append(templates, &Template{\r\n\t\t\tname:     \"tchan\",\r\n\t\t\ttemplate: template.Must(parseTemplate(tchannelTmpl)),\r\n\t\t})\r\n\t}\r\n\tfor _, f := range templateFiles {\r\n\t\tt, err := parseTemplateFile(f)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\ttemplates = append(templates, t)\r\n\t}\r\n\treturn templates, nil\r\n}","code-length":173,"reference":"\/\/ parseTemplates returns a list of Templates that must be rendered given the template files.","result":"Parse the templates.","score":[0.0075,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewStringSliceFlag(name string, usage string) *[]string {\r\n\tvar ss stringSliceFlag\r\n\tflag.Var(&ss, name, usage)\r\n\treturn (*[]string)(&ss)\r\n}","code-length":61,"reference":"\/\/ NewStringSliceFlag creates a new string slice flag. The default value is always nil.","result":"Generate the generated code.","score":[0,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Template) withStateFuncs(td TemplateData) *template.Template {\r\n\treturn t.template.Funcs(map[string]interface{}{\r\n\t\t\"goType\": td.global.goType,\r\n\t})\r\n}","code-length":67,"reference":"\/\/ withStateFuncs adds functions to the template that are dependent upon state.","result":"Create template with state funcs.","score":[0.0593,0.0442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ch *Channel) IntrospectOthers(opts *IntrospectionOptions) map[string][]ChannelInfo {\r\n\tif !opts.IncludeOtherChannels {\r\n\t\treturn nil\r\n\t}\r\n\tchannelMap.Lock()\r\n\tdefer channelMap.Unlock()\r\n\tstates := make(map[string][]ChannelInfo)\r\n\tfor svc, channels := range channelMap.existing {\r\n\t\tchannelInfos := make([]ChannelInfo, 0, len(channels))\r\n\t\tfor _, otherChan := range channels {\r\n\t\t\tif ch == otherChan {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tchannelInfos = append(channelInfos, otherChan.ReportInfo(opts))\r\n\t\t}\r\n\t\tstates[svc] = channelInfos\r\n\t}\r\n\treturn states\r\n}","code-length":201,"reference":"\/\/ IntrospectOthers returns the ChannelInfo for all other channels in this process.","result":"Introspect the channel .","score":[0.0432,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ch *Channel) ReportInfo(opts *IntrospectionOptions) ChannelInfo {\r\n\treturn ChannelInfo{\r\n\t\tID:           ch.chID,\r\n\t\tCreatedStack: ch.createdStack,\r\n\t\tLocalPeer:    ch.PeerInfo(),\r\n\t}\r\n}","code-length":78,"reference":"\/\/ ReportInfo returns ChannelInfo for a channel.","result":"Report channel info.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *RootPeerList) IntrospectState(opts *IntrospectionOptions) map[string]PeerRuntimeState {\r\n\treturn fromPeerList(l, opts)\r\n}","code-length":50,"reference":"\/\/ IntrospectState returns the runtime state of the","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (subChMap *subChannelMap) IntrospectState(opts *IntrospectionOptions) map[string]SubChannelRuntimeState {\r\n\tm := make(map[string]SubChannelRuntimeState)\r\n\tsubChMap.RLock()\r\n\tfor k, sc := range subChMap.subchannels {\r\n\t\tstate := SubChannelRuntimeState{\r\n\t\t\tService:  k,\r\n\t\t\tIsolated: sc.Isolated(),\r\n\t\t}\r\n\t\tif state.Isolated {\r\n\t\t\tstate.IsolatedPeers = sc.Peers().IntrospectList(opts)\r\n\t\t}\r\n\t\tif hmap, ok := sc.handler.(*handlerMap); ok {\r\n\t\t\tstate.Handler.Type = methodHandler\r\n\t\t\tmethods := make([]string, 0, len(hmap.handlers))\r\n\t\t\tfor k := range hmap.handlers {\r\n\t\t\t\tmethods = append(methods, k)\r\n\t\t\t}\r\n\t\t\tsort.Strings(methods)\r\n\t\t\tstate.Handler.Methods = methods\r\n\t\t} else {\r\n\t\t\tstate.Handler.Type = overrideHandler\r\n\t\t}\r\n\t\tm[k] = state\r\n\t}\r\n\tsubChMap.RUnlock()\r\n\treturn m\r\n}","code-length":311,"reference":"\/\/ IntrospectState returns the runtime state of the subchannels.","result":"Introspect the subchannel map .","score":[0.108,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Peer) IntrospectState(opts *IntrospectionOptions) PeerRuntimeState {\r\n\tp.RLock()\r\n\tdefer p.RUnlock()\r\n\treturn PeerRuntimeState{\r\n\t\tHostPort:            p.hostPort,\r\n\t\tInboundConnections:  getConnectionRuntimeState(p.inboundConnections, opts),\r\n\t\tOutboundConnections: getConnectionRuntimeState(p.outboundConnections, opts),\r\n\t\tChosenCount:         p.chosenCount.Load(),\r\n\t\tSCCount:             p.scCount,\r\n\t}\r\n}","code-length":142,"reference":"\/\/ IntrospectState returns the runtime state for this peer.","result":"Get the runtime state.","score":[0.1294,0.2206]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Connection) IntrospectState(opts *IntrospectionOptions) ConnectionRuntimeState {\r\n\tc.stateMut.RLock()\r\n\tdefer c.stateMut.RUnlock()\r\n\t\r\n\tstate := ConnectionRuntimeState{\r\n\t\tID:               c.connID,\r\n\t\tConnectionState:  c.state.String(),\r\n\t\tLocalHostPort:    c.conn.LocalAddr().String(),\r\n\t\tRemoteHostPort:   c.conn.RemoteAddr().String(),\r\n\t\tOutboundHostPort: c.outboundHP,\r\n\t\tRemotePeer:       c.remotePeerInfo,\r\n\t\tInboundExchange:  c.inbound.IntrospectState(opts),\r\n\t\tOutboundExchange: c.outbound.IntrospectState(opts),\r\n\t\tHealthChecks:     c.healthCheckHistory.asBools(),\r\n\t\tLastActivity:     c.lastActivity.Load(),\r\n\t}\r\n\tif c.relay != nil {\r\n\t\tstate.Relayer = c.relay.IntrospectState(opts)\r\n\t}\r\n\treturn state\r\n}","code-length":268,"reference":"\/\/ IntrospectState returns the runtime state for this connection.","result":"Get the connection state from the server .","score":[0.1458,0.1124]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Relayer) IntrospectState(opts *IntrospectionOptions) RelayerRuntimeState {\r\n\tcount := r.inbound.Count() + r.outbound.Count()\r\n\treturn RelayerRuntimeState{\r\n\t\tCount:         count,\r\n\t\tInboundItems:  r.inbound.IntrospectState(opts, \"inbound\"),\r\n\t\tOutboundItems: r.outbound.IntrospectState(opts, \"outbound\"),\r\n\t\tMaxTimeout:    r.maxTimeout,\r\n\t}\r\n}","code-length":136,"reference":"\/\/ IntrospectState returns the runtime state for this relayer.","result":"Get the state of all the inbound and outbound.","score":[0.1449,0.1111]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ri *relayItems) IntrospectState(opts *IntrospectionOptions, name string) RelayItemSetState {\r\n\tri.RLock()\r\n\tdefer ri.RUnlock()\r\n\tsetState := RelayItemSetState{\r\n\t\tName:  name,\r\n\t\tCount: ri.Count(),\r\n\t}\r\n\tif opts.IncludeExchanges {\r\n\t\tsetState.Items = make(map[string]RelayItemState, len(ri.items))\r\n\t\tfor k, v := range ri.items {\r\n\t\t\tif !opts.IncludeTombstones && v.tomb {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tstate := RelayItemState{\r\n\t\t\t\tID:                      k,\r\n\t\t\t\tRemapID:                 v.remapID,\r\n\t\t\t\tDestinationConnectionID: v.destination.conn.connID,\r\n\t\t\t\tTomb:                    v.tomb,\r\n\t\t\t}\r\n\t\t\tsetState.Items[strconv.Itoa(int(k))] = state\r\n\t\t}\r\n\t}\r\n\treturn setState\r\n}","code-length":275,"reference":"\/\/ IntrospectState returns the runtime state for this relayItems.","result":"Get the state of the relay items.","score":[0.1443,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mexset *messageExchangeSet) IntrospectState(opts *IntrospectionOptions) ExchangeSetRuntimeState {\r\n\tmexset.RLock()\r\n\tsetState := ExchangeSetRuntimeState{\r\n\t\tName:  mexset.name,\r\n\t\tCount: len(mexset.exchanges),\r\n\t}\r\n\tif opts.IncludeExchanges {\r\n\t\tsetState.Exchanges = make(map[string]ExchangeRuntimeState, len(mexset.exchanges))\r\n\t\tfor k, v := range mexset.exchanges {\r\n\t\t\tstate := ExchangeRuntimeState{\r\n\t\t\t\tID:          k,\r\n\t\t\t\tMessageType: v.msgType,\r\n\t\t\t}\r\n\t\t\tsetState.Exchanges[strconv.Itoa(int(k))] = state\r\n\t\t}\r\n\t}\r\n\tmexset.RUnlock()\r\n\treturn setState\r\n}","code-length":228,"reference":"\/\/ IntrospectState returns the runtime state for this messsage exchange set.","result":"Get the message exchange set.","score":[0.1133,0.2457]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewContext(timeout time.Duration) (Context, context.CancelFunc) {\r\n\tctx, cancel := tchannel.NewContext(timeout)\r\n\treturn tchannel.WrapWithHeaders(ctx, nil), cancel\r\n}","code-length":59,"reference":"\/\/ NewContext returns a Context that can be used to make JSON calls.","result":"Create a new context.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WriteResponse(response *tchannel.InboundCallResponse, resp *Res) error {\r\n\tif resp.SystemErr != nil {\r\n\t\treturn response.SendSystemError(resp.SystemErr)\r\n\t}\r\n\tif resp.IsErr {\r\n\t\tif err := response.SetApplicationError(); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tif err := tchannel.NewArgWriter(response.Arg2Writer()).Write(resp.Arg2); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn tchannel.NewArgWriter(response.Arg3Writer()).Write(resp.Arg3)\r\n}","code-length":169,"reference":"\/\/ WriteResponse writes the given Res to the InboundCallResponse.","result":"Write the response to the response channel.","score":[0.1899,0.4261]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Wrap(handler Handler) tchannel.Handler {\r\n\treturn tchannel.HandlerFunc(func(ctx context.Context, call *tchannel.InboundCall) {\r\n\t\targs, err := ReadArgs(call)\r\n\t\tif err != nil {\r\n\t\t\thandler.OnError(ctx, err)\r\n\t\t\treturn\r\n\t\t}\r\n\t\tresp, err := handler.Handle(ctx, args)\r\n\t\tresponse := call.Response()\r\n\t\tif err != nil {\r\n\t\t\tresp = &Res{\r\n\t\t\t\tSystemErr: err,\r\n\t\t\t}\r\n\t\t}\r\n\t\tif err := WriteResponse(response, resp); err != nil {\r\n\t\t\thandler.OnError(ctx, err)\r\n\t\t}\r\n\t})\r\n}","code-length":195,"reference":"\/\/ Wrap wraps a Handler as a tchannel.Handler that can be passed to tchannel.Register.","result":"Wrap a handler.","score":[0.0124,0.0775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *injectableSpan) initFromOpenTracing(span opentracing.Span) error {\r\n\treturn span.Tracer().Inject(span.Context(), zipkinSpanFormat, s)\r\n}","code-length":53,"reference":"\/\/ initFromOpenTracing initializes injectableSpan fields from an OpenTracing Span,\n\/\/ assuming the tracing implementation supports Zipkin-style span IDs.","result":"Initialize span from OpenTracing.","score":[0.0115,0.0904]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Connection) startOutboundSpan(ctx context.Context, serviceName, methodName string, call *OutboundCall, startTime time.Time) opentracing.Span {\r\n\tvar parent opentracing.SpanContext\r\n\tif s := opentracing.SpanFromContext(ctx); s != nil {\r\n\t\tparent = s.Context()\r\n\t}\r\n\tspan := c.Tracer().StartSpan(\r\n\t\tmethodName,\r\n\t\topentracing.ChildOf(parent),\r\n\t\topentracing.StartTime(startTime),\r\n\t)\r\n\tif isTracingDisabled(ctx) {\r\n\t\text.SamplingPriority.Set(span, 0)\r\n\t}\r\n\text.SpanKindRPCClient.Set(span)\r\n\text.PeerService.Set(span, serviceName)\r\n\tc.setPeerHostPort(span)\r\n\tspan.SetTag(\"as\", call.callReq.Headers[ArgScheme])\r\n\tvar injectable injectableSpan\r\n\tif err := injectable.initFromOpenTracing(span); err == nil {\r\n\t\tcall.callReq.Tracing = Span(injectable)\r\n\t} else {\r\n\t\tcall.callReq.Tracing.initRandom()\r\n\t}\r\n\treturn span\r\n}","code-length":296,"reference":"\/\/ startOutboundSpan creates a new tracing span to represent the outbound RPC call.\n\/\/ If the context already contains a span, it will be used as a parent, otherwise\n\/\/ a new root span is created.\n\/\/\n\/\/ If the tracer supports Zipkin-style trace IDs, then call.callReq.Tracing is\n\/\/ initialized with those IDs. Otherwise it is assigned random values.","result":"Create a new span.","score":[0.0,0.0478]}
{"code":"\/*is used to<extra_id_0>\r\nfunc intToIP4(ip uint32) net.IP {\r\n\treturn net.IP{\r\n\t\tbyte(ip >> 24 & 0xff),\r\n\t\tbyte(ip >> 16 & 0xff),\r\n\t\tbyte(ip >> 8 & 0xff),\r\n\t\tbyte(ip & 0xff),\r\n\t}\r\n}","code-length":88,"reference":"\/\/ intToIP4 converts an integer IP representation into a 4-byte net.IP struct","result":"Convert int to IP.","score":[0,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc servicePeerToHostPort(peer *hyperbahn.ServicePeer) string {\r\n\thost := intToIP4(uint32(*peer.IP.Ipv4)).String()\r\n\tport := strconv.Itoa(int(peer.Port))\r\n\treturn net.JoinHostPort(host, port)\r\n}","code-length":82,"reference":"\/\/ servicePeerToHostPort converts a Hyperbahn ServicePeer into a hostPort string.","result":"Generate the service peer to host.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewStatsdReporter(addr, prefix string) (tchannel.StatsReporter, error) {\r\n\tclient, err := statsd.NewBufferedClient(addr, prefix, time.Second, 0)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn NewStatsdReporterClient(client), nil\r\n}","code-length":90,"reference":"\/\/ NewStatsdReporter returns a StatsReporter that reports to statsd on the given addr.","result":"Create a new statsd reporter.","score":[0.0577,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ToS) UnmarshalText(data []byte) error {\r\n\tif v, ok := _tosNameToValue[string(data)]; ok {\r\n\t\t*r = v\r\n\t\treturn nil\r\n\t}\r\n\treturn fmt.Errorf(\"invalid ToS %q\", string(data))\r\n}","code-length":84,"reference":"\/\/ UnmarshalText implements TextUnMarshaler from encoding","result":"Unmarshal the ToS.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ph *peerHeap) Push(x interface{}) {\r\n\tn := len(ph.peerScores)\r\n\titem := x.(*peerScore)\r\n\titem.index = n\r\n\tph.peerScores = append(ph.peerScores, item)\r\n}","code-length":74,"reference":"\/\/ Push implements heap Push interface","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ph *peerHeap) Pop() interface{} {\r\n\told := *ph\r\n\tn := len(old.peerScores)\r\n\titem := old.peerScores[n-1]\r\n\titem.index = -1\r\n\tph.peerScores = old.peerScores[:n-1]\r\n\treturn item\r\n}","code-length":88,"reference":"\/\/ Pop implements heap Pop interface","result":"Pop the peerHeap.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ph *peerHeap) updatePeer(peerScore *peerScore) {\r\n\theap.Fix(ph, peerScore.index)\r\n}","code-length":43,"reference":"\/\/ updatePeer updates the score for the given peer.","result":"Update peer heap.","score":[0,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ph *peerHeap) removePeer(peerScore *peerScore) {\r\n\theap.Remove(ph, peerScore.index)\r\n}","code-length":43,"reference":"\/\/ removePeer remove peer at specific index.","result":"Remove peers from peerHeap.","score":[0,0.2799]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ph *peerHeap) pushPeer(peerScore *peerScore) {\r\n\tph.order++\r\n\tnewOrder := ph.order\r\n\t\r\n\trandRange := ph.Len()\/2 + 1\r\n\tpeerScore.order = newOrder + uint64(ph.rng.Intn(randRange))\r\n\theap.Push(ph, peerScore)\r\n}","code-length":99,"reference":"\/\/ pushPeer pushes the new peer into the heap.","result":"Push peers to the peerHeap.","score":[0.108,0.1744]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ph *peerHeap) addPeer(peerScore *peerScore) {\r\n\tph.pushPeer(peerScore)\r\n\t\r\n\tr := ph.rng.Intn(ph.Len())\r\n\tph.swapOrder(peerScore.index, r)\r\n}","code-length":75,"reference":"\/\/ AddPeer adds a peer to the peer heap.","result":"Add peers to the peerHeap.","score":[0.1527,0.367]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(ch *tchannel.Channel, serviceName string, opts *ClientOptions) TChanClient {\r\n\tclient := &client{\r\n\t\tch:          ch,\r\n\t\tsc:          ch.GetSubChannel(serviceName),\r\n\t\tserviceName: serviceName,\r\n\t}\r\n\tif opts != nil {\r\n\t\tclient.opts = *opts\r\n\t}\r\n\treturn client\r\n}","code-length":105,"reference":"\/\/ NewClient returns a Client that makes calls over the given tchannel to the given Hyperbahn service.","result":"Create a TChanClient.","score":[0.0038,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *RootPeerList) Add(hostPort string) *Peer {\r\n\tl.RLock()\r\n\tif p, ok := l.peersByHostPort[hostPort]; ok {\r\n\t\tl.RUnlock()\r\n\t\treturn p\r\n\t}\r\n\tl.RUnlock()\r\n\tl.Lock()\r\n\tdefer l.Unlock()\r\n\tif p, ok := l.peersByHostPort[hostPort]; ok {\r\n\t\treturn p\r\n\t}\r\n\tvar p *Peer\r\n\t\r\n\t\r\n\tp = newPeer(l.channel, hostPort, l.onPeerStatusChanged, l.onClosedConnRemoved)\r\n\tl.peersByHostPort[hostPort] = p\r\n\treturn p\r\n}","code-length":187,"reference":"\/\/ Add adds a peer to the root peer list if it does not exist, or return\n\/\/ an existing peer if it exists.","result":"Add a new peer to the peer list.","score":[0.046,0.1904]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *RootPeerList) Get(hostPort string) (*Peer, bool) {\r\n\tl.RLock()\r\n\tp, ok := l.peersByHostPort[hostPort]\r\n\tl.RUnlock()\r\n\treturn p, ok\r\n}","code-length":72,"reference":"\/\/ Get returns a peer for the given hostPort if it exists.","result":"Get the peer from the peer list.","score":[0.104,0.1304]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WithTimeout(timeout time.Duration) Option {\r\n\treturn func(opts *options) {\r\n\t\topts.timeout = timeout\r\n\t}\r\n}","code-length":46,"reference":"\/\/ WithTimeout sets the timeout to use for each call.","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Service) Methods() []*Method {\r\n\tif s.methods != nil {\r\n\t\treturn s.methods\r\n\t}\r\n\tfor _, m := range s.Service.Methods {\r\n\t\ts.methods = append(s.methods, &Method{m, s, s.state})\r\n\t}\r\n\tsort.Sort(byMethodName(s.methods))\r\n\treturn s.methods\r\n}","code-length":111,"reference":"\/\/ Methods returns the methods on this service, not including methods from inherited services.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Service) InheritedMethods() []string {\r\n\tif s.inheritedMethods != nil {\r\n\t\treturn s.inheritedMethods\r\n\t}\r\n\tfor svc := s.ExtendsService; svc != nil; svc = svc.ExtendsService {\r\n\t\tfor m := range svc.Service.Methods {\r\n\t\t\ts.inheritedMethods = append(s.inheritedMethods, m)\r\n\t\t}\r\n\t}\r\n\tsort.Strings(s.inheritedMethods)\r\n\treturn s.inheritedMethods\r\n}","code-length":138,"reference":"\/\/ InheritedMethods returns names for inherited methods on this service.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Method) Arguments() []*Field {\r\n\tvar args []*Field\r\n\tfor _, f := range m.Method.Arguments {\r\n\t\targs = append(args, &Field{f, m.state})\r\n\t}\r\n\treturn args\r\n}","code-length":75,"reference":"\/\/ Arguments returns the argument declarations for this method.","result":"Get the arguments of the method.","score":[0.1392,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Method) ArgList() string {\r\n\targs := []string{\"ctx \" + contextType()}\r\n\tfor _, arg := range m.Arguments() {\r\n\t\targs = append(args, arg.Declaration())\r\n\t}\r\n\treturn strings.Join(args, \", \")\r\n}","code-length":81,"reference":"\/\/ ArgList returns the argument list for the function.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Method) CallList(reqStruct string) string {\r\n\targs := []string{\"ctx\"}\r\n\tfor _, arg := range m.Arguments() {\r\n\t\targs = append(args, reqStruct+\".\"+arg.ArgStructName())\r\n\t}\r\n\treturn strings.Join(args, \", \")\r\n}","code-length":89,"reference":"\/\/ CallList creates the call to a function satisfying Interface from an Args struct.","result":"Generate the call list.","score":[0.0371,0.1442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Method) RetType() string {\r\n\tif !m.HasReturn() {\r\n\t\treturn \"error\"\r\n\t}\r\n\treturn fmt.Sprintf(\"(%v, %v)\", m.state.goType(m.Method.ReturnType), \"error\")\r\n}","code-length":78,"reference":"\/\/ RetType returns the go return type of the method.","result":"Generate the return type for the method.","score":[0.207,0.4598]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Method) WrapResult(respVar string) string {\r\n\tif !m.HasReturn() {\r\n\t\tpanic(\"cannot wrap a return when there is no return mode\")\r\n\t}\r\n\tif m.state.isResultPointer(m.ReturnType) {\r\n\t\treturn respVar\r\n\t}\r\n\treturn \"&\" + respVar\r\n}","code-length":96,"reference":"\/\/ WrapResult wraps the result variable before being used in the result struct.","result":"Wrap the return value in the result pointer.","score":[0.1645,0.3872]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Method) ReturnWith(respName string, errName string) string {\r\n\tif !m.HasReturn() {\r\n\t\treturn errName\r\n\t}\r\n\treturn fmt.Sprintf(\"%v, %v\", respName, errName)\r\n}","code-length":73,"reference":"\/\/ ReturnWith takes the result name and the error name, and generates the return expression.","result":"Generate code.","score":[0,0.0365]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Field) Declaration() string {\r\n\treturn fmt.Sprintf(\"%s %s\", a.Name(), a.ArgType())\r\n}","code-length":45,"reference":"\/\/ Declaration returns the declaration for this field.","result":"Generate the declaration.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc startIdleSweep(ch *Channel, opts *ChannelOptions) *idleSweep {\r\n\tis := &idleSweep{\r\n\t\tch:                ch,\r\n\t\tmaxIdleTime:       opts.MaxIdleTime,\r\n\t\tidleCheckInterval: opts.IdleCheckInterval,\r\n\t}\r\n\tis.start()\r\n\treturn is\r\n}","code-length":96,"reference":"\/\/ startIdleSweep starts a poller that checks for idle connections at given\n\/\/ intervals.","result":"Start the idle sweep.","score":[0.0262,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (is *idleSweep) start() {\r\n\tif is.started || is.idleCheckInterval <= 0 {\r\n\t\treturn\r\n\t}\r\n\tis.ch.log.WithFields(\r\n\t\tLogField{\"idleCheckInterval\", is.idleCheckInterval},\r\n\t\tLogField{\"maxIdleTime\", is.maxIdleTime},\r\n\t).Info(\"Starting idle connections poller.\")\r\n\tis.started = true\r\n\tis.stopCh = make(chan struct{})\r\n\tgo is.pollerLoop()\r\n}","code-length":138,"reference":"\/\/ Start runs the goroutine responsible for checking idle connections.","result":"Start the sweep.","score":[0.0471,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (is *idleSweep) Stop() {\r\n\tif !is.started {\r\n\t\treturn\r\n\t}\r\n\tis.started = false\r\n\tis.ch.log.Info(\"Stopping idle connections poller.\")\r\n\tclose(is.stopCh)\r\n}","code-length":76,"reference":"\/\/ Stop kills the poller checking for idle connections.","result":"Stop the sweep.","score":[0.0657,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ResolveWithGoPath(filename string) (string, error) {\r\n\tfor _, file := range goPathCandidates(filename) {\r\n\t\tif _, err := os.Stat(file); !os.IsNotExist(err) {\r\n\t\t\treturn file, nil\r\n\t\t}\r\n\t}\r\n\treturn \"\", fmt.Errorf(\"file not found on GOPATH: %q\", filename)\r\n}","code-length":106,"reference":"\/\/ ResolveWithGoPath will resolve the filename relative to GOPATH and returns\n\/\/ the first file that exists, or an error otherwise.","result":"Resolve file paths in Go.","score":[0.0098,0.0515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc setExtends(state map[string]parseState) error {\r\n\tfor _, v := range state {\r\n\t\tfor _, s := range v.services {\r\n\t\t\tif s.Extends == \"\" {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tvar searchServices []*Service\r\n\t\t\tvar searchFor string\r\n\t\t\tparts := strings.SplitN(s.Extends, \".\", 2)\r\n\t\t\t\r\n\t\t\tif len(parts) < 2 {\r\n\t\t\t\tsearchServices = v.services\r\n\t\t\t\tsearchFor = s.Extends\r\n\t\t\t} else {\r\n\t\t\t\tinclude := v.global.includes[parts[0]]\r\n\t\t\t\ts.ExtendsPrefix = include.pkg + \".\"\r\n\t\t\t\tsearchServices = state[include.file].services\r\n\t\t\t\tsearchFor = parts[1]\r\n\t\t\t}\r\n\t\t\tfoundService := sort.Search(len(searchServices), func(i int) bool {\r\n\t\t\t\treturn searchServices[i].Name >= searchFor\r\n\t\t\t})\r\n\t\t\tif foundService == len(searchServices) {\r\n\t\t\t\treturn fmt.Errorf(\"failed to find base service %q for %q\", s.Extends, s.Name)\r\n\t\t\t}\r\n\t\t\ts.ExtendsService = searchServices[foundService]\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":329,"reference":"\/\/ setExtends will set the ExtendsService for all services.\n\/\/ It is done after all files are parsed, as services may extend those\n\/\/ found in an included file.","result":"Set the extends service for all the files in the file.","score":[0.0355,0.1654]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (hmap *handlerMap) register(h Handler, method string) {\r\n\thmap.Lock()\r\n\tdefer hmap.Unlock()\r\n\tif hmap.handlers == nil {\r\n\t\thmap.handlers = make(map[string]Handler)\r\n\t}\r\n\thmap.handlers[method] = h\r\n}","code-length":90,"reference":"\/\/ Registers a handler","result":"Register handlers.","score":[0,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(hosts []string, optFns ...Option) Client {\r\n\topts := getOptions(optFns)\r\n\tif opts.external {\r\n\t\treturn newExternalClient(hosts, opts)\r\n\t}\r\n\tif opts.numClients > 1 {\r\n\t\treturn newInternalMultiClient(hosts, opts)\r\n\t}\r\n\treturn newClient(hosts, opts)\r\n}","code-length":100,"reference":"\/\/ NewClient returns a new Client that can make calls to a benchmark server.","result":"Create a new client.","score":[0.0371,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ListenIP() (net.IP, error) {\r\n\tinterfaces, err := net.Interfaces()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn listenIP(interfaces)\r\n}","code-length":64,"reference":"\/\/ ListenIP returns the IP to bind to in Listen. It tries to find an IP that can be used\n\/\/ by other machines to reach this machine.","result":"Create a new interface.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *listener) Close() error {\r\n\tif err := s.Listener.Close(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\ts.cond.L.Lock()\r\n\tfor s.refs > 0 {\r\n\t\ts.cond.Wait()\r\n\t}\r\n\ts.cond.L.Unlock()\r\n\treturn nil\r\n}","code-length":99,"reference":"\/\/ Close closes the listener.\n\/\/ Any blocked Accept operations will be unblocked and return errors.","result":"Close the listener.","score":[0.0084,0.1738]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReadArgsV2(r tchannel.ArgReadable) ([]byte, []byte, error) {\r\n\tvar arg2, arg3 []byte\r\n\tif err := tchannel.NewArgReader(r.Arg2Reader()).Read(&arg2); err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\tif err := tchannel.NewArgReader(r.Arg3Reader()).Read(&arg3); err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\treturn arg2, arg3, nil\r\n}","code-length":145,"reference":"\/\/ ReadArgsV2 reads arg2 and arg3 from a reader.","result":"Read args from the channel.","score":[0.108,0.1163]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WriteArgs(call *tchannel.OutboundCall, arg2, arg3 []byte) ([]byte, []byte, *tchannel.OutboundCallResponse, error) {\r\n\tif err := tchannel.NewArgWriter(call.Arg2Writer()).Write(arg2); err != nil {\r\n\t\treturn nil, nil, nil, err\r\n\t}\r\n\tif err := tchannel.NewArgWriter(call.Arg3Writer()).Write(arg3); err != nil {\r\n\t\treturn nil, nil, nil, err\r\n\t}\r\n\tresp := call.Response()\r\n\tvar respArg2 []byte\r\n\tif err := tchannel.NewArgReader(resp.Arg2Reader()).Read(&respArg2); err != nil {\r\n\t\treturn nil, nil, nil, err\r\n\t}\r\n\tvar respArg3 []byte\r\n\tif err := tchannel.NewArgReader(resp.Arg3Reader()).Read(&respArg3); err != nil {\r\n\t\treturn nil, nil, nil, err\r\n\t}\r\n\treturn respArg2, respArg3, resp, nil\r\n}","code-length":276,"reference":"\/\/ WriteArgs writes the given arguments to the call, and returns the response args.","result":"Write the args to the channel.","score":[0.0796,0.1515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Call(ctx context.Context, ch *tchannel.Channel, hostPort string, serviceName, method string,\r\n\targ2, arg3 []byte) ([]byte, []byte, *tchannel.OutboundCallResponse, error) {\r\n\tcall, err := ch.BeginCall(ctx, hostPort, serviceName, method, nil)\r\n\tif err != nil {\r\n\t\treturn nil, nil, nil, err\r\n\t}\r\n\treturn WriteArgs(call, arg2, arg3)\r\n}","code-length":125,"reference":"\/\/ Call makes a call to the given hostPort with the given arguments and returns the response args.","result":"Call the service method.","score":[0.0115,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CallSC(ctx context.Context, sc *tchannel.SubChannel, method string, arg2, arg3 []byte) (\r\n\t[]byte, []byte, *tchannel.OutboundCallResponse, error) {\r\n\tcall, err := sc.BeginCall(ctx, method, nil)\r\n\tif err != nil {\r\n\t\treturn nil, nil, nil, err\r\n\t}\r\n\treturn WriteArgs(call, arg2, arg3)\r\n}","code-length":118,"reference":"\/\/ CallSC makes a call using the given subcahnnel","result":"Call the CallSC method.","score":[0.1088,0.1765]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CallV2(ctx context.Context, sc *tchannel.SubChannel, cArgs CArgs) (*CRes, error) {\r\n\tcall, err := sc.BeginCall(ctx, cArgs.Method, cArgs.CallOptions)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\targ2, arg3, res, err := WriteArgs(call, cArgs.Arg2, cArgs.Arg3)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &CRes{\r\n\t\tArg2:     arg2,\r\n\t\tArg3:     arg3,\r\n\t\tAppError: res.ApplicationError(),\r\n\t}, nil\r\n}","code-length":185,"reference":"\/\/ CallV2 makes a call and does not attempt any retries.","result":"Methods.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRealRelay(services map[string][]string) (Relay, error) {\r\n\thosts := &fixedHosts{hosts: services}\r\n\tch, err := tchannel.NewChannel(\"relay\", &tchannel.ChannelOptions{\r\n\t\tRelayHost: relaytest.HostFunc(hosts.Get),\r\n\t\tLogger:    tchannel.NewLevelLogger(tchannel.NewLogger(os.Stderr), tchannel.LogLevelWarn),\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err := ch.ListenAndServe(\"127.0.0.1:0\"); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &realRelay{\r\n\t\tch:    ch,\r\n\t\thosts: hosts,\r\n\t}, nil\r\n}","code-length":205,"reference":"\/\/ NewRealRelay creates a TChannel relay.","result":"Create a new relay instance.","score":[0.1967,0.3178]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewServer(registrar tchannel.Registrar) *Server {\r\n\tmetaHandler := newMetaHandler()\r\n\tserver := &Server{\r\n\t\tch:          registrar,\r\n\t\tlog:         registrar.Logger(),\r\n\t\thandlers:    make(map[string]handler),\r\n\t\tmetaHandler: metaHandler,\r\n\t\tctxFn:       defaultContextFn,\r\n\t}\r\n\tserver.Register(newTChanMetaServer(metaHandler))\r\n\tif ch, ok := registrar.(*tchannel.Channel); ok {\r\n\t\t\r\n\t\tNewServer(ch.GetSubChannel(\"tchannel\"))\r\n\t}\r\n\treturn server\r\n}","code-length":171,"reference":"\/\/ NewServer returns a server that can serve thrift services over TChannel.","result":"Register the server.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Server) RegisterHealthHandler(f HealthFunc) {\r\n\twrapped := func(ctx Context, r HealthRequest) (bool, string) {\r\n\t\treturn f(ctx)\r\n\t}\r\n\ts.metaHandler.setHandler(wrapped)\r\n}","code-length":73,"reference":"\/\/ RegisterHealthHandler uses the user-specified function f for the Health endpoint.","result":"Register the handler.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Server) Handle(ctx context.Context, call *tchannel.InboundCall) {\r\n\top := call.MethodString()\r\n\tservice, method, ok := getServiceMethod(op)\r\n\tif !ok {\r\n\t\tlog.Fatalf(\"Handle got call for %s which does not match the expected call format\", op)\r\n\t}\r\n\ts.RLock()\r\n\thandler, ok := s.handlers[service]\r\n\ts.RUnlock()\r\n\tif !ok {\r\n\t\tlog.Fatalf(\"Handle got call for service %v which is not registered\", service)\r\n\t}\r\n\tif err := s.handle(ctx, handler, method, call); err != nil {\r\n\t\ts.onError(call, err)\r\n\t}\r\n}","code-length":197,"reference":"\/\/ Handle handles an incoming TChannel call and forwards it to the correct handler.","result":"Handle tchannel inbound calls.","score":[0.0262,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c SystemErrCode) MetricsKey() string {\r\n\tswitch c {\r\n\tcase ErrCodeInvalid:\r\n\t\t\r\n\t\treturn \"invalid\"\r\n\tcase ErrCodeTimeout:\r\n\t\treturn \"timeout\"\r\n\tcase ErrCodeCancelled:\r\n\t\treturn \"cancelled\"\r\n\tcase ErrCodeBusy:\r\n\t\treturn \"busy\"\r\n\tcase ErrCodeDeclined:\r\n\t\treturn \"declined\"\r\n\tcase ErrCodeUnexpected:\r\n\t\treturn \"unexpected-error\"\r\n\tcase ErrCodeBadRequest:\r\n\t\treturn \"bad-request\"\r\n\tcase ErrCodeNetwork:\r\n\t\treturn \"network-error\"\r\n\tcase ErrCodeProtocol:\r\n\t\treturn \"protocol-error\"\r\n\tdefault:\r\n\t\treturn c.String()\r\n\t}\r\n}","code-length":197,"reference":"\/\/ MetricsKey is a string representation of the error code that's suitable for\n\/\/ inclusion in metrics tags.","result":"Generate the metrics key for the error code.","score":[0.0669,0.1857]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSystemError(code SystemErrCode, msg string, args ...interface{}) error {\r\n\treturn SystemError{code: code, msg: fmt.Sprintf(msg, args...)}\r\n}","code-length":55,"reference":"\/\/ NewSystemError defines a new SystemError with a code and message","result":"Create a new SystemError.","score":[0.0785,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewWrappedSystemError(code SystemErrCode, wrapped error) error {\r\n\tif se, ok := wrapped.(SystemError); ok {\r\n\t\treturn se\r\n\t}\r\n\treturn SystemError{code: code, msg: fmt.Sprint(wrapped), wrapped: wrapped}\r\n}","code-length":78,"reference":"\/\/ NewWrappedSystemError defines a new SystemError wrapping an existing error","result":"Wrap a wrapped error .","score":[0.1051,0.1579]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (se SystemError) Error() string {\r\n\treturn fmt.Sprintf(\"tchannel error %v: %s\", se.Code(), se.msg)\r\n}","code-length":48,"reference":"\/\/ Error returns the code and message, conforming to the error interface","result":"Generate the code.","score":[0.0203,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetContextError(err error) error {\r\n\tif err == context.DeadlineExceeded {\r\n\t\treturn ErrTimeout\r\n\t}\r\n\tif err == context.Canceled {\r\n\t\treturn ErrRequestCancelled\r\n\t}\r\n\treturn err\r\n}","code-length":71,"reference":"\/\/ GetContextError converts the context error to a tchannel error.","result":"Get the error from the context.","score":[0.1179,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetSystemErrorCode(err error) SystemErrCode {\r\n\tif err == nil {\r\n\t\treturn ErrCodeInvalid\r\n\t}\r\n\tif se, ok := err.(SystemError); ok {\r\n\t\treturn se.Code()\r\n\t}\r\n\treturn ErrCodeUnexpected\r\n}","code-length":77,"reference":"\/\/ GetSystemErrorCode returns the code to report for the given error.  If the error is a\n\/\/ SystemError, we can get the code directly.  Otherwise treat it as an unexpected error","result":"Generate the generated code.","score":[0.0004,0.0177]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Connection) ping(ctx context.Context) error {\r\n\treq := &pingReq{id: c.NextMessageID()}\r\n\tmex, err := c.outbound.newExchange(ctx, c.opts.FramePool, req.messageType(), req.ID(), 1)\r\n\tif err != nil {\r\n\t\treturn c.connectionError(\"create ping exchange\", err)\r\n\t}\r\n\tdefer c.outbound.removeExchange(req.ID())\r\n\tif err := c.sendMessage(req); err != nil {\r\n\t\treturn c.connectionError(\"send ping\", err)\r\n\t}\r\n\treturn c.recvMessage(ctx, &pingRes{}, mex)\r\n}","code-length":179,"reference":"\/\/ ping sends a ping message and waits for a ping response.","result":"Test the compiler .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Connection) handlePingRes(frame *Frame) bool {\r\n\tif err := c.outbound.forwardPeerFrame(frame); err != nil {\r\n\t\tc.log.WithFields(LogField{\"response\", frame.Header}).Warn(\"Unexpected ping response.\")\r\n\t\treturn true\r\n\t}\r\n\t\r\n\treturn false\r\n}","code-length":95,"reference":"\/\/ handlePingRes calls registered ping handlers.","result":"Handle ping responses.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Connection) handlePingReq(frame *Frame) {\r\n\tif state := c.readState(); state != connectionActive {\r\n\t\tc.protocolError(frame.Header.ID, errConnNotActive{\"ping on incoming\", state})\r\n\t\treturn\r\n\t}\r\n\tpingRes := &pingRes{id: frame.Header.ID}\r\n\tif err := c.sendMessage(pingRes); err != nil {\r\n\t\tc.connectionError(\"send pong\", err)\r\n\t}\r\n}","code-length":132,"reference":"\/\/ handlePingReq responds to the pingReq message with a pingRes.","result":"Avoid code duplication.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Connection) SendSystemError(id uint32, span Span, err error) error {\r\n\tframe := c.opts.FramePool.Get()\r\n\tif err := frame.write(&errorMessage{\r\n\t\tid:      id,\r\n\t\terrCode: GetSystemErrorCode(err),\r\n\t\ttracing: span,\r\n\t\tmessage: GetSystemErrorMessage(err),\r\n\t}); err != nil {\r\n\t\t\r\n\t\tc.log.WithFields(\r\n\t\t\tLogField{\"remotePeer\", c.remotePeerInfo},\r\n\t\t\tLogField{\"id\", id},\r\n\t\t\tErrField(err),\r\n\t\t).Warn(\"Couldn't create outbound frame.\")\r\n\t\treturn fmt.Errorf(\"failed to create outbound error frame: %v\", err)\r\n\t}\r\n\t\r\n\t\r\n\treturn c.withStateRLock(func() error {\r\n\t\t\r\n\t\tif c.state == connectionClosed {\r\n\t\t\tc.log.WithFields(\r\n\t\t\t\tLogField{\"remotePeer\", c.remotePeerInfo},\r\n\t\t\t\tLogField{\"id\", id},\r\n\t\t\t).Info(\"Could not send error frame on closed connection.\")\r\n\t\t\treturn fmt.Errorf(\"failed to send error frame, connection state %v\", c.state)\r\n\t\t}\r\n\t\tselect {\r\n\t\tcase c.sendCh <- frame:\r\n\t\t\treturn nil\r\n\t\tdefault:\r\n\t\t}\r\n\t\tc.log.WithFields(\r\n\t\t\tLogField{\"remotePeer\", c.remotePeerInfo},\r\n\t\t\tLogField{\"id\", id},\r\n\t\t\tErrField(err),\r\n\t\t).Warn(\"Couldn't send outbound frame.\")\r\n\t\treturn fmt.Errorf(\"failed to send error frame, buffer full\")\r\n\t})\r\n}","code-length":439,"reference":"\/\/ SendSystemError sends an error frame for the given system error.","result":"Send error frames to remote peer.","score":[0.0839,0.2434]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Connection) connectionError(site string, err error) error {\r\n\tvar closeLogFields LogFields\r\n\tif err == io.EOF {\r\n\t\tcloseLogFields = LogFields{{\"reason\", \"network connection EOF\"}}\r\n\t} else {\r\n\t\tcloseLogFields = LogFields{\r\n\t\t\t{\"reason\", \"connection error\"},\r\n\t\t\tErrField(err),\r\n\t\t}\r\n\t}\r\n\tc.stopHealthCheck()\r\n\terr = c.logConnectionError(site, err)\r\n\tc.close(closeLogFields...)\r\n\t\r\n\tif c.stoppedExchanges.CAS(false, true) {\r\n\t\tc.outbound.stopExchanges(err)\r\n\t\tc.inbound.stopExchanges(err)\r\n\t}\r\n\t\r\n\tc.checkExchanges()\r\n\treturn err\r\n}","code-length":219,"reference":"\/\/ connectionError handles a connection level error","result":"Avoid the need for the following code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Connection) withStateLock(f func() error) error {\r\n\tc.stateMut.Lock()\r\n\terr := f()\r\n\tc.stateMut.Unlock()\r\n\treturn err\r\n}","code-length":61,"reference":"\/\/ withStateLock performs an action with the connection state mutex locked","result":"Lock the connection state.","score":[0.0785,0.2481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Connection) withStateRLock(f func() error) error {\r\n\tc.stateMut.RLock()\r\n\terr := f()\r\n\tc.stateMut.RUnlock()\r\n\treturn err\r\n}","code-length":64,"reference":"\/\/ withStateRLock performs an action with the connection state mutex rlocked.","result":"Avoid the following line.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Connection) readFrames(_ uint32) {\r\n\theaderBuf := make([]byte, FrameHeaderSize)\r\n\thandleErr := func(err error) {\r\n\t\tif !c.closeNetworkCalled.Load() {\r\n\t\t\tc.connectionError(\"read frames\", err)\r\n\t\t} else {\r\n\t\t\tc.log.Debugf(\"Ignoring error after connection was closed: %v\", err)\r\n\t\t}\r\n\t}\r\n\tfor {\r\n\t\t\r\n\t\t\r\n\t\tif _, err := io.ReadFull(c.conn, headerBuf); err != nil {\r\n\t\t\thandleErr(err)\r\n\t\t\treturn\r\n\t\t}\r\n\t\tframe := c.opts.FramePool.Get()\r\n\t\tif err := frame.ReadBody(headerBuf, c.conn); err != nil {\r\n\t\t\thandleErr(err)\r\n\t\t\tc.opts.FramePool.Release(frame)\r\n\t\t\treturn\r\n\t\t}\r\n\t\tc.updateLastActivity(frame)\r\n\t\tvar releaseFrame bool\r\n\t\tif c.relay == nil {\r\n\t\t\treleaseFrame = c.handleFrameNoRelay(frame)\r\n\t\t} else {\r\n\t\t\treleaseFrame = c.handleFrameRelay(frame)\r\n\t\t}\r\n\t\tif releaseFrame {\r\n\t\t\tc.opts.FramePool.Release(frame)\r\n\t\t}\r\n\t}\r\n}","code-length":353,"reference":"\/\/ readFrames is the loop that reads frames from the network connection and\n\/\/ dispatches to the appropriate handler. Run within its own goroutine to\n\/\/ prevent overlapping reads on the socket.  Most handlers simply send the\n\/\/ incoming frame to a channel; the init handlers are a notable exception,\n\/\/ since we cannot process new frames until the initialization is complete.","result":"Read frames from the network.","score":[0.0,0.0355]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Connection) writeFrames(_ uint32) {\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase f := <-c.sendCh:\r\n\t\t\tif c.log.Enabled(LogLevelDebug) {\r\n\t\t\t\tc.log.Debugf(\"Writing frame %s\", f.Header)\r\n\t\t\t}\r\n\t\t\tc.updateLastActivity(f)\r\n\t\t\terr := f.WriteOut(c.conn)\r\n\t\t\tc.opts.FramePool.Release(f)\r\n\t\t\tif err != nil {\r\n\t\t\t\tc.connectionError(\"write frames\", err)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\tcase <-c.stopCh:\r\n\t\t\t\r\n\t\t\tif len(c.sendCh) > 0 {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tc.closeNetwork()\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":228,"reference":"\/\/ writeFrames is the main loop that pulls frames from the send channel and\n\/\/ writes them to the connection.","result":"Write frames to the network.","score":[0.0187,0.1706]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Connection) hasPendingCalls() bool {\r\n\tif c.inbound.count() > 0 || c.outbound.count() > 0 {\r\n\t\treturn true\r\n\t}\r\n\tif !c.relay.canClose() {\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":87,"reference":"\/\/ hasPendingCalls returns whether there's any pending inbound or outbound calls on this connection.","result":"Check if the connection has pending calls.","score":[0.0594,0.0376]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Connection) checkExchanges() {\r\n\tc.callOnExchangeChange()\r\n\tmoveState := func(fromState, toState connectionState) bool {\r\n\t\terr := c.withStateLock(func() error {\r\n\t\t\tif c.state != fromState {\r\n\t\t\t\treturn errors.New(\"\")\r\n\t\t\t}\r\n\t\t\tc.state = toState\r\n\t\t\treturn nil\r\n\t\t})\r\n\t\treturn err == nil\r\n\t}\r\n\tcurState := c.readState()\r\n\torigState := curState\r\n\tif curState != connectionClosed && c.stoppedExchanges.Load() {\r\n\t\tif moveState(curState, connectionClosed) {\r\n\t\t\tcurState = connectionClosed\r\n\t\t}\r\n\t}\r\n\tif curState == connectionStartClose {\r\n\t\tif !c.relay.canClose() {\r\n\t\t\treturn\r\n\t\t}\r\n\t\tif c.inbound.count() == 0 && moveState(connectionStartClose, connectionInboundClosed) {\r\n\t\t\tcurState = connectionInboundClosed\r\n\t\t}\r\n\t}\r\n\tif curState == connectionInboundClosed {\r\n\t\t\r\n\t\t\r\n\t\tif !c.relay.canClose() {\r\n\t\t\tc.relay.logger.Error(\"Relay can't close even though state is InboundClosed.\")\r\n\t\t\treturn\r\n\t\t}\r\n\t\tif c.outbound.count() == 0 && moveState(connectionInboundClosed, connectionClosed) {\r\n\t\t\tcurState = connectionClosed\r\n\t\t}\r\n\t}\r\n\tif curState != origState {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif curState == connectionClosed {\r\n\t\t\tclose(c.stopCh)\r\n\t\t}\r\n\t\tc.log.WithFields(\r\n\t\t\tLogField{\"newState\", curState},\r\n\t\t).Debug(\"Connection state updated during shutdown.\")\r\n\t\tc.callOnCloseStateChange()\r\n\t}\r\n}","code-length":491,"reference":"\/\/ checkExchanges is called whenever an exchange is removed, and when Close is called.","result":"Check exchanges during shutdown.","score":[0,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Connection) closeNetwork() {\r\n\t\r\n\t\r\n\t\r\n\tc.log.Debugf(\"Closing underlying network connection\")\r\n\tc.stopHealthCheck()\r\n\tc.closeNetworkCalled.Store(true)\r\n\tif err := c.conn.Close(); err != nil {\r\n\t\tc.log.WithFields(\r\n\t\t\tLogField{\"remotePeer\", c.remotePeerInfo},\r\n\t\t\tErrField(err),\r\n\t\t).Warn(\"Couldn't close connection to peer.\")\r\n\t}\r\n}","code-length":137,"reference":"\/\/ closeNetwork closes the network connection and all network-related channels.\n\/\/ This should only be done in response to a fatal connection or protocol\n\/\/ error, or after all pending frames have been sent.","result":"Close the underlying network connection.","score":[0.0009,0.0822]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Connection) getLastActivityTime() time.Time {\r\n\treturn time.Unix(0, c.lastActivity.Load())\r\n}","code-length":43,"reference":"\/\/ getLastActivityTime returns the timestamp of the last frame read or written,\n\/\/ excluding pings. If no frames were transmitted yet, it will return the time\n\/\/ this connection was created.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Validate(svc *parser.Service) error {\r\n\tfor _, m := range svc.Methods {\r\n\t\tif err := validateMethod(svc, m); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":74,"reference":"\/\/ Validate validates that the given spec is supported by thrift-gen.","result":"Validate the service.","score":[0.0337,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) logFailedRegistrationRetry(errLogger tchannel.Logger, consecutiveFailures uint) {\r\n\tlogFn := errLogger.Info\r\n\tif consecutiveFailures > maxAdvertiseFailures {\r\n\t\tlogFn = errLogger.Warn\r\n\t}\r\n\tlogFn(\"Hyperbahn client registration failed, will retry.\")\r\n}","code-length":90,"reference":"\/\/ logFailedRegistrationRetry logs either a warning or info depending on the number of\n\/\/ consecutiveFailures. If consecutiveFailures > maxAdvertiseFailures, then we log a warning.","result":"Log failed registration retry.","score":[0,0.0227]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) initialAdvertise() error {\r\n\tvar err error\r\n\tfor attempt := uint(0); attempt < maxAdvertiseFailures; attempt++ {\r\n\t\terr = c.sendAdvertise()\r\n\t\tif err == nil || err == errEphemeralPeer {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tc.tchan.Logger().WithFields(tchannel.ErrField(err)).Info(\r\n\t\t\t\"Hyperbahn client initial registration failure, will retry\")\r\n\t\t\r\n\t\tsleepFor := fuzzInterval(advertiseRetryInterval * time.Duration(1<<attempt))\r\n\t\tc.sleep(sleepFor)\r\n\t}\r\n\treturn err\r\n}","code-length":175,"reference":"\/\/ initialAdvertise will do the initial Advertise call to Hyperbahn with additional\n\/\/ retries on top of the built-in TChannel retries. It will use exponential backoff\n\/\/ between each of the call attempts.","result":"Register the initial advertise.","score":[0.0003,0.0332]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f lazyCallReq) Service() []byte {\r\n\tl := f.Payload[_serviceLenIndex]\r\n\treturn f.Payload[_serviceNameIndex : _serviceNameIndex+l]\r\n}","code-length":56,"reference":"\/\/ Service returns the name of the destination service for this callReq.","result":"Get the service from the call request.","score":[0.104,0.1739]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f lazyCallReq) TTL() time.Duration {\r\n\tttl := binary.BigEndian.Uint32(f.Payload[_ttlIndex : _ttlIndex+_ttlLen])\r\n\treturn time.Duration(ttl) * time.Millisecond\r\n}","code-length":70,"reference":"\/\/ TTL returns the time to live for this callReq.","result":"Get the TTL of the call request.","score":[0.1251,0.1031]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f lazyCallReq) SetTTL(d time.Duration) {\r\n\tttl := uint32(d \/ time.Millisecond)\r\n\tbinary.BigEndian.PutUint32(f.Payload[_ttlIndex:_ttlIndex+_ttlLen], ttl)\r\n}","code-length":74,"reference":"\/\/ SetTTL overwrites the frame's TTL.","result":"Set the TTL of the call request.","score":[0.1615,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc finishesCall(f *Frame) bool {\r\n\tswitch f.messageType() {\r\n\tcase messageTypeError:\r\n\t\treturn true\r\n\tcase messageTypeCallRes, messageTypeCallResContinue:\r\n\t\tflags := f.Payload[_flagsIndex]\r\n\t\treturn flags&hasMoreFragmentsFlag == 0\r\n\tdefault:\r\n\t\treturn false\r\n\t}\r\n}","code-length":100,"reference":"\/\/ finishesCall checks whether this frame is the last one we should expect for\n\/\/ this RPC req-res.","result":"Check if the frame finishesCall function.","score":[0.0344,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ps *PlatformStrings) Flat() []string {\r\n\tunique := make(map[string]struct{})\r\n\tfor _, s := range ps.Generic {\r\n\t\tunique[s] = struct{}{}\r\n\t}\r\n\tfor _, ss := range ps.OS {\r\n\t\tfor _, s := range ss {\r\n\t\t\tunique[s] = struct{}{}\r\n\t\t}\r\n\t}\r\n\tfor _, ss := range ps.Arch {\r\n\t\tfor _, s := range ss {\r\n\t\t\tunique[s] = struct{}{}\r\n\t\t}\r\n\t}\r\n\tfor _, ss := range ps.Platform {\r\n\t\tfor _, s := range ss {\r\n\t\t\tunique[s] = struct{}{}\r\n\t\t}\r\n\t}\r\n\tflat := make([]string, 0, len(unique))\r\n\tfor s := range unique {\r\n\t\tflat = append(flat, s)\r\n\t}\r\n\tsort.Strings(flat)\r\n\treturn flat\r\n}","code-length":260,"reference":"\/\/ Flat returns all the strings in the set, sorted and de-duplicated.","result":"Generate the generated code.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ps *PlatformStrings) Map(f func(s string) (string, error)) (PlatformStrings, []error) {\r\n\tvar errors []error\r\n\tmapSlice := func(ss []string) ([]string, error) {\r\n\t\trs := make([]string, 0, len(ss))\r\n\t\tfor _, s := range ss {\r\n\t\t\tif r, err := f(s); err != nil {\r\n\t\t\t\terrors = append(errors, err)\r\n\t\t\t} else if r != \"\" {\r\n\t\t\t\trs = append(rs, r)\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn rs, nil\r\n\t}\r\n\tresult, _ := ps.MapSlice(mapSlice)\r\n\treturn result, errors\r\n}","code-length":191,"reference":"\/\/ Map applies a function that processes individual strings to the strings\n\/\/ in \"ps\" and returns a new PlatformStrings with the result. Empty strings\n\/\/ returned by the function are dropped.","result":"Generate code for the generated code.","score":[0.0025,0.017]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ps *PlatformStrings) MapSlice(f func([]string) ([]string, error)) (PlatformStrings, []error) {\r\n\tvar errors []error\r\n\tmapSlice := func(ss []string) []string {\r\n\t\trs, err := f(ss)\r\n\t\tif err != nil {\r\n\t\t\terrors = append(errors, err)\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\treturn rs\r\n\t}\r\n\tmapStringMap := func(m map[string][]string) map[string][]string {\r\n\t\tif m == nil {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\trm := make(map[string][]string)\r\n\t\tfor k, ss := range m {\r\n\t\t\tss = mapSlice(ss)\r\n\t\t\tif len(ss) > 0 {\r\n\t\t\t\trm[k] = ss\r\n\t\t\t}\r\n\t\t}\r\n\t\tif len(rm) == 0 {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\treturn rm\r\n\t}\r\n\tmapPlatformMap := func(m map[Platform][]string) map[Platform][]string {\r\n\t\tif m == nil {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\trm := make(map[Platform][]string)\r\n\t\tfor k, ss := range m {\r\n\t\t\tss = mapSlice(ss)\r\n\t\t\tif len(ss) > 0 {\r\n\t\t\t\trm[k] = ss\r\n\t\t\t}\r\n\t\t}\r\n\t\tif len(rm) == 0 {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\treturn rm\r\n\t}\r\n\tresult := PlatformStrings{\r\n\t\tGeneric:  mapSlice(ps.Generic),\r\n\t\tOS:       mapStringMap(ps.OS),\r\n\t\tArch:     mapStringMap(ps.Arch),\r\n\t\tPlatform: mapPlatformMap(ps.Platform),\r\n\t}\r\n\treturn result, errors\r\n}","code-length":489,"reference":"\/\/ MapSlice applies a function that processes slices of strings to the strings\n\/\/ in \"ps\" and returns a new PlatformStrings with the results.","result":"Map slices of strings to strings.","score":[0.0301,0.1676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetProtoConfig(c *config.Config) *ProtoConfig {\r\n\tpc := c.Exts[protoName]\r\n\tif pc == nil {\r\n\t\treturn nil\r\n\t}\r\n\treturn pc.(*ProtoConfig)\r\n}","code-length":68,"reference":"\/\/ GetProtoConfig returns the proto language configuration. If the proto\n\/\/ extension was not run, it will return nil.","result":"Generate the proto config file.","score":[0.0207,0.1065]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MapExprStrings(e bzl.Expr, f func(string) string) bzl.Expr {\r\n\tif e == nil {\r\n\t\treturn nil\r\n\t}\r\n\tswitch expr := e.(type) {\r\n\tcase *bzl.StringExpr:\r\n\t\ts := f(expr.Value)\r\n\t\tif s == \"\" {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tret := *expr\r\n\t\tret.Value = s\r\n\t\treturn &ret\r\n\tcase *bzl.ListExpr:\r\n\t\tvar list []bzl.Expr\r\n\t\tfor _, elem := range expr.List {\r\n\t\t\telem = MapExprStrings(elem, f)\r\n\t\t\tif elem != nil {\r\n\t\t\t\tlist = append(list, elem)\r\n\t\t\t}\r\n\t\t}\r\n\t\tif len(list) == 0 && len(expr.List) > 0 {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tret := *expr\r\n\t\tret.List = list\r\n\t\treturn &ret\r\n\tcase *bzl.DictExpr:\r\n\t\tvar cases []bzl.Expr\r\n\t\tisEmpty := true\r\n\t\tfor _, kv := range expr.List {\r\n\t\t\tkeyval, ok := kv.(*bzl.KeyValueExpr)\r\n\t\t\tif !ok {\r\n\t\t\t\tlog.Panicf(\"unexpected expression in generated imports dict: %#v\", kv)\r\n\t\t\t}\r\n\t\t\tvalue := MapExprStrings(keyval.Value, f)\r\n\t\t\tif value != nil {\r\n\t\t\t\tcases = append(cases, &bzl.KeyValueExpr{Key: keyval.Key, Value: value})\r\n\t\t\t\tif key, ok := keyval.Key.(*bzl.StringExpr); !ok || key.Value != \"\r\n\t\t\t\t\tisEmpty = false\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\tif isEmpty {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tret := *expr\r\n\t\tret.List = cases\r\n\t\treturn &ret\r\n\tcase *bzl.CallExpr:\r\n\t\tif x, ok := expr.X.(*bzl.Ident); !ok || x.Name != \"select\" || len(expr.List) != 1 {\r\n\t\t\tlog.Panicf(\"unexpected call expression in generated imports: %#v\", e)\r\n\t\t}\r\n\t\targ := MapExprStrings(expr.List[0], f)\r\n\t\tif arg == nil {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tcall := *expr\r\n\t\tcall.List[0] = arg\r\n\t\treturn &call\r\n\tcase *bzl.BinaryExpr:\r\n\t\tx := MapExprStrings(expr.X, f)\r\n\t\ty := MapExprStrings(expr.Y, f)\r\n\t\tif x == nil {\r\n\t\t\treturn y\r\n\t\t}\r\n\t\tif y == nil {\r\n\t\t\treturn x\r\n\t\t}\r\n\t\tbinop := *expr\r\n\t\tbinop.X = x\r\n\t\tbinop.Y = y\r\n\t\treturn &binop\r\n\tdefault:\r\n\t\treturn nil\r\n\t}\r\n}","code-length":791,"reference":"\/\/ MapExprStrings applies a function to string sub-expressions within e.\n\/\/ An expression containing the results with the same structure as e is\n\/\/ returned.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FlattenExpr(e bzl.Expr) bzl.Expr {\r\n\tps, err := extractPlatformStringsExprs(e)\r\n\tif err != nil {\r\n\t\treturn e\r\n\t}\r\n\tls := makeListSquasher()\r\n\taddElem := func(e bzl.Expr) bool {\r\n\t\ts, ok := e.(*bzl.StringExpr)\r\n\t\tif !ok {\r\n\t\t\treturn false\r\n\t\t}\r\n\t\tls.add(s)\r\n\t\treturn true\r\n\t}\r\n\taddList := func(e bzl.Expr) bool {\r\n\t\tl, ok := e.(*bzl.ListExpr)\r\n\t\tif !ok {\r\n\t\t\treturn false\r\n\t\t}\r\n\t\tfor _, elem := range l.List {\r\n\t\t\tif !addElem(elem) {\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn true\r\n\t}\r\n\taddDict := func(d *bzl.DictExpr) bool {\r\n\t\tfor _, kv := range d.List {\r\n\t\t\tif !addList(kv.(*bzl.KeyValueExpr).Value) {\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn true\r\n\t}\r\n\tif ps.generic != nil {\r\n\t\tif !addList(ps.generic) {\r\n\t\t\treturn e\r\n\t\t}\r\n\t}\r\n\tfor _, d := range []*bzl.DictExpr{ps.os, ps.arch, ps.platform} {\r\n\t\tif d == nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif !addDict(d) {\r\n\t\t\treturn e\r\n\t\t}\r\n\t}\r\n\treturn ls.list()\r\n}","code-length":449,"reference":"\/\/ FlattenExpr takes an expression that may have been generated from\n\/\/ PlatformStrings and returns its values in a flat, sorted, de-duplicated\n\/\/ list. Comments are accumulated and de-duplicated across duplicate\n\/\/ expressions. If the expression could not have been generted by\n\/\/ PlatformStrings, the expression will be returned unmodified.","result":"Flatten expression.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc makePlatformStringsExpr(ps platformStringsExprs) bzl.Expr {\r\n\tmakeSelect := func(dict *bzl.DictExpr) bzl.Expr {\r\n\t\treturn &bzl.CallExpr{\r\n\t\t\tX:    &bzl.Ident{Name: \"select\"},\r\n\t\t\tList: []bzl.Expr{dict},\r\n\t\t}\r\n\t}\r\n\tforceMultiline := func(e bzl.Expr) {\r\n\t\tswitch e := e.(type) {\r\n\t\tcase *bzl.ListExpr:\r\n\t\t\te.ForceMultiLine = true\r\n\t\tcase *bzl.CallExpr:\r\n\t\t\te.List[0].(*bzl.DictExpr).ForceMultiLine = true\r\n\t\t}\r\n\t}\r\n\tvar parts []bzl.Expr\r\n\tif ps.generic != nil {\r\n\t\tparts = append(parts, ps.generic)\r\n\t}\r\n\tif ps.os != nil {\r\n\t\tparts = append(parts, makeSelect(ps.os))\r\n\t}\r\n\tif ps.arch != nil {\r\n\t\tparts = append(parts, makeSelect(ps.arch))\r\n\t}\r\n\tif ps.platform != nil {\r\n\t\tparts = append(parts, makeSelect(ps.platform))\r\n\t}\r\n\tif len(parts) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\tif len(parts) == 1 {\r\n\t\treturn parts[0]\r\n\t}\r\n\texpr := parts[0]\r\n\tforceMultiline(expr)\r\n\tfor _, part := range parts[1:] {\r\n\t\tforceMultiline(part)\r\n\t\texpr = &bzl.BinaryExpr{\r\n\t\t\tOp: \"+\",\r\n\t\t\tX:  expr,\r\n\t\t\tY:  part,\r\n\t\t}\r\n\t}\r\n\treturn expr\r\n}","code-length":469,"reference":"\/\/ makePlatformStringsExpr constructs a single expression from the\n\/\/ sub-expressions in ps.","result":"Generate the platform strings expression.","score":[0.0593,0.0442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p Platform) String() string {\r\n\tswitch {\r\n\tcase p.OS != \"\" && p.Arch != \"\":\r\n\t\treturn p.OS + \"_\" + p.Arch\r\n\tcase p.OS != \"\":\r\n\t\treturn p.OS\r\n\tcase p.Arch != \"\":\r\n\t\treturn p.Arch\r\n\tdefault:\r\n\t\treturn \"\"\r\n\t}\r\n}","code-length":107,"reference":"\/\/ String returns OS, Arch, or \"OS_Arch\" if both are set. This must match\n\/\/ the names of config_setting rules in @io_bazel_rules_go\/\/go\/platform.","result":"Generate the string representation of the platform.","score":[0.0225,0.0732]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Find(dir string) (string, error) {\r\n\tdir, err := filepath.Abs(dir)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tfor {\r\n\t\t_, err = os.Stat(filepath.Join(dir, workspaceFile))\r\n\t\tif err == nil {\r\n\t\t\treturn dir, nil\r\n\t\t}\r\n\t\tif !os.IsNotExist(err) {\r\n\t\t\treturn \"\", err\r\n\t\t}\r\n\t\tif strings.HasSuffix(dir, string(os.PathSeparator)) {\r\n\t\t\treturn \"\", os.ErrNotExist\r\n\t\t}\r\n\t\tdir = filepath.Dir(dir)\r\n\t}\r\n}","code-length":181,"reference":"\/\/ Find searches from the given dir and up for the WORKSPACE file\n\/\/ returning the directory containing it, or an error if none found in the tree.","result":"Find the workspace file.","score":[0.0009,0.0586]}
{"code":"\/*is used to<extra_id_0>\r\nfunc runGazelle(mode mode, dirs []string) error {\r\n\tif mode == fastMode && len(dirs) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\targs := []string{os.Getenv(\"BAZEL_REAL\"), \"run\", *gazelleLabel, \"--\", \"-args\"}\r\n\targs = append(args, \"-index=false\")\r\n\tif mode == fastMode {\r\n\t\targs = append(args, \"-r=false\")\r\n\t\targs = append(args, dirs...)\r\n\t}\r\n\tcmd := exec.Command(args[0], args[1:]...)\r\n\tcmd.Stdout = os.Stdout\r\n\tcmd.Stderr = os.Stderr\r\n\tlog.Printf(\"running gazelle: %s\\n\", strings.Join(cmd.Args, \" \"))\r\n\treturn cmd.Run()\r\n}","code-length":216,"reference":"\/\/ runGazelle invokes gazelle with \"bazel run\". In fullMode, gazelle will\n\/\/ run in the entire repository. In fastMode, gazelle will only run\n\/\/ in the given directories.","result":"Run gazelle in the background.","score":[0.0038,0.1228]}
{"code":"\/*is used to<extra_id_0>\r\nfunc restoreBuildFilesInRepo() {\r\n\terr := filepath.Walk(\".\", func(path string, info os.FileInfo, err error) error {\r\n\t\tif err != nil {\r\n\t\t\tlog.Print(err)\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\trestoreBuildFilesInDir(path)\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\tlog.Print(err)\r\n\t}\r\n}","code-length":120,"reference":"\/\/ restoreBuildFilesInRepo copies BUILD.in and BUILD.bazel.in files and\n\/\/ copies them to BUILD and BUILD.bazel.","result":"Restore build files in a repo.","score":[0.0431,0.0709]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FixLoads(f *rule.File, knownLoads []rule.LoadInfo) {\r\n\tknownFiles := make(map[string]bool)\r\n\tknownKinds := make(map[string]string)\r\n\tfor _, l := range knownLoads {\r\n\t\tknownFiles[l.Name] = true\r\n\t\tfor _, k := range l.Symbols {\r\n\t\t\tknownKinds[k] = l.Name\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\tf.Sync()\r\n\t\r\n\t\r\n\t\r\n\tvar loads []*rule.Load\r\n\totherLoadedKinds := make(map[string]bool)\r\n\tfor _, l := range f.Loads {\r\n\t\tif knownFiles[l.Name()] {\r\n\t\t\tloads = append(loads, l)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tfor _, sym := range l.Symbols() {\r\n\t\t\totherLoadedKinds[sym] = true\r\n\t\t}\r\n\t}\r\n\t\r\n\tusedKinds := make(map[string]map[string]bool)\r\n\tfor _, r := range f.Rules {\r\n\t\tkind := r.Kind()\r\n\t\tif file, ok := knownKinds[kind]; ok && !otherLoadedKinds[kind] {\r\n\t\t\tif usedKinds[file] == nil {\r\n\t\t\t\tusedKinds[file] = make(map[string]bool)\r\n\t\t\t}\r\n\t\t\tusedKinds[file][kind] = true\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\tfor _, known := range knownLoads {\r\n\t\tfile := known.Name\r\n\t\tfirst := true\r\n\t\tfor _, l := range loads {\r\n\t\t\tif l.Name() != file {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tif first {\r\n\t\t\t\tfixLoad(l, file, usedKinds[file], knownKinds)\r\n\t\t\t\tfirst = false\r\n\t\t\t} else {\r\n\t\t\t\tfixLoad(l, file, nil, knownKinds)\r\n\t\t\t}\r\n\t\t\tif l.IsEmpty() {\r\n\t\t\t\tl.Delete()\r\n\t\t\t}\r\n\t\t}\r\n\t\tif first {\r\n\t\t\tload := fixLoad(nil, file, usedKinds[file], knownKinds)\r\n\t\t\tif load != nil {\r\n\t\t\t\tindex := newLoadIndex(f, known.After)\r\n\t\t\t\tload.Insert(f, index)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":630,"reference":"\/\/ FixLoads removes loads of unused go rules and adds loads of newly used rules.\n\/\/ This should be called after FixFile and MergeFile, since symbols\n\/\/ may be introduced that aren't loaded.\n\/\/\n\/\/ This function calls File.Sync before processing loads.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc fixLoad(load *rule.Load, file string, kinds map[string]bool, knownKinds map[string]string) *rule.Load {\r\n\tif load == nil {\r\n\t\tif len(kinds) == 0 {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tload = rule.NewLoad(file)\r\n\t}\r\n\tfor k := range kinds {\r\n\t\tload.Add(k)\r\n\t}\r\n\tfor _, k := range load.Symbols() {\r\n\t\tif knownKinds[k] != \"\" && !kinds[k] {\r\n\t\t\tload.Remove(k)\r\n\t\t}\r\n\t}\r\n\treturn load\r\n}","code-length":177,"reference":"\/\/ fixLoad updates a load statement with the given symbols. If load is nil,\n\/\/ a new load may be created and returned. Symbols in kinds will be added\n\/\/ to the load if they're not already present. Known symbols not in kinds\n\/\/ will be removed if present. Other symbols will be preserved. If load is\n\/\/ empty, nil is returned.","result":"Fix load .","score":[0.0,0.0089]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newLoadIndex(f *rule.File, after []string) int {\r\n\tif len(after) == 0 {\r\n\t\treturn 0\r\n\t}\r\n\tindex := 0\r\n\tfor _, r := range f.Rules {\r\n\t\tfor _, a := range after {\r\n\t\t\tif r.Kind() == a && r.Index() >= index {\r\n\t\t\t\tindex = r.Index() + 1\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn index\r\n}","code-length":131,"reference":"\/\/ newLoadIndex returns the index in stmts where a new load statement should\n\/\/ be inserted. after is a list of function names that the load should not\n\/\/ be inserted before.","result":"Create a new load index.","score":[0.0022,0.0512]}
{"code":"\/*is used to<extra_id_0>\r\nfunc removeLegacyGoRepository(f *rule.File) {\r\n\tfor _, l := range f.Loads {\r\n\t\tif l.Name() == \"@io_bazel_rules_go\r\n\t\t\tl.Remove(\"go_repository\")\r\n\t\t\tif l.IsEmpty() {\r\n\t\t\t\tl.Delete()\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":102,"reference":"\/\/ removeLegacyGoRepository removes loads of go_repository from\n\/\/ @io_bazel_rules_go. FixLoads should be called after this; it will load from\n\/\/ @bazel_gazelle.","result":"Remove legacy go.","score":[0,0.026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (x Version) Compare(y Version) int {\r\n\tn := len(x)\r\n\tif len(y) < n {\r\n\t\tn = len(y)\r\n\t}\r\n\tfor i := 0; i < n; i++ {\r\n\t\tcmp := x[i] - y[i]\r\n\t\tif cmp != 0 {\r\n\t\t\treturn cmp\r\n\t\t}\r\n\t}\r\n\treturn len(x) - len(y)\r\n}","code-length":125,"reference":"\/\/ Compare returns an integer comparing two versions lexicographically.","result":"Compare two versions.","score":[0.0657,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseVersion(vs string) (Version, error) {\r\n\ti := strings.IndexByte(vs, '-')\r\n\tif i >= 0 {\r\n\t\tvs = vs[:i]\r\n\t}\r\n\tcstrs := strings.Split(vs, \".\")\r\n\tv := make(Version, len(cstrs))\r\n\tfor i, cstr := range cstrs {\r\n\t\tcn, err := strconv.Atoi(cstr)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"could not parse version string: %q is not an integer\", cstr)\r\n\t\t}\r\n\t\tif cn < 0 {\r\n\t\t\treturn nil, fmt.Errorf(\"could not parse version string: %q is negative\", cstr)\r\n\t\t}\r\n\t\tv[i] = cn\r\n\t}\r\n\treturn v, nil\r\n}","code-length":219,"reference":"\/\/ ParseVersion parses a version of the form \"12.34.56-abcd\". Non-negative\n\/\/ integer components are separated by dots. An arbitrary suffix may appear\n\/\/ after '-', which is ignored.","result":"Parse the version string.","score":[0.0009,0.0586]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EmptyFile(path, pkg string) *File {\r\n\treturn &File{\r\n\t\tFile: &bzl.File{Path: path, Type: bzl.TypeBuild},\r\n\t\tPath: path,\r\n\t\tPkg:  pkg,\r\n\t}\r\n}","code-length":76,"reference":"\/\/ EmptyFile creates a File wrapped around an empty syntax tree.","result":"Create empty files.","score":[0.0284,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadWorkspaceFile(path, pkg string) (*File, error) {\r\n\tdata, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn LoadWorkspaceData(path, pkg, data)\r\n}","code-length":77,"reference":"\/\/ LoadWorkspaceFile is similar to LoadFile but parses the file as a WORKSPACE\n\/\/ file.","result":"Load a file in the workspace.","score":[0.0567,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadMacroFile(path, pkg, defName string) (*File, error) {\r\n\tdata, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn LoadMacroData(path, pkg, defName, data)\r\n}","code-length":83,"reference":"\/\/ LoadMacroFile loads a bzl file from disk, parses it, then scans for the load\n\/\/ statements and the rules called from the given Starlark function. If there is\n\/\/ no matching function name, then a new function with that name will be created.\n\/\/ The function's syntax tree will be returned within File and can be modified by\n\/\/ Sync and Save calls.","result":"Load macros from a file.","score":[0.0,0.0258]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EmptyMacroFile(path, pkg, defName string) (*File, error) {\r\n\t_, err := os.Create(path)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn LoadMacroData(path, pkg, defName, nil)\r\n}","code-length":82,"reference":"\/\/ EmptyMacroFile creates a bzl file at the given path and within the file creates\n\/\/ a Starlark function with the provided name. The function can then be modified\n\/\/ by Sync and Save calls.","result":"Create empty macro files.","score":[0,0.0157]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadData(path, pkg string, data []byte) (*File, error) {\r\n\tast, err := bzl.ParseBuild(path, data)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn ScanAST(pkg, ast), nil\r\n}","code-length":81,"reference":"\/\/ LoadData parses a build file from a byte slice and scans it for rules and\n\/\/ load statements. The syntax tree within the returned File will be modified\n\/\/ by editing methods.","result":"Load data.","score":[0,0.0167]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadWorkspaceData(path, pkg string, data []byte) (*File, error) {\r\n\tast, err := bzl.ParseWorkspace(path, data)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn ScanAST(pkg, ast), nil\r\n}","code-length":82,"reference":"\/\/ LoadWorkspaceData is similar to LoadData but parses the data as a\n\/\/ WORKSPACE file.","result":"Load workspace data.","score":[0,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadMacroData(path, pkg, defName string, data []byte) (*File, error) {\r\n\tast, err := bzl.ParseBzl(path, data)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn ScanASTBody(pkg, defName, ast), nil\r\n}","code-length":91,"reference":"\/\/ LoadMacroData parses a bzl file from a byte slice and scans for the load\n\/\/ statements and the rules called from the given Starlark function. If there is\n\/\/ no matching function name, then a new function will be created, and added to the\n\/\/ File the next time Sync is called. The function's syntax tree will be returned\n\/\/ within File and can be modified by Sync and Save calls.","result":"Load macro data.","score":[0,0.0077]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ScanAST(pkg string, bzlFile *bzl.File) *File {\r\n\treturn ScanASTBody(pkg, \"\", bzlFile)\r\n}","code-length":46,"reference":"\/\/ ScanAST creates a File wrapped around the given syntax tree. This tree\n\/\/ will be modified by editing methods.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ScanASTBody(pkg, defName string, bzlFile *bzl.File) *File {\r\n\tf := &File{\r\n\t\tFile: bzlFile,\r\n\t\tPkg:  pkg,\r\n\t\tPath: bzlFile.Path,\r\n\t}\r\n\tvar defStmt *bzl.DefStmt\r\n\tf.Rules, f.Loads, defStmt = scanExprs(defName, bzlFile.Stmt)\r\n\tif defStmt != nil {\r\n\t\tf.Rules, _, _ = scanExprs(\"\", defStmt.Body)\r\n\t\tf.function = &function{\r\n\t\t\tstmt:     defStmt,\r\n\t\t\tinserted: true,\r\n\t\t}\r\n\t\tif len(defStmt.Body) == 1 {\r\n\t\t\tif v, ok := defStmt.Body[0].(*bzl.BranchStmt); ok && v.Token == \"pass\" {\r\n\t\t\t\tf.function.hasPass = true\r\n\t\t\t}\r\n\t\t}\r\n\t} else if defName != \"\" {\r\n\t\tf.function = &function{\r\n\t\t\tstmt:     &bzl.DefStmt{Name: defName},\r\n\t\t\tinserted: false,\r\n\t\t}\r\n\t}\r\n\tf.Directives = ParseDirectives(bzlFile)\r\n\treturn f\r\n}","code-length":329,"reference":"\/\/ ScanASTBody creates a File wrapped around the given syntax tree. It will also\n\/\/ scan the AST for a function matching the given defName, and if the function\n\/\/ does not exist it will create a new one and mark it to be added to the File\n\/\/ the next time Sync is called.","result":"Scan the AST body of a.","score":[0.0001,0.0299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MatchBuildFileName(dir string, names []string, files []os.FileInfo) string {\r\n\tfor _, name := range names {\r\n\t\tfor _, fi := range files {\r\n\t\t\tif fi.Name() == name && !fi.IsDir() {\r\n\t\t\t\treturn filepath.Join(dir, name)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn \"\"\r\n}","code-length":106,"reference":"\/\/ MatchBuildFileName looks for a file in files that has a name from names.\n\/\/ If there is at least one matching file, a path will be returned by joining\n\/\/ dir and the first matching name. If there are no matching files, the\n\/\/ empty string is returned.","result":"Match build file names.","score":[0.0,0.0337]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *File) SyncMacroFile(from *File) {\r\n\tfromFunc := *from.function.stmt\r\n\t_, _, toFunc := scanExprs(from.function.stmt.Name, f.File.Stmt)\r\n\tif toFunc != nil {\r\n\t\t*toFunc = fromFunc\r\n\t} else {\r\n\t\tf.File.Stmt = append(f.File.Stmt, &fromFunc)\r\n\t}\r\n}","code-length":117,"reference":"\/\/ SyncMacroFile syncs the file's syntax tree with another file's. This is\n\/\/ useful for keeping multiple macro definitions from the same .bzl file in sync.","result":"Sync macros.","score":[0,0.0212]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *File) MacroName() string {\r\n\tif f.function != nil && f.function.stmt != nil {\r\n\t\treturn f.function.stmt.Name\r\n\t}\r\n\treturn \"\"\r\n}","code-length":62,"reference":"\/\/ MacroName returns the name of the macro function that this file is editing,\n\/\/ or an empty string if a macro function is not being edited.","result":"Generate the name of the macro.","score":[0.0182,0.1594]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *File) Sync() {\r\n\tvar loadInserts, loadDeletes, loadStmts []*stmt\r\n\tvar r, w int\r\n\tfor r, w = 0, 0; r < len(f.Loads); r++ {\r\n\t\ts := f.Loads[r]\r\n\t\ts.sync()\r\n\t\tif s.deleted {\r\n\t\t\tloadDeletes = append(loadDeletes, &s.stmt)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif s.inserted {\r\n\t\t\tloadInserts = append(loadInserts, &s.stmt)\r\n\t\t\ts.inserted = false\r\n\t\t} else {\r\n\t\t\tloadStmts = append(loadStmts, &s.stmt)\r\n\t\t}\r\n\t\tf.Loads[w] = s\r\n\t\tw++\r\n\t}\r\n\tf.Loads = f.Loads[:w]\r\n\tvar ruleInserts, ruleDeletes, ruleStmts []*stmt\r\n\tfor r, w = 0, 0; r < len(f.Rules); r++ {\r\n\t\ts := f.Rules[r]\r\n\t\ts.sync()\r\n\t\tif s.deleted {\r\n\t\t\truleDeletes = append(ruleDeletes, &s.stmt)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif s.inserted {\r\n\t\t\truleInserts = append(ruleInserts, &s.stmt)\r\n\t\t\ts.inserted = false\r\n\t\t} else {\r\n\t\t\truleStmts = append(ruleStmts, &s.stmt)\r\n\t\t}\r\n\t\tf.Rules[w] = s\r\n\t\tw++\r\n\t}\r\n\tf.Rules = f.Rules[:w]\r\n\tif f.function == nil {\r\n\t\tdeletes := append(ruleDeletes, loadDeletes...)\r\n\t\tinserts := append(ruleInserts, loadInserts...)\r\n\t\tstmts := append(ruleStmts, loadStmts...)\r\n\t\tupdateStmt(&f.File.Stmt, inserts, deletes, stmts)\r\n\t} else {\r\n\t\tupdateStmt(&f.File.Stmt, loadInserts, loadDeletes, loadStmts)\r\n\t\tif f.function.hasPass && len(ruleInserts) > 0 {\r\n\t\t\tf.function.stmt.Body = []bzl.Expr{}\r\n\t\t\tf.function.hasPass = false\r\n\t\t}\r\n\t\tupdateStmt(&f.function.stmt.Body, ruleInserts, ruleDeletes, ruleStmts)\r\n\t\tif len(f.function.stmt.Body) == 0 {\r\n\t\t\tf.function.stmt.Body = append(f.function.stmt.Body, &bzl.BranchStmt{Token: \"pass\"})\r\n\t\t\tf.function.hasPass = true\r\n\t\t}\r\n\t\tif !f.function.inserted {\r\n\t\t\tf.File.Stmt = append(f.File.Stmt, f.function.stmt)\r\n\t\t\tf.function.inserted = true\r\n\t\t}\r\n\t}\r\n}","code-length":740,"reference":"\/\/ Sync writes all changes back to the wrapped syntax tree. This should be\n\/\/ called after editing operations, before reading the syntax tree again.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *File) Format() []byte {\r\n\tf.Sync()\r\n\treturn bzl.Format(f.File)\r\n}","code-length":43,"reference":"\/\/ Format formats the build file in a form that can be written to disk.\n\/\/ This method calls Sync internally.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *File) Save(path string) error {\r\n\tf.Sync()\r\n\tdata := bzl.Format(f.File)\r\n\treturn ioutil.WriteFile(path, data, 0666)\r\n}","code-length":62,"reference":"\/\/ Save writes the build file to disk. This method calls Sync internally.","result":"Save the file.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *File) HasDefaultVisibility() bool {\r\n\tfor _, r := range f.Rules {\r\n\t\tif r.Kind() == \"package\" && r.Attr(\"default_visibility\") != nil {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":82,"reference":"\/\/ HasDefaultVisibility returns whether the File contains a \"package\" rule with\n\/\/ a \"default_visibility\" attribute. Rules generated by Gazelle should not\n\/\/ have their own visibility attributes if this is the case.","result":"Generate code.","score":[0,0.0172]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLoad(name string) *Load {\r\n\treturn &Load{\r\n\t\tstmt: stmt{\r\n\t\t\texpr: &bzl.LoadStmt{\r\n\t\t\t\tModule:       &bzl.StringExpr{Value: name},\r\n\t\t\t\tForceCompact: true,\r\n\t\t\t},\r\n\t\t},\r\n\t\tname:    name,\r\n\t\tsymbols: make(map[string]identPair),\r\n\t}\r\n}","code-length":115,"reference":"\/\/ NewLoad creates a new, empty load statement for the given file name.","result":"Create a new Load object.","score":[0.0485,0.2095]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *Load) Symbols() []string {\r\n\tsyms := make([]string, 0, len(l.symbols))\r\n\tfor sym := range l.symbols {\r\n\t\tsyms = append(syms, sym)\r\n\t}\r\n\tsort.Strings(syms)\r\n\treturn syms\r\n}","code-length":87,"reference":"\/\/ Symbols returns a list of symbols this statement loads.","result":"Get the symbol list of the load.","score":[0.1488,0.2635]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *Load) Has(sym string) bool {\r\n\t_, ok := l.symbols[sym]\r\n\treturn ok\r\n}","code-length":43,"reference":"\/\/ Has returns true if sym is loaded by this statement.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *Load) Add(sym string) {\r\n\tif _, ok := l.symbols[sym]; !ok {\r\n\t\ti := &bzl.Ident{Name: sym}\r\n\t\tl.symbols[sym] = identPair{to: i, from: i}\r\n\t\tl.updated = true\r\n\t}\r\n}","code-length":92,"reference":"\/\/ Add inserts a new symbol into the load statement. This has no effect if\n\/\/ the symbol is already loaded. Symbols will be sorted, so the order\n\/\/ doesn't matter.","result":"Add symbols to the load.","score":[0.0016,0.0528]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *Load) Remove(sym string) {\r\n\tif _, ok := l.symbols[sym]; ok {\r\n\t\tdelete(l.symbols, sym)\r\n\t\tl.updated = true\r\n\t}\r\n}","code-length":65,"reference":"\/\/ Remove deletes a symbol from the load statement. This has no effect if\n\/\/ the symbol is not loaded.","result":"Remove symbol from Load.","score":[0.0092,0.0815]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *Load) Insert(f *File, index int) {\r\n\tl.index = index\r\n\tl.inserted = true\r\n\tf.Loads = append(f.Loads, l)\r\n}","code-length":60,"reference":"\/\/ Insert marks this statement for insertion at the given index. If multiple\n\/\/ statements are inserted at the same index, they will be inserted in the\n\/\/ order Insert is called.","result":"Insert the load in the file.","score":[0.0043,0.1074]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRule(kind, name string) *Rule {\r\n\tnameAttr := &bzl.AssignExpr{\r\n\t\tLHS: &bzl.Ident{Name: \"name\"},\r\n\t\tRHS: &bzl.StringExpr{Value: name},\r\n\t\tOp:  \"=\",\r\n\t}\r\n\tr := &Rule{\r\n\t\tstmt: stmt{\r\n\t\t\texpr: &bzl.CallExpr{\r\n\t\t\t\tX:    &bzl.Ident{Name: kind},\r\n\t\t\t\tList: []bzl.Expr{nameAttr},\r\n\t\t\t},\r\n\t\t},\r\n\t\tkind:    kind,\r\n\t\tattrs:   map[string]*bzl.AssignExpr{\"name\": nameAttr},\r\n\t\tprivate: map[string]interface{}{},\r\n\t}\r\n\treturn r\r\n}","code-length":212,"reference":"\/\/ NewRule creates a new, empty rule with the given kind and name.","result":"Create a new rule.","score":[0.0337,0.155]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Rule) SetKind(kind string) {\r\n\tr.kind = kind\r\n\tr.updated = true\r\n}","code-length":41,"reference":"\/\/ SetKind changes the kind of rule this is.","result":"Set the kind of the rule.","score":[0.2412,0.2937]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Rule) AttrKeys() []string {\r\n\tkeys := make([]string, 0, len(r.attrs))\r\n\tfor k := range r.attrs {\r\n\t\tkeys = append(keys, k)\r\n\t}\r\n\tsort.SliceStable(keys, func(i, j int) bool {\r\n\t\tif cmp := bt.NamePriority[keys[i]] - bt.NamePriority[keys[j]]; cmp != 0 {\r\n\t\t\treturn cmp < 0\r\n\t\t}\r\n\t\treturn keys[i] < keys[j]\r\n\t})\r\n\treturn keys\r\n}","code-length":155,"reference":"\/\/ AttrKeys returns a sorted list of attribute keys used in this rule.","result":"Sort the attributes .","score":[0,0.0826]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Rule) Attr(key string) bzl.Expr {\r\n\tattr, ok := r.attrs[key]\r\n\tif !ok {\r\n\t\treturn nil\r\n\t}\r\n\treturn attr.RHS\r\n}","code-length":66,"reference":"\/\/ Attr returns the value of the named attribute. nil is returned when the\n\/\/ attribute is not set.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Rule) AttrString(key string) string {\r\n\tattr, ok := r.attrs[key]\r\n\tif !ok {\r\n\t\treturn \"\"\r\n\t}\r\n\tstr, ok := attr.RHS.(*bzl.StringExpr)\r\n\tif !ok {\r\n\t\treturn \"\"\r\n\t}\r\n\treturn str.Value\r\n}","code-length":99,"reference":"\/\/ AttrString returns the value of the named attribute if it is a scalar string.\n\/\/ \"\" is returned if the attribute is not set or is not a string.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Rule) AttrStrings(key string) []string {\r\n\tattr, ok := r.attrs[key]\r\n\tif !ok {\r\n\t\treturn nil\r\n\t}\r\n\tlist, ok := attr.RHS.(*bzl.ListExpr)\r\n\tif !ok {\r\n\t\treturn nil\r\n\t}\r\n\tstrs := make([]string, 0, len(list.List))\r\n\tfor _, e := range list.List {\r\n\t\tif str, ok := e.(*bzl.StringExpr); ok {\r\n\t\t\tstrs = append(strs, str.Value)\r\n\t\t}\r\n\t}\r\n\treturn strs\r\n}","code-length":172,"reference":"\/\/ AttrStrings returns the string values of an attribute if it is a list.\n\/\/ nil is returned if the attribute is not set or is not a list. Non-string\n\/\/ values within the list won't be returned.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Rule) DelAttr(key string) {\r\n\tdelete(r.attrs, key)\r\n\tr.updated = true\r\n}","code-length":44,"reference":"\/\/ DelAttr removes the named attribute from the rule.","result":"Remove the comments.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Rule) SetAttr(key string, value interface{}) {\r\n\trhs := ExprFromValue(value)\r\n\tif attr, ok := r.attrs[key]; ok {\r\n\t\tattr.RHS = rhs\r\n\t} else {\r\n\t\tr.attrs[key] = &bzl.AssignExpr{\r\n\t\t\tLHS: &bzl.Ident{Name: key},\r\n\t\t\tRHS: rhs,\r\n\t\t\tOp:  \"=\",\r\n\t\t}\r\n\t}\r\n\tr.updated = true\r\n}","code-length":143,"reference":"\/\/ SetAttr adds or replaces the named attribute with an expression produced\n\/\/ by ExprFromValue.","result":"Set the value of a rule.","score":[0.0431,0.0355]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Rule) PrivateAttrKeys() []string {\r\n\tkeys := make([]string, 0, len(r.private))\r\n\tfor k := range r.private {\r\n\t\tkeys = append(keys, k)\r\n\t}\r\n\tsort.Strings(keys)\r\n\treturn keys\r\n}","code-length":84,"reference":"\/\/ PrivateAttrKeys returns a sorted list of private attribute names.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Rule) SetPrivateAttr(key string, value interface{}) {\r\n\tr.private[key] = value\r\n}","code-length":41,"reference":"\/\/ SetPrivateAttr associates a value with a key. Unlike SetAttr, this value\n\/\/ is not converted to a build syntax tree and will not be written to a build\n\/\/ file.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Rule) Insert(f *File) {\r\n\t\r\n\t\r\n\tvar stmt []bzl.Expr\r\n\tif f.function == nil {\r\n\t\tstmt = f.File.Stmt\r\n\t} else {\r\n\t\tstmt = f.function.stmt.Body\r\n\t}\r\n\tr.index = len(stmt)\r\n\tr.inserted = true\r\n\tf.Rules = append(f.Rules, r)\r\n}","code-length":120,"reference":"\/\/ Insert marks this statement for insertion at the end of the file. Multiple\n\/\/ statements will be inserted in the order Insert is called.","result":"Insert a new rule.","score":[0.0017,0.0218]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Rule) IsEmpty(info KindInfo) bool {\r\n\tif info.NonEmptyAttrs == nil {\r\n\t\treturn false\r\n\t}\r\n\tfor k := range info.NonEmptyAttrs {\r\n\t\tif _, ok := r.attrs[k]; ok {\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":96,"reference":"\/\/ IsEmpty returns true when the rule contains none of the attributes in attrs\n\/\/ for its kind. attrs should contain attributes that make the rule buildable\n\/\/ like srcs or deps and not descriptive attributes like name or visibility.","result":"Check if the rule.","score":[0.0,0.0275]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CheckInternalVisibility(rel, visibility string) string {\r\n\tif i := strings.LastIndex(rel, \"\/internal\/\"); i >= 0 {\r\n\t\tvisibility = fmt.Sprintf(\"\r\n\t} else if strings.HasPrefix(rel, \"internal\/\") {\r\n\t\tvisibility = \"\r\n\t}\r\n\treturn visibility\r\n}","code-length":90,"reference":"\/\/ CheckInternalVisibility overrides the given visibility if the package is\n\/\/ internal.","result":"Check internal visibility.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(repo, pkg, name string) Label {\r\n\treturn Label{Repo: repo, Pkg: pkg, Name: name}\r\n}","code-length":43,"reference":"\/\/ New constructs a new label from components.","result":"Create labels.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l Label) Rel(repo, pkg string) Label {\r\n\tif l.Relative || l.Repo != repo {\r\n\t\treturn l\r\n\t}\r\n\tif l.Pkg == pkg {\r\n\t\treturn Label{Name: l.Name, Relative: true}\r\n\t}\r\n\treturn Label{Pkg: l.Pkg, Name: l.Name}\r\n}","code-length":99,"reference":"\/\/ Rel attempts to compute a relative label from this label. If this label\n\/\/ is already relative or is in a different package, this label may be\n\/\/ returned unchanged.","result":"Resolve labels in the repo.","score":[0.0013,0.0352]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l Label) Equal(other Label) bool {\r\n\treturn l.Repo == other.Repo &&\r\n\t\tl.Pkg == other.Pkg &&\r\n\t\tl.Name == other.Name &&\r\n\t\tl.Relative == other.Relative\r\n}","code-length":71,"reference":"\/\/ Equal returns whether two labels are exactly the same. It does not return\n\/\/ true for different labels that refer to the same target.","result":"Compare labels.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l Label) Contains(other Label) bool {\r\n\tif l.Relative {\r\n\t\tlog.Panicf(\"l must not be relative: %s\", l)\r\n\t}\r\n\tif other.Relative {\r\n\t\tlog.Panicf(\"other must not be relative: %s\", other)\r\n\t}\r\n\tresult := l.Repo == other.Repo && pathtools.HasPrefix(other.Pkg, l.Pkg)\r\n\treturn result\r\n}","code-length":120,"reference":"\/\/ Contains returns whether other is contained by the package of l or a\n\/\/ sub-package. Neither label may be relative.","result":"Check if labels are contained in other labels.","score":[0.0325,0.1269]}
{"code":"\/*is used to<extra_id_0>\r\nfunc generateFromPath(w io.Writer, rootPath string) error {\r\n\treturn filepath.Walk(rootPath, func(path string, info os.FileInfo, err error) error {\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif !strings.HasSuffix(path, \".proto\") {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\trelPath, err := filepath.Rel(rootPath, path)\r\n\t\tif err != nil || strings.HasPrefix(relPath, \"..\") {\r\n\t\t\tlog.Panicf(\"file %q not in repository rootPath %q\", path, rootPath)\r\n\t\t}\r\n\t\trelPath = filepath.ToSlash(relPath)\r\n\t\tif strings.HasPrefix(relPath, \"google\/api\/experimental\/\") {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tpackagePath := \"google.golang.org\/genproto\/googleapis\/api\"\r\n\t\t\tprotoLabel, goLabel := protoLabels(\"google\/api\/x\", \"api\")\r\n\t\t\tfmt.Fprintf(w, \"%s,%s,%s,%s\\n\", relPath, protoLabel, packagePath, goLabel)\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tpackagePath, packageName, err := loadGoPackage(path)\r\n\t\tif err != nil {\r\n\t\t\tlog.Print(err)\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tprotoLabel, goLabel := protoLabels(relPath, packageName)\r\n\t\tfmt.Fprintf(w, \"%s,%s,%s,%s\\n\", relPath, protoLabel, packagePath, goLabel)\r\n\t\treturn nil\r\n\t})\r\n}","code-length":412,"reference":"\/\/\n\/\/ Process -go_googleapis case\n\/\/","result":"Generate from a directory.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc shouldCall(rel string, mode Mode, updateRels map[string]bool) bool {\r\n\treturn mode != UpdateDirsMode || updateRels[rel]\r\n}","code-length":49,"reference":"\/\/ shouldCall returns true if Walk should call the callback in the\n\/\/ directory rel.","result":"Call shouldCall .","score":[0.0075,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc shouldUpdate(rel string, mode Mode, updateParent bool, updateRels map[string]bool) bool {\r\n\treturn mode == VisitAllUpdateSubdirsMode && updateParent || updateRels[rel]\r\n}","code-length":59,"reference":"\/\/ shouldUpdate returns true if Walk should pass true to the callback's update\n\/\/ parameter in the directory rel. This indicates the build file should be\n\/\/ updated.","result":"Update the parent directory.","score":[0.0008,0.0391]}
{"code":"\/*is used to<extra_id_0>\r\nfunc shouldVisit(rel string, mode Mode, updateRels map[string]bool) bool {\r\n\tif mode != UpdateDirsMode {\r\n\t\treturn true\r\n\t}\r\n\t_, ok := updateRels[rel]\r\n\treturn ok\r\n}","code-length":71,"reference":"\/\/ shouldVisit returns true if Walk should visit the subdirectory rel.","result":"Check if the rel is a directory.","score":[0.1085,0.0943]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SquashRules(src, dst *Rule, filename string) error {\r\n\tif dst.ShouldKeep() {\r\n\t\treturn nil\r\n\t}\r\n\tfor key, srcAttr := range src.attrs {\r\n\t\tsrcValue := srcAttr.RHS\r\n\t\tif dstAttr, ok := dst.attrs[key]; !ok {\r\n\t\t\tdst.SetAttr(key, srcValue)\r\n\t\t} else if !ShouldKeep(dstAttr) {\r\n\t\t\tdstValue := dstAttr.RHS\r\n\t\t\tif squashedValue, err := squashExprs(srcValue, dstValue); err != nil {\r\n\t\t\t\tstart, end := dstValue.Span()\r\n\t\t\t\treturn fmt.Errorf(\"%s:%d.%d-%d.%d: could not squash expression\", filename, start.Line, start.LineRune, end.Line, end.LineRune)\r\n\t\t\t} else {\r\n\t\t\t\tdst.SetAttr(key, squashedValue)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tdst.expr.Comment().Before = append(dst.expr.Comment().Before, src.expr.Comment().Before...)\r\n\tdst.expr.Comment().Suffix = append(dst.expr.Comment().Suffix, src.expr.Comment().Suffix...)\r\n\tdst.expr.Comment().After = append(dst.expr.Comment().After, src.expr.Comment().After...)\r\n\treturn nil\r\n}","code-length":346,"reference":"\/\/ SquashRules copies information from src into dst without discarding\n\/\/ information in dst. SquashRules detects duplicate elements in lists and\n\/\/ dictionaries, but it doesn't sort elements after squashing. If squashing\n\/\/ fails because the expression is not understood, an error is returned,\n\/\/ and neither rule is modified.","result":"Squash expressions in rules.","score":[0.0,0.033]}
{"code":"\/*is used to<extra_id_0>\r\nfunc runClient() error {\r\n\tstartTime := time.Now()\r\n\tconn, err := net.Dial(\"unix\", *socketPath)\r\n\tif err != nil {\r\n\t\tif err := startServer(); err != nil {\r\n\t\t\treturn fmt.Errorf(\"error starting server: %v\", err)\r\n\t\t}\r\n\t\tfor retry := 0; retry < 3; retry++ {\r\n\t\t\tconn, err = net.Dial(\"unix\", *socketPath)\r\n\t\t\tif err == nil {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\ttime.Sleep(1 * time.Second)\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to connect to server: %v\", err)\r\n\t\t}\r\n\t}\r\n\tdefer conn.Close()\r\n\tif _, err := io.Copy(os.Stderr, conn); err != nil {\r\n\t\tlog.Print(err)\r\n\t}\r\n\telapsedTime := time.Since(startTime)\r\n\tlog.Printf(\"ran gazelle in %.3f s\", elapsedTime.Seconds())\r\n\treturn nil\r\n}","code-length":287,"reference":"\/\/ runClient performs the main work of the client. It attempts to connect\n\/\/ to the server via a UNIX-domain socket. If the server is not running,\n\/\/ it starts the server and tries again. The server does all the work, so\n\/\/ the client just waits for the server to complete, then exits.","result":"Run the client.","score":[0.0,0.0307]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UpdateRepo(rc *RemoteCache, importPath string) (Repo, error) {\r\n\troot, name, err := rc.Root(importPath)\r\n\tif err != nil {\r\n\t\treturn Repo{}, err\r\n\t}\r\n\tremote, vcs, err := rc.Remote(root)\r\n\tif err != nil {\r\n\t\treturn Repo{}, err\r\n\t}\r\n\tcommit, tag, err := rc.Head(remote, vcs)\r\n\tif err != nil {\r\n\t\treturn Repo{}, err\r\n\t}\r\n\trepo := Repo{\r\n\t\tName:     name,\r\n\t\tGoPrefix: root,\r\n\t\tCommit:   commit,\r\n\t\tTag:      tag,\r\n\t\tRemote:   remote,\r\n\t\tVCS:      vcs,\r\n\t}\r\n\treturn repo, nil\r\n}","code-length":214,"reference":"\/\/ UpdateRepo returns an object describing a repository at the most recent\n\/\/ commit or version tag.\n\/\/\n\/\/ This function uses RemoteCache to retrieve information about the repository.\n\/\/ Depending on how the RemoteCache was initialized and used earlier, some\n\/\/ information may already be locally available. Frequently though, information\n\/\/ will be fetched over the network, so this function may be slow.","result":"Update the repo in the repo cache.","score":[0.0001,0.0172]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRemoteCache(knownRepos []Repo) (r *RemoteCache, cleanup func() error) {\r\n\tr = &RemoteCache{\r\n\t\tRepoRootForImportPath: vcs.RepoRootForImportPath,\r\n\t\tHeadCmd:               defaultHeadCmd,\r\n\t\troot:                  remoteCacheMap{cache: make(map[string]*remoteCacheEntry)},\r\n\t\tremote:                remoteCacheMap{cache: make(map[string]*remoteCacheEntry)},\r\n\t\thead:                  remoteCacheMap{cache: make(map[string]*remoteCacheEntry)},\r\n\t\tmod:                   remoteCacheMap{cache: make(map[string]*remoteCacheEntry)},\r\n\t}\r\n\tr.ModInfo = func(importPath string) (string, error) {\r\n\t\treturn defaultModInfo(r, importPath)\r\n\t}\r\n\tfor _, repo := range knownRepos {\r\n\t\tr.root.cache[repo.GoPrefix] = &remoteCacheEntry{\r\n\t\t\tvalue: rootValue{\r\n\t\t\t\troot: repo.GoPrefix,\r\n\t\t\t\tname: repo.Name,\r\n\t\t\t},\r\n\t\t}\r\n\t\tif repo.Remote != \"\" {\r\n\t\t\tr.remote.cache[repo.GoPrefix] = &remoteCacheEntry{\r\n\t\t\t\tvalue: remoteValue{\r\n\t\t\t\t\tremote: repo.Remote,\r\n\t\t\t\t\tvcs:    repo.VCS,\r\n\t\t\t\t},\r\n\t\t\t}\r\n\t\t}\r\n\t\tr.mod.cache[repo.GoPrefix] = &remoteCacheEntry{\r\n\t\t\tvalue: modValue{\r\n\t\t\t\tpath:  repo.GoPrefix,\r\n\t\t\t\tname:  repo.Name,\r\n\t\t\t\tknown: true,\r\n\t\t\t},\r\n\t\t}\r\n\t}\r\n\treturn r, r.cleanup\r\n}","code-length":438,"reference":"\/\/ NewRemoteCache creates a new RemoteCache with a set of known repositories.\n\/\/ The Root and Remote methods will return information about repositories listed\n\/\/ here without accessing the network. However, the Head method will still\n\/\/ access the network for these repositories to retrieve information about new\n\/\/ versions.\n\/\/\n\/\/ A cleanup function is also returned. The caller must call this when\n\/\/ RemoteCache is no longer needed. RemoteCache may write files to a temporary\n\/\/ directory. This will delete them.","result":"Create a new remote cache.","score":[0.0,0.0266]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *RemoteCache) Remote(root string) (remote, vcs string, err error) {\r\n\tv, err := r.remote.ensure(root, func() (interface{}, error) {\r\n\t\trepo, err := r.RepoRootForImportPath(root, false)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn remoteValue{remote: repo.Repo, vcs: repo.VCS.Cmd}, nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn \"\", \"\", err\r\n\t}\r\n\tvalue := v.(remoteValue)\r\n\treturn value.remote, value.vcs, nil\r\n}","code-length":172,"reference":"\/\/ Remote returns the VCS name and the remote URL for a repository with the\n\/\/ given root import path. This is suitable for creating new repository rules.","result":"Generate code for the generated code.","score":[0.0059,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *remoteCacheMap) get(key string) (value interface{}, ok bool, err error) {\r\n\tm.mu.Lock()\r\n\te, ok := m.cache[key]\r\n\tm.mu.Unlock()\r\n\tif !ok {\r\n\t\treturn nil, ok, nil\r\n\t}\r\n\tif e.ready != nil {\r\n\t\t<-e.ready\r\n\t}\r\n\treturn e.value, ok, e.err\r\n}","code-length":125,"reference":"\/\/ get retrieves a value associated with the given key from the cache. ok will\n\/\/ be true if the key exists in the cache, even if it's in the process of\n\/\/ being fetched.","result":"Get the value of a remote cache entry.","score":[0.0067,0.0774]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *remoteCacheMap) ensure(key string, load func() (interface{}, error)) (interface{}, error) {\r\n\tm.mu.Lock()\r\n\te, ok := m.cache[key]\r\n\tif !ok {\r\n\t\te = &remoteCacheEntry{ready: make(chan struct{})}\r\n\t\tm.cache[key] = e\r\n\t\tm.mu.Unlock()\r\n\t\te.value, e.err = load()\r\n\t\tclose(e.ready)\r\n\t} else {\r\n\t\tm.mu.Unlock()\r\n\t\tif e.ready != nil {\r\n\t\t\t<-e.ready\r\n\t\t}\r\n\t}\r\n\treturn e.value, e.err\r\n}","code-length":190,"reference":"\/\/ ensure retreives a value associated with the given key from the cache. If\n\/\/ the key does not exist in the cache, the load function will be called,\n\/\/ and its result will be associated with the key. The load function will not\n\/\/ be called more than once for any key.","result":"Ensure remote cache map entries.","score":[0,0.0207]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RelBaseName(rel, prefix, root string) string {\r\n\tbase := path.Base(rel)\r\n\tif base == \".\" || base == \"\/\" {\r\n\t\tbase = path.Base(prefix)\r\n\t}\r\n\tif base == \".\" || base == \"\/\" {\r\n\t\tbase = filepath.Base(root)\r\n\t}\r\n\tif base == \".\" || base == \"\/\" {\r\n\t\tbase = \"root\"\r\n\t}\r\n\treturn base\r\n}","code-length":122,"reference":"\/\/ RelBaseName returns the base name for rel, a slash-separated path relative\n\/\/ to the repository root. If rel is empty, RelBaseName returns the base name\n\/\/ of prefix. If prefix is empty, RelBaseName returns the base name of root,\n\/\/ the absolute file path of the repository root directory. If that's empty\n\/\/ to, then RelBaseName returns \"root\".","result":"Generate the relBaseName function.","score":[0.0,0.0187]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) Clone() *Config {\r\n\tcc := *c\r\n\tcc.Exts = make(map[string]interface{})\r\n\tfor k, v := range c.Exts {\r\n\t\tcc.Exts[k] = v\r\n\t}\r\n\tcc.KindMap = make(map[string]MappedKind)\r\n\tfor k, v := range c.KindMap {\r\n\t\tcc.KindMap[k] = v\r\n\t}\r\n\treturn &cc\r\n}","code-length":132,"reference":"\/\/ Clone creates a copy of the configuration for use in a subdirectory.\n\/\/ Note that the Exts map is copied, but its contents are not.\n\/\/ Configurer.Configure should do this, if needed.","result":"Clone the config.","score":[0.0,0.0333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) IsValidBuildFileName(name string) bool {\r\n\tfor _, n := range c.ValidBuildFileNames {\r\n\t\tif name == n {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":72,"reference":"\/\/ IsValidBuildFileName returns true if a file with the given base name\n\/\/ should be treated as a build file.","result":"Validate build file names.","score":[0.007,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l tagLine) check(c *config.Config, os, arch string) bool {\r\n\tif len(l) == 0 {\r\n\t\treturn false\r\n\t}\r\n\tfor _, g := range l {\r\n\t\tif g.check(c, os, arch) {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":101,"reference":"\/\/ check returns true if at least one of the tag groups is satisfied.","result":"Check the tags in the tagLine.","score":[0.0509,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc fileNameInfo(path_ string) fileInfo {\r\n\tname := filepath.Base(path_)\r\n\tvar ext ext\r\n\tswitch path.Ext(name) {\r\n\tcase \".go\":\r\n\t\text = goExt\r\n\tcase \".c\", \".cc\", \".cpp\", \".cxx\", \".m\", \".mm\":\r\n\t\text = cExt\r\n\tcase \".h\", \".hh\", \".hpp\", \".hxx\":\r\n\t\text = hExt\r\n\tcase \".s\":\r\n\t\text = sExt\r\n\tcase \".S\":\r\n\t\text = csExt\r\n\tcase \".proto\":\r\n\t\text = protoExt\r\n\tdefault:\r\n\t\text = unknownExt\r\n\t}\r\n\tif strings.HasPrefix(name, \".\") || strings.HasPrefix(name, \"_\") {\r\n\t\text = unknownExt\r\n\t}\r\n\t\r\n\t\r\n\tvar isTest bool\r\n\tvar goos, goarch string\r\n\tl := strings.Split(name[:len(name)-len(path.Ext(name))], \"_\")\r\n\tif len(l) >= 2 && l[len(l)-1] == \"test\" {\r\n\t\tisTest = ext == goExt\r\n\t\tl = l[:len(l)-1]\r\n\t}\r\n\tswitch {\r\n\tcase len(l) >= 3 && rule.KnownOSSet[l[len(l)-2]] && rule.KnownArchSet[l[len(l)-1]]:\r\n\t\tgoos = l[len(l)-2]\r\n\t\tgoarch = l[len(l)-1]\r\n\tcase len(l) >= 2 && rule.KnownOSSet[l[len(l)-1]]:\r\n\t\tgoos = l[len(l)-1]\r\n\tcase len(l) >= 2 && rule.KnownArchSet[l[len(l)-1]]:\r\n\t\tgoarch = l[len(l)-1]\r\n\t}\r\n\treturn fileInfo{\r\n\t\tpath:   path_,\r\n\t\tname:   name,\r\n\t\text:    ext,\r\n\t\tisTest: isTest,\r\n\t\tgoos:   goos,\r\n\t\tgoarch: goarch,\r\n\t}\r\n}","code-length":555,"reference":"\/\/ fileNameInfo returns information that can be inferred from the name of\n\/\/ a file. It does not read data from the file.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc otherFileInfo(path string) fileInfo {\r\n\tinfo := fileNameInfo(path)\r\n\tif info.ext == unknownExt {\r\n\t\treturn info\r\n\t}\r\n\ttags, err := readTags(info.path)\r\n\tif err != nil {\r\n\t\tlog.Printf(\"%s: error reading file: %v\", info.path, err)\r\n\t\treturn info\r\n\t}\r\n\tinfo.tags = tags\r\n\treturn info\r\n}","code-length":120,"reference":"\/\/ otherFileInfo returns information about a non-.go file. It will parse\n\/\/ part of the file to determine build tags. If the file can't be read, an\n\/\/ error will be logged, and partial information will be returned.","result":"Avoid file names with multiple extensions.","score":[0.0009,0.0144]}
{"code":"\/*is used to<extra_id_0>\r\nfunc protoFileInfo(path_ string, protoInfo proto.FileInfo) fileInfo {\r\n\tinfo := fileNameInfo(path_)\r\n\t\r\n\t\r\n\tfor _, opt := range protoInfo.Options {\r\n\t\tif opt.Key != \"go_package\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif strings.LastIndexByte(opt.Value, '\/') == -1 {\r\n\t\t\tinfo.packageName = opt.Value\r\n\t\t} else {\r\n\t\t\tif i := strings.LastIndexByte(opt.Value, ';'); i != -1 {\r\n\t\t\t\tinfo.importPath = opt.Value[:i]\r\n\t\t\t\tinfo.packageName = opt.Value[i+1:]\r\n\t\t\t} else {\r\n\t\t\t\tinfo.importPath = opt.Value\r\n\t\t\t\tinfo.packageName = path.Base(opt.Value)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\tif info.packageName == \"\" && protoInfo.PackageName != \"\" {\r\n\t\tinfo.packageName = strings.Replace(protoInfo.PackageName, \".\", \"_\", -1)\r\n\t}\r\n\tinfo.imports = protoInfo.Imports\r\n\tinfo.hasServices = protoInfo.HasServices\r\n\treturn info\r\n}","code-length":312,"reference":"\/\/ protoFileInfo extracts metadata from a proto file. The proto extension\n\/\/ already \"parses\" these and stores metadata in proto.FileInfo, so this is\n\/\/ just processing relevant options.","result":"Generate the file info.","score":[0,0.0195]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ix *RuleIndex) AddRule(c *config.Config, r *rule.Rule, f *rule.File) {\r\n\tvar imps []ImportSpec\r\n\tif rslv := ix.mrslv(r, f.Pkg); rslv != nil {\r\n\t\timps = rslv.Imports(c, r, f)\r\n\t}\r\n\t\r\n\t\r\n\tif imps == nil {\r\n\t\treturn\r\n\t}\r\n\trecord := &ruleRecord{\r\n\t\trule:       r,\r\n\t\tlabel:      label.New(c.RepoName, f.Pkg, r.Name()),\r\n\t\tfile:       f,\r\n\t\timportedAs: imps,\r\n\t}\r\n\tif _, ok := ix.labelMap[record.label]; ok {\r\n\t\tlog.Printf(\"multiple rules found with label %s\", record.label)\r\n\t\treturn\r\n\t}\r\n\tix.rules = append(ix.rules, record)\r\n\tix.labelMap[record.label] = record\r\n}","code-length":266,"reference":"\/\/ AddRule adds a rule r to the index. The rule will only be indexed if there\n\/\/ is a known resolver for the rule's kind and Resolver.Imports returns a\n\/\/ non-nil slice.\n\/\/\n\/\/ AddRule may only be called before Finish.","result":"Generate the generated code.","score":[0.0,0.0131]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ix *RuleIndex) Finish() {\r\n\tfor _, r := range ix.rules {\r\n\t\tix.collectEmbeds(r)\r\n\t}\r\n\tix.buildImportIndex()\r\n}","code-length":60,"reference":"\/\/ Finish constructs the import index and performs any other necessary indexing\n\/\/ actions after all rules have been added. This step is necessary because\n\/\/ a rule may be indexed differently based on what rules are added later.\n\/\/\n\/\/ Finish must be called after all AddRule calls and before any\n\/\/ FindRulesByImport calls.","result":"Finish the import index.","score":[0.0,0.0512]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ix *RuleIndex) buildImportIndex() {\r\n\tix.importMap = make(map[ImportSpec][]*ruleRecord)\r\n\tfor _, r := range ix.rules {\r\n\t\tif r.embedded {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tindexed := make(map[ImportSpec]bool)\r\n\t\tfor _, imp := range r.importedAs {\r\n\t\t\tif indexed[imp] {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tindexed[imp] = true\r\n\t\t\tix.importMap[imp] = append(ix.importMap[imp], r)\r\n\t\t}\r\n\t}\r\n}","code-length":167,"reference":"\/\/ buildImportIndex constructs the map used by FindRulesByImport.","result":"Build the import index.","score":[0.1175,0.2467]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r FindResult) IsSelfImport(from label.Label) bool {\r\n\tif from.Equal(r.Label) {\r\n\t\treturn true\r\n\t}\r\n\tfor _, e := range r.Embeds {\r\n\t\tif from.Equal(e) {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":98,"reference":"\/\/ IsSelfImport returns true if the result's label matches the given label\n\/\/ or the result's rule transitively embeds the rule with the given label.\n\/\/ Self imports cause cyclic dependencies, so the caller may want to omit\n\/\/ the dependency or report an error.","result":"Check if the result is self.","score":[0.0004,0.0365]}
{"code":"\/*is used to<extra_id_0>\r\nfunc applyKindMappings(mappedKinds []config.MappedKind, loads []rule.LoadInfo) []rule.LoadInfo {\r\n\tif len(mappedKinds) == 0 {\r\n\t\treturn loads\r\n\t}\r\n\t\r\n\tmappedLoads := make([]rule.LoadInfo, len(loads))\r\n\tcopy(mappedLoads, loads)\r\n\tfor _, mappedKind := range mappedKinds {\r\n\t\tmappedLoads = appendOrMergeKindMapping(mappedLoads, mappedKind)\r\n\t}\r\n\treturn mappedLoads\r\n}","code-length":136,"reference":"\/\/ applyKindMappings returns a copy of LoadInfo that includes c.KindMap.","result":"Apply kind mappings.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc appendOrMergeKindMapping(mappedLoads []rule.LoadInfo, mappedKind config.MappedKind) []rule.LoadInfo {\r\n\t\r\n\tfor _, load := range mappedLoads {\r\n\t\tif load.Name == mappedKind.KindLoad {\r\n\t\t\tload.Symbols = append(load.Symbols, mappedKind.KindName)\r\n\t\t\treturn mappedLoads\r\n\t\t}\r\n\t}\r\n\t\r\n\treturn append(mappedLoads, rule.LoadInfo{\r\n\t\tName:    mappedKind.KindLoad,\r\n\t\tSymbols: []string{mappedKind.KindName},\r\n\t})\r\n}","code-length":155,"reference":"\/\/ appendOrMergeKindMapping adds LoadInfo for the given replacement.","result":"Merge kind mappings.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RuleName(names ...string) string {\r\n\tbase := \"root\"\r\n\tfor _, name := range names {\r\n\t\tnotIdent := func(c rune) bool {\r\n\t\t\treturn !('A' <= c && c <= 'Z' ||\r\n\t\t\t\t'a' <= c && c <= 'z' ||\r\n\t\t\t\t'0' <= c && c <= '9' ||\r\n\t\t\t\tc == '_')\r\n\t\t}\r\n\t\tif i := strings.LastIndexFunc(name, notIdent); i >= 0 {\r\n\t\t\tname = name[i+1:]\r\n\t\t}\r\n\t\tif name != \"\" {\r\n\t\t\tbase = name\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\treturn base + \"_proto\"\r\n}","code-length":196,"reference":"\/\/ RuleName returns a name for a proto_library derived from the given strings.\n\/\/ For each string, RuleName will look for a non-empty suffix of identifier\n\/\/ characters and then append \"_proto\" to that.","result":"Generate the rule name.","score":[0.0002,0.0161]}
{"code":"\/*is used to<extra_id_0>\r\nfunc buildPackages(pc *ProtoConfig, dir, rel string, protoFiles, genFiles []string) []*Package {\r\n\tpackageMap := make(map[string]*Package)\r\n\tfor _, name := range protoFiles {\r\n\t\tinfo := protoFileInfo(dir, name)\r\n\t\tkey := info.PackageName\r\n\t\tif pc.groupOption != \"\" {\r\n\t\t\tfor _, opt := range info.Options {\r\n\t\t\t\tif opt.Key == pc.groupOption {\r\n\t\t\t\t\tkey = opt.Value\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\tif packageMap[key] == nil {\r\n\t\t\tpackageMap[key] = newPackage(info.PackageName)\r\n\t\t}\r\n\t\tpackageMap[key].addFile(info)\r\n\t}\r\n\tswitch pc.Mode {\r\n\tcase DefaultMode:\r\n\t\tpkg, err := selectPackage(dir, rel, packageMap)\r\n\t\tif err != nil {\r\n\t\t\tlog.Print(err)\r\n\t\t}\r\n\t\tif pkg == nil {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tfor _, name := range genFiles {\r\n\t\t\tpkg.addGenFile(dir, name)\r\n\t\t}\r\n\t\treturn []*Package{pkg}\r\n\tcase PackageMode:\r\n\t\tpkgs := make([]*Package, 0, len(packageMap))\r\n\t\tfor _, pkg := range packageMap {\r\n\t\t\tpkgs = append(pkgs, pkg)\r\n\t\t}\r\n\t\treturn pkgs\r\n\tdefault:\r\n\t\treturn nil\r\n\t}\r\n}","code-length":404,"reference":"\/\/ buildPackage extracts metadata from the .proto files in a directory and\n\/\/ constructs possibly several packages, then selects a package to generate\n\/\/ a proto_library rule for.","result":"Build the package tree.","score":[0.0009,0.0586]}
{"code":"\/*is used to<extra_id_0>\r\nfunc selectPackage(dir, rel string, packageMap map[string]*Package) (*Package, error) {\r\n\tif len(packageMap) == 0 {\r\n\t\treturn nil, nil\r\n\t}\r\n\tif len(packageMap) == 1 {\r\n\t\tfor _, pkg := range packageMap {\r\n\t\t\treturn pkg, nil\r\n\t\t}\r\n\t}\r\n\tdefaultPackageName := strings.Replace(rel, \"\/\", \"_\", -1)\r\n\tfor _, pkg := range packageMap {\r\n\t\tif pkgName := goPackageName(pkg); pkgName != \"\" && pkgName == defaultPackageName {\r\n\t\t\treturn pkg, nil\r\n\t\t}\r\n\t}\r\n\treturn nil, fmt.Errorf(\"%s: directory contains multiple proto packages. Gazelle can only generate a proto_library for one package.\", dir)\r\n}","code-length":206,"reference":"\/\/ selectPackage chooses a package to generate rules for.","result":"Select a proto package.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc generateProto(pc *ProtoConfig, rel string, pkg *Package, shouldSetVisibility bool) *rule.Rule {\r\n\tvar name string\r\n\tif pc.Mode == DefaultMode {\r\n\t\tname = RuleName(goPackageName(pkg), pc.GoPrefix, rel)\r\n\t} else {\r\n\t\tname = RuleName(pkg.Options[pc.groupOption], pkg.Name, rel)\r\n\t}\r\n\tr := rule.NewRule(\"proto_library\", name)\r\n\tsrcs := make([]string, 0, len(pkg.Files))\r\n\tfor f := range pkg.Files {\r\n\t\tsrcs = append(srcs, f)\r\n\t}\r\n\tsort.Strings(srcs)\r\n\tif len(srcs) > 0 {\r\n\t\tr.SetAttr(\"srcs\", srcs)\r\n\t}\r\n\tr.SetPrivateAttr(PackageKey, *pkg)\r\n\timports := make([]string, 0, len(pkg.Imports))\r\n\tfor i := range pkg.Imports {\r\n\t\timports = append(imports, i)\r\n\t}\r\n\tsort.Strings(imports)\r\n\t\r\n\t\r\n\tr.SetPrivateAttr(config.GazelleImportsKey, imports)\r\n\tfor k, v := range pkg.Options {\r\n\t\tr.SetPrivateAttr(k, v)\r\n\t}\r\n\tif shouldSetVisibility {\r\n\t\tvis := rule.CheckInternalVisibility(rel, \"\r\n\t\tr.SetAttr(\"visibility\", []string{vis})\r\n\t}\r\n\tif pc.stripImportPrefix != \"\" {\r\n\t\tr.SetAttr(\"strip_import_prefix\", pc.stripImportPrefix)\r\n\t}\r\n\tif pc.importPrefix != \"\" {\r\n\t\tr.SetAttr(\"import_prefix\", pc.importPrefix)\r\n\t}\r\n\treturn r\r\n}","code-length":457,"reference":"\/\/ generateProto creates a new proto_library rule for a package. The rule may\n\/\/ be empty if there are no sources.","result":"Generate the proto library.","score":[0,0.0259]}
{"code":"\/*is used to<extra_id_0>\r\nfunc generateEmpty(f *rule.File, regularFiles, genFiles []string) []*rule.Rule {\r\n\tif f == nil {\r\n\t\treturn nil\r\n\t}\r\n\tknownFiles := make(map[string]bool)\r\n\tfor _, f := range regularFiles {\r\n\t\tknownFiles[f] = true\r\n\t}\r\n\tfor _, f := range genFiles {\r\n\t\tknownFiles[f] = true\r\n\t}\r\n\tvar empty []*rule.Rule\r\nouter:\r\n\tfor _, r := range f.Rules {\r\n\t\tif r.Kind() != \"proto_library\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tsrcs := r.AttrStrings(\"srcs\")\r\n\t\tif len(srcs) == 0 && r.Attr(\"srcs\") != nil {\r\n\t\t\t\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tfor _, src := range r.AttrStrings(\"srcs\") {\r\n\t\t\tif knownFiles[src] {\r\n\t\t\t\tcontinue outer\r\n\t\t\t}\r\n\t\t}\r\n\t\tempty = append(empty, rule.NewRule(\"proto_library\", r.Name()))\r\n\t}\r\n\treturn empty\r\n}","code-length":305,"reference":"\/\/ generateEmpty generates a list of proto_library rules that may be deleted.\n\/\/ This is generated from existing proto_library rules with srcs lists that\n\/\/ don't match any static or generated files.","result":"Generate empty proto library.","score":[0,0.0171]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ImportRepoRules(filename string, repoCache *RemoteCache) ([]*rule.Rule, error) {\r\n\tformat := getLockFileFormat(filename)\r\n\tif format == unknownFormat {\r\n\t\treturn nil, fmt.Errorf(`%s: unrecognized lock file format. Expected \"Gopkg.lock\", \"go.mod\", or \"Godeps.json\"`, filename)\r\n\t}\r\n\tparser := lockFileParsers[format]\r\n\trepos, err := parser(filename, repoCache)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error parsing %q: %v\", filename, err)\r\n\t}\r\n\tsort.Stable(byName(repos))\r\n\trules := make([]*rule.Rule, 0, len(repos))\r\n\tfor _, repo := range repos {\r\n\t\trules = append(rules, GenerateRule(repo))\r\n\t}\r\n\treturn rules, nil\r\n}","code-length":230,"reference":"\/\/ ImportRepoRules reads the lock file of a vendoring tool and returns\n\/\/ a list of equivalent repository rules that can be merged into a WORKSPACE\n\/\/ file. The format of the file is inferred from its basename.","result":"Import the rules from a file.","score":[0.0014,0.0718]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MergeRules(genRules []*rule.Rule, existingRules map[*rule.File][]string, destFile *rule.File, kinds map[string]rule.KindInfo) []*rule.File {\r\n\tsort.Stable(byRuleName(genRules))\r\n\trepoMap := make(map[string]*rule.File)\r\n\tfor file, repoNames := range existingRules {\r\n\t\tif file.Path == destFile.Path && file.MacroName() != \"\" && file.MacroName() == destFile.MacroName() {\r\n\t\t\tfile = destFile\r\n\t\t}\r\n\t\tfor _, name := range repoNames {\r\n\t\t\trepoMap[name] = file\r\n\t\t}\r\n\t}\r\n\trulesByFile := make(map[*rule.File][]*rule.Rule)\r\n\tfor _, rule := range genRules {\r\n\t\tdest := destFile\r\n\t\tif file, ok := repoMap[rule.Name()]; ok {\r\n\t\t\tdest = file\r\n\t\t}\r\n\t\trulesByFile[dest] = append(rulesByFile[dest], rule)\r\n\t}\r\n\tupdatedFiles := make(map[string]*rule.File)\r\n\tfor f, rules := range rulesByFile {\r\n\t\tmerger.MergeFile(f, nil, rules, merger.PreResolve, kinds)\r\n\t\tf.Sync()\r\n\t\tif uf, ok := updatedFiles[f.Path]; ok {\r\n\t\t\tuf.SyncMacroFile(f)\r\n\t\t} else {\r\n\t\t\tupdatedFiles[f.Path] = f\r\n\t\t}\r\n\t}\r\n\tfiles := make([]*rule.File, 0, len(updatedFiles))\r\n\tfor _, f := range updatedFiles {\r\n\t\tfiles = append(files, f)\r\n\t}\r\n\treturn files\r\n}","code-length":447,"reference":"\/\/ MergeRules merges a list of generated repo rules with the already defined repo rules,\n\/\/ and then updates each rule's underlying file. If the generated rule matches an existing\n\/\/ one, then it inherits the file where the existing rule was defined. If the rule is new then\n\/\/ its file is set as the destFile parameter. A list of the updated files is returned.","result":"Merge rules.","score":[0,0.0084]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GenerateRule(repo Repo) *rule.Rule {\r\n\tr := rule.NewRule(\"go_repository\", repo.Name)\r\n\tif repo.Commit != \"\" {\r\n\t\tr.SetAttr(\"commit\", repo.Commit)\r\n\t}\r\n\tif repo.Tag != \"\" {\r\n\t\tr.SetAttr(\"tag\", repo.Tag)\r\n\t}\r\n\tr.SetAttr(\"importpath\", repo.GoPrefix)\r\n\tif repo.Remote != \"\" {\r\n\t\tr.SetAttr(\"remote\", repo.Remote)\r\n\t}\r\n\tif repo.VCS != \"\" {\r\n\t\tr.SetAttr(\"vcs\", repo.VCS)\r\n\t}\r\n\tif repo.Version != \"\" {\r\n\t\tr.SetAttr(\"version\", repo.Version)\r\n\t}\r\n\tif repo.Sum != \"\" {\r\n\t\tr.SetAttr(\"sum\", repo.Sum)\r\n\t}\r\n\tif repo.Replace != \"\" {\r\n\t\tr.SetAttr(\"replace\", repo.Replace)\r\n\t}\r\n\treturn r\r\n}","code-length":268,"reference":"\/\/ GenerateRule returns a repository rule for the given repository that can\n\/\/ be written in a WORKSPACE file.","result":"Generate the rule.","score":[0.002,0.0287]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FindExternalRepo(repoRoot, name string) (string, error) {\r\n\tRoot, \"bazel-out\", \"..\", \"..\", \"..\", \"external\", name}, string(os.PathSeparator))\r\n\tcleanPath, err := filepath.EvalSymlinks(externalPath)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tst, err := os.Stat(cleanPath)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tif !st.IsDir() {\r\n\t\treturn \"\", fmt.Errorf(\"%s: not a directory\", externalPath)\r\n\t}\r\n\treturn cleanPath, nil\r\n}","code-length":172,"reference":"\/\/ FindExternalRepo attempts to locate the directory where Bazel has fetched\n\/\/ the external repository with the given name. An error is returned if the\n\/\/ repository directory cannot be located.","result":"Find external repos.","score":[0.0,0.0177]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ListRepositories(workspace *rule.File) (repos []Repo, repoNamesByFile map[*rule.File][]string, err error) {\r\n\trepoNamesByFile = make(map[*rule.File][]string)\r\n\trepos, repoNamesByFile[workspace] = getRepos(workspace.Rules)\r\n\tfor _, d := range workspace.Directives {\r\n\t\tswitch d.Key {\r\n\t\tcase \"repository_macro\":\r\n\t\t\tf, defName, err := parseRepositoryMacroDirective(d.Value)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, nil, err\r\n\t\t\t}\r\n\t\t\tf = filepath.Join(filepath.Dir(workspace.Path), filepath.Clean(f))\r\n\t\t\tmacroFile, err := rule.LoadMacroFile(f, \"\", defName)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, nil, err\r\n\t\t\t}\r\n\t\t\tcurrRepos, names := getRepos(macroFile.Rules)\r\n\t\t\trepoNamesByFile[macroFile] = names\r\n\t\t\trepos = append(repos, currRepos...)\r\n\t\t}\r\n\t}\r\n\treturn repos, repoNamesByFile, nil\r\n}","code-length":295,"reference":"\/\/ ListRepositories extracts metadata about repositories declared in a\n\/\/ file.","result":"List repositories in a workspace.","score":[0.1133,0.2457]}
{"code":"\/*is used to<extra_id_0>\r\nfunc migrateLibraryEmbed(c *config.Config, f *rule.File) {\r\n\tfor _, r := range f.Rules {\r\n\t\tif !isGoRule(r.Kind()) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tlibExpr := r.Attr(\"library\")\r\n\t\tif libExpr == nil || rule.ShouldKeep(libExpr) || r.Attr(\"embed\") != nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tr.DelAttr(\"library\")\r\n\t\tr.SetAttr(\"embed\", &bzl.ListExpr{List: []bzl.Expr{libExpr}})\r\n\t}\r\n}","code-length":164,"reference":"\/\/ migrateLibraryEmbed converts \"library\" attributes to \"embed\" attributes,\n\/\/ preserving comments. This only applies to Go rules, and only if there is\n\/\/ no keep comment on \"library\" and no existing \"embed\" attribute.","result":"Migrate library embed.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc migrateGrpcCompilers(c *config.Config, f *rule.File) {\r\n\tfor _, r := range f.Rules {\r\n\t\tif r.Kind() != \"go_grpc_library\" || r.ShouldKeep() || r.Attr(\"compilers\") != nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tr.SetKind(\"go_proto_library\")\r\n\t\tr.SetAttr(\"compilers\", []string{grpcCompilerLabel})\r\n\t}\r\n}","code-length":130,"reference":"\/\/ migrateGrpcCompilers converts \"go_grpc_library\" rules into \"go_proto_library\"\n\/\/ rules with a \"compilers\" attribute.","result":"Migrate the gRPC compiler.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc squashCgoLibrary(c *config.Config, f *rule.File) {\r\n\t\r\n\tvar cgoLibrary, goLibrary *rule.Rule\r\n\tfor _, r := range f.Rules {\r\n\t\tif r.Kind() == \"cgo_library\" && r.Name() == \"cgo_default_library\" && !r.ShouldKeep() {\r\n\t\t\tif cgoLibrary != nil {\r\n\t\t\t\tlog.Printf(\"%s: when fixing existing file, multiple cgo_library rules with default name found\", f.Path)\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tcgoLibrary = r\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif r.Kind() == \"go_library\" && r.Name() == defaultLibName {\r\n\t\t\tif goLibrary != nil {\r\n\t\t\t\tlog.Printf(\"%s: when fixing existing file, multiple go_library rules with default name referencing cgo_library found\", f.Path)\r\n\t\t\t}\r\n\t\t\tgoLibrary = r\r\n\t\t\tcontinue\r\n\t\t}\r\n\t}\r\n\tif cgoLibrary == nil {\r\n\t\treturn\r\n\t}\r\n\tif !c.ShouldFix {\r\n\t\tlog.Printf(\"%s: cgo_library is deprecated. Run 'gazelle fix' to squash with go_library.\", f.Path)\r\n\t\treturn\r\n\t}\r\n\tif goLibrary == nil {\r\n\t\tcgoLibrary.SetKind(\"go_library\")\r\n\t\tcgoLibrary.SetName(defaultLibName)\r\n\t\tcgoLibrary.SetAttr(\"cgo\", true)\r\n\t\treturn\r\n\t}\r\n\tif err := rule.SquashRules(cgoLibrary, goLibrary, f.Path); err != nil {\r\n\t\tlog.Print(err)\r\n\t\treturn\r\n\t}\r\n\tgoLibrary.DelAttr(\"embed\")\r\n\tgoLibrary.SetAttr(\"cgo\", true)\r\n\tcgoLibrary.Delete()\r\n}","code-length":485,"reference":"\/\/ squashCgoLibrary removes cgo_library rules with the default name and\n\/\/ merges their attributes with go_library with the default name. If no\n\/\/ go_library rule exists, a new one will be created.\n\/\/\n\/\/ Note that the library attribute is disregarded, so cgo_library and\n\/\/ go_library attributes will be squashed even if the cgo_library was unlinked.\n\/\/ MergeFile will remove unused values and attributes later.","result":"Library rules.","score":[0,0.0085]}
{"code":"\/*is used to<extra_id_0>\r\nfunc removeLegacyProto(c *config.Config, f *rule.File) {\r\n\t\r\n\tif pcMode := getProtoMode(c); pcMode != proto.DefaultMode {\r\n\t\treturn\r\n\t}\r\n\t\r\n\tvar protoLoads []*rule.Load\r\n\tfor _, l := range f.Loads {\r\n\t\tif l.Name() == \"@io_bazel_rules_go\r\n\t\t\tprotoLoads = append(protoLoads, l)\r\n\t\t}\r\n\t}\r\n\tvar protoFilegroups, protoRules []*rule.Rule\r\n\tfor _, r := range f.Rules {\r\n\t\tif r.Kind() == \"filegroup\" && r.Name() == legacyProtoFilegroupName {\r\n\t\t\tprotoFilegroups = append(protoFilegroups, r)\r\n\t\t}\r\n\t\tif r.Kind() == \"go_proto_library\" {\r\n\t\t\tprotoRules = append(protoRules, r)\r\n\t\t}\r\n\t}\r\n\tif len(protoLoads)+len(protoFilegroups) == 0 {\r\n\t\treturn\r\n\t}\r\n\tif !c.ShouldFix {\r\n\t\tlog.Printf(\"%s: go_proto_library.bzl is deprecated. Run 'gazelle fix' to replace old rules.\", f.Path)\r\n\t\treturn\r\n\t}\r\n\t\r\n\t\r\n\tfor _, l := range protoLoads {\r\n\t\tl.Delete()\r\n\t}\r\n\tfor _, r := range protoFilegroups {\r\n\t\tr.Delete()\r\n\t}\r\n\tif len(protoLoads) > 0 {\r\n\t\tfor _, r := range protoRules {\r\n\t\t\tr.Delete()\r\n\t\t}\r\n\t}\r\n}","code-length":429,"reference":"\/\/ removeLegacyProto removes uses of the old proto rules. It deletes loads\n\/\/ from go_proto_library.bzl. It deletes proto filegroups. It removes\n\/\/ go_proto_library attributes which are no longer recognized. New rules\n\/\/ are generated in place of the deleted rules, but attributes and comments\n\/\/ are not migrated.","result":"Remove legacy proto rules.","score":[0.0,0.0344]}
{"code":"\/*is used to<extra_id_0>\r\nfunc removeLegacyGazelle(c *config.Config, f *rule.File) {\r\n\tfor _, l := range f.Loads {\r\n\t\tif l.Name() == \"@io_bazel_rules_go\r\n\t\t\tl.Remove(\"gazelle\")\r\n\t\t\tif l.IsEmpty() {\r\n\t\t\t\tl.Delete()\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":109,"reference":"\/\/ removeLegacyGazelle removes loads of the \"gazelle\" macro from\n\/\/ @io_bazel_rules_go\/\/go:def.bzl. The definition has moved to\n\/\/ @bazel_gazelle\/\/:def.bzl, and the old one will be deleted soon.","result":"Remove legacy gazelle.","score":[0,0.0211]}
{"code":"\/*is used to<extra_id_0>\r\nfunc selectPackage(c *config.Config, dir string, packageMap map[string]*goPackage) (*goPackage, error) {\r\n\tbuildablePackages := make(map[string]*goPackage)\r\n\tfor name, pkg := range packageMap {\r\n\t\tif pkg.isBuildable(c) {\r\n\t\t\tbuildablePackages[name] = pkg\r\n\t\t}\r\n\t}\r\n\tif len(buildablePackages) == 0 {\r\n\t\treturn nil, &build.NoGoError{Dir: dir}\r\n\t}\r\n\tif len(buildablePackages) == 1 {\r\n\t\tfor _, pkg := range buildablePackages {\r\n\t\t\treturn pkg, nil\r\n\t\t}\r\n\t}\r\n\tif pkg, ok := buildablePackages[defaultPackageName(c, dir)]; ok {\r\n\t\treturn pkg, nil\r\n\t}\r\n\terr := &build.MultiplePackageError{Dir: dir}\r\n\tfor name, pkg := range buildablePackages {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\terr.Packages = append(err.Packages, name)\r\n\t\terr.Files = append(err.Files, pkg.firstGoFile())\r\n\t}\r\n\treturn nil, err\r\n}","code-length":306,"reference":"\/\/ selectPackages selects one Go packages out of the buildable packages found\n\/\/ in a directory. If multiple packages are found, it returns the package\n\/\/ whose name matches the directory if such a package exists.","result":"Select a package.","score":[0.0,0.0306]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mr *metaResolver) AddBuiltin(kindName string, resolver resolve.Resolver) {\r\n\tmr.builtins[kindName] = resolver\r\n}","code-length":45,"reference":"\/\/ AddBuiltin registers a builtin kind with its info.","result":"Resolve the package .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mr *metaResolver) MappedKind(pkgRel string, kind config.MappedKind) {\r\n\tmr.mappedKinds[pkgRel] = append(mr.mappedKinds[pkgRel], kind)\r\n}","code-length":59,"reference":"\/\/ MappedKind records the fact that the given mapping was applied while\n\/\/ processing the given package.","result":"Resolve the package.","score":[0.0046,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mr metaResolver) Resolver(r *rule.Rule, pkgRel string) resolve.Resolver {\r\n\tfor _, mappedKind := range mr.mappedKinds[pkgRel] {\r\n\t\tif mappedKind.KindName == r.Kind() {\r\n\t\t\treturn mr.builtins[mappedKind.FromKind]\r\n\t\t}\r\n\t}\r\n\treturn mr.builtins[r.Kind()]\r\n}","code-length":109,"reference":"\/\/ Resolver returns a resolver for the given rule and package, and a bool\n\/\/ indicating whether one was found. Empty string may be passed for pkgRel,\n\/\/ which results in consulting the builtin kinds only.","result":"Resolve meta.","score":[0,0.0153]}
{"code":"\/*is used to<extra_id_0>\r\nfunc sortExprLabels(e bzl.Expr, _ []bzl.Expr) {\r\n\tlist, ok := e.(*bzl.ListExpr)\r\n\tif !ok || len(list.List) == 0 {\r\n\t\treturn\r\n\t}\r\n\tkeys := make([]stringSortKey, len(list.List))\r\n\tfor i, elem := range list.List {\r\n\t\ts, ok := elem.(*bzl.StringExpr)\r\n\t\tif !ok {\r\n\t\t\treturn\r\n\t\t}\r\n\t\tkeys[i] = makeSortKey(i, s)\r\n\t}\r\n\tbefore := keys[0].x.Comment().Before\r\n\tkeys[0].x.Comment().Before = nil\r\n\tsort.Sort(byStringExpr(keys))\r\n\tkeys[0].x.Comment().Before = append(before, keys[0].x.Comment().Before...)\r\n\tfor i, k := range keys {\r\n\t\tlist.List[i] = k.x\r\n\t}\r\n}","code-length":256,"reference":"\/\/ sortExprLabels sorts lists of strings using the same order as buildifier.\n\/\/ Buildifier also sorts string lists, but not those involved with \"select\"\n\/\/ expressions. This function is intended to be used with bzl.Walk.","result":"Sort expressions by label.","score":[0,0.0157]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkRulesGoVersion(repoRoot string) {\r\n\tconst message = `Gazelle may not be compatible with this version of rules_go.\r\nUpdate io_bazel_rules_go to a newer version in your WORKSPACE file.`\r\n\trulesGoPath, err := repo.FindExternalRepo(repoRoot, config.RulesGoRepoName)\r\n\tif err != nil {\r\n\t\treturn\r\n\t}\r\n\tdefBzlPath := filepath.Join(rulesGoPath, \"go\", \"def.bzl\")\r\n\tdefBzlContent, err := ioutil.ReadFile(defBzlPath)\r\n\tif err != nil {\r\n\t\treturn\r\n\t}\r\n\tversionRe := regexp.MustCompile(`(?m)^RULES_GO_VERSION = ['\"]([0-9.]*)['\"]`)\r\n\tmatch := versionRe.FindSubmatch(defBzlContent)\r\n\tif match == nil {\r\n\t\tlog.Printf(\"RULES_GO_VERSION not found in @%s\r\n\t\treturn\r\n\t}\r\n\tvstr := string(match[1])\r\n\tv, err := version.ParseVersion(vstr)\r\n\tif err != nil {\r\n\t\tlog.Printf(\"RULES_GO_VERSION %q could not be parsed in @%s\r\n\t}\r\n\tif v.Compare(minimumRulesGoVersion) < 0 {\r\n\t\tlog.Printf(\"Found RULES_GO_VERSION %s. Minimum compatible version is %s.\\n%s\", v, minimumRulesGoVersion, message)\r\n\t}\r\n}","code-length":383,"reference":"\/\/ checkRulesGoVersion checks whether a compatible version of rules_go is\n\/\/ being used in the workspace. A message will be logged if an incompatible\n\/\/ version is found.\n\/\/\n\/\/ Note that we can't always determine the version of rules_go in use. Also,\n\/\/ if we find an incompatible version, we shouldn't bail out since the\n\/\/ incompatibility may not matter in the current workspace.","result":"Check rules.","score":[0,0.0085]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gc *goConfig) preprocessTags() {\r\n\tif gc.genericTags == nil {\r\n\t\tgc.genericTags = make(map[string]bool)\r\n\t}\r\n\tgc.genericTags[\"gc\"] = true\r\n}","code-length":67,"reference":"\/\/ preprocessTags adds some tags which are on by default before they are\n\/\/ used to match files.","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gc *goConfig) setBuildTags(tags string) error {\r\n\tif tags == \"\" {\r\n\t\treturn nil\r\n\t}\r\n\tfor _, t := range strings.Split(tags, \",\") {\r\n\t\tif strings.HasPrefix(t, \"!\") {\r\n\t\t\treturn fmt.Errorf(\"build tags can't be negated: %s\", t)\r\n\t\t}\r\n\t\tgc.genericTags[t] = true\r\n\t}\r\n\treturn nil\r\n}","code-length":127,"reference":"\/\/ setBuildTags sets genericTags by parsing as a comma separated list. An\n\/\/ error will be returned for tags that wouldn't be recognized by \"go build\".\n\/\/ preprocessTags should be called before this.","result":"Set build tags in go.","score":[0.0009,0.0331]}
{"code":"\/*is used to<extra_id_0>\r\nfunc splitValue(value string) []string {\r\n\tparts := strings.Split(value, \",\")\r\n\tvalues := make([]string, 0, len(parts))\r\n\tfor _, part := range parts {\r\n\t\tvalues = append(values, strings.TrimSpace(part))\r\n\t}\r\n\treturn values\r\n}","code-length":88,"reference":"\/\/ splitDirective splits a comma-separated directive value into its component\n\/\/ parts, trimming each of any whitespace characters.","result":"Split the value.","score":[0,0.0303]}
{"code":"\/*is used to<extra_id_0>\r\nfunc copyGoModToTemp(filename string) (tempDir string, err error) {\r\n\tgoModOrig, err := os.Open(filename)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tdefer goModOrig.Close()\r\n\ttempDir, err = ioutil.TempDir(\"\", \"gazelle-temp-gomod\")\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tgoModCopy, err := os.Create(filepath.Join(tempDir, \"go.mod\"))\r\n\tif err != nil {\r\n\t\tos.Remove(tempDir)\r\n\t\treturn \"\", err\r\n\t}\r\n\tdefer func() {\r\n\t\tif cerr := goModCopy.Close(); err == nil && cerr != nil {\r\n\t\t\terr = cerr\r\n\t\t}\r\n\t}()\r\n\t_, err = io.Copy(goModCopy, goModOrig)\r\n\tif err != nil {\r\n\t\tos.RemoveAll(tempDir)\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn tempDir, err\r\n}","code-length":277,"reference":"\/\/ copyGoModToTemp copies to given go.mod file to a temporary directory.\n\/\/ go list tends to mutate go.mod files, but gazelle shouldn't do that.","result":"Mod to a temporary directory.","score":[0.0168,0.1697]}
{"code":"\/*is used to<extra_id_0>\r\nfunc findGoTool() string {\r\n\tpath := \"go\"\r\n\tif goroot, ok := os.LookupEnv(\"GOROOT\"); ok {\r\n\t\tpath = filepath.Join(goroot, \"bin\", \"go\")\r\n\t}\r\n\tif runtime.GOOS == \"windows\" {\r\n\t\tpath += \".exe\"\r\n\t}\r\n\treturn path\r\n}","code-length":101,"reference":"\/\/ findGoTool attempts to locate the go executable. If GOROOT is set, we'll\n\/\/ prefer the one in there; otherwise, we'll rely on PATH. If the wrapper\n\/\/ script generated by the gazelle rule is invoked by Bazel, it will set\n\/\/ GOROOT to the configured SDK. We don't want to rely on the host SDK in\n\/\/ that situation.","result":"Find the go tool.","score":[0.0,0.0276]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pkg *goPackage) isBuildable(c *config.Config) bool {\r\n\treturn pkg.firstGoFile() != \"\" || !pkg.proto.sources.isEmpty()\r\n}","code-length":54,"reference":"\/\/ isBuildable returns true if anything in the package is buildable.\n\/\/ This is true if the package has Go code that satisfies build constraints\n\/\/ on any platform or has proto files not in legacy mode.","result":"Build the package.","score":[0.0,0.0298]}
{"code":"\/*is used to<extra_id_0>\r\nfunc startServer() error {\r\n\texe, err := os.Executable()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\targs := []string{\"-server\"}\r\n\targs = append(args, os.Args[1:]...)\r\n\tcmd := exec.Command(exe, args...)\r\n\tlog.Printf(\"starting server: %s\", strings.Join(cmd.Args, \" \"))\r\n\tif err := cmd.Start(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := cmd.Process.Release(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":167,"reference":"\/\/ startServer starts a new server process. This is called by the client.","result":"Start the server.","score":[0.0146,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc watchDir(root string, record func(string)) (cancel func(), err error) {\r\n\tw, err := fsnotify.NewWatcher()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdirs, errs := listDirs(root)\r\n\tfor _, err := range errs {\r\n\t\tlog.Print(err)\r\n\t}\r\n\tgitDir := filepath.Join(root, \".git\")\r\n\tfor _, dir := range dirs {\r\n\t\tif dir == gitDir {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif err := w.Add(dir); err != nil {\r\n\t\t\tlog.Print(err)\r\n\t\t}\r\n\t}\r\n\tdone := make(chan struct{})\r\n\tgo func() {\r\n\t\tfor {\r\n\t\t\tselect {\r\n\t\t\tcase ev := <-w.Events:\r\n\t\t\t\tif shouldIgnore(ev.Name) {\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\tif ev.Op == fsnotify.Create {\r\n\t\t\t\t\tif st, err := os.Lstat(ev.Name); err != nil {\r\n\t\t\t\t\t\tlog.Print(err)\r\n\t\t\t\t\t} else if st.IsDir() {\r\n\t\t\t\t\t\tdirs, errs := listDirs(ev.Name)\r\n\t\t\t\t\t\tfor _, err := range errs {\r\n\t\t\t\t\t\t\tlog.Print(err)\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\tfor _, dir := range dirs {\r\n\t\t\t\t\t\t\tif err := w.Add(dir); err != nil {\r\n\t\t\t\t\t\t\t\tlog.Print(err)\r\n\t\t\t\t\t\t\t}\r\n\t\t\t\t\t\t\trecordWrite(dir)\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t}\r\n\t\t\t\t} else {\r\n\t\t\t\t\trecordWrite(filepath.Dir(ev.Name))\r\n\t\t\t\t}\r\n\t\t\tcase err := <-w.Errors:\r\n\t\t\t\tlog.Print(err)\r\n\t\t\tcase <-done:\r\n\t\t\t\tif err := w.Close(); err != nil {\r\n\t\t\t\t\tlog.Print(err)\r\n\t\t\t\t}\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t}\r\n\t}()\r\n\treturn func() { close(done) }, nil\r\n}","code-length":538,"reference":"\/\/ watchDir listens for file system changes in root and its\n\/\/ subdirectories. The record function is called with directories whose\n\/\/ contents have changed. New directories are watched recursively.\n\/\/ The returned cancel function may be called to stop watching.","result":"Code too long,keep in 512.","score":[0.0002,0.0134]}
{"code":"\/*is used to<extra_id_0>\r\nfunc listDirs(dir string) ([]string, []error) {\r\n\tvar dirs []string\r\n\tvar errs []error\r\n\terr := filepath.Walk(dir, func(path string, info os.FileInfo, err error) error {\r\n\t\tif err != nil {\r\n\t\t\terrs = append(errs, err)\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tif info.IsDir() {\r\n\t\t\tdirs = append(dirs, path)\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\terrs = append(errs, err)\r\n\t}\r\n\treturn dirs, errs\r\n}","code-length":172,"reference":"\/\/ listDirs returns a slice containing all the subdirectories under dir,\n\/\/ including dir itself.","result":"List the directories in a directory.","score":[0.0512,0.0709]}
{"code":"\/*is used to<extra_id_0>\r\nfunc shouldIgnore(p string) bool {\r\n\tp = strings.TrimPrefix(filepath.ToSlash(p), \".\/\")\r\n\tbase := path.Base(p)\r\n\treturn strings.HasPrefix(p, \"tools\/\") || base == \".git\" || base == \"BUILD\" || base == \"BUILD.bazel\"\r\n}","code-length":88,"reference":"\/\/ shouldIgnore returns whether a write to the given file should be ignored\n\/\/ because they were caused by gazelle or autogazelle or something unrelated\n\/\/ to the build.","result":"Ignore files.","score":[0,0.019]}
{"code":"\/*is used to<extra_id_0>\r\nfunc recordWrite(path string) {\r\n\tdirSetMutex.Lock()\r\n\tdefer dirSetMutex.Unlock()\r\n\tdirSet[path] = true\r\n}","code-length":49,"reference":"\/\/ recordWrite records that a directory has been modified and that its build\n\/\/ file should be updated the next time gazelle runs.","result":"Record write to a file.","score":[0.0066,0.0472]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getAndClearWrittenDirs() []string {\r\n\tdirSetMutex.Lock()\r\n\tdefer dirSetMutex.Unlock()\r\n\tdirs := make([]string, 0, len(dirSet))\r\n\tfor d := range dirSet {\r\n\t\tdirs = append(dirs, d)\r\n\t}\r\n\tdirSet = make(map[string]bool)\r\n\treturn dirs\r\n}","code-length":102,"reference":"\/\/ getAndClearWrittenDirs retrieves a list of directories that have been\n\/\/ modified since the last time getAndClearWrittenDirs was called.","result":"Clear the directory set.","score":[0.0075,0.0571]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CombineHandlers(handlers ...http.HandlerFunc) http.HandlerFunc {\r\n\treturn func(w http.ResponseWriter, req *http.Request) {\r\n\t\tfor _, handler := range handlers {\r\n\t\t\thandler(w, req)\r\n\t\t}\r\n\t}\r\n}","code-length":78,"reference":"\/\/CombineHandler takes variadic list of handlers and produces one handler\n\/\/that calls each handler in order.","result":"Combine multiple handlers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc VerifyContentType(contentType string) http.HandlerFunc {\r\n\treturn func(w http.ResponseWriter, req *http.Request) {\r\n\t\tExpect(req.Header.Get(\"Content-Type\")).Should(Equal(contentType))\r\n\t}\r\n}","code-length":70,"reference":"\/\/VerifyContentType returns a handler that verifies that a request has a Content-Type header set to the\n\/\/specified value","result":"Verify the content type.","score":[0.0096,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc VerifyMimeType(mimeType string) http.HandlerFunc {\r\n\treturn func(w http.ResponseWriter, req *http.Request) {\r\n\t\tExpect(strings.Split(req.Header.Get(\"Content-Type\"), \";\")[0]).Should(Equal(mimeType))\r\n\t}\r\n}","code-length":79,"reference":"\/\/VerifyMimeType returns a handler that verifies that a request has a specified mime type set\n\/\/in Content-Type header","result":"Verify the content type.","score":[0,0.0301]}
{"code":"\/*is used to<extra_id_0>\r\nfunc VerifyBasicAuth(username string, password string) http.HandlerFunc {\r\n\treturn func(w http.ResponseWriter, req *http.Request) {\r\n\t\tauth := req.Header.Get(\"Authorization\")\r\n\t\tExpect(auth).ShouldNot(Equal(\"\"), \"Authorization header must be specified\")\r\n\t\tdecoded, err := base64.StdEncoding.DecodeString(auth[6:])\r\n\t\tExpect(err).ShouldNot(HaveOccurred())\r\n\t\tExpect(string(decoded)).Should(Equal(fmt.Sprintf(\"%s:%s\", username, password)), \"Authorization mismatch\")\r\n\t}\r\n}","code-length":155,"reference":"\/\/VerifyBasicAuth returns a handler that verifies the request contains a BasicAuth Authorization header\n\/\/matching the passed in username and password","result":"Verify basic auth.","score":[0,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc VerifyJSONRepresenting(object interface{}) http.HandlerFunc {\r\n\tdata, err := json.Marshal(object)\r\n\tExpect(err).ShouldNot(HaveOccurred())\r\n\treturn CombineHandlers(\r\n\t\tVerifyContentType(\"application\/json\"),\r\n\t\tVerifyJSON(string(data)),\r\n\t)\r\n}","code-length":88,"reference":"\/\/VerifyJSONRepresenting is similar to VerifyJSON.  Instead of taking a JSON string, however, it\n\/\/takes an arbitrary JSON-encodable object and verifies that the requests's body is a JSON representation\n\/\/that matches the object","result":"Verify json representation of a given object.","score":[0.006,0.1261]}
{"code":"\/*is used to<extra_id_0>\r\nfunc VerifyFormKV(key string, values ...string) http.HandlerFunc {\r\n\treturn VerifyForm(url.Values{key: values})\r\n}","code-length":44,"reference":"\/\/VerifyFormKV returns a handler that verifies a request contains a form key with the specified values.\n\/\/\n\/\/It is a convenience wrapper around `VerifyForm` that lets you avoid having to create a `url.Values` object.","result":"Verify form values.","score":[0.0,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RespondWithProto(statusCode int, message proto.Message, optionalHeader ...http.Header) http.HandlerFunc {\r\n\treturn func(w http.ResponseWriter, req *http.Request) {\r\n\t\tdata, err := proto.Marshal(message)\r\n\t\tExpect(err).ShouldNot(HaveOccurred())\r\n\t\tvar headers http.Header\r\n\t\tif len(optionalHeader) == 1 {\r\n\t\t\theaders = optionalHeader[0]\r\n\t\t} else {\r\n\t\t\theaders = make(http.Header)\r\n\t\t}\r\n\t\tif _, found := headers[\"Content-Type\"]; !found {\r\n\t\t\theaders[\"Content-Type\"] = []string{\"application\/x-protobuf\"}\r\n\t\t}\r\n\t\tcopyHeader(headers, w.Header())\r\n\t\tw.WriteHeader(statusCode)\r\n\t\tw.Write(data)\r\n\t}\r\n}","code-length":225,"reference":"\/\/RespondWithProto returns a handler that responds to a request with the specified status code and a body\n\/\/containing the protobuf serialization of the provided message.\n\/\/\n\/\/Also, RespondWithProto can be given an optional http.Header.  The headers defined therein will be added to the response headers.","result":"Respond with the given message.","score":[0.0001,0.061]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterFailHandlerWithT(t types.TWithHelper, handler types.GomegaFailHandler) {\r\n\tif handler == nil {\r\n\t\tglobalFailWrapper = nil\r\n\t\treturn\r\n\t}\r\n\tglobalFailWrapper = &types.GomegaFailWrapper{\r\n\t\tFail:        handler,\r\n\t\tTWithHelper: t,\r\n\t}\r\n}","code-length":101,"reference":"\/\/ RegisterFailHandlerWithT ensures that the given types.TWithHelper and fail handler\n\/\/ are used globally.","result":"Register a handler with a t.","score":[0.0509,0.0379]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EventuallyWithOffset(offset int, actual interface{}, intervals ...interface{}) AsyncAssertion {\r\n\tif globalFailWrapper == nil {\r\n\t\tpanic(nilFailHandlerPanic)\r\n\t}\r\n\ttimeoutInterval := defaultEventuallyTimeout\r\n\tpollingInterval := defaultEventuallyPollingInterval\r\n\tif len(intervals) > 0 {\r\n\t\ttimeoutInterval = toDuration(intervals[0])\r\n\t}\r\n\tif len(intervals) > 1 {\r\n\t\tpollingInterval = toDuration(intervals[1])\r\n\t}\r\n\treturn asyncassertion.New(asyncassertion.AsyncAssertionTypeEventually, actual, globalFailWrapper, timeoutInterval, pollingInterval, offset)\r\n}","code-length":172,"reference":"\/\/ EventuallyWithOffset operates like Eventually but takes an additional\n\/\/ initial argument to indicate an offset in the call stack.  This is useful when building helper\n\/\/ functions that contain matchers.  To learn more, read about `ExpectWithOffset`.","result":"Test the offset .","score":[0.0001,0.0297]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ConsistentlyWithOffset(offset int, actual interface{}, intervals ...interface{}) AsyncAssertion {\r\n\tif globalFailWrapper == nil {\r\n\t\tpanic(nilFailHandlerPanic)\r\n\t}\r\n\ttimeoutInterval := defaultConsistentlyDuration\r\n\tpollingInterval := defaultConsistentlyPollingInterval\r\n\tif len(intervals) > 0 {\r\n\t\ttimeoutInterval = toDuration(intervals[0])\r\n\t}\r\n\tif len(intervals) > 1 {\r\n\t\tpollingInterval = toDuration(intervals[1])\r\n\t}\r\n\treturn asyncassertion.New(asyncassertion.AsyncAssertionTypeConsistently, actual, globalFailWrapper, timeoutInterval, pollingInterval, offset)\r\n}","code-length":173,"reference":"\/\/ ConsistentlyWithOffset operates like Consistnetly but takes an additional\n\/\/ initial argument to indicate an offset in the call stack. This is useful when building helper\n\/\/ functions that contain matchers. To learn more, read about `ExpectWithOffset`.","result":"Test the consistency of the function .","score":[0.0022,0.0294]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *WithT) Expect(actual interface{}, extra ...interface{}) Assertion {\r\n\treturn assertion.New(actual, testingtsupport.BuildTestingTGomegaFailWrapper(g.t), 0, extra...)\r\n}","code-length":63,"reference":"\/\/ Expect is used to make assertions. See documentation for Expect.","result":"Test assertions.","score":[0.0056,0.0495]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *WithT) Eventually(actual interface{}, intervals ...interface{}) AsyncAssertion {\r\n\ttimeoutInterval := defaultEventuallyTimeout\r\n\tpollingInterval := defaultEventuallyPollingInterval\r\n\tif len(intervals) > 0 {\r\n\t\ttimeoutInterval = toDuration(intervals[0])\r\n\t}\r\n\tif len(intervals) > 1 {\r\n\t\tpollingInterval = toDuration(intervals[1])\r\n\t}\r\n\treturn asyncassertion.New(asyncassertion.AsyncAssertionTypeEventually, actual, testingtsupport.BuildTestingTGomegaFailWrapper(g.t), timeoutInterval, pollingInterval, 0)\r\n}","code-length":160,"reference":"\/\/ Eventually is used to make asynchronous assertions. See documentation for Eventually.","result":"Test if the function is not a function.","score":[0.0842,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *WithT) Consistently(actual interface{}, intervals ...interface{}) AsyncAssertion {\r\n\ttimeoutInterval := defaultConsistentlyDuration\r\n\tpollingInterval := defaultConsistentlyPollingInterval\r\n\tif len(intervals) > 0 {\r\n\t\ttimeoutInterval = toDuration(intervals[0])\r\n\t}\r\n\tif len(intervals) > 1 {\r\n\t\tpollingInterval = toDuration(intervals[1])\r\n\t}\r\n\treturn asyncassertion.New(asyncassertion.AsyncAssertionTypeConsistently, actual, testingtsupport.BuildTestingTGomegaFailWrapper(g.t), timeoutInterval, pollingInterval, 0)\r\n}","code-length":161,"reference":"\/\/ Consistently is used to make asynchronous assertions. See documentation for Consistently.","result":"Test if the function is not a function.","score":[0.0842,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc TimeoutCloser(c io.Closer, timeout time.Duration) io.Closer {\r\n\treturn timeoutReaderWriterCloser{c: c, d: timeout}\r\n}","code-length":47,"reference":"\/\/ TimeoutCloser returns an io.Closer that wraps the passed-in io.Closer.  If the underlying Closer fails to close within the alloted timeout ErrTimeout is returned.","result":"Generate the code.","score":[0.0004,0.0228]}
{"code":"\/*is used to<extra_id_0>\r\nfunc TimeoutReader(r io.Reader, timeout time.Duration) io.Reader {\r\n\treturn timeoutReaderWriterCloser{r: r, d: timeout}\r\n}","code-length":47,"reference":"\/\/ TimeoutReader returns an io.Reader that wraps the passed-in io.Reader.  If the underlying Reader fails to read within the alloted timeout ErrTimeout is returned.","result":"Generate the generated code.","score":[0.0022,0.0227]}
{"code":"\/*is used to<extra_id_0>\r\nfunc TimeoutWriter(w io.Writer, timeout time.Duration) io.Writer {\r\n\treturn timeoutReaderWriterCloser{w: w, d: timeout}\r\n}","code-length":47,"reference":"\/\/ TimeoutWriter returns an io.Writer that wraps the passed-in io.Writer.  If the underlying Writer fails to write within the alloted timeout ErrTimeout is returned.","result":"Generate the code.","score":[0.0004,0.0228]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Nest(path string, err error) error {\r\n\tif ag, ok := err.(AggregateError); ok {\r\n\t\tvar errs AggregateError\r\n\t\tfor _, e := range ag {\r\n\t\t\terrs = append(errs, Nest(path, e))\r\n\t\t}\r\n\t\treturn errs\r\n\t}\r\n\tif ne, ok := err.(*NestedError); ok {\r\n\t\treturn &NestedError{\r\n\t\t\tPath: path + ne.Path,\r\n\t\t\tErr:  ne.Err,\r\n\t\t}\r\n\t}\r\n\treturn &NestedError{\r\n\t\tPath: path,\r\n\t\tErr:  err,\r\n\t}\r\n}","code-length":180,"reference":"\/\/ Create a NestedError with the given path.\n\/\/ If err is a NestedError, prepend the path to it.\n\/\/ If err is an AggregateError, recursively Nest each error.","result":"Generate the error tree.","score":[0.0006,0.0189]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetMockService(m *MockService) {\r\n\tm.Cache = &cache.MockAppCacheService{}\r\n\tm.Plan = &app.MockPlanService{}\r\n\tm.Platform = &app.MockPlatformService{}\r\n\tm.PlatformImage = &image.MockPlatformImageService{}\r\n\tm.Team = &auth.MockTeamService{}\r\n\tm.UserQuota = &quota.MockQuotaService{}\r\n\tm.AppQuota = &quota.MockQuotaService{}\r\n\tm.Cluster = &provision.MockClusterService{}\r\n\tm.ServiceBroker = &service.MockServiceBrokerService{}\r\n\tm.ServiceBrokerCatalogCache = &service.MockServiceBrokerCatalogCacheService{}\r\n\tservicemanager.AppCache = m.Cache\r\n\tservicemanager.Plan = m.Plan\r\n\tservicemanager.Platform = m.Platform\r\n\tservicemanager.PlatformImage = m.PlatformImage\r\n\tservicemanager.Team = m.Team\r\n\tservicemanager.UserQuota = m.UserQuota\r\n\tservicemanager.AppQuota = m.AppQuota\r\n\tservicemanager.Cluster = m.Cluster\r\n\tservicemanager.ServiceBroker = m.ServiceBroker\r\n\tservicemanager.ServiceBrokerCatalogCache = m.ServiceBrokerCatalogCache\r\n}","code-length":301,"reference":"\/\/ SetMockService return a new MockService and set as a servicemanager","result":"Set the mock service .","score":[0,0.0481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FindMachineByIdOrAddress(id string, address string) (Machine, error) {\r\n\tcoll, err := collection()\r\n\tif err != nil {\r\n\t\treturn Machine{}, err\r\n\t}\r\n\tdefer coll.Close()\r\n\tvar result Machine\r\n\tquery := bson.M{}\r\n\tif id != \"\" {\r\n\t\tquery[\"_id\"] = id\r\n\t} else {\r\n\t\tquery[\"address\"] = address\r\n\t}\r\n\terr = coll.Find(query).One(&result)\r\n\tif err == mgo.ErrNotFound {\r\n\t\terr = ErrMachineNotFound\r\n\t}\r\n\treturn result, err\r\n}","code-length":170,"reference":"\/\/ Uses id or address, this is only used because previously we didn't have\n\/\/ iaas-id in node metadata.","result":"Find a machine by id or address.","score":[0.0411,0.1053]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *FlushingWriter) Write(data []byte) (written int, err error) {\r\n\tw.writeMutex.Lock()\r\n\tdefer w.writeMutex.Unlock()\r\n\tw.wrote = true\r\n\twritten, err = w.ResponseWriter.Write(data)\r\n\tif err != nil {\r\n\t\treturn\r\n\t}\r\n\tif f, ok := w.ResponseWriter.(http.Flusher); ok {\r\n\t\tdefer func() {\r\n\t\t\tif r := recover(); r != nil {\r\n\t\t\t\tmsg := fmt.Sprintf(\"Error recovered on flushing writer: %#v\", r)\r\n\t\t\t\tlog.Debugf(msg)\r\n\t\t\t\terr = errors.Errorf(msg)\r\n\t\t\t}\r\n\t\t}()\r\n\t\tf.Flush()\r\n\t}\r\n\treturn\r\n}","code-length":211,"reference":"\/\/ Write writes and flushes the data.","result":"Write to the responseWriter.","score":[0.1795,0.1493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *FlushingWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\r\n\tif hijacker, ok := w.ResponseWriter.(http.Hijacker); ok {\r\n\t\treturn hijacker.Hijack()\r\n\t}\r\n\treturn nil, nil, errors.New(\"cannot hijack connection\")\r\n}","code-length":95,"reference":"\/\/ Hijack will hijack the underlying TCP connection, if available in the\n\/\/ ResponseWriter.","result":"Avoid the need for the hijack function.","score":[0.0782,0.1128]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ListDeploys(filter *Filter, skip, limit int) ([]DeployData, error) {\r\n\tappsList, err := List(filter)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tapps := make([]string, len(appsList))\r\n\tfor i, a := range appsList {\r\n\t\tapps[i] = a.GetName()\r\n\t}\r\n\tevts, err := event.List(&event.Filter{\r\n\t\tTarget:    event.Target{Type: event.TargetTypeApp},\r\n\t\tRaw:       bson.M{\"target.value\": bson.M{\"$in\": apps}},\r\n\t\tKindNames: []string{permission.PermAppDeploy.FullName()},\r\n\t\tKindType:  event.KindTypePermission,\r\n\t\tLimit:     limit,\r\n\t\tSkip:      skip,\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvalidImages, err := findValidImages(appsList...)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tlist := make([]DeployData, len(evts))\r\n\tfor i := range evts {\r\n\t\tlist[i] = *eventToDeployData(&evts[i], validImages, false)\r\n\t}\r\n\treturn list, nil\r\n}","code-length":345,"reference":"\/\/ ListDeploys returns the list of deploy that match a given filter.","result":"List all the apps that have deploy permission.","score":[0.1109,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *DelayedRouter) AddAll(version, path string, h http.Handler) *mux.Route {\r\n\treturn r.addRoute(version, path, h, \"GET\", \"POST\", \"PUT\", \"DELETE\")\r\n}","code-length":65,"reference":"\/\/ AddAll binds a path to GET, POST, PUT and DELETE methods.","result":"Add routes to the router.","score":[0.0593,0.0442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc samlRequestTimeout(schemeData map[string]string) int {\r\n\tp := schemeData[\"request_timeout\"]\r\n\ttimeout, _ := strconv.Atoi(p)\r\n\treturn timeout\r\n}","code-length":58,"reference":"\/\/Return timeout in seconds","result":"Set the default timeout.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterHandler(path string, method string, h http.Handler) {\r\n\tRegisterHandlerVersion(\"1.0\", path, method, h)\r\n}","code-length":45,"reference":"\/\/ RegisterHandler inserts a handler on a list of handlers for version 1.0","result":"Register handlers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterHandlerVersion(version, path, method string, h http.Handler) {\r\n\tvar th TsuruHandler\r\n\tth.version = version\r\n\tth.path = path\r\n\tth.method = method\r\n\tth.h = h\r\n\ttsuruHandlerList = append(tsuruHandlerList, th)\r\n}","code-length":90,"reference":"\/\/ RegisterHandlerVersion inserts a handler on a list of handlers","result":"Register the handler version.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Check(names ...string) []Result {\r\n\tresults := make([]Result, 0, len(checkers))\r\n\tnameSet := set.FromSlice(names)\r\n\tisAll := nameSet.Includes(\"all\")\r\n\tfor _, checker := range checkers {\r\n\t\tif !isAll && !nameSet.Includes(checker.name) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tstartTime := time.Now()\r\n\t\tif err := checker.check(); err != nil && err != ErrDisabledComponent {\r\n\t\t\tresults = append(results, Result{\r\n\t\t\t\tName:     checker.name,\r\n\t\t\t\tStatus:   \"fail - \" + err.Error(),\r\n\t\t\t\tDuration: time.Since(startTime),\r\n\t\t\t})\r\n\t\t} else if err == nil {\r\n\t\t\tresults = append(results, Result{\r\n\t\t\t\tName:     checker.name,\r\n\t\t\t\tStatus:   HealthCheckOK,\r\n\t\t\t\tDuration: time.Since(startTime),\r\n\t\t\t})\r\n\t\t}\r\n\t}\r\n\treturn results\r\n}","code-length":271,"reference":"\/\/ Check check the status of registered checkers matching names and return a\n\/\/ list of results.","result":"Check the component names.","score":[0.0147,0.1194]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DiscoverRepositoryPath(dir string) (string, error) {\r\n\t_, err := os.Stat(dir)\r\n\tif os.IsNotExist(err) {\r\n\t\treturn \"\", ErrRepositoryNotFound\r\n\t}\r\n\tdir = filepath.Join(dir, \".git\")\r\n\tfor dir != \"\/.git\" {\r\n\t\tfi, err := os.Stat(dir)\r\n\t\tif err == nil && fi.IsDir() {\r\n\t\t\treturn dir, nil\r\n\t\t}\r\n\t\tdir = filepath.Join(dir, \"..\", \"..\", \".git\")\r\n\t}\r\n\treturn \"\", ErrRepositoryNotFound\r\n}","code-length":164,"reference":"\/\/ DiscoverRepositoryPath finds the path of the repository from a given\n\/\/ directory. It returns the path to the repository, or an an empty string and\n\/\/ a non-nil error if it can't find the repository.","result":"Discover the repository path.","score":[0.0002,0.0305]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OpenRepository(p string) (*Repository, error) {\r\n\tif !strings.HasSuffix(p, \".git\") && !strings.HasSuffix(p, \".git\/\") {\r\n\t\tp = filepath.Join(p, \".git\")\r\n\t}\r\n\tp = strings.TrimRight(p, \"\/\")\r\n\tfi, err := os.Stat(filepath.Join(p, \"config\"))\r\n\tif err == nil && !fi.IsDir() {\r\n\t\treturn &Repository{path: p}, nil\r\n\t}\r\n\treturn nil, ErrRepositoryNotFound\r\n}","code-length":150,"reference":"\/\/ OpenRepository opens a repository by its filepath. You can use\n\/\/ DiscoverRepositoryPath to discover the repository from any directory, and\n\/\/ use the result of this call as parameter for OpenRepository.\n\/\/\n\/\/ OpenRepository will return an error if the given path does not appear to be\n\/\/ a git repository.","result":"Open a repository.","score":[0.0,0.0318]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Repository) RemoteURL(name string) (string, error) {\r\n\tconfig, err := os.Open(filepath.Join(r.path, \"config\"))\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tdefer config.Close()\r\n\tline := fmt.Sprintf(\"[remote %q]\", name)\r\n\tscanner := bufio.NewScanner(config)\r\n\tscanner.Split(bufio.ScanLines)\r\n\tfor scanner.Scan() {\r\n\t\tif scanner.Text() == line {\r\n\t\t\tscanner.Scan()\r\n\t\t\treturn strings.Split(scanner.Text(), \" = \")[1], nil\r\n\t\t}\r\n\t}\r\n\treturn \"\", errRemoteNotFound{name}\r\n}","code-length":192,"reference":"\/\/ RemoteURL returns the URL of a remote by its name. Or an error, if the\n\/\/ remote is not declared.","result":"Generate the code.","score":[0.001,0.026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *appLister) List(selector labels.Selector) (ret []*v1.App, err error) {\r\n\terr = cache.ListAll(s.indexer, selector, func(m interface{}) {\r\n\t\tret = append(ret, m.(*v1.App))\r\n\t})\r\n\treturn ret, err\r\n}","code-length":91,"reference":"\/\/ List lists all Apps in the indexer.","result":"Filter list of objects.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *appLister) Apps(namespace string) AppNamespaceLister {\r\n\treturn appNamespaceLister{indexer: s.indexer, namespace: namespace}\r\n}","code-length":47,"reference":"\/\/ Apps returns an object that can list and get Apps.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s appNamespaceLister) List(selector labels.Selector) (ret []*v1.App, err error) {\r\n\terr = cache.ListAllByNamespace(s.indexer, s.namespace, selector, func(m interface{}) {\r\n\t\tret = append(ret, m.(*v1.App))\r\n\t})\r\n\treturn ret, err\r\n}","code-length":97,"reference":"\/\/ List lists all Apps in the indexer for a given namespace.","result":"Support nested list operations.","score":[0,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StreamJSONResponse(w io.Writer, response *http.Response) error {\r\n\tif response == nil {\r\n\t\treturn errors.New(\"response cannot be nil\")\r\n\t}\r\n\tdefer response.Body.Close()\r\n\tvar err error\r\n\toutput := tsuruio.NewStreamWriter(w, nil)\r\n\tfor n := int64(1); n > 0 && err == nil; n, err = io.Copy(output, response.Body) {\r\n\t}\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tunparsed := output.Remaining()\r\n\tif len(unparsed) > 0 {\r\n\t\treturn errors.Errorf(\"unparsed message error: %s\", string(unparsed))\r\n\t}\r\n\treturn nil\r\n}","code-length":198,"reference":"\/\/ StreamJSONResponse supports the JSON streaming format from the tsuru API.","result":"Stream JSON responses .","score":[0.0555,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) DropDatabase(name string) error {\r\n\treturn s.session.DB(name).DropDatabase()\r\n}","code-length":41,"reference":"\/\/ DropDatabase drop database of any given name","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) Collection(name string) *Collection {\r\n\treturn &Collection{Collection: s.session.DB(s.dbname).C(name)}\r\n}","code-length":49,"reference":"\/\/ Collection returns a collection by its name.\n\/\/\n\/\/ If the collection does not exist, MongoDB will create it.","result":"Store the collection in a database.","score":[0.0293,0.1374]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Target) SetLogger(l Logger) {\r\n\tt.mut.Lock()\r\n\tdefer t.mut.Unlock()\r\n\tt.logger = l\r\n}","code-length":52,"reference":"\/\/ SetLogger defines a new logger for the current target.\n\/\/\n\/\/ See the builtin log package for more details.","result":"Set the logger.","score":[0.0014,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Target) Error(v error) {\r\n\tt.mut.RLock()\r\n\tdefer t.mut.RUnlock()\r\n\tif t.logger != nil {\r\n\t\tt.logger.Errorf(\"%+v\", v)\r\n\t}\r\n}","code-length":74,"reference":"\/\/ Error writes the given values to the Target\n\/\/ logger.","result":"Set the error on the target.","score":[0.0998,0.1429]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Target) Errorf(format string, v ...interface{}) {\r\n\tt.mut.RLock()\r\n\tdefer t.mut.RUnlock()\r\n\tif t.logger != nil {\r\n\t\tt.logger.Errorf(format, v...)\r\n\t\tfor _, item := range v {\r\n\t\t\tif _, hasStack := item.(withStack); hasStack {\r\n\t\t\t\tt.logger.Errorf(\"stack for error: %+v\", item)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":139,"reference":"\/\/ Errorf writes the formatted string to the Target\n\/\/ logger.","result":"Log errors to the console.","score":[0.1023,0.1803]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Target) Fatal(v string) {\r\n\tt.mut.RLock()\r\n\tdefer t.mut.RUnlock()\r\n\tif t.logger != nil {\r\n\t\tt.logger.Fatal(v)\r\n\t}\r\n}","code-length":71,"reference":"\/\/ Fatal writes the given values to the Target\n\/\/ logger.","result":"Print errors to the console.","score":[0.1023,0.1803]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Target) Debugf(format string, v ...interface{}) {\r\n\tt.mut.RLock()\r\n\tdefer t.mut.RUnlock()\r\n\tif t.logger != nil {\r\n\t\tt.logger.Debugf(format, v...)\r\n\t}\r\n}","code-length":78,"reference":"\/\/ Debugf writes the formatted string to the Target\n\/\/ logger.","result":"Debug the target .","score":[0.0555,0.182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Target) GetStdLogger() *log.Logger {\r\n\tt.mut.RLock()\r\n\tdefer t.mut.RUnlock()\r\n\tif t.logger != nil {\r\n\t\treturn t.logger.GetStdLogger()\r\n\t}\r\n\treturn nil\r\n}","code-length":80,"reference":"\/\/ GetStdLogger returns a standard Logger instance\n\/\/ useful for configuring log in external packages.","result":"Get the std logger for the target.","score":[0.0515,0.0704]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterClient) Namespace() string {\r\n\tif c.CustomData != nil && c.CustomData[namespaceClusterKey] != \"\" {\r\n\t\treturn c.CustomData[namespaceClusterKey]\r\n\t}\r\n\treturn \"tsuru\"\r\n}","code-length":73,"reference":"\/\/ Namespace returns the namespace to be used by Custom Resources","result":"Get the cluster namespace.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc recreateContainers(p DockerProvisioner, w io.Writer, nodes ...cluster.Node) error {\r\n\treturn ensureContainersStarted(p, w, true, nil, nodes...)\r\n}","code-length":51,"reference":"\/\/ recreateContainers relaunch all node containers in the cluster for the given\n\/\/ DockerProvisioner, logging progress to the given writer.\n\/\/\n\/\/ It assumes that the given writer is thread safe.","result":"Generate the generated code.","score":[0.0004,0.0177]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkProvisioner() error {\r\n\tif value, _ := config.Get(\"provisioner\"); value == defaultProvisionerName || value == \"\" {\r\n\t\treturn checkDocker()\r\n\t}\r\n\treturn nil\r\n}","code-length":60,"reference":"\/\/ Check provisioner configs","result":"Check the provisioner.","score":[0.2925,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkDocker() error {\r\n\tif _, err := config.Get(\"docker\"); err != nil {\r\n\t\treturn errors.New(\"Config error: you should configure docker.\")\r\n\t}\r\n\terr := checkDockerBasicConfig()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = checkScheduler()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = checkRouter()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn checkCluster()\r\n}","code-length":145,"reference":"\/\/ Check Docker configs","result":"Check the docker configuration.","score":[0.3195,0.25]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkScheduler() error {\r\n\tif servers, err := config.Get(\"docker:servers\"); err == nil && servers != nil {\r\n\t\treturn errors.Errorf(`Using docker:servers is deprecated, please remove it your config and use \"tsuru docker-node-add\" do add docker nodes.`)\r\n\t}\r\n\tisSegregate, err := config.GetBool(\"docker:segregate\")\r\n\tif err == nil {\r\n\t\tif isSegregate {\r\n\t\t\treturn config.NewWarning(`Setting \"docker:segregate\" is not necessary anymore, this is the default behavior from now on.`)\r\n\t\t} else {\r\n\t\t\treturn errors.Errorf(`You must remove \"docker:segregate\" from your config.`)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":205,"reference":"\/\/ Check Schedulers\n\/\/ It verifies your scheduler configuration and validates related confs.","result":"Check scheduler.","score":[0.002,0.042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkRouter() error {\r\n\tdefaultRouter, _ := config.GetString(\"docker:router\")\r\n\tif defaultRouter == \"\" {\r\n\t\treturn errors.Errorf(`You must configure a default router in \"docker:router\".`)\r\n\t}\r\n\tisHipacheOld := false\r\n\tif defaultRouter == \"hipache\" {\r\n\t\thipacheOld, _ := config.Get(\"hipache\")\r\n\t\tisHipacheOld = hipacheOld != nil\r\n\t}\r\n\trouterConf, _ := config.Get(\"routers:\" + defaultRouter)\r\n\tif isHipacheOld {\r\n\t\treturn config.NewWarning(`Setting \"hipache:*\" config entries is deprecated. You should configure your router with \"routers:*\". See http:\r\n\t}\r\n\tif routerConf == nil {\r\n\t\treturn errors.Errorf(`You must configure your default router %q in \"routers:%s\".`, defaultRouter, defaultRouter)\r\n\t}\r\n\trouterType, _ := config.Get(\"routers:\" + defaultRouter + \":type\")\r\n\tif routerType == nil {\r\n\t\treturn errors.Errorf(`You must configure your default router type in \"routers:%s:type\".`, defaultRouter)\r\n\t}\r\n\treturn nil\r\n}","code-length":314,"reference":"\/\/ Check Router\n\/\/ It verifies your router configuration and validates related confs.","result":"Check the default router configuration.","score":[0.0577,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *Unit) Available() bool {\r\n\treturn u.Status == StatusStarted ||\r\n\t\tu.Status == StatusStarting ||\r\n\t\tu.Status == StatusError\r\n}","code-length":54,"reference":"\/\/ Available returns true if the unit is available. It will return true\n\/\/ whenever the unit itself is available, even when the application process is\n\/\/ not.","result":"Check if unit is available.","score":[0.0053,0.0778]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Get(name string) (Provisioner, error) {\r\n\tpFunc, ok := provisioners[name]\r\n\tif !ok {\r\n\t\treturn nil, errors.Errorf(\"unknown provisioner: %q\", name)\r\n\t}\r\n\treturn pFunc()\r\n}","code-length":75,"reference":"\/\/ Get gets the named provisioner from the registry.","result":"Get a provisioner.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Registry() ([]Provisioner, error) {\r\n\tregistry := make([]Provisioner, 0, len(provisioners))\r\n\tfor _, pFunc := range provisioners {\r\n\t\tp, err := pFunc()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tregistry = append(registry, p)\r\n\t}\r\n\treturn registry, nil\r\n}","code-length":108,"reference":"\/\/ Registry returns the list of registered provisioners.","result":"Create a registry .","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Error) Error() string {\r\n\tvar err string\r\n\tif e.Err != nil {\r\n\t\terr = e.Err.Error() + \": \" + e.Reason\r\n\t} else {\r\n\t\terr = e.Reason\r\n\t}\r\n\treturn err\r\n}","code-length":81,"reference":"\/\/ Error is the string representation of a provisioning error.","result":"Generate the error message.","score":[0.0713,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc validateVersion(supported, current string) bool {\r\n\tif supported == \"\" {\r\n\t\treturn true\r\n\t}\r\n\tvSupported, err := goVersion.NewVersion(supported)\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\tvCurrent, err := goVersion.NewVersion(current)\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\treturn vCurrent.Compare(vSupported) >= 0\r\n}","code-length":123,"reference":"\/\/ validateVersion checks whether current version is greater or equal to\n\/\/ supported version.","result":"Validate the version of the library.","score":[0.0509,0.0379]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReadTarget() (string, error) {\r\n\tif target := os.Getenv(\"TSURU_TARGET\"); target != \"\" {\r\n\t\ttargets, err := getTargets()\r\n\t\tif err == nil {\r\n\t\t\tif val, ok := targets[target]; ok {\r\n\t\t\t\treturn val, nil\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn target, nil\r\n\t}\r\n\ttargetPath := JoinWithUserDir(\".tsuru\", \"target\")\r\n\ttarget, err := readTarget(targetPath)\r\n\tif err == errUndefinedTarget {\r\n\t\tcopyTargetFiles()\r\n\t\ttarget, err = readTarget(JoinWithUserDir(\".tsuru_target\"))\r\n\t}\r\n\treturn target, err\r\n}","code-length":193,"reference":"\/\/ ReadTarget returns the current target, as defined in the TSURU_TARGET\n\/\/ environment variable or in the target file.","result":"Read the target file.","score":[0.0155,0.1683]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WriteTarget(t string) error {\r\n\ttargetPath := JoinWithUserDir(\".tsuru\", \"target\")\r\n\ttargetFile, err := filesystem().OpenFile(targetPath, syscall.O_WRONLY|syscall.O_CREAT|syscall.O_TRUNC, 0600)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer targetFile.Close()\r\n\tn, err := targetFile.WriteString(t)\r\n\tif n != len(t) || err != nil {\r\n\t\treturn errors.New(\"Failed to write the target file\")\r\n\t}\r\n\treturn nil\r\n}","code-length":162,"reference":"\/\/ WriteTarget writes the given endpoint to the target file.","result":"Write the target file.","score":[0.1468,0.3989]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WriteOnTargetList(label, target string) error {\r\n\tlabel = strings.TrimSpace(label)\r\n\ttarget = strings.TrimSpace(target)\r\n\ttargetExist, err := CheckIfTargetLabelExists(label)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif targetExist {\r\n\t\treturn errors.New(\"Target label provided already exists\")\r\n\t}\r\n\ttargetsPath := JoinWithUserDir(\".tsuru\", \"targets\")\r\n\ttargetsFile, err := filesystem().OpenFile(targetsPath, syscall.O_RDWR|syscall.O_CREAT|syscall.O_APPEND, 0600)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer targetsFile.Close()\r\n\tcontent := label + \"\\t\" + target + \"\\n\"\r\n\tn, err := targetsFile.WriteString(content)\r\n\tif n != len(content) || err != nil {\r\n\t\treturn errors.New(\"Failed to write the target file\")\r\n\t}\r\n\treturn nil\r\n}","code-length":267,"reference":"\/\/ WriteOnTargetList writes the given target in the target list file.","result":"Write on target list.","score":[0.0555,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Conn() (*Storage, error) {\r\n\tvar (\r\n\t\tstrg Storage\r\n\t\terr  error\r\n\t)\r\n\turl, dbname := DbConfig(\"\")\r\n\tstrg.Storage, err = storage.Open(url, dbname)\r\n\treturn &strg, err\r\n}","code-length":83,"reference":"\/\/ Conn reads the tsuru config and calls storage.Open to get a database connection.\n\/\/\n\/\/ Most tsuru packages should probably use this function. storage.Open is intended for\n\/\/ use when supporting more than one database.","result":"Connect to the database.","score":[0.0001,0.0457]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) Apps() *storage.Collection {\r\n\tnameIndex := mgo.Index{Key: []string{\"name\"}, Unique: true}\r\n\tc := s.Collection(\"apps\")\r\n\tc.EnsureIndex(nameIndex)\r\n\treturn c\r\n}","code-length":75,"reference":"\/\/ Apps returns the apps collection from MongoDB.","result":"Store the app collection.","score":[0.1175,0.2467]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) PoolsConstraints() *storage.Collection {\r\n\tpoolConstraintIndex := mgo.Index{Key: []string{\"poolexpr\", \"field\"}, Unique: true}\r\n\tc := s.Collection(\"pool_constraints\")\r\n\tc.EnsureIndex(poolConstraintIndex)\r\n\treturn c\r\n}","code-length":86,"reference":"\/\/ PoolsConstraints return the pool constraints collection.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) Users() *storage.Collection {\r\n\temailIndex := mgo.Index{Key: []string{\"email\"}, Unique: true}\r\n\tc := s.Collection(\"users\")\r\n\tc.EnsureIndex(emailIndex)\r\n\treturn c\r\n}","code-length":74,"reference":"\/\/ Users returns the users collection from MongoDB.","result":"Store the users collection.","score":[0.1662,0.2467]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) SAMLRequests() *storage.Collection {\r\n\tid := mgo.Index{Key: []string{\"id\"}}\r\n\tcoll := s.Collection(\"saml_requests\")\r\n\tcoll.EnsureIndex(id)\r\n\treturn coll\r\n}","code-length":71,"reference":"\/\/ SAMLRequests returns the saml_requests from MongoDB.","result":"Store SAML requests.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *LogStorage) AppLogCollection(appName string) *storage.Collection {\r\n\tif appName == \"\" {\r\n\t\treturn nil\r\n\t}\r\n\treturn s.Collection(\"logs_\" + appName)\r\n}","code-length":63,"reference":"\/\/ AppLogCollection returns the logs collection for one app from MongoDB.","result":"Generate code for generated code.","score":[0.0724,0.0481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *LogStorage) CreateAppLogCollection(appName string) (*storage.Collection, error) {\r\n\tc := s.AppLogCollection(appName)\r\n\terr := c.Create(&logCappedInfo)\r\n\treturn c, err\r\n}","code-length":73,"reference":"\/\/ CreateAppLogCollection creates a new capped collection to store logs for an app.","result":"Create a new log collection.","score":[0.0686,0.3074]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *LogStorage) LogsCollections() ([]*storage.Collection, error) {\r\n\tvar names []struct {\r\n\t\tName string\r\n\t}\r\n\tconn, err := Conn()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer conn.Close()\r\n\terr = conn.Apps().Find(nil).All(&names)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar colls []*storage.Collection\r\n\tfor _, name := range names {\r\n\t\tcolls = append(colls, s.Collection(\"logs_\"+name.Name))\r\n\t}\r\n\treturn colls, nil\r\n}","code-length":181,"reference":"\/\/ LogsCollections returns logs collections for all apps from MongoDB.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ArchiveBuildCmds(app provision.App, archiveURL string) []string {\r\n\treturn buildCmds(app, \"build\", \"archive\", archiveURL)\r\n}","code-length":49,"reference":"\/\/ ArchiveBuildCmds build a image using the archive method.","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ArchiveDeployCmds(app provision.App, archiveURL string) []string {\r\n\treturn buildCmds(app, \"deploy\", \"archive\", archiveURL)\r\n}","code-length":49,"reference":"\/\/ ArchiveDeployCmds is a legacy command to deploys an unit using the archive method.","result":"Generate the generated code.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DeployCmds(app provision.App) []string {\r\n\tuaCmds := unitAgentCmds(app)\r\n\tuaCmds = append(uaCmds, \"deploy-only\")\r\n\tfinalCmd := strings.Join(uaCmds, \" \")\r\n\treturn []string{\"\/bin\/sh\", \"-lc\", finalCmd}\r\n}","code-length":91,"reference":"\/\/ DeployCmds deploys an unit builded by tsuru.","result":"Deploy only app.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc runWithAgentCmds(app provision.App) ([]string, error) {\r\n\trunCmd, err := config.GetString(\"docker:run-cmd:bin\")\r\n\tif err != nil {\r\n\t\trunCmd = \"\/var\/lib\/tsuru\/start\"\r\n\t}\r\n\thost, _ := config.GetString(\"host\")\r\n\ttoken := app.Envs()[\"TSURU_APP_TOKEN\"].Value\r\n\treturn []string{\"tsuru_unit_agent\", host, token, app.GetName(), runCmd}, nil\r\n}","code-length":145,"reference":"\/\/ runWithAgentCmds returns the list of commands that should be passed when the\n\/\/ provisioner will run a unit using tsuru_unit_agent to start.\n\/\/\n\/\/ This will only be called for legacy containers that have not been re-\n\/\/ deployed since the introduction of independent units per 'process' in\n\/\/ 0.12.0.","result":"Run unit agent .","score":[0.0,0.0216]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newApps(c *TsuruV1Client, namespace string) *apps {\r\n\treturn &apps{\r\n\t\tclient: c.RESTClient(),\r\n\t\tns:     namespace,\r\n\t}\r\n}","code-length":62,"reference":"\/\/ newApps returns a Apps","result":"Create new apps.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Container) Commit(client provision.BuilderDockerClient, limiter provision.ActionLimiter, writer io.Writer, isDeploy bool) (string, error) {\r\n\tlog.Debugf(\"committing container %s\", c.ID)\r\n\trepository, tag := image.SplitImageName(c.BuildingImage)\r\n\topts := docker.CommitContainerOptions{Container: c.ID, Repository: repository, Tag: tag}\r\n\tdone := limiter.Start(c.HostAddr)\r\n\timage, err := client.CommitContainer(opts)\r\n\tdone()\r\n\tif err != nil {\r\n\t\treturn \"\", log.WrapError(errors.Wrapf(err, \"error in commit container %s\", c.ID))\r\n\t}\r\n\ttags := []string{tag}\r\n\tif isDeploy && tag != \"latest\" {\r\n\t\ttags = append(tags, \"latest\")\r\n\t\terr = client.TagImage(fmt.Sprintf(\"%s:%s\", repository, tag), docker.TagImageOptions{\r\n\t\t\tRepo:  repository,\r\n\t\t\tTag:   \"latest\",\r\n\t\t\tForce: true,\r\n\t\t})\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", log.WrapError(errors.Wrapf(err, \"error in tag container %s\", c.ID))\r\n\t\t}\r\n\t}\r\n\timgHistory, err := client.ImageHistory(c.BuildingImage)\r\n\timgSize := \"\"\r\n\tif err == nil && len(imgHistory) > 0 {\r\n\t\tfullSize := imgHistory[0].Size\r\n\t\tif len(imgHistory) > 1 && strings.Contains(imgHistory[1].CreatedBy, \"tail -f \/dev\/null\") {\r\n\t\t\tfullSize += imgHistory[1].Size\r\n\t\t}\r\n\t\timgSize = fmt.Sprintf(\"(%.02fMB)\", float64(fullSize)\/1024\/1024)\r\n\t}\r\n\tfmt.Fprintf(writer, \" ---> Sending image to repository %s\\n\", imgSize)\r\n\tlog.Debugf(\"image %s generated from container %s\", image.ID, c.ID)\r\n\tfor _, tag := range tags {\r\n\t\tmaxTry, _ := config.GetInt(\"docker:registry-max-try\")\r\n\t\tif maxTry <= 0 {\r\n\t\t\tmaxTry = 3\r\n\t\t}\r\n\t\tfor i := 0; i < maxTry; i++ {\r\n\t\t\terr = dockercommon.PushImage(client, repository, tag, dockercommon.RegistryAuthConfig(repository))\r\n\t\t\tif err != nil {\r\n\t\t\t\tfmt.Fprintf(writer, \"Could not send image, trying again. Original error: %s\\n\", err.Error())\r\n\t\t\t\tlog.Errorf(\"error in push image %s: %s\", c.BuildingImage, err)\r\n\t\t\t\ttime.Sleep(time.Second)\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", log.WrapError(errors.Wrapf(err, \"error in push image %s\", c.BuildingImage))\r\n\t\t}\r\n\t}\r\n\treturn c.BuildingImage, nil\r\n}","code-length":777,"reference":"\/\/ Commits commits the container, creating an image in Docker. It then returns\n\/\/ the image identifier for usage in future container creation.","result":"Code too long,keep in 512.","score":[0.0066,0.0236]}
{"code":"\/*is used to<extra_id_0>\r\nfunc processTags(tags []string) []string {\r\n\tif tags == nil {\r\n\t\treturn nil\r\n\t}\r\n\tprocessedTags := []string{}\r\n\tusedTags := make(map[string]bool)\r\n\tfor _, tag := range tags {\r\n\t\ttag = strings.TrimSpace(tag)\r\n\t\tif len(tag) > 0 && !usedTags[tag] {\r\n\t\t\tprocessedTags = append(processedTags, tag)\r\n\t\t\tusedTags[tag] = true\r\n\t\t}\r\n\t}\r\n\treturn processedTags\r\n}","code-length":147,"reference":"\/\/ processTags removes duplicates and trims spaces from each tag","result":"Process tags.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *segregatedScheduler) aggregateContainersBy(matcher bson.M) (map[string]int, error) {\r\n\tcoll := s.provisioner.Collection()\r\n\tdefer coll.Close()\r\n\tpipe := coll.Pipe([]bson.M{\r\n\t\tmatcher,\r\n\t\t{\"$group\": bson.M{\"_id\": \"$hostaddr\", \"count\": bson.M{\"$sum\": 1}}},\r\n\t})\r\n\tvar results []nodeAggregate\r\n\terr := pipe.All(&results)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tcountMap := make(map[string]int)\r\n\tfor _, result := range results {\r\n\t\tcountMap[result.HostAddr] = result.Count\r\n\t}\r\n\treturn countMap, nil\r\n}","code-length":210,"reference":"\/\/ aggregateContainersBy aggregates and counts how many containers\n\/\/ exist each node that matches received filters","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *segregatedScheduler) chooseNodeToAdd(nodes []cluster.Node, contName string, appName, process string) (string, error) {\r\n\tlog.Debugf(\"[scheduler] Possible nodes for container %s: %#v\", contName, nodes)\r\n\ts.hostMutex.Lock()\r\n\tdefer s.hostMutex.Unlock()\r\n\tchosenNode, _, err := s.minMaxNodes(nodes, appName, process)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tlog.Debugf(\"[scheduler] Chosen node for container %s: %#v\", contName, chosenNode)\r\n\tif contName != \"\" {\r\n\t\tcoll := s.provisioner.Collection()\r\n\t\tdefer coll.Close()\r\n\t\terr = coll.Update(bson.M{\"name\": contName}, bson.M{\"$set\": bson.M{\"hostaddr\": net.URLToHost(chosenNode)}})\r\n\t}\r\n\treturn chosenNode, err\r\n}","code-length":251,"reference":"\/\/ chooseNodeToAdd finds which is the node with the minimum number of containers\n\/\/ and returns it","result":"Avoid the need for the following code.","score":[0.046,0.0625]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *segregatedScheduler) chooseContainerToRemove(nodes []cluster.Node, appName, process string) (string, error) {\r\n\t_, chosenNode, err := s.minMaxNodes(nodes, appName, process)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tlog.Debugf(\"[scheduler] Chosen node for remove a container: %#v\", chosenNode)\r\n\tcontainerID, err := s.getContainerPreferablyFromHost(chosenNode, appName, process)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn containerID, err\r\n}","code-length":160,"reference":"\/\/ chooseContainerToRemove finds a container from the the node with maximum\n\/\/ number of containers and returns it","result":"Generate code for the generated code.","score":[0.0261,0.0298]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Get(name string) (Router, error) {\r\n\trouterType, prefix, err := Type(name)\r\n\tif err != nil {\r\n\t\treturn nil, &ErrRouterNotFound{Name: name}\r\n\t}\r\n\tfactory, ok := routers[routerType]\r\n\tif !ok {\r\n\t\treturn nil, errors.Errorf(\"unknown router: %q.\", routerType)\r\n\t}\r\n\tr, err := factory(name, prefix)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn r, nil\r\n}","code-length":150,"reference":"\/\/ Get gets the named router from the registry.","result":"Get the router by name.","score":[0.1421,0.1744]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Default() (string, error) {\r\n\tplans, err := List()\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tif len(plans) == 0 {\r\n\t\treturn \"\", ErrDefaultRouterNotFound\r\n\t}\r\n\tif len(plans) == 1 {\r\n\t\treturn plans[0].Name, nil\r\n\t}\r\n\tfor _, p := range plans {\r\n\t\tif p.Default {\r\n\t\t\treturn p.Name, nil\r\n\t\t}\r\n\t}\r\n\treturn \"\", ErrDefaultRouterNotFound\r\n}","code-length":152,"reference":"\/\/ Default returns the default router","result":"Generate the default router .","score":[0.4052,0.4991]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Store(appName, routerName, kind string) error {\r\n\tcoll, err := collection()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer coll.Close()\r\n\tdata := routerAppEntry{\r\n\t\tApp:    appName,\r\n\t\tRouter: routerName,\r\n\t\tKind:   kind,\r\n\t}\r\n\t_, err = coll.Upsert(bson.M{\"app\": appName}, data)\r\n\treturn err\r\n}","code-length":128,"reference":"\/\/ Store stores the app name related with the\n\/\/ router name.","result":"Store the router app entry.","score":[0.0838,0.177]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Clientset) TsuruV1() tsuruv1.TsuruV1Interface {\r\n\treturn &faketsuruv1.FakeTsuruV1{Fake: &c.Fake}\r\n}","code-length":63,"reference":"\/\/ TsuruV1 retrieves the TsuruV1Client","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Clientset) Tsuru() tsuruv1.TsuruV1Interface {\r\n\treturn &faketsuruv1.FakeTsuruV1{Fake: &c.Fake}\r\n}","code-length":61,"reference":"\/\/ Tsuru retrieves the TsuruV1Client","result":"Create a new client.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewAppInformer(client versioned.Interface, namespace string, resyncPeriod time.Duration, indexers cache.Indexers) cache.SharedIndexInformer {\r\n\treturn NewFilteredAppInformer(client, namespace, resyncPeriod, indexers, nil)\r\n}","code-length":63,"reference":"\/\/ NewAppInformer constructs a new informer for App type.\n\/\/ Always prefer using an informer factory to get a shared informer instead of getting an independent\n\/\/ one. This reduces memory footprint and number of connections to the server.","result":"Create a new app informer.","score":[0.0004,0.0421]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFilteredAppInformer(client versioned.Interface, namespace string, resyncPeriod time.Duration, indexers cache.Indexers, tweakListOptions internalinterfaces.TweakListOptionsFunc) cache.SharedIndexInformer {\r\n\treturn cache.NewSharedIndexInformer(\r\n\t\t&cache.ListWatch{\r\n\t\t\tListFunc: func(options meta_v1.ListOptions) (runtime.Object, error) {\r\n\t\t\t\tif tweakListOptions != nil {\r\n\t\t\t\t\ttweakListOptions(&options)\r\n\t\t\t\t}\r\n\t\t\t\treturn client.TsuruV1().Apps(namespace).List(options)\r\n\t\t\t},\r\n\t\t\tWatchFunc: func(options meta_v1.ListOptions) (watch.Interface, error) {\r\n\t\t\t\tif tweakListOptions != nil {\r\n\t\t\t\t\ttweakListOptions(&options)\r\n\t\t\t\t}\r\n\t\t\t\treturn client.TsuruV1().Apps(namespace).Watch(options)\r\n\t\t\t},\r\n\t\t},\r\n\t\t&tsuru_v1.App{},\r\n\t\tresyncPeriod,\r\n\t\tindexers,\r\n\t)\r\n}","code-length":268,"reference":"\/\/ NewFilteredAppInformer constructs a new informer for App type.\n\/\/ Always prefer using an informer factory to get a shared informer instead of getting an independent\n\/\/ one. This reduces memory footprint and number of connections to the server.","result":"Test if the app is not yet created.","score":[0.0029,0.0279]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *FakeApps) Watch(opts v1.ListOptions) (watch.Interface, error) {\r\n\treturn c.Fake.\r\n\t\tInvokesWatch(testing.NewWatchAction(appsResource, c.ns, opts))\r\n}","code-length":66,"reference":"\/\/ Watch returns a watch.Interface that watches the requested apps.","result":"Test if watch is supported by the.","score":[0,0.0515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *FakeApps) Patch(name string, pt types.PatchType, data []byte, subresources ...string) (result *tsuru_v1.App, err error) {\r\n\tobj, err := c.Fake.\r\n\t\tInvokes(testing.NewPatchSubresourceAction(appsResource, c.ns, name, data, subresources...), &tsuru_v1.App{})\r\n\tif obj == nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn obj.(*tsuru_v1.App), err\r\n}","code-length":144,"reference":"\/\/ Patch applies the patch and returns the patched app.","result":"Test if the object is not nil.","score":[0.1052,0.0515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSharedInformerFactory(client versioned.Interface, defaultResync time.Duration) SharedInformerFactory {\r\n\treturn NewFilteredSharedInformerFactory(client, defaultResync, v1.NamespaceAll, nil)\r\n}","code-length":58,"reference":"\/\/ NewSharedInformerFactory constructs a new instance of sharedInformerFactory","result":"Create a new shared informer.","score":[0.1865,0.2435]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFilteredSharedInformerFactory(client versioned.Interface, defaultResync time.Duration, namespace string, tweakListOptions internalinterfaces.TweakListOptionsFunc) SharedInformerFactory {\r\n\treturn &sharedInformerFactory{\r\n\t\tclient:           client,\r\n\t\tnamespace:        namespace,\r\n\t\ttweakListOptions: tweakListOptions,\r\n\t\tdefaultResync:    defaultResync,\r\n\t\tinformers:        make(map[reflect.Type]cache.SharedIndexInformer),\r\n\t\tstartedInformers: make(map[reflect.Type]bool),\r\n\t}\r\n}","code-length":146,"reference":"\/\/ NewFilteredSharedInformerFactory constructs a new instance of sharedInformerFactory.\n\/\/ Listers obtained via this SharedInformerFactory will be subject to the same filters\n\/\/ as specified here.","result":"Create a shared informer factory.","score":[0.0044,0.0217]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *brokerClient) Proxy(path string, evt *event.Event, requestID string, w http.ResponseWriter, r *http.Request) error {\r\n\treturn fmt.Errorf(\"service proxy is not available for broker services\")\r\n}","code-length":65,"reference":"\/\/ Proxy is not implemented for OSB API implementations","result":"Proxy service proxy.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *brokerClient) UnbindUnit(instance *ServiceInstance, app bind.App, unit bind.Unit) error {\r\n\treturn nil\r\n}","code-length":44,"reference":"\/\/ UnbindUnit is a no-op for OSB API implementations","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *planService) Create(plan appTypes.Plan) error {\r\n\tif plan.Name == \"\" {\r\n\t\treturn appTypes.PlanValidationError{Field: \"name\"}\r\n\t}\r\n\tif plan.CpuShare < 2 {\r\n\t\treturn appTypes.ErrLimitOfCpuShare\r\n\t}\r\n\tif plan.Memory > 0 && plan.Memory < 4194304 {\r\n\t\treturn appTypes.ErrLimitOfMemory\r\n\t}\r\n\treturn s.storage.Insert(plan)\r\n}","code-length":135,"reference":"\/\/ Create implements Create method of PlanService interface","result":"Create a new plan.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *planService) Remove(planName string) error {\r\n\treturn s.storage.Delete(appTypes.Plan{Name: planName})\r\n}","code-length":47,"reference":"\/\/ Remove implements Remove method of PlanService interface","result":"Remove a plan.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *planService) ensureDefault() error {\r\n\tplans, err := s.storage.FindAll()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif len(plans) > 0 {\r\n\t\treturn nil\r\n\t}\r\n\tconfigMemory, _ := config.GetInt(\"docker:memory\")\r\n\tconfigSwap, _ := config.GetInt(\"docker:swap\")\r\n\tdp := appTypes.Plan{\r\n\t\tName:     \"autogenerated\",\r\n\t\tMemory:   int64(configMemory) * 1024 * 1024,\r\n\t\tSwap:     int64(configSwap-configMemory) * 1024 * 1024,\r\n\t\tCpuShare: 100,\r\n\t\tDefault:  true,\r\n\t}\r\n\treturn s.storage.Insert(dp)\r\n}","code-length":206,"reference":"\/\/ ensureDefault creates and stores an autogenerated plan in case of no plans\n\/\/ exists.","result":"Generate code for the plan.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DeleteInstance(si *ServiceInstance, evt *event.Event, requestID string) error {\r\n\tif len(si.Apps) > 0 {\r\n\t\treturn ErrServiceInstanceBound\r\n\t}\r\n\ts, err := Get(si.ServiceName)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tendpoint, err := s.getClient(\"production\")\r\n\tif err == nil {\r\n\t\tendpoint.Destroy(si, evt, requestID)\r\n\t}\r\n\tconn, err := db.Conn()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer conn.Close()\r\n\treturn conn.ServiceInstances().Remove(bson.M{\"name\": si.Name, \"service_name\": si.ServiceName})\r\n}","code-length":197,"reference":"\/\/ DeleteInstance deletes the service instance from the database.","result":"Delete service instance.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (si *ServiceInstance) ToInfo() (ServiceInstanceWithInfo, error) {\r\n\tinfo, err := si.Info(\"\")\r\n\tif err != nil {\r\n\t\tinfo = nil\r\n\t}\r\n\treturn ServiceInstanceWithInfo{\r\n\t\tId:          si.Id,\r\n\t\tName:        si.Name,\r\n\t\tTeams:       si.Teams,\r\n\t\tPlanName:    si.PlanName,\r\n\t\tApps:        si.Apps,\r\n\t\tServiceName: si.ServiceName,\r\n\t\tInfo:        info,\r\n\t\tTeamOwner:   si.TeamOwner,\r\n\t}, nil\r\n}","code-length":164,"reference":"\/\/ ToInfo returns the service instance as a struct compatible with the return\n\/\/ of the service info api call.","result":"Generate the service instance info.","score":[0.0246,0.1381]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (si *ServiceInstance) Update(service Service, updateData ServiceInstance, evt *event.Event, requestID string) error {\r\n\terr := validateServiceInstanceTeamOwner(updateData)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tconn, err := db.Conn()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer conn.Close()\r\n\ttags := processTags(updateData.Tags)\r\n\tif tags == nil {\r\n\t\tupdateData.Tags = si.Tags\r\n\t} else {\r\n\t\tupdateData.Tags = tags\r\n\t}\r\n\tactions := []*action.Action{&updateServiceInstance, &notifyUpdateServiceInstance}\r\n\tpipeline := action.NewPipeline(actions...)\r\n\treturn pipeline.Execute(service, *si, updateData, evt, requestID)\r\n}","code-length":213,"reference":"\/\/ Update changes informations of the service instance.","result":"Update the service instance data.","score":[0.2064,0.3319]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (si *ServiceInstance) BindApp(app bind.App, params BindAppParameters, shouldRestart bool, writer io.Writer, evt *event.Event, requestID string) error {\r\n\targs := bindPipelineArgs{\r\n\t\tserviceInstance: si,\r\n\t\tapp:             app,\r\n\t\twriter:          writer,\r\n\t\tshouldRestart:   shouldRestart,\r\n\t\tparams:          params,\r\n\t\tevent:           evt,\r\n\t\trequestID:       requestID,\r\n\t}\r\n\tactions := []*action.Action{\r\n\t\tbindAppDBAction,\r\n\t\tbindAppEndpointAction,\r\n\t\tsetBoundEnvsAction,\r\n\t\tbindUnitsAction,\r\n\t}\r\n\tpipeline := action.NewPipeline(actions...)\r\n\treturn pipeline.Execute(&args)\r\n}","code-length":206,"reference":"\/\/ BindApp makes the bind between the service instance and an app.","result":"Bind app to service instance.","score":[0.0593,0.0885]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (si *ServiceInstance) BindUnit(app bind.App, unit bind.Unit) error {\r\n\ts, err := Get(si.ServiceName)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tendpoint, err := s.getClient(\"production\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tconn, err := db.Conn()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tupdateOp := bson.M{\r\n\t\t\"$addToSet\": bson.M{\r\n\t\t\t\"bound_units\": bson.D([]bson.DocElem{\r\n\t\t\t\t{Name: \"appname\", Value: app.GetName()},\r\n\t\t\t\t{Name: \"id\", Value: unit.GetID()},\r\n\t\t\t\t{Name: \"ip\", Value: unit.GetIp()},\r\n\t\t\t}),\r\n\t\t},\r\n\t}\r\n\terr = conn.ServiceInstances().Update(bson.M{\"name\": si.Name, \"service_name\": si.ServiceName, \"bound_units.id\": bson.M{\"$ne\": unit.GetID()}}, updateOp)\r\n\tconn.Close()\r\n\tif err != nil {\r\n\t\tif err == mgo.ErrNotFound {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\treturn err\r\n\t}\r\n\terr = endpoint.BindUnit(si, app, unit)\r\n\tif err != nil {\r\n\t\tupdateOp = bson.M{\r\n\t\t\t\"$pull\": bson.M{\r\n\t\t\t\t\"bound_units\": bson.D([]bson.DocElem{\r\n\t\t\t\t\t{Name: \"appname\", Value: app.GetName()},\r\n\t\t\t\t\t{Name: \"id\", Value: unit.GetID()},\r\n\t\t\t\t\t{Name: \"ip\", Value: unit.GetIp()},\r\n\t\t\t\t}),\r\n\t\t\t},\r\n\t\t}\r\n\t\trollbackErr := si.updateData(updateOp)\r\n\t\tif rollbackErr != nil {\r\n\t\t\tlog.Errorf(\"[bind unit] could not remove stil unbound unit from db after failure: %s\", rollbackErr)\r\n\t\t}\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":554,"reference":"\/\/ BindUnit makes the bind between the binder and an unit.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (si *ServiceInstance) UnbindApp(unbindArgs UnbindAppArgs) error {\r\n\tif si.FindApp(unbindArgs.App.GetName()) == -1 {\r\n\t\treturn ErrAppNotBound\r\n\t}\r\n\targs := bindPipelineArgs{\r\n\t\tserviceInstance: si,\r\n\t\tapp:             unbindArgs.App,\r\n\t\twriter:          unbindArgs.Event,\r\n\t\tshouldRestart:   unbindArgs.Restart,\r\n\t\tevent:           unbindArgs.Event,\r\n\t\trequestID:       unbindArgs.RequestID,\r\n\t\tforceRemove:     unbindArgs.ForceRemove,\r\n\t}\r\n\tactions := []*action.Action{\r\n\t\t&unbindUnits,\r\n\t\t&unbindAppDB,\r\n\t\t&unbindAppEndpoint,\r\n\t\t&removeBoundEnvs,\r\n\t}\r\n\tpipeline := action.NewPipeline(actions...)\r\n\treturn pipeline.Execute(&args)\r\n}","code-length":243,"reference":"\/\/ UnbindApp makes the unbind between the service instance and an app.","result":"Remove the service instance from the service instance.","score":[0.1864,0.2721]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (si *ServiceInstance) Status(requestID string) (string, error) {\r\n\ts, err := Get(si.ServiceName)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tendpoint, err := s.getClient(\"production\")\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn endpoint.Status(si, requestID)\r\n}","code-length":108,"reference":"\/\/ Status returns the service instance status.","result":"Check the status of the service instance.","score":[0.2284,0.3651]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ProxyInstance(instance *ServiceInstance, path string, evt *event.Event, requestID string, w http.ResponseWriter, r *http.Request) error {\r\n\tservice, err := Get(instance.ServiceName)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tendpoint, err := service.getClient(\"production\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tprefix := fmt.Sprintf(\"\/resources\/%s\/\", instance.GetIdentifier())\r\n\tpath = strings.Trim(strings.TrimPrefix(path+\"\/\", prefix), \"\/\")\r\n\tfor _, reserved := range reservedProxyPaths {\r\n\t\tif path == reserved && r.Method != \"GET\" {\r\n\t\t\treturn &tsuruErrors.ValidationError{\r\n\t\t\t\tMessage: fmt.Sprintf(\"proxy request %s %q is forbidden\", r.Method, path),\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn endpoint.Proxy(fmt.Sprintf(\"%s%s\", prefix, path), evt, requestID, w, r)\r\n}","code-length":266,"reference":"\/\/ ProxyInstance is a proxy between tsuru and the service instance.\n\/\/ This method allow customized service instance methods.","result":"Proxy the instance.","score":[0.0023,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *QuotaService) Inc(appName string, quantity int) error {\r\n\tquota, err := s.Storage.Get(appName)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = s.checkLimit(quota, quantity)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn s.Storage.Inc(appName, quantity)\r\n}","code-length":111,"reference":"\/\/ Inc implements Inc method from QuotaService interface","result":"Increment the quota.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *QuotaService) SetLimit(appName string, limit int) error {\r\n\tq, err := s.Storage.Get(appName)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif limit < 0 {\r\n\t\tlimit = -1\r\n\t} else if limit < q.InUse {\r\n\t\treturn quota.ErrLimitLowerThanAllocated\r\n\t}\r\n\treturn s.Storage.SetLimit(appName, limit)\r\n}","code-length":125,"reference":"\/\/ SetLimit redefines the limit of the app. The new limit must be bigger\n\/\/ than or equal to the current number of units in the app. The new limit may be\n\/\/ smaller than 0, which means that the app should have an unlimited number of\n\/\/ units.\n\/\/ SetLimit implements SetLimit method from QuotaService interface","result":"Set the quota on the application.","score":[0.0,0.0289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *QuotaService) Set(appName string, inUse int) error {\r\n\tq, err := s.Storage.Get(appName)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif inUse < 0 {\r\n\t\treturn quota.ErrLessThanZero\r\n\t}\r\n\tif !q.IsUnlimited() && inUse > q.Limit {\r\n\t\treturn &quota.QuotaExceededError{\r\n\t\t\tRequested: uint(inUse),\r\n\t\t\tAvailable: uint(q.Limit),\r\n\t\t}\r\n\t}\r\n\treturn s.Storage.Set(appName, inUse)\r\n}","code-length":167,"reference":"\/\/ Set redefines the inuse units of the app. This new value must be smaller\n\/\/ than or equal to the current limit of the app. It also must be a non negative number.\n\/\/ Set implements Set method from QuotaService interface","result":"Set the quota on the application.","score":[0.0006,0.0391]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *QuotaService) Get(appName string) (*quota.Quota, error) {\r\n\treturn s.Storage.Get(appName)\r\n}","code-length":47,"reference":"\/\/ Get implements Get method from QuotaService interface","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RemoveImage(imageName string) error {\r\n\tregistry, image, tag := parseImage(imageName)\r\n\tif registry == \"\" {\r\n\t\tregistry, _ = config.GetString(\"docker:registry\")\r\n\t}\r\n\tif registry == \"\" {\r\n\t\t\r\n\t\treturn nil\r\n\t}\r\n\tif image == \"\" {\r\n\t\treturn errors.Errorf(\"empty image after parsing %q\", imageName)\r\n\t}\r\n\tr := &dockerRegistry{server: registry}\r\n\tdigest, err := r.getDigest(image, tag)\r\n\tif err != nil {\r\n\t\treturn errors.Wrapf(err, \"failed to get digest for image %s\/%s:%s on registry\", r.server, image, tag)\r\n\t}\r\n\terr = r.removeImage(image, digest)\r\n\tif err != nil {\r\n\t\treturn errors.Wrapf(err, \"failed to remove image %s\/%s:%s\/%s on registry\", r.server, image, tag, digest)\r\n\t}\r\n\treturn nil\r\n}","code-length":263,"reference":"\/\/ RemoveImage removes an image manifest from a remote registry v2 server, returning an error\n\/\/ in case of failure.","result":"Remove an image from the registry.","score":[0.0293,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RemoveAppImages(appName string) error {\r\n\tregistry, _ := config.GetString(\"docker:registry\")\r\n\tif registry == \"\" {\r\n\t\t\r\n\t\treturn nil\r\n\t}\r\n\tr := &dockerRegistry{server: registry}\r\n\timage := fmt.Sprintf(\"tsuru\/app-%s\", appName)\r\n\ttags, err := r.getImageTags(image)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tmulti := tsuruErrors.NewMultiError()\r\n\tfor _, tag := range tags {\r\n\t\tdigest, err := r.getDigest(image, tag)\r\n\t\tif err != nil {\r\n\t\t\tmulti.Add(errors.Wrapf(err, \"failed to get digest for image %s\/%s:%s on registry\", r.server, image, tag))\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\terr = r.removeImage(image, digest)\r\n\t\tif err != nil {\r\n\t\t\tmulti.Add(errors.Wrapf(err, \"failed to remove image %s\/%s:%s\/%s on registry\", r.server, image, tag, digest))\r\n\t\t\tif errors.Cause(err) == ErrDeleteDisabled {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn multi.ToError()\r\n}","code-length":335,"reference":"\/\/ RemoveAppImages removes all app images from a remote registry v2 server, returning an error\n\/\/ in case of failure.","result":"Remove images from the app.","score":[0.0169,0.1381]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *platformService) Create(opts appTypes.PlatformOptions) error {\r\n\tp := appTypes.Platform{Name: opts.Name}\r\n\tif err := s.validate(p); err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr := s.storage.Insert(p)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\topts.ImageName, err = servicemanager.PlatformImage.NewImage(opts.Name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = builder.PlatformAdd(opts)\r\n\tif err != nil {\r\n\t\tif imgErr := servicemanager.PlatformImage.DeleteImages(opts.Name); imgErr != nil {\r\n\t\t\tlog.Errorf(\"unable to remove platform images: %s\", imgErr)\r\n\t\t}\r\n\t\tdbErr := s.storage.Delete(p)\r\n\t\tif dbErr != nil {\r\n\t\t\treturn tsuruErrors.NewMultiError(\r\n\t\t\t\terrors.Wrapf(dbErr, \"unable to rollback platform add\"),\r\n\t\t\t\terrors.Wrapf(err, \"original platform add error\"),\r\n\t\t\t)\r\n\t\t}\r\n\t\treturn err\r\n\t}\r\n\treturn servicemanager.PlatformImage.AppendImage(opts.Name, opts.ImageName)\r\n}","code-length":334,"reference":"\/\/ Create implements Create method of PlatformService interface","result":"Create a new platform.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *platformService) List(enabledOnly bool) ([]appTypes.Platform, error) {\r\n\tif enabledOnly {\r\n\t\treturn s.storage.FindEnabled()\r\n\t}\r\n\treturn s.storage.FindAll()\r\n}","code-length":69,"reference":"\/\/ List implements List method of PlatformService interface","result":"List all platforms.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *platformService) FindByName(name string) (*appTypes.Platform, error) {\r\n\tp, err := s.storage.FindByName(name)\r\n\tif err != nil {\r\n\t\treturn nil, appTypes.ErrInvalidPlatform\r\n\t}\r\n\treturn p, nil\r\n}","code-length":83,"reference":"\/\/ FindByName implements FindByName method of PlatformService interface","result":"Find the platform by name.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *platformService) Update(opts appTypes.PlatformOptions) error {\r\n\tif opts.Name == \"\" {\r\n\t\treturn appTypes.ErrPlatformNameMissing\r\n\t}\r\n\tconn, err := db.Conn()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer conn.Close()\r\n\t_, err = s.FindByName(opts.Name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif opts.Input != nil {\r\n\t\tdata, err := ioutil.ReadAll(opts.Input)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif len(data) == 0 {\r\n\t\t\treturn appTypes.ErrMissingFileContent\r\n\t\t}\r\n\t\topts.Data = data\r\n\t\topts.ImageName, err = servicemanager.PlatformImage.NewImage(opts.Name)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\terr = builder.PlatformUpdate(opts)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\terr = servicemanager.PlatformImage.AppendImage(opts.Name, opts.ImageName)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tvar apps []App\r\n\t\terr = conn.Apps().Find(bson.M{\"framework\": opts.Name}).All(&apps)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tfor _, app := range apps {\r\n\t\t\tapp.SetUpdatePlatform(true)\r\n\t\t}\r\n\t}\r\n\tif opts.Args[\"disabled\"] != \"\" {\r\n\t\tdisableBool, err := strconv.ParseBool(opts.Args[\"disabled\"])\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn s.storage.Update(appTypes.Platform{Name: opts.Name, Disabled: disableBool})\r\n\t}\r\n\treturn nil\r\n}","code-length":512,"reference":"\/\/ Update implements Update method of PlatformService interface","result":"Update the platform .","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *platformService) Remove(name string) error {\r\n\tif name == \"\" {\r\n\t\treturn appTypes.ErrPlatformNameMissing\r\n\t}\r\n\tconn, err := db.Conn()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer conn.Close()\r\n\tapps, _ := conn.Apps().Find(bson.M{\"framework\": name}).Count()\r\n\tif apps > 0 {\r\n\t\treturn appTypes.ErrDeletePlatformWithApps\r\n\t}\r\n\terr = builder.PlatformRemove(name)\r\n\tif err != nil {\r\n\t\tlog.Errorf(\"Failed to remove platform from builder: %s\", err)\r\n\t}\r\n\timages, err := servicemanager.PlatformImage.ListImagesOrDefault(name)\r\n\tif err == nil {\r\n\t\tfor _, img := range images {\r\n\t\t\tif regErr := registry.RemoveImage(img); regErr != nil {\r\n\t\t\t\tlog.Errorf(\"Failed to remove platform image from registry: %s\", regErr)\r\n\t\t\t}\r\n\t\t}\r\n\t} else {\r\n\t\tlog.Errorf(\"Failed to retrieve platform images from storage: %s\", err)\r\n\t}\r\n\terr = servicemanager.PlatformImage.DeleteImages(name)\r\n\tif err != nil {\r\n\t\tlog.Errorf(\"Failed to remove platform images from storage: %s\", err)\r\n\t}\r\n\treturn s.storage.Delete(appTypes.Platform{Name: name})\r\n}","code-length":371,"reference":"\/\/ Remove implements Remove method of PlatformService interface","result":"Remove the platform from the database.","score":[0.1383,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *platformService) Rollback(opts appTypes.PlatformOptions) error {\r\n\tif opts.Name == \"\" {\r\n\t\treturn appTypes.ErrPlatformNameMissing\r\n\t}\r\n\tif opts.ImageName == \"\" {\r\n\t\treturn appTypes.ErrPlatformImageMissing\r\n\t}\r\n\t_, err := s.FindByName(opts.Name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\timage, err := servicemanager.PlatformImage.FindImage(opts.Name, opts.ImageName)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif image == \"\" {\r\n\t\treturn fmt.Errorf(\"Image %s not found in platform %q\", opts.ImageName, opts.Name)\r\n\t}\r\n\topts.Data = []byte(\"FROM \" + image)\r\n\topts.ImageName, err = servicemanager.PlatformImage.NewImage(opts.Name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = builder.PlatformUpdate(opts)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = servicemanager.PlatformImage.AppendImage(opts.Name, opts.ImageName)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tconn, err := db.Conn()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer conn.Close()\r\n\tvar apps []App\r\n\terr = conn.Apps().Find(bson.M{\"framework\": opts.Name}).All(&apps)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfor _, app := range apps {\r\n\t\tapp.SetUpdatePlatform(true)\r\n\t}\r\n\treturn nil\r\n}","code-length":449,"reference":"\/\/ Rollback implements Rollback method of PlatformService interface","result":"Rollback a platform.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetPoolByName(name string) (*Pool, error) {\r\n\tconn, err := db.Conn()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer conn.Close()\r\n\tvar p Pool\r\n\terr = conn.Pools().FindId(name).One(&p)\r\n\tif err != nil {\r\n\t\tif err == mgo.ErrNotFound {\r\n\t\t\treturn nil, ErrPoolNotFound\r\n\t\t}\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &p, nil\r\n}","code-length":146,"reference":"\/\/ GetPoolByName finds a pool by name","result":"Get the pool by name.","score":[0.2278,0.3758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Manager() RepositoryManager {\r\n\tmanagerName, err := config.GetString(\"repo-manager\")\r\n\tif err != nil {\r\n\t\tmanagerName = defaultManager\r\n\t}\r\n\tif _, ok := managers[managerName]; !ok {\r\n\t\tmanagerName = \"nop\"\r\n\t}\r\n\treturn managers[managerName]\r\n}","code-length":96,"reference":"\/\/ Manager returns the current configured manager, as defined in the\n\/\/ configuration file.","result":"Get the repository manager.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Register(name string, manager RepositoryManager) {\r\n\tif managers == nil {\r\n\t\tmanagers = make(map[string]RepositoryManager)\r\n\t}\r\n\tmanagers[name] = manager\r\n}","code-length":59,"reference":"\/\/ Register registers a new repository manager, that can be later configured\n\/\/ and used.","result":"Register a repository.","score":[0.0089,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *bindSyncer) start() error {\r\n\tif b.started {\r\n\t\treturn errors.New(\"syncer already started\")\r\n\t}\r\n\tif b.appLister == nil {\r\n\t\treturn errors.New(\"must set app lister function\")\r\n\t}\r\n\tif b.interval == 0 {\r\n\t\tb.interval = 5 * time.Minute\r\n\t}\r\n\tb.shutdown = make(chan struct{}, 1)\r\n\tb.done = make(chan struct{})\r\n\tb.started = true\r\n\tlog.Debugf(\"[bind-syncer] starting. Running every %s.\\n\", b.interval)\r\n\tgo func(d time.Duration) {\r\n\t\tfor {\r\n\t\t\tselect {\r\n\t\t\tcase <-time.After(d):\r\n\t\t\t\tstart := time.Now()\r\n\t\t\t\tlog.Debug(\"[bind-syncer] starting run\")\r\n\t\t\t\tapps, err := b.appLister()\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tlog.Errorf(\"[bind-syncer] error listing apps: %v. Aborting sync.\", err)\r\n\t\t\t\t\tsyncDuration.Set(time.Since(start).Seconds())\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t\tfor _, a := range apps {\r\n\t\t\t\t\terr = b.sync(a)\r\n\t\t\t\t\tif err != nil {\r\n\t\t\t\t\t\tlog.Errorf(\"[bind-syncer] error syncing app %q: %v\", a.GetName(), err)\r\n\t\t\t\t\t}\r\n\t\t\t\t\tif len(b.shutdown) > 0 {\r\n\t\t\t\t\t\tbreak\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t\tlog.Debugf(\"[bind-syncer] finished running. Synced %d apps.\", len(apps))\r\n\t\t\t\td = b.interval\r\n\t\t\t\tsyncDuration.Set(time.Since(start).Seconds())\r\n\t\t\tcase <-b.shutdown:\r\n\t\t\t\tb.done <- struct{}{}\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t}\r\n\t}(time.Millisecond * 100)\r\n\treturn nil\r\n}","code-length":516,"reference":"\/\/ start starts the sync process on a different goroutine","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *bindSyncer) Shutdown(ctx context.Context) error {\r\n\tif !b.started {\r\n\t\treturn nil\r\n\t}\r\n\tb.shutdown <- struct{}{}\r\n\tselect {\r\n\tcase <-b.done:\r\n\tcase <-ctx.Done():\r\n\t}\r\n\tb.started = false\r\n\treturn ctx.Err()\r\n}","code-length":101,"reference":"\/\/ Shutdown shutdowns bindSyncer waiting for the current sync\n\/\/ to complete","result":"Shutdown the bindSyncer.","score":[0.0242,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetForProvisioner(p provision.Provisioner) (Builder, error) {\r\n\tbuilder, err := get(p.GetName())\r\n\tif err != nil {\r\n\t\tif _, ok := p.(provision.BuilderDeployDockerClient); ok {\r\n\t\t\treturn get(\"docker\")\r\n\t\t} else if _, ok := p.(provision.BuilderDeployKubeClient); ok {\r\n\t\t\treturn get(\"kubernetes\")\r\n\t\t}\r\n\t}\r\n\treturn builder, err\r\n}","code-length":129,"reference":"\/\/ GetForProvisioner gets the builder required by the provisioner.","result":"Get the builder for a specific provisioner.","score":[0.1899,0.2273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc get(name string) (Builder, error) {\r\n\tb, ok := builders[name]\r\n\tif !ok {\r\n\t\treturn nil, errors.Errorf(\"unknown builder: %q\", name)\r\n\t}\r\n\treturn b, nil\r\n}","code-length":72,"reference":"\/\/ get gets the named builder from the registry.","result":"Get the builder by name.","score":[0.1284,0.1744]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Registry() ([]Builder, error) {\r\n\tregistry := make([]Builder, 0, len(builders))\r\n\tfor _, b := range builders {\r\n\t\tregistry = append(registry, b)\r\n\t}\r\n\treturn registry, nil\r\n}","code-length":73,"reference":"\/\/ Registry returns the list of registered builders.","result":"Generate the registry.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterQueueTask(p DockerProvisioner) error {\r\n\tq, err := queue.Queue()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn q.RegisterTask(&runBs{provisioner: p})\r\n}","code-length":71,"reference":"\/\/ RegisterQueueTask registers the internal bs queue task for later execution.","result":"Register the task in the queue.","score":[0.0998,0.1429]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v *version) Apps() AppInformer {\r\n\treturn &appInformer{factory: v.factory, namespace: v.namespace, tweakListOptions: v.tweakListOptions}\r\n}","code-length":53,"reference":"\/\/ Apps returns a AppInformer.","result":"Package version.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *App) DeepCopy() *App {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(App)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":64,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new App.","result":"Create a deep copy of an object.","score":[0.0707,0.2373]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *AppList) DeepCopy() *AppList {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(AppList)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":67,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new AppList.","result":"Avoid deep copy.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *AppSpec) DeepCopy() *AppSpec {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(AppSpec)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":67,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new AppSpec.","result":"Create a deep copy of the same object.","score":[0.078,0.2355]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *LogWriter) Write(data []byte) (int, error) {\r\n\tw.finLk.RLock()\r\n\tdefer w.finLk.RUnlock()\r\n\tif w.closed {\r\n\t\treturn len(data), nil\r\n\t}\r\n\tif w.msgCh == nil {\r\n\t\treturn len(data), w.write(data)\r\n\t}\r\n\tcopied := make([]byte, len(data))\r\n\tcopy(copied, data)\r\n\tw.msgCh <- copied\r\n\treturn len(data), nil\r\n}","code-length":151,"reference":"\/\/ Write writes and logs the data.","result":"Write to the log.","score":[0.1795,0.1493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s NativeScheme) ResetPassword(user *auth.User, resetToken string) error {\r\n\tif resetToken == \"\" {\r\n\t\treturn auth.ErrInvalidToken\r\n\t}\r\n\tconn, err := db.Conn()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer conn.Close()\r\n\tpassToken, err := getPasswordToken(resetToken)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif passToken.UserEmail != user.Email {\r\n\t\treturn auth.ErrInvalidToken\r\n\t}\r\n\tpassword := generatePassword(12)\r\n\tuser.Password = password\r\n\thashPassword(user)\r\n\tgo sendNewPassword(user, password)\r\n\tpassToken.Used = true\r\n\tconn.PasswordTokens().UpdateId(passToken.Token, passToken)\r\n\treturn user.Update()\r\n}","code-length":227,"reference":"\/\/ ResetPassword actually resets the password of the user. It needs the token\n\/\/ string. The new password will be a random string, that will be then sent to\n\/\/ the user email.","result":"Generate the password.","score":[0.0,0.0167]}
{"code":"\/*is used to<extra_id_0>\r\nfunc addKnownTypes(scheme *runtime.Scheme) error {\r\n\tscheme.AddKnownTypes(SchemeGroupVersion,\r\n\t\t&App{},\r\n\t\t&AppList{},\r\n\t)\r\n\tscheme.AddKnownTypes(SchemeGroupVersion,\r\n\t\t&metav1.Status{},\r\n\t)\r\n\tmetav1.AddToGroupVersion(scheme, SchemeGroupVersion)\r\n\treturn nil\r\n}","code-length":107,"reference":"\/\/ Adds the list of known types to the given scheme.","result":"Add custom types to the scheme.","score":[0.1857,0.4248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Register(s Shutdownable) {\r\n\tlock.Lock()\r\n\tdefer lock.Unlock()\r\n\tregistered = append(registered, s)\r\n}","code-length":46,"reference":"\/\/ Register registers an item as shutdownable","result":"Register shutdownable objects.","score":[0.128,0.1515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Do(ctx context.Context, w io.Writer) error {\r\n\tlock.Lock()\r\n\tdefer lock.Unlock()\r\n\tdone := make(chan bool)\r\n\twg := sync.WaitGroup{}\r\n\tfor _, h := range registered {\r\n\t\twg.Add(1)\r\n\t\tgo func(h Shutdownable) {\r\n\t\t\tdefer wg.Done()\r\n\t\t\tvar name string\r\n\t\t\tif _, ok := h.(fmt.Stringer); ok {\r\n\t\t\t\tname = fmt.Sprintf(\"%s\", h)\r\n\t\t\t} else {\r\n\t\t\t\tname = fmt.Sprintf(\"%T\", h)\r\n\t\t\t}\r\n\t\t\tfmt.Fprintf(w, \"[shutdown] running shutdown for %s...\\n\", name)\r\n\t\t\terr := h.Shutdown(ctx)\r\n\t\t\tif err != nil {\r\n\t\t\t\tfmt.Fprintf(w, \"[shutdown] running shutdown for %s. ERROED: %v\", name, err)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tfmt.Fprintf(w, \"[shutdown] running shutdown for %s. DONE.\\n\", name)\r\n\t\t}(h)\r\n\t}\r\n\tgo func() {\r\n\t\twg.Wait()\r\n\t\tclose(done)\r\n\t}()\r\n\tselect {\r\n\tcase <-ctx.Done():\r\n\t\treturn ctx.Err()\r\n\tcase <-done:\r\n\t}\r\n\treturn nil\r\n}","code-length":364,"reference":"\/\/ Do shutdowns All registered Shutdownable items","result":"Shutdown all registered handlers.","score":[0.1509,0.3814]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *platformImageService) ListImagesOrDefault(platformName string) ([]string, error) {\r\n\timgs, err := s.ListImages(platformName)\r\n\tif err != nil && err == imageTypes.ErrPlatformImageNotFound {\r\n\t\treturn []string{platformBasicImageName(platformName)}, nil\r\n\t}\r\n\treturn imgs, err\r\n}","code-length":98,"reference":"\/\/ PlatformListImagesOrDefault returns basicImageName when platform is empty\n\/\/ for backwards compatibility","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MigrateAppsCRDs() error {\r\n\tconfig.Set(\"kubernetes:use-pool-namespaces\", false)\r\n\tdefer config.Unset(\"kubernetes:use-pool-namespaces\")\r\n\tprov := kubernetes.GetProvisioner()\r\n\tpools, err := pool.ListAllPools()\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to list pools\")\r\n\t}\r\n\tvar kubePools []string\r\n\tfor _, p := range pools {\r\n\t\tif p.Provisioner == prov.GetName() {\r\n\t\t\tkubePools = append(kubePools, p.Name)\r\n\t\t}\r\n\t}\r\n\tapps, err := app.List(&app.Filter{Pools: kubePools})\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"failed to list apps\")\r\n\t}\r\n\tmultiErr := tsuruerrors.NewMultiError()\r\n\tfor _, a := range apps {\r\n\t\terrProv := prov.Provision(&a)\r\n\t\tif errProv != nil {\r\n\t\t\tmultiErr.Add(errProv)\r\n\t\t}\r\n\t}\r\n\treturn multiErr.ToError()\r\n}","code-length":302,"reference":"\/\/ MigrateAppsCRDs creates the necessary CRDs for every application\n\/\/ on a Kubernetes cluster. This is done by re-provisioning the App\n\/\/ on the cluster.","result":"Migrate apps CRDs.","score":[0,0.0219]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Register(name string, fn MigrateFunc) error {\r\n\treturn register(name, false, fn)\r\n}","code-length":36,"reference":"\/\/ Register register a new migration for later execution with the Run\n\/\/ functions.","result":"Register MigrateFunc .","score":[0.0104,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterOptional(name string, fn MigrateFunc) error {\r\n\treturn register(name, true, fn)\r\n}","code-length":37,"reference":"\/\/ RegisterOptional register a new migration that will not run automatically\n\/\/ when calling the Run funcition.","result":"Register optional functions.","score":[0,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Run(args RunArgs) error {\r\n\tif args.Name != \"\" {\r\n\t\treturn runOptional(args)\r\n\t}\r\n\tif args.Force {\r\n\t\treturn ErrCannotForceMandatory\r\n\t}\r\n\treturn run(args)\r\n}","code-length":75,"reference":"\/\/ Run runs all registered non optional migrations if no \".Name\" is informed.\n\/\/ Migrations are executed in the order that they were registered. If \".Name\"\n\/\/ is informed, an optional migration with the given name is executed.","result":"Run the command .","score":[0.0001,0.0289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) Units() ([]provision.Unit, error) {\r\n\tprov, err := app.getProvisioner()\r\n\tif err != nil {\r\n\t\treturn []provision.Unit{}, err\r\n\t}\r\n\tunits, err := prov.Units(app)\r\n\tif units == nil {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tunits = []provision.Unit{}\r\n\t}\r\n\treturn units, err\r\n}","code-length":117,"reference":"\/\/ Units returns the list of units.","result":"Get all the units.","score":[0.1795,0.1493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) MarshalJSON() ([]byte, error) {\r\n\trepo, _ := repository.Manager().GetRepository(app.Name)\r\n\tresult := make(map[string]interface{})\r\n\tresult[\"name\"] = app.Name\r\n\tresult[\"platform\"] = app.Platform\r\n\tif version := app.GetPlatformVersion(); version != \"latest\" {\r\n\t\tresult[\"platform\"] = fmt.Sprintf(\"%s:%s\", app.Platform, version)\r\n\t}\r\n\tresult[\"teams\"] = app.Teams\r\n\tunits, err := app.Units()\r\n\tresult[\"units\"] = units\r\n\tvar errMsgs []string\r\n\tif err != nil {\r\n\t\terrMsgs = append(errMsgs, fmt.Sprintf(\"unable to list app units: %+v\", err))\r\n\t}\r\n\tresult[\"repository\"] = repo.ReadWriteURL\r\n\tplan := map[string]interface{}{\r\n\t\t\"name\":     app.Plan.Name,\r\n\t\t\"memory\":   app.Plan.Memory,\r\n\t\t\"swap\":     app.Plan.Swap,\r\n\t\t\"cpushare\": app.Plan.CpuShare,\r\n\t}\r\n\trouters, err := app.GetRoutersWithAddr()\r\n\tif err != nil {\r\n\t\terrMsgs = append(errMsgs, fmt.Sprintf(\"unable to get app addresses: %+v\", err))\r\n\t}\r\n\tif len(routers) > 0 {\r\n\t\tresult[\"ip\"] = routers[0].Address\r\n\t\tplan[\"router\"] = routers[0].Name\r\n\t\tresult[\"router\"] = routers[0].Name\r\n\t\tresult[\"routeropts\"] = routers[0].Opts\r\n\t}\r\n\tresult[\"cname\"] = app.CName\r\n\tresult[\"owner\"] = app.Owner\r\n\tresult[\"pool\"] = app.Pool\r\n\tresult[\"description\"] = app.Description\r\n\tresult[\"deploys\"] = app.Deploys\r\n\tresult[\"teamowner\"] = app.TeamOwner\r\n\tresult[\"plan\"] = plan\r\n\tresult[\"lock\"] = app.Lock\r\n\tresult[\"tags\"] = app.Tags\r\n\tresult[\"routers\"] = routers\r\n\tif len(errMsgs) > 0 {\r\n\t\tresult[\"error\"] = strings.Join(errMsgs, \"\\n\")\r\n\t}\r\n\treturn json.Marshal(&result)\r\n}","code-length":587,"reference":"\/\/ MarshalJSON marshals the app in json format.","result":"Code too long,keep in 512.","score":[0.1319,0.0649]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AcquireApplicationLockWait(appName string, owner string, reason string, timeout time.Duration) (bool, error) {\r\n\ttimeoutChan := time.After(timeout)\r\n\tfor {\r\n\t\tappLock := appTypes.AppLock{\r\n\t\t\tLocked:      true,\r\n\t\t\tReason:      reason,\r\n\t\t\tOwner:       owner,\r\n\t\t\tAcquireDate: time.Now().In(time.UTC),\r\n\t\t}\r\n\t\tconn, err := db.Conn()\r\n\t\tif err != nil {\r\n\t\t\treturn false, err\r\n\t\t}\r\n\t\terr = conn.Apps().Update(bson.M{\"name\": appName, \"lock.locked\": bson.M{\"$in\": []interface{}{false, nil}}}, bson.M{\"$set\": bson.M{\"lock\": appLock}})\r\n\t\tconn.Close()\r\n\t\tif err == nil {\r\n\t\t\treturn true, nil\r\n\t\t}\r\n\t\tif err != mgo.ErrNotFound {\r\n\t\t\treturn false, err\r\n\t\t}\r\n\t\tselect {\r\n\t\tcase <-timeoutChan:\r\n\t\t\treturn false, nil\r\n\t\tcase <-time.After(300 * time.Millisecond):\r\n\t\t}\r\n\t}\r\n}","code-length":316,"reference":"\/\/ Same as AcquireApplicationLock but it keeps trying to acquire the lock\n\/\/ until timeout is reached.","result":"Wait for the lock to be acquired.","score":[0.0606,0.1597]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReleaseApplicationLock(appName string) {\r\n\tvar err error\r\n\tretries := 3\r\n\tfor i := 0; i < retries; i++ {\r\n\t\terr = releaseApplicationLockOnce(appName)\r\n\t\tif err == nil {\r\n\t\t\treturn\r\n\t\t}\r\n\t\ttime.Sleep(time.Second * time.Duration(i+1))\r\n\t}\r\n\tlog.Error(err)\r\n}","code-length":115,"reference":"\/\/ ReleaseApplicationLock releases a lock hold on an app, currently it's called\n\/\/ by a middleware, however, ideally, it should be called individually by each\n\/\/ handler since they might be doing operations in background.","result":"Release the application lock.","score":[0,0.0157]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetByName(name string) (*App, error) {\r\n\tvar app App\r\n\tconn, err := db.Conn()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer conn.Close()\r\n\terr = conn.Apps().Find(bson.M{\"name\": name}).One(&app)\r\n\tif err == mgo.ErrNotFound {\r\n\t\treturn nil, appTypes.ErrAppNotFound\r\n\t}\r\n\treturn &app, err\r\n}","code-length":133,"reference":"\/\/ GetByName queries the database to find an app identified by the given\n\/\/ name.","result":"Get the app by name.","score":[0.046,0.1786]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) AddUnits(n uint, process string, w io.Writer) error {\r\n\tif n == 0 {\r\n\t\treturn errors.New(\"Cannot add zero units.\")\r\n\t}\r\n\tunits, err := app.Units()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfor _, u := range units {\r\n\t\tif (u.Status == provision.StatusAsleep) || (u.Status == provision.StatusStopped) {\r\n\t\t\treturn errors.New(\"Cannot add units to an app that has stopped or sleeping units\")\r\n\t\t}\r\n\t}\r\n\tw = app.withLogWriter(w)\r\n\terr = action.NewPipeline(\r\n\t\t&reserveUnitsToAdd,\r\n\t\t&provisionAddUnits,\r\n\t).Execute(app, n, w, process)\r\n\trebuild.RoutesRebuildOrEnqueue(app.Name)\r\n\tquotaErr := app.fixQuota()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn quotaErr\r\n}","code-length":268,"reference":"\/\/ AddUnits creates n new units within the provisioner, saves new units in the\n\/\/ database and enqueues the apprc serialization.","result":"Add units to an app.","score":[0.0098,0.0258]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) SetUnitStatus(unitName string, status provision.Status) error {\r\n\tunits, err := app.Units()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfor _, unit := range units {\r\n\t\tif strings.HasPrefix(unit.ID, unitName) {\r\n\t\t\tprov, err := app.getProvisioner()\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tunitProv, ok := prov.(provision.UnitStatusProvisioner)\r\n\t\t\tif !ok {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\treturn unitProv.SetUnitStatus(unit, status)\r\n\t\t}\r\n\t}\r\n\treturn &provision.UnitNotFoundError{ID: unitName}\r\n}","code-length":203,"reference":"\/\/ SetUnitStatus changes the status of the given unit.","result":"Generate code for the generated code.","score":[0.1171,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UpdateNodeStatus(nodeData provision.NodeStatusData) ([]UpdateUnitsResult, error) {\r\n\tnode, findNodeErr := findNodeForNodeData(nodeData)\r\n\tvar nodeAddresses []string\r\n\tif findNodeErr == nil {\r\n\t\tnodeAddresses = []string{node.Address()}\r\n\t} else {\r\n\t\tnodeAddresses = nodeData.Addrs\r\n\t}\r\n\tif healer.HealerInstance != nil {\r\n\t\terr := healer.HealerInstance.UpdateNodeData(nodeAddresses, nodeData.Checks)\r\n\t\tif err != nil {\r\n\t\t\tlog.Errorf(\"[update node status] unable to set node status in healer: %s\", err)\r\n\t\t}\r\n\t}\r\n\tif findNodeErr == provision.ErrNodeNotFound {\r\n\t\tcounterNodesNotFound.Inc()\r\n\t\tlog.Errorf(\"[update node status] node not found with nodedata: %#v\", nodeData)\r\n\t\tresult := make([]UpdateUnitsResult, len(nodeData.Units))\r\n\t\tfor i, unitData := range nodeData.Units {\r\n\t\t\tresult[i] = UpdateUnitsResult{ID: unitData.ID, Found: false}\r\n\t\t}\r\n\t\treturn result, nil\r\n\t}\r\n\tif findNodeErr != nil {\r\n\t\treturn nil, findNodeErr\r\n\t}\r\n\tunitProv, ok := node.Provisioner().(provision.UnitStatusProvisioner)\r\n\tif !ok {\r\n\t\treturn []UpdateUnitsResult{}, nil\r\n\t}\r\n\tresult := make([]UpdateUnitsResult, len(nodeData.Units))\r\n\tfor i, unitData := range nodeData.Units {\r\n\t\tunit := provision.Unit{ID: unitData.ID, Name: unitData.Name}\r\n\t\terr := unitProv.SetUnitStatus(unit, unitData.Status)\r\n\t\t_, isNotFound := err.(*provision.UnitNotFoundError)\r\n\t\tif err != nil && !isNotFound {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tresult[i] = UpdateUnitsResult{ID: unitData.ID, Found: !isNotFound}\r\n\t}\r\n\treturn result, nil\r\n}","code-length":535,"reference":"\/\/ UpdateNodeStatus updates the status of the given node and its units,\n\/\/ returning a map which units were found during the update.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) available() bool {\r\n\tunits, err := app.Units()\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\tfor _, unit := range units {\r\n\t\tif unit.Available() {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":92,"reference":"\/\/ available returns true if at least one of N units is started or unreachable.","result":"Check if the app is available.","score":[0.0512,0.0709]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) Grant(team *authTypes.Team) error {\r\n\tif _, found := app.findTeam(team); found {\r\n\t\treturn ErrAlreadyHaveAccess\r\n\t}\r\n\tapp.Teams = append(app.Teams, team.Name)\r\n\tconn, err := db.Conn()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer conn.Close()\r\n\terr = conn.Apps().Update(bson.M{\"name\": app.Name}, bson.M{\"$addToSet\": bson.M{\"teams\": team.Name}})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tusers, err := auth.ListUsersWithPermissions(permission.Permission{\r\n\t\tScheme:  permission.PermAppDeploy,\r\n\t\tContext: permission.Context(permTypes.CtxTeam, team.Name),\r\n\t})\r\n\tif err != nil {\r\n\t\tconn.Apps().Update(bson.M{\"name\": app.Name}, bson.M{\"$pull\": bson.M{\"teams\": team.Name}})\r\n\t\treturn err\r\n\t}\r\n\tfor _, user := range users {\r\n\t\terr = repository.Manager().GrantAccess(app.Name, user.Email)\r\n\t\tif err != nil {\r\n\t\t\tconn.Apps().Update(bson.M{\"name\": app.Name}, bson.M{\"$pull\": bson.M{\"teams\": team.Name}})\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":386,"reference":"\/\/ Grant allows a team to have access to an app. It returns an error if the\n\/\/ team already have access to the app.","result":"Grant access to app teams.","score":[0.0069,0.1111]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) Revoke(team *authTypes.Team) error {\r\n\tif len(app.Teams) == 1 {\r\n\t\treturn ErrCannotOrphanApp\r\n\t}\r\n\tindex, found := app.findTeam(team)\r\n\tif !found {\r\n\t\treturn ErrNoAccess\r\n\t}\r\n\tlast := len(app.Teams) - 1\r\n\tapp.Teams[index] = app.Teams[last]\r\n\tapp.Teams = app.Teams[:last]\r\n\tconn, err := db.Conn()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer conn.Close()\r\n\terr = conn.Apps().Update(bson.M{\"name\": app.Name}, bson.M{\"$pull\": bson.M{\"teams\": team.Name}})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tusers, err := auth.ListUsersWithPermissions(permission.Permission{\r\n\t\tScheme:  permission.PermAppDeploy,\r\n\t\tContext: permission.Context(permTypes.CtxTeam, team.Name),\r\n\t})\r\n\tif err != nil {\r\n\t\tconn.Apps().Update(bson.M{\"name\": app.Name}, bson.M{\"$addToSet\": bson.M{\"teams\": team.Name}})\r\n\t\treturn err\r\n\t}\r\n\tfor _, user := range users {\r\n\t\tperms, err := user.Permissions()\r\n\t\tif err != nil {\r\n\t\t\tconn.Apps().Update(bson.M{\"name\": app.Name}, bson.M{\"$addToSet\": bson.M{\"teams\": team.Name}})\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tcanDeploy := permission.CheckFromPermList(perms, permission.PermAppDeploy,\r\n\t\t\tappend(permission.Contexts(permTypes.CtxTeam, app.Teams),\r\n\t\t\t\tpermission.Context(permTypes.CtxApp, app.Name),\r\n\t\t\t\tpermission.Context(permTypes.CtxPool, app.Pool),\r\n\t\t\t)...,\r\n\t\t)\r\n\t\tif canDeploy {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\terr = repository.Manager().RevokeAccess(app.Name, user.Email)\r\n\t\tif err != nil {\r\n\t\t\tconn.Apps().Update(bson.M{\"name\": app.Name}, bson.M{\"$addToSet\": bson.M{\"teams\": team.Name}})\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":625,"reference":"\/\/ Revoke removes the access from a team. It returns an error if the team do\n\/\/ not have access to the app.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) GetTeams() []authTypes.Team {\r\n\tt, _ := servicemanager.Team.FindByNames(app.Teams)\r\n\treturn t\r\n}","code-length":54,"reference":"\/\/ GetTeams returns a slice of teams that have access to the app.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) setEnv(env bind.EnvVar) {\r\n\tif app.Env == nil {\r\n\t\tapp.Env = make(map[string]bind.EnvVar)\r\n\t}\r\n\tapp.Env[env.Name] = env\r\n\tif env.Public {\r\n\t\tapp.Log(fmt.Sprintf(\"setting env %s with value %s\", env.Name, env.Value), \"tsuru\", \"api\")\r\n\t}\r\n}","code-length":124,"reference":"\/\/ setEnv sets the given environment variable in the app.","result":"Set env variables in the app.","score":[0.2042,0.5042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) getEnv(name string) (bind.EnvVar, error) {\r\n\tif env, ok := app.Env[name]; ok {\r\n\t\treturn env, nil\r\n\t}\r\n\treturn bind.EnvVar{}, errors.New(\"Environment variable not declared for this app.\")\r\n}","code-length":83,"reference":"\/\/ getEnv returns the environment variable if it's declared in the app. It will\n\/\/ return an error if the variable is not defined in this app.","result":"Get the environment variable from the app.","score":[0.0233,0.1]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) validateNew() error {\r\n\tif app.Name == InternalAppName || !validation.ValidateName(app.Name) {\r\n\t\tmsg := \"Invalid app name, your app should have at most 40 \" +\r\n\t\t\t\"characters, containing only lower case letters, numbers or dashes, \" +\r\n\t\t\t\"starting with a letter.\"\r\n\t\treturn &tsuruErrors.ValidationError{Message: msg}\r\n\t}\r\n\treturn app.validate()\r\n}","code-length":124,"reference":"\/\/ validateNew checks app name format, pool and plan","result":"Validate the app.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) validate() error {\r\n\terr := app.validatePool()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn app.validatePlan()\r\n}","code-length":59,"reference":"\/\/ validate checks app pool and plan","result":"Validate the app.","score":[0,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) InstanceEnvs(serviceName, instanceName string) map[string]bind.EnvVar {\r\n\tenvs := make(map[string]bind.EnvVar)\r\n\tfor _, env := range app.ServiceEnvs {\r\n\t\tif env.ServiceName == serviceName && env.InstanceName == instanceName {\r\n\t\t\tenvs[env.Name] = env.EnvVar\r\n\t\t}\r\n\t}\r\n\treturn envs\r\n}","code-length":113,"reference":"\/\/ InstanceEnvs returns a map of environment variables that belongs to the\n\/\/ given service and service instance.","result":"Get the instance envs from the service.","score":[0.0336,0.0296]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) Run(cmd string, w io.Writer, args provision.RunArgs) error {\r\n\tif !args.Isolated && !app.available() {\r\n\t\treturn errors.New(\"App must be available to run non-isolated commands\")\r\n\t}\r\n\tapp.Log(fmt.Sprintf(\"running '%s'\", cmd), \"tsuru\", \"api\")\r\n\tlogWriter := LogWriter{App: app, Source: \"app-run\"}\r\n\tlogWriter.Async()\r\n\tdefer logWriter.Close()\r\n\treturn app.run(cmd, io.MultiWriter(w, &logWriter), args)\r\n}","code-length":165,"reference":"\/\/ Run executes the command in app units, sourcing apprc before running the\n\/\/ command.","result":"Run commands in a container.","score":[0.0387,0.1825]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) GetUnits() ([]bind.Unit, error) {\r\n\tprovUnits, err := app.Units()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tunits := make([]bind.Unit, len(provUnits))\r\n\tfor i := range provUnits {\r\n\t\tunits[i] = &provUnits[i]\r\n\t}\r\n\treturn units, nil\r\n}","code-length":115,"reference":"\/\/ GetUnits returns the internal list of units converted to bind.Unit.","result":"Generate code for unit definitions.","score":[0,0.0481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) GetUUID() (string, error) {\r\n\tif app.UUID != \"\" {\r\n\t\treturn app.UUID, nil\r\n\t}\r\n\tuuidV4, err := uuid.NewV4()\r\n\tif err != nil {\r\n\t\treturn \"\", errors.WithMessage(err, \"failed to generate uuid v4\")\r\n\t}\r\n\tconn, err := db.Conn()\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tdefer conn.Close()\r\n\terr = conn.Apps().Update(bson.M{\"name\": app.Name}, bson.M{\"$set\": bson.M{\"uuid\": uuidV4.String()}})\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tapp.UUID = uuidV4.String()\r\n\treturn app.UUID, nil\r\n}","code-length":220,"reference":"\/\/ GetUUID returns the app v4 UUID. An UUID will be generated\n\/\/ if it does not exist.","result":"Generate the UUID for the app.","score":[0.0311,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) Envs() map[string]bind.EnvVar {\r\n\tmergedEnvs := make(map[string]bind.EnvVar, len(app.Env)+len(app.ServiceEnvs)+1)\r\n\tfor _, e := range app.Env {\r\n\t\tmergedEnvs[e.Name] = e\r\n\t}\r\n\tfor _, e := range app.ServiceEnvs {\r\n\t\tmergedEnvs[e.Name] = e.EnvVar\r\n\t}\r\n\tmergedEnvs[TsuruServicesEnvVar] = serviceEnvsFromEnvVars(app.ServiceEnvs)\r\n\treturn mergedEnvs\r\n}","code-length":166,"reference":"\/\/ Envs returns a map representing the apps environment variables.","result":"Generate the app.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) SetEnvs(setEnvs bind.SetEnvArgs) error {\r\n\tif len(setEnvs.Envs) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\tfor _, env := range setEnvs.Envs {\r\n\t\terr := validateEnv(env.Name)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tif setEnvs.Writer != nil {\r\n\t\tfmt.Fprintf(setEnvs.Writer, \"---- Setting %d new environment variables ----\\n\", len(setEnvs.Envs))\r\n\t}\r\n\tfor _, env := range setEnvs.Envs {\r\n\t\tapp.setEnv(env)\r\n\t}\r\n\tconn, err := db.Conn()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer conn.Close()\r\n\terr = conn.Apps().Update(bson.M{\"name\": app.Name}, bson.M{\"$set\": bson.M{\"env\": app.Env}})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif setEnvs.ShouldRestart {\r\n\t\treturn app.restartIfUnits(setEnvs.Writer)\r\n\t}\r\n\treturn nil\r\n}","code-length":327,"reference":"\/\/ SetEnvs saves a list of environment variables in the app.","result":"Set environment variables in the app.","score":[0.3492,0.4743]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) UnsetEnvs(unsetEnvs bind.UnsetEnvArgs) error {\r\n\tif len(unsetEnvs.VariableNames) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\tif unsetEnvs.Writer != nil {\r\n\t\tfmt.Fprintf(unsetEnvs.Writer, \"---- Unsetting %d environment variables ----\\n\", len(unsetEnvs.VariableNames))\r\n\t}\r\n\tfor _, name := range unsetEnvs.VariableNames {\r\n\t\tdelete(app.Env, name)\r\n\t}\r\n\tconn, err := db.Conn()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer conn.Close()\r\n\terr = conn.Apps().Update(bson.M{\"name\": app.Name}, bson.M{\"$set\": bson.M{\"env\": app.Env}})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif unsetEnvs.ShouldRestart {\r\n\t\treturn app.restartIfUnits(unsetEnvs.Writer)\r\n\t}\r\n\treturn nil\r\n}","code-length":275,"reference":"\/\/ UnsetEnvs removes environment variables from an app, serializing the\n\/\/ remaining list of environment variables to all units of the app.","result":"Unset environment variables from the app.","score":[0.0337,0.2186]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) AddCName(cnames ...string) error {\r\n\tactions := []*action.Action{\r\n\t\t&validateNewCNames,\r\n\t\t&setNewCNamesToProvisioner,\r\n\t\t&saveCNames,\r\n\t\t&updateApp,\r\n\t}\r\n\terr := action.NewPipeline(actions...).Execute(app, cnames)\r\n\trebuild.RoutesRebuildOrEnqueue(app.Name)\r\n\treturn err\r\n}","code-length":124,"reference":"\/\/ AddCName adds a CName to app. It updates the attribute,\n\/\/ calls the SetCName function on the provisioner and saves\n\/\/ the app in the database, returning an error when it cannot save the change\n\/\/ in the database or add the CName on the provisioner.","result":"Add new CNames to the provisioner.","score":[0.0003,0.0867]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) Log(message, source, unit string) error {\r\n\tmessages := strings.Split(message, \"\\n\")\r\n\tlogs := make([]interface{}, 0, len(messages))\r\n\tfor _, msg := range messages {\r\n\t\tif msg != \"\" {\r\n\t\t\tl := Applog{\r\n\t\t\t\tDate:    time.Now().In(time.UTC),\r\n\t\t\t\tMessage: msg,\r\n\t\t\t\tSource:  source,\r\n\t\t\t\tAppName: app.Name,\r\n\t\t\t\tUnit:    unit,\r\n\t\t\t}\r\n\t\t\tlogs = append(logs, l)\r\n\t\t}\r\n\t}\r\n\tif len(logs) > 0 {\r\n\t\tconn, err := db.LogConn()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdefer conn.Close()\r\n\t\treturn conn.AppLogCollection(app.Name).Insert(logs...)\r\n\t}\r\n\treturn nil\r\n}","code-length":250,"reference":"\/\/ Log adds a log message to the app. Specifying a good source is good so the\n\/\/ user can filter where the message come from.","result":"Log the message.","score":[0.0002,0.0422]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) LastLogs(lines int, filterLog Applog) ([]Applog, error) {\r\n\treturn app.lastLogs(lines, filterLog, false)\r\n}","code-length":53,"reference":"\/\/ LastLogs returns a list of the last `lines` log of the app, matching the\n\/\/ fields in the log instance received as an example.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc List(filter *Filter) ([]App, error) {\r\n\tapps := []App{}\r\n\tquery := filter.Query()\r\n\tconn, err := db.Conn()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\terr = conn.Apps().Find(query).All(&apps)\r\n\tconn.Close()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif filter != nil && len(filter.Statuses) > 0 {\r\n\t\tappsProvisionerMap := make(map[string][]provision.App)\r\n\t\tvar prov provision.Provisioner\r\n\t\tfor i := range apps {\r\n\t\t\ta := &apps[i]\r\n\t\t\tprov, err = a.getProvisioner()\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\tappsProvisionerMap[prov.GetName()] = append(appsProvisionerMap[prov.GetName()], a)\r\n\t\t}\r\n\t\tvar provisionApps []provision.App\r\n\t\tfor provName, apps := range appsProvisionerMap {\r\n\t\t\tprov, err = provision.Get(provName)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\tif filterProv, ok := prov.(provision.AppFilterProvisioner); ok {\r\n\t\t\t\tapps, err = filterProv.FilterAppsByUnitStatus(apps, filter.Statuses)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn nil, err\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tprovisionApps = append(provisionApps, apps...)\r\n\t\t}\r\n\t\tfor i := range provisionApps {\r\n\t\t\tapps[i] = *(provisionApps[i].(*App))\r\n\t\t}\r\n\t\tapps = apps[:len(provisionApps)]\r\n\t}\r\n\terr = loadCachedAddrsInApps(apps)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn apps, nil\r\n}","code-length":501,"reference":"\/\/ List returns the list of apps filtered through the filter parameter.","result":"List apps in the db.","score":[0.078,0.1327]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Swap(app1, app2 *App, cnameOnly bool) error {\r\n\ta1Routers := app1.GetRouters()\r\n\ta2Routers := app2.GetRouters()\r\n\tif len(a1Routers) != 1 || len(a2Routers) != 1 {\r\n\t\treturn errors.New(\"swapping apps with multiple routers is not supported\")\r\n\t}\r\n\tr1, err := router.Get(a1Routers[0].Name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tr2, err := router.Get(a2Routers[0].Name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer func(app1, app2 *App) {\r\n\t\trebuild.RoutesRebuildOrEnqueue(app1.Name)\r\n\t\trebuild.RoutesRebuildOrEnqueue(app2.Name)\r\n\t\tapp1.GetRoutersWithAddr()\r\n\t\tapp2.GetRoutersWithAddr()\r\n\t}(app1, app2)\r\n\terr = r1.Swap(app1.Name, app2.Name, cnameOnly)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tconn, err := db.Conn()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer conn.Close()\r\n\tapp1.CName, app2.CName = app2.CName, app1.CName\r\n\tupdateCName := func(app *App, r router.Router) error {\r\n\t\treturn conn.Apps().Update(\r\n\t\t\tbson.M{\"name\": app.Name},\r\n\t\t\tbson.M{\"$set\": bson.M{\"cname\": app.CName}},\r\n\t\t)\r\n\t}\r\n\terr = updateCName(app1, r1)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn updateCName(app2, r2)\r\n}","code-length":502,"reference":"\/\/ Swap calls the Router.Swap and updates the app.CName in the database.","result":"Swap routes in app.","score":[0.0514,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (app *App) Start(w io.Writer, process string) error {\r\n\tw = app.withLogWriter(w)\r\n\tmsg := fmt.Sprintf(\"\\n ---> Starting the process %q\", process)\r\n\tif process == \"\" {\r\n\t\tmsg = fmt.Sprintf(\"\\n ---> Starting the app %q\", app.Name)\r\n\t}\r\n\tfmt.Fprintf(w, \"%s\\n\", msg)\r\n\tprov, err := app.getProvisioner()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = prov.Start(app, process)\r\n\tif err != nil {\r\n\t\tlog.Errorf(\"[start] error on start the app %s - %s\", app.Name, err)\r\n\t\treturn err\r\n\t}\r\n\trebuild.RoutesRebuildOrEnqueue(app.Name)\r\n\treturn err\r\n}","code-length":227,"reference":"\/\/ Start starts the app calling the provisioner.Start method and\n\/\/ changing the units state to StatusStarted.","result":"Start the app.","score":[0.0046,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetDbDriver(name string) (*DbDriver, error) {\r\n\tdriver, ok := dbDrivers[name]\r\n\tif !ok {\r\n\t\treturn nil, errors.Errorf(\"Unknown database driver: %q.\", name)\r\n\t}\r\n\treturn &driver, nil\r\n}","code-length":80,"reference":"\/\/ GetDbDriver returns the DB driver that was registered with a specific name","result":"Get the driver.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetCurrentDbDriver() (*DbDriver, error) {\r\n\tdriverLock.RLock()\r\n\tif currentDbDriver != nil {\r\n\t\tdriverLock.RUnlock()\r\n\t\treturn currentDbDriver, nil\r\n\t}\r\n\tdriverLock.RUnlock()\r\n\tdriverLock.Lock()\r\n\tdefer driverLock.Unlock()\r\n\tif currentDbDriver != nil {\r\n\t\treturn currentDbDriver, nil\r\n\t}\r\n\tdbDriverName, err := config.GetString(\"database:driver\")\r\n\tif err != nil || dbDriverName == \"\" {\r\n\t\tdbDriverName = DefaultDbDriverName\r\n\t}\r\n\tcurrentDbDriver, err = GetDbDriver(dbDriverName)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn currentDbDriver, nil\r\n}","code-length":213,"reference":"\/\/ GetCurrentDbDriver returns the DB driver specified in the configuration file.\n\/\/ If this configuration was omitted, it returns the default DB driver","result":"Get the current db driver .","score":[0.0135,0.12]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewForConfig(c *rest.Config) (*Clientset, error) {\r\n\tconfigShallowCopy := *c\r\n\tif configShallowCopy.RateLimiter == nil && configShallowCopy.QPS > 0 {\r\n\t\tconfigShallowCopy.RateLimiter = flowcontrol.NewTokenBucketRateLimiter(configShallowCopy.QPS, configShallowCopy.Burst)\r\n\t}\r\n\tvar cs Clientset\r\n\tvar err error\r\n\tcs.tsuruV1, err = tsuruv1.NewForConfig(&configShallowCopy)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tcs.DiscoveryClient, err = discovery.NewDiscoveryClientForConfig(&configShallowCopy)\r\n\tif err != nil {\r\n\t\tglog.Errorf(\"failed to create the DiscoveryClient: %v\", err)\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &cs, nil\r\n}","code-length":237,"reference":"\/\/ NewForConfig creates a new Clientset for the given config.","result":"Create a new client.","score":[0.1008,0.3132]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *dockerProvisioner) GetAppFromUnitID(unitID string) (provision.App, error) {\r\n\tcnt, err := p.GetContainer(unitID)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\ta, err := app.GetByName(cnt.AppName)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn a, nil\r\n}","code-length":116,"reference":"\/\/ GetAppFromUnitID returns app from unit id","result":"Get the app from unitID.","score":[0.2278,0.2757]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPipeline(actions ...*Action) *Pipeline {\r\n\t\r\n\t\r\n\tnewActions := make([]*Action, len(actions))\r\n\tfor i, action := range actions {\r\n\t\tnewAction := &Action{\r\n\t\t\tName:      action.Name,\r\n\t\t\tForward:   action.Forward,\r\n\t\t\tBackward:  action.Backward,\r\n\t\t\tMinParams: action.MinParams,\r\n\t\t\tOnError:   action.OnError,\r\n\t\t}\r\n\t\tnewActions[i] = newAction\r\n\t}\r\n\treturn &Pipeline{actions: newActions}\r\n}","code-length":155,"reference":"\/\/ NewPipeline creates a new pipeline instance with the given list of actions.","result":"Create a new pipeline.","score":[0.0476,0.2433]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Pipeline) Result() Result {\r\n\taction := p.actions[len(p.actions)-1]\r\n\taction.rMutex.Lock()\r\n\tdefer action.rMutex.Unlock()\r\n\treturn action.result\r\n}","code-length":67,"reference":"\/\/ Result returns the result of the last action.","result":"Return the result of the pipeline.","score":[0.3665,0.5724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Request) DecodeJsonPayload(v interface{}) error {\r\n\tcontent, err := ioutil.ReadAll(r.Body)\r\n\tr.Body.Close()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif len(content) == 0 {\r\n\t\treturn ErrJsonPayloadEmpty\r\n\t}\r\n\terr = json.Unmarshal(content, v)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":131,"reference":"\/\/ DecodeJsonPayload reads the request body and decodes the JSON using json.Unmarshal.","result":"Decode json payload.","score":[0,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Request) UrlFor(path string, queryParams map[string][]string) *url.URL {\r\n\tbaseUrl := r.BaseUrl()\r\n\tbaseUrl.Path = path\r\n\tif queryParams != nil {\r\n\t\tquery := url.Values{}\r\n\t\tfor k, v := range queryParams {\r\n\t\t\tfor _, vv := range v {\r\n\t\t\t\tquery.Add(k, vv)\r\n\t\t\t}\r\n\t\t}\r\n\t\tbaseUrl.RawQuery = query.Encode()\r\n\t}\r\n\treturn baseUrl\r\n}","code-length":140,"reference":"\/\/ UrlFor returns the URL object from UriBase with the Path set to path, and the query\n\/\/ string built with queryParams.","result":"Generate the url for the request.","score":[0.016,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Request) GetCorsInfo() *CorsInfo {\r\n\torigin := r.Header.Get(\"Origin\")\r\n\tvar originUrl *url.URL\r\n\tvar isCors bool\r\n\tif origin == \"\" {\r\n\t\tisCors = false\r\n\t} else if origin == \"null\" {\r\n\t\tisCors = true\r\n\t} else {\r\n\t\tvar err error\r\n\t\toriginUrl, err = url.ParseRequestURI(origin)\r\n\t\tisCors = err == nil && r.Host != originUrl.Host\r\n\t}\r\n\treqMethod := r.Header.Get(\"Access-Control-Request-Method\")\r\n\treqHeaders := []string{}\r\n\trawReqHeaders := r.Header[http.CanonicalHeaderKey(\"Access-Control-Request-Headers\")]\r\n\tfor _, rawReqHeader := range rawReqHeaders {\r\n\t\tif len(rawReqHeader) == 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tfor _, reqHeader := range strings.Split(rawReqHeader, \",\") {\r\n\t\t\treqHeaders = append(reqHeaders, http.CanonicalHeaderKey(strings.TrimSpace(reqHeader)))\r\n\t\t}\r\n\t}\r\n\tisPreflight := isCors && r.Method == \"OPTIONS\" && reqMethod != \"\"\r\n\treturn &CorsInfo{\r\n\t\tIsCors:                      isCors,\r\n\t\tIsPreflight:                 isPreflight,\r\n\t\tOrigin:                      origin,\r\n\t\tOriginUrl:                   originUrl,\r\n\t\tAccessControlRequestMethod:  strings.ToUpper(reqMethod),\r\n\t\tAccessControlRequestHeaders: reqHeaders,\r\n\t}\r\n}","code-length":412,"reference":"\/\/ GetCorsInfo derives CorsInfo from Request.","result":"Get CORS info from the request.","score":[0.193,0.1667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mw *CorsMiddleware) MiddlewareFunc(handler HandlerFunc) HandlerFunc {\r\n\t\r\n\tmw.allowedMethods = map[string]bool{}\r\n\tnormedMethods := []string{}\r\n\tfor _, allowedMethod := range mw.AllowedMethods {\r\n\t\tnormed := strings.ToUpper(allowedMethod)\r\n\t\tmw.allowedMethods[normed] = true\r\n\t\tnormedMethods = append(normedMethods, normed)\r\n\t}\r\n\tmw.allowedMethodsCsv = strings.Join(normedMethods, \",\")\r\n\tmw.allowedHeaders = map[string]bool{}\r\n\tnormedHeaders := []string{}\r\n\tfor _, allowedHeader := range mw.AllowedHeaders {\r\n\t\tnormed := http.CanonicalHeaderKey(allowedHeader)\r\n\t\tmw.allowedHeaders[normed] = true\r\n\t\tnormedHeaders = append(normedHeaders, normed)\r\n\t}\r\n\tmw.allowedHeadersCsv = strings.Join(normedHeaders, \",\")\r\n\treturn func(writer ResponseWriter, request *Request) {\r\n\t\tcorsInfo := request.GetCorsInfo()\r\n\t\t\r\n\t\tif !corsInfo.IsCors {\r\n\t\t\tif mw.RejectNonCorsRequests {\r\n\t\t\t\tError(writer, \"Non CORS request\", http.StatusForbidden)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\thandler(writer, request)\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\tif mw.OriginValidator(corsInfo.Origin, request) == false {\r\n\t\t\tError(writer, \"Invalid Origin\", http.StatusForbidden)\r\n\t\t\treturn\r\n\t\t}\r\n\t\tif corsInfo.IsPreflight {\r\n\t\t\t\r\n\t\t\tif mw.allowedMethods[corsInfo.AccessControlRequestMethod] == false {\r\n\t\t\t\tError(writer, \"Invalid Preflight Request\", http.StatusForbidden)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tfor _, requestedHeader := range corsInfo.AccessControlRequestHeaders {\r\n\t\t\t\tif mw.allowedHeaders[requestedHeader] == false {\r\n\t\t\t\t\tError(writer, \"Invalid Preflight Request\", http.StatusForbidden)\r\n\t\t\t\t\treturn\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\twriter.Header().Set(\"Access-Control-Allow-Methods\", mw.allowedMethodsCsv)\r\n\t\t\twriter.Header().Set(\"Access-Control-Allow-Headers\", mw.allowedHeadersCsv)\r\n\t\t\twriter.Header().Set(\"Access-Control-Allow-Origin\", corsInfo.Origin)\r\n\t\t\tif mw.AccessControlAllowCredentials == true {\r\n\t\t\t\twriter.Header().Set(\"Access-Control-Allow-Credentials\", \"true\")\r\n\t\t\t}\r\n\t\t\twriter.Header().Set(\"Access-Control-Max-Age\", strconv.Itoa(mw.AccessControlMaxAge))\r\n\t\t\twriter.WriteHeader(http.StatusOK)\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\tfor _, exposed := range mw.AccessControlExposeHeaders {\r\n\t\t\twriter.Header().Add(\"Access-Control-Expose-Headers\", exposed)\r\n\t\t}\r\n\t\twriter.Header().Set(\"Access-Control-Allow-Origin\", corsInfo.Origin)\r\n\t\tif mw.AccessControlAllowCredentials == true {\r\n\t\t\twriter.Header().Set(\"Access-Control-Allow-Credentials\", \"true\")\r\n\t\t}\r\n\t\t\r\n\t\thandler(writer, request)\r\n\t\treturn\r\n\t}\r\n}","code-length":846,"reference":"\/\/ MiddlewareFunc makes CorsMiddleware implement the Middleware interface.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mw *RecorderMiddleware) MiddlewareFunc(h HandlerFunc) HandlerFunc {\r\n\treturn func(w ResponseWriter, r *Request) {\r\n\t\twriter := &recorderResponseWriter{w, 0, false, 0}\r\n\t\t\r\n\t\th(writer, r)\r\n\t\tr.Env[\"STATUS_CODE\"] = writer.statusCode\r\n\t\tr.Env[\"BYTES_WRITTEN\"] = writer.bytesWritten\r\n\t}\r\n}","code-length":114,"reference":"\/\/ MiddlewareFunc makes RecorderMiddleware implement the Middleware interface.","result":"Add the recorder middleware.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *recorderResponseWriter) WriteHeader(code int) {\r\n\tw.ResponseWriter.WriteHeader(code)\r\n\tif w.wroteHeader {\r\n\t\treturn\r\n\t}\r\n\tw.statusCode = code\r\n\tw.wroteHeader = true\r\n}","code-length":77,"reference":"\/\/ Record the status code.","result":"Write the response to the recorder.","score":[0.193,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MakeRouter(routes ...*Route) (App, error) {\r\n\tr := &router{\r\n\t\tRoutes: routes,\r\n\t}\r\n\terr := r.start()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn r, nil\r\n}","code-length":83,"reference":"\/\/ MakeRouter returns the router app. Given a set of Routes, it dispatches the request to the\n\/\/ HandlerFunc of the first route that matches. The order of the Routes matters.","result":"Create the router.","score":[0.0,0.0177]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rt *router) AppFunc() HandlerFunc {\r\n\treturn func(writer ResponseWriter, request *Request) {\r\n\t\t\r\n\t\troute, params, pathMatched := rt.findRouteFromURL(request.Method, request.URL)\r\n\t\tif route == nil {\r\n\t\t\tif pathMatched {\r\n\t\t\t\t\r\n\t\t\t\tError(writer, \"Method not allowed\", http.StatusMethodNotAllowed)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tNotFound(writer, request)\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\trequest.PathParams = params\r\n\t\t\r\n\t\thandler := route.Func\r\n\t\thandler(writer, request)\r\n\t}\r\n}","code-length":177,"reference":"\/\/ Handle the REST routing and run the user code.","result":"Generate code for the generated code.","score":[0.1179,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc escapedPath(urlObj *url.URL) string {\r\n\t\r\n\t\r\n\tparts := strings.SplitN(urlObj.RequestURI(), \"?\", 2)\r\n\treturn parts[0]\r\n}","code-length":59,"reference":"\/\/ This is run for each new request, perf is important.","result":"Escape the path.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc escapedPathExp(pathExp string) (string, error) {\r\n\t\r\n\tif pathExp == \"\" {\r\n\t\treturn \"\", errors.New(\"empty PathExp\")\r\n\t}\r\n\tif pathExp[0] != '\/' {\r\n\t\treturn \"\", errors.New(\"PathExp must start with \/\")\r\n\t}\r\n\tif strings.Contains(pathExp, \"?\") {\r\n\t\treturn \"\", errors.New(\"PathExp must not contain the query string\")\r\n\t}\r\n\t\r\n\t\r\n\tpathExp = preEscape.Replace(pathExp)\r\n\turlObj, err := url.Parse(pathExp)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\t\r\n\tpathExp = urlObj.RequestURI()\r\n\tpathExp = postEscape.Replace(pathExp)\r\n\treturn pathExp, nil\r\n}","code-length":218,"reference":"\/\/ This is run at init time only.","result":"Escape the pathExp.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rt *router) start() error {\r\n\trt.trie = trie.New()\r\n\trt.index = map[*Route]int{}\r\n\tfor i, route := range rt.Routes {\r\n\t\t\r\n\t\tpathExp, err := escapedPathExp(route.PathExp)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\terr = rt.trie.AddRoute(\r\n\t\t\tstrings.ToUpper(route.HttpMethod),\r\n\t\t\tpathExp,\r\n\t\t\troute,\r\n\t\t)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\trt.index[route] = i\r\n\t}\r\n\tif rt.disableTrieCompression == false {\r\n\t\trt.trie.Compress()\r\n\t}\r\n\treturn nil\r\n}","code-length":219,"reference":"\/\/ This validates the Routes and prepares the Trie data structure.\n\/\/ It must be called once the Routes are defined and before trying to find Routes.\n\/\/ The order matters, if multiple Routes match, the first defined will be used.","result":"Start the router.","score":[0.0,0.0269]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rt *router) ofFirstDefinedRoute(matches []*trie.Match) *trie.Match {\r\n\tminIndex := -1\r\n\tvar bestMatch *trie.Match\r\n\tfor _, result := range matches {\r\n\t\troute := result.Route.(*Route)\r\n\t\trouteIndex := rt.index[route]\r\n\t\tif minIndex == -1 || routeIndex < minIndex {\r\n\t\t\tminIndex = routeIndex\r\n\t\t\tbestMatch = result\r\n\t\t}\r\n\t}\r\n\treturn bestMatch\r\n}","code-length":139,"reference":"\/\/ return the result that has the route defined the earliest","result":"Find the first route in the route index.","score":[0.1494,0.1402]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rt *router) findRouteFromURL(httpMethod string, urlObj *url.URL) (*Route, map[string]string, bool) {\r\n\t\r\n\tmatches, pathMatched := rt.trie.FindRoutesAndPathMatched(\r\n\t\tstrings.ToUpper(httpMethod),\r\n\t\tescapedPath(urlObj),\r\n\t)\r\n\t\r\n\tif len(matches) == 0 {\r\n\t\t\r\n\t\treturn nil, nil, pathMatched\r\n\t}\r\n\tif len(matches) == 1 {\r\n\t\t\r\n\t\treturn matches[0].Route.(*Route), matches[0].Params, pathMatched\r\n\t}\r\n\t\r\n\tresult := rt.ofFirstDefinedRoute(matches)\r\n\treturn result.Route.(*Route), result.Params, pathMatched\r\n}","code-length":200,"reference":"\/\/ Return the first matching Route and the corresponding parameters for a given URL object.","result":"Find the route from a URL.","score":[0.0512,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mw *ContentTypeCheckerMiddleware) MiddlewareFunc(handler HandlerFunc) HandlerFunc {\r\n\treturn func(w ResponseWriter, r *Request) {\r\n\t\tmediatype, params, _ := mime.ParseMediaType(r.Header.Get(\"Content-Type\"))\r\n\t\tcharset, ok := params[\"charset\"]\r\n\t\tif !ok {\r\n\t\t\tcharset = \"UTF-8\"\r\n\t\t}\r\n\t\t\r\n\t\tif r.ContentLength > 0 &&\r\n\t\t\t!(mediatype == \"application\/json\" && strings.ToUpper(charset) == \"UTF-8\") {\r\n\t\t\tError(w,\r\n\t\t\t\t\"Bad Content-Type or charset, expected 'application\/json'\",\r\n\t\t\t\thttp.StatusUnsupportedMediaType,\r\n\t\t\t)\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\thandler(w, r)\r\n\t}\r\n}","code-length":219,"reference":"\/\/ MiddlewareFunc makes ContentTypeCheckerMiddleware implement the Middleware interface.","result":"Avoid the need for the import.","score":[0.1383,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *responseWriter) CloseNotify() <-chan bool {\r\n\tnotifier := w.ResponseWriter.(http.CloseNotifier)\r\n\treturn notifier.CloseNotify()\r\n}","code-length":52,"reference":"\/\/ Provided in order to implement the http.CloseNotifier interface.","result":"Generate the code.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mw *AccessLogApacheMiddleware) MiddlewareFunc(h HandlerFunc) HandlerFunc {\r\n\t\r\n\tif mw.Logger == nil {\r\n\t\tmw.Logger = log.New(os.Stderr, \"\", 0)\r\n\t}\r\n\t\r\n\tif mw.Format == \"\" {\r\n\t\tmw.Format = DefaultLogFormat\r\n\t}\r\n\tmw.convertFormat()\r\n\treturn func(w ResponseWriter, r *Request) {\r\n\t\t\r\n\t\th(w, r)\r\n\t\tutil := &accessLogUtil{w, r}\r\n\t\tmw.Logger.Print(mw.executeTextTemplate(util))\r\n\t}\r\n}","code-length":172,"reference":"\/\/ MiddlewareFunc makes AccessLogApacheMiddleware implement the Middleware interface.","result":"Replace the default middleware function.","score":[0.1319,0.1299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mw *AccessLogApacheMiddleware) executeTextTemplate(util *accessLogUtil) string {\r\n\tbuf := bytes.NewBufferString(\"\")\r\n\terr := mw.textTemplate.Execute(buf, util)\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\treturn buf.String()\r\n}","code-length":92,"reference":"\/\/ Execute the text template with the data derived from the request, and return a string.","result":"Execute text template.","score":[0.0064,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *accessLogUtil) RemoteUser() string {\r\n\tif u.R.Env[\"REMOTE_USER\"] != nil {\r\n\t\treturn u.R.Env[\"REMOTE_USER\"].(string)\r\n\t}\r\n\treturn \"\"\r\n}","code-length":70,"reference":"\/\/ As stored by the auth middlewares.","result":"Access the remote user.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *accessLogUtil) ApacheQueryString() string {\r\n\tif u.R.URL.RawQuery != \"\" {\r\n\t\treturn \"?\" + u.R.URL.RawQuery\r\n\t}\r\n\treturn \"\"\r\n}","code-length":64,"reference":"\/\/ If qs exists then return it with a leadin \"?\", apache log style.","result":"Generate ApacheQueryString .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *accessLogUtil) StartTime() *time.Time {\r\n\tif u.R.Env[\"START_TIME\"] != nil {\r\n\t\treturn u.R.Env[\"START_TIME\"].(*time.Time)\r\n\t}\r\n\treturn nil\r\n}","code-length":74,"reference":"\/\/ When the request entered the timer middleware.","result":"Access the log.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *accessLogUtil) ApacheRemoteAddr() string {\r\n\tremoteAddr := u.R.RemoteAddr\r\n\tif remoteAddr != \"\" {\r\n\t\tif ip, _, err := net.SplitHostPort(remoteAddr); err == nil {\r\n\t\t\treturn ip\r\n\t\t}\r\n\t}\r\n\treturn \"\"\r\n}","code-length":89,"reference":"\/\/ If remoteAddr is set then return is without the port number, apache log style.","result":"Generate Apache code.","score":[0,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *accessLogUtil) ResponseTime() *time.Duration {\r\n\tif u.R.Env[\"ELAPSED_TIME\"] != nil {\r\n\t\treturn u.R.Env[\"ELAPSED_TIME\"].(*time.Duration)\r\n\t}\r\n\treturn nil\r\n}","code-length":79,"reference":"\/\/ As mesured by the timer middleware.","result":"Access the response time.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mw *JsonIndentMiddleware) MiddlewareFunc(handler HandlerFunc) HandlerFunc {\r\n\tif mw.Indent == \"\" {\r\n\t\tmw.Indent = \"  \"\r\n\t}\r\n\treturn func(w ResponseWriter, r *Request) {\r\n\t\twriter := &jsonIndentResponseWriter{w, false, mw.Prefix, mw.Indent}\r\n\t\t\r\n\t\thandler(writer, r)\r\n\t}\r\n}","code-length":110,"reference":"\/\/ MiddlewareFunc makes JsonIndentMiddleware implement the Middleware interface.","result":"Replace the middleware function .","score":[0.1319,0.2435]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *jsonIndentResponseWriter) EncodeJson(v interface{}) ([]byte, error) {\r\n\tb, err := json.MarshalIndent(v, w.prefix, w.indent)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn b, nil\r\n}","code-length":84,"reference":"\/\/ Replace the parent EncodeJson to provide indentation.","result":"Encode json.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *jsonIndentResponseWriter) WriteHeader(code int) {\r\n\tw.ResponseWriter.WriteHeader(code)\r\n\tw.wroteHeader = true\r\n}","code-length":50,"reference":"\/\/ Call the parent WriteHeader.","result":"Indent the output.","score":[0.2096,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (route *Route) MakePath(pathParams map[string]string) string {\r\n\tpath := route.PathExp\r\n\tfor paramName, paramValue := range pathParams {\r\n\t\tparamPlaceholder := \":\" + paramName\r\n\t\trelaxedPlaceholder := \"#\" + paramName\r\n\t\tsplatPlaceholder := \"*\" + paramName\r\n\t\tr := strings.NewReplacer(paramPlaceholder, paramValue, splatPlaceholder, paramValue, relaxedPlaceholder, paramValue)\r\n\t\tpath = r.Replace(path)\r\n\t}\r\n\treturn path\r\n}","code-length":133,"reference":"\/\/ MakePath generates the path corresponding to this Route and the provided path parameters.\n\/\/ This is used for reverse route resolution.","result":"Generate the path.","score":[0.0007,0.0498]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mw *RecoverMiddleware) MiddlewareFunc(h HandlerFunc) HandlerFunc {\r\n\t\r\n\tif mw.Logger == nil {\r\n\t\tmw.Logger = log.New(os.Stderr, \"\", 0)\r\n\t}\r\n\treturn func(w ResponseWriter, r *Request) {\r\n\t\t\r\n\t\tdefer func() {\r\n\t\t\tif reco := recover(); reco != nil {\r\n\t\t\t\ttrace := debug.Stack()\r\n\t\t\t\t\r\n\t\t\t\tmessage := fmt.Sprintf(\"%s\\n%s\", reco, trace)\r\n\t\t\t\tmw.logError(message)\r\n\t\t\t\t\r\n\t\t\t\tif mw.EnableResponseStackTrace {\r\n\t\t\t\t\tError(w, message, http.StatusInternalServerError)\r\n\t\t\t\t} else {\r\n\t\t\t\t\tError(w, \"Internal Server Error\", http.StatusInternalServerError)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}()\r\n\t\t\r\n\t\th(w, r)\r\n\t}\r\n}","code-length":239,"reference":"\/\/ MiddlewareFunc makes RecoverMiddleware implement the Middleware interface.","result":"Recover from panics.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WrapMiddlewares(middlewares []Middleware, handler HandlerFunc) HandlerFunc {\r\n\twrapped := handler\r\n\tfor i := len(middlewares) - 1; i >= 0; i-- {\r\n\t\twrapped = middlewares[i].MiddlewareFunc(wrapped)\r\n\t}\r\n\treturn wrapped\r\n}","code-length":78,"reference":"\/\/ WrapMiddlewares calls the MiddlewareFunc methods in the reverse order and returns an HandlerFunc\n\/\/ ready to be executed. This can be used to wrap a set of middlewares, post routing, on a per Route\n\/\/ basis.","result":"Wrap middlewares in a function.","score":[0.0005,0.0444]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mw *GzipMiddleware) MiddlewareFunc(h HandlerFunc) HandlerFunc {\r\n\treturn func(w ResponseWriter, r *Request) {\r\n\t\t\r\n\t\tcanGzip := strings.Contains(r.Header.Get(\"Accept-Encoding\"), \"gzip\")\r\n\t\t\r\n\t\twriter := &gzipResponseWriter{w, false, canGzip, nil}\r\n\t\tdefer func() {\r\n\t\t\t\r\n\t\t\tif writer.gzipWriter != nil {\r\n\t\t\t\twriter.gzipWriter.Close()\r\n\t\t\t}\r\n\t\t}()\r\n\t\t\r\n\t\th(writer, r)\r\n\t}\r\n}","code-length":155,"reference":"\/\/ MiddlewareFunc makes GzipMiddleware implement the Middleware interface.","result":"Prevent the middleware from being called twice.","score":[0.14,0.2373]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *gzipResponseWriter) WriteHeader(code int) {\r\n\t\r\n\t\r\n\tw.Header().Add(\"Vary\", \"Accept-Encoding\")\r\n\tif w.canGzip {\r\n\t\tw.Header().Set(\"Content-Encoding\", \"gzip\")\r\n\t}\r\n\tw.ResponseWriter.WriteHeader(code)\r\n\tw.wroteHeader = true\r\n}","code-length":102,"reference":"\/\/ Set the right headers for gzip encoded responses.","result":"Write the gzip header.","score":[0.1088,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *gzipResponseWriter) Hijack() (net.Conn, *bufio.ReadWriter, error) {\r\n\thijacker := w.ResponseWriter.(http.Hijacker)\r\n\treturn hijacker.Hijack()\r\n}","code-length":68,"reference":"\/\/ Provided in order to implement the http.Hijacker interface.","result":"Compress the gzipped response.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *gzipResponseWriter) Write(b []byte) (int, error) {\r\n\tif !w.wroteHeader {\r\n\t\tw.WriteHeader(http.StatusOK)\r\n\t}\r\n\twriter := w.ResponseWriter.(http.ResponseWriter)\r\n\tif w.canGzip {\r\n\t\t\r\n\t\t\r\n\t\tr(writer)\r\n\t\t}\r\n\t\tcount, errW := w.gzipWriter.Write(b)\r\n\t\terrF := w.gzipWriter.Flush()\r\n\t\tif errW != nil {\r\n\t\t\treturn count, errW\r\n\t\t}\r\n\t\tif errF != nil {\r\n\t\t\treturn count, errF\r\n\t\t}\r\n\t\treturn count, nil\r\n\t}\r\n\treturn writer.Write(b)\r\n}","code-length":207,"reference":"\/\/ Make sure the local WriteHeader is called, and encode the payload if necessary.\n\/\/ Provided in order to implement the http.ResponseWriter interface.","result":"Write gzipped data.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mw *AuthBasicMiddleware) MiddlewareFunc(handler HandlerFunc) HandlerFunc {\r\n\tif mw.Realm == \"\" {\r\n\t\tlog.Fatal(\"Realm is required\")\r\n\t}\r\n\tif mw.Authenticator == nil {\r\n\t\tlog.Fatal(\"Authenticator is required\")\r\n\t}\r\n\tif mw.Authorizator == nil {\r\n\t\tmw.Authorizator = func(userId string, request *Request) bool {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn func(writer ResponseWriter, request *Request) {\r\n\t\tauthHeader := request.Header.Get(\"Authorization\")\r\n\t\tif authHeader == \"\" {\r\n\t\t\tmw.unauthorized(writer)\r\n\t\t\treturn\r\n\t\t}\r\n\t\tprovidedUserId, providedPassword, err := mw.decodeBasicAuthHeader(authHeader)\r\n\t\tif err != nil {\r\n\t\t\tError(writer, \"Invalid authentication\", http.StatusBadRequest)\r\n\t\t\treturn\r\n\t\t}\r\n\t\tif !mw.Authenticator(providedUserId, providedPassword) {\r\n\t\t\tmw.unauthorized(writer)\r\n\t\t\treturn\r\n\t\t}\r\n\t\tif !mw.Authorizator(providedUserId, request) {\r\n\t\t\tmw.unauthorized(writer)\r\n\t\t\treturn\r\n\t\t}\r\n\t\trequest.Env[\"REMOTE_USER\"] = providedUserId\r\n\t\thandler(writer, request)\r\n\t}\r\n}","code-length":358,"reference":"\/\/ MiddlewareFunc makes AuthBasicMiddleware implement the Middleware interface.","result":"Replace the default middleware.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *node) printDebug(level int) {\r\n\tlevel++\r\n\t\r\n\tif n.SplatChild != nil {\r\n\t\tprintFPadding(level, \"*splat\\n\")\r\n\t\tn.SplatChild.printDebug(level)\r\n\t}\r\n\t\r\n\tif n.ParamChild != nil {\r\n\t\tprintFPadding(level, \":param\\n\")\r\n\t\tn.ParamChild.printDebug(level)\r\n\t}\r\n\t\r\n\tif n.RelaxedChild != nil {\r\n\t\tprintFPadding(level, \"#relaxed\\n\")\r\n\t\tn.RelaxedChild.printDebug(level)\r\n\t}\r\n\t\r\n\tfor key, node := range n.Children {\r\n\t\tprintFPadding(level, \"\\\"%s\\\"\\n\", key)\r\n\t\tnode.printDebug(level)\r\n\t}\r\n}","code-length":229,"reference":"\/\/ Private function for now","result":"Print debug information.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Trie) AddRoute(httpMethod, pathExp string, route interface{}) error {\r\n\treturn t.root.addRoute(httpMethod, pathExp, route, []string{})\r\n}","code-length":57,"reference":"\/\/ Insert the route in the Trie following or creating the nodes corresponding to the path.","result":"Generate the code.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Trie) printDebug() {\r\n\tfmt.Print(\"<trie>\\n\")\r\n\tt.root.printDebug(0)\r\n\tfmt.Print(\"<\/trie>\\n\")\r\n}","code-length":58,"reference":"\/\/ Private function for now.","result":"Print debug info.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Trie) FindRoutes(httpMethod, path string) []*Match {\r\n\tcontext := newFindContext()\r\n\tmatches := []*Match{}\r\n\tcontext.matchFunc = func(httpMethod, path string, node *node) {\r\n\t\tif node.HttpMethodToRoute[httpMethod] != nil {\r\n\t\t\t\r\n\t\t\tmatches = append(\r\n\t\t\t\tmatches,\r\n\t\t\t\t&Match{\r\n\t\t\t\t\tRoute:  node.HttpMethodToRoute[httpMethod],\r\n\t\t\t\t\tParams: context.paramsAsMap(),\r\n\t\t\t\t},\r\n\t\t\t)\r\n\t\t}\r\n\t}\r\n\tt.root.find(httpMethod, path, context)\r\n\treturn matches\r\n}","code-length":181,"reference":"\/\/ Given a path and an http method, return all the matching routes.","result":"Find all routes in the trie.","score":[0.0715,0.0813]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Trie) FindRoutesAndPathMatched(httpMethod, path string) ([]*Match, bool) {\r\n\tcontext := newFindContext()\r\n\tpathMatched := false\r\n\tmatches := []*Match{}\r\n\tcontext.matchFunc = func(httpMethod, path string, node *node) {\r\n\t\tpathMatched = true\r\n\t\tif node.HttpMethodToRoute[httpMethod] != nil {\r\n\t\t\t\r\n\t\t\tmatches = append(\r\n\t\t\t\tmatches,\r\n\t\t\t\t&Match{\r\n\t\t\t\t\tRoute:  node.HttpMethodToRoute[httpMethod],\r\n\t\t\t\t\tParams: context.paramsAsMap(),\r\n\t\t\t\t},\r\n\t\t\t)\r\n\t\t}\r\n\t}\r\n\tt.root.find(httpMethod, path, context)\r\n\treturn matches, pathMatched\r\n}","code-length":205,"reference":"\/\/ Same as FindRoutes, but return in addition a boolean indicating if the path was matched.\n\/\/ Useful to return 405","result":"Find routes and path matched.","score":[0.0116,0.0515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Trie) FindRoutesForPath(path string) []*Match {\r\n\tcontext := newFindContext()\r\n\tmatches := []*Match{}\r\n\tcontext.matchFunc = func(httpMethod, path string, node *node) {\r\n\t\tparams := context.paramsAsMap()\r\n\t\tfor _, route := range node.HttpMethodToRoute {\r\n\t\t\tmatches = append(\r\n\t\t\t\tmatches,\r\n\t\t\t\t&Match{\r\n\t\t\t\t\tRoute:  route,\r\n\t\t\t\t\tParams: params,\r\n\t\t\t\t},\r\n\t\t\t)\r\n\t\t}\r\n\t}\r\n\tt.root.find(\"\", path, context)\r\n\treturn matches\r\n}","code-length":173,"reference":"\/\/ Given a path, and whatever the http method, return all the matching routes.","result":"Find routes for a given path.","score":[0.0509,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (api *Api) Use(middlewares ...Middleware) {\r\n\tapi.stack = append(api.stack, middlewares...)\r\n}","code-length":41,"reference":"\/\/ Use pushes one or multiple middlewares to the stack for middlewares\n\/\/ maintained in the Api object.","result":"Create the api .","score":[0.0096,0.113]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (api *Api) MakeHandler() http.Handler {\r\n\tvar appFunc HandlerFunc\r\n\tif api.app != nil {\r\n\t\tappFunc = api.app.AppFunc()\r\n\t} else {\r\n\t\tappFunc = func(w ResponseWriter, r *Request) {}\r\n\t}\r\n\treturn http.HandlerFunc(\r\n\t\tadapterFunc(\r\n\t\t\tWrapMiddlewares(api.stack, appFunc),\r\n\t\t),\r\n\t)\r\n}","code-length":123,"reference":"\/\/ MakeHandler wraps all the Middlewares of the stack and the App together, and returns an\n\/\/ http.Handler ready to be used. If the Middleware stack is empty the App is used directly. If the\n\/\/ App is nil, a HandlerFunc that does nothing is used instead.","result":"Create a handler for the api.","score":[0.0002,0.0233]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mw *PoweredByMiddleware) MiddlewareFunc(h HandlerFunc) HandlerFunc {\r\n\tpoweredBy := xPoweredByDefault\r\n\tif mw.XPoweredBy != \"\" {\r\n\t\tpoweredBy = mw.XPoweredBy\r\n\t}\r\n\treturn func(w ResponseWriter, r *Request) {\r\n\t\tw.Header().Add(\"X-Powered-By\", poweredBy)\r\n\t\t\r\n\t\th(w, r)\r\n\t}\r\n}","code-length":118,"reference":"\/\/ MiddlewareFunc makes PoweredByMiddleware implement the Middleware interface.","result":"Wrap the middleware function .","score":[0.1319,0.2435]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mw *StatusMiddleware) MiddlewareFunc(h HandlerFunc) HandlerFunc {\r\n\tmw.start = time.Now()\r\n\tmw.pid = os.Getpid()\r\n\tmw.responseCounts = map[string]int{}\r\n\tmw.totalResponseTime = time.Time{}\r\n\treturn func(w ResponseWriter, r *Request) {\r\n\t\t\r\n\t\th(w, r)\r\n\t\tif r.Env[\"STATUS_CODE\"] == nil {\r\n\t\t\tlog.Fatal(\"StatusMiddleware: Env[\\\"STATUS_CODE\\\"] is nil, \" +\r\n\t\t\t\t\"RecorderMiddleware may not be in the wrapped Middlewares.\")\r\n\t\t}\r\n\t\tstatusCode := r.Env[\"STATUS_CODE\"].(int)\r\n\t\tif r.Env[\"ELAPSED_TIME\"] == nil {\r\n\t\t\tlog.Fatal(\"StatusMiddleware: Env[\\\"ELAPSED_TIME\\\"] is nil, \" +\r\n\t\t\t\t\"TimerMiddleware may not be in the wrapped Middlewares.\")\r\n\t\t}\r\n\t\tresponseTime := r.Env[\"ELAPSED_TIME\"].(*time.Duration)\r\n\t\tmw.lock.Lock()\r\n\t\tmw.responseCounts[fmt.Sprintf(\"%d\", statusCode)]++\r\n\t\tmw.totalResponseTime = mw.totalResponseTime.Add(*responseTime)\r\n\t\tmw.lock.Unlock()\r\n\t}\r\n}","code-length":349,"reference":"\/\/ MiddlewareFunc makes StatusMiddleware implement the Middleware interface.","result":"Wrap middleware functions .","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mw *StatusMiddleware) GetStatus() *Status {\r\n\tmw.lock.RLock()\r\n\tnow := time.Now()\r\n\tuptime := now.Sub(mw.start)\r\n\ttotalCount := 0\r\n\tfor _, count := range mw.responseCounts {\r\n\t\ttotalCount += count\r\n\t}\r\n\ttotalResponseTime := mw.totalResponseTime.Sub(time.Time{})\r\n\taverageResponseTime := time.Duration(0)\r\n\tif totalCount > 0 {\r\n\t\tavgNs := int64(totalResponseTime) \/ int64(totalCount)\r\n\t\taverageResponseTime = time.Duration(avgNs)\r\n\t}\r\n\tstatus := &Status{\r\n\t\tPid:                    mw.pid,\r\n\t\tUpTime:                 uptime.String(),\r\n\t\tUpTimeSec:              uptime.Seconds(),\r\n\t\tTime:                   now.String(),\r\n\t\tTimeUnix:               now.Unix(),\r\n\t\tStatusCodeCount:        mw.responseCounts,\r\n\t\tTotalCount:             totalCount,\r\n\t\tTotalResponseTime:      totalResponseTime.String(),\r\n\t\tTotalResponseTimeSec:   totalResponseTime.Seconds(),\r\n\t\tAverageResponseTime:    averageResponseTime.String(),\r\n\t\tAverageResponseTimeSec: averageResponseTime.Seconds(),\r\n\t}\r\n\tmw.lock.RUnlock()\r\n\treturn status\r\n}","code-length":346,"reference":"\/\/ GetStatus computes and returns a Status object based on the request informations accumulated\n\/\/ since the start of the process.","result":"Get the status from the middleware.","score":[0.0188,0.1026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mw *JsonpMiddleware) MiddlewareFunc(h HandlerFunc) HandlerFunc {\r\n\tif mw.CallbackNameKey == \"\" {\r\n\t\tmw.CallbackNameKey = \"callback\"\r\n\t}\r\n\treturn func(w ResponseWriter, r *Request) {\r\n\t\tcallbackName := r.URL.Query().Get(mw.CallbackNameKey)\r\n\t\t\r\n\t\tif callbackName != \"\" {\r\n\t\t\t\r\n\t\t\twriter := &jsonpResponseWriter{w, false, callbackName}\r\n\t\t\t\r\n\t\t\th(writer, r)\r\n\t\t} else {\r\n\t\t\t\r\n\t\t\th(w, r)\r\n\t\t}\r\n\t}\r\n}","code-length":172,"reference":"\/\/ MiddlewareFunc returns a HandlerFunc that implements the middleware.","result":"Replace the default middleware.","score":[0.1088,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *jsonpResponseWriter) Flush() {\r\n\tif !w.wroteHeader {\r\n\t\tw.WriteHeader(http.StatusOK)\r\n\t}\r\n\tflusher := w.ResponseWriter.(http.Flusher)\r\n\tflusher.Flush()\r\n}","code-length":78,"reference":"\/\/ Make sure the local WriteHeader is called, and call the parent Flush.\n\/\/ Provided in order to implement the http.Flusher interface.","result":"Flush the responseWriter.","score":[0.0007,0.0249]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mw *AccessLogJsonMiddleware) MiddlewareFunc(h HandlerFunc) HandlerFunc {\r\n\t\r\n\tif mw.Logger == nil {\r\n\t\tmw.Logger = log.New(os.Stderr, \"\", 0)\r\n\t}\r\n\treturn func(w ResponseWriter, r *Request) {\r\n\t\t\r\n\t\th(w, r)\r\n\t\tmw.Logger.Printf(\"%s\", makeAccessLogJsonRecord(r).asJson())\r\n\t}\r\n}","code-length":122,"reference":"\/\/ MiddlewareFunc makes AccessLogJsonMiddleware implement the Middleware interface.","result":"Wrap the middleware function .","score":[0.1319,0.2435]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *S3) Fetch() (io.Reader, error) {\r\n\t\r\n\tif s.delay {\r\n\t\ttime.Sleep(s.Interval)\r\n\t}\r\n\ts.delay = true\r\n\t\r\n\thead, err := s.client.HeadObject(&s3.HeadObjectInput{Bucket: &s.Bucket, Key: &s.Key})\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"HEAD request failed (%s)\", err)\r\n\t}\r\n\tif s.lastETag == *head.ETag {\r\n\t\treturn nil, nil\r\n\t}\r\n\ts.lastETag = *head.ETag\r\n\t\r\n\tget, err := s.client.GetObject(&s3.GetObjectInput{Bucket: &s.Bucket, Key: &s.Key})\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"GET request failed (%s)\", err)\r\n\t}\r\n\t\r\n\tif strings.HasSuffix(s.Key, \".gz\") && aws.StringValue(get.ContentEncoding) != \"gzip\" {\r\n\t\treturn gzip.NewReader(get.Body)\r\n\t}\r\n\t\r\n\treturn get.Body, nil\r\n}","code-length":308,"reference":"\/\/ Fetch the binary from S3","result":"Delay the fetch.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc sanityCheck() bool {\r\n\t\r\n\tif token := os.Getenv(envBinCheck); token != \"\" {\r\n\t\tfmt.Fprint(os.Stdout, token)\r\n\t\treturn true\r\n\t}\r\n\t\r\n\tif token := os.Getenv(envBinCheckLegacy); token != \"\" {\r\n\t\tfmt.Fprint(os.Stdout, token)\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":118,"reference":"\/\/sanityCheck returns true if a check was performed","result":"Check the validity of the binary .","score":[0,0.0633]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *overseerListener) release(timeout time.Duration) {\r\n\t\r\n\tl.closeError = l.Listener.Close()\r\n\t\r\n\twaited := make(chan bool)\r\n\tgo func() {\r\n\t\tl.wg.Wait()\r\n\t\twaited <- true\r\n\t}()\r\n\tgo func() {\r\n\t\tselect {\r\n\t\tcase <-time.After(timeout):\r\n\t\t\tclose(l.closeByForce)\r\n\t\tcase <-waited:\r\n\t\t\t\r\n\t\t}\r\n\t}()\r\n}","code-length":149,"reference":"\/\/non-blocking trigger close","result":"Release the listener.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mp *master) fetchLoop() {\r\n\tmin := mp.Config.MinFetchInterval\r\n\ttime.Sleep(min)\r\n\tfor {\r\n\t\tt0 := time.Now()\r\n\t\tmp.fetch()\r\n\t\t\r\n\t\tdiff := time.Now().Sub(t0)\r\n\t\tif diff < min {\r\n\t\t\tdelay := min - diff\r\n\t\t\t\r\n\t\t\t\r\n\t\t\ttime.Sleep(delay)\r\n\t\t}\r\n\t}\r\n}","code-length":128,"reference":"\/\/fetchLoop is run in a goroutine","result":"Run the fetchLoop.","score":[0,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mp *master) forkLoop() error {\r\n\t\r\n\tfor {\r\n\t\tif err := mp.fork(); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n}","code-length":61,"reference":"\/\/not a real fork","result":"Create a new master.","score":[0.3195,0.125]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *File) Init() error {\r\n\tif f.Path == \"\" {\r\n\t\treturn fmt.Errorf(\"Path required\")\r\n\t}\r\n\tif f.Interval < 1*time.Second {\r\n\t\tf.Interval = 1 * time.Second\r\n\t}\r\n\tif err := f.updateHash(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":109,"reference":"\/\/ Init sets the Path and Interval options","result":"Initialize the file.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *File) Fetch() (io.Reader, error) {\r\n\t\r\n\tif f.delay {\r\n\t\ttime.Sleep(f.Interval)\r\n\t}\r\n\tf.delay = true\r\n\tlastHash := f.hash\r\n\tif err := f.updateHash(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tif lastHash == f.hash {\r\n\t\treturn nil, nil\r\n\t}\r\n\t\r\n\tfile, err := os.Open(f.Path)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\t\r\n\tconst rate = 250 * time.Millisecond\r\n\tconst total = int(5 * time.Second \/ rate)\r\n\tattempt := 1\r\n\tfor {\r\n\t\tif attempt == total {\r\n\t\t\tfile.Close()\r\n\t\t\treturn nil, errors.New(\"file is currently being changed\")\r\n\t\t}\r\n\t\tattempt++\r\n\t\t\r\n\t\ttime.Sleep(rate)\r\n\t\t\r\n\t\tif err := f.updateHash(); err != nil {\r\n\t\t\tfile.Close()\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\t\r\n\t\tif lastHash == f.hash {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tlastHash = f.hash\r\n\t}\r\n\treturn file, nil\r\n}","code-length":353,"reference":"\/\/ Fetch file from the specified Path","result":"Fetch the file.","score":[0.128,0.1515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *HTTP) Fetch() (io.Reader, error) {\r\n\t\r\n\tif h.delay {\r\n\t\ttime.Sleep(h.Interval)\r\n\t}\r\n\th.delay = true\r\n\t\r\n\tresp, err := http.Head(h.URL)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"HEAD request failed (%s)\", err)\r\n\t}\r\n\tresp.Body.Close()\r\n\tif resp.StatusCode != http.StatusOK {\r\n\t\treturn nil, fmt.Errorf(\"HEAD request failed (status code %d)\", resp.StatusCode)\r\n\t}\r\n\t\r\n\tmatches, total := 0, 0\r\n\tfor _, header := range h.CheckHeaders {\r\n\t\tif curr := resp.Header.Get(header); curr != \"\" {\r\n\t\t\tif last, ok := h.lasts[header]; ok && last == curr {\r\n\t\t\t\tmatches++\r\n\t\t\t}\r\n\t\t\th.lasts[header] = curr\r\n\t\t\ttotal++\r\n\t\t}\r\n\t}\r\n\tif matches == total {\r\n\t\treturn nil, nil\r\n\t}\r\n\t\r\n\tresp, err = http.Get(h.URL)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"GET request failed (%s)\", err)\r\n\t}\r\n\tif resp.StatusCode != http.StatusOK {\r\n\t\treturn nil, fmt.Errorf(\"GET request failed (status code %d)\", resp.StatusCode)\r\n\t}\r\n\t\r\n\tif strings.HasSuffix(h.URL, \".gz\") && resp.Header.Get(\"Content-Encoding\") != \"gzip\" {\r\n\t\treturn gzip.NewReader(resp.Body)\r\n\t}\r\n\t\r\n\treturn resp.Body, nil\r\n}","code-length":448,"reference":"\/\/ Fetch the binary from the provided URL","result":"Fetch the data from the server.","score":[0.2575,0.4808]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewConfig() *Config {\r\n\tc := &Config{\r\n\t\tConfig: *sarama.NewConfig(),\r\n\t}\r\n\tc.Group.PartitionStrategy = StrategyRange\r\n\tc.Group.Offsets.Retry.Max = 3\r\n\tc.Group.Offsets.Synchronization.DwellTime = c.Consumer.MaxProcessingTime\r\n\tc.Group.Session.Timeout = 30 * time.Second\r\n\tc.Group.Heartbeat.Interval = 3 * time.Second\r\n\tc.Config.Version = minVersion\r\n\treturn c\r\n}","code-length":141,"reference":"\/\/ NewConfig returns a new configuration instance with sane defaults.","result":"Create a new config object.","score":[0.125,0.1974]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) Validate() error {\r\n\tif c.Group.Heartbeat.Interval%time.Millisecond != 0 {\r\n\t\tsarama.Logger.Println(\"Group.Heartbeat.Interval only supports millisecond precision; nanoseconds will be truncated.\")\r\n\t}\r\n\tif c.Group.Session.Timeout%time.Millisecond != 0 {\r\n\t\tsarama.Logger.Println(\"Group.Session.Timeout only supports millisecond precision; nanoseconds will be truncated.\")\r\n\t}\r\n\tif c.Group.PartitionStrategy != StrategyRange && c.Group.PartitionStrategy != StrategyRoundRobin {\r\n\t\tsarama.Logger.Println(\"Group.PartitionStrategy is not supported; range will be assumed.\")\r\n\t}\r\n\tif !c.Version.IsAtLeast(minVersion) {\r\n\t\tsarama.Logger.Println(\"Version is not supported; 0.9. will be assumed.\")\r\n\t\tc.Version = minVersion\r\n\t}\r\n\tif err := c.Config.Validate(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tswitch {\r\n\tcase c.Group.Offsets.Retry.Max < 0:\r\n\t\treturn sarama.ConfigurationError(\"Group.Offsets.Retry.Max must be >= 0\")\r\n\tcase c.Group.Offsets.Synchronization.DwellTime <= 0:\r\n\t\treturn sarama.ConfigurationError(\"Group.Offsets.Synchronization.DwellTime must be > 0\")\r\n\tcase c.Group.Offsets.Synchronization.DwellTime > 10*time.Minute:\r\n\t\treturn sarama.ConfigurationError(\"Group.Offsets.Synchronization.DwellTime must be <= 10m\")\r\n\tcase c.Group.Heartbeat.Interval <= 0:\r\n\t\treturn sarama.ConfigurationError(\"Group.Heartbeat.Interval must be > 0\")\r\n\tcase c.Group.Session.Timeout <= 0:\r\n\t\treturn sarama.ConfigurationError(\"Group.Session.Timeout must be > 0\")\r\n\tcase !c.Metadata.Full && c.Group.Topics.Whitelist != nil:\r\n\t\treturn sarama.ConfigurationError(\"Metadata.Full must be enabled when Group.Topics.Whitelist is used\")\r\n\tcase !c.Metadata.Full && c.Group.Topics.Blacklist != nil:\r\n\t\treturn sarama.ConfigurationError(\"Metadata.Full must be enabled when Group.Topics.Blacklist is used\")\r\n\t}\r\n\t\r\n\tswitch c.Consumer.Offsets.Initial {\r\n\tcase sarama.OffsetOldest, sarama.OffsetNewest:\r\n\tdefault:\r\n\t\treturn sarama.ConfigurationError(\"Consumer.Offsets.Initial must be either OffsetOldest or OffsetNewest\")\r\n\t}\r\n\treturn nil\r\n}","code-length":660,"reference":"\/\/ Validate checks a Config instance. It will return a\n\/\/ sarama.ConfigurationError if the specified values don't make sense.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(addrs []string, config *Config) (*Client, error) {\r\n\tif config == nil {\r\n\t\tconfig = NewConfig()\r\n\t}\r\n\tif err := config.Validate(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tclient, err := sarama.NewClient(addrs, &config.Config)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &Client{Client: client, config: *config}, nil\r\n}","code-length":134,"reference":"\/\/ NewClient creates a new client instance","result":"Create a client .","score":[0.1795,0.3814]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *partitionConsumer) AsyncClose() {\r\n\tc.closeOnce.Do(func() {\r\n\t\tc.closeErr = c.PartitionConsumer.Close()\r\n\t\tclose(c.dying)\r\n\t})\r\n}","code-length":67,"reference":"\/\/ AsyncClose implements PartitionConsumer","result":"Close the partition consumer.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *partitionConsumer) Close() error {\r\n\tc.AsyncClose()\r\n\t<-c.dead\r\n\treturn c.closeErr\r\n}","code-length":47,"reference":"\/\/ Close implements PartitionConsumer","result":"Close the partition consumer.","score":[0.3195,0.125]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *partitionConsumer) MarkOffset(offset int64, metadata string) {\r\n\tc.mu.Lock()\r\n\tif next := offset + 1; next > c.state.Info.Offset {\r\n\t\tc.state.Info.Offset = next\r\n\t\tc.state.Info.Metadata = metadata\r\n\t\tc.state.Dirty = true\r\n\t}\r\n\tc.mu.Unlock()\r\n}","code-length":109,"reference":"\/\/ MarkOffset implements PartitionConsumer","result":"Mark offset.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewConsumer(addrs []string, groupID string, topics []string, config *Config) (*Consumer, error) {\r\n\tclient, err := NewClient(addrs, config)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tconsumer, err := NewConsumerFromClient(client, groupID, topics)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tconsumer.ownClient = true\r\n\treturn consumer, nil\r\n}","code-length":125,"reference":"\/\/ NewConsumer initializes a new consumer","result":"Create a new consumer.","score":[0.274,0.3233]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Consumer) MarkOffsets(s *OffsetStash) {\r\n\ts.mu.Lock()\r\n\tdefer s.mu.Unlock()\r\n\tfor tp, info := range s.offsets {\r\n\t\tif sub := c.subs.Fetch(tp.Topic, tp.Partition); sub != nil {\r\n\t\t\tsub.MarkOffset(info.Offset, info.Metadata)\r\n\t\t}\r\n\t\tdelete(s.offsets, tp)\r\n\t}\r\n}","code-length":123,"reference":"\/\/ MarkOffsets marks stashed offsets as processed.\n\/\/ See MarkOffset for additional explanation.","result":"Generate code for generated code.","score":[0.0485,0.041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Consumer) ResetOffset(msg *sarama.ConsumerMessage, metadata string) {\r\n\tif sub := c.subs.Fetch(msg.Topic, msg.Partition); sub != nil {\r\n\t\tsub.ResetOffset(msg.Offset, metadata)\r\n\t}\r\n}","code-length":77,"reference":"\/\/ ResetOffset marks the provided message as processed, alongside a metadata string\n\/\/ that represents the state of the partition consumer at that point in time. The\n\/\/ metadata string can be used by another consumer to restore that state, so it\n\/\/ can resume consumption.\n\/\/\n\/\/ Difference between ResetOffset and MarkOffset is that it allows to rewind to an earlier offset","result":"Reset the offset of the consumer.","score":[0.0,0.0349]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Consumer) Close() (err error) {\r\n\tc.closeOnce.Do(func() {\r\n\t\tclose(c.dying)\r\n\t\t<-c.dead\r\n\t\tif e := c.release(); e != nil {\r\n\t\t\terr = e\r\n\t\t}\r\n\t\tif e := c.consumer.Close(); e != nil {\r\n\t\t\terr = e\r\n\t\t}\r\n\t\tclose(c.messages)\r\n\t\tclose(c.errors)\r\n\t\tif e := c.leaveGroup(); e != nil {\r\n\t\t\terr = e\r\n\t\t}\r\n\t\tclose(c.partitions)\r\n\t\tclose(c.notifications)\r\n\t\t\r\n\t\tfor range c.messages {\r\n\t\t}\r\n\t\tfor range c.errors {\r\n\t\t}\r\n\t\tfor p := range c.partitions {\r\n\t\t\t_ = p.Close()\r\n\t\t}\r\n\t\tfor range c.notifications {\r\n\t\t}\r\n\t\tc.client.release()\r\n\t\tif c.ownClient {\r\n\t\t\tif e := c.client.Close(); e != nil {\r\n\t\t\t\terr = e\r\n\t\t\t}\r\n\t\t}\r\n\t})\r\n\treturn\r\n}","code-length":319,"reference":"\/\/ Close safely closes the consumer and releases all resources","result":"Close the consumer.","score":[0.0471,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Consumer) hbLoop(stopped <-chan none) {\r\n\tticker := time.NewTicker(c.client.config.Group.Heartbeat.Interval)\r\n\tdefer ticker.Stop()\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase <-ticker.C:\r\n\t\t\tswitch err := c.heartbeat(); err {\r\n\t\t\tcase nil, sarama.ErrNoError:\r\n\t\t\tcase sarama.ErrNotCoordinatorForConsumer, sarama.ErrRebalanceInProgress:\r\n\t\t\t\treturn\r\n\t\t\tdefault:\r\n\t\t\t\tc.handleError(&Error{Ctx: \"heartbeat\", error: err})\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\tcase <-stopped:\r\n\t\t\treturn\r\n\t\tcase <-c.dying:\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":212,"reference":"\/\/ heartbeat loop, triggered by the mainLoop","result":"Trigger the heartbeat loop.","score":[0.1795,0.2239]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Consumer) twLoop(stopped <-chan none) {\r\n\tticker := time.NewTicker(c.client.config.Metadata.RefreshFrequency \/ 2)\r\n\tdefer ticker.Stop()\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase <-ticker.C:\r\n\t\t\ttopics, err := c.client.Topics()\r\n\t\t\tif err != nil {\r\n\t\t\t\tc.handleError(&Error{Ctx: \"topics\", error: err})\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tfor _, topic := range topics {\r\n\t\t\t\tif !c.isKnownCoreTopic(topic) &&\r\n\t\t\t\t\t!c.isKnownExtraTopic(topic) &&\r\n\t\t\t\t\tc.isPotentialExtraTopic(topic) {\r\n\t\t\t\t\treturn\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\tcase <-stopped:\r\n\t\t\treturn\r\n\t\tcase <-c.dying:\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":245,"reference":"\/\/ topic watcher loop, triggered by the mainLoop","result":"Detect if a topic is not known.","score":[0.14,0.0633]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Consumer) cmLoop(stopped <-chan none) {\r\n\tticker := time.NewTicker(c.client.config.Consumer.Offsets.CommitInterval)\r\n\tdefer ticker.Stop()\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase <-ticker.C:\r\n\t\t\tif err := c.commitOffsetsWithRetry(c.client.config.Group.Offsets.Retry.Max); err != nil {\r\n\t\t\t\tc.handleError(&Error{Ctx: \"commit\", error: err})\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\tcase <-stopped:\r\n\t\t\treturn\r\n\t\tcase <-c.dying:\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":182,"reference":"\/\/ commit loop, triggered by the mainLoop","result":"Avoid the need for the function to be executed.","score":[0.1219,0.0694]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Consumer) fetchOffsets(subs map[string][]int32) (map[string]map[int32]offsetInfo, error) {\r\n\toffsets := make(map[string]map[int32]offsetInfo, len(subs))\r\n\treq := &sarama.OffsetFetchRequest{\r\n\t\tVersion:       1,\r\n\t\tConsumerGroup: c.groupID,\r\n\t}\r\n\tfor topic, partitions := range subs {\r\n\t\toffsets[topic] = make(map[int32]offsetInfo, len(partitions))\r\n\t\tfor _, partition := range partitions {\r\n\t\t\toffsets[topic][partition] = offsetInfo{Offset: -1}\r\n\t\t\treq.AddPartition(topic, partition)\r\n\t\t}\r\n\t}\r\n\tbroker, err := c.client.Coordinator(c.groupID)\r\n\tif err != nil {\r\n\t\tc.closeCoordinator(broker, err)\r\n\t\treturn nil, err\r\n\t}\r\n\tresp, err := broker.FetchOffset(req)\r\n\tif err != nil {\r\n\t\tc.closeCoordinator(broker, err)\r\n\t\treturn nil, err\r\n\t}\r\n\tfor topic, partitions := range subs {\r\n\t\tfor _, partition := range partitions {\r\n\t\t\tblock := resp.GetBlock(topic, partition)\r\n\t\t\tif block == nil {\r\n\t\t\t\treturn nil, sarama.ErrIncompleteResponse\r\n\t\t\t}\r\n\t\t\tif block.Err == sarama.ErrNoError {\r\n\t\t\t\toffsets[topic][partition] = offsetInfo{Offset: block.Offset, Metadata: block.Metadata}\r\n\t\t\t} else {\r\n\t\t\t\treturn nil, block.Err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn offsets, nil\r\n}","code-length":440,"reference":"\/\/ Fetches latest committed offsets for all subscriptions","result":"Fetch offsets from the coordinator.","score":[0.1319,0.1299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *OffsetStash) MarkOffset(msg *sarama.ConsumerMessage, metadata string) {\r\n\ts.MarkPartitionOffset(msg.Topic, msg.Partition, msg.Offset, metadata)\r\n}","code-length":59,"reference":"\/\/ MarkOffset stashes the provided message offset","result":"Mark offset.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *OffsetStash) ResetOffset(msg *sarama.ConsumerMessage, metadata string) {\r\n\ts.ResetPartitionOffset(msg.Topic, msg.Partition, msg.Offset, metadata)\r\n}","code-length":59,"reference":"\/\/ ResetOffset stashes the provided message offset\n\/\/ See ResetPartitionOffset for explanation","result":"Reset the offset stash.","score":[0.0514,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *OffsetStash) Offsets() map[string]int64 {\r\n\ts.mu.Lock()\r\n\tdefer s.mu.Unlock()\r\n\tres := make(map[string]int64, len(s.offsets))\r\n\tfor tp, info := range s.offsets {\r\n\t\tres[tp.String()] = info.Offset\r\n\t}\r\n\treturn res\r\n}","code-length":106,"reference":"\/\/ Offsets returns the latest stashed offsets by topic-partition","result":"Store the offsets in the stash.","score":[0.1392,0.1149]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *InstanceGroup) Actual(immutable *cluster.Cluster) (*cluster.Cluster, cloud.Resource, error) {\r\n\tlogger.Debug(\"instanceGroup.Actual\")\r\n\tif r.CachedActual != nil {\r\n\t\tlogger.Debug(\"Using cached instance [actual]\")\r\n\t\treturn immutable, r.CachedActual, nil\r\n\t}\r\n\tnewResource := &InstanceGroup{\r\n\t\tShared: Shared{\r\n\t\t\tName:    r.Name,\r\n\t\t\tCloudID: r.ServerPool.Identifier,\r\n\t\t},\r\n\t}\r\n\tproject, err := Sdk.Service.Projects.Get(immutable.ProviderConfig().CloudId).Do()\r\n\tif err != nil && project != nil {\r\n\t\tinstances, err := Sdk.Service.Instances.List(immutable.ProviderConfig().CloudId, immutable.ProviderConfig().Location).Do()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, nil, err\r\n\t\t}\r\n\t\tcount := len(instances.Items)\r\n\t\tif count > 0 {\r\n\t\t\tnewResource.Count = count\r\n\t\t\tinstance := instances.Items[0]\r\n\t\t\tnewResource.Name = instance.Name\r\n\t\t\tnewResource.CloudID = string(instance.Id)\r\n\t\t\tnewResource.Size = instance.Kind\r\n\t\t\tnewResource.Image = r.Image\r\n\t\t\tnewResource.Location = instance.Zone\r\n\t\t}\r\n\t}\r\n\tnewResource.BootstrapScripts = r.ServerPool.BootstrapScripts\r\n\tnewResource.SSHFingerprint = immutable.ProviderConfig().SSH.PublicKeyFingerprint\r\n\tnewResource.Name = r.Name\r\n\tr.CachedActual = newResource\r\n\treturn immutable, newResource, nil\r\n}","code-length":421,"reference":"\/\/ Actual is used to build a cluster based on instances on the cloud provider.","result":"Test if the resource is a valid instance group.","score":[0.0823,0.1389]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *InstanceGroup) Expected(immutable *cluster.Cluster) (*cluster.Cluster, cloud.Resource, error) {\r\n\tlogger.Debug(\"instanceGroup.Expected\")\r\n\tif r.CachedExpected != nil {\r\n\t\tlogger.Debug(\"Using instance subnet [expected]\")\r\n\t\treturn immutable, r.CachedExpected, nil\r\n\t}\r\n\texpected := &InstanceGroup{\r\n\t\tShared: Shared{\r\n\t\t\tName:    r.Name,\r\n\t\t\tCloudID: r.ServerPool.Identifier,\r\n\t\t},\r\n\t\tSize:             r.ServerPool.Size,\r\n\t\tLocation:         immutable.ProviderConfig().Location,\r\n\t\tImage:            r.ServerPool.Image,\r\n\t\tCount:            r.ServerPool.MaxCount,\r\n\t\tSSHFingerprint:   immutable.ProviderConfig().SSH.PublicKeyFingerprint,\r\n\t\tBootstrapScripts: r.ServerPool.BootstrapScripts,\r\n\t}\r\n\tr.CachedExpected = expected\r\n\treturn immutable, expected, nil\r\n}","code-length":253,"reference":"\/\/ Expected is used to build a cluster expected to be on the cloud provider.","result":"Create a new instance group.","score":[0.0325,0.0357]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *InstanceGroup) Delete(actual cloud.Resource, immutable *cluster.Cluster) (*cluster.Cluster, cloud.Resource, error) {\r\n\tlogger.Debug(\"instanceGroup.Delete\")\r\n\tdeleteResource := actual.(*InstanceGroup)\r\n\tif deleteResource.Name == \"\" {\r\n\t\treturn nil, nil, fmt.Errorf(\"Unable to delete instance resource without Name [%s]\", deleteResource.Name)\r\n\t}\r\n\tlogger.Success(\"Deleting InstanceGroup manager [%s]\", r.ServerPool.Name)\r\n\t_, err := Sdk.Service.InstanceGroupManagers.Get(immutable.ProviderConfig().CloudId, immutable.ProviderConfig().Location, strings.ToLower(r.ServerPool.Name)).Do()\r\n\tif err == nil {\r\n\t\t_, err := Sdk.Service.InstanceGroupManagers.Delete(immutable.ProviderConfig().CloudId, immutable.ProviderConfig().Location, strings.ToLower(r.ServerPool.Name)).Do()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, nil, err\r\n\t\t}\r\n\t}\r\n\t_, err = Sdk.Service.InstanceTemplates.Get(immutable.ProviderConfig().CloudId, strings.ToLower(r.ServerPool.Name)).Do()\r\n\tif err == nil {\r\n\t\terr := r.retryDeleteInstanceTemplate(immutable)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, nil, err\r\n\t\t}\r\n\t}\r\n\t\r\n\tproviderConfig := immutable.ProviderConfig()\r\n\tproviderConfig.KubernetesAPI.Endpoint = \"\"\r\n\timmutable.SetProviderConfig(providerConfig)\r\n\trenderedCluster, err := r.immutableRender(actual, immutable)\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\treturn renderedCluster, actual, nil\r\n}","code-length":445,"reference":"\/\/ Delete is used to delete the instances on the cloud provider","result":"Delete the resource.","score":[0.0242,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetReconciler(known *cluster.Cluster, runtimeParameters *RuntimeParameters) (reconciler cloud.Reconciler, err error) {\r\n\tswitch known.ProviderConfig().Cloud {\r\n\tcase cluster.CloudGoogle:\r\n\t\tsdk, err := googleSDK.NewSdk()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tgr.Sdk = sdk\r\n\t\treturn cloud.NewAtomicReconciler(known, compute.NewGoogleComputeModel(known)), nil\r\n\tcase cluster.CloudDigitalOcean:\r\n\t\tsdk, err := godoSdk.NewSdk()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tdr.Sdk = sdk\r\n\t\treturn cloud.NewAtomicReconciler(known, droplet.NewDigitalOceanDropletModel(known)), nil\r\n\tcase cluster.CloudAmazon:\r\n\t\tawsProfile := \"\"\r\n\t\tif runtimeParameters != nil {\r\n\t\t\tawsProfile = runtimeParameters.AwsProfile\r\n\t\t}\r\n\t\tsdk, err := awsSdkGo.NewSdk(known.ProviderConfig().Location, awsProfile)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tar.Sdk = sdk\r\n\t\treturn cloud.NewAtomicReconciler(known, awspub.NewAmazonPublicModel(known)), nil\r\n\tcase cluster.CloudAzure:\r\n\t\tsdk, err := azureSDK.NewSdk()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tazr.Sdk = sdk\r\n\t\treturn cloud.NewAtomicReconciler(known, azpub.NewAzurePublicModel(known)), nil\r\n\tcase cluster.CloudOVH:\r\n\t\tsdk, err := openstackSdk.NewSdk(known.ProviderConfig().Location)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tosr.Sdk = sdk\r\n\t\treturn cloud.NewAtomicReconciler(known, osovh.NewOvhPublicModel(known)), nil\r\n\tcase cluster.CloudPacket:\r\n\t\tsdk, err := packetSDK.NewSdk()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tpacketr.Sdk = sdk\r\n\t\treturn cloud.NewAtomicReconciler(known, packetpub.NewPacketPublicModel(known)), nil\r\n\tcase cluster.CloudECS:\r\n\t\tsdk, err := openstackSdk.NewSdk(known.ProviderConfig().Location)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tosr.Sdk = sdk\r\n\t\treturn cloud.NewAtomicReconciler(known, osecs.NewEcsPublicModel(known)), nil\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"Invalid cloud type: %s\", known.ProviderConfig().Cloud)\r\n\t}\r\n}","code-length":739,"reference":"\/\/ GetReconciler gets the correct Reconciler for the cloud provider currenty used.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetVersion() *Version {\r\n\treturn &Version{\r\n\t\tVersion:   KubicornVersion,\r\n\t\tGitCommit: GitSha,\r\n\t\tBuildDate: time.Now().UTC().String(),\r\n\t\tGoVersion: runtime.Version(),\r\n\t\tGOOS:      runtime.GOOS,\r\n\t\tGOArch:    runtime.GOARCH,\r\n\t}\r\n}","code-length":104,"reference":"\/\/ GetVersion returns Kubicorn version.","result":"Get the version of the service.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetVersionJSON() string {\r\n\tverBytes, err := json.Marshal(GetVersion())\r\n\tif err != nil {\r\n\t\tlogger.Critical(\"Unable to marshal version struct: %v\", err)\r\n\t}\r\n\treturn string(verBytes)\r\n}","code-length":74,"reference":"\/\/ GetVersionJSON returns Kubicorn version in JSON format.","result":"Generate the version string.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ResourceGroup) Actual(immutable *cluster.Cluster) (*cluster.Cluster, cloud.Resource, error) {\r\n\tlogger.Debug(\"resourcegroup.Actual\")\r\n\tnewResource := &ResourceGroup{\r\n\t\tShared: Shared{\r\n\t\t\tName:       r.Name,\r\n\t\t\tTags:       r.Tags,\r\n\t\t\tIdentifier: immutable.ProviderConfig().GroupIdentifier,\r\n\t\t},\r\n\t\tLocation: r.Location,\r\n\t}\r\n\tif r.Identifier != \"\" {\r\n\t\tgroup, err := Sdk.ResourceGroup.Get(immutable.Name)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, nil, err\r\n\t\t}\r\n\t\tnewResource.Location = *group.Location\r\n\t\tnewResource.Name = *group.Name\r\n\t\tnewResource.Identifier = *group.ID\r\n\t}\r\n\tnewCluster := r.immutableRender(newResource, immutable)\r\n\treturn newCluster, newResource, nil\r\n}","code-length":247,"reference":"\/\/ Actual returns the actual resource group in Azure if it exists.","result":"Test if the function is not defined in the package.","score":[0.117,0.1271]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ResourceGroup) Expected(immutable *cluster.Cluster) (*cluster.Cluster, cloud.Resource, error) {\r\n\tlogger.Debug(\"resourcegroup.Expected\")\r\n\tnewResource := &ResourceGroup{\r\n\t\tShared: Shared{\r\n\t\t\tName:       immutable.Name,\r\n\t\t\tTags:       r.Tags,\r\n\t\t\tIdentifier: immutable.ProviderConfig().GroupIdentifier,\r\n\t\t},\r\n\t\tLocation: immutable.ProviderConfig().Location,\r\n\t}\r\n\tnewCluster := r.immutableRender(newResource, immutable)\r\n\treturn newCluster, newResource, nil\r\n}","code-length":154,"reference":"\/\/ Expected will return the expected resource group as it would be defined in Azure","result":"Test if the resource group is expected.","score":[0.0806,0.2223]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CreateCmd() *cobra.Command {\r\n\tvar co = &cli.CreateOptions{}\r\n\tvar createCmd = &cobra.Command{\r\n\t\tUse:   \"create [NAME] [-p|--profile PROFILENAME] [-c|--cloudid CLOUDID]\",\r\n\t\tShort: \"Create a Kubicorn API model from a profile\",\r\n\t\tLong: `Use this command to create a Kubicorn API model in a defined state store.\r\n\tThis command will create a cluster API model as a YAML manifest in a state store.\r\n\tOnce the API model has been created, a user can optionally change the model to their liking.\r\n\tAfter a model is defined and configured properly, the user can then apply the model.`,\r\n\t\tRun: func(cmd *cobra.Command, args []string) {\r\n\t\t\tswitch len(args) {\r\n\t\t\tcase 0:\r\n\t\t\t\tco.Name = viper.GetString(keyKubicornName)\r\n\t\t\t\tif co.Name == \"\" {\r\n\t\t\t\t\tco.Name = namer.RandomName()\r\n\t\t\t\t}\r\n\t\t\tcase 1:\r\n\t\t\t\tco.Name = args[0]\r\n\t\t\tdefault:\r\n\t\t\t\tlogger.Critical(\"Too many arguments.\")\r\n\t\t\t\tos.Exit(1)\r\n\t\t\t}\r\n\t\t\tif err := RunCreate(co); err != nil {\r\n\t\t\t\tlogger.Critical(err.Error())\r\n\t\t\t\tos.Exit(1)\r\n\t\t\t}\r\n\t\t},\r\n\t}\r\n\tfs := createCmd.Flags()\r\n\tbindCommonStateStoreFlags(&co.StateStoreOptions, fs)\r\n\tbindCommonAwsFlags(&co.AwsOptions, fs)\r\n\tfs.StringVarP(&co.Profile, keyProfile, \"p\", viper.GetString(keyProfile), descProfile)\r\n\tfs.StringVarP(&co.CloudID, keyCloudID, \"c\", viper.GetString(keyCloudID), descCloudID)\r\n\tfs.StringVar(&co.KubeConfigLocalFile, keyKubeConfigLocalFile, viper.GetString(keyKubeConfigLocalFile), descKubeConfigLocalFile)\r\n\tfs.StringArrayVarP(&co.Set, keySet, \"C\", viper.GetStringSlice(keySet), descSet)\r\n\tfs.StringArrayVarP(&co.MasterSet, keyMasterSet, \"M\", viper.GetStringSlice(keyMasterSet), descMasterSet)\r\n\tfs.StringArrayVarP(&co.NodeSet, keyNodeSet, \"N\", viper.GetStringSlice(keyNodeSet), descNodeSet)\r\n\tfs.StringVarP(&co.GitRemote, keyGitConfig, \"g\", viper.GetString(keyGitConfig), descGitConfig)\r\n\tfs.StringArrayVar(&co.AwsOptions.PolicyAttachments, keyPolicyAttachments, co.AwsOptions.PolicyAttachments, descPolicyAttachments)\r\n\tflagApplyAnnotations(createCmd, \"profile\", \"__kubicorn_parse_profiles\")\r\n\tflagApplyAnnotations(createCmd, \"cloudid\", \"__kubicorn_parse_cloudid\")\r\n\tcreateCmd.SetUsageTemplate(cli.UsageTemplate)\r\n\treturn createCmd\r\n}","code-length":765,"reference":"\/\/ CreateCmd represents create command","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewUbuntuCluster(name string) *cluster.Cluster {\r\n\tcontrolPlaneProviderConfig := &cluster.ControlPlaneProviderConfig{\r\n\t\tCloud:    cluster.CloudAzure,\r\n\t\tLocation: \"eastus\",\r\n\t\tSSH: &cluster.SSH{\r\n\t\t\tPublicKeyPath: \"~\/.ssh\/id_rsa.pub\",\r\n\t\t\tUser:          \"root\",\r\n\t\t},\r\n\t\tKubernetesAPI: &cluster.KubernetesAPI{\r\n\t\t\tPort: \"443\",\r\n\t\t},\r\n\t\tValues: &cluster.Values{\r\n\t\t\tItemMap: map[string]string{\r\n\t\t\t\t\"INJECTEDTOKEN\": kubeadm.GetRandomToken(),\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n\tmachineSetsProviderConfigs := []*cluster.MachineProviderConfig{\r\n\t\t{\r\n\t\t\tServerPool: &cluster.ServerPool{\r\n\t\t\t\tType:             cluster.ServerPoolTypeMaster,\r\n\t\t\t\tName:             fmt.Sprintf(\"%s-master\", name),\r\n\t\t\t\tMaxCount:         1,\r\n\t\t\t\tImage:            \"UbuntuServer\",\r\n\t\t\t\tSize:             \"Standard_DS3_v2 \",\r\n\t\t\t\tBootstrapScripts: []string{},\r\n\t\t\t\tFirewalls: []*cluster.Firewall{\r\n\t\t\t\t\t{\r\n\t\t\t\t\t\tName: fmt.Sprintf(\"%s-master\", name),\r\n\t\t\t\t\t\tIngressRules: []*cluster.IngressRule{\r\n\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\tIngressToPort:   \"22\",\r\n\t\t\t\t\t\t\t\tIngressSource:   \"0.0.0.0\/0\",\r\n\t\t\t\t\t\t\t\tIngressProtocol: \"tcp\",\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\tIngressToPort:   \"443\",\r\n\t\t\t\t\t\t\t\tIngressSource:   \"0.0.0.0\/0\",\r\n\t\t\t\t\t\t\t\tIngressProtocol: \"tcp\",\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\tIngressToPort:   \"1194\",\r\n\t\t\t\t\t\t\t\tIngressSource:   \"0.0.0.0\/0\",\r\n\t\t\t\t\t\t\t\tIngressProtocol: \"udp\",\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t\tEgressRules: []*cluster.EgressRule{\r\n\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\tEgressToPort:      \"all\",\r\n\t\t\t\t\t\t\t\tEgressDestination: \"0.0.0.0\/0\",\r\n\t\t\t\t\t\t\t\tEgressProtocol:    \"tcp\",\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\tEgressToPort:      \"all\",\r\n\t\t\t\t\t\t\t\tEgressDestination: \"0.0.0.0\/0\",\r\n\t\t\t\t\t\t\t\tEgressProtocol:    \"udp\",\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t},\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t},\r\n\t\t{\r\n\t\t\tServerPool: &cluster.ServerPool{\r\n\t\t\t\tType:             cluster.ServerPoolTypeNode,\r\n\t\t\t\tName:             fmt.Sprintf(\"%s-node\", name),\r\n\t\t\t\tMaxCount:         1,\r\n\t\t\t\tImage:            \"UbuntuServer\",\r\n\t\t\t\tSize:             \"Standard_DS3_v2 \",\r\n\t\t\t\tBootstrapScripts: []string{},\r\n\t\t\t\tFirewalls: []*cluster.Firewall{\r\n\t\t\t\t\t{\r\n\t\t\t\t\t\tName: fmt.Sprintf(\"%s-node\", name),\r\n\t\t\t\t\t\tIngressRules: []*cluster.IngressRule{\r\n\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\tIngressToPort:   \"22\",\r\n\t\t\t\t\t\t\t\tIngressSource:   \"0.0.0.0\/0\",\r\n\t\t\t\t\t\t\t\tIngressProtocol: \"tcp\",\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\tIngressToPort:   \"1194\",\r\n\t\t\t\t\t\t\t\tIngressSource:   \"0.0.0.0\/0\",\r\n\t\t\t\t\t\t\t\tIngressProtocol: \"udp\",\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t\tEgressRules: []*cluster.EgressRule{\r\n\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\tEgressToPort:      \"all\",\r\n\t\t\t\t\t\t\t\tEgressDestination: \"0.0.0.0\/0\",\r\n\t\t\t\t\t\t\t\tEgressProtocol:    \"tcp\",\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\tEgressToPort:      \"all\",\r\n\t\t\t\t\t\t\t\tEgressDestination: \"0.0.0.0\/0\",\r\n\t\t\t\t\t\t\t\tEgressProtocol:    \"udp\",\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t},\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n\tc := cluster.NewCluster(name)\r\n\tc.SetProviderConfig(controlPlaneProviderConfig)\r\n\tc.NewMachineSetsFromProviderConfigs(machineSetsProviderConfigs)\r\n\treturn c\r\n}","code-length":1154,"reference":"\/\/ NewUbuntuCluster creates a basic Azure cluster profile, to bootstrap Kubernetes.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ProviderConfig() *ControlPlaneProviderConfig {\r\n\t\r\n\traw := c.ClusterAPI.Spec.ProviderConfig\r\n\tproviderConfig := &ControlPlaneProviderConfig{}\r\n\terr := json.Unmarshal([]byte(raw), providerConfig)\r\n\tif err != nil {\r\n\t\tlogger.Critical(\"Unable to unmarshal provider config: %v\", err)\r\n\t}\r\n\treturn providerConfig\r\n}","code-length":110,"reference":"\/\/ ProviderConfig is a convenience method that will attempt\n\/\/ to return a ControlPlaneProviderConfig for a cluster.\n\/\/ This is useful for managing the legacy API in a clean way.\n\/\/ This will ignore errors from json.Unmarshal and will simply\n\/\/ return an empty config.","result":"Generate the provider config.","score":[0.0,0.0244]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) SetProviderConfig(config *ControlPlaneProviderConfig) error {\r\n\tbytes, err := json.Marshal(config)\r\n\tif err != nil {\r\n\t\tlogger.Critical(\"Unable to marshal provider config: %v\", err)\r\n\t\treturn err\r\n\t}\r\n\tstr := string(bytes)\r\n\tc.ClusterAPI.Spec.ProviderConfig = str\r\n\treturn nil\r\n}","code-length":109,"reference":"\/\/ SetProviderConfig is a convenience method that will attempt\n\/\/ to set a provider config on a particular cluster. Just like\n\/\/ it's counterpart ProviderConfig this makes working with the legacy API much easier.","result":"Set the provider config in the cluster api.","score":[0.0084,0.1005]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) MachineProviderConfigs() []*MachineProviderConfig {\r\n\tvar providerConfigs []*MachineProviderConfig\r\n\tfor _, machineSet := range c.MachineSets {\r\n\t\traw := machineSet.Spec.Template.Spec.ProviderConfig\r\n\t\tproviderConfig := &MachineProviderConfig{}\r\n\t\terr := json.Unmarshal([]byte(raw), providerConfig)\r\n\t\tif err != nil {\r\n\t\t\tlogger.Critical(\"Unable to unmarshal provider config: %v\", err)\r\n\t\t}\r\n\t\tproviderConfigs = append(providerConfigs, providerConfig)\r\n\t}\r\n\treturn providerConfigs\r\n}","code-length":159,"reference":"\/\/ MachineProviderConfigs will return all MachineProviderConfigs for a cluster","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) SetMachineProviderConfigs(providerConfigs []*MachineProviderConfig) {\r\n\tfor _, providerConfig := range providerConfigs {\r\n\t\tname := providerConfig.ServerPool.Name\r\n\t\tfound := false\r\n\t\tfor _, machineSet := range c.MachineSets {\r\n\t\t\tif machineSet.Name == name {\r\n\t\t\t\t\r\n\t\t\t\tbytes, err := json.Marshal(providerConfig)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tlogger.Critical(\"unable to marshal machine provider config: %v\")\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\tstr := string(bytes)\r\n\t\t\t\tmachineSet.Spec.Template.Spec.ProviderConfig = str\r\n\t\t\t\tfound = true\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif !found {\r\n\t\t\tlogger.Warning(\"Unable to match provider config to machine set: %s\", name)\r\n\t\t}\r\n\t}\r\n}","code-length":246,"reference":"\/\/ SetMachineProviderConfig will attempt to match a provider config to a machine set\n\/\/ on the \"Name\" field. If a match cannot be made we warn and move on.","result":"Generate the generated code.","score":[0.0006,0.0189]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCluster(name string) *Cluster {\r\n\treturn &Cluster{\r\n\t\tName: name,\r\n\t\tClusterAPI: &clusterv1.Cluster{\r\n\t\t\tObjectMeta: metav1.ObjectMeta{\r\n\t\t\t\tName: name,\r\n\t\t\t},\r\n\t\t\tSpec: clusterv1.ClusterSpec{},\r\n\t\t},\r\n\t\tControlPlane: &clusterv1.MachineSet{},\r\n\t}\r\n}","code-length":116,"reference":"\/\/ NewCluster will initialize a new Cluster","result":"Create a new cluster.","score":[0.2134,0.2799]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DeployControllerCmd() *cobra.Command {\r\n\tvar dco = &cli.DeployControllerOptions{}\r\n\tvar deployControllerCmd = &cobra.Command{\r\n\t\tUse:   \"deploycontroller <NAME>\",\r\n\t\tShort: \"Deploy a controller for a given cluster\",\r\n\t\tLong: `Use this command to deploy a controller for a given cluster.\r\nAs long as a controller is defined, this will create the deployment and the namespace.`,\r\n\t\tRun: func(cmd *cobra.Command, args []string) {\r\n\t\t\tswitch len(args) {\r\n\t\t\tcase 0:\r\n\t\t\t\tdco.Name = viper.GetString(keyKubicornName)\r\n\t\t\tcase 1:\r\n\t\t\t\tdco.Name = args[0]\r\n\t\t\tdefault:\r\n\t\t\t\tlogger.Critical(\"Too many arguments.\")\r\n\t\t\t\tos.Exit(1)\r\n\t\t\t}\r\n\t\t\tif err := runDeployController(dco); err != nil {\r\n\t\t\t\tlogger.Critical(err.Error())\r\n\t\t\t\tos.Exit(1)\r\n\t\t\t}\r\n\t\t},\r\n\t}\r\n\tfs := deployControllerCmd.Flags()\r\n\tbindCommonStateStoreFlags(&dco.StateStoreOptions, fs)\r\n\tbindCommonAwsFlags(&dco.AwsOptions, fs)\r\n\tfs.StringVar(&dco.GitRemote, keyGitConfig, viper.GetString(keyGitConfig), descGitConfig)\r\n\treturn deployControllerCmd\r\n}","code-length":373,"reference":"\/\/ DeployControllerCmd represents the apply command","result":"Create a controller for a given cluster.","score":[0,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRetrier(retries, sleepSeconds int, retryable Retryable) *Retrier {\r\n\treturn &Retrier{\r\n\t\tretries:      retries,\r\n\t\tsleepSeconds: sleepSeconds,\r\n\t\tretryable:    retryable,\r\n\t}\r\n}","code-length":77,"reference":"\/\/ NewRetrier creates a new Retrier using given properties.","result":"Create a new instance of the Retrier.","score":[0.1716,0.3346]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Retrier) RunRetry() error {\r\n\t\r\n\tsigHandler := signals.NewSignalHandler(10)\r\n\tgo sigHandler.Register()\r\n\tfinish := make(chan bool, 1)\r\n\tgo func() {\r\n\t\tselect {\r\n\t\tcase <-finish:\r\n\t\t\treturn\r\n\t\tcase <-time.After(10 * time.Second):\r\n\t\t\treturn\r\n\t\tdefault:\r\n\t\t\tfor {\r\n\t\t\t\tif sigHandler.GetState() != 0 {\r\n\t\t\t\t\tlogger.Critical(\"detected signal. retry failed.\")\r\n\t\t\t\t\tos.Exit(1)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}()\r\n\tfor i := 0; i < r.retries; i++ {\r\n\t\terr := r.retryable.Try()\r\n\t\tif err != nil {\r\n\t\t\tlogger.Info(\"Retryable error: %v\", err)\r\n\t\t\ttime.Sleep(time.Duration(r.sleepSeconds) * time.Second)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tfinish <- true\r\n\t\treturn nil\r\n\t}\r\n\tfinish <- true\r\n\treturn fmt.Errorf(\"unable to succeed at retry after %d attempts at %d seconds\", r.retries, r.sleepSeconds)\r\n}","code-length":324,"reference":"\/\/ RunRetry runs a retryable function.","result":"Run the retry function .","score":[0,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MustGenerateRandomBytes(length int) []byte {\r\n\tres, err := GenerateRandomBytes(length)\r\n\tif err != nil {\r\n\t\tpanic(\"Could not generate random bytes\")\r\n\t}\r\n\treturn res\r\n}","code-length":67,"reference":"\/\/ MustGenerateRandomBytes generates random bytes or panics if it can't","result":"Generate random bytes.","score":[0.0396,0.2016]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ExplainCmd() *cobra.Command {\r\n\tvar exo = &cli.ExplainOptions{}\r\n\tvar cmd = &cobra.Command{\r\n\t\tUse:   \"explain\",\r\n\t\tShort: \"Explain cluster\",\r\n\t\tLong:  `Output expected and actual state of the given cluster`,\r\n\t\tRun: func(cmd *cobra.Command, args []string) {\r\n\t\t\tswitch len(args) {\r\n\t\t\tcase 0:\r\n\t\t\t\texo.Name = viper.GetString(keyKubicornName)\r\n\t\t\tcase 1:\r\n\t\t\t\texo.Name = args[0]\r\n\t\t\tdefault:\r\n\t\t\t\tlogger.Critical(\"Too many arguments.\")\r\n\t\t\t\tos.Exit(1)\r\n\t\t\t}\r\n\t\t\tif err := runExplain(exo); err != nil {\r\n\t\t\t\tlogger.Critical(err.Error())\r\n\t\t\t\tos.Exit(1)\r\n\t\t\t}\r\n\t\t},\r\n\t}\r\n\tfs := cmd.Flags()\r\n\tbindCommonStateStoreFlags(&exo.StateStoreOptions, fs)\r\n\tbindCommonAwsFlags(&exo.AwsOptions, fs)\r\n\tfs.StringVarP(&exo.Output, keyOutput, \"o\", viper.GetString(keyOutput), descOutput)\r\n\tfs.StringVar(&exo.GitRemote, keyGitConfig, viper.GetString(keyGitConfig), descGitConfig)\r\n\treturn cmd\r\n}","code-length":371,"reference":"\/\/ ExplainCmd represents the explain command","result":"Generate the explanations.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc TimeOrderedUUID() string {\r\n\tunixTime := uint32(time.Now().UTC().Unix())\r\n\treturn fmt.Sprintf(\"%08x-%04x-%04x-%04x-%04x%08x\",\r\n\t\tunixTime,\r\n\t\trand.MustGenerateRandomBytes(2),\r\n\t\trand.MustGenerateRandomBytes(2),\r\n\t\trand.MustGenerateRandomBytes(2),\r\n\t\trand.MustGenerateRandomBytes(2),\r\n\t\trand.MustGenerateRandomBytes(4))\r\n}","code-length":135,"reference":"\/\/ TimeOrderedUUID generates a time ordered UUID. Top 32b are timestamp bottom 96b are random.","result":"Generate a UUID.","score":[0.0089,0.1852]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetConfigCmd() *cobra.Command {\r\n\tvar cro = &cli.GetConfigOptions{}\r\n\tvar getConfigCmd = &cobra.Command{\r\n\t\tUse:   \"getconfig <NAME>\",\r\n\t\tShort: \"Manage Kubernetes configuration\",\r\n\t\tLong: `Use this command to pull a kubeconfig file from a cluster so you can use kubectl.\r\n\t\r\n\tThis command will attempt to find a cluster, and append a local kubeconfig file with a kubeconfig `,\r\n\t\tRun: func(cmd *cobra.Command, args []string) {\r\n\t\t\tswitch len(args) {\r\n\t\t\tcase 0:\r\n\t\t\t\tcro.Name = viper.GetString(keyKubicornName)\r\n\t\t\tcase 1:\r\n\t\t\t\tcro.Name = args[0]\r\n\t\t\tdefault:\r\n\t\t\t\tlogger.Critical(\"Too many arguments.\")\r\n\t\t\t\tos.Exit(1)\r\n\t\t\t}\r\n\t\t\tif err := runGetConfig(cro); err != nil {\r\n\t\t\t\tlogger.Critical(err.Error())\r\n\t\t\t\tos.Exit(1)\r\n\t\t\t}\r\n\t\t},\r\n\t}\r\n\tfs := getConfigCmd.Flags()\r\n\tbindCommonStateStoreFlags(&cro.StateStoreOptions, fs)\r\n\tbindCommonAwsFlags(&cro.AwsOptions, fs)\r\n\tfs.StringVar(&cro.GitRemote, keyGitConfig, viper.GetString(keyGitConfig), descGitConfig)\r\n\treturn getConfigCmd\r\n}","code-length":378,"reference":"\/\/ GetConfigCmd represents the apply command","result":"Generate the kubeconfig file.","score":[0.1938,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RunAnnotated(task Task, description string, symbol string, options ...interface{}) error {\r\n\tdoneCh := make(chan bool)\r\n\terrCh := make(chan error)\r\n\tl := logger.Log\r\n\tt := DefaultTicker\r\n\tfor _, o := range options {\r\n\t\tif value, ok := o.(logger.Logger); ok {\r\n\t\t\tl = value\r\n\t\t} else if value, ok := o.(*time.Ticker); ok {\r\n\t\t\tt = value\r\n\t\t}\r\n\t}\r\n\tgo func() {\r\n\t\terrCh <- task()\r\n\t}()\r\n\tl(description)\r\n\tlogActivity(symbol, l, t, doneCh)\r\n\terr := <-errCh\r\n\tdoneCh <- true\r\n\treturn err\r\n}","code-length":204,"reference":"\/\/ RunAnnotated annotates a task with a description and a sequence of symbols indicating task activity until it terminates","result":"Run tasks annotated with .","score":[0.0146,0.0852]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ListCmd() *cobra.Command {\r\n\tvar lo = &cli.ListOptions{}\r\n\tvar cmd = &cobra.Command{\r\n\t\tUse:   \"list\",\r\n\t\tShort: \"List available states\",\r\n\t\tLong:  `List the states available in the _state directory`,\r\n\t\tRun: func(cmd *cobra.Command, args []string) {\r\n\t\t\tif err := runList(lo); err != nil {\r\n\t\t\t\tlogger.Critical(err.Error())\r\n\t\t\t\tos.Exit(1)\r\n\t\t\t}\r\n\t\t},\r\n\t}\r\n\tfs := cmd.Flags()\r\n\tbindCommonStateStoreFlags(&lo.StateStoreOptions, fs)\r\n\tbindCommonAwsFlags(&lo.AwsOptions, fs)\r\n\tfs.BoolVarP(&noHeaders, keyNoHeaders, \"n\", viper.GetBool(keyNoHeaders), desNoHeaders)\r\n\treturn cmd\r\n}","code-length":240,"reference":"\/\/ ListCmd represents the list command","result":"List the states in the .","score":[0.193,0.1667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewUbuntuCluster(name string) *cluster.Cluster {\r\n\tcontrolPlaneProviderConfig := &cluster.ControlPlaneProviderConfig{\r\n\t\tCloud: cluster.CloudPacket,\r\n\t\tProject: &cluster.Project{\r\n\t\t\tName: fmt.Sprintf(\"kubicorn-%s\", name),\r\n\t\t},\r\n\t\tLocation: \"ewr1\",\r\n\t\tSSH: &cluster.SSH{\r\n\t\t\tPublicKeyPath: \"~\/.ssh\/id_rsa.pub\",\r\n\t\t\tUser:          \"root\",\r\n\t\t},\r\n\t\tKubernetesAPI: &cluster.KubernetesAPI{\r\n\t\t\tPort: \"443\",\r\n\t\t},\r\n\t\tValues: &cluster.Values{\r\n\t\t\tItemMap: map[string]string{\r\n\t\t\t\t\"INJECTEDTOKEN\": kubeadm.GetRandomToken(),\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n\tmachineSetsProviderConfigs := []*cluster.MachineProviderConfig{\r\n\t\t{\r\n\t\t\tServerPool: &cluster.ServerPool{\r\n\t\t\t\tType:     cluster.ServerPoolTypeMaster,\r\n\t\t\t\tName:     fmt.Sprintf(\"%s.master\", name),\r\n\t\t\t\tMaxCount: 1,\r\n\t\t\t\tMinCount: 1,\r\n\t\t\t\tImage:    \"ubuntu_16_04\",\r\n\t\t\t\tSize:     \"baremetal_1\",\r\n\t\t\t\tBootstrapScripts: []string{\r\n\t\t\t\t\t\"bootstrap\/packet_k8s_ubuntu_16.04_master.sh\",\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t},\r\n\t\t{\r\n\t\t\tServerPool: &cluster.ServerPool{\r\n\t\t\t\tType:     cluster.ServerPoolTypeNode,\r\n\t\t\t\tName:     fmt.Sprintf(\"%s.node\", name),\r\n\t\t\t\tMaxCount: 1,\r\n\t\t\t\tMinCount: 1,\r\n\t\t\t\tImage:    \"ubuntu_16_04\",\r\n\t\t\t\tSize:     \"baremetal_2\",\r\n\t\t\t\tBootstrapScripts: []string{\r\n\t\t\t\t\t\"bootstrap\/packet_k8s_ubuntu_16.04_node.sh\",\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n\tc := cluster.NewCluster(name)\r\n\tc.SetProviderConfig(controlPlaneProviderConfig)\r\n\tc.NewMachineSetsFromProviderConfigs(machineSetsProviderConfigs)\r\n\treturn c\r\n}","code-length":589,"reference":"\/\/ NewUbuntuCluster creates a simple Ubuntu Amazon cluster","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EditCmd() *cobra.Command {\r\n\tvar eo = &cli.EditOptions{}\r\n\tvar editCmd = &cobra.Command{\r\n\t\tUse:   \"edit <NAME>\",\r\n\t\tShort: \"Edit a cluster state\",\r\n\t\tLong:  `Use this command to edit a state.`,\r\n\t\tRun: func(cmd *cobra.Command, args []string) {\r\n\t\t\tswitch len(args) {\r\n\t\t\tcase 0:\r\n\t\t\t\teo.Name = viper.GetString(keyKubicornName)\r\n\t\t\tcase 1:\r\n\t\t\t\teo.Name = args[0]\r\n\t\t\tdefault:\r\n\t\t\t\tlogger.Critical(\"Too many arguments.\")\r\n\t\t\t\tos.Exit(1)\r\n\t\t\t}\r\n\t\t\tif err := runEdit(eo); err != nil {\r\n\t\t\t\tlogger.Critical(err.Error())\r\n\t\t\t\tos.Exit(1)\r\n\t\t\t}\r\n\t\t},\r\n\t}\r\n\tfs := editCmd.Flags()\r\n\tbindCommonStateStoreFlags(&eo.StateStoreOptions, fs)\r\n\tbindCommonAwsFlags(&eo.AwsOptions, fs)\r\n\tfs.StringVarP(&eo.Editor, keyEditor, \"e\", viper.GetString(keyEditor), descEditor)\r\n\tfs.StringVar(&eo.GitRemote, keyGitConfig, viper.GetString(keyGitConfig), descGitConfig)\r\n\treturn editCmd\r\n}","code-length":366,"reference":"\/\/ EditCmd represents edit command","result":"Edit a cluster state.","score":[0,0.102]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (k *Keyring) RemoveKey(key ssh.PublicKey) error {\r\n\treturn k.Agent.Remove(key)\r\n}","code-length":41,"reference":"\/\/ RemoveKey removes an existing key from keyring","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (k *Keyring) RemoveKeyUsingFile(pubkey string) error {\r\n\tp, err := ioutil.ReadFile(pubkey)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tkey, _, _, _, _ := ssh.ParseAuthorizedKey(p)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn k.RemoveKey(key)\r\n}","code-length":111,"reference":"\/\/ RemoveKeyUsingFile removes an existing key from keyring given a file","result":"Remove a key from the keyring.","score":[0.1313,0.3006]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Firewall) Actual(immutable *cluster.Cluster) (*cluster.Cluster, cloud.Resource, error) {\r\n\tlogger.Debug(\"firewall.Actual\")\r\n\tnewResource := defaultFirewallStruct()\r\n\t\r\n\tfirewalls, _, err := Sdk.Client.Firewalls.List(context.TODO(), &godo.ListOptions{})\r\n\tif err != nil {\r\n\t\treturn nil, nil, fmt.Errorf(\"failed to get firwalls info\")\r\n\t}\r\n\tfor _, firewall := range firewalls {\r\n\t\tif firewall.Name == r.Name {\r\n\t\t\t\r\n\t\t\tfirewallBytes, err := json.Marshal(firewall)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, nil, fmt.Errorf(\"failed to marshal DO firewall details err: %v\", err)\r\n\t\t\t}\r\n\t\t\tif err := json.Unmarshal(firewallBytes, newResource); err != nil {\r\n\t\t\t\treturn nil, nil, fmt.Errorf(\"failed to unmarhal DO firewall details err: %v\", err)\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tfor i := 0; i < len(newResource.OutboundRules); i++ {\r\n\t\t\t\tif newResource.OutboundRules[i].PortRange == \"0\" {\r\n\t\t\t\t\tnewResource.OutboundRules[i].PortRange = \"all\"\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tfor i := 0; i < len(newResource.InboundRules); i++ {\r\n\t\t\t\tif newResource.InboundRules[i].PortRange == \"0\" {\r\n\t\t\t\t\tnewResource.InboundRules[i].PortRange = \"all\"\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tnewCluster := r.immutableRender(newResource, immutable)\r\n\treturn newCluster, newResource, nil\r\n}","code-length":441,"reference":"\/\/ Actual calls DO firewall Api and returns the actual state of firewall in the cloud.","result":"Test if firewall is created by the user.","score":[0.0608,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Firewall) Expected(immutable *cluster.Cluster) (*cluster.Cluster, cloud.Resource, error) {\r\n\tlogger.Debug(\"firewall.Expected\")\r\n\tnewResource := &Firewall{\r\n\t\tShared: Shared{\r\n\t\t\tName:    r.Name,\r\n\t\t\tCloudID: r.ServerPool.Identifier,\r\n\t\t},\r\n\t\tInboundRules:  r.InboundRules,\r\n\t\tOutboundRules: r.OutboundRules,\r\n\t\tDropletIDs:    r.DropletIDs,\r\n\t\tTags:          r.Tags,\r\n\t\tFirewallID:    r.FirewallID,\r\n\t\tStatus:        r.Status,\r\n\t\tCreated:       r.Created,\r\n\t}\r\n\t\r\n\tnewCluster := r.immutableRender(newResource, immutable)\r\n\treturn newCluster, newResource, nil\r\n}","code-length":220,"reference":"\/\/ Expected returns the Firewall structure of what is Expected.","result":"Test if the firewall is expected.","score":[0.1179,0.3906]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Firewall) Apply(actual, expected cloud.Resource, immutable *cluster.Cluster) (*cluster.Cluster, cloud.Resource, error) {\r\n\tlogger.Debug(\"firewall.Apply\")\r\n\texpectedResource := expected.(*Firewall)\r\n\tactualResource := actual.(*Firewall)\r\n\tisEqual, err := compare.IsEqual(actualResource, expectedResource)\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\tif isEqual {\r\n\t\treturn immutable, expected, nil\r\n\t}\r\n\tfirewallRequest := godo.FirewallRequest{\r\n\t\tName:          expectedResource.Name,\r\n\t\tInboundRules:  convertInRuleType(expectedResource.InboundRules),\r\n\t\tOutboundRules: convertOutRuleType(expectedResource.OutboundRules),\r\n\t\tDropletIDs:    expectedResource.DropletIDs,\r\n\t\tTags:          expectedResource.Tags,\r\n\t}\r\n\t\r\n\tmachineProviderConfigs := immutable.MachineProviderConfigs()\r\n\tfor _, machineProviderConfig := range machineProviderConfigs {\r\n\t\tfor i := 0; i <= TagsGetAttempts; i++ {\r\n\t\t\tactive := true\r\n\t\t\tdroplets, _, err := Sdk.Client.Droplets.ListByTag(context.TODO(), machineProviderConfig.ServerPool.Name, &godo.ListOptions{})\r\n\t\t\tif err != nil {\r\n\t\t\t\tlogger.Debug(\"Hanging for droplets to get created.. (%v)\", err)\r\n\t\t\t\ttime.Sleep(time.Duration(TagsGetTimeout) * time.Second)\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tif len(droplets) == 0 {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tfor _, d := range droplets {\r\n\t\t\t\tif d.Status != \"active\" {\r\n\t\t\t\t\tactive = false\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tif !active {\r\n\t\t\t\tlogger.Debug(\"Waiting for droplets to become active..\")\r\n\t\t\t\ttime.Sleep(time.Duration(TagsGetTimeout) * time.Second)\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tfirewall, _, err := Sdk.Client.Firewalls.Create(context.TODO(), &firewallRequest)\r\n\tif err != nil {\r\n\t\treturn nil, nil, fmt.Errorf(\"failed to create the firewall err: %v\", err)\r\n\t}\r\n\tlogger.Success(\"Created Firewall [%s]\", firewall.ID)\r\n\tnewResource := &Firewall{\r\n\t\tShared: Shared{\r\n\t\t\tCloudID: firewall.ID,\r\n\t\t\tName:    r.Name,\r\n\t\t\tTags:    r.Tags,\r\n\t\t},\r\n\t\tDropletIDs:    r.DropletIDs,\r\n\t\tFirewallID:    firewall.ID,\r\n\t\tInboundRules:  r.InboundRules,\r\n\t\tOutboundRules: r.OutboundRules,\r\n\t\tCreated:       r.Created,\r\n\t}\r\n\tnewCluster := r.immutableRender(newResource, immutable)\r\n\treturn newCluster, newResource, nil\r\n}","code-length":768,"reference":"\/\/ Apply will compare the actual and expected firewall config, if needed it will create the firewall.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Firewall) Delete(actual cloud.Resource, immutable *cluster.Cluster) (*cluster.Cluster, cloud.Resource, error) {\r\n\tlogger.Debug(\"firewall.Delete\")\r\n\tdeleteResource, ok := actual.(*Firewall)\r\n\tif !ok {\r\n\t\treturn nil, nil, fmt.Errorf(\"failed to type convert actual Firewall type \")\r\n\t}\r\n\tif deleteResource.Name == \"\" {\r\n\t\treturn immutable, nil, nil\r\n\t\treturn nil, nil, fmt.Errorf(\"Unable to delete firewall resource without Name [%s]\", deleteResource.Name)\r\n\t}\r\n\tif _, err := Sdk.Client.Firewalls.Delete(context.TODO(), deleteResource.FirewallID); err != nil {\r\n\t\treturn nil, nil, fmt.Errorf(\"failed to delete firewall [%s] err: %v\", deleteResource.Name, err)\r\n\t}\r\n\tlogger.Success(\"Deleted firewall [%s]\", deleteResource.FirewallID)\r\n\tnewResource := &Firewall{\r\n\t\tShared: Shared{\r\n\t\t\tName: r.Name,\r\n\t\t\tTags: r.Tags,\r\n\t\t},\r\n\t\tInboundRules:  r.InboundRules,\r\n\t\tOutboundRules: r.OutboundRules,\r\n\t\tCreated:       r.Created,\r\n\t}\r\n\tnewCluster := r.immutableRender(newResource, immutable)\r\n\treturn newCluster, newResource, nil\r\n}","code-length":349,"reference":"\/\/ Delete removes the firewall","result":"Delete firewall.","score":[0.1116,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DeleteCmd() *cobra.Command {\r\n\tvar do = &cli.DeleteOptions{}\r\n\tvar deleteCmd = &cobra.Command{\r\n\t\tUse:   \"delete <NAME>\",\r\n\t\tShort: \"Delete a Kubernetes cluster\",\r\n\t\tLong: `Use this command to delete cloud resources.\r\n\t\r\n\tThis command will attempt to build the resource graph based on an API model.\r\n\tOnce the graph is built, the delete will attempt to delete the resources from the cloud.\r\n\tAfter the delete is complete, the state store will be left in tact and could potentially be applied later.\r\n\t\r\n\tTo delete the resource AND the API model in the state store, use --purge.`,\r\n\t\tRun: func(cmd *cobra.Command, args []string) {\r\n\t\t\tswitch len(args) {\r\n\t\t\tcase 0:\r\n\t\t\t\tdo.Name = viper.GetString(keyKubicornName)\r\n\t\t\tcase 1:\r\n\t\t\t\tdo.Name = args[0]\r\n\t\t\tdefault:\r\n\t\t\t\tlogger.Critical(\"Too many arguments.\")\r\n\t\t\t\tos.Exit(1)\r\n\t\t\t}\r\n\t\t\tif err := runDelete(do); err != nil {\r\n\t\t\t\tlogger.Critical(err.Error())\r\n\t\t\t\tos.Exit(1)\r\n\t\t\t}\r\n\t\t},\r\n\t}\r\n\tfs := deleteCmd.Flags()\r\n\tbindCommonStateStoreFlags(&do.StateStoreOptions, fs)\r\n\tbindCommonAwsFlags(&do.AwsOptions, fs)\r\n\tfs.StringVar(&do.AwsProfile, keyAwsProfile, viper.GetString(keyAwsProfile), descAwsProfile)\r\n\tfs.StringVar(&do.GitRemote, keyGitConfig, viper.GetString(keyGitConfig), descGitConfig)\r\n\tfs.BoolVarP(&do.Purge, keyPurge, \"p\", viper.GetBool(keyPurge), descPurge)\r\n\treturn deleteCmd\r\n}","code-length":485,"reference":"\/\/ DeleteCmd represents the delete command","result":"Delete resources from the state store.","score":[0.193,0.1667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (options Options) NewStateStore() (state.ClusterStorer, error) {\r\n\tvar stateStore state.ClusterStorer\r\n\tswitch options.StateStore {\r\n\tcase \"fs\":\r\n\t\tlogger.Info(\"Selected [fs] state store\")\r\n\t\tstateStore = fs.NewFileSystemStore(&fs.FileSystemStoreOptions{\r\n\t\t\tBasePath:    options.StateStorePath,\r\n\t\t\tClusterName: options.Name,\r\n\t\t})\r\n\tcase \"crd\":\r\n\t\tlogger.Info(\"Selected [crd] state store\")\r\n\t\tstateStore = crd.NewCRDStore(&crd.CRDStoreOptions{\r\n\t\t\tBasePath:    options.StateStorePath,\r\n\t\t\tClusterName: options.Name,\r\n\t\t})\r\n\tcase \"git\":\r\n\t\tlogger.Info(\"Selected [git] state store\")\r\n\t\tif options.GitRemote == \"\" {\r\n\t\t\treturn nil, errors.New(\"empty GitRemote url. Must specify the link to the remote git repo\")\r\n\t\t}\r\n\t\tuser, _ := gg.Global(\"user.name\")\r\n\t\temail, _ := gg.Email()\r\n\t\tstateStore = git.NewJSONGitStore(&git.JSONGitStoreOptions{\r\n\t\t\tBasePath:    options.StateStorePath,\r\n\t\t\tClusterName: options.Name,\r\n\t\t\tCommitConfig: &git.JSONGitCommitConfig{\r\n\t\t\t\tName:   user,\r\n\t\t\t\tEmail:  email,\r\n\t\t\t\tRemote: options.GitRemote,\r\n\t\t\t},\r\n\t\t})\r\n\tcase \"jsonfs\":\r\n\t\tlogger.Info(\"Selected [jsonfs] state store\")\r\n\t\tstateStore = jsonfs.NewJSONFileSystemStore(&jsonfs.JSONFileSystemStoreOptions{\r\n\t\t\tBasePath:    options.StateStorePath,\r\n\t\t\tClusterName: options.Name,\r\n\t\t})\r\n\tcase \"s3\":\r\n\t\tlogger.Info(\"Selected [s3] state store\")\r\n\t\tclient, err := minio.New(options.BucketEndpointURL, options.S3AccessKey, options.S3SecretKey, options.BucketSSL)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tstateStore = s3.NewJSONFS3Store(&s3.JSONS3StoreOptions{\r\n\t\t\tBasePath:    options.StateStorePath,\r\n\t\t\tClusterName: options.Name,\r\n\t\t\tClient:      client,\r\n\t\t\tBucketOptions: &s3.S3BucketOptions{\r\n\t\t\t\tEndpointURL: options.BucketEndpointURL,\r\n\t\t\t\tBucketName:  options.BucketName,\r\n\t\t\t},\r\n\t\t})\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"state store [%s] has an invalid type [%s]\", options.Name, options.StateStore)\r\n\t}\r\n\treturn stateStore, nil\r\n}","code-length":703,"reference":"\/\/ NewStateStore returns clusterStorer object based on type.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (git *JSONGitStore) Commit(c *cluster.Cluster) error {\r\n\tif c == nil {\r\n\t\treturn fmt.Errorf(\"Nil cluster spec\")\r\n\t}\r\n\tbytes, err := json.Marshal(c)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tgit.Write(state.ClusterJSONFile, bytes)\r\n\t\r\n\tr, err := g.NewFilesystemRepository(state.ClusterJSONFile)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t_, err = r.CreateRemote(&config.RemoteConfig{\r\n\t\tName: git.ClusterName,\r\n\t\tURL:  git.options.CommitConfig.Remote,\r\n\t})\r\n\t_, err = r.Commits()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":229,"reference":"\/\/Performs a git 'commit' and 'push' of the current cluster changes.","result":"Commit the changes to the cluster.","score":[0.0839,0.0476]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ApplyCmd() *cobra.Command {\r\n\tvar ao = &cli.ApplyOptions{}\r\n\tvar applyCmd = &cobra.Command{\r\n\t\tUse:   \"apply <NAME>\",\r\n\t\tShort: \"Apply a cluster resource to a cloud\",\r\n\t\tLong: `Use this command to apply an API model in a cloud.\r\n\tThis command will attempt to find an API model in a defined state store, and then apply any changes needed directly to a cloud.\r\n\tThe apply will run once, and ultimately time out if something goes wrong.`,\r\n\t\tRun: func(cmd *cobra.Command, args []string) {\r\n\t\t\tswitch len(args) {\r\n\t\t\tcase 0:\r\n\t\t\t\tao.Name = viper.GetString(keyKubicornName)\r\n\t\t\tcase 1:\r\n\t\t\t\tao.Name = args[0]\r\n\t\t\tdefault:\r\n\t\t\t\tlogger.Critical(\"Too many arguments.\")\r\n\t\t\t\tos.Exit(1)\r\n\t\t\t}\r\n\t\t\tif err := runApply(ao); err != nil {\r\n\t\t\t\tlogger.Critical(err.Error())\r\n\t\t\t\tos.Exit(1)\r\n\t\t\t}\r\n\t\t},\r\n\t}\r\n\tfs := applyCmd.Flags()\r\n\tbindCommonStateStoreFlags(&ao.StateStoreOptions, fs)\r\n\tbindCommonAwsFlags(&ao.AwsOptions, fs)\r\n\tfs.StringArrayVarP(&ao.Set, keyKubicornSet, \"e\", viper.GetStringSlice(keyKubicornSet), descSet)\r\n\tfs.StringVar(&ao.AwsProfile, keyAwsProfile, viper.GetString(keyAwsProfile), descAwsProfile)\r\n\tfs.StringVar(&ao.GitRemote, keyGitConfig, viper.GetString(keyGitConfig), descGitConfig)\r\n\treturn applyCmd\r\n}","code-length":459,"reference":"\/\/ ApplyCmd represents the apply command","result":"Generate the apply command.","score":[0.274,0.3233]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ExpandPath(path string) string {\r\n\tswitch path {\r\n\tcase \".\":\r\n\t\twd, err := os.Getwd()\r\n\t\tif err != nil {\r\n\t\t\tlogger.Critical(\"Unable to get current working directory: %v\", err)\r\n\t\t\treturn \"\"\r\n\t\t}\r\n\t\tpath = wd\r\n\tcase \"~\":\r\n\t\thomeVar := os.Getenv(\"HOME\")\r\n\t\tif homeVar == \"\" {\r\n\t\t\thomeUser, err := user.Current()\r\n\t\t\tif err != nil {\r\n\t\t\t\tlogger.Critical(\"Unable to use user.Current() for user. Maybe a cross compile issue: %v\", err)\r\n\t\t\t\treturn \"\"\r\n\t\t\t}\r\n\t\t\tpath = homeUser.HomeDir\r\n\t\t}\r\n\t}\r\n\treturn path\r\n}","code-length":210,"reference":"\/\/ ExpandPath returns working directory path","result":"Expand paths.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CompletionCmd() *cobra.Command {\r\n\treturn &cobra.Command{\r\n\t\tUse:   \"completion\",\r\n\t\tShort: \"Generate completion code for bash and zsh shells.\",\r\n\t\tLong: `completion is used to output completion code for bash and zsh shells.\r\n\t\r\n\tBefore using completion features, you have to source completion code\r\n\tfrom your .profile. This is done by adding following line to one of above files:\r\n\t\tsource <(kubicorn completion SHELL)\r\n\tValid arguments for SHELL are: \"bash\" and \"zsh\".\r\n\tNotes:\r\n\t1) zsh completions requires zsh 5.2 or newer.\r\n\t\t\r\n\t2) macOS users have to install bash-completion framework to utilize\r\n\tcompletion features. This can be done using homebrew:\r\n\t\tbrew install bash-completion\r\n\tOnce installed, you must load bash_completion by adding following\r\n\tline to your .profile or .bashrc\/.zshrc:\r\n\t\tsource $(brew --prefix)\/etc\/bash_completion`,\r\n\t\tRunE: func(cmd *cobra.Command, args []string) error {\r\n\t\t\tif logger.Fabulous {\r\n\t\t\t\tcmd.SetOutput(logger.FabulousWriter)\r\n\t\t\t}\r\n\t\t\tif viper.GetString(keyTrueColor) != \"\" {\r\n\t\t\t\tcmd.SetOutput(logger.FabulousWriter)\r\n\t\t\t}\r\n\t\t\tswitch len(args) {\r\n\t\t\tcase 0:\r\n\t\t\t\treturn fmt.Errorf(\"shell argument is not specified\")\r\n\t\t\tdefault:\r\n\t\t\t\tswitch args[0] {\r\n\t\t\t\tcase \"bash\":\r\n\t\t\t\t\treturn runBashGeneration()\r\n\t\t\t\tcase \"zsh\":\r\n\t\t\t\t\treturn runZshGeneration()\r\n\t\t\t\tdefault:\r\n\t\t\t\t\treturn fmt.Errorf(\"invalid shell argument\")\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t},\r\n\t}\r\n}","code-length":491,"reference":"\/\/ CompletionCmd represents the completion command","result":"Generate bash and zsh completions.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AdoptCmd() *cobra.Command {\r\n\treturn &cobra.Command{\r\n\t\tUse:   \"adopt\",\r\n\t\tShort: \"Adopt a Kubernetes cluster into a Kubicorn state store\",\r\n\t\tLong: `Use this command to audit and adopt a Kubernetes cluster into a Kubicorn state store.\r\n\t\r\n\tThis command will query cloud resources and attempt to build a representation of the cluster in the Kubicorn API model.\r\n\tOnce the cluster has been adopted, a user can manage and scale their Kubernetes cluster with Kubicorn.`,\r\n\t\tRun: func(cmd *cobra.Command, args []string) {\r\n\t\t\tfmt.Println(\"adopt called\")\r\n\t\t},\r\n\t}\r\n}","code-length":192,"reference":"\/\/ AdoptCmd represents the adopt command","result":"Audit and adopt a Kubernetes cluster.","score":[0.193,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StrEnvDef(env string, def string) string {\r\n\tval := os.Getenv(env)\r\n\tif val == \"\" {\r\n\t\treturn def\r\n\t}\r\n\treturn val\r\n}","code-length":60,"reference":"\/\/ StrEnvDef get environment variable, or some default def","result":"Define the default value.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IntEnvDef(env string, def int) int {\r\n\tval := os.Getenv(env)\r\n\tif val == \"\" {\r\n\t\treturn def\r\n\t}\r\n\tival, err := strconv.Atoi(val)\r\n\tif err != nil {\r\n\t\treturn def\r\n\t}\r\n\treturn ival\r\n}","code-length":93,"reference":"\/\/ IntEnvDef get environment variable, or some default def","result":"Define default value for env vars.","score":[0.1171,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc BoolEnvDef(env string, def bool) bool {\r\n\tval := os.Getenv(env)\r\n\tif val == \"\" {\r\n\t\treturn def\r\n\t}\r\n\tb, err := strconv.ParseBool(val)\r\n\tif err != nil {\r\n\t\treturn def\r\n\t}\r\n\treturn b\r\n}","code-length":92,"reference":"\/\/ BoolEnvDef get environemnt variable and return bool.","result":"Define default value of env variables.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc readFromFS(sourcePath string) (string, error) {\r\n\t\r\n\t\r\n\t\r\n\tif strings.HasPrefix(sourcePath, \"~\") {\r\n\t\thomeDir := os.Getenv(\"HOME\")\r\n\t\tif homeDir == \"\" {\r\n\t\t\treturn \"\", fmt.Errorf(\"Could not find $HOME\")\r\n\t\t}\r\n\t\tsourcePath = filepath.Join(homeDir, sourcePath[1:])\r\n\t}\r\n\tbytes, err := ioutil.ReadFile(sourcePath)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn string(bytes), nil\r\n}","code-length":161,"reference":"\/\/ readFromFS reads file from a local path and returns as string","result":"Read from a file.","score":[0.0611,0.2282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc VersionCmd() *cobra.Command {\r\n\treturn &cobra.Command{\r\n\t\tUse:   \"version\",\r\n\t\tShort: \"Verify Kubicorn version\",\r\n\t\tLong: `Use this command to check the version of Kubicorn.\r\n\t\r\n\tThis command will return the version of the Kubicorn binary.`,\r\n\t\tRun: func(cmd *cobra.Command, args []string) {\r\n\t\t\tfmt.Printf(\"%s\\n\", version.GetVersionJSON())\r\n\t\t},\r\n\t}\r\n}","code-length":144,"reference":"\/\/ VersionCmd represents the version command","result":"Generate the version of the Kubicorn binary.","score":[0.2284,0.1639]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSignalHandler(timeoutSeconds int) *Handler {\r\n\tsignals := make(chan os.Signal)\r\n\tsignal.Notify(signals, os.Interrupt, os.Kill)\r\n\treturn &Handler{\r\n\t\ttimeoutSeconds: timeoutSeconds,\r\n\t\tsignals:        signals,\r\n\t\tsignalReceived: 0,\r\n\t}\r\n}","code-length":92,"reference":"\/\/ NewSignalHandler creates a new Handler using given properties.","result":"Create a new signal handler.","score":[0.1527,0.3424]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *Handler) Register() {\r\n\tgo func() {\r\n\t\th.timer = time.NewTimer(time.Duration(h.timeoutSeconds) * time.Second)\r\n\t\tfor {\r\n\t\t\tselect {\r\n\t\t\tcase s := <-h.signals:\r\n\t\t\t\tswitch {\r\n\t\t\t\tcase s == os.Interrupt:\r\n\t\t\t\t\tif h.signalReceived == 0 {\r\n\t\t\t\t\t\th.signalReceived = 1\r\n\t\t\t\t\t\tlogger.Debug(\"SIGINT Received\")\r\n\t\t\t\t\t\tcontinue\r\n\t\t\t\t\t}\r\n\t\t\t\t\th.signalReceived = signalTerminate\r\n\t\t\t\t\tdebug.PrintStack()\r\n\t\t\t\t\tos.Exit(130)\r\n\t\t\t\t\tbreak\r\n\t\t\t\tcase s == syscall.SIGQUIT:\r\n\t\t\t\t\th.signalReceived = signalAbort\r\n\t\t\t\t\tbreak\r\n\t\t\t\tcase s == syscall.SIGTERM:\r\n\t\t\t\t\th.signalReceived = signalTerminate\r\n\t\t\t\t\tos.Exit(3)\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\tcase <-h.timer.C:\r\n\t\t\t\tos.Exit(4)\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t}()\r\n}","code-length":289,"reference":"\/\/ Register starts handling signals.","result":"Register the handler.","score":[0.2096,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewUbuntuCluster(name string) *cluster.Cluster {\r\n\tvar (\r\n\t\tmasterName = fmt.Sprintf(\"%s-master\", name)\r\n\t\tnodeName   = fmt.Sprintf(\"%s-node\", name)\r\n\t)\r\n\tcontrolPlaneProviderConfig := &cluster.ControlPlaneProviderConfig{\r\n\t\tCloud:    cluster.CloudECS,\r\n\t\tLocation: \"nl-ams1\",\r\n\t\tSSH: &cluster.SSH{\r\n\t\t\tPublicKeyPath: \"~\/.ssh\/id_rsa.pub\",\r\n\t\t\tUser:          \"ubuntu\",\r\n\t\t},\r\n\t\tValues: &cluster.Values{\r\n\t\t\tItemMap: map[string]string{\r\n\t\t\t\t\"INJECTEDTOKEN\": kubeadm.GetRandomToken(),\r\n\t\t\t},\r\n\t\t},\r\n\t\tKubernetesAPI: &cluster.KubernetesAPI{\r\n\t\t\tPort: \"443\",\r\n\t\t},\r\n\t\tNetwork: &cluster.Network{\r\n\t\t\tType: cluster.NetworkTypePublic,\r\n\t\t\tInternetGW: &cluster.InternetGW{\r\n\t\t\t\tName: \"default\",\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n\tmachineSetsProviderConfigs := []*cluster.MachineProviderConfig{\r\n\t\t{\r\n\t\t\tServerPool: &cluster.ServerPool{\r\n\t\t\t\tType:     cluster.ServerPoolTypeMaster,\r\n\t\t\t\tName:     masterName,\r\n\t\t\t\tMaxCount: 1,\r\n\t\t\t\tImage:    \"GNU\/Linux Ubuntu Server 16.04 Xenial Xerus x64\",\r\n\t\t\t\tSize:     \"e3standard.x3\",\r\n\t\t\t\tBootstrapScripts: []string{\r\n\t\t\t\t\t\"bootstrap\/ecs_k8s_ubuntu_16.04_master.sh\",\r\n\t\t\t\t},\r\n\t\t\t\tSubnets: []*cluster.Subnet{\r\n\t\t\t\t\t{\r\n\t\t\t\t\t\tName: \"internal\",\r\n\t\t\t\t\t\tCIDR: \"192.168.200.0\/24\",\r\n\t\t\t\t\t},\r\n\t\t\t\t},\r\n\t\t\t\tFirewalls: []*cluster.Firewall{\r\n\t\t\t\t\t{\r\n\t\t\t\t\t\tName: masterName,\r\n\t\t\t\t\t\tIngressRules: []*cluster.IngressRule{\r\n\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\tIngressFromPort: \"22\",\r\n\t\t\t\t\t\t\t\tIngressToPort:   \"22\",\r\n\t\t\t\t\t\t\t\tIngressSource:   \"0.0.0.0\/0\",\r\n\t\t\t\t\t\t\t\tIngressProtocol: \"tcp\",\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\tIngressFromPort: \"443\",\r\n\t\t\t\t\t\t\t\tIngressToPort:   \"443\",\r\n\t\t\t\t\t\t\t\tIngressSource:   \"0.0.0.0\/0\",\r\n\t\t\t\t\t\t\t\tIngressProtocol: \"tcp\",\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\tIngressSource: \"192.168.200.0\/24\",\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t},\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t},\r\n\t\t{\r\n\t\t\tServerPool: &cluster.ServerPool{\r\n\t\t\t\tType:     cluster.ServerPoolTypeNode,\r\n\t\t\t\tName:     nodeName,\r\n\t\t\t\tMaxCount: 2,\r\n\t\t\t\tImage:    \"GNU\/Linux Ubuntu Server 16.04 Xenial Xerus x64\",\r\n\t\t\t\tSize:     \"e3standard.x3\",\r\n\t\t\t\tBootstrapScripts: []string{\r\n\t\t\t\t\t\"bootstrap\/ecs_k8s_ubuntu_16.04_node.sh\",\r\n\t\t\t\t},\r\n\t\t\t\tFirewalls: []*cluster.Firewall{\r\n\t\t\t\t\t{\r\n\t\t\t\t\t\tName: nodeName,\r\n\t\t\t\t\t\tIngressRules: []*cluster.IngressRule{\r\n\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\tIngressFromPort: \"22\",\r\n\t\t\t\t\t\t\t\tIngressToPort:   \"22\",\r\n\t\t\t\t\t\t\t\tIngressSource:   \"0.0.0.0\/0\",\r\n\t\t\t\t\t\t\t\tIngressProtocol: \"tcp\",\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t\tIngressSource: \"192.168.200.0\/24\",\r\n\t\t\t\t\t\t\t},\r\n\t\t\t\t\t\t},\r\n\t\t\t\t\t},\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n\tc := cluster.NewCluster(name)\r\n\tc.SetProviderConfig(controlPlaneProviderConfig)\r\n\tc.NewMachineSetsFromProviderConfigs(machineSetsProviderConfigs)\r\n\treturn c\r\n}","code-length":1085,"reference":"\/\/ NewUbuntuCluster creates a simple Ubuntu Openstack cluster.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (now *Now) BeginningOfHour() time.Time {\r\n\ty, m, d := now.Date()\r\n\treturn time.Date(y, m, d, now.Time.Hour(), 0, 0, 0, now.Time.Location())\r\n}","code-length":72,"reference":"\/\/ BeginningOfHour beginning of hour","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (now *Now) BeginningOfDay() time.Time {\r\n\ty, m, d := now.Date()\r\n\treturn time.Date(y, m, d, 0, 0, 0, 0, now.Time.Location())\r\n}","code-length":67,"reference":"\/\/ BeginningOfDay beginning of day","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (now *Now) BeginningOfWeek() time.Time {\r\n\tt := now.BeginningOfDay()\r\n\tweekday := int(t.Weekday())\r\n\tif WeekStartDay != time.Sunday {\r\n\t\tweekStartDayInt := int(WeekStartDay)\r\n\t\tif weekday < weekStartDayInt {\r\n\t\t\tweekday = weekday + 7 - weekStartDayInt\r\n\t\t} else {\r\n\t\t\tweekday = weekday - weekStartDayInt\r\n\t\t}\r\n\t}\r\n\treturn t.AddDate(0, 0, -weekday)\r\n}","code-length":150,"reference":"\/\/ BeginningOfWeek beginning of week","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (now *Now) BeginningOfMonth() time.Time {\r\n\ty, m, _ := now.Date()\r\n\treturn time.Date(y, m, 1, 0, 0, 0, 0, now.Location())\r\n}","code-length":65,"reference":"\/\/ BeginningOfMonth beginning of month","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (now *Now) BeginningOfQuarter() time.Time {\r\n\tmonth := now.BeginningOfMonth()\r\n\toffset := (int(month.Month()) - 1) % 3\r\n\treturn month.AddDate(0, -offset, 0)\r\n}","code-length":72,"reference":"\/\/ BeginningOfQuarter beginning of quarter","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (now *Now) BeginningOfYear() time.Time {\r\n\ty, _, _ := now.Date()\r\n\treturn time.Date(y, time.January, 1, 0, 0, 0, 0, now.Location())\r\n}","code-length":69,"reference":"\/\/ BeginningOfYear BeginningOfYear beginning of year","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (now *Now) EndOfMinute() time.Time {\r\n\treturn now.BeginningOfMinute().Add(time.Minute - time.Nanosecond)\r\n}","code-length":49,"reference":"\/\/ EndOfMinute end of minute","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (now *Now) EndOfHour() time.Time {\r\n\treturn now.BeginningOfHour().Add(time.Hour - time.Nanosecond)\r\n}","code-length":49,"reference":"\/\/ EndOfHour end of hour","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (now *Now) EndOfDay() time.Time {\r\n\ty, m, d := now.Date()\r\n\treturn time.Date(y, m, d, 23, 59, 59, int(time.Second-time.Nanosecond), now.Location())\r\n}","code-length":74,"reference":"\/\/ EndOfDay end of day","result":"Generate the end of day time .","score":[0.3327,0.5662]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (now *Now) EndOfWeek() time.Time {\r\n\treturn now.BeginningOfWeek().AddDate(0, 0, 7).Add(-time.Nanosecond)\r\n}","code-length":52,"reference":"\/\/ EndOfWeek end of week","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (now *Now) EndOfMonth() time.Time {\r\n\treturn now.BeginningOfMonth().AddDate(0, 1, 0).Add(-time.Nanosecond)\r\n}","code-length":52,"reference":"\/\/ EndOfMonth end of month","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (now *Now) EndOfQuarter() time.Time {\r\n\treturn now.BeginningOfQuarter().AddDate(0, 3, 0).Add(-time.Nanosecond)\r\n}","code-length":56,"reference":"\/\/ EndOfQuarter end of quarter","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (now *Now) EndOfYear() time.Time {\r\n\treturn now.BeginningOfYear().AddDate(1, 0, 0).Add(-time.Nanosecond)\r\n}","code-length":52,"reference":"\/\/ EndOfYear end of year","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (now *Now) MustParse(strs ...string) (t time.Time) {\r\n\tt, err := now.Parse(strs...)\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\treturn t\r\n}","code-length":71,"reference":"\/\/ MustParse must parse string to time or it will panic","result":"Parse the time.","score":[0,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (now *Now) Between(begin, end string) bool {\r\n\tbeginTime := now.MustParse(begin)\r\n\tendTime := now.MustParse(end)\r\n\treturn now.After(beginTime) && now.Before(endTime)\r\n}","code-length":73,"reference":"\/\/ Between check time between the begin, end time or not","result":"Test the code.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseInLocation(loc *time.Location, strs ...string) (time.Time, error) {\r\n\treturn New(time.Now().In(loc)).Parse(strs...)\r\n}","code-length":54,"reference":"\/\/ ParseInLocation parse string to time in location","result":"Parse the file .","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MustParse(strs ...string) time.Time {\r\n\treturn New(time.Now()).MustParse(strs...)\r\n}","code-length":40,"reference":"\/\/ MustParse must parse string to time or will panic","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MustParseInLocation(loc *time.Location, strs ...string) time.Time {\r\n\treturn New(time.Now().In(loc)).MustParse(strs...)\r\n}","code-length":52,"reference":"\/\/ MustParseInLocation must parse string to time in location or will panic","result":"Parse the file .","score":[0,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Between(time1, time2 string) bool {\r\n\treturn New(time.Now()).Between(time1, time2)\r\n}","code-length":44,"reference":"\/\/ Between check now between the begin, end time or not","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewChannelMemoryBackend(size int) *ChannelMemoryBackend {\r\n\tbackend := &ChannelMemoryBackend{\r\n\t\tmaxSize:  size,\r\n\t\tincoming: make(chan *Record, 1024),\r\n\t\tevents:   make(chan event),\r\n\t}\r\n\tbackend.Start()\r\n\treturn backend\r\n}","code-length":88,"reference":"\/\/ NewChannelMemoryBackend creates a simple in-memory logging backend which\n\/\/ utilizes a go channel for communication.\n\/\/\n\/\/ Start will automatically be called by this function.","result":"Create a new backend.","score":[0.0013,0.042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *ChannelMemoryBackend) Start() {\r\n\tb.mu.Lock()\r\n\tdefer b.mu.Unlock()\r\n\t\r\n\tif b.running != true {\r\n\t\tb.running = true\r\n\t\tb.stopWg.Add(1)\r\n\t\tgo b.process()\r\n\t}\r\n}","code-length":91,"reference":"\/\/ Start launches the internal goroutine which starts processing data from the\n\/\/ input channel.","result":"Start the backend.","score":[0.0089,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *ChannelMemoryBackend) Flush() {\r\n\tb.flushWg.Add(1)\r\n\tb.events <- eventFlush\r\n\tb.flushWg.Wait()\r\n}","code-length":56,"reference":"\/\/ Flush waits until all records in the buffered channel have been processed.","result":"Flush channel memory backend.","score":[0.04,0.0826]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *ChannelMemoryBackend) Stop() {\r\n\tb.mu.Lock()\r\n\tif b.running == true {\r\n\t\tb.running = false\r\n\t\tb.events <- eventStop\r\n\t}\r\n\tb.mu.Unlock()\r\n\tb.stopWg.Wait()\r\n}","code-length":85,"reference":"\/\/ Stop signals the internal goroutine to exit and waits until it have.","result":"Stop the backend.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Record) Formatted(calldepth int) string {\r\n\tif r.formatted == \"\" {\r\n\t\tvar buf bytes.Buffer\r\n\t\tr.formatter.Format(calldepth+1, r, &buf)\r\n\t\tr.formatted = buf.String()\r\n\t}\r\n\treturn r.formatted\r\n}","code-length":89,"reference":"\/\/ Formatted returns the formatted log record string.","result":"Format the record.","score":[0.0771,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Record) Message() string {\r\n\tif r.message == nil {\r\n\t\t\r\n\t\tfor i, arg := range r.Args {\r\n\t\t\tif redactor, ok := arg.(Redactor); ok == true {\r\n\t\t\t\tr.Args[i] = redactor.Redacted()\r\n\t\t\t}\r\n\t\t}\r\n\t\tvar buf bytes.Buffer\r\n\t\tif r.fmt != nil {\r\n\t\t\tfmt.Fprintf(&buf, *r.fmt, r.Args...)\r\n\t\t} else {\r\n\t\t\t\r\n\t\t\tfmt.Fprintln(&buf, r.Args...)\r\n\t\t\tbuf.Truncate(buf.Len() - 1)\r\n\t\t}\r\n\t\tmsg := buf.String()\r\n\t\tr.message = &msg\r\n\t}\r\n\treturn *r.message\r\n}","code-length":215,"reference":"\/\/ Message returns the log record message.","result":"Generate the message.","score":[0.128,0.1515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *Logger) SetBackend(backend LeveledBackend) {\r\n\tl.backend = backend\r\n\tl.haveBackend = true\r\n}","code-length":44,"reference":"\/\/ SetBackend overrides any previously defined backend for this logger.","result":"Set the backend of the logger.","score":[0.1179,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MustGetLogger(module string) *Logger {\r\n\tlogger, err := GetLogger(module)\r\n\tif err != nil {\r\n\t\tpanic(\"logger: \" + module + \": \" + err.Error())\r\n\t}\r\n\treturn logger\r\n}","code-length":72,"reference":"\/\/ MustGetLogger is like GetLogger but panics if the logger can't be created.\n\/\/ It simplifies safe initialization of a global logger for eg. a package.","result":"Check if the module is not registered.","score":[0.0167,0.106]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Reset() {\r\n\t\r\n\t\r\n\t\r\n\tsequenceNo = 0\r\n\tb := SetBackend(NewLogBackend(os.Stderr, \"\", log.LstdFlags))\r\n\tb.SetLevel(DEBUG, \"\")\r\n\tSetFormatter(DefaultFormatter)\r\n\ttimeNow = time.Now\r\n}","code-length":85,"reference":"\/\/ Reset restores the internal state of the logging library.","result":"Reset the sequenceNo.","score":[0.0471,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *Logger) IsEnabledFor(level Level) bool {\r\n\treturn defaultBackend.IsEnabledFor(level, l.Module)\r\n}","code-length":44,"reference":"\/\/ IsEnabledFor returns true if the logger is enabled for the given level.","result":"Test the log file.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *Logger) Criticalf(format string, args ...interface{}) {\r\n\tl.log(CRITICAL, &format, args...)\r\n}","code-length":46,"reference":"\/\/ Criticalf logs a message using CRITICAL as log level.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *Logger) Warningf(format string, args ...interface{}) {\r\n\tl.log(WARNING, &format, args...)\r\n}","code-length":43,"reference":"\/\/ Warningf logs a message using WARNING as log level.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *Logger) Noticef(format string, args ...interface{}) {\r\n\tl.log(NOTICE, &format, args...)\r\n}","code-length":44,"reference":"\/\/ Noticef logs a message using NOTICE as log level.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *Logger) Infof(format string, args ...interface{}) {\r\n\tl.log(INFO, &format, args...)\r\n}","code-length":43,"reference":"\/\/ Infof logs a message using INFO as log level.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetFormatter(f Formatter) {\r\n\tformatter.Lock()\r\n\tdefer formatter.Unlock()\r\n\tformatter.def = f\r\n}","code-length":43,"reference":"\/\/ SetFormatter sets the default formatter for all new backends. A backend will\n\/\/ fetch this value once it is needed to format a record. Note that backends\n\/\/ will cache the formatter after the first point. For now, make sure to set\n\/\/ the formatter before logging.","result":"Set the default formatter.","score":[0.0,0.0344]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MustStringFormatter(format string) Formatter {\r\n\tf, err := NewStringFormatter(format)\r\n\tif err != nil {\r\n\t\tpanic(\"Failed to initialized string formatter: \" + err.Error())\r\n\t}\r\n\treturn f\r\n}","code-length":70,"reference":"\/\/ MustStringFormatter is equivalent to NewStringFormatter with a call to panic\n\/\/ on error.","result":"Initialize the string formatter.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc formatFuncName(v fmtVerb, f string) string {\r\n\ti := strings.LastIndex(f, \"\/\")\r\n\tj := strings.Index(f[i+1:], \".\")\r\n\tif j < 1 {\r\n\t\treturn \"???\"\r\n\t}\r\n\tpkg, fun := f[:i+j+1], f[i+j+2:]\r\n\tswitch v {\r\n\tcase fmtVerbLongpkg:\r\n\t\treturn pkg\r\n\tcase fmtVerbShortpkg:\r\n\t\treturn path.Base(pkg)\r\n\tcase fmtVerbLongfunc:\r\n\t\treturn fun\r\n\tcase fmtVerbShortfunc:\r\n\t\ti = strings.LastIndex(fun, \".\")\r\n\t\treturn fun[i+1:]\r\n\t}\r\n\tpanic(\"unexpected func formatter\")\r\n}","code-length":206,"reference":"\/\/ formatFuncName tries to extract certain part of the runtime formatted\n\/\/ function name to some pre-defined variation.\n\/\/\n\/\/ This function is known to not work properly if the package path or name\n\/\/ contains a dot.","result":"Format function names.","score":[0.0,0.029]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (bf *backendFormatter) Log(level Level, calldepth int, r *Record) error {\r\n\t\r\n\tr2 := *r\r\n\tr2.formatter = bf.f\r\n\treturn bf.b.Log(level, calldepth+1, &r2)\r\n}","code-length":77,"reference":"\/\/ Log implements the Log function required by the Backend interface.","result":"Format backend logs.","score":[0,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LogLevel(level string) (Level, error) {\r\n\tfor i, name := range levelNames {\r\n\t\tif strings.EqualFold(name, level) {\r\n\t\t\treturn Level(i), nil\r\n\t\t}\r\n\t}\r\n\treturn ERROR, ErrInvalidLogLevel\r\n}","code-length":78,"reference":"\/\/ LogLevel returns the log level from a string representation.","result":"Generate the log file.","score":[0.1008,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AddModuleLevel(backend Backend) LeveledBackend {\r\n\tvar leveled LeveledBackend\r\n\tvar ok bool\r\n\tif leveled, ok = backend.(LeveledBackend); !ok {\r\n\t\tleveled = &moduleLeveled{\r\n\t\t\tlevels:  make(map[string]Level),\r\n\t\t\tbackend: backend,\r\n\t\t}\r\n\t}\r\n\treturn leveled\r\n}","code-length":108,"reference":"\/\/ AddModuleLevel wraps a log backend with knobs to have different log levels\n\/\/ for different modules.","result":"Add a module level.","score":[0.0124,0.0318]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *moduleLeveled) GetLevel(module string) Level {\r\n\tlevel, exists := l.levels[module]\r\n\tif exists == false {\r\n\t\tlevel, exists = l.levels[\"\"]\r\n\t\t\r\n\t\tif exists == false {\r\n\t\t\tlevel = DEBUG\r\n\t\t}\r\n\t}\r\n\treturn level\r\n}","code-length":96,"reference":"\/\/ GetLevel returns the log level for the given module.","result":"Get the level of a module.","score":[0.1304,0.1562]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *moduleLeveled) SetLevel(level Level, module string) {\r\n\tl.levels[module] = level\r\n}","code-length":41,"reference":"\/\/ SetLevel sets the log level for the given module.","result":"Set the level of the module.","score":[0.1402,0.3875]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *moduleLeveled) IsEnabledFor(level Level, module string) bool {\r\n\treturn level <= l.GetLevel(module)\r\n}","code-length":45,"reference":"\/\/ IsEnabledFor will return true if logging is enabled for the given module.","result":"Generate the generated code.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MultiLogger(backends ...Backend) LeveledBackend {\r\n\tvar leveledBackends []LeveledBackend\r\n\tfor _, backend := range backends {\r\n\t\tleveledBackends = append(leveledBackends, AddModuleLevel(backend))\r\n\t}\r\n\treturn &multiLogger{leveledBackends}\r\n}","code-length":87,"reference":"\/\/ MultiLogger creates a logger which contain multiple loggers.","result":"Create a logger.","score":[0.0553,0.2232]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *multiLogger) Log(level Level, calldepth int, rec *Record) (err error) {\r\n\tfor _, backend := range b.backends {\r\n\t\tif backend.IsEnabledFor(level, rec.Module) {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tr2 := *rec\r\n\t\t\tif e := backend.Log(level, calldepth+1, &r2); e != nil {\r\n\t\t\t\terr = e\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn\r\n}","code-length":135,"reference":"\/\/ Log passes the log record to all backends.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *multiLogger) GetLevel(module string) Level {\r\n\tvar level Level\r\n\tfor _, backend := range b.backends {\r\n\t\tif backendLevel := backend.GetLevel(module); backendLevel > level {\r\n\t\t\tlevel = backendLevel\r\n\t\t}\r\n\t}\r\n\treturn level\r\n}","code-length":89,"reference":"\/\/ GetLevel returns the highest level enabled by all backends.","result":"Get the level of the module.","score":[0.1179,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *multiLogger) SetLevel(level Level, module string) {\r\n\tfor _, backend := range b.backends {\r\n\t\tbackend.SetLevel(level, module)\r\n\t}\r\n}","code-length":60,"reference":"\/\/ SetLevel propagates the same level to all backends.","result":"Set the level of the logger.","score":[0.1392,0.1149]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *multiLogger) IsEnabledFor(level Level, module string) bool {\r\n\tfor _, backend := range b.backends {\r\n\t\tif backend.IsEnabledFor(level, module) {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":81,"reference":"\/\/ IsEnabledFor returns true if any of the backends are enabled for it.","result":"Check if a logger is enabled for a specific module.","score":[0.1259,0.2012]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ConvertColors(colors []int, bold bool) []string {\r\n\tconverted := []string{}\r\n\tfor _, i := range colors {\r\n\t\tif bold {\r\n\t\t\tconverted = append(converted, ColorSeqBold(color(i)))\r\n\t\t} else {\r\n\t\t\tconverted = append(converted, ColorSeq(color(i)))\r\n\t\t}\r\n\t}\r\n\treturn converted\r\n}","code-length":114,"reference":"\/\/ ConvertColors takes a list of ints representing colors for log levels and\n\/\/ converts them into strings for ANSI color formatting","result":"Convert colors to strings.","score":[0.0035,0.0495]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSyslogBackend(prefix string) (b *SyslogBackend, err error) {\r\n\tvar w *syslog.Writer\r\n\tw, err = syslog.New(syslog.LOG_CRIT, prefix)\r\n\treturn &SyslogBackend{w}, err\r\n}","code-length":75,"reference":"\/\/ NewSyslogBackend connects to the syslog daemon using UNIX sockets with the\n\/\/ given prefix. If prefix is not given, the prefix will be derived from the\n\/\/ launched command.","result":"Create a new syslog backend.","score":[0.0016,0.0182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSyslogBackendPriority(prefix string, priority syslog.Priority) (b *SyslogBackend, err error) {\r\n\tvar w *syslog.Writer\r\n\tw, err = syslog.New(priority, prefix)\r\n\treturn &SyslogBackend{w}, err\r\n}","code-length":75,"reference":"\/\/ NewSyslogBackendPriority is the same as NewSyslogBackend, but with custom\n\/\/ syslog priority, like syslog.LOG_LOCAL3|syslog.LOG_DEBUG etc.","result":"Create a syslog backend.","score":[0.0159,0.0338]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetBackend(backends ...Backend) LeveledBackend {\r\n\tvar backend Backend\r\n\tif len(backends) == 1 {\r\n\t\tbackend = backends[0]\r\n\t} else {\r\n\t\tbackend = MultiLogger(backends...)\r\n\t}\r\n\tdefaultBackend = AddModuleLevel(backend)\r\n\treturn defaultBackend\r\n}","code-length":93,"reference":"\/\/ SetBackend replaces the backend currently set with the given new logging\n\/\/ backend.","result":"Set the default backend.","score":[0.0312,0.1154]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCommander(topLevelFlags *flag.FlagSet, name string) *Commander {\r\n\tcdr := &Commander{\r\n\t\ttopFlags: topLevelFlags,\r\n\t\tname:     name,\r\n\t\tOutput:   os.Stdout,\r\n\t\tError:    os.Stderr,\r\n\t}\r\n\ttopLevelFlags.Usage = func() { cdr.explain(cdr.Error) }\r\n\treturn cdr\r\n}","code-length":118,"reference":"\/\/ NewCommander returns a new commander with the specified top-level\n\/\/ flags and command name. The Usage function for the topLevelFlags\n\/\/ will be set as well.","result":"Create a new command.","score":[0.0014,0.0759]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cdr *Commander) Execute(ctx context.Context, args ...interface{}) ExitStatus {\r\n\tif cdr.topFlags.NArg() < 1 {\r\n\t\tcdr.topFlags.Usage()\r\n\t\treturn ExitUsageError\r\n\t}\r\n\tname := cdr.topFlags.Arg(0)\r\n\tfor _, group := range cdr.commands {\r\n\t\tfor _, cmd := range group.commands {\r\n\t\t\tif name != cmd.Name() {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tf := flag.NewFlagSet(name, flag.ContinueOnError)\r\n\t\t\tf.Usage = func() { explain(cdr.Error, cmd) }\r\n\t\t\tcmd.SetFlags(f)\r\n\t\t\tif f.Parse(cdr.topFlags.Args()[1:]) != nil {\r\n\t\t\t\treturn ExitUsageError\r\n\t\t\t}\r\n\t\t\treturn cmd.Execute(ctx, f, args...)\r\n\t\t}\r\n\t}\r\n\t\r\n\tcdr.topFlags.Usage()\r\n\treturn ExitUsageError\r\n}","code-length":272,"reference":"\/\/ Execute should be called once the top-level-flags on a Commander\n\/\/ have been initialized. It finds the correct subcommand and executes\n\/\/ it, and returns an ExitStatus with the result. On a usage error, an\n\/\/ appropriate message is printed to os.Stderr, and ExitUsageError is\n\/\/ returned. The additional args are provided as-is to the Execute method\n\/\/ of the selected Command.","result":"Execute the command.","score":[0.0,0.0263]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cdr *Commander) explain(w io.Writer) {\r\n\tfmt.Fprintf(w, \"Usage: %s <flags> <subcommand> <subcommand args>\\n\\n\", cdr.name)\r\n\tsort.Sort(byGroupName(cdr.commands))\r\n\tfor _, group := range cdr.commands {\r\n\t\texplainGroup(w, group)\r\n\t}\r\n\tif cdr.topFlags == nil {\r\n\t\tfmt.Fprintln(w, \"\\nNo top level flags.\")\r\n\t\treturn\r\n\t}\r\n\tif len(cdr.important) == 0 {\r\n\t\tfmt.Fprintf(w, \"\\nUse \\\"%s flags\\\" for a list of top-level flags\\n\", cdr.name)\r\n\t\treturn\r\n\t}\r\n\tfmt.Fprintf(w, \"\\nTop-level flags (use \\\"%s flags\\\" for a full list):\\n\", cdr.name)\r\n\tfor _, name := range cdr.important {\r\n\t\tf := cdr.topFlags.Lookup(name)\r\n\t\tif f == nil {\r\n\t\t\tpanic(fmt.Sprintf(\"Important flag (%s) is not defined\", name))\r\n\t\t}\r\n\t\tfmt.Fprintf(w, \"  -%s=%s: %s\\n\", f.Name, f.DefValue, f.Usage)\r\n\t}\r\n}","code-length":350,"reference":"\/\/ explain prints a brief description of all the subcommands and the\n\/\/ important top-level flags.","result":"Generate the help text.","score":[0.0159,0.0338]}
{"code":"\/*is used to<extra_id_0>\r\nfunc explainGroup(w io.Writer, group *commandGroup) {\r\n\tif len(group.commands) == 0 {\r\n\t\treturn\r\n\t}\r\n\tif group.name == \"\" {\r\n\t\tfmt.Fprintf(w, \"Subcommands:\\n\")\r\n\t} else {\r\n\t\tfmt.Fprintf(w, \"Subcommands for %s:\\n\", group.name)\r\n\t}\r\n\tsort.Sort(group)\r\n\taliases := make(map[string][]string)\r\n\tfor _, cmd := range group.commands {\r\n\t\tif alias, ok := cmd.(*aliaser); ok {\r\n\t\t\troot := dealias(alias).Name()\r\n\t\t\tif _, ok := aliases[root]; !ok {\r\n\t\t\t\taliases[root] = []string{}\r\n\t\t\t}\r\n\t\t\taliases[root] = append(aliases[root], alias.Name())\r\n\t\t}\r\n\t}\r\n\tfor _, cmd := range group.commands {\r\n\t\tif _, ok := cmd.(*aliaser); ok {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tname := cmd.Name()\r\n\t\tnames := []string{name}\r\n\t\tif a, ok := aliases[name]; ok {\r\n\t\t\tnames = append(names, a...)\r\n\t\t}\r\n\t\tfmt.Fprintf(w, \"\\t%-15s  %s\\n\", strings.Join(names, \", \"), cmd.Synopsis())\r\n\t}\r\n\tfmt.Fprintln(w)\r\n}","code-length":381,"reference":"\/\/ explainGroup explains all the subcommands for a particular group.","result":"Explain the group of commands.","score":[0.0884,0.1053]}
{"code":"\/*is used to<extra_id_0>\r\nfunc explain(w io.Writer, cmd Command) {\r\n\tfmt.Fprintf(w, \"%s\", cmd.Usage())\r\n\tsubflags := flag.NewFlagSet(cmd.Name(), flag.PanicOnError)\r\n\tsubflags.SetOutput(w)\r\n\tcmd.SetFlags(subflags)\r\n\tsubflags.PrintDefaults()\r\n}","code-length":93,"reference":"\/\/ explainCmd prints a brief description of a single command.","result":"Explain the command.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc dealias(cmd Command) Command {\r\n\tif alias, ok := cmd.(*aliaser); ok {\r\n\t\treturn dealias(alias.Command)\r\n\t}\r\n\treturn cmd\r\n}","code-length":58,"reference":"\/\/ dealias recursivly dealiases a command until a non-aliased command\n\/\/ is reached.","result":"Remove aliases.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Execute(ctx context.Context, args ...interface{}) ExitStatus {\r\n\treturn DefaultCommander.Execute(ctx, args...)\r\n}","code-length":42,"reference":"\/\/ Execute should be called once the default flags have been\n\/\/ initialized by flag.Parse. It finds the correct subcommand and\n\/\/ executes it, and returns an ExitStatus with the result. On a usage\n\/\/ error, an appropriate message is printed to os.Stderr, and\n\/\/ ExitUsageError is returned. The additional args are provided as-is\n\/\/ to the Execute method of the selected Command. It is a wrapper\n\/\/ around DefaultCommander.Execute.","result":"Execute commands.","score":[8.57e-16,0.0079]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadFromData(data []byte) (c *ConfigFile, err error) {\r\n\t\r\n\ttmpName := path.Join(os.TempDir(), \"goconfig\", fmt.Sprintf(\"%d\", time.Now().Nanosecond()))\r\n\tif err = os.MkdirAll(path.Dir(tmpName), os.ModePerm); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err = ioutil.WriteFile(tmpName, data, 0655); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tc = newConfigFile([]string{tmpName})\r\n\terr = c.read(bytes.NewBuffer(data))\r\n\treturn c, err\r\n}","code-length":181,"reference":"\/\/ LoadFromData accepts raw data directly from memory\n\/\/ and returns a new configuration representation.\n\/\/ Note that the configuration is written to the system\n\/\/ temporary folder, so your file should not contain\n\/\/ sensitive information.","result":"Load the config file from data.","score":[0.0014,0.0442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadFromReader(in io.Reader) (c *ConfigFile, err error) {\r\n\tc = newConfigFile([]string{\"\"})\r\n\terr = c.read(in)\r\n\treturn c, err\r\n}","code-length":62,"reference":"\/\/ LoadFromReader accepts raw data directly from a reader\n\/\/ and returns a new configuration representation.\n\/\/ You must use ReloadData to reload.\n\/\/ You cannot append files a configfile read this way.","result":"Load the config file from a reader.","score":[0.0056,0.0493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ConfigFile) ReloadData(in io.Reader) (err error) {\r\n\tvar cfg *ConfigFile\r\n\tif len(c.fileNames) != 1 {\r\n\t\treturn fmt.Errorf(\"Multiple files loaded, unable to mix in-memory and file data\")\r\n\t}\r\n\tcfg, err = LoadFromReader(in)\r\n\tif err == nil {\r\n\t\t*c = *cfg\r\n\t}\r\n\treturn err\r\n}","code-length":118,"reference":"\/\/ ReloadData reloads configuration file from memory","result":"Reload data.","score":[0,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ConfigFile) AppendFiles(files ...string) error {\r\n\tif len(c.fileNames) == 1 && c.fileNames[0] == \"\" {\r\n\t\treturn fmt.Errorf(\"Cannot append file data to in-memory data\")\r\n\t}\r\n\tc.fileNames = append(c.fileNames, files...)\r\n\treturn c.Reload()\r\n}","code-length":99,"reference":"\/\/ AppendFiles appends more files to ConfigFile and reload automatically.","result":"Append files to the config file.","score":[0.1402,0.2662]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ConfigFile) GetKeyList(section string) []string {\r\n\t\r\n\tif len(section) == 0 {\r\n\t\tsection = DEFAULT_SECTION\r\n\t}\r\n\tif c.BlockMode {\r\n\t\tc.lock.RLock()\r\n\t\tdefer c.lock.RUnlock()\r\n\t}\r\n\t\r\n\tif _, ok := c.data[section]; !ok {\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\tlist := make([]string, 0, len(c.keyList[section]))\r\n\tfor _, key := range c.keyList[section] {\r\n\t\tif key != \" \" {\r\n\t\t\tlist = append(list, key)\r\n\t\t}\r\n\t}\r\n\treturn list\r\n}","code-length":197,"reference":"\/\/ GetKeyList returns the list of all keys in give section\n\/\/ in the same order in the file.\n\/\/ It returns nil if given section does not exist.","result":"Generate code for the generated code.","score":[0.0042,0.0187]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SaveConfigData(c *ConfigFile, out io.Writer) (err error) {\r\n\tequalSign := \"=\"\r\n\tif PrettyFormat {\r\n\t\tequalSign = \" = \"\r\n\t}\r\n\tbuf := bytes.NewBuffer(nil)\r\n\tfor _, section := range c.sectionList {\r\n\t\t\r\n\t\tif len(c.GetSectionComments(section)) > 0 {\r\n\t\t\tif _, err = buf.WriteString(c.GetSectionComments(section) + LineBreak); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\tif section != DEFAULT_SECTION {\r\n\t\t\t\r\n\t\t\tif _, err = buf.WriteString(\"[\" + section + \"]\" + LineBreak); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\tfor _, key := range c.keyList[section] {\r\n\t\t\tif key != \" \" {\r\n\t\t\t\t\r\n\t\t\t\tif len(c.GetKeyComments(section, key)) > 0 {\r\n\t\t\t\t\tif _, err = buf.WriteString(c.GetKeyComments(section, key) + LineBreak); err != nil {\r\n\t\t\t\t\t\treturn err\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t\tkeyName := key\r\n\t\t\t\t\r\n\t\t\t\tif keyName[0] == '#' {\r\n\t\t\t\t\tkeyName = \"-\"\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\tif strings.Contains(keyName, `=`) || strings.Contains(keyName, `:`) {\r\n\t\t\t\t\tif strings.Contains(keyName, \"`\") {\r\n\t\t\t\t\t\tif strings.Contains(keyName, `\"`) {\r\n\t\t\t\t\t\t\tkeyName = `\"\"\"` + keyName + `\"\"\"`\r\n\t\t\t\t\t\t} else {\r\n\t\t\t\t\t\t\tkeyName = `\"` + keyName + `\"`\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t} else {\r\n\t\t\t\t\t\tkeyName = \"`\" + keyName + \"`\"\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t\tvalue := c.data[section][key]\r\n\t\t\t\t\r\n\t\t\t\tif strings.Contains(value, \"`\") {\r\n\t\t\t\t\tif strings.Contains(value, `\"`) {\r\n\t\t\t\t\t\tvalue = `\"\"\"` + value + `\"\"\"`\r\n\t\t\t\t\t} else {\r\n\t\t\t\t\t\tvalue = `\"` + value + `\"`\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\tif _, err = buf.WriteString(keyName + equalSign + value + LineBreak); err != nil {\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tif _, err = buf.WriteString(LineBreak); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tif _, err := buf.WriteTo(out); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":697,"reference":"\/\/ SaveConfigData writes configuration to a writer","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SaveConfigFile(c *ConfigFile, filename string) (err error) {\r\n\t\r\n\tvar f *os.File\r\n\tif f, err = os.Create(filename); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := SaveConfigData(c, f); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn f.Close()\r\n}","code-length":104,"reference":"\/\/ SaveConfigFile writes configuration file to local file system","result":"Save config files.","score":[0,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *selectable) Find(selector string) *Selection {\r\n\treturn newSelection(s.session, s.selectors.Append(target.CSS, selector).Single())\r\n}","code-length":52,"reference":"\/\/ Find finds exactly one element by CSS selector.","result":"Find the first occurrence of a selector.","score":[0.1443,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *selectable) FindByXPath(selector string) *Selection {\r\n\treturn newSelection(s.session, s.selectors.Append(target.XPath, selector).Single())\r\n}","code-length":54,"reference":"\/\/ FindByXPath finds exactly one element by XPath selector.","result":"Find the closest match in the xpath.","score":[0,0.0568]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *selectable) FindByLink(text string) *Selection {\r\n\treturn newSelection(s.session, s.selectors.Append(target.Link, text).Single())\r\n}","code-length":54,"reference":"\/\/ FindByLink finds exactly one anchor element by its text content.","result":"Find the link in a selectable.","score":[0,0.0476]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *selectable) FindByLabel(text string) *Selection {\r\n\treturn newSelection(s.session, s.selectors.Append(target.Label, text).Single())\r\n}","code-length":54,"reference":"\/\/ FindByLabel finds exactly one element by associated label text.","result":"Find the label in a selectable.","score":[0.0991,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *selectable) FindByName(name string) *Selection {\r\n\treturn newSelection(s.session, s.selectors.Append(target.Name, name).Single())\r\n}","code-length":53,"reference":"\/\/ FindByName finds exactly element with the provided name attribute.","result":"Find a selection by name.","score":[0,0.0526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *selectable) FindByClass(text string) *Selection {\r\n\treturn newSelection(s.session, s.selectors.Append(target.Class, text).Single())\r\n}","code-length":53,"reference":"\/\/ FindByClass finds exactly one element with a given CSS class.","result":"Find the first occurrence of a class.","score":[0.1085,0.1415]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *selectable) FindByID(id string) *Selection {\r\n\treturn newSelection(s.session, s.selectors.Append(target.ID, id).Single())\r\n}","code-length":53,"reference":"\/\/ FindByID finds exactly one element that has the given ID.","result":"Find a single item in a selectable.","score":[0,0.0472]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *selectable) First(selector string) *Selection {\r\n\treturn newSelection(s.session, s.selectors.Append(target.CSS, selector).At(0))\r\n}","code-length":54,"reference":"\/\/ First finds the first element by CSS selector.","result":"Select the first element in the selectable.","score":[0.25,0.2904]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *selectable) FirstByXPath(selector string) *Selection {\r\n\treturn newSelection(s.session, s.selectors.Append(target.XPath, selector).At(0))\r\n}","code-length":56,"reference":"\/\/ FirstByXPath finds the first element by XPath selector.","result":"Find the first element by XPath.","score":[0.3665,0.5724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *selectable) FirstByLink(text string) *Selection {\r\n\treturn newSelection(s.session, s.selectors.Append(target.Link, text).At(0))\r\n}","code-length":56,"reference":"\/\/ FirstByLink finds the first anchor element by its text content.","result":"Detect the first by link.","score":[0.1133,0.3606]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *selectable) FirstByLabel(text string) *Selection {\r\n\treturn newSelection(s.session, s.selectors.Append(target.Label, text).At(0))\r\n}","code-length":56,"reference":"\/\/ FirstByLabel finds the first element by associated label text.","result":"Create the first by label function.","score":[0.1667,0.3288]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *selectable) FirstByName(name string) *Selection {\r\n\treturn newSelection(s.session, s.selectors.Append(target.Name, name).At(0))\r\n}","code-length":55,"reference":"\/\/ FirstByName finds the first element with the provided name attribute.","result":"Check if the first element is selected.","score":[0.1879,0.2411]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *selectable) All(selector string) *MultiSelection {\r\n\treturn newMultiSelection(s.session, s.selectors.Append(target.CSS, selector))\r\n}","code-length":52,"reference":"\/\/ All finds zero or more elements by CSS selector.","result":"Create a new multi selection.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *selectable) AllByXPath(selector string) *MultiSelection {\r\n\treturn newMultiSelection(s.session, s.selectors.Append(target.XPath, selector))\r\n}","code-length":54,"reference":"\/\/ AllByXPath finds zero or more elements by XPath selector.","result":"Select all by xpath.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *selectable) AllByLink(text string) *MultiSelection {\r\n\treturn newMultiSelection(s.session, s.selectors.Append(target.Link, text))\r\n}","code-length":54,"reference":"\/\/ AllByLink finds zero or more anchor elements by their text content.","result":"Create a new selectable.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *selectable) AllByLabel(text string) *MultiSelection {\r\n\treturn newMultiSelection(s.session, s.selectors.Append(target.Label, text))\r\n}","code-length":54,"reference":"\/\/ AllByLabel finds zero or more elements by associated label text.","result":"Select all by label .","score":[0.0861,0.0962]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *selectable) AllByName(name string) *MultiSelection {\r\n\treturn newMultiSelection(s.session, s.selectors.Append(target.Name, name))\r\n}","code-length":53,"reference":"\/\/ AllByName finds zero or more elements with the provided name attribute.","result":"Select all by name.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *selectable) AllByClass(text string) *MultiSelection {\r\n\treturn newMultiSelection(s.session, s.selectors.Append(target.Class, text))\r\n}","code-length":53,"reference":"\/\/ AllByClass finds zero or more elements with a given CSS class.","result":"Select all classes in a selectable.","score":[0.071,0.0439]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *selectable) AllByID(text string) *MultiSelection {\r\n\treturn newMultiSelection(s.session, s.selectors.Append(target.ID, text))\r\n}","code-length":53,"reference":"\/\/ AllByID finds zero or more elements with a given ID.","result":"Select all by ID.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *selectable) FindForAppium(selectorType string, text string) *Selection {\r\n\treturn newSelection(s.session, s.selectors.Append(target.Class, text).At(0))\r\n}","code-length":61,"reference":"\/\/ FirstByClass finds the first element with a given CSS class.","result":"Find the element in the appium application.","score":[0.1085,0.1415]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Timeout(seconds int) Option {\r\n\treturn func(c *config) {\r\n\t\tc.Timeout = time.Duration(seconds) * time.Second\r\n\t}\r\n}","code-length":53,"reference":"\/\/ Timeout provides an Option for specifying a timeout in seconds.","result":"Set the default timeout.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ChromeOptions(opt string, value interface{}) Option {\r\n\treturn func(c *config) {\r\n\t\tif c.ChromeOptions == nil {\r\n\t\t\tc.ChromeOptions = make(map[string]interface{})\r\n\t\t}\r\n\t\tc.ChromeOptions[opt] = value\r\n\t}\r\n}","code-length":88,"reference":"\/\/ ChromeOptions is used to pass additional options to Chrome via ChromeDriver.","result":"Set the value of the option.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc JoinPage(url string, options ...Option) *Page {\r\n\tpageOptions := config{}.Merge(options)\r\n\tsession := api.NewWithClient(url, pageOptions.HTTPClient)\r\n\treturn newPage(session)\r\n}","code-length":65,"reference":"\/\/ JoinPage creates a Page using existing session URL. This method takes Options\n\/\/ but respects only the HTTPClient Option if provided.","result":"Join pages.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) Destroy() error {\r\n\tif err := p.session.Delete(); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to destroy session: %s\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":66,"reference":"\/\/ Destroy closes any open browsers by ending the session.","result":"Destroy the page.","score":[0.0471,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) Reset() error {\r\n\tp.ConfirmPopup()\r\n\turl, err := p.URL()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif url == \"about:blank\" {\r\n\t\treturn nil\r\n\t}\r\n\tif err := p.ClearCookies(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := p.session.DeleteLocalStorage(); err != nil {\r\n\t\tif err := p.RunScript(\"localStorage.clear();\", nil, nil); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tif err := p.session.DeleteSessionStorage(); err != nil {\r\n\t\tif err := p.RunScript(\"sessionStorage.clear();\", nil, nil); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn p.Navigate(\"about:blank\")\r\n}","code-length":237,"reference":"\/\/ Reset deletes all cookies set for the current domain and navigates to a blank page.\n\/\/ Unlike Destroy, Reset will permit the page to be re-used after it is called.\n\/\/ Reset is faster than Destroy, but any cookies from domains outside the current\n\/\/ domain will remain after a page is reset.","result":"Avoid the need for the function to be executed.","score":[0.0016,0.0752]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) Navigate(url string) error {\r\n\tif err := p.session.SetURL(url); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to navigate: %s\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":72,"reference":"\/\/ Navigate navigates to the provided URL.","result":"Navigate to a specific URL.","score":[0.212,0.2206]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) GetCookies() ([]*http.Cookie, error) {\r\n\tapiCookies, err := p.session.GetCookies()\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to get cookies: %s\", err)\r\n\t}\r\n\tcookies := []*http.Cookie{}\r\n\tfor _, apiCookie := range apiCookies {\r\n\t\texpSeconds := int64(apiCookie.Expiry)\r\n\t\texpNano := int64(apiCookie.Expiry-float64(expSeconds)) * 1000000000\r\n\t\tcookie := &http.Cookie{\r\n\t\t\tName:     apiCookie.Name,\r\n\t\t\tValue:    apiCookie.Value,\r\n\t\t\tPath:     apiCookie.Path,\r\n\t\t\tDomain:   apiCookie.Domain,\r\n\t\t\tSecure:   apiCookie.Secure,\r\n\t\t\tHttpOnly: apiCookie.HTTPOnly,\r\n\t\t\tExpires:  time.Unix(expSeconds, expNano),\r\n\t\t}\r\n\t\tcookies = append(cookies, cookie)\r\n\t}\r\n\treturn cookies, nil\r\n}","code-length":270,"reference":"\/\/ GetCookies returns all cookies on the page.","result":"Get the cookies from the session.","score":[0.1645,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) SetCookie(cookie *http.Cookie) error {\r\n\tif cookie == nil {\r\n\t\treturn errors.New(\"nil cookie is invalid\")\r\n\t}\r\n\tvar expiry int64\r\n\tif !cookie.Expires.IsZero() {\r\n\t\texpiry = cookie.Expires.Unix()\r\n\t}\r\n\tapiCookie := &api.Cookie{\r\n\t\tName:     cookie.Name,\r\n\t\tValue:    cookie.Value,\r\n\t\tPath:     cookie.Path,\r\n\t\tDomain:   cookie.Domain,\r\n\t\tSecure:   cookie.Secure,\r\n\t\tHTTPOnly: cookie.HttpOnly,\r\n\t\tExpiry:   float64(expiry),\r\n\t}\r\n\tif err := p.session.SetCookie(apiCookie); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to set cookie: %s\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":233,"reference":"\/\/ SetCookie sets a cookie on the page.","result":"Set the cookie in the browser.","score":[0.1645,0.1923]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) DeleteCookie(name string) error {\r\n\tif err := p.session.DeleteCookie(name); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to delete cookie %s: %s\", name, err)\r\n\t}\r\n\treturn nil\r\n}","code-length":77,"reference":"\/\/ DeleteCookie deletes a cookie on the page by name.","result":"Delete cookies.","score":[0,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) ClearCookies() error {\r\n\tif err := p.session.DeleteCookies(); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to clear cookies: %s\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":68,"reference":"\/\/ ClearCookies deletes all cookies on the page.","result":"Clear all cookies.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) URL() (string, error) {\r\n\turl, err := p.session.GetURL()\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"failed to retrieve URL: %s\", err)\r\n\t}\r\n\treturn url, nil\r\n}","code-length":79,"reference":"\/\/ URL returns the current page URL.","result":"Retrieve the URL of the page.","score":[0.1943,0.1449]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) Size(width, height int) error {\r\n\twindow, err := p.session.GetWindow()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to retrieve window: %s\", err)\r\n\t}\r\n\tif err := window.SetSize(width, height); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to set window size: %s\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":120,"reference":"\/\/ Size sets the current page size in pixels.","result":"Set the size of the window.","score":[0.1392,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) Screenshot(filename string) error {\r\n\tabsFilePath, err := filepath.Abs(filename)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to find absolute path for filename: %s\", err)\r\n\t}\r\n\tscreenshot, err := p.session.GetScreenshot()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to retrieve screenshot: %s\", err)\r\n\t}\r\n\tif err := ioutil.WriteFile(absFilePath, screenshot, 0666); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to save screenshot: %s\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":170,"reference":"\/\/ Screenshot takes a screenshot and saves it to the provided filename.\n\/\/ The provided filename may be an absolute or relative path.","result":"Capture the page.","score":[0.0005,0.0238]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) Title() (string, error) {\r\n\ttitle, err := p.session.GetTitle()\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"failed to retrieve page title: %s\", err)\r\n\t}\r\n\treturn title, nil\r\n}","code-length":80,"reference":"\/\/ Title returns the page title.","result":"Generate the title of the page.","score":[0.193,0.1667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) HTML() (string, error) {\r\n\thtml, err := p.session.GetSource()\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"failed to retrieve page HTML: %s\", err)\r\n\t}\r\n\treturn html, nil\r\n}","code-length":80,"reference":"\/\/ HTML returns the current contents of the DOM for the entire page.","result":"Generate the HTML.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) PopupText() (string, error) {\r\n\ttext, err := p.session.GetAlertText()\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"failed to retrieve popup text: %s\", err)\r\n\t}\r\n\treturn text, nil\r\n}","code-length":83,"reference":"\/\/ PopupText returns the current alert, confirm, or prompt popup text.","result":"Get popup text.","score":[0.0401,0.1838]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) EnterPopupText(text string) error {\r\n\tif err := p.session.SetAlertText(text); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to enter popup text: %s\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":76,"reference":"\/\/ EnterPopupText enters text into an open prompt popup.","result":"Prevent the page from being closed.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) ConfirmPopup() error {\r\n\tif err := p.session.AcceptAlert(); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to confirm popup: %s\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":68,"reference":"\/\/ ConfirmPopup confirms an alert, confirm, or prompt popup.","result":"Confirm the popup.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) CancelPopup() error {\r\n\tif err := p.session.DismissAlert(); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to cancel popup: %s\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":69,"reference":"\/\/ CancelPopup cancels an alert, confirm, or prompt popup.","result":"Cancel the popup.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) SwitchToParentFrame() error {\r\n\tif err := p.session.FrameParent(); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to switch to parent frame: %s\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":72,"reference":"\/\/ SwitchToParentFrame focuses on the immediate parent frame of a frame selected\n\/\/ by Selection.Frame. After switching, all new and existing selections will refer\n\/\/ to the parent frame. All further Page methods will apply to this frame as well.\n\/\/\n\/\/ This method is not supported by PhantomJS. Please use SwitchToRootFrame instead.","result":"Switch to parent frame.","score":[0.0,0.0531]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) SwitchToRootFrame() error {\r\n\tif err := p.session.Frame(nil); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to switch to original page frame: %s\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":74,"reference":"\/\/ SwitchToRootFrame focuses on the original, default page frame before any calls\n\/\/ to Selection.Frame were made. After switching, all new and existing selections\n\/\/ will refer to the root frame. All further Page methods will apply to this frame\n\/\/ as well.","result":"Switch to root frame.","score":[0.0,0.0654]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) NextWindow() error {\r\n\twindows, err := p.session.GetWindows()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to find available windows: %s\", err)\r\n\t}\r\n\tvar windowIDs []string\r\n\tfor _, window := range windows {\r\n\t\twindowIDs = append(windowIDs, window.ID)\r\n\t}\r\n\t\r\n\tsort.Strings(windowIDs)\r\n\tactiveWindow, err := p.session.GetWindow()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to find active window: %s\", err)\r\n\t}\r\n\tfor position, windowID := range windowIDs {\r\n\t\tif windowID == activeWindow.ID {\r\n\t\t\tactiveWindow.ID = windowIDs[(position+1)%len(windowIDs)]\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif err := p.session.SetWindow(activeWindow); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to change active window: %s\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":280,"reference":"\/\/ NextWindow switches to the next available window.","result":"Generate code for the next window in the page.","score":[0.1723,0.1235]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) CloseWindow() error {\r\n\tif err := p.session.DeleteWindow(); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to close active window: %s\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":69,"reference":"\/\/ CloseWindow closes the active window.","result":"Close the window.","score":[0.1786,0.4483]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) WindowCount() (int, error) {\r\n\twindows, err := p.session.GetWindows()\r\n\tif err != nil {\r\n\t\treturn 0, fmt.Errorf(\"failed to find available windows: %s\", err)\r\n\t}\r\n\treturn len(windows), nil\r\n}","code-length":84,"reference":"\/\/ WindowCount returns the number of available windows.","result":"Calculate the window count.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) LogTypes() ([]string, error) {\r\n\ttypes, err := p.session.GetLogTypes()\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to retrieve log types: %s\", err)\r\n\t}\r\n\treturn types, nil\r\n}","code-length":84,"reference":"\/\/ LogTypes returns all of the valid log types that may be used with a LogReader.","result":"Retrieve log types.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) MoveMouseBy(xOffset, yOffset int) error {\r\n\tif err := p.session.MoveTo(nil, api.XYOffset{X: xOffset, Y: yOffset}); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to move mouse: %s\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":93,"reference":"\/\/ MoveMouseBy moves the mouse by the provided offset.","result":"Move the mouse.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) DoubleClick() error {\r\n\tif err := p.session.DoubleClick(); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to double click: %s\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":68,"reference":"\/\/ DoubleClick double clicks the left mouse button at the current mouse\n\/\/ position.","result":"Prevent double clicking.","score":[0.0104,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Page) Click(event Click, button Button) error {\r\n\tvar err error\r\n\tswitch event {\r\n\tcase SingleClick:\r\n\t\terr = p.session.Click(api.Button(button))\r\n\tcase HoldClick:\r\n\t\terr = p.session.ButtonDown(api.Button(button))\r\n\tcase ReleaseClick:\r\n\t\terr = p.session.ButtonUp(api.Button(button))\r\n\tdefault:\r\n\t\terr = errors.New(\"invalid touch event\")\r\n\t}\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to %s %s: %s\", event, button, err)\r\n\t}\r\n\treturn nil\r\n}","code-length":183,"reference":"\/\/ Click performs the provided Click event using the provided Button at the\n\/\/ current mouse position.","result":"Trigger the page click event.","score":[0.0218,0.0633]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Selection) Click() error {\r\n\treturn s.forEachElement(func(selectedElement element.Element) error {\r\n\t\tif err := selectedElement.Click(); err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to click on %s: %s\", s, err)\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n}","code-length":96,"reference":"\/\/ Click clicks on all of the elements that the selection refers to.","result":"Click the element in the selection.","score":[0.0791,0.2566]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Selection) DoubleClick() error {\r\n\treturn s.forEachElement(func(selectedElement element.Element) error {\r\n\t\tif err := s.session.MoveTo(selectedElement.(*api.Element), nil); err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to move mouse to %s: %s\", s, err)\r\n\t\t}\r\n\t\tif err := s.session.DoubleClick(); err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to double-click on %s: %s\", s, err)\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n}","code-length":158,"reference":"\/\/ DoubleClick double-clicks on all of the elements that the selection refers to.","result":"Clicking of elements.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Selection) Fill(text string) error {\r\n\treturn s.forEachElement(func(selectedElement element.Element) error {\r\n\t\tif err := selectedElement.Clear(); err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to clear %s: %s\", s, err)\r\n\t\t}\r\n\t\tif err := selectedElement.Value(text); err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to enter text into %s: %s\", s, err)\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n}","code-length":145,"reference":"\/\/ Fill fills all of the fields the selection refers to with the provided text.","result":"Fill the selection.","score":[0.0089,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Selection) Tap(event Tap) error {\r\n\tvar touchFunc func(*api.Element) error\r\n\tswitch event {\r\n\tcase SingleTap:\r\n\t\ttouchFunc = s.session.TouchClick\r\n\tcase DoubleTap:\r\n\t\ttouchFunc = s.session.TouchDoubleClick\r\n\tcase LongTap:\r\n\t\ttouchFunc = s.session.TouchLongClick\r\n\tdefault:\r\n\t\treturn fmt.Errorf(\"failed to %s on %s: invalid tap event\", event, s)\r\n\t}\r\n\treturn s.forEachElement(func(selectedElement element.Element) error {\r\n\t\tif err := touchFunc(selectedElement.(*api.Element)); err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to %s on %s: %s\", event, s, err)\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n}","code-length":225,"reference":"\/\/ Tap performs the provided Tap event on each element in the selection.","result":"Avoid the need for the function to be executed.","score":[0.0929,0.0794]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Selection) Touch(event Touch) error {\r\n\tvar touchFunc func(x, y int) error\r\n\tswitch event {\r\n\tcase HoldFinger:\r\n\t\ttouchFunc = s.session.TouchDown\r\n\tcase ReleaseFinger:\r\n\t\ttouchFunc = s.session.TouchUp\r\n\tcase MoveFinger:\r\n\t\ttouchFunc = s.session.TouchMove\r\n\tdefault:\r\n\t\treturn fmt.Errorf(\"failed to %s on %s: invalid touch event\", event, s)\r\n\t}\r\n\treturn s.forEachElement(func(selectedElement element.Element) error {\r\n\t\tx, y, err := selectedElement.GetLocation()\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to retrieve location of %s: %s\", s, err)\r\n\t\t}\r\n\t\tif err := touchFunc(x, y); err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to flick finger on %s: %s\", s, err)\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n}","code-length":275,"reference":"\/\/ Touch performs the provided Touch event at the location of each element in the\n\/\/ selection.","result":"Prevent flicking finger on elements.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Selection) FlickFinger(xOffset, yOffset int, speed uint) error {\r\n\tselectedElement, err := s.elements.GetExactlyOne()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to select element from %s: %s\", s, err)\r\n\t}\r\n\tif err := s.session.TouchFlick(selectedElement.(*api.Element), api.XYOffset{X: xOffset, Y: yOffset}, api.ScalarSpeed(speed)); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to flick finger on %s: %s\", s, err)\r\n\t}\r\n\treturn nil\r\n}","code-length":170,"reference":"\/\/ FlickFinger performs a flick touch action by the provided offset and at the\n\/\/ provided speed on exactly one element.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Selection) ScrollFinger(xOffset, yOffset int) error {\r\n\tselectedElement, err := s.elements.GetExactlyOne()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to select element from %s: %s\", s, err)\r\n\t}\r\n\tif err := s.session.TouchScroll(selectedElement.(*api.Element), api.XYOffset{X: xOffset, Y: yOffset}); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to scroll finger on %s: %s\", s, err)\r\n\t}\r\n\treturn nil\r\n}","code-length":157,"reference":"\/\/ ScrollFinger performs a scroll touch action by the provided offset on exactly\n\/\/ one element.","result":"Generate code for the generated code.","score":[0.0365,0.0333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCapabilities(features ...string) Capabilities {\r\n\tc := Capabilities{}\r\n\tfor _, feature := range features {\r\n\t\tc.With(feature)\r\n\t}\r\n\treturn c\r\n}","code-length":59,"reference":"\/\/ NewCapabilities returns a Capabilities instance with any provided features enabled.","result":"Create a new Capabilities object.","score":[0.0861,0.0962]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c Capabilities) JSON() (string, error) {\r\n\tcapabilitiesJSON, err := json.Marshal(c)\r\n\treturn string(capabilitiesJSON), err\r\n}","code-length":49,"reference":"\/\/ JSON returns a JSON string representing the desired capabilities.","result":"Generate the JSON file.","score":[0.0848,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HaveTitle(title string) types.GomegaMatcher {\r\n\treturn &internal.ValueMatcher{Method: \"Title\", Property: \"title\", Expected: title}\r\n}","code-length":50,"reference":"\/\/ HaveTitle passes when the expected title is equivalent to the\n\/\/ title of the provided page.","result":"Test the code.","score":[0.0038,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HaveURL(url string) types.GomegaMatcher {\r\n\treturn &internal.ValueMatcher{Method: \"URL\", Property: \"URL\", Expected: url}\r\n}","code-length":50,"reference":"\/\/ HaveURL passes when the expected URL is equivalent to the\n\/\/ current URL of the provided page.","result":"Test the presence of a URL.","score":[0.0311,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HavePopupText(text string) types.GomegaMatcher {\r\n\treturn &internal.ValueMatcher{Method: \"PopupText\", Property: \"popup text\", Expected: text}\r\n}","code-length":53,"reference":"\/\/ HavePopupText passes when the expected text is equivalent to the\n\/\/ text contents of an open alert, confirm, or prompt popup.","result":"Match popup text.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HaveLoggedError(messages ...string) types.GomegaMatcher {\r\n\treturn &internal.LogMatcher{\r\n\t\tExpectedMessages: messages,\r\n\t\tLevels:           []string{\"WARNING\", \"SEVERE\"},\r\n\t\tName:             \"error\",\r\n\t\tType:             \"browser\",\r\n\t}\r\n}","code-length":89,"reference":"\/\/ HaveLoggedError passes when all of the expected log messages are logged as\n\/\/ errors in the browser console. If no message is provided, this matcher will\n\/\/ pass if any error message has been logged. When negated, this matcher will\n\/\/ only fail if all of the provided messages are logged.","result":"Match against the log.","score":[0.0,0.0106]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Selection) Text() (string, error) {\r\n\tselectedElement, err := s.elements.GetExactlyOne()\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"failed to select element from %s: %s\", s, err)\r\n\t}\r\n\ttext, err := selectedElement.GetText()\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"failed to retrieve text for %s: %s\", s, err)\r\n\t}\r\n\treturn text, nil\r\n}","code-length":137,"reference":"\/\/ Text returns the entirety of the text content for exactly one element.","result":"Retrieve the text of the first element in the selection.","score":[0.1497,0.1575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Selection) Active() (bool, error) {\r\n\tselectedElement, err := s.elements.GetExactlyOne()\r\n\tif err != nil {\r\n\t\treturn false, fmt.Errorf(\"failed to select element from %s: %s\", s, err)\r\n\t}\r\n\tactiveElement, err := s.session.GetActiveElement()\r\n\tif err != nil {\r\n\t\treturn false, fmt.Errorf(\"failed to retrieve active element: %s\", err)\r\n\t}\r\n\tequal, err := selectedElement.IsEqualTo(activeElement)\r\n\tif err != nil {\r\n\t\treturn false, fmt.Errorf(\"failed to compare selection to active element: %s\", err)\r\n\t}\r\n\treturn equal, nil\r\n}","code-length":191,"reference":"\/\/ Active returns true if the single element that the selection refers to is active.","result":"Test if the code is executed in a block.","score":[0.0979,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Selection) Attribute(attribute string) (string, error) {\r\n\treturn s.hasProperty(element.Element.GetAttribute, attribute, \"attribute\")\r\n}","code-length":50,"reference":"\/\/ Attribute returns an attribute value for exactly one element.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Selection) CSS(property string) (string, error) {\r\n\treturn s.hasProperty(element.Element.GetCSS, property, \"CSS property\")\r\n}","code-length":51,"reference":"\/\/ CSS returns a CSS style property value for exactly one element.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Selection) Selected() (bool, error) {\r\n\treturn s.hasState(element.Element.IsSelected, \"selected\")\r\n}","code-length":46,"reference":"\/\/ Selected returns true if all of the elements that the selection refers to are selected.","result":"Check if the element.","score":[0.0189,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Selection) Visible() (bool, error) {\r\n\treturn s.hasState(element.Element.IsDisplayed, \"visible\")\r\n}","code-length":46,"reference":"\/\/ Visible returns true if all of the elements that the selection refers to are visible.","result":"Check visibility of elements in the selection.","score":[0.0588,0.1325]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Selection) Enabled() (bool, error) {\r\n\treturn s.hasState(element.Element.IsEnabled, \"enabled\")\r\n}","code-length":45,"reference":"\/\/ Enabled returns true if all of the elements that the selection refers to are enabled.","result":"Check if the selection is enabled.","score":[0.0613,0.2104]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HaveCount(count int) types.GomegaMatcher {\r\n\treturn &internal.ValueMatcher{Method: \"Count\", Property: \"element count\", Expected: count}\r\n}","code-length":51,"reference":"\/\/ HaveCount passes when the expected element count is equal to the actual\n\/\/ number of elements in the selection.","result":"Test the code .","score":[0.0059,0.0272]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HaveAttribute(attribute string, value string) types.GomegaMatcher {\r\n\treturn &internal.HaveAttributeMatcher{ExpectedAttribute: attribute, ExpectedValue: value}\r\n}","code-length":50,"reference":"\/\/ HaveAttribute passes when the expected attribute and value are present on the element.\n\/\/ This matcher will fail if the provided selection refers to more than one element.","result":"Generate the generated code.","score":[0.0006,0.0189]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EdgeDriver(options ...Option) *WebDriver {\r\n\tvar binaryName string\r\n\tif runtime.GOOS == \"windows\" {\r\n\t\tbinaryName = \"MicrosoftWebDriver.exe\"\r\n\t} else {\r\n\t\treturn nil\r\n\t}\r\n\tcommand := []string{binaryName, \"--port={{.Port}}\"}\r\n\t\r\n\t\r\n\treturn NewWebDriver(\"http:\r\n}","code-length":109,"reference":"\/\/ EdgeDriver returns an instance of a EdgeDriver WebDriver.\n\/\/\n\/\/ Provided Options will apply as default arguments for new pages.\n\/\/ New pages will accept invalid SSL certificates by default. This\n\/\/ may be disabled using the RejectInvalidSSL Option.","result":"Connect to the EdgeDriver.","score":[0.0,0.0137]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Selendroid(jarFile string, options ...Option) *WebDriver {\r\n\tabsJARPath, err := filepath.Abs(jarFile)\r\n\tif err != nil {\r\n\t\treturn nil\r\n\t}\r\n\tcommand := []string{\r\n\t\t\"java\",\r\n\t\t\"-jar\", absJARPath,\r\n\t\t\"-port\", \"{{.Port}}\",\r\n\t}\r\n\toptions = append([]Option{Timeout(90), Browser(\"android\")}, options...)\r\n\treturn NewWebDriver(\"http:\r\n}","code-length":140,"reference":"\/\/ Selendroid returns an instance of a Selendroid WebDriver.\n\/\/\n\/\/ Provided Options will apply as default arguments for new pages.\n\/\/ New pages will accept invalid SSL certificates by default. This\n\/\/ may be disabled using the RejectInvalidSSL Option.\n\/\/\n\/\/ The jarFile is a relative or absolute path to Selendroid JAR file.\n\/\/ Selendroid will return nil if an invalid path is provided.","result":"Test the selenium driver.","score":[0.0,0.0085]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Selection) SwitchToFrame() error {\r\n\tselectedElement, err := s.elements.GetExactlyOne()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to select element from %s: %s\", s, err)\r\n\t}\r\n\tif err := s.session.Frame(selectedElement.(*api.Element)); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to switch to frame referred to by %s: %s\", s, err)\r\n\t}\r\n\treturn nil\r\n}","code-length":137,"reference":"\/\/ SwitchToFrame focuses on the frame specified by the selection. All new and\n\/\/ existing selections will refer to the new frame. All further Page methods\n\/\/ will apply to this frame as well.","result":"Generate code for the generated code.","score":[0.0018,0.016]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Selection) Count() (int, error) {\r\n\telements, err := s.elements.Get()\r\n\tif err != nil {\r\n\t\treturn 0, fmt.Errorf(\"failed to select elements from %s: %s\", s, err)\r\n\t}\r\n\treturn len(elements), nil\r\n}","code-length":86,"reference":"\/\/ Count returns the number of elements that the selection refers to.","result":"Count the number of elements in the selection.","score":[0.2918,0.4849]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Selection) EqualsElement(other interface{}) (bool, error) {\r\n\totherSelection, ok := other.(*Selection)\r\n\tif !ok {\r\n\t\tmultiSelection, ok := other.(*MultiSelection)\r\n\t\tif !ok {\r\n\t\t\treturn false, fmt.Errorf(\"must be *Selection or *MultiSelection\")\r\n\t\t}\r\n\t\totherSelection = &multiSelection.Selection\r\n\t}\r\n\tselectedElement, err := s.elements.GetExactlyOne()\r\n\tif err != nil {\r\n\t\treturn false, fmt.Errorf(\"failed to select element from %s: %s\", s, err)\r\n\t}\r\n\totherElement, err := otherSelection.elements.GetExactlyOne()\r\n\tif err != nil {\r\n\t\treturn false, fmt.Errorf(\"failed to select element from %s: %s\", other, err)\r\n\t}\r\n\tequal, err := selectedElement.IsEqualTo(otherElement.(*api.Element))\r\n\tif err != nil {\r\n\t\treturn false, fmt.Errorf(\"failed to compare %s to %s: %s\", s, other, err)\r\n\t}\r\n\treturn equal, nil\r\n}","code-length":296,"reference":"\/\/ EqualsElement returns whether or not two selections of exactly\n\/\/ one element refer to the same element.","result":"Compare two elements in one go.","score":[0.0311,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Selection) MouseToElement() error {\r\n\tselectedElement, err := s.elements.GetExactlyOne()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to select element from %s: %s\", s, err)\r\n\t}\r\n\tif err := s.session.MoveTo(selectedElement.(*api.Element), nil); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to move mouse to element for %s: %s\", s, err)\r\n\t}\r\n\treturn nil\r\n}","code-length":139,"reference":"\/\/ MouseToElement moves the mouse over exactly one element in the selection.","result":"Prevent the selection from being modified.","score":[0.071,0.0439]}
{"code":"\/*is used to<extra_id_0>\r\nfunc loggingMiddleware(next http.Handler) http.Handler {\r\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\r\n\t\tlog.Printf(\"[DEBUG] http reverse proxy received connection from %s on path %s\\n\", r.RemoteAddr, r.RequestURI)\r\n\t\tnext.ServeHTTP(w, r)\r\n\t})\r\n}","code-length":102,"reference":"\/\/ loggingMiddleware logs requests to the proxy","result":"Log requests.","score":[0,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc chainHandlers(mw ...Middleware) Middleware {\r\n\treturn func(final http.Handler) http.Handler {\r\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\r\n\t\t\tlast := final\r\n\t\t\tfor i := len(mw) - 1; i >= 0; i-- {\r\n\t\t\t\tlast = mw[i](last)\r\n\t\t\t}\r\n\t\t\tlast.ServeHTTP(w, r)\r\n\t\t})\r\n\t}\r\n}","code-length":131,"reference":"\/\/ chainHandlers takes a set of middleware and joins them together\n\/\/ into a single Middleware, making it much simpler to compose middleware\n\/\/ together","result":"Chain handlers in a chain.","score":[0.0044,0.0217]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HTTPReverseProxy(options Options) (int, error) {\r\n\tport := options.ProxyPort\r\n\tvar err error\r\n\tproxy := httputil.NewSingleHostReverseProxy(&url.URL{\r\n\t\tScheme: options.TargetScheme,\r\n\t\tHost:   options.TargetAddress,\r\n\t})\r\n\tif port == 0 {\r\n\t\tport, err = utils.GetFreePort()\r\n\t\tif err != nil {\r\n\t\t\tlog.Println(\"[ERROR] unable to start reverse proxy server:\", err)\r\n\t\t\treturn 0, err\r\n\t\t}\r\n\t}\r\n\twrapper := chainHandlers(append(options.Middleware, loggingMiddleware)...)\r\n\tlog.Println(\"[DEBUG] starting reverse proxy on port\", port)\r\n\tgo http.ListenAndServe(fmt.Sprintf(\":%d\", port), wrapper(proxy))\r\n\treturn port, nil\r\n}","code-length":225,"reference":"\/\/ HTTPReverseProxy provides a default setup for proxying\n\/\/ internal components within the framework","result":"Start a reverse proxy server.","score":[0.0397,0.0763]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *Installer) CheckInstallation() error {\r\n\tfor binary, versionRange := range versionMap {\r\n\t\tlog.Println(\"[INFO] checking\", binary, \"within range\", versionRange)\r\n\t\tversion, err := i.GetVersionForBinary(binary)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif err = i.CheckVersion(binary, version); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":136,"reference":"\/\/ CheckInstallation checks installation of all of the tools","result":"Check the installation of the package.","score":[0.2028,0.3628]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *Installer) CheckVersion(binary, version string) error {\r\n\tlog.Println(\"[DEBUG] checking version for binary\", binary, \"version\", version)\r\n\tv, err := goversion.NewVersion(version)\r\n\tif err != nil {\r\n\t\tlog.Println(\"[DEBUG] err\", err)\r\n\t\treturn err\r\n\t}\r\n\tversionRange, ok := versionMap[binary]\r\n\tif !ok {\r\n\t\treturn fmt.Errorf(\"unable to find version range for binary %s\", binary)\r\n\t}\r\n\tlog.Println(\"[DEBUG] checking if version\", v, \"within semver range\", versionRange)\r\n\tconstraints, err := goversion.NewConstraint(versionRange)\r\n\tif constraints.Check(v) {\r\n\t\tlog.Println(\"[DEBUG]\", v, \"satisfies constraints\", v, constraints)\r\n\t\treturn nil\r\n\t}\r\n\treturn fmt.Errorf(\"version %s of %s does not match constraint %s\", version, binary, versionRange)\r\n}","code-length":260,"reference":"\/\/ CheckVersion checks installation of a given binary using semver-compatible\n\/\/ comparisions","result":"Check if a version is installed.","score":[0.071,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *Installer) GetVersionForBinary(binary string) (version string, err error) {\r\n\tlog.Println(\"[DEBUG] running binary\", binary)\r\n\tcontent, err := i.commander.Output(binary, \"version\")\r\n\telements := strings.Split(strings.TrimSpace(string(content)), \"\\n\")\r\n\tversion = strings.TrimSpace(elements[len(elements)-1])\r\n\treturn version, err\r\n}","code-length":116,"reference":"\/\/ GetVersionForBinary gets the version of a given Ruby binary","result":"Get the version of the binary.","score":[0.2042,0.3288]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) getUser(id string) (*ex.User, error) {\r\n\tu := fmt.Sprintf(\"%s\/users\/%s\", c.Host, id)\r\n\treq, err := http.NewRequest(\"GET\", u, nil)\r\n\t\r\n\t\r\n\t\r\n\treq.Header.Set(\"Content-Type\", \"application\/json\")\r\n\treq.Header.Set(\"Authorization\", c.token)\r\n\tres, err := http.DefaultClient.Do(req)\r\n\tif res.StatusCode != 200 || err != nil {\r\n\t\treturn nil, fmt.Errorf(\"get user failed\")\r\n\t}\r\n\tdata, err := ioutil.ReadAll(res.Body)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar response ex.User\r\n\terr = json.Unmarshal(data, &response)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &response, err\r\n}","code-length":249,"reference":"\/\/ getUser finds a user","result":"Get the user by id.","score":[0.2403,0.2]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) login(username string, password string) (*ex.User, error) {\r\n\tloginRequest := fmt.Sprintf(`\r\n    {\r\n      \"username\":\"%s\",\r\n      \"password\": \"%s\"\r\n    }`, username, password)\r\n\tres, err := http.Post(fmt.Sprintf(\"%s\/login\/10?foo=anything\", c.Host), \"application\/json; charset=utf-8\", bytes.NewReader([]byte(loginRequest)))\r\n\tif res.StatusCode != 200 || err != nil {\r\n\t\treturn nil, fmt.Errorf(\"login failed\")\r\n\t}\r\n\tdata, err := ioutil.ReadAll(res.Body)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar response loginResponse\r\n\terr = json.Unmarshal(data, &response)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &response.User, err\r\n}","code-length":250,"reference":"\/\/ Login handles the login API call to the User Service.","result":"Login to the ex.","score":[0.0869,0.2481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) loginHandler(w http.ResponseWriter, r *http.Request) {\r\n\tusername := r.FormValue(\"username\")\r\n\tpassword := r.FormValue(\"password\")\r\n\tuser, err := c.login(username, password)\r\n\tif err == nil && user != nil {\r\n\t\tc.user = user\r\n\t\tc.err = nil\r\n\t\thttp.Redirect(w, r, \"\/\", http.StatusFound)\r\n\t\treturn\r\n\t}\r\n\tc.err = fmt.Errorf(\"Invalid username\/password\")\r\n\thttp.Redirect(w, r, \"\/\", http.StatusFound)\r\n\treturn\r\n}","code-length":169,"reference":"\/\/ Deal with the login request.","result":"Login to the server.","score":[0.1938,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) logoutHandler(w http.ResponseWriter, r *http.Request) {\r\n\tc.user = nil\r\n\tc.err = nil\r\n\thttp.Redirect(w, r, \"\/\", http.StatusFound)\r\n\treturn\r\n}","code-length":72,"reference":"\/\/ Deal with the logout request.","result":"Logout the client.","score":[0.1502,0.1754]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) viewHandler(w http.ResponseWriter, r *http.Request) {\r\n\tdata := templateData{\r\n\t\tUser:  c.user,\r\n\t\tError: c.err,\r\n\t}\r\n\trenderTemplate(w, \"login\", data)\r\n}","code-length":79,"reference":"\/\/ Show the current user if logged in, otherwise display a login form.","result":"Handle the view handler.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Run() {\r\n\thttp.HandleFunc(\"\/login\", c.loginHandler)\r\n\thttp.HandleFunc(\"\/logout\", c.logoutHandler)\r\n\thttp.HandleFunc(\"\/\", c.viewHandler)\r\n\tfmt.Println(\"User svc client running on port 8081\")\r\n\thttp.ListenAndServe(\":8081\", nil)\r\n}","code-length":100,"reference":"\/\/ Run the web application.","result":"Run the client.","score":[0.2964,0.3906]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *Interaction) WithRequest(request Request) *Interaction {\r\n\ti.Request = request\r\n\t\r\n\t\r\n\t\r\n\tif isJSONFormattedObject(request.Body) {\r\n\t\tlog.Println(\"[WARN] request body appears to be a JSON formatted object, \" +\r\n\t\t\t\"no structural matching will occur. Support for structured strings has been\" +\r\n\t\t\t\"deprecated as of 0.13.0\")\r\n\t}\r\n\treturn i\r\n}","code-length":125,"reference":"\/\/ WithRequest specifies the details of the HTTP request that will be used to\n\/\/ confirm that the Provider provides an API listening on the given interface.\n\/\/ Mandatory.","result":"Set the request.","score":[0.0001,0.0189]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *Interaction) WillRespondWith(response Response) *Interaction {\r\n\ti.Response = response\r\n\treturn i\r\n}","code-length":41,"reference":"\/\/ WillRespondWith specifies the details of the HTTP response that will be used to\n\/\/ confirm that the Provider must satisfy. Mandatory.","result":"Define the following functions.","score":[0.0035,0.0495]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isJSONFormattedObject(stringOrObject interface{}) bool {\r\n\tswitch content := stringOrObject.(type) {\r\n\tcase []byte:\r\n\tcase string:\r\n\t\tvar obj interface{}\r\n\t\terr := json.Unmarshal([]byte(content), &obj)\r\n\t\tif err != nil {\r\n\t\t\treturn false\r\n\t\t}\r\n\t\t\r\n\t\tif _, ok := obj.(map[string]interface{}); ok {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":143,"reference":"\/\/ Checks to see if someone has tried to submit a JSON string\n\/\/ for an object, which is no longer supported","result":"Check if a string or object is JSON formatted.","score":[0.043,0.1449]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *UserRepository) ByUsername(username string) (*User, error) {\r\n\tif user, ok := u.Users[username]; ok {\r\n\t\treturn user, nil\r\n\t}\r\n\treturn nil, ErrNotFound\r\n}","code-length":67,"reference":"\/\/ ByUsername finds a user by their username.","result":"Avoid recursive call to ByName.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *UserRepository) ByID(ID int) (*User, error) {\r\n\tfor _, user := range u.Users {\r\n\t\tif user.ID == ID {\r\n\t\t\treturn user, nil\r\n\t\t}\r\n\t}\r\n\treturn nil, ErrNotFound\r\n}","code-length":80,"reference":"\/\/ ByID finds a user by their ID","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UserLogin(w http.ResponseWriter, r *http.Request) {\r\n\tvar login types.LoginRequest\r\n\tw.Header().Set(\"Content-Type\", \"application\/json; charset=utf-8\")\r\n\tw.Header().Set(\"X-Api-Correlation-Id\", \"1234\")\r\n\tbody, err := ioutil.ReadAll(r.Body)\r\n\tdefer r.Body.Close()\r\n\tif err != nil {\r\n\t\tw.WriteHeader(http.StatusServiceUnavailable)\r\n\t\treturn\r\n\t}\r\n\terr = json.Unmarshal(body, &login)\r\n\tif err != nil {\r\n\t\tw.WriteHeader(http.StatusServiceUnavailable)\r\n\t\treturn\r\n\t}\r\n\tuser, err := userRepository.ByUsername(login.Username)\r\n\tif err != nil {\r\n\t\tw.WriteHeader(http.StatusNotFound)\r\n\t} else if user.Username != login.Username || user.Password != login.Password {\r\n\t\tw.WriteHeader(http.StatusUnauthorized)\r\n\t} else {\r\n\t\tw.Header().Set(\"X-Auth-Token\", getAuthToken())\r\n\t\tw.WriteHeader(http.StatusOK)\r\n\t\tres := types.LoginResponse{User: user}\r\n\t\tresBody, _ := json.Marshal(res)\r\n\t\tw.Write(resBody)\r\n\t}\r\n}","code-length":345,"reference":"\/\/ UserLogin logs a user in, returning an auth token and the user object","result":"Login user.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newClient(MockServiceManager client.Service, verificationServiceManager client.Service, messageServiceManager client.Service, publishServiceManager client.Service) *PactClient {\r\n\tMockServiceManager.Setup()\r\n\tverificationServiceManager.Setup()\r\n\tmessageServiceManager.Setup()\r\n\tpublishServiceManager.Setup()\r\n\treturn &PactClient{\r\n\t\tpactMockSvcManager:     MockServiceManager,\r\n\t\tverificationSvcManager: verificationServiceManager,\r\n\t\tmessageSvcManager:      messageServiceManager,\r\n\t\tpublishSvcManager:      publishServiceManager,\r\n\t\tTimeoutDuration:        10 * time.Second,\r\n\t}\r\n}","code-length":164,"reference":"\/\/ newClient creates a new Pact client manager with the provided services","result":"Create a new client.","score":[0.0611,0.2629]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient() *PactClient {\r\n\treturn newClient(&client.MockService{}, &client.VerificationService{}, &client.MessageService{}, &client.PublishService{})\r\n}","code-length":54,"reference":"\/\/ NewClient creates a new Pact client manager with defaults","result":"Create a new client.","score":[0.1008,0.3132]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PactClient) ListServers() []*types.MockServer {\r\n\tlog.Println(\"[DEBUG] client: starting a server\")\r\n\tvar servers []*types.MockServer\r\n\tfor port, s := range p.pactMockSvcManager.List() {\r\n\t\tservers = append(servers, &types.MockServer{\r\n\t\t\tPid:  s.Process.Pid,\r\n\t\t\tPort: port,\r\n\t\t})\r\n\t}\r\n\treturn servers\r\n}","code-length":129,"reference":"\/\/ ListServers lists all known Mock Servers","result":"List the servers of the client.","score":[0,0.1449]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PactClient) UpdateMessagePact(request types.PactMessageRequest) error {\r\n\tlog.Println(\"[DEBUG] client: adding pact message...\")\r\n\t\r\n\terr := request.Validate()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tsvc := p.messageSvcManager.NewService(request.Args)\r\n\tcmd := svc.Command()\r\n\tstdOutPipe, err := cmd.StdoutPipe()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tstdErrPipe, err := cmd.StderrPipe()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = cmd.Start()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tstdOut, err := ioutil.ReadAll(stdOutPipe)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tstdErr, err := ioutil.ReadAll(stdErrPipe)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = cmd.Wait()\r\n\tif err == nil {\r\n\t\treturn nil\r\n\t}\r\n\treturn fmt.Errorf(\"error creating message: %s\\n\\nSTDERR:\\n%s\\n\\nSTDOUT:\\n%s\", err, stdErr, stdOut)\r\n}","code-length":342,"reference":"\/\/ UpdateMessagePact adds a pact message to a contract file","result":"Update the message pact.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PactClient) PublishPacts(request types.PublishRequest) error {\r\n\tsvc := p.publishSvcManager.NewService(request.Args)\r\n\tlog.Println(\"[DEBUG] about to publish pacts\")\r\n\tcmd := svc.Start()\r\n\tlog.Println(\"[DEBUG] waiting for response\")\r\n\terr := cmd.Wait()\r\n\tlog.Println(\"[DEBUG] response from publish\", err)\r\n\treturn err\r\n}","code-length":124,"reference":"\/\/ PublishPacts publishes a set of pacts to a pact broker","result":"Publish pacts.","score":[0,0.0495]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getPort(rawURL string) int {\r\n\tparsedURL, err := url.Parse(rawURL)\r\n\tif err == nil {\r\n\t\tsplitHost := strings.Split(parsedURL.Host, \":\")\r\n\t\tif len(splitHost) == 2 {\r\n\t\t\tport, err := strconv.Atoi(splitHost[1])\r\n\t\t\tif err == nil {\r\n\t\t\t\treturn port\r\n\t\t\t}\r\n\t\t}\r\n\t\tif parsedURL.Scheme == \"https\" {\r\n\t\t\treturn 443\r\n\t\t}\r\n\t\treturn 80\r\n\t}\r\n\treturn -1\r\n}","code-length":159,"reference":"\/\/ Get a port given a URL","result":"Determine the port number.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getAddress(rawURL string) string {\r\n\tparsedURL, err := url.Parse(rawURL)\r\n\tif err != nil {\r\n\t\treturn \"\"\r\n\t}\r\n\tsplitHost := strings.Split(parsedURL.Host, \":\")\r\n\treturn splitHost[0]\r\n}","code-length":80,"reference":"\/\/ Get the address given a URL","result":"Generate the address .","score":[0.2134,0.2799]}
{"code":"\/*is used to<extra_id_0>\r\nfunc sanitiseRubyResponse(response string) string {\r\n\tlog.Println(\"[TRACE] response from Ruby process pre-sanitisation:\", response)\r\n\tr := regexp.MustCompile(\"(?m)^\\\\s*#.*$\")\r\n\ts := r.ReplaceAllString(response, \"\")\r\n\tr = regexp.MustCompile(\"(?m).*bundle exec rake pact:verify.*$\")\r\n\ts = r.ReplaceAllString(s, \"\")\r\n\tr = regexp.MustCompile(\"\\\\n+\")\r\n\ts = r.ReplaceAllString(s, \"\\n\")\r\n\treturn s\r\n}","code-length":155,"reference":"\/\/ sanitiseRubyResponse removes Ruby-isms from the response content\n\/\/ making the output much more human readable","result":"Sanitize the response from Ruby.","score":[0.0417,0.1007]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Publisher) Publish(request types.PublishRequest) error {\r\n\tlog.Println(\"[DEBUG] pact publisher: publish pact\")\r\n\tif p.pactClient == nil {\r\n\t\tc := NewClient()\r\n\t\tp.pactClient = c\r\n\t}\r\n\terr := request.Validate()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn p.pactClient.PublishPacts(request)\r\n}","code-length":126,"reference":"\/\/ Publish sends the Pacts to a broker, optionally tagging them","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FindPortInRange(s string) (int, error) {\r\n\t\r\n\tif !strings.Contains(s, \"-\") {\r\n\t\tports := strings.Split(strings.TrimSpace(s), \",\")\r\n\t\tfor _, p := range ports {\r\n\t\t\ti, err := strconv.Atoi(p)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn 0, err\r\n\t\t\t}\r\n\t\t\terr = checkPort(i)\r\n\t\t\tif err != nil {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\treturn i, nil\r\n\t\t}\r\n\t\treturn 0, errors.New(\"all passed ports are unusable\")\r\n\t}\r\n\t\r\n\tports := strings.Split(strings.TrimSpace(s), \"-\")\r\n\tif len(ports) != 2 {\r\n\t\treturn 0, errors.New(\"invalid range passed\")\r\n\t}\r\n\tlower, err := strconv.Atoi(ports[0])\r\n\tif err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\tupper, err := strconv.Atoi(ports[1])\r\n\tif err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\tif upper < lower {\r\n\t\treturn 0, errors.New(\"invalid range passed\")\r\n\t}\r\n\tfor i := lower; i <= upper; i++ {\r\n\t\terr = checkPort(i)\r\n\t\tif err != nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\treturn i, nil\r\n\t}\r\n\treturn 0, errors.New(\"all passed ports are unusable\")\r\n}","code-length":400,"reference":"\/\/ FindPortInRange Iterate through CSV or Range of ports to find open port\n\/\/ Valid inputs are \"8081\", \"8081,8085\", \"8081-8085\". Do not combine\n\/\/ list and range","result":"Find the port in the range.","score":[0.0058,0.0402]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EachLike(content interface{}, minRequired int) Matcher {\r\n\treturn eachLike{\r\n\t\tContents: content,\r\n\t\tMin:      minRequired,\r\n\t}\r\n}","code-length":55,"reference":"\/\/ EachLike specifies that a given element in a JSON body can be repeated\n\/\/ \"minRequired\" times. Number needs to be 1 or greater","result":"Match each like .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Term(generate string, matcher string) Matcher {\r\n\treturn term{\r\n\t\tData: termData{\r\n\t\t\tGenerate: generate,\r\n\t\t\tMatcher: termMatcher{\r\n\t\t\t\tType:  \"Regexp\",\r\n\t\t\t\tO:     0,\r\n\t\t\t\tRegex: matcher,\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n}","code-length":96,"reference":"\/\/ Term specifies that the matching should generate a value\n\/\/ and also match using a regular expression.","result":"Generate the term .","score":[0.0096,0.0904]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *MapMatcher) UnmarshalJSON(bytes []byte) (err error) {\r\n\tsk := make(map[string]string)\r\n\terr = json.Unmarshal(bytes, &sk)\r\n\tif err != nil {\r\n\t\treturn\r\n\t}\r\n\t*m = make(map[string]Matcher)\r\n\tfor k, v := range sk {\r\n\t\t(*m)[k] = String(v)\r\n\t}\r\n\treturn\r\n}","code-length":121,"reference":"\/\/ UnmarshalJSON is a custom JSON parser for MapMatcher\n\/\/ It treats the matchers as strings","result":"Unmarshal the map matcher.","score":[0.0159,0.0338]}
{"code":"\/*is used to<extra_id_0>\r\nfunc objectToString(obj interface{}) string {\r\n\tswitch content := obj.(type) {\r\n\tcase string:\r\n\t\treturn content\r\n\tdefault:\r\n\t\tjsonString, err := json.Marshal(obj)\r\n\t\tif err != nil {\r\n\t\t\tlog.Println(\"[DEBUG] objectToString: error unmarshaling object into string:\", err.Error())\r\n\t\t\treturn \"\"\r\n\t\t}\r\n\t\treturn string(jsonString)\r\n\t}\r\n}","code-length":127,"reference":"\/\/ Takes an object and converts it to a JSON representation","result":"Convert object to string.","score":[0.066,0.1456]}
{"code":"\/*is used to<extra_id_0>\r\nfunc match(srcType reflect.Type, params params) Matcher {\r\n\tswitch kind := srcType.Kind(); kind {\r\n\tcase reflect.Ptr:\r\n\t\treturn match(srcType.Elem(), params)\r\n\tcase reflect.Slice, reflect.Array:\r\n\t\treturn EachLike(match(srcType.Elem(), getDefaults()), params.slice.min)\r\n\tcase reflect.Struct:\r\n\t\tresult := StructMatcher{}\r\n\t\tfor i := 0; i < srcType.NumField(); i++ {\r\n\t\t\tfield := srcType.Field(i)\r\n\t\t\tresult[field.Tag.Get(\"json\")] = match(field.Type, pluckParams(field.Type, field.Tag.Get(\"pact\")))\r\n\t\t}\r\n\t\treturn result\r\n\tcase reflect.String:\r\n\t\tif params.str.regEx != \"\" {\r\n\t\t\treturn Term(params.str.example, params.str.regEx)\r\n\t\t}\r\n\t\tif params.str.example != \"\" {\r\n\t\t\treturn Like(params.str.example)\r\n\t\t}\r\n\t\treturn Like(\"string\")\r\n\tcase reflect.Bool:\r\n\t\treturn Like(true)\r\n\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64,\r\n\t\treflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64:\r\n\t\treturn Like(1)\r\n\tcase reflect.Float32, reflect.Float64:\r\n\t\treturn Like(1.1)\r\n\tdefault:\r\n\t\tpanic(fmt.Sprintf(\"match: unhandled type: %v\", srcType))\r\n\t}\r\n}","code-length":425,"reference":"\/\/ match recursively traverses the provided type and outputs a\n\/\/ matcher string for it that is compatible with the Pact dsl.","result":"Match a type .","score":[0.0042,0.0743]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Pact) AddMessage() *Message {\r\n\tlog.Println(\"[DEBUG] pact add message\")\r\n\tm := &Message{}\r\n\tp.MessageInteractions = append(p.MessageInteractions, m)\r\n\treturn m\r\n}","code-length":73,"reference":"\/\/ AddMessage creates a new asynchronous consumer expectation","result":"Add message to pact.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Pact) AddInteraction() *Interaction {\r\n\tp.Setup(true)\r\n\tlog.Println(\"[DEBUG] pact add interaction\")\r\n\ti := &Interaction{}\r\n\tp.Interactions = append(p.Interactions, i)\r\n\treturn i\r\n}","code-length":80,"reference":"\/\/ AddInteraction creates a new Pact interaction, initialising all\n\/\/ required things. Will automatically start a Mock Service if none running.","result":"Add an interaction to the pact.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Pact) Teardown() *Pact {\r\n\tlog.Println(\"[DEBUG] teardown\")\r\n\tif p.Server != nil {\r\n\t\tserver, err := p.pactClient.StopServer(p.Server)\r\n\t\tif err != nil {\r\n\t\t\tlog.Println(\"error:\", err)\r\n\t\t}\r\n\t\tp.Server = server\r\n\t}\r\n\treturn p\r\n}","code-length":116,"reference":"\/\/ Teardown stops the Pact Mock Server. This usually is called on completion\n\/\/ of each test suite.","result":"Teardown the pact.","score":[0.0033,0.0606]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Pact) Verify(integrationTest func() error) error {\r\n\tp.Setup(true)\r\n\tlog.Println(\"[DEBUG] pact verify\")\r\n\t\r\n\tif len(p.Interactions) == 0 {\r\n\t\treturn errors.New(\"there are no interactions to be verified\")\r\n\t}\r\n\tmockServer := &MockService{\r\n\t\tBaseURL:  fmt.Sprintf(\"http:\r\n\t\tConsumer: p.Consumer,\r\n\t\tProvider: p.Provider,\r\n\t}\r\n\tfor _, interaction := range p.Interactions {\r\n\t\terr := mockServer.AddInteraction(interaction)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\t\r\n\terr := integrationTest()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\terr = mockServer.Verify()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tp.Interactions = make([]*Interaction, 0)\r\n\treturn mockServer.DeleteInteractions()\r\n}","code-length":280,"reference":"\/\/ Verify runs the current test case against a Mock Service.\n\/\/ Will cleanup interactions between tests within a suite.","result":"Verify the pact.","score":[0.0017,0.0546]}
{"code":"\/*is used to<extra_id_0>\r\nfunc stateHandlerMiddleware(stateHandlers types.StateHandlers) proxy.Middleware {\r\n\treturn func(next http.Handler) http.Handler {\r\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\r\n\t\t\tif r.URL.Path == \"\/__setup\" {\r\n\t\t\t\tvar s *types.ProviderState\r\n\t\t\t\tdecoder := json.NewDecoder(r.Body)\r\n\t\t\t\tdecoder.Decode(&s)\r\n\t\t\t\t\r\n\t\t\t\tfor _, state := range s.States {\r\n\t\t\t\t\tsf, stateFound := stateHandlers[state]\r\n\t\t\t\t\tif !stateFound {\r\n\t\t\t\t\t\tlog.Printf(\"[WARN] state handler not found for state: %v\", state)\r\n\t\t\t\t\t} else {\r\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tif err := sf(); err != nil {\r\n\t\t\t\t\t\t\tlog.Printf(\"[ERROR] state handler for '%v' errored: %v\", state, err)\r\n\t\t\t\t\t\t\tw.WriteHeader(http.StatusInternalServerError)\r\n\t\t\t\t\t\t\treturn\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t\tw.WriteHeader(http.StatusOK)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tlog.Println(\"[DEBUG] skipping state handler for request\", r.RequestURI)\r\n\t\t\t\r\n\t\t\tnext.ServeHTTP(w, r)\r\n\t\t})\r\n\t}\r\n}","code-length":344,"reference":"\/\/ stateHandlerMiddleware responds to the various states that are\n\/\/ given during provider verification\n\/\/\n\/\/ statehandler accepts a state object from the verifier and executes\n\/\/ any state handlers associated with the provider.\n\/\/ It will not execute further middleware if it is the designted \"state\" request","result":"Handle state handlers .","score":[0.0,0.043]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Pact) VerifyMessageProviderRaw(request VerifyMessageRequest) (types.ProviderVerifierResponse, error) {\r\n\tp.Setup(false)\r\n\tresponse := types.ProviderVerifierResponse{}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tmux := http.NewServeMux()\r\n\tport, err := utils.GetFreePort()\r\n\tif err != nil {\r\n\t\treturn response, fmt.Errorf(\"unable to allocate a port for verification: %v\", err)\r\n\t}\r\n\t\r\n\tverificationRequest := types.VerifyRequest{\r\n\t\tProviderBaseURL:            fmt.Sprintf(\"http:\r\n\t\tPactURLs:                   request.PactURLs,\r\n\t\tBrokerURL:                  request.BrokerURL,\r\n\t\tTags:                       request.Tags,\r\n\t\tBrokerUsername:             request.BrokerUsername,\r\n\t\tBrokerPassword:             request.BrokerPassword,\r\n\t\tBrokerToken:                request.BrokerToken,\r\n\t\tPublishVerificationResults: request.PublishVerificationResults,\r\n\t\tProviderVersion:            request.ProviderVersion,\r\n\t\tProvider:                   p.Provider,\r\n\t}\r\n\tmux.HandleFunc(\"\/\", messageVerificationHandler(request.MessageHandlers, request.StateHandlers))\r\n\tln, err := net.Listen(\"tcp\", fmt.Sprintf(\":%d\", port))\r\n\tif err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n\tdefer ln.Close()\r\n\tlog.Printf(\"[DEBUG] API handler starting: port %d (%s)\", port, ln.Addr())\r\n\tgo http.Serve(ln, mux)\r\n\tportErr := waitForPort(port, \"tcp\", \"localhost\", p.ClientTimeout,\r\n\t\tfmt.Sprintf(`Timed out waiting for pact proxy on port %d - check for errors`, port))\r\n\tif portErr != nil {\r\n\t\tlog.Fatal(\"Error:\", err)\r\n\t\treturn response, portErr\r\n\t}\r\n\tlog.Println(\"[DEBUG] pact provider verification\")\r\n\treturn p.pactClient.VerifyProvider(verificationRequest)\r\n}","code-length":515,"reference":"\/\/ VerifyMessageProviderRaw runs provider message verification.\n\/\/\n\/\/ A Message Producer is analagous to Consumer in the HTTP Interaction model.\n\/\/ It is the initiator of an interaction, and expects something on the other end\n\/\/ of the interaction to respond - just in this case, not immediately.","result":"Code too long,keep in 512.","score":[0.0,0.0114]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Pact) VerifyMessageConsumerRaw(message *Message, handler MessageConsumer) error {\r\n\tlog.Printf(\"[DEBUG] verify message\")\r\n\tp.Setup(false)\r\n\t\r\n\treified, err := p.pactClient.ReifyMessage(&types.PactReificationRequest{\r\n\t\tMessage: message.Content,\r\n\t})\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"unable to convert consumer test to a valid JSON representation: %v\", err)\r\n\t}\r\n\tt := reflect.TypeOf(message.Type)\r\n\tif t != nil && t.Name() != \"interface\" {\r\n\t\tlog.Println(\"[DEBUG] narrowing type to\", t.Name())\r\n\t\terr = json.Unmarshal(reified.ResponseRaw, &message.Type)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"unable to narrow type to %v: %v\", t.Name(), err)\r\n\t\t}\r\n\t}\r\n\t\r\n\tgeneratedMessage :=\r\n\t\tMessage{\r\n\t\t\tContent:     message.Type,\r\n\t\t\tStates:      message.States,\r\n\t\t\tDescription: message.Description,\r\n\t\t\tMetadata:    message.Metadata,\r\n\t\t}\r\n\terr = handler(generatedMessage)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\treturn p.pactClient.UpdateMessagePact(types.PactMessageRequest{\r\n\t\tMessage:  message,\r\n\t\tConsumer: p.Consumer,\r\n\t\tProvider: p.Provider,\r\n\t\tPactDir:  p.PactDir,\r\n\t})\r\n}","code-length":418,"reference":"\/\/ VerifyMessageConsumerRaw creates a new Pact _message_ interaction to build a testable\n\/\/ interaction.\n\/\/\n\/\/\n\/\/ A Message Consumer is analagous to a Provider in the HTTP Interaction model.\n\/\/ It is the receiver of an interaction, and needs to be able to handle whatever\n\/\/ request was provided.","result":"Verify message consumer.","score":[0,0.011]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *mockClient) VerifyProvider(request types.VerifyRequest) (types.ProviderVerifierResponse, error) {\r\n\treturn p.VerifyProviderResponse, p.VerifyProviderError\r\n}","code-length":53,"reference":"\/\/ VerifyProvider runs the verification process against a running Provider.","result":"Test the tests.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *MockService) NewService(args []string) Service {\r\n\tm.Args = []string{\r\n\t\t\"service\",\r\n\t}\r\n\tm.Args = append(m.Args, args...)\r\n\tm.Cmd = getMockServiceCommandPath()\r\n\treturn m\r\n}","code-length":82,"reference":"\/\/ NewService creates a new MockService with default settings.","result":"Create a new service .","score":[0.1527,0.3424]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *ServiceManager) Setup() {\r\n\tlog.Println(\"[DEBUG] setting up a service manager\")\r\n\ts.commandCreatedChan = make(chan *exec.Cmd)\r\n\ts.commandCompleteChan = make(chan *exec.Cmd)\r\n\ts.processMap = processMap{processes: make(map[int]*exec.Cmd)}\r\n\t\r\n\tgo s.addServiceMonitor()\r\n\tgo s.removeServiceMonitor()\r\n}","code-length":119,"reference":"\/\/ Setup the Management services.","result":"Setup the service manager.","score":[0.3519,0.3827]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *ServiceManager) addServiceMonitor() {\r\n\tlog.Println(\"[DEBUG] starting service creation monitor\")\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase p := <-s.commandCreatedChan:\r\n\t\t\tif p != nil && p.Process != nil {\r\n\t\t\t\ts.processMap.Set(p.Process.Pid, p)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":113,"reference":"\/\/ addServiceMonitor watches a channel to add services into operation.","result":"Monitor service creation.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *ServiceManager) removeServiceMonitor() {\r\n\tlog.Println(\"[DEBUG] starting service removal monitor\")\r\n\tvar p *exec.Cmd\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase p = <-s.commandCompleteChan:\r\n\t\t\tif p != nil && p.Process != nil {\r\n\t\t\t\tp.Process.Signal(os.Interrupt)\r\n\t\t\t\ts.processMap.Delete(p.Process.Pid)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":134,"reference":"\/\/ removeServiceMonitor watches a channel to remove services from operation.","result":"Remove service monitor.","score":[0,0.2016]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *ServiceManager) List() map[int]*exec.Cmd {\r\n\tlog.Println(\"[DEBUG] listing services\")\r\n\treturn s.processMap.processes\r\n}","code-length":53,"reference":"\/\/ List all Service PIDs.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *ServiceManager) Command() *exec.Cmd {\r\n\tcmd := exec.Command(s.Cmd, s.Args...)\r\n\tenv := os.Environ()\r\n\tenv = append(env, s.Env...)\r\n\tcmd.Env = env\r\n\treturn cmd\r\n}","code-length":78,"reference":"\/\/ Command creates an os command to be run","result":"Generate the command .","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *MockService) call(method string, url string, content interface{}) error {\r\n\tbody, err := json.Marshal(content)\r\n\tif err != nil {\r\n\t\tfmt.Println(err)\r\n\t\treturn err\r\n\t}\r\n\tclient := &http.Client{}\r\n\tvar req *http.Request\r\n\tif method == \"POST\" {\r\n\t\treq, err = http.NewRequest(method, url, bytes.NewReader(body))\r\n\t} else {\r\n\t\treq, err = http.NewRequest(method, url, nil)\r\n\t}\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treq.Header.Set(\"X-Pact-Mock-Service\", \"true\")\r\n\treq.Header.Set(\"Content-Type\", \"application\/json\")\r\n\tres, err := client.Do(req)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tresponseBody, err := ioutil.ReadAll(res.Body)\r\n\tres.Body.Close()\r\n\tif res.StatusCode < 200 || res.StatusCode >= 300 {\r\n\t\treturn errors.New(string(responseBody))\r\n\t}\r\n\treturn err\r\n}","code-length":310,"reference":"\/\/ call sends a message to the Pact service","result":"Call the service.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *MockService) DeleteInteractions() error {\r\n\tlog.Println(\"[DEBUG] mock service delete interactions\")\r\n\turl := fmt.Sprintf(\"%s\/interactions\", m.BaseURL)\r\n\treturn m.call(\"DELETE\", url, nil)\r\n}","code-length":74,"reference":"\/\/ DeleteInteractions removes any previous Mock Service Interactions.","result":"Delete interactions.","score":[0,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *MockService) AddInteraction(interaction *Interaction) error {\r\n\tlog.Println(\"[DEBUG] mock service add interaction\")\r\n\turl := fmt.Sprintf(\"%s\/interactions\", m.BaseURL)\r\n\treturn m.call(\"POST\", url, interaction)\r\n}","code-length":77,"reference":"\/\/ AddInteraction adds a new Pact Mock Service interaction.","result":"Add interactions to a service.","score":[0.108,0.1163]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *MockService) WritePact() error {\r\n\tlog.Println(\"[DEBUG] mock service write pact\")\r\n\tif m.Consumer == \"\" || m.Provider == \"\" {\r\n\t\treturn errors.New(\"Consumer and Provider name need to be provided\")\r\n\t}\r\n\tif m.PactFileWriteMode == \"\" {\r\n\t\tm.PactFileWriteMode = \"overwrite\"\r\n\t}\r\n\tpact := map[string]interface{}{\r\n\t\t\"consumer\": map[string]string{\r\n\t\t\t\"name\": m.Consumer,\r\n\t\t},\r\n\t\t\"provider\": map[string]string{\r\n\t\t\t\"name\": m.Provider,\r\n\t\t},\r\n\t\t\"pactFileWriteMode\": m.PactFileWriteMode,\r\n\t}\r\n\turl := fmt.Sprintf(\"%s\/pact\", m.BaseURL)\r\n\treturn m.call(\"POST\", url, pact)\r\n}","code-length":241,"reference":"\/\/ WritePact writes the pact file to disk.","result":"Write pact file.","score":[0.0771,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Message) ExpectsToReceive(description string) *Message {\r\n\tp.Description = description\r\n\treturn p\r\n}","code-length":41,"reference":"\/\/ ExpectsToReceive specifies the content it is expecting to be\n\/\/ given from the Provider. The function must be able to handle this\n\/\/ message for the interaction to succeed.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Message) WithMetadata(metadata MapMatcher) *Message {\r\n\tp.Metadata = metadata\r\n\treturn p\r\n}","code-length":41,"reference":"\/\/ WithMetadata specifies message-implementation specific metadata\n\/\/ to go with the content","result":"Set the metadata on the message.","score":[0.0845,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Message) AsType(t interface{}) *Message {\r\n\tfmt.Println(\"[DEBUG] setting Message decoding to type:\", reflect.TypeOf(t))\r\n\tp.Type = t\r\n\treturn p\r\n}","code-length":66,"reference":"\/\/ AsType specifies that the content sent through to the\n\/\/ consumer handler should be sent as the given type","result":"Set Message decoding to type.","score":[0.012,0.027]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UserLogin(c *gin.Context) {\r\n\tc.Header(\"X-Api-Correlation-Id\", \"1234\")\r\n\tvar json Login\r\n\tif c.BindJSON(&json) == nil {\r\n\t\tuser, err := userRepository.ByUsername(json.User)\r\n\t\tif err != nil {\r\n\t\t\tc.JSON(http.StatusNotFound, gin.H{\"status\": \"file not found\"})\r\n\t\t} else if user.Username != json.User || user.Password != json.Password {\r\n\t\t\tc.JSON(http.StatusUnauthorized, gin.H{\"status\": \"unauthorized\"})\r\n\t\t} else {\r\n\t\t\tc.Header(\"X-Auth-Token\", getAuthToken())\r\n\t\t\tc.JSON(http.StatusOK, types.LoginResponse{User: user})\r\n\t\t}\r\n\t}\r\n}","code-length":216,"reference":"\/\/ UserLogin is the login route.","result":"Log in user.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *S3) Region() string {\r\n\tregion := os.Getenv(\"AWS_REGION\")\r\n\tswitch s.Domain {\r\n\tcase \"s3.amazonaws.com\", \"s3-external-1.amazonaws.com\":\r\n\t\treturn \"us-east-1\"\r\n\tcase \"s3-accelerate.amazonaws.com\":\r\n\t\tif region == \"\" {\r\n\t\t\tpanic(\"can't find endpoint region\")\r\n\t\t}\r\n\t\treturn region\r\n\tdefault:\r\n\t\tregions := regionMatcher.FindStringSubmatch(s.Domain)\r\n\t\tif len(regions) < 2 {\r\n\t\t\tif region == \"\" {\r\n\t\t\t\tpanic(\"can't find endpoint region\")\r\n\t\t\t}\r\n\t\t\treturn region\r\n\t\t}\r\n\t\treturn regions[1]\r\n\t}\r\n}","code-length":217,"reference":"\/\/ Region returns the service region infering it from S3 domain.","result":"Find the region of the endpoint.","score":[0.0998,0.0952]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(domain string, keys Keys) *S3 {\r\n\tif domain == \"\" {\r\n\t\tdomain = DefaultDomain\r\n\t}\r\n\treturn &S3{domain, keys}\r\n}","code-length":57,"reference":"\/\/ New Returns a new S3\n\/\/ domain defaults to DefaultDomain if empty","result":"Create a new S.","score":[0.0476,0.155]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *S3) Bucket(name string) *Bucket {\r\n\treturn &Bucket{\r\n\t\tS3:     s,\r\n\t\tName:   name,\r\n\t\tConfig: DefaultConfig,\r\n\t}\r\n}","code-length":66,"reference":"\/\/ Bucket returns a bucket on s3\n\/\/ Bucket Config is initialized to DefaultConfig","result":"Create a bucket.","score":[0.0104,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Bucket) PutWriter(path string, h http.Header, c *Config) (w io.WriteCloser, err error) {\r\n\tif c == nil {\r\n\t\tc = b.conf()\r\n\t}\r\n\tu, err := b.url(path, c)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn newPutter(*u, h, c, b)\r\n}","code-length":117,"reference":"\/\/ PutWriter provides a writer to upload data as multipart upload requests.\n\/\/\n\/\/ Each header in h is added to the HTTP request header. This is useful for specifying\n\/\/ options such as server-side encryption in metadata as well as custom user metadata.\n\/\/ DefaultConfig is used if c is nil.\n\/\/ Callers should call Close on w to ensure that all resources are released.","result":"Create a new object to store the content.","score":[0.0001,0.0249]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Bucket) url(bPath string, c *Config) (*url.URL, error) {\r\n\t\r\n\tn nil, err\r\n\t}\r\n\tvar vals url.Values\r\n\tif v := purl.Query().Get(versionParam); v != \"\" {\r\n\t\tvals = make(url.Values)\r\n\t\tvals.Add(versionParam, v)\r\n\t\tbPath = strings.Split(bPath, \"?\")[0]\r\n\t}\r\n\t\r\n\tt:     b.S3.Domain,\r\n\t\t\tScheme:   c.Scheme,\r\n\t\t\tPath:     path.Clean(fmt.Sprintf(\"\/%s\/%s\", b.Name, bPath)),\r\n\t\t\tRawQuery: vals.Encode(),\r\n\t\t}, nil\r\n\t} else {\r\n\t\treturn &url.URL{\r\n\t\t\tScheme:   c.Scheme,\r\n\t\t\tPath:     path.Clean(fmt.Sprintf(\"\/%s\", bPath)),\r\n\t\t\tHost:     path.Clean(fmt.Sprintf(\"%s.%s\", b.Name, b.S3.Domain)),\r\n\t\t\tRawQuery: vals.Encode(),\r\n\t\t}, nil\r\n\t}\r\n}","code-length":302,"reference":"\/\/ url returns a parsed url to the given path. c must not be nil","result":"Generate the url for the bucket.","score":[0.0512,0.0709]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetLogger(out io.Writer, prefix string, flag int, debug bool) {\r\n\tlogger = internalLogger{\r\n\t\tlog.New(out, prefix, flag),\r\n\t\tdebug,\r\n\t}\r\n}","code-length":63,"reference":"\/\/ SetLogger wraps the standard library log package.\n\/\/\n\/\/ It allows the internal logging of s3gof3r to be set to a desired output and format.\n\/\/ Setting debug to true enables debug logging output. s3gof3r does not log output by default.","result":"Set the logger.","score":[0.0,0.0262]}
{"code":"\/*is used to<extra_id_0>\r\nfunc InstanceKeys() (keys Keys, err error) {\r\n\trolePath := \"http:\r\n\tvar creds mdCreds\r\n\t\r\n\t\r\n\tresp, err := ClientWithTimeout(2 * time.Second).Get(rolePath)\r\n\tif err != nil {\r\n\t\treturn\r\n\t}\r\n\tdefer checkClose(resp.Body, err)\r\n\tif resp.StatusCode != 200 {\r\n\t\terr = newRespError(resp)\r\n\t\treturn\r\n\t}\r\n\trole, err := ioutil.ReadAll(resp.Body)\r\n\tif err != nil {\r\n\t\treturn\r\n\t}\r\n\t\r\n\tresp, err = http.Get(rolePath + string(role))\r\n\tif err != nil {\r\n\t\treturn\r\n\t}\r\n\tdefer checkClose(resp.Body, err)\r\n\tif resp.StatusCode != 200 {\r\n\t\terr = newRespError(resp)\r\n\t\treturn\r\n\t}\r\n\tmetadata, err := ioutil.ReadAll(resp.Body)\r\n\tif err != nil {\r\n\t\treturn\r\n\t}\r\n\tif err = json.Unmarshal([]byte(metadata), &creds); err != nil {\r\n\t\treturn\r\n\t}\r\n\tkeys = Keys{\r\n\t\tAccessKey:     creds.AccessKeyID,\r\n\t\tSecretKey:     creds.SecretAccessKey,\r\n\t\tSecurityToken: creds.Token,\r\n\t}\r\n\treturn\r\n}","code-length":358,"reference":"\/\/ InstanceKeys Requests the AWS keys from the instance-based metadata on EC2\n\/\/ Assumes only one IAM role.","result":"Get the instance keys.","score":[0.0096,0.0301]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EnvKeys() (keys Keys, err error) {\r\n\tkeys = Keys{\r\n\t\tAccessKey:     os.Getenv(\"AWS_ACCESS_KEY_ID\"),\r\n\t\tSecretKey:     os.Getenv(\"AWS_SECRET_ACCESS_KEY\"),\r\n\t\tSecurityToken: os.Getenv(\"AWS_SECURITY_TOKEN\"),\r\n\t}\r\n\tif keys.AccessKey == \"\" || keys.SecretKey == \"\" {\r\n\t\terr = fmt.Errorf(\"keys not set in environment: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY\")\r\n\t}\r\n\treturn\r\n}","code-length":152,"reference":"\/\/ EnvKeys Reads the AWS keys from the environment","result":"Set the keys in the environment.","score":[0.1541,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Bucket) Sign(req *http.Request) {\r\n\tif req.Header == nil {\r\n\t\treq.Header = http.Header{}\r\n\t}\r\n\tif b.S3.Keys.SecurityToken != \"\" {\r\n\t\treq.Header.Set(\"X-Amz-Security-Token\", b.S3.Keys.SecurityToken)\r\n\t}\r\n\treq.Header.Set(\"User-Agent\", \"S3Gof3r\")\r\n\ts := &signer{\r\n\t\tTime:    time.Now(),\r\n\t\tRequest: req,\r\n\t\tRegion:  b.S3.Region(),\r\n\t\tKeys:    b.S3.Keys,\r\n\t}\r\n\ts.sign()\r\n}","code-length":190,"reference":"\/\/ Sign signs the http.Request","result":"Sign the request.","score":[0.2493,0.2083]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getAWSKeys() (keys s3gof3r.Keys, err error) {\r\n\tkeys, err = s3gof3r.EnvKeys()\r\n\tif err == nil {\r\n\t\treturn\r\n\t}\r\n\tkeys, err = s3gof3r.InstanceKeys()\r\n\tif err == nil {\r\n\t\treturn\r\n\t}\r\n\terr = errors.New(\"no AWS keys found\")\r\n\treturn\r\n}","code-length":118,"reference":"\/\/ getAWSKeys gets the AWS Keys from environment variables or the instance-based metadata on EC2\n\/\/ Environment variables are attempted first, followed by the instance-based credentials.","result":"Generate the keys for the request.","score":[0.0082,0.0625]}
{"code":"\/*is used to<extra_id_0>\r\nfunc homeDir() (string, error) {\r\n\tif h := os.Getenv(\"HOME\"); h != \"\" {\r\n\t\treturn h, nil\r\n\t}\r\n\th, err := exec.Command(\"sh\", \"-c\", \"eval echo ~$USER\").Output()\r\n\tif err == nil && len(h) > 0 {\r\n\t\treturn strings.TrimSpace(string(h)), nil\r\n\t}\r\n\treturn \"\", fmt.Errorf(\"home directory not found for current user\")\r\n}","code-length":128,"reference":"\/\/ find unix home directory","result":"Get the home directory of the current user.","score":[0.1964,0.4822]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ACL(h http.Header, acl string) http.Header {\r\n\tif acl != \"\" {\r\n\t\th.Set(\"x-amz-acl\", acl)\r\n\t}\r\n\treturn h\r\n}","code-length":61,"reference":"\/\/ add canned acl to http.Header","result":"Set headers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *putter) putPart(part *part) error {\r\n\tv := url.Values{}\r\n\tv.Set(\"partNumber\", strconv.Itoa(part.PartNumber))\r\n\tv.Set(\"uploadId\", p.UploadID)\r\n\tif _, err := part.r.Seek(0, 0); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treq, err := http.NewRequest(\"PUT\", p.url.String()+\"?\"+v.Encode(), part.r)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treq.ContentLength = part.len\r\n\treq.Header.Set(md5Header, part.md5)\r\n\treq.Header.Set(sha256Header, part.sha256)\r\n\tp.b.Sign(req)\r\n\tresp, err := p.c.Client.Do(req)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer checkClose(resp.Body, err)\r\n\tif resp.StatusCode != 200 {\r\n\t\treturn newRespError(resp)\r\n\t}\r\n\ts := resp.Header.Get(\"etag\")\r\n\tif len(s) < 2 {\r\n\t\treturn fmt.Errorf(\"Got Bad etag:%s\", s)\r\n\t}\r\n\ts = s[1 : len(s)-1]\r\n\tif part.ETag != s {\r\n\t\treturn fmt.Errorf(\"Response etag does not match. Remote:%s Calculated:%s\", s, p.ETag)\r\n\t}\r\n\treturn nil\r\n}","code-length":392,"reference":"\/\/ uploads a part, checking the etag against the calculated value","result":"Store the part in the multipart upload.","score":[0.1085,0.0943]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *putter) abort() {\r\n\tv := url.Values{}\r\n\tv.Set(\"uploadId\", p.UploadID)\r\n\ts := p.url.String() + \"?\" + v.Encode()\r\n\tresp, err := p.retryRequest(\"DELETE\", s, nil, nil)\r\n\tif err != nil {\r\n\t\tlogger.Printf(\"Error aborting multipart upload: %v\\n\", err)\r\n\t\treturn\r\n\t}\r\n\tdefer checkClose(resp.Body, err)\r\n\tif resp.StatusCode != 204 {\r\n\t\tlogger.Printf(\"Error aborting multipart upload: %v\", newRespError(resp))\r\n\t}\r\n\treturn\r\n}","code-length":176,"reference":"\/\/ Try to abort multipart upload. Do not error on failure.","result":"Prevent a race condition.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc growPartSize(partIndex int, partSize, putsz int64) bool {\r\n\treturn (maxObjSize-putsz)\/(maxNPart-int64(partIndex)) > partSize\r\n}","code-length":57,"reference":"\/\/ returns true unless partSize is large enough\n\/\/ to achieve maxObjSize with remaining parts","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CheckDisallowed(prefix string, spec interface{}) error {\r\n\tinfos, err := gatherInfo(prefix, spec)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tvars := make(map[string]struct{})\r\n\tfor _, info := range infos {\r\n\t\tvars[info.Key] = struct{}{}\r\n\t}\r\n\tif prefix != \"\" {\r\n\t\tprefix = strings.ToUpper(prefix) + \"_\"\r\n\t}\r\n\tfor _, env := range os.Environ() {\r\n\t\tif !strings.HasPrefix(env, prefix) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tv := strings.SplitN(env, \"=\", 2)[0]\r\n\t\tif _, found := vars[v]; !found {\r\n\t\t\treturn fmt.Errorf(\"unknown environment variable %s\", v)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":234,"reference":"\/\/ CheckDisallowed checks that no environment variables with the prefix are set\n\/\/ that we don't know how or want to parse. This is likely only meaningful with\n\/\/ a non-empty prefix.","result":"Check disallowed environment variables.","score":[0.0003,0.0342]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Process(prefix string, spec interface{}) error {\r\n\tinfos, err := gatherInfo(prefix, spec)\r\n\tfor _, info := range infos {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tvalue, ok := lookupEnv(info.Key)\r\n\t\tif !ok && info.Alt != \"\" {\r\n\t\t\tvalue, ok = lookupEnv(info.Alt)\r\n\t\t}\r\n\t\tdef := info.Tags.Get(\"default\")\r\n\t\tif def != \"\" && !ok {\r\n\t\t\tvalue = def\r\n\t\t}\r\n\t\treq := info.Tags.Get(\"required\")\r\n\t\tif !ok && def == \"\" {\r\n\t\t\tif isTrue(req) {\r\n\t\t\t\treturn fmt.Errorf(\"required key %s missing value\", info.Key)\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\terr = processField(value, info.Field)\r\n\t\tif err != nil {\r\n\t\t\treturn &ParseError{\r\n\t\t\t\tKeyName:   info.Key,\r\n\t\t\t\tFieldName: info.Name,\r\n\t\t\t\tTypeName:  info.Field.Type().String(),\r\n\t\t\t\tValue:     value,\r\n\t\t\t\tErr:       err,\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn err\r\n}","code-length":324,"reference":"\/\/ Process populates the specified struct based on environment variables","result":"Process spec values.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MustProcess(prefix string, spec interface{}) {\r\n\tif err := Process(prefix, spec); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n}","code-length":53,"reference":"\/\/ MustProcess is the same as Process but panics if an error occurs","result":"Check if the spec is valid.","score":[0.0791,0.122]}
{"code":"\/*is used to<extra_id_0>\r\nfunc toTypeDescription(t reflect.Type) string {\r\n\tswitch t.Kind() {\r\n\tcase reflect.Array, reflect.Slice:\r\n\t\treturn fmt.Sprintf(\"Comma-separated list of %s\", toTypeDescription(t.Elem()))\r\n\tcase reflect.Map:\r\n\t\treturn fmt.Sprintf(\r\n\t\t\t\"Comma-separated list of %s:%s pairs\",\r\n\t\t\ttoTypeDescription(t.Key()),\r\n\t\t\ttoTypeDescription(t.Elem()),\r\n\t\t)\r\n\tcase reflect.Ptr:\r\n\t\treturn toTypeDescription(t.Elem())\r\n\tcase reflect.Struct:\r\n\t\tif implementsInterface(t) && t.Name() != \"\" {\r\n\t\t\treturn t.Name()\r\n\t\t}\r\n\t\treturn \"\"\r\n\tcase reflect.String:\r\n\t\tname := t.Name()\r\n\t\tif name != \"\" && name != \"string\" {\r\n\t\t\treturn name\r\n\t\t}\r\n\t\treturn \"String\"\r\n\tcase reflect.Bool:\r\n\t\tname := t.Name()\r\n\t\tif name != \"\" && name != \"bool\" {\r\n\t\t\treturn name\r\n\t\t}\r\n\t\treturn \"True or False\"\r\n\tcase reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:\r\n\t\tname := t.Name()\r\n\t\tif name != \"\" && !strings.HasPrefix(name, \"int\") {\r\n\t\t\treturn name\r\n\t\t}\r\n\t\treturn \"Integer\"\r\n\tcase reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64:\r\n\t\tname := t.Name()\r\n\t\tif name != \"\" && !strings.HasPrefix(name, \"uint\") {\r\n\t\t\treturn name\r\n\t\t}\r\n\t\treturn \"Unsigned Integer\"\r\n\tcase reflect.Float32, reflect.Float64:\r\n\t\tname := t.Name()\r\n\t\tif name != \"\" && !strings.HasPrefix(name, \"float\") {\r\n\t\t\treturn name\r\n\t\t}\r\n\t\treturn \"Float\"\r\n\t}\r\n\treturn fmt.Sprintf(\"%+v\", t)\r\n}","code-length":546,"reference":"\/\/ toTypeDescription converts Go types into a human readable description","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Usage(prefix string, spec interface{}) error {\r\n\t\r\n\t\r\n\ttabs := tabwriter.NewWriter(os.Stdout, 1, 0, 4, ' ', 0)\r\n\terr := Usagef(prefix, spec, tabs, DefaultTableFormat)\r\n\ttabs.Flush()\r\n\treturn err\r\n}","code-length":85,"reference":"\/\/ Usage writes usage information to stderr using the default header and table format","result":"Print usage.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Usagef(prefix string, spec interface{}, out io.Writer, format string) error {\r\n\t\r\n\tfunctions := template.FuncMap{\r\n\t\t\"usage_key\":         func(v varInfo) string { return v.Key },\r\n\t\t\"usage_description\": func(v varInfo) string { return v.Tags.Get(\"desc\") },\r\n\t\t\"usage_type\":        func(v varInfo) string { return toTypeDescription(v.Field.Type()) },\r\n\t\t\"usage_default\":     func(v varInfo) string { return v.Tags.Get(\"default\") },\r\n\t\t\"usage_required\": func(v varInfo) (string, error) {\r\n\t\t\treq := v.Tags.Get(\"required\")\r\n\t\t\tif req != \"\" {\r\n\t\t\t\treqB, err := strconv.ParseBool(req)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn \"\", err\r\n\t\t\t\t}\r\n\t\t\t\tif reqB {\r\n\t\t\t\t\treq = \"true\"\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn req, nil\r\n\t\t},\r\n\t}\r\n\ttmpl, err := template.New(\"envconfig\").Funcs(functions).Parse(format)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn Usaget(prefix, spec, out, tmpl)\r\n}","code-length":334,"reference":"\/\/ Usagef writes usage information to the specified io.Writer using the specifed template specification","result":"Format the usage of the envconfig file.","score":[0.0782,0.1128]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Usaget(prefix string, spec interface{}, out io.Writer, tmpl *template.Template) error {\r\n\t\r\n\tinfos, err := gatherInfo(prefix, spec)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn tmpl.Execute(out, infos)\r\n}","code-length":84,"reference":"\/\/ Usaget writes usage information to the specified io.Writer using the specified template","result":"Specify a user.","score":[0,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Time) Scan(value interface{}) error {\r\n\tvar err error\r\n\tswitch x := value.(type) {\r\n\tcase time.Time:\r\n\t\tt.Time = x\r\n\tcase nil:\r\n\t\tt.Valid = false\r\n\t\treturn nil\r\n\tdefault:\r\n\t\terr = fmt.Errorf(\"null: cannot scan type %T into null.Time: %v\", value, value)\r\n\t}\r\n\tt.Valid = err == nil\r\n\treturn err\r\n}","code-length":135,"reference":"\/\/ Scan implements the Scanner interface.","result":"Scan the value of the time field.","score":[0.1921,0.1639]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t Time) Value() (driver.Value, error) {\r\n\tif !t.Valid {\r\n\t\treturn nil, nil\r\n\t}\r\n\treturn t.Time, nil\r\n}","code-length":57,"reference":"\/\/ Value implements the driver Valuer interface.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTime(t time.Time, valid bool) Time {\r\n\treturn Time{\r\n\t\tTime:  t,\r\n\t\tValid: valid,\r\n\t}\r\n}","code-length":53,"reference":"\/\/ NewTime creates a new Time.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc TimeFromPtr(t *time.Time) Time {\r\n\tif t == nil {\r\n\t\treturn NewTime(time.Time{}, false)\r\n\t}\r\n\treturn NewTime(*t, true)\r\n}","code-length":63,"reference":"\/\/ TimeFromPtr creates a new Time that will be null if t is nil.","result":"Convert pointer to time.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t Time) ValueOrZero() time.Time {\r\n\tif !t.Valid {\r\n\t\treturn time.Time{}\r\n\t}\r\n\treturn t.Time\r\n}","code-length":54,"reference":"\/\/ ValueOrZero returns the inner value if valid, otherwise zero.","result":"Store the value of the time in the database.","score":[0.1297,0.101]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t Time) MarshalJSON() ([]byte, error) {\r\n\tif !t.Valid {\r\n\t\treturn []byte(\"null\"), nil\r\n\t}\r\n\treturn t.Time.MarshalJSON()\r\n}","code-length":61,"reference":"\/\/ MarshalJSON implements json.Marshaler.\n\/\/ It will encode null if this time is null.","result":"Serialize time objects.","score":[0.0104,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Time) SetValid(v time.Time) {\r\n\tt.Time = v\r\n\tt.Valid = true\r\n}","code-length":43,"reference":"\/\/ SetValid changes this Time's value and sets it to be non-null.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t Time) Ptr() *time.Time {\r\n\tif !t.Valid {\r\n\t\treturn nil\r\n\t}\r\n\treturn &t.Time\r\n}","code-length":51,"reference":"\/\/ Ptr returns a pointer to this Time's value, or a nil pointer if this Time is null.","result":"Generate the pointer to a time object.","score":[0.0525,0.1183]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewBool(b bool, valid bool) Bool {\r\n\treturn Bool{\r\n\t\tNullBool: sql.NullBool{\r\n\t\t\tBool:  b,\r\n\t\t\tValid: valid,\r\n\t\t},\r\n\t}\r\n}","code-length":68,"reference":"\/\/ NewBool creates a new Bool","result":"Create a new bool.","score":[0.274,0.5077]}
{"code":"\/*is used to<extra_id_0>\r\nfunc BoolFromPtr(b *bool) Bool {\r\n\tif b == nil {\r\n\t\treturn NewBool(false, false)\r\n\t}\r\n\treturn NewBool(*b, true)\r\n}","code-length":58,"reference":"\/\/ BoolFromPtr creates a new Bool that will be null if f is nil.","result":"Create a new function to convert a bool to a bool.","score":[0.1054,0.146]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Bool) UnmarshalJSON(data []byte) error {\r\n\tvar err error\r\n\tvar v interface{}\r\n\tif err = json.Unmarshal(data, &v); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tswitch x := v.(type) {\r\n\tcase bool:\r\n\t\tb.Bool = x\r\n\tcase map[string]interface{}:\r\n\t\terr = json.Unmarshal(data, &b.NullBool)\r\n\tcase nil:\r\n\t\tb.Valid = false\r\n\t\treturn nil\r\n\tdefault:\r\n\t\terr = fmt.Errorf(\"json: cannot unmarshal %v into Go value of type null.Bool\", reflect.TypeOf(v).Name())\r\n\t}\r\n\tb.Valid = err == nil\r\n\treturn err\r\n}","code-length":203,"reference":"\/\/ UnmarshalJSON implements json.Unmarshaler.\n\/\/ It supports number and null input.\n\/\/ 0 will not be considered a null Bool.\n\/\/ It also supports unmarshalling a sql.NullBool.","result":"Unmarshal a JSON bool value.","score":[0.003,0.0202]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Bool) UnmarshalText(text []byte) error {\r\n\tstr := string(text)\r\n\tswitch str {\r\n\tcase \"\", \"null\":\r\n\t\tb.Valid = false\r\n\t\treturn nil\r\n\tcase \"true\":\r\n\t\tb.Bool = true\r\n\tcase \"false\":\r\n\t\tb.Bool = false\r\n\tdefault:\r\n\t\tb.Valid = false\r\n\t\treturn errors.New(\"invalid input:\" + str)\r\n\t}\r\n\tb.Valid = true\r\n\treturn nil\r\n}","code-length":143,"reference":"\/\/ UnmarshalText implements encoding.TextUnmarshaler.\n\/\/ It will unmarshal to a null Bool if the input is a blank or not an integer.\n\/\/ It will return an error if the input is not an integer, blank, or \"null\".","result":"Unmarshal the text into a bool.","score":[0.0011,0.0431]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b Bool) MarshalJSON() ([]byte, error) {\r\n\tif !b.Valid {\r\n\t\treturn []byte(\"null\"), nil\r\n\t}\r\n\tif !b.Bool {\r\n\t\treturn []byte(\"false\"), nil\r\n\t}\r\n\treturn []byte(\"true\"), nil\r\n}","code-length":87,"reference":"\/\/ MarshalJSON implements json.Marshaler.\n\/\/ It will encode null if this Bool is null.","result":"Serialize Bool objects.","score":[0.0104,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Bool) SetValid(v bool) {\r\n\tb.Bool = v\r\n\tb.Valid = true\r\n}","code-length":41,"reference":"\/\/ SetValid changes this Bool's value and also sets it to be non-null.","result":"Set the valid flag.","score":[0,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewString(s string, valid bool) String {\r\n\treturn String{\r\n\t\tNullString: sql.NullString{\r\n\t\t\tString: s,\r\n\t\t\tValid:  valid,\r\n\t\t},\r\n\t}\r\n}","code-length":67,"reference":"\/\/ NewString creates a new String","result":"Generate the generated SQL.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *String) UnmarshalJSON(data []byte) error {\r\n\tvar err error\r\n\tvar v interface{}\r\n\tif err = json.Unmarshal(data, &v); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tswitch x := v.(type) {\r\n\tcase string:\r\n\t\ts.String = x\r\n\tcase map[string]interface{}:\r\n\t\terr = json.Unmarshal(data, &s.NullString)\r\n\tcase nil:\r\n\t\ts.Valid = false\r\n\t\treturn nil\r\n\tdefault:\r\n\t\terr = fmt.Errorf(\"json: cannot unmarshal %v into Go value of type zero.String\", reflect.TypeOf(v).Name())\r\n\t}\r\n\ts.Valid = (err == nil) && (s.String != \"\")\r\n\treturn err\r\n}","code-length":213,"reference":"\/\/ UnmarshalJSON implements json.Unmarshaler.\n\/\/ It supports string and null input. Blank string input produces a null String.\n\/\/ It also supports unmarshalling a sql.NullString.","result":"Unmarshal a JSON string into a string object.","score":[0.0235,0.0858]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s String) MarshalText() ([]byte, error) {\r\n\tif !s.Valid {\r\n\t\treturn []byte{}, nil\r\n\t}\r\n\treturn []byte(s.String), nil\r\n}","code-length":62,"reference":"\/\/ MarshalText implements encoding.TextMarshaler.\n\/\/ It will encode a blank string when this String is null.","result":"Marshal the string.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *String) UnmarshalText(text []byte) error {\r\n\ts.String = string(text)\r\n\ts.Valid = s.String != \"\"\r\n\treturn nil\r\n}","code-length":55,"reference":"\/\/ UnmarshalText implements encoding.TextUnmarshaler.\n\/\/ It will unmarshal to a null String if the input is a blank string.","result":"Parse the text into a string.","score":[0.0291,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *String) SetValid(v string) {\r\n\ts.String = v\r\n\ts.Valid = true\r\n}","code-length":41,"reference":"\/\/ SetValid changes this String's value and also sets it to be non-null.","result":"Validate the string.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StringFromPtr(s *string) String {\r\n\tif s == nil {\r\n\t\treturn NewString(\"\", false)\r\n\t}\r\n\treturn NewString(*s, true)\r\n}","code-length":55,"reference":"\/\/ StringFromPtr creates a new String that be null if s is nil.","result":"Convert string to string.","score":[0,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s String) MarshalJSON() ([]byte, error) {\r\n\tif !s.Valid {\r\n\t\treturn []byte(\"null\"), nil\r\n\t}\r\n\treturn json.Marshal(s.String)\r\n}","code-length":63,"reference":"\/\/ MarshalJSON implements json.Marshaler.\n\/\/ It will encode null if this String is null.","result":"Serialize the string to json.","score":[0,0.0382]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewInt(i int64, valid bool) Int {\r\n\treturn Int{\r\n\t\tNullInt64: sql.NullInt64{\r\n\t\t\tInt64: i,\r\n\t\t\tValid: valid,\r\n\t\t},\r\n\t}\r\n}","code-length":70,"reference":"\/\/ NewInt creates a new Int","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IntFromPtr(i *int64) Int {\r\n\tif i == nil {\r\n\t\treturn NewInt(0, false)\r\n\t}\r\n\tn := NewInt(*i, true)\r\n\treturn n\r\n}","code-length":63,"reference":"\/\/ IntFromPtr creates a new Int that be null if i is nil.","result":"Create a new Int from a pointer to a int.","score":[0.1657,0.2485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *Int) UnmarshalJSON(data []byte) error {\r\n\tvar err error\r\n\tvar v interface{}\r\n\tif err = json.Unmarshal(data, &v); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tswitch x := v.(type) {\r\n\tcase float64:\r\n\t\t\r\n\t\terr = json.Unmarshal(data, &i.Int64)\r\n\tcase string:\r\n\t\tstr := string(x)\r\n\t\tif len(str) == 0 {\r\n\t\t\ti.Valid = false\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\ti.Int64, err = strconv.ParseInt(str, 10, 64)\r\n\tcase map[string]interface{}:\r\n\t\terr = json.Unmarshal(data, &i.NullInt64)\r\n\tcase nil:\r\n\t\ti.Valid = false\r\n\t\treturn nil\r\n\tdefault:\r\n\t\terr = fmt.Errorf(\"json: cannot unmarshal %v into Go value of type zero.Int\", reflect.TypeOf(v).Name())\r\n\t}\r\n\ti.Valid = (err == nil) && (i.Int64 != 0)\r\n\treturn err\r\n}","code-length":298,"reference":"\/\/ UnmarshalJSON implements json.Unmarshaler.\n\/\/ It supports number and null input.\n\/\/ 0 will be considered a null Int.\n\/\/ It also supports unmarshalling a sql.NullInt64.","result":"Prevent recursive call to UnmarshalJSON .","score":[0.0069,0.0208]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i Int) MarshalText() ([]byte, error) {\r\n\tn := i.Int64\r\n\tif !i.Valid {\r\n\t\tn = 0\r\n\t}\r\n\treturn []byte(strconv.FormatInt(n, 10)), nil\r\n}","code-length":75,"reference":"\/\/ MarshalText implements encoding.TextMarshaler.\n\/\/ It will encode a zero if this Int is null.","result":"Marshal the text.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *Int) SetValid(n int64) {\r\n\ti.Int64 = n\r\n\ti.Valid = true\r\n}","code-length":43,"reference":"\/\/ SetValid changes this Int's value and also sets it to be non-null.","result":"Set the valid value.","score":[0,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *Int) UnmarshalText(text []byte) error {\r\n\tstr := string(text)\r\n\tif str == \"\" || str == \"null\" {\r\n\t\ti.Valid = false\r\n\t\treturn nil\r\n\t}\r\n\tvar err error\r\n\ti.Int64, err = strconv.ParseInt(string(text), 10, 64)\r\n\ti.Valid = err == nil\r\n\treturn err\r\n}","code-length":113,"reference":"\/\/ UnmarshalText implements encoding.TextUnmarshaler.\n\/\/ It will unmarshal to a null Int if the input is a blank or not an integer.\n\/\/ It will return an error if the input is not an integer, blank, or \"null\".","result":"Unmarshal the text into a .","score":[0.0011,0.0431]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b Bool) MarshalText() ([]byte, error) {\r\n\tif !b.Valid || !b.Bool {\r\n\t\treturn []byte(\"false\"), nil\r\n\t}\r\n\treturn []byte(\"true\"), nil\r\n}","code-length":68,"reference":"\/\/ MarshalText implements encoding.TextMarshaler.\n\/\/ It will encode a zero if this Bool is null.","result":"Marshal the bool.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *Float) SetValid(v float64) {\r\n\tf.Float64 = v\r\n\tf.Valid = true\r\n}","code-length":43,"reference":"\/\/ SetValid changes this Float's value and also sets it to be non-null.","result":"Set the valid flag in the code.","score":[0,0.0403]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t Time) MarshalJSON() ([]byte, error) {\r\n\tif !t.Valid {\r\n\t\treturn (time.Time{}).MarshalJSON()\r\n\t}\r\n\treturn t.Time.MarshalJSON()\r\n}","code-length":62,"reference":"\/\/ MarshalJSON implements json.Marshaler.\n\/\/ It will encode the zero value of time.Time\n\/\/ if this time is invalid.","result":"Serialize time objects.","score":[0.002,0.0287]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *Float) UnmarshalJSON(data []byte) error {\r\n\tvar err error\r\n\tvar v interface{}\r\n\tif err = json.Unmarshal(data, &v); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tswitch x := v.(type) {\r\n\tcase float64:\r\n\t\tf.Float64 = float64(x)\r\n\tcase string:\r\n\t\tstr := string(x)\r\n\t\tif len(str) == 0 {\r\n\t\t\tf.Valid = false\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tf.Float64, err = strconv.ParseFloat(str, 64)\r\n\tcase map[string]interface{}:\r\n\t\terr = json.Unmarshal(data, &f.NullFloat64)\r\n\tcase nil:\r\n\t\tf.Valid = false\r\n\t\treturn nil\r\n\tdefault:\r\n\t\terr = fmt.Errorf(\"json: cannot unmarshal %v into Go value of type null.Float\", reflect.TypeOf(v).Name())\r\n\t}\r\n\tf.Valid = err == nil\r\n\treturn err\r\n}","code-length":278,"reference":"\/\/ UnmarshalJSON implements json.Unmarshaler.\n\/\/ It supports number and null input.\n\/\/ 0 will not be considered a null Float.\n\/\/ It also supports unmarshalling a sql.NullFloat64.","result":"Prevent recursive call to UnmarshalJSON .","score":[0.0058,0.0201]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *Float) UnmarshalText(text []byte) error {\r\n\tstr := string(text)\r\n\tif str == \"\" || str == \"null\" {\r\n\t\tf.Valid = false\r\n\t\treturn nil\r\n\t}\r\n\tvar err error\r\n\tf.Float64, err = strconv.ParseFloat(string(text), 64)\r\n\tf.Valid = err == nil\r\n\treturn err\r\n}","code-length":111,"reference":"\/\/ UnmarshalText implements encoding.TextUnmarshaler.\n\/\/ It will unmarshal to a null Float if the input is a blank or not an integer.\n\/\/ It will return an error if the input is not an integer, blank, or \"null\".","result":"Unmarshal JSON.","score":[0,0.0145]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f Float) MarshalJSON() ([]byte, error) {\r\n\tif !f.Valid {\r\n\t\treturn []byte(\"null\"), nil\r\n\t}\r\n\tif math.IsInf(f.Float64, 0) || math.IsNaN(f.Float64) {\r\n\t\treturn nil, &json.UnsupportedValueError{\r\n\t\t\tValue: reflect.ValueOf(f.Float64),\r\n\t\t\tStr:   strconv.FormatFloat(f.Float64, 'g', -1, 64),\r\n\t\t}\r\n\t}\r\n\treturn []byte(strconv.FormatFloat(f.Float64, 'f', -1, 64)), nil\r\n}","code-length":170,"reference":"\/\/ MarshalJSON implements json.Marshaler.\n\/\/ It will encode null if this Float is null.","result":"Serialize the JSON string representation of a float.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newGossipChannel(channelName string, ourself *localPeer, r *routes, g Gossiper, logger Logger) *gossipChannel {\r\n\treturn &gossipChannel{\r\n\t\tname:     channelName,\r\n\t\tourself:  ourself,\r\n\t\troutes:   r,\r\n\t\tgossiper: g,\r\n\t\tlogger:   logger,\r\n\t}\r\n}","code-length":107,"reference":"\/\/ newGossipChannel returns a named, usable channel.\n\/\/ It delegates receiving duties to the passed Gossiper.","result":"Create a new channel.","score":[0.0189,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *gossipChannel) GossipUnicast(dstPeerName PeerName, msg []byte) error {\r\n\treturn c.relayUnicast(dstPeerName, gobEncode(c.name, c.ourself.Name, dstPeerName, msg))\r\n}","code-length":71,"reference":"\/\/ GossipUnicast implements Gossip, relaying msg to dst, which must be a\n\/\/ member of the channel.","result":"Implement the following code.","score":[0.0124,0.0955]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *gossipChannel) GossipBroadcast(update GossipData) {\r\n\tc.relayBroadcast(c.ourself.Name, update)\r\n}","code-length":46,"reference":"\/\/ GossipBroadcast implements Gossip, relaying update to all members of the\n\/\/ channel.","result":"Broadcast gossip data.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *gossipChannel) Send(data GossipData) {\r\n\tc.relay(c.ourself.Name, data)\r\n}","code-length":44,"reference":"\/\/ Send relays data into the channel topology via random neighbours.","result":"Send data to the channel.","score":[0.0952,0.1442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *gossipChannel) SendDown(conn Connection, data GossipData) {\r\n\tc.senderFor(conn).Send(data)\r\n}","code-length":45,"reference":"\/\/ SendDown relays data into the channel topology via conn.","result":"Generate the code.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc gobEncode(items ...interface{}) []byte {\r\n\tbuf := new(bytes.Buffer)\r\n\tenc := gob.NewEncoder(buf)\r\n\tfor _, i := range items {\r\n\t\tif err := enc.Encode(i); err != nil {\r\n\t\t\tpanic(err)\r\n\t\t}\r\n\t}\r\n\treturn buf.Bytes()\r\n}","code-length":101,"reference":"\/\/ GobEncode gob-encodes each item and returns the resulting byte slice.","result":"Encode a list of items to a byte array.","score":[0.0976,0.0926]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newTokenBucket(capacity int64, tokenInterval time.Duration) *tokenBucket {\r\n\ttb := tokenBucket{\r\n\t\tcapacity:       capacity,\r\n\t\ttokenInterval:  tokenInterval,\r\n\t\trefillDuration: tokenInterval * time.Duration(capacity)}\r\n\ttb.earliestUnspentToken = tb.capacityToken()\r\n\treturn &tb\r\n}","code-length":98,"reference":"\/\/ newTokenBucket returns a bucket containing capacity tokens, refilled at a\n\/\/ rate of one token per tokenInterval.","result":"Create a new token bucket.","score":[0.0212,0.0599]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tb *tokenBucket) wait() {\r\n\t\r\n\ttime.Sleep(time.Until(tb.earliestUnspentToken))\r\n\t\r\n\tcapacityToken := tb.capacityToken()\r\n\tif tb.earliestUnspentToken.Before(capacityToken) {\r\n\t\ttb.earliestUnspentToken = capacityToken\r\n\t}\r\n\t\r\n\ttb.earliestUnspentToken = tb.earliestUnspentToken.Add(tb.tokenInterval)\r\n}","code-length":123,"reference":"\/\/ Blocks until there is a token available.\n\/\/ Not safe for concurrent use by multiple goroutines.","result":"Wait for the wait function.","score":[0.0218,0.0316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tb *tokenBucket) capacityToken() time.Time {\r\n\treturn time.Now().Add(-tb.refillDuration).Truncate(tb.tokenInterval)\r\n}","code-length":49,"reference":"\/\/ Determine the historic token timestamp representing a full bucket","result":"Generate the code.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PrefixRangeEnd(prefix []byte) []byte {\r\n\tr i := len(end) - 1; i >= 0; i-- {\r\n\t\tif end[i] < 0xff {\r\n\t\t\tend[i] = end[i] + 1\r\n\t\t\tend = end[:i+1]\r\n\t\t\treturn end\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\treturn []byte{0}\r\n}","code-length":114,"reference":"\/\/ PrefixRangeEnd allows Get, Delete, and Watch requests to operate on all keys\n\/\/ with a matching prefix. Pass the prefix to this function, and use the result\n\/\/ as the RangeEnd value.","result":"Generate the prefix range end .","score":[0.003,0.033]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newLocalPeer(name PeerName, nickName string, router *Router) *localPeer {\r\n\tactionChan := make(chan localPeerAction, ChannelSize)\r\n\tpeer := &localPeer{\r\n\t\tPeer:       newPeer(name, nickName, randomPeerUID(), 0, randomPeerShortID()),\r\n\t\trouter:     router,\r\n\t\tactionChan: actionChan,\r\n\t}\r\n\tgo peer.actorLoop(actionChan)\r\n\treturn peer\r\n}","code-length":125,"reference":"\/\/ newLocalPeer returns a usable LocalPeer.","result":"Create a new local peer.","score":[0.1967,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (peer *localPeer) getConnections() connectionSet {\r\n\tconnections := make(connectionSet)\r\n\tpeer.RLock()\r\n\tdefer peer.RUnlock()\r\n\tfor _, conn := range peer.connections {\r\n\t\tconnections[conn] = struct{}{}\r\n\t}\r\n\treturn connections\r\n}","code-length":86,"reference":"\/\/ Connections returns all the connections that the local peer is aware of.","result":"Get the set of connections for all peers.","score":[0.0978,0.12]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (peer *localPeer) createConnection(localAddr string, peerAddr string, acceptNewPeer bool, logger Logger) error {\r\n\tif err := peer.checkConnectionLimit(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tlocalTCPAddr, err := net.ResolveTCPAddr(\"tcp\", localAddr)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tremoteTCPAddr, err := net.ResolveTCPAddr(\"tcp\", peerAddr)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ttcpConn, err := net.DialTCP(\"tcp\", localTCPAddr, remoteTCPAddr)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tconnRemote := newRemoteConnection(peer.Peer, nil, peerAddr, true, false)\r\n\tstartLocalConnection(connRemote, tcpConn, peer.router, acceptNewPeer, logger)\r\n\treturn nil\r\n}","code-length":233,"reference":"\/\/ createConnection creates a new connection, originating from\n\/\/ localAddr, to peerAddr. If acceptNewPeer is false, peerAddr must\n\/\/ already be a member of the mesh.","result":"Create a new connection.","score":[0.0018,0.063]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (peer *localPeer) doAddConnection(conn ourConnection, isRestartedPeer bool) error {\r\n\tresultChan := make(chan error)\r\n\tpeer.actionChan <- func() {\r\n\t\tresultChan <- peer.handleAddConnection(conn, isRestartedPeer)\r\n\t}\r\n\treturn <-resultChan\r\n}","code-length":88,"reference":"\/\/ ACTOR client API\n\/\/ Synchronous.","result":"Create a new connection.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc startLocalConnection(connRemote *remoteConnection, tcpConn *net.TCPConn, router *Router, acceptNewPeer bool, logger Logger) {\r\n\tif connRemote.local != router.Ourself.Peer {\r\n\t\tpanic(\"attempt to create local connection from a peer which is not ourself\")\r\n\t}\r\n\terrorChan := make(chan error, 1)\r\n\tfinished := make(chan struct{})\r\n\tconn := &LocalConnection{\r\n\t\tremoteConnection: *connRemote,\r\n\t\trouter:           router,\r\n\t\ttcpConn:          tcpConn,\r\n\t\ttrustRemote:      router.trusts(connRemote),\r\n\t\tuid:              randUint64(),\r\n\t\terrorChan:        errorChan,\r\n\t\tfinished:         finished,\r\n\t\tlogger:           logger,\r\n\t}\r\n\tconn.senders = newGossipSenders(conn, finished)\r\n\tgo conn.run(errorChan, finished, acceptNewPeer)\r\n}","code-length":245,"reference":"\/\/ If the connection is successful, it will end up in the local peer's\n\/\/ connections map.","result":"Start a new local connection.","score":[0.0218,0.0316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (conn *LocalConnection) SendProtocolMsg(m protocolMsg) error {\r\n\tif err := conn.sendProtocolMsg(m); err != nil {\r\n\t\tconn.shutdown(err)\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":72,"reference":"\/\/ SendProtocolMsg implements ProtocolSender.","result":"Send messages to the remote server.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewStatus(router *Router) *Status {\r\n\treturn &Status{\r\n\t\tProtocol:           Protocol,\r\n\t\tProtocolMinVersion: int(router.ProtocolMinVersion),\r\n\t\tProtocolMaxVersion: ProtocolMaxVersion,\r\n\t\tEncryption:         router.usingPassword(),\r\n\t\tPeerDiscovery:      router.PeerDiscovery,\r\n\t\tName:               router.Ourself.Name.String(),\r\n\t\tNickName:           router.Ourself.NickName,\r\n\t\tPort:               router.Port,\r\n\t\tPeers:              makePeerStatusSlice(router.Peers),\r\n\t\tUnicastRoutes:      makeUnicastRouteStatusSlice(router.Routes),\r\n\t\tBroadcastRoutes:    makeBroadcastRouteStatusSlice(router.Routes),\r\n\t\tConnections:        makeLocalConnectionStatusSlice(router.ConnectionMaker),\r\n\t\tTerminationCount:   router.ConnectionMaker.terminationCount,\r\n\t\tTargets:            router.ConnectionMaker.Targets(false),\r\n\t\tOverlayDiagnostics: router.Overlay.Diagnostics(),\r\n\t\tTrustedSubnets:     makeTrustedSubnetsSlice(router.TrustedSubnets),\r\n\t}\r\n}","code-length":279,"reference":"\/\/ NewStatus returns a Status object, taken as a snapshot from the router.","result":"Create a new status object.","score":[0.0485,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc makePeerStatusSlice(peers *Peers) []PeerStatus {\r\n\tvar slice []PeerStatus\r\n\tpeers.forEach(func(peer *Peer) {\r\n\t\tvar connections []connectionStatus\r\n\t\tif peer == peers.ourself.Peer {\r\n\t\t\tfor conn := range peers.ourself.getConnections() {\r\n\t\t\t\tconnections = append(connections, makeConnectionStatus(conn))\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfor _, conn := range peer.connections {\r\n\t\t\t\tconnections = append(connections, makeConnectionStatus(conn))\r\n\t\t\t}\r\n\t\t}\r\n\t\tslice = append(slice, PeerStatus{\r\n\t\t\tpeer.Name.String(),\r\n\t\t\tpeer.NickName,\r\n\t\t\tpeer.UID,\r\n\t\t\tpeer.ShortID,\r\n\t\t\tpeer.Version,\r\n\t\t\tconnections,\r\n\t\t})\r\n\t})\r\n\treturn slice\r\n}","code-length":243,"reference":"\/\/ makePeerStatusSlice takes a snapshot of the state of peers.","result":"Create a slice of peer statuses.","score":[0.1179,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc makeUnicastRouteStatusSlice(r *routes) []unicastRouteStatus {\r\n\tr.RLock()\r\n\tdefer r.RUnlock()\r\n\tvar slice []unicastRouteStatus\r\n\tfor dest, via := range r.unicast {\r\n\t\tslice = append(slice, unicastRouteStatus{dest.String(), via.String()})\r\n\t}\r\n\treturn slice\r\n}","code-length":104,"reference":"\/\/ makeUnicastRouteStatusSlice takes a snapshot of the unicast routes in routes.","result":"Make a slice of unicast route statuses.","score":[0.12,0.4208]}
{"code":"\/*is used to<extra_id_0>\r\nfunc makeBroadcastRouteStatusSlice(r *routes) []broadcastRouteStatus {\r\n\tr.RLock()\r\n\tdefer r.RUnlock()\r\n\tvar slice []broadcastRouteStatus\r\n\tfor source, via := range r.broadcast {\r\n\t\tvar hops []string\r\n\t\tfor _, hop := range via {\r\n\t\t\thops = append(hops, hop.String())\r\n\t\t}\r\n\t\tslice = append(slice, broadcastRouteStatus{source.String(), hops})\r\n\t}\r\n\treturn slice\r\n}","code-length":139,"reference":"\/\/ makeBroadcastRouteStatusSlice takes a snapshot of the broadcast routes in routes.","result":"Create a slice of broadcast route statuses.","score":[0.12,0.2978]}
{"code":"\/*is used to<extra_id_0>\r\nfunc makeLocalConnectionStatusSlice(cm *connectionMaker) []LocalConnectionStatus {\r\n\tresultChan := make(chan []LocalConnectionStatus)\r\n\tcm.actionChan <- func() bool {\r\n\t\tvar slice []LocalConnectionStatus\r\n\t\tfor conn := range cm.connections {\r\n\t\t\tstate := \"pending\"\r\n\t\t\tif conn.isEstablished() {\r\n\t\t\t\tstate = \"established\"\r\n\t\t\t}\r\n\t\t\tlc, _ := conn.(*LocalConnection)\r\n\t\t\tattrs := lc.OverlayConn.Attrs()\r\n\t\t\tname, ok := attrs[\"name\"]\r\n\t\t\tif !ok {\r\n\t\t\t\tname = \"none\"\r\n\t\t\t}\r\n\t\t\tinfo := fmt.Sprintf(\"%-6v %v\", name, conn.Remote())\r\n\t\t\tif lc.router.usingPassword() {\r\n\t\t\t\tif lc.untrusted() {\r\n\t\t\t\t\tinfo = fmt.Sprintf(\"%-11v %v\", \"encrypted\", info)\r\n\t\t\t\t\tif attrs != nil {\r\n\t\t\t\t\t\tattrs[\"encrypted\"] = true\r\n\t\t\t\t\t}\r\n\t\t\t\t} else {\r\n\t\t\t\t\tinfo = fmt.Sprintf(\"%-11v %v\", \"unencrypted\", info)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tslice = append(slice, LocalConnectionStatus{conn.remoteTCPAddress(), conn.isOutbound(), state, info, attrs})\r\n\t\t}\r\n\t\tfor address, target := range cm.targets {\r\n\t\t\tadd := func(state, info string) {\r\n\t\t\t\tslice = append(slice, LocalConnectionStatus{address, true, state, info, nil})\r\n\t\t\t}\r\n\t\t\tswitch target.state {\r\n\t\t\tcase targetWaiting:\r\n\t\t\t\tuntil := \"never\"\r\n\t\t\t\tif !target.tryAfter.IsZero() {\r\n\t\t\t\t\tuntil = target.tryAfter.String()\r\n\t\t\t\t}\r\n\t\t\t\tif target.lastError == nil {\r\n\t\t\t\t\tadd(\"waiting\", \"until: \"+until)\r\n\t\t\t\t} else {\r\n\t\t\t\t\tadd(\"failed\", target.lastError.Error()+\", retry: \"+until)\r\n\t\t\t\t}\r\n\t\t\tcase targetAttempting:\r\n\t\t\t\tif target.lastError == nil {\r\n\t\t\t\t\tadd(\"connecting\", \"\")\r\n\t\t\t\t} else {\r\n\t\t\t\t\tadd(\"retrying\", target.lastError.Error())\r\n\t\t\t\t}\r\n\t\t\tcase targetConnected:\r\n\t\t\tcase targetSuspended:\r\n\t\t\t}\r\n\t\t}\r\n\t\tresultChan <- slice\r\n\t\treturn false\r\n\t}\r\n\treturn <-resultChan\r\n}","code-length":633,"reference":"\/\/ makeLocalConnectionStatusSlice takes a snapshot of the active local\n\/\/ connections in the ConnectionMaker.","result":"Code too long,keep in 512.","score":[0.0397,0.0382]}
{"code":"\/*is used to<extra_id_0>\r\nfunc makeTrustedSubnetsSlice(trustedSubnets []*net.IPNet) []string {\r\n\ttrustedSubnetStrs := []string{}\r\n\tfor _, trustedSubnet := range trustedSubnets {\r\n\t\ttrustedSubnetStrs = append(trustedSubnetStrs, trustedSubnet.String())\r\n\t}\r\n\treturn trustedSubnetStrs\r\n}","code-length":83,"reference":"\/\/ makeTrustedSubnetsSlice makes a human-readable copy of the trustedSubnets.","result":"Make the list of trusted subnets in the function.","score":[0.1449,0.1667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *etcdStore) Range(ctx context.Context, req *etcdserverpb.RangeRequest) (*etcdserverpb.RangeResponse, error) {\r\n\tireq := etcdserverpb.InternalRaftRequest{ID: <-s.idgen, Range: req}\r\n\tmsgc, errc, err := s.proposeInternalRaftRequest(ireq)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tselect {\r\n\tcase <-ctx.Done():\r\n\t\ts.cancelInternalRaftRequest(ireq)\r\n\t\treturn nil, ctx.Err()\r\n\tcase msg := <-msgc:\r\n\t\treturn msg.(*etcdserverpb.RangeResponse), nil\r\n\tcase err := <-errc:\r\n\t\treturn nil, err\r\n\tcase <-s.quitc:\r\n\t\treturn nil, errStopped\r\n\t}\r\n}","code-length":228,"reference":"\/\/ Range implements gRPC KVServer.\n\/\/ Range gets the keys in the range from the store.","result":"Avoid the need for the following line.","score":[0.0531,0.0662]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *etcdStore) Put(ctx context.Context, req *etcdserverpb.PutRequest) (*etcdserverpb.PutResponse, error) {\r\n\tireq := etcdserverpb.InternalRaftRequest{ID: <-s.idgen, Put: req}\r\n\tmsgc, errc, err := s.proposeInternalRaftRequest(ireq)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tselect {\r\n\tcase <-ctx.Done():\r\n\t\ts.cancelInternalRaftRequest(ireq)\r\n\t\treturn nil, ctx.Err()\r\n\tcase msg := <-msgc:\r\n\t\treturn msg.(*etcdserverpb.PutResponse), nil\r\n\tcase err := <-errc:\r\n\t\treturn nil, err\r\n\tcase <-s.quitc:\r\n\t\treturn nil, errStopped\r\n\t}\r\n}","code-length":228,"reference":"\/\/ Put implements gRPC KVServer.\n\/\/ Put puts the given key into the store.\n\/\/ A put request increases the revision of the store,\n\/\/ and generates one event in the event history.","result":"Avoid the need for the following code.","score":[0.0047,0.0329]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *etcdStore) DeleteRange(ctx context.Context, req *etcdserverpb.DeleteRangeRequest) (*etcdserverpb.DeleteRangeResponse, error) {\r\n\tireq := etcdserverpb.InternalRaftRequest{ID: <-s.idgen, DeleteRange: req}\r\n\tmsgc, errc, err := s.proposeInternalRaftRequest(ireq)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tselect {\r\n\tcase <-ctx.Done():\r\n\t\ts.cancelInternalRaftRequest(ireq)\r\n\t\treturn nil, ctx.Err()\r\n\tcase msg := <-msgc:\r\n\t\treturn msg.(*etcdserverpb.DeleteRangeResponse), nil\r\n\tcase err := <-errc:\r\n\t\treturn nil, err\r\n\tcase <-s.quitc:\r\n\t\treturn nil, errStopped\r\n\t}\r\n}","code-length":233,"reference":"\/\/ Delete implements gRPC KVServer.\n\/\/ Delete deletes the given range from the store.\n\/\/ A delete request increase the revision of the store,\n\/\/ and generates one event in the event history.","result":"Avoid the need for the following code.","score":[0.0047,0.0329]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *etcdStore) Txn(ctx context.Context, req *etcdserverpb.TxnRequest) (*etcdserverpb.TxnResponse, error) {\r\n\tireq := etcdserverpb.InternalRaftRequest{ID: <-s.idgen, Txn: req}\r\n\tmsgc, errc, err := s.proposeInternalRaftRequest(ireq)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tselect {\r\n\tcase <-ctx.Done():\r\n\t\ts.cancelInternalRaftRequest(ireq)\r\n\t\treturn nil, ctx.Err()\r\n\tcase msg := <-msgc:\r\n\t\treturn msg.(*etcdserverpb.TxnResponse), nil\r\n\tcase err := <-errc:\r\n\t\treturn nil, err\r\n\tcase <-s.quitc:\r\n\t\treturn nil, errStopped\r\n\t}\r\n}","code-length":228,"reference":"\/\/ Txn implements gRPC KVServer.\n\/\/ Txn processes all the requests in one transaction.\n\/\/ A txn request increases the revision of the store,\n\/\/ and generates events with the same revision in the event history.\n\/\/ It is not allowed to modify the same key several times within one txn.","result":"Avoid the need for the following code.","score":[0.0004,0.0215]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *etcdStore) Compact(ctx context.Context, req *etcdserverpb.CompactionRequest) (*etcdserverpb.CompactionResponse, error) {\r\n\t\r\n\t\r\n\treturn nil, errors.New(\"not implemented\")\r\n}","code-length":71,"reference":"\/\/ Compact implements gRPC KVServer.\n\/\/ Compact compacts the event history in s. User should compact the\n\/\/ event history periodically, or it will grow infinitely.","result":"Generate the generated code.","score":[0.0013,0.021]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *etcdStore) proposeInternalRaftRequest(req etcdserverpb.InternalRaftRequest) (<-chan proto.Message, <-chan error, error) {\r\n\tdata, err := req.Marshal()\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\tif len(data) > maxRequestBytes {\r\n\t\treturn nil, nil, errTooBig\r\n\t}\r\n\tmsgc, errc, err := s.registerPending(req.ID)\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\ts.proposalc <- data\r\n\treturn msgc, errc, nil\r\n}","code-length":177,"reference":"\/\/ From public API method to proposalc.","result":"Store the proposal in the store.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc applyCompare(kv mvcc.KV, c *etcdserverpb.Compare) (int64, bool) {\r\n\tckvs, rev, err := kv.Range(c.Key, nil, 1, 0)\r\n\tif err != nil {\r\n\t\tif err == mvcc.ErrTxnIDMismatch {\r\n\t\t\tpanic(\"unexpected txn ID mismatch error\")\r\n\t\t}\r\n\t\treturn rev, false\r\n\t}\r\n\tvar ckv mvccpb.KeyValue\r\n\tif len(ckvs) != 0 {\r\n\t\tckv = ckvs[0]\r\n\t} else {\r\n\t\t\r\n\t\tif c.Target == etcdserverpb.Compare_VALUE {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\treturn rev, false\r\n\t\t}\r\n\t}\r\n\t\r\n\tvar result int\r\n\tswitch c.Target {\r\n\tcase etcdserverpb.Compare_VALUE:\r\n\t\ttv, _ := c.TargetUnion.(*etcdserverpb.Compare_Value)\r\n\t\tif tv != nil {\r\n\t\t\tresult = bytes.Compare(ckv.Value, tv.Value)\r\n\t\t}\r\n\tcase etcdserverpb.Compare_CREATE:\r\n\t\ttv, _ := c.TargetUnion.(*etcdserverpb.Compare_CreateRevision)\r\n\t\tif tv != nil {\r\n\t\t\tresult = compareInt64(ckv.CreateRevision, tv.CreateRevision)\r\n\t\t}\r\n\tcase etcdserverpb.Compare_MOD:\r\n\t\ttv, _ := c.TargetUnion.(*etcdserverpb.Compare_ModRevision)\r\n\t\tif tv != nil {\r\n\t\t\tresult = compareInt64(ckv.ModRevision, tv.ModRevision)\r\n\t\t}\r\n\tcase etcdserverpb.Compare_VERSION:\r\n\t\ttv, _ := c.TargetUnion.(*etcdserverpb.Compare_Version)\r\n\t\tif tv != nil {\r\n\t\t\tresult = compareInt64(ckv.Version, tv.Version)\r\n\t\t}\r\n\t}\r\n\tswitch c.Result {\r\n\tcase etcdserverpb.Compare_EQUAL:\r\n\t\tif result != 0 {\r\n\t\t\treturn rev, false\r\n\t\t}\r\n\tcase etcdserverpb.Compare_GREATER:\r\n\t\tif result != 1 {\r\n\t\t\treturn rev, false\r\n\t\t}\r\n\tcase etcdserverpb.Compare_LESS:\r\n\t\tif result != -1 {\r\n\t\t\treturn rev, false\r\n\t\t}\r\n\t}\r\n\treturn rev, true\r\n}","code-length":627,"reference":"\/\/ applyCompare applies the compare request.\n\/\/ It returns the revision at which the comparison happens. If the comparison\n\/\/ succeeds, the it returns true. Otherwise it returns false.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (peers *Peers) Descriptions() []PeerDescription {\r\n\tpeers.RLock()\r\n\tdefer peers.RUnlock()\r\n\tdescriptions := make([]PeerDescription, 0, len(peers.byName))\r\n\tfor _, peer := range peers.byName {\r\n\t\tdescriptions = append(descriptions, PeerDescription{\r\n\t\t\tName:           peer.Name,\r\n\t\t\tNickName:       peer.peerSummary.NickName,\r\n\t\t\tUID:            peer.UID,\r\n\t\t\tSelf:           peer.Name == peers.ourself.Name,\r\n\t\t\tNumConnections: len(peer.connections),\r\n\t\t})\r\n\t}\r\n\treturn descriptions\r\n}","code-length":172,"reference":"\/\/ Descriptions returns descriptions for all known peers.","result":"Return the list of.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (peers *Peers) OnGC(callback func(*Peer)) {\r\n\tpeers.Lock()\r\n\tdefer peers.Unlock()\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tpeers.onGC = append(peers.onGC, callback)\r\n}","code-length":71,"reference":"\/\/ OnGC adds a new function to be set of functions that will be executed on\n\/\/ all subsequent GC runs, receiving the GC'd peer.","result":"Clean up the garbage.","score":[0.0017,0.0218]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (peers *Peers) OnInvalidateShortIDs(callback func()) {\r\n\tpeers.Lock()\r\n\tdefer peers.Unlock()\r\n\t\r\n\tpeers.onInvalidateShortIDs = append(peers.onInvalidateShortIDs, callback)\r\n}","code-length":66,"reference":"\/\/ OnInvalidateShortIDs adds a new function to a set of functions that will be\n\/\/ executed on all subsequent GC runs, when the mapping from short IDs to\n\/\/ peers has changed.","result":"Avoid recursive call to callback .","score":[0.0025,0.017]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (peers *Peers) chooseShortID() (PeerShortID, bool) {\r\n\trng := rand.New(rand.NewSource(int64(randUint64())))\r\n\t\r\n\t\r\n\tfor i := 0; i < 10; i++ {\r\n\t\tshortID := PeerShortID(rng.Intn(1 << peerShortIDBits))\r\n\t\tif peers.byShortID[shortID].peer == nil {\r\n\t\t\treturn shortID, true\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\tavailable := int(1 << peerShortIDBits)\r\n\tfor _, entry := range peers.byShortID {\r\n\t\tif entry.peer != nil {\r\n\t\t\tavailable--\r\n\t\t}\r\n\t}\r\n\tif available == 0 {\r\n\t\t\r\n\t\treturn 0, false\r\n\t}\r\n\tn := rng.Intn(available)\r\n\tvar i PeerShortID\r\n\tfor {\r\n\t\tif peers.byShortID[i].peer == nil {\r\n\t\t\tif n == 0 {\r\n\t\t\t\treturn i, true\r\n\t\t\t}\r\n\t\t\tn--\r\n\t\t}\r\n\t\ti++\r\n\t}\r\n}","code-length":303,"reference":"\/\/ Choose an available short ID at random.","result":"Generate a random short ID for the peer.","score":[0.1964,0.2344]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (peers *Peers) fetchWithDefault(peer *Peer) *Peer {\r\n\tpeers.Lock()\r\n\tvar pending peersPendingNotifications\r\n\tdefer peers.unlockAndNotify(&pending)\r\n\tif existingPeer, found := peers.byName[peer.Name]; found {\r\n\t\texistingPeer.localRefCount++\r\n\t\treturn existingPeer\r\n\t}\r\n\tpeers.byName[peer.Name] = peer\r\n\tpeers.addByShortID(peer, &pending)\r\n\tpeer.localRefCount++\r\n\treturn peer\r\n}","code-length":141,"reference":"\/\/ fetchWithDefault will use reference fields of the passed peer object to\n\/\/ look up and return an existing, matching peer. If no matching peer is\n\/\/ found, the passed peer is saved and returned.","result":"Fetch default peers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (peers *Peers) Fetch(name PeerName) *Peer {\r\n\tpeers.RLock()\r\n\tdefer peers.RUnlock()\r\n\treturn peers.byName[name]\r\n}","code-length":55,"reference":"\/\/ Fetch returns a peer matching the passed name, without incrementing its\n\/\/ refcount. If no matching peer is found, Fetch returns nil.","result":"Fetch peers.","score":[0.0,0.0239]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (peers *Peers) fetchAndAddRef(name PeerName) *Peer {\r\n\tpeers.Lock()\r\n\tdefer peers.Unlock()\r\n\tpeer := peers.byName[name]\r\n\tif peer != nil {\r\n\t\tpeer.localRefCount++\r\n\t}\r\n\treturn peer\r\n}","code-length":84,"reference":"\/\/ Like fetch, but increments local refcount.","result":"Fetch and add a peer reference.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (peers *Peers) FetchByShortID(shortID PeerShortID) *Peer {\r\n\tpeers.RLock()\r\n\tdefer peers.RUnlock()\r\n\treturn peers.byShortID[shortID].peer\r\n}","code-length":63,"reference":"\/\/ FetchByShortID returns a peer matching the passed short ID.\n\/\/ If no matching peer is found, FetchByShortID returns nil.","result":"Fetch peers by short id.","score":[0.012,0.1381]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (peers *Peers) GarbageCollect() {\r\n\tpeers.Lock()\r\n\tvar pending peersPendingNotifications\r\n\tdefer peers.unlockAndNotify(&pending)\r\n\tpeers.garbageCollect(&pending)\r\n}","code-length":63,"reference":"\/\/ GarbageCollect takes a lock, triggers a GC, and invokes the accumulated GC\n\/\/ callbacks.","result":"Garbage collect peers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newRoutes(ourself *localPeer, peers *Peers) *routes {\r\n\trecalculate := make(chan *struct{}, 1)\r\n\twait := make(chan chan struct{})\r\n\taction := make(chan func())\r\n\tr := &routes{\r\n\t\tourself:      ourself,\r\n\t\tpeers:        peers,\r\n\t\tunicast:      unicastRoutes{ourself.Name: UnknownPeerName},\r\n\t\tunicastAll:   unicastRoutes{ourself.Name: UnknownPeerName},\r\n\t\tbroadcast:    broadcastRoutes{ourself.Name: []PeerName{}},\r\n\t\tbroadcastAll: broadcastRoutes{ourself.Name: []PeerName{}},\r\n\t\trecalc:       recalculate,\r\n\t\twait:         wait,\r\n\t\taction:       action,\r\n\t}\r\n\tgo r.run(recalculate, wait, action)\r\n\treturn r\r\n}","code-length":229,"reference":"\/\/ newRoutes returns a usable Routes based on the LocalPeer and existing Peers.","result":"Create new routes.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *routes) OnChange(callback func()) {\r\n\tr.Lock()\r\n\tdefer r.Unlock()\r\n\tr.onChange = append(r.onChange, callback)\r\n}","code-length":57,"reference":"\/\/ OnChange appends callback to the functions that will be called whenever the\n\/\/ routes are recalculated.","result":"Generate the generated code.","score":[0.0124,0.0318]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *routes) Unicast(name PeerName) (PeerName, bool) {\r\n\tr.RLock()\r\n\tdefer r.RUnlock()\r\n\thop, found := r.unicast[name]\r\n\treturn hop, found\r\n}","code-length":70,"reference":"\/\/ Unicast returns the next hop on the unicast route to the named peer,\n\/\/ based on established and symmetric connections.","result":"Create the route .","score":[0.0054,0.0518]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *routes) UnicastAll(name PeerName) (PeerName, bool) {\r\n\tr.RLock()\r\n\tdefer r.RUnlock()\r\n\thop, found := r.unicastAll[name]\r\n\treturn hop, found\r\n}","code-length":72,"reference":"\/\/ UnicastAll returns the next hop on the unicast route to the named peer,\n\/\/ based on all connections.","result":"Create the route .","score":[0.0089,0.0571]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *routes) Broadcast(name PeerName) []PeerName {\r\n\treturn r.lookupOrCalculate(name, &r.broadcast, true)\r\n}","code-length":47,"reference":"\/\/ Broadcast returns the set of peer names that should be notified\n\/\/ when we receive a broadcast message originating from the named peer\n\/\/ based on established and symmetric connections.","result":"Generate the code.","score":[0.0,0.0177]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *routes) BroadcastAll(name PeerName) []PeerName {\r\n\treturn r.lookupOrCalculate(name, &r.broadcastAll, false)\r\n}","code-length":49,"reference":"\/\/ BroadcastAll returns the set of peer names that should be notified\n\/\/ when we receive a broadcast message originating from the named peer\n\/\/ based on all connections.","result":"Generate the code.","score":[0.0001,0.0189]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPeer(name mesh.PeerName, uid mesh.PeerUID, logger mesh.Logger) *Peer {\r\n\tp := &Peer{\r\n\t\tname:    name,\r\n\t\tuid:     uid,\r\n\t\tgossip:  nil,\r\n\t\trecv:    make(chan pkt),\r\n\t\tactions: make(chan func()),\r\n\t\tquit:    make(chan struct{}),\r\n\t\tlogger:  logger,\r\n\t}\r\n\tgo p.loop()\r\n\treturn p\r\n}","code-length":135,"reference":"\/\/ NewPeer returns a Peer, which can be used as a net.PacketConn.\n\/\/ Clients must Register a mesh.Gossip before calling ReadFrom or WriteTo.\n\/\/ Clients should aggressively consume from ReadFrom.","result":"Create a new peer.","score":[0.0005,0.0182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Peer) Register(gossip mesh.Gossip) {\r\n\tp.actions <- func() { p.gossip = gossip }\r\n}","code-length":45,"reference":"\/\/ Register injects the mesh.Gossip and enables full-duplex communication.\n\/\/ Clients should consume from ReadFrom without blocking.","result":"Register gossip.","score":[0.0003,0.0323]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Peer) ReadFrom(b []byte) (n int, remote net.Addr, err error) {\r\n\tc := make(chan struct{})\r\n\tp.actions <- func() {\r\n\t\tgo func() {\r\n\t\t\tdefer close(c)\r\n\t\t\tselect {\r\n\t\t\tcase pkt := <-p.recv:\r\n\t\t\t\tn = copy(b, pkt.Buf)\r\n\t\t\t\tremote = MeshAddr{PeerName: pkt.SrcName, PeerUID: pkt.SrcUID}\r\n\t\t\t\tif n < len(pkt.Buf) {\r\n\t\t\t\t\terr = ErrShortRead\r\n\t\t\t\t}\r\n\t\t\tcase <-p.quit:\r\n\t\t\t\terr = ErrPeerClosed\r\n\t\t\t}\r\n\t\t}()\r\n\t}\r\n\t<-c\r\n\treturn n, remote, err\r\n}","code-length":210,"reference":"\/\/ ReadFrom implements net.PacketConn.\n\/\/ Clients should consume from ReadFrom without blocking.","result":"Read from a buffer.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Peer) WriteTo(b []byte, dst net.Addr) (n int, err error) {\r\n\tc := make(chan struct{})\r\n\tp.actions <- func() {\r\n\t\tdefer close(c)\r\n\t\tif p.gossip == nil {\r\n\t\t\terr = ErrGossipNotRegistered\r\n\t\t\treturn\r\n\t\t}\r\n\t\tmeshAddr, ok := dst.(MeshAddr)\r\n\t\tif !ok {\r\n\t\t\terr = ErrNotMeshAddr\r\n\t\t\treturn\r\n\t\t}\r\n\t\tpkt := pkt{SrcName: p.name, SrcUID: p.uid, Buf: b}\r\n\t\tif meshAddr.PeerName == p.name {\r\n\t\t\tp.recv <- pkt\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\tbuf := pkt.encode()\r\n\t\tn = len(buf)\r\n\t\terr = p.gossip.GossipUnicast(meshAddr.PeerName, buf)\r\n\t}\r\n\t<-c\r\n\treturn n, err\r\n}","code-length":268,"reference":"\/\/ WriteTo implements net.PacketConn.","result":"Write to a file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Peer) LocalAddr() net.Addr {\r\n\treturn MeshAddr{PeerName: p.name, PeerUID: p.uid}\r\n}","code-length":46,"reference":"\/\/ LocalAddr implements net.PacketConn.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Peer) OnGossip(buf []byte) (delta mesh.GossipData, err error) {\r\n\treturn pktSlice{makePkt(buf)}, nil\r\n}","code-length":53,"reference":"\/\/ OnGossip implements mesh.Gossiper.\n\/\/ The buf is a single pkt.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Peer) OnGossipBroadcast(_ mesh.PeerName, buf []byte) (received mesh.GossipData, err error) {\r\n\tpkt := makePkt(buf)\r\n\tp.recv <- pkt\r\n\treturn pktSlice{pkt}, nil\r\n}","code-length":75,"reference":"\/\/ OnGossipBroadcast implements mesh.Gossiper.\n\/\/ The buf is a single pkt","result":"Send broadcasts to peers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Peer) OnGossipUnicast(_ mesh.PeerName, buf []byte) error {\r\n\tpkt := makePkt(buf)\r\n\tp.recv <- pkt\r\n\treturn nil\r\n}","code-length":60,"reference":"\/\/ OnGossipUnicast implements mesh.Gossiper.\n\/\/ The buf is a single pkt.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDefaultServer(\r\n\tminPeerCount int,\r\n\tterminatec <-chan struct{},\r\n\tterminatedc chan<- error,\r\n\tlogger mesh.Logger,\r\n) Server {\r\n\tvar (\r\n\t\tpeerName = mustPeerName()\r\n\t\tnickName = mustHostname()\r\n\t\thost     = \"0.0.0.0\"\r\n\t\tport     = 6379\r\n\t\tpassword = \"\"\r\n\t\tchannel  = \"metcd\"\r\n\t)\r\n\trouter := mesh.NewRouter(mesh.Config{\r\n\t\tHost:               host,\r\n\t\tPort:               port,\r\n\t\tProtocolMinVersion: mesh.ProtocolMinVersion,\r\n\t\tPassword:           []byte(password),\r\n\t\tConnLimit:          64,\r\n\t\tPeerDiscovery:      true,\r\n\t\tTrustedSubnets:     []*net.IPNet{},\r\n\t}, peerName, nickName, mesh.NullOverlay{}, logger)\r\n\t\r\n\tpeer := meshconn.NewPeer(router.Ourself.Peer.Name, router.Ourself.UID, logger)\r\n\tgossip := router.NewGossip(channel, peer)\r\n\tpeer.Register(gossip)\r\n\t\r\n\t\r\n\t\r\n\t\r\n\trouter.Start()\r\n\treturn NewServer(router, peer, minPeerCount, terminatec, terminatedc, logger)\r\n}","code-length":344,"reference":"\/\/ NewDefaultServer is like NewServer, but we take care of creating a\n\/\/ mesh.Router and meshconn.Peer for you, with sane defaults. If you need more\n\/\/ fine-grained control, create the components yourself and use NewServer.","result":"Create a default server.","score":[0.0001,0.0313]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PeerNameFromUserInput(userInput string) (PeerName, error) {\r\n\t\r\n\tnameByteAry := sha256.Sum256([]byte(userInput))\r\n\treturn PeerNameFromBin(nameByteAry[:NameSize]), nil\r\n}","code-length":71,"reference":"\/\/ PeerNameFromUserInput parses PeerName from a user-provided string.","result":"Create a peer name from user input.","score":[0.1665,0.1266]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (name PeerName) bytes() []byte {\r\n\tres, err := hex.DecodeString(string(name))\r\n\tif err != nil {\r\n\t\tpanic(\"unable to decode name to bytes: \" + name)\r\n\t}\r\n\treturn res\r\n}","code-length":74,"reference":"\/\/ bytes encodes PeerName as a byte slice.","result":"Generate the peer name bytes.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRouter(config Config, name PeerName, nickName string, overlay Overlay, logger Logger) (*Router, error) {\r\n\trouter := &Router{Config: config, gossipChannels: make(gossipChannels)}\r\n\tif overlay == nil {\r\n\t\toverlay = NullOverlay{}\r\n\t}\r\n\trouter.Overlay = overlay\r\n\trouter.Ourself = newLocalPeer(name, nickName, router)\r\n\trouter.Peers = newPeers(router.Ourself)\r\n\trouter.Peers.OnGC(func(peer *Peer) {\r\n\t\tlogger.Printf(\"Removed unreachable peer %s\", peer)\r\n\t})\r\n\trouter.Routes = newRoutes(router.Ourself, router.Peers)\r\n\trouter.ConnectionMaker = newConnectionMaker(router.Ourself, router.Peers, net.JoinHostPort(router.Host, \"0\"), router.Port, router.PeerDiscovery, logger)\r\n\trouter.logger = logger\r\n\tgossip, err := router.NewGossip(\"topology\", router)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\trouter.topologyGossip = gossip\r\n\trouter.acceptLimiter = newTokenBucket(acceptMaxTokens, acceptTokenDelay)\r\n\treturn router, nil\r\n}","code-length":312,"reference":"\/\/ NewRouter returns a new router. It must be started.","result":"Create a new router.","score":[0.1468,0.3132]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (router *Router) sendAllGossip() {\r\n\tfor channel := range router.gossipChannelSet() {\r\n\t\tif gossip := channel.gossiper.Gossip(); gossip != nil {\r\n\t\t\tchannel.Send(gossip)\r\n\t\t}\r\n\t}\r\n}","code-length":79,"reference":"\/\/ Relay all pending gossip data for each channel via random neighbours.","result":"Send all gossip.","score":[0.0203,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (router *Router) sendAllGossipDown(conn Connection) {\r\n\tfor channel := range router.gossipChannelSet() {\r\n\t\tif gossip := channel.gossiper.Gossip(); gossip != nil {\r\n\t\t\tchannel.SendDown(conn, gossip)\r\n\t\t}\r\n\t}\r\n}","code-length":85,"reference":"\/\/ Relay all pending gossip data for each channel via conn.","result":"Generate code for generated code.","score":[0.0724,0.0481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (router *Router) broadcastTopologyUpdate(update []*Peer) {\r\n\tnames := make(peerNameSet)\r\n\tfor _, p := range update {\r\n\t\tnames[p.Name] = struct{}{}\r\n\t}\r\n\trouter.topologyGossip.GossipBroadcast(&topologyGossipData{peers: router.Peers, update: names})\r\n}","code-length":97,"reference":"\/\/ BroadcastTopologyUpdate is invoked whenever there is a change to the mesh\n\/\/ topology, and broadcasts the new set of peers to the mesh.","result":"Broadcast the update of the topology of the router.","score":[0.0325,0.1111]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (router *Router) OnGossipUnicast(sender PeerName, msg []byte) error {\r\n\treturn fmt.Errorf(\"unexpected topology gossip unicast: %v\", msg)\r\n}","code-length":53,"reference":"\/\/ OnGossipUnicast implements Gossiper, but always returns an error, as a\n\/\/ router should only receive gossip broadcasts of TopologyGossipData.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (router *Router) OnGossipBroadcast(_ PeerName, update []byte) (GossipData, error) {\r\n\torigUpdate, _, err := router.applyTopologyUpdate(update)\r\n\tif err != nil || len(origUpdate) == 0 {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &topologyGossipData{peers: router.Peers, update: origUpdate}, nil\r\n}","code-length":106,"reference":"\/\/ OnGossipBroadcast receives broadcasts of TopologyGossipData.\n\/\/ It returns the received update unchanged.","result":"Generate code for the generated code.","score":[0.0601,0.0407]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (router *Router) Gossip() GossipData {\r\n\treturn &topologyGossipData{peers: router.Peers, update: router.Peers.names()}\r\n}","code-length":47,"reference":"\/\/ Gossip yields the current topology as GossipData.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (router *Router) OnGossip(update []byte) (GossipData, error) {\r\n\t_, newUpdate, err := router.applyTopologyUpdate(update)\r\n\tif err != nil || len(newUpdate) == 0 {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &topologyGossipData{peers: router.Peers, update: newUpdate}, nil\r\n}","code-length":102,"reference":"\/\/ OnGossip receives broadcasts of TopologyGossipData.\n\/\/ It returns an \"improved\" version of the received update.\n\/\/ See peers.ApplyUpdate.","result":"Generate code for the generated code.","score":[0.0221,0.0282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *topologyGossipData) Encode() [][]byte {\r\n\treturn [][]byte{d.peers.encodePeers(d.update)}\r\n}","code-length":46,"reference":"\/\/ Encode implements GossipData.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newState(self mesh.PeerName) *state {\r\n\treturn &state{\r\n\t\tset:  map[mesh.PeerName]int{},\r\n\t\tself: self,\r\n\t}\r\n}","code-length":60,"reference":"\/\/ Construct an empty state object, ready to receive updates.\n\/\/ This is suitable to use at program start.\n\/\/ Other peers will populate us with data.","result":"Create new state.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (st *state) Merge(other mesh.GossipData) (complete mesh.GossipData) {\r\n\treturn st.mergeComplete(other.(*state).copy().set)\r\n}","code-length":54,"reference":"\/\/ Merge merges the other GossipData into this one,\n\/\/ and returns our resulting, complete state.","result":"Merge mesh.","score":[0.0005,0.0342]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (st *state) mergeReceived(set map[mesh.PeerName]int) (received mesh.GossipData) {\r\n\tst.mtx.Lock()\r\n\tdefer st.mtx.Unlock()\r\n\tfor peer, v := range set {\r\n\t\tif v <= st.set[peer] {\r\n\t\t\tdelete(set, peer)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tst.set[peer] = v\r\n\t}\r\n\treturn &state{\r\n\t\tset: set,\r\n\t}\r\n}","code-length":141,"reference":"\/\/ Merge the set into our state, abiding increment-only semantics.\n\/\/ Return a non-nil mesh.GossipData representation of the received set.","result":"Merge received data.","score":[0.0017,0.0546]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (st *state) mergeComplete(set map[mesh.PeerName]int) (complete mesh.GossipData) {\r\n\tst.mtx.Lock()\r\n\tdefer st.mtx.Unlock()\r\n\tfor peer, v := range set {\r\n\t\tif v > st.set[peer] {\r\n\t\t\tst.set[peer] = v\r\n\t\t}\r\n\t}\r\n\treturn &state{\r\n\t\tset: st.set,\r\n\t}\r\n}","code-length":128,"reference":"\/\/ Merge the set into our state, abiding increment-only semantics.\n\/\/ Return our resulting, complete state.","result":"Merge complete data.","score":[0.0064,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (*surrogateGossiper) OnGossipBroadcast(_ PeerName, update []byte) (GossipData, error) {\r\n\treturn newSurrogateGossipData(update), nil\r\n}","code-length":55,"reference":"\/\/ OnGossipBroadcast implements Gossiper.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *surrogateGossiper) OnGossip(update []byte) (GossipData, error) {\r\n\thash := fnv.New64a()\r\n\t_, _ = hash.Write(update)\r\n\tupdateHash := hash.Sum64()\r\n\ts.Lock()\r\n\tdefer s.Unlock()\r\n\tfor _, p := range s.prevUpdates {\r\n\t\tif updateHash == p.hash && bytes.Equal(update, p.update) {\r\n\t\t\treturn nil, nil\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tupdateTime := now()\r\n\tdeleteBefore := updateTime.Add(-gossipInterval)\r\n\tkeepFrom := len(s.prevUpdates)\r\n\tfor i, p := range s.prevUpdates {\r\n\t\tif p.t.After(deleteBefore) {\r\n\t\t\tkeepFrom = i\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\ts.prevUpdates = append(s.prevUpdates[keepFrom:], prevUpdate{update, updateHash, updateTime})\r\n\treturn newSurrogateGossipData(update), nil\r\n}","code-length":283,"reference":"\/\/ OnGossip should return \"everything new I've just learnt\".\n\/\/ surrogateGossiper doesn't understand the content of messages, but it can eliminate simple duplicates","result":"Generate code for the code.","score":[0.0066,0.0236]}
{"code":"\/*is used to<extra_id_0>\r\nfunc generateKeyPair() (publicKey, privateKey *[32]byte, err error) {\r\n\treturn box.GenerateKey(rand.Reader)\r\n}","code-length":44,"reference":"\/\/ GenerateKeyPair is used during encrypted protocol introduction.","result":"Generate a keypair.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc formSessionKey(remotePublicKey, localPrivateKey *[32]byte, secretKey []byte) *[32]byte {\r\n\tvar sharedKey [32]byte\r\n\tbox.Precompute(&sharedKey, remotePublicKey, localPrivateKey)\r\n\tsharedKeySlice := sharedKey[:]\r\n\tsharedKeySlice = append(sharedKeySlice, secretKey...)\r\n\tsessionKey := sha256.Sum256(sharedKeySlice)\r\n\treturn &sessionKey\r\n}","code-length":115,"reference":"\/\/ FormSessionKey is used during encrypted protocol introduction.","result":"Form the session key.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newTCPCryptoState(sessionKey *[32]byte, outbound bool) *tcpCryptoState {\r\n\ts := &tcpCryptoState{sessionKey: sessionKey}\r\n\tif outbound {\r\n\t\ts.nonce[0] |= (1 << 7)\r\n\t}\r\n\ts.nonce[0] |= (1 << 6)\r\n\treturn s\r\n}","code-length":96,"reference":"\/\/ NewTCPCryptoState returns a valid TCPCryptoState.","result":"Create a new state.","score":[0.1938,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (sender *gobTCPSender) Send(msg []byte) error {\r\n\treturn sender.encoder.Encode(msg)\r\n}","code-length":41,"reference":"\/\/ Send implements TCPSender by encoding the msg.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (sender *lengthPrefixTCPSender) Send(msg []byte) error {\r\n\tl := len(msg)\r\n\tif l > maxTCPMsgSize {\r\n\t\treturn fmt.Errorf(\"outgoing message exceeds maximum size: %d > %d\", l, maxTCPMsgSize)\r\n\t}\r\n\t\r\n\t\r\n\tprefixedMsg := make([]byte, 4+l)\r\n\tbinary.BigEndian.PutUint32(prefixedMsg, uint32(l))\r\n\tcopy(prefixedMsg[4:], msg)\r\n\t_, err := sender.writer.Write(prefixedMsg)\r\n\treturn err\r\n}","code-length":160,"reference":"\/\/ Send implements TCPSender by writing the size of the msg as a big-endian\n\/\/ uint32 before the msg. msgs larger than MaxTCPMsgSize are rejected.","result":"Send messages to the sender.","score":[0.0052,0.0435]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (sender *encryptedTCPSender) Send(msg []byte) error {\r\n\tsender.Lock()\r\n\tdefer sender.Unlock()\r\n\tencodedMsg := secretbox.Seal(nil, msg, &sender.state.nonce, sender.state.sessionKey)\r\n\tsender.state.advance()\r\n\treturn sender.sender.Send(encodedMsg)\r\n}","code-length":96,"reference":"\/\/ Send implements TCPSender by sealing and sending the msg as-is.","result":"Encrypt the message.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (receiver *gobTCPReceiver) Receive() ([]byte, error) {\r\n\tvar msg []byte\r\n\terr := receiver.decoder.Decode(&msg)\r\n\treturn msg, err\r\n}","code-length":58,"reference":"\/\/ Receive implements TCPReciever by Gob decoding into a byte slice directly.","result":"Receive messages from the receiver.","score":[0.0593,0.0442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (receiver *lengthPrefixTCPReceiver) Receive() ([]byte, error) {\r\n\tlenPrefix := make([]byte, 4)\r\n\tif _, err := io.ReadFull(receiver.reader, lenPrefix); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tl := binary.BigEndian.Uint32(lenPrefix)\r\n\tif l > maxTCPMsgSize {\r\n\t\treturn nil, fmt.Errorf(\"incoming message exceeds maximum size: %d > %d\", l, maxTCPMsgSize)\r\n\t}\r\n\tmsg := make([]byte, l)\r\n\t_, err := io.ReadFull(receiver.reader, msg)\r\n\treturn msg, err\r\n}","code-length":177,"reference":"\/\/ Receive implements TCPReceiver by making a length-limited read into a byte buffer.","result":"Receive messages from the receiver.","score":[0.0485,0.041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (receiver *encryptedTCPReceiver) Receive() ([]byte, error) {\r\n\tmsg, err := receiver.receiver.Receive()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdecodedMsg, success := secretbox.Open(nil, msg, &receiver.state.nonce, receiver.state.sessionKey)\r\n\tif !success {\r\n\t\treturn nil, fmt.Errorf(\"Unable to decrypt TCP msg\")\r\n\t}\r\n\treceiver.state.advance()\r\n\treturn decodedMsg, nil\r\n}","code-length":139,"reference":"\/\/ Receive implements TCPReceiver by reading from the wrapped TCPReceiver and\n\/\/ unboxing the encrypted message, returning the decoded message.","result":"Protect the receiver.","score":[0.0014,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newPeer(self mesh.PeerName, logger *log.Logger) *peer {\r\n\tactions := make(chan func())\r\n\tp := &peer{\r\n\t\tst:      newState(self),\r\n\t\tsend:    nil,\r\n\t\tactions: actions,\r\n\t\tquit:    make(chan struct{}),\r\n\t\tlogger:  logger,\r\n\t}\r\n\tgo p.loop(actions)\r\n\treturn p\r\n}","code-length":118,"reference":"\/\/ Construct a peer with empty state.\n\/\/ Be sure to register a channel, later,\n\/\/ so we can make outbound communication.","result":"Create a new peer.","score":[0.0035,0.0248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *peer) incr() (result int) {\r\n\tc := make(chan struct{})\r\n\tp.actions <- func() {\r\n\t\tdefer close(c)\r\n\t\tst := p.st.incr()\r\n\t\tif p.send != nil {\r\n\t\t\tp.send.GossipBroadcast(st)\r\n\t\t} else {\r\n\t\t\tp.logger.Printf(\"no sender configured; not broadcasting update right now\")\r\n\t\t}\r\n\t\tresult = st.get()\r\n\t}\r\n\t<-c\r\n\treturn result\r\n}","code-length":151,"reference":"\/\/ Increment the counter by one.","result":"Send gossip updates to peers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *peer) Gossip() (complete mesh.GossipData) {\r\n\tcomplete = p.st.copy()\r\n\tp.logger.Printf(\"Gossip => complete %v\", complete.(*state).set)\r\n\treturn complete\r\n}","code-length":68,"reference":"\/\/ Return a copy of our complete state.","result":"Create a new peer.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *peer) OnGossipUnicast(src mesh.PeerName, buf []byte) error {\r\n\tvar set map[mesh.PeerName]int\r\n\tif err := gob.NewDecoder(bytes.NewReader(buf)).Decode(&set); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tcomplete := p.st.mergeComplete(set)\r\n\tp.logger.Printf(\"OnGossipUnicast %s %v => complete %v\", src, set, complete)\r\n\treturn nil\r\n}","code-length":135,"reference":"\/\/ Merge the gossiped data represented by buf into our state.","result":"Detect if a peer is a multicast.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc makeRaftPeer(addr net.Addr) raft.Peer {\r\n\treturn raft.Peer{\r\n\t\tID:      uint64(addr.(meshconn.MeshAddr).PeerUID),\r\n\t\tContext: nil,\r\n\t}\r\n}","code-length":69,"reference":"\/\/ makeRaftPeer converts a net.Addr into a raft.Peer.\n\/\/ All peers must perform the Addr-to-Peer mapping in the same way.\n\/\/\n\/\/ The etcd Raft implementation tracks the committed entry for each node ID,\n\/\/ and panics if it discovers a node has lost previously committed entries.\n\/\/ In effect, it assumes commitment implies durability. But our storage is\n\/\/ explicitly non-durable. So, whenever a node restarts, we need to give it\n\/\/ a brand new ID. That is the peer UID.","result":"Create a raft peer.","score":[0.0,0.0135]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (peer *Peer) String() string {\r\n\treturn fmt.Sprint(peer.Name, \"(\", peer.NickName, \")\")\r\n}","code-length":44,"reference":"\/\/ String returns the peer name and nickname.","result":"Generate the peer string.","score":[0.1662,0.2467]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (peer *Peer) forEachConnectedPeer(establishedAndSymmetric bool, exclude map[PeerName]PeerName, f func(*Peer)) {\r\n\tfor remoteName, conn := range peer.connections {\r\n\t\tif establishedAndSymmetric && !conn.isEstablished() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif _, found := exclude[remoteName]; found {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tremotePeer := conn.Remote()\r\n\t\tif remoteConn, found := remotePeer.connections[peer.Name]; !establishedAndSymmetric || (found && remoteConn.isEstablished()) {\r\n\t\t\tf(remotePeer)\r\n\t\t}\r\n\t}\r\n}","code-length":179,"reference":"\/\/ Apply f to all peers reachable by peer. If establishedAndSymmetric is true,\n\/\/ only peers with established bidirectional connections will be selected. The\n\/\/ exclude maps is treated as a set of remote peers to blacklist.","result":"Generate code for each peer.","score":[0.0004,0.0148]}
{"code":"\/*is used to<extra_id_0>\r\nfunc parsePeerUID(s string) (PeerUID, error) {\r\n\tuid, err := strconv.ParseUint(s, 10, 64)\r\n\treturn PeerUID(uid), err\r\n}","code-length":55,"reference":"\/\/ ParsePeerUID parses a decimal peer UID from a string.","result":"Parse peerUIDs.","score":[0,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lop listOfPeers) Swap(i, j int) {\r\n\tlop[i], lop[j] = lop[j], lop[i]\r\n}","code-length":49,"reference":"\/\/ Swap implements sort.Interface.","result":"Sort the list of peers by name.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lop listOfPeers) Less(i, j int) bool {\r\n\treturn lop[i].Name < lop[j].Name\r\n}","code-length":44,"reference":"\/\/ Less implements sort.Interface.","result":"Sort the list of peers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (params protocolIntroParams) doIntro() (res protocolIntroResults, err error) {\r\n\tif err = params.Conn.SetDeadline(time.Now().Add(headerTimeout)); err != nil {\r\n\t\treturn\r\n\t}\r\n\tif res.Version, err = params.exchangeProtocolHeader(); err != nil {\r\n\t\treturn\r\n\t}\r\n\tvar pubKey, privKey *[32]byte\r\n\tif params.Password != nil {\r\n\t\tif pubKey, privKey, err = generateKeyPair(); err != nil {\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n\tif err = params.Conn.SetWriteDeadline(time.Time{}); err != nil {\r\n\t\treturn\r\n\t}\r\n\tif err = params.Conn.SetReadDeadline(time.Now().Add(tcpHeartbeat * 2)); err != nil {\r\n\t\treturn\r\n\t}\r\n\tswitch res.Version {\r\n\tcase 1:\r\n\t\terr = res.doIntroV1(params, pubKey, privKey)\r\n\tcase 2:\r\n\t\terr = res.doIntroV2(params, pubKey, privKey)\r\n\tdefault:\r\n\t\tpanic(\"unhandled protocol version\")\r\n\t}\r\n\treturn\r\n}","code-length":308,"reference":"\/\/ DoIntro executes the protocol introduction.","result":"Implement the protocol interface.","score":[0.274,0.3233]}
{"code":"\/*is used to<extra_id_0>\r\nfunc filterV1Features(intro map[string]string) map[string]string {\r\n\tsafe := make(map[string]string)\r\n\tfor _, k := range protocolV1Features {\r\n\t\tif val, ok := intro[k]; ok {\r\n\t\t\tsafe[k] = val\r\n\t\t}\r\n\t}\r\n\treturn safe\r\n}","code-length":97,"reference":"\/\/ In the V1 protocol, the intro fields are sent unencrypted.  So we\n\/\/ restrict them to an established subset of fields that are assumed\n\/\/ to be safe.","result":"Filter out v.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newConnectionMaker(ourself *localPeer, peers *Peers, localAddr string, port int, discovery bool, logger Logger) *connectionMaker {\r\n\tactionChan := make(chan connectionMakerAction, ChannelSize)\r\n\tcm := &connectionMaker{\r\n\t\tourself:     ourself,\r\n\t\tpeers:       peers,\r\n\t\tlocalAddr:   localAddr,\r\n\t\tport:        port,\r\n\t\tdiscovery:   discovery,\r\n\t\tdirectPeers: peerAddrs{},\r\n\t\ttargets:     make(map[string]*target),\r\n\t\tconnections: make(map[Connection]struct{}),\r\n\t\tactionChan:  actionChan,\r\n\t\tlogger:      logger,\r\n\t}\r\n\tgo cm.queryLoop(actionChan)\r\n\treturn cm\r\n}","code-length":200,"reference":"\/\/ newConnectionMaker returns a usable ConnectionMaker, seeded with\n\/\/ peers, making outbound connections from localAddr, and listening on\n\/\/ port. If discovery is true, ConnectionMaker will attempt to\n\/\/ initiate new connections with peers it's not directly connected to.","result":"Create a new connectionMaker .","score":[0.0003,0.0421]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cm *connectionMaker) connectionAborted(address string, err error) {\r\n\tcm.actionChan <- func() bool {\r\n\t\ttarget := cm.targets[address]\r\n\t\ttarget.state = targetWaiting\r\n\t\ttarget.lastError = err\r\n\t\ttarget.nextTryLater()\r\n\t\treturn true\r\n\t}\r\n}","code-length":93,"reference":"\/\/ connectionAborted marks the target identified by address as broken, and\n\/\/ puts it in the TargetWaiting state.","result":"Prevent connection from being closed.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newGossipSender(\r\n\tmakeMsg func(msg []byte) protocolMsg,\r\n\tmakeBroadcastMsg func(srcName PeerName, msg []byte) protocolMsg,\r\n\tsender protocolSender,\r\n\tstop <-chan struct{},\r\n) *gossipSender {\r\n\tmore := make(chan struct{}, 1)\r\n\tflush := make(chan chan<- bool)\r\n\ts := &gossipSender{\r\n\t\tmakeMsg:          makeMsg,\r\n\t\tmakeBroadcastMsg: makeBroadcastMsg,\r\n\t\tsender:           sender,\r\n\t\tbroadcasts:       make(map[PeerName]GossipData),\r\n\t\tmore:             more,\r\n\t\tflush:            flush,\r\n\t}\r\n\tgo s.run(stop, more, flush)\r\n\treturn s\r\n}","code-length":204,"reference":"\/\/ NewGossipSender constructs a usable GossipSender.","result":"Create a new gossip sender.","score":[0.1967,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *gossipSender) Send(data GossipData) {\r\n\ts.Lock()\r\n\tdefer s.Unlock()\r\n\tif s.empty() {\r\n\t\tdefer s.prod()\r\n\t}\r\n\tif s.gossip == nil {\r\n\t\ts.gossip = data\r\n\t} else {\r\n\t\ts.gossip = s.gossip.Merge(data)\r\n\t}\r\n}","code-length":113,"reference":"\/\/ Send accumulates the GossipData and will send it eventually.\n\/\/ Send and Broadcast accumulate into different buckets.","result":"Send gossip data to the sender.","score":[0.0311,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *gossipSender) Broadcast(srcName PeerName, data GossipData) {\r\n\ts.Lock()\r\n\tdefer s.Unlock()\r\n\tif s.empty() {\r\n\t\tdefer s.prod()\r\n\t}\r\n\td, found := s.broadcasts[srcName]\r\n\tif !found {\r\n\t\ts.broadcasts[srcName] = data\r\n\t} else {\r\n\t\ts.broadcasts[srcName] = d.Merge(data)\r\n\t}\r\n}","code-length":134,"reference":"\/\/ Broadcast accumulates the GossipData under the given srcName and will send\n\/\/ it eventually. Send and Broadcast accumulate into different buckets.","result":"Broadcast data to peers.","score":[0.0035,0.0248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *gossipSender) Flush() bool {\r\n\tch := make(chan bool)\r\n\ts.flush <- ch\r\n\treturn <-ch\r\n}","code-length":48,"reference":"\/\/ Flush sends all pending data, and returns true if anything was sent since\n\/\/ the previous flush. For testing.","result":"Generate the code.","score":[0.0014,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gs *gossipSenders) Sender(channelName string, makeGossipSender func(sender protocolSender, stop <-chan struct{}) *gossipSender) *gossipSender {\r\n\tgs.Lock()\r\n\tdefer gs.Unlock()\r\n\ts, found := gs.senders[channelName]\r\n\tif !found {\r\n\t\ts = makeGossipSender(gs.sender, gs.stop)\r\n\t\tgs.senders[channelName] = s\r\n\t}\r\n\treturn s\r\n}","code-length":132,"reference":"\/\/ Sender yields the GossipSender for the named channel.\n\/\/ It will use the factory function if no sender yet exists.","result":"Create a new receiver.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gs *gossipSenders) Flush() bool {\r\n\tsent := false\r\n\tgs.Lock()\r\n\tdefer gs.Unlock()\r\n\tfor _, sender := range gs.senders {\r\n\t\tsent = sender.Flush() || sent\r\n\t}\r\n\treturn sent\r\n}","code-length":81,"reference":"\/\/ Flush flushes all managed senders. Used for testing.","result":"Flush the gossipSenders.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc findMainPath() string {\r\n\tpc := make([]uintptr, 100)\r\n\tn := runtime.Callers(2, pc)\r\n\tframes := runtime.CallersFrames(pc[:n])\r\n\tfor {\r\n\t\tframe, more := frames.Next()\r\n\t\t\r\n\t\tif frame.Function == \"main.main\" || frame.Function == \"testing.tRunner\" {\r\n\t\t\treturn frame.File\r\n\t\t}\r\n\t\tif !more {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\treturn \"\"\r\n}","code-length":148,"reference":"\/\/ Find the path to package main by looking at the root Caller.","result":"Find the main path.","score":[0.0527,0.124]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Create(c context.Context, clientID string) (token string, err error) {\r\n\treq := &pb.CreateChannelRequest{\r\n\t\tApplicationKey: &clientID,\r\n\t}\r\n\tresp := &pb.CreateChannelResponse{}\r\n\terr = internal.Call(c, service, \"CreateChannel\", req, resp)\r\n\ttoken = resp.GetToken()\r\n\treturn token, remapError(err)\r\n}","code-length":110,"reference":"\/\/ Create creates a channel and returns a token for use by the client.\n\/\/ The clientID is an application-provided string used to identify the client.","result":"Create a channel.","score":[0.0002,0.0422]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Send(c context.Context, clientID, message string) error {\r\n\treq := &pb.SendMessageRequest{\r\n\t\tApplicationKey: &clientID,\r\n\t\tMessage:        &message,\r\n\t}\r\n\tresp := &basepb.VoidProto{}\r\n\treturn remapError(internal.Call(c, service, \"SendChannelMessage\", req, resp))\r\n}","code-length":100,"reference":"\/\/ Send sends a message on the channel associated with clientID.","result":"Send messages to clients.","score":[0.0555,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SendJSON(c context.Context, clientID string, value interface{}) error {\r\n\tm, err := json.Marshal(value)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn Send(c, clientID, string(m))\r\n}","code-length":75,"reference":"\/\/ SendJSON is a helper function that sends a JSON-encoded value\n\/\/ on the channel associated with clientID.","result":"Send JSON to the client.","score":[0.0178,0.0599]}
{"code":"\/*is used to<extra_id_0>\r\nfunc remapError(err error) error {\r\n\tif e, ok := err.(*internal.APIError); ok {\r\n\t\tif e.Service == \"xmpp\" {\r\n\t\t\te.Service = \"channel\"\r\n\t\t}\r\n\t}\r\n\treturn err\r\n}","code-length":77,"reference":"\/\/ remapError fixes any APIError referencing \"xmpp\" into one referencing \"channel\".","result":"Remap errors.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NamespacedContext(ctx netcontext.Context, namespace string) netcontext.Context {\r\n\treturn withNamespace(ctx, namespace)\r\n}","code-length":42,"reference":"\/\/ NamespacedContext wraps a Context to support namespaces.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc protoToItem(p *pb.MemcacheGetResponse_Item) *Item {\r\n\treturn &Item{\r\n\t\tKey:   string(p.Key),\r\n\t\tValue: p.Value,\r\n\t\tFlags: p.GetFlags(),\r\n\t\tcasID: p.GetCasId(),\r\n\t}\r\n}","code-length":90,"reference":"\/\/ protoToItem converts a protocol buffer item to a Go struct.","result":"Convert the item proto to a proto item.","score":[0.1494,0.295]}
{"code":"\/*is used to<extra_id_0>\r\nfunc singleError(err error) error {\r\n\tif me, ok := err.(appengine.MultiError); ok {\r\n\t\treturn me[0]\r\n\t}\r\n\treturn err\r\n}","code-length":59,"reference":"\/\/ If err is an appengine.MultiError, return its first element. Otherwise, return err.","result":"Generate the error message.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Get(c context.Context, key string) (*Item, error) {\r\n\tm, err := GetMulti(c, []string{key})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif _, ok := m[key]; !ok {\r\n\t\treturn nil, ErrCacheMiss\r\n\t}\r\n\treturn m[key], nil\r\n}","code-length":105,"reference":"\/\/ Get gets the item for the given key. ErrCacheMiss is returned for a memcache\n\/\/ cache miss. The key must be at most 250 bytes in length.","result":"Cache the result of the Get function.","score":[0.0106,0.0772]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetMulti(c context.Context, key []string) (map[string]*Item, error) {\r\n\tif len(key) == 0 {\r\n\t\treturn nil, nil\r\n\t}\r\n\tkeyAsBytes := make([][]byte, len(key))\r\n\tfor i, k := range key {\r\n\t\tkeyAsBytes[i] = []byte(k)\r\n\t}\r\n\treq := &pb.MemcacheGetRequest{\r\n\t\tKey:    keyAsBytes,\r\n\t\tForCas: proto.Bool(true),\r\n\t}\r\n\tres := &pb.MemcacheGetResponse{}\r\n\tif err := internal.Call(c, \"memcache\", \"Get\", req, res); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tm := make(map[string]*Item, len(res.Item))\r\n\tfor _, p := range res.Item {\r\n\t\tt := protoToItem(p)\r\n\t\tm[t.Key] = t\r\n\t}\r\n\treturn m, nil\r\n}","code-length":267,"reference":"\/\/ GetMulti is a batch version of Get. The returned map from keys to items may\n\/\/ have fewer elements than the input slice, due to memcache cache misses.\n\/\/ Each key must be at most 250 bytes in length.","result":"Get multiple items from memcache.","score":[0.0003,0.0411]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Delete(c context.Context, key string) error {\r\n\treturn singleError(DeleteMulti(c, []string{key}))\r\n}","code-length":42,"reference":"\/\/ Delete deletes the item for the given key.\n\/\/ ErrCacheMiss is returned if the specified item can not be found.\n\/\/ The key must be at most 250 bytes in length.","result":"Delete a key.","score":[0.0,0.0344]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DeleteMulti(c context.Context, key []string) error {\r\n\tif len(key) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\treq := &pb.MemcacheDeleteRequest{\r\n\t\tItem: make([]*pb.MemcacheDeleteRequest_Item, len(key)),\r\n\t}\r\n\tfor i, k := range key {\r\n\t\treq.Item[i] = &pb.MemcacheDeleteRequest_Item{Key: []byte(k)}\r\n\t}\r\n\tres := &pb.MemcacheDeleteResponse{}\r\n\tif err := internal.Call(c, \"memcache\", \"Delete\", req, res); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif len(res.DeleteStatus) != len(key) {\r\n\t\treturn ErrServerError\r\n\t}\r\n\tme, any := make(appengine.MultiError, len(key)), false\r\n\tfor i, s := range res.DeleteStatus {\r\n\t\tswitch s {\r\n\t\tcase pb.MemcacheDeleteResponse_DELETED:\r\n\t\t\t\r\n\t\tcase pb.MemcacheDeleteResponse_NOT_FOUND:\r\n\t\t\tme[i] = ErrCacheMiss\r\n\t\t\tany = true\r\n\t\tdefault:\r\n\t\t\tme[i] = ErrServerError\r\n\t\t\tany = true\r\n\t\t}\r\n\t}\r\n\tif any {\r\n\t\treturn me\r\n\t}\r\n\treturn nil\r\n}","code-length":358,"reference":"\/\/ DeleteMulti is a batch version of Delete.\n\/\/ If any keys cannot be found, an appengine.MultiError is returned.\n\/\/ Each key must be at most 250 bytes in length.","result":"Delete multiple keys in one go.","score":[0.0042,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Increment(c context.Context, key string, delta int64, initialValue uint64) (newValue uint64, err error) {\r\n\treturn incr(c, key, delta, &initialValue)\r\n}","code-length":57,"reference":"\/\/ Increment atomically increments the decimal value in the given key\n\/\/ by delta and returns the new value. The value must fit in a uint64.\n\/\/ Overflow wraps around, and underflow is capped to zero. The\n\/\/ provided delta may be negative. If the key doesn't exist in\n\/\/ memcache, the provided initial value is used to atomically\n\/\/ populate it before the delta is applied.\n\/\/ The key must be at most 250 bytes in length.","result":"Generate the code.","score":[0.0,0.0071]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IncrementExisting(c context.Context, key string, delta int64) (newValue uint64, err error) {\r\n\treturn incr(c, key, delta, nil)\r\n}","code-length":52,"reference":"\/\/ IncrementExisting works like Increment but assumes that the key\n\/\/ already exists in memcache and doesn't take an initial value.\n\/\/ IncrementExisting can save work if calculating the initial value is\n\/\/ expensive.\n\/\/ An error is returned if the specified item can not be found.","result":"Generate the generated code.","score":[0.0,0.0117]}
{"code":"\/*is used to<extra_id_0>\r\nfunc set(c context.Context, item []*Item, value [][]byte, policy pb.MemcacheSetRequest_SetPolicy) error {\r\n\tif len(item) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\treq := &pb.MemcacheSetRequest{\r\n\t\tItem: make([]*pb.MemcacheSetRequest_Item, len(item)),\r\n\t}\r\n\tfor i, t := range item {\r\n\t\tp := &pb.MemcacheSetRequest_Item{\r\n\t\t\tKey: []byte(t.Key),\r\n\t\t}\r\n\t\tif value == nil {\r\n\t\t\tp.Value = t.Value\r\n\t\t} else {\r\n\t\t\tp.Value = value[i]\r\n\t\t}\r\n\t\tif t.Flags != 0 {\r\n\t\t\tp.Flags = proto.Uint32(t.Flags)\r\n\t\t}\r\n\t\tif t.Expiration != 0 {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tif t.Expiration < time.Second {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tp.ExpirationTime = proto.Uint32(uint32(time.Now().Unix()) - 5)\r\n\t\t\t} else if t.Expiration >= thirtyYears {\r\n\t\t\t\tp.ExpirationTime = proto.Uint32(uint32(time.Now().Unix()) + uint32(t.Expiration\/time.Second))\r\n\t\t\t} else {\r\n\t\t\t\tp.ExpirationTime = proto.Uint32(uint32(t.Expiration \/ time.Second))\r\n\t\t\t}\r\n\t\t}\r\n\t\tif t.casID != 0 {\r\n\t\t\tp.CasId = proto.Uint64(t.casID)\r\n\t\t\tp.ForCas = proto.Bool(true)\r\n\t\t}\r\n\t\tp.SetPolicy = policy.Enum()\r\n\t\treq.Item[i] = p\r\n\t}\r\n\tres := &pb.MemcacheSetResponse{}\r\n\tif err := internal.Call(c, \"memcache\", \"Set\", req, res); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif len(res.SetStatus) != len(item) {\r\n\t\treturn ErrServerError\r\n\t}\r\n\tme, any := make(appengine.MultiError, len(item)), false\r\n\tfor i, st := range res.SetStatus {\r\n\t\tvar err error\r\n\t\tswitch st {\r\n\t\tcase pb.MemcacheSetResponse_STORED:\r\n\t\t\t\r\n\t\tcase pb.MemcacheSetResponse_NOT_STORED:\r\n\t\t\terr = ErrNotStored\r\n\t\tcase pb.MemcacheSetResponse_EXISTS:\r\n\t\t\terr = ErrCASConflict\r\n\t\tdefault:\r\n\t\t\terr = ErrServerError\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\tme[i] = err\r\n\t\t\tany = true\r\n\t\t}\r\n\t}\r\n\tif any {\r\n\t\treturn me\r\n\t}\r\n\treturn nil\r\n}","code-length":746,"reference":"\/\/ set sets the given items using the given conflict resolution policy.\n\/\/ appengine.MultiError may be returned.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cd Codec) Get(c context.Context, key string, v interface{}) (*Item, error) {\r\n\ti, err := Get(c, key)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err := cd.Unmarshal(i.Value, v); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn i, nil\r\n}","code-length":110,"reference":"\/\/ Get gets the item for the given key and decodes the obtained value into v.\n\/\/ ErrCacheMiss is returned for a memcache cache miss.\n\/\/ The key must be at most 250 bytes in length.","result":"Get the item from the cache.","score":[0.0022,0.0606]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Stats(c context.Context) (*Statistics, error) {\r\n\treq := &pb.MemcacheStatsRequest{}\r\n\tres := &pb.MemcacheStatsResponse{}\r\n\tif err := internal.Call(c, \"memcache\", \"Stats\", req, res); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif res.Stats == nil {\r\n\t\treturn nil, ErrNoStats\r\n\t}\r\n\treturn &Statistics{\r\n\t\tHits:     *res.Stats.Hits,\r\n\t\tMisses:   *res.Stats.Misses,\r\n\t\tByteHits: *res.Stats.ByteHits,\r\n\t\tItems:    *res.Stats.Items,\r\n\t\tBytes:    *res.Stats.Bytes,\r\n\t\tOldest:   int64(*res.Stats.OldestItemAge),\r\n\t}, nil\r\n}","code-length":220,"reference":"\/\/ Stats retrieves the current memcache statistics.","result":"Call the Memcache API to get statistics.","score":[0.1921,0.2143]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Flush(c context.Context) error {\r\n\treq := &pb.MemcacheFlushRequest{}\r\n\tres := &pb.MemcacheFlushResponse{}\r\n\treturn internal.Call(c, \"memcache\", \"FlushAll\", req, res)\r\n}","code-length":70,"reference":"\/\/ Flush flushes all items from memcache.","result":"Flush all caches.","score":[0.128,0.1515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RunInBackground(c context.Context, f func(c context.Context)) error {\r\n\treq := &pb.StartBackgroundRequestRequest{}\r\n\tres := &pb.StartBackgroundRequestResponse{}\r\n\tif err := internal.Call(c, \"system\", \"StartBackgroundRequest\", req, res); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tsendc <- send{res.GetRequestId(), f}\r\n\treturn nil\r\n}","code-length":116,"reference":"\/\/ RunInBackground runs f in a background goroutine in this process.\n\/\/ f is provided a context that may outlast the context provided to RunInBackground.\n\/\/ This is only valid to invoke from a service set to basic or manual scaling.","result":"Run in background.","score":[0.0,0.0269]}
{"code":"\/*is used to<extra_id_0>\r\nfunc List(c context.Context) ([]string, error) {\r\n\treq := &pb.GetModulesRequest{}\r\n\tres := &pb.GetModulesResponse{}\r\n\terr := internal.Call(c, \"modules\", \"GetModules\", req, res)\r\n\treturn res.Module, err\r\n}","code-length":82,"reference":"\/\/ List returns the names of modules belonging to this application.","result":"List all modules in the system.","score":[0.1104,0.1429]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetNumInstances(c context.Context, module, version string, instances int) error {\r\n\treq := &pb.SetNumInstancesRequest{}\r\n\tif module != \"\" {\r\n\t\treq.Module = &module\r\n\t}\r\n\tif version != \"\" {\r\n\t\treq.Version = &version\r\n\t}\r\n\treq.Instances = proto.Int64(int64(instances))\r\n\tres := &pb.SetNumInstancesResponse{}\r\n\treturn internal.Call(c, \"modules\", \"SetNumInstances\", req, res)\r\n}","code-length":140,"reference":"\/\/ SetNumInstances sets the number of instances of the given module.version to the\n\/\/ specified value. If either module or version are the empty string it means the\n\/\/ default.","result":"Set the number of instances in a module.","score":[0.0278,0.0899]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Versions(c context.Context, module string) ([]string, error) {\r\n\treq := &pb.GetVersionsRequest{}\r\n\tif module != \"\" {\r\n\t\treq.Module = &module\r\n\t}\r\n\tres := &pb.GetVersionsResponse{}\r\n\terr := internal.Call(c, \"modules\", \"GetVersions\", req, res)\r\n\treturn res.GetVersion(), err\r\n}","code-length":108,"reference":"\/\/ Versions returns the names of the versions that belong to the specified module.\n\/\/ If module is the empty string, it means the default module.","result":"Get the versions of a module.","score":[0.0116,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DefaultVersion(c context.Context, module string) (string, error) {\r\n\treq := &pb.GetDefaultVersionRequest{}\r\n\tif module != \"\" {\r\n\t\treq.Module = &module\r\n\t}\r\n\tres := &pb.GetDefaultVersionResponse{}\r\n\terr := internal.Call(c, \"modules\", \"GetDefaultVersion\", req, res)\r\n\treturn res.GetVersion(), err\r\n}","code-length":110,"reference":"\/\/ DefaultVersion returns the default version of the specified module.\n\/\/ If module is the empty string, it means the default module.","result":"Get the default version of the module.","score":[0.0825,0.208]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Start(c context.Context, module, version string) error {\r\n\treq := &pb.StartModuleRequest{}\r\n\tif module != \"\" {\r\n\t\treq.Module = &module\r\n\t}\r\n\tif version != \"\" {\r\n\t\treq.Version = &version\r\n\t}\r\n\tres := &pb.StartModuleResponse{}\r\n\treturn internal.Call(c, \"modules\", \"StartModule\", req, res)\r\n}","code-length":116,"reference":"\/\/ Start starts the specified version of the specified module.\n\/\/ If either module or version are the empty string, it means the default.","result":"Start the module.","score":[0.0005,0.0685]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Stop(c context.Context, module, version string) error {\r\n\treq := &pb.StopModuleRequest{}\r\n\tif module != \"\" {\r\n\t\treq.Module = &module\r\n\t}\r\n\tif version != \"\" {\r\n\t\treq.Version = &version\r\n\t}\r\n\tres := &pb.StopModuleResponse{}\r\n\treturn internal.Call(c, \"modules\", \"StopModule\", req, res)\r\n}","code-length":116,"reference":"\/\/ Stop stops the specified version of the specified module.\n\/\/ If either module or version are the empty string, it means the default.","result":"Stop a module.","score":[0.0004,0.0457]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *Query) Ancestor(ancestor *Key) *Query {\r\n\tq = q.clone()\r\n\tif ancestor == nil {\r\n\t\tq.err = errors.New(\"datastore: nil query ancestor\")\r\n\t\treturn q\r\n\t}\r\n\tq.ancestor = ancestor\r\n\treturn q\r\n}","code-length":86,"reference":"\/\/ Ancestor returns a derivative query with an ancestor filter.\n\/\/ The ancestor should not be nil.","result":"Create a query .","score":[0.0147,0.0637]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *Query) EventualConsistency() *Query {\r\n\tq = q.clone()\r\n\tq.eventual = true\r\n\treturn q\r\n}","code-length":48,"reference":"\/\/ EventualConsistency returns a derivative query that returns eventually\n\/\/ consistent results.\n\/\/ It only has an effect on ancestor queries.","result":"Enforce the consistency of the query.","score":[0,0.0256]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *Query) Project(fieldNames ...string) *Query {\r\n\tq = q.clone()\r\n\tq.projection = append([]string(nil), fieldNames...)\r\n\treturn q\r\n}","code-length":58,"reference":"\/\/ Project returns a derivative query that yields only the given fields. It\n\/\/ cannot be used with KeysOnly.","result":"Create a new query.","score":[0.0075,0.0286]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *Query) Distinct() *Query {\r\n\tq = q.clone()\r\n\tq.distinct = true\r\n\treturn q\r\n}","code-length":46,"reference":"\/\/ Distinct returns a derivative query that yields de-duplicated entities with\n\/\/ respect to the set of projected fields. It is only used for projection\n\/\/ queries. Distinct cannot be used with DistinctOn.","result":"Create a query to return a distinct set of results.","score":[0.0194,0.1865]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *Query) DistinctOn(fieldNames ...string) *Query {\r\n\tq = q.clone()\r\n\tq.distinctOn = fieldNames\r\n\treturn q\r\n}","code-length":53,"reference":"\/\/ DistinctOn returns a derivative query that yields de-duplicated entities with\n\/\/ respect to the set of the specified fields. It is only used for projection\n\/\/ queries. The field list should be a subset of the projected field list.\n\/\/ DistinctOn cannot be used with Distinct.","result":"Create a query with distinctOn.","score":[0.0001,0.035]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *Query) KeysOnly() *Query {\r\n\tq = q.clone()\r\n\tq.keysOnly = true\r\n\treturn q\r\n}","code-length":47,"reference":"\/\/ KeysOnly returns a derivative query that yields only keys, not keys and\n\/\/ entities. It cannot be used with projection queries.","result":"Test if query is keys only.","score":[0.016,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *Query) Limit(limit int) *Query {\r\n\tq = q.clone()\r\n\tif limit < math.MinInt32 || limit > math.MaxInt32 {\r\n\t\tq.err = errors.New(\"datastore: query limit overflow\")\r\n\t\treturn q\r\n\t}\r\n\tq.limit = int32(limit)\r\n\treturn q\r\n}","code-length":100,"reference":"\/\/ Limit returns a derivative query that has a limit on the number of results\n\/\/ returned. A negative value means unlimited.","result":"Set the limit of the query.","score":[0.0177,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *Query) Offset(offset int) *Query {\r\n\tq = q.clone()\r\n\tif offset < 0 {\r\n\t\tq.err = errors.New(\"datastore: negative query offset\")\r\n\t\treturn q\r\n\t}\r\n\tif offset > math.MaxInt32 {\r\n\t\tq.err = errors.New(\"datastore: query offset overflow\")\r\n\t\treturn q\r\n\t}\r\n\tq.offset = int32(offset)\r\n\treturn q\r\n}","code-length":128,"reference":"\/\/ Offset returns a derivative query that has an offset of how many keys to\n\/\/ skip over before returning results. A negative value is invalid.","result":"Set the offset.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *Query) BatchSize(size int) *Query {\r\n\tq = q.clone()\r\n\tif size <= 0 || size > math.MaxInt32 {\r\n\t\tq.err = errors.New(\"datastore: query batch size overflow\")\r\n\t\treturn q\r\n\t}\r\n\tq.count = int32(size)\r\n\treturn q\r\n}","code-length":98,"reference":"\/\/ BatchSize returns a derivative query to fetch the supplied number of results\n\/\/ at once. This value should be greater than zero, and equal to or less than\n\/\/ the Limit.","result":"Batch size queries.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *Query) Start(c Cursor) *Query {\r\n\tq = q.clone()\r\n\tif c.cc == nil {\r\n\t\tq.err = errors.New(\"datastore: invalid cursor\")\r\n\t\treturn q\r\n\t}\r\n\tq.start = c.cc\r\n\treturn q\r\n}","code-length":87,"reference":"\/\/ Start returns a derivative query with the given start point.","result":"Start a query.","score":[0.0337,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *Query) End(c Cursor) *Query {\r\n\tq = q.clone()\r\n\tif c.cc == nil {\r\n\t\tq.err = errors.New(\"datastore: invalid cursor\")\r\n\t\treturn q\r\n\t}\r\n\tq.end = c.cc\r\n\treturn q\r\n}","code-length":87,"reference":"\/\/ End returns a derivative query with the given end point.","result":"End the query.","score":[0.0337,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *Query) Count(c context.Context) (int, error) {\r\n\t\r\n\tif q.err != nil {\r\n\t\treturn 0, q.err\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tnewQ := q.clone()\r\n\tnewQ.keysOnly = len(newQ.projection) == 0\r\n\tnewQ.limit = 0\r\n\tif q.limit < 0 {\r\n\t\t\r\n\t\tnewQ.offset = math.MaxInt32\r\n\t} else {\r\n\t\tnewQ.offset = q.offset + q.limit\r\n\t\tif newQ.offset < 0 {\r\n\t\t\t\r\n\t\t\tnewQ.offset = math.MaxInt32\r\n\t\t}\r\n\t}\r\n\treq := &pb.Query{}\r\n\tif err := newQ.toProto(req, internal.FullyQualifiedAppID(c)); err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\tres := &pb.QueryResult{}\r\n\tif err := internal.Call(c, \"datastore_v3\", \"RunQuery\", req, res); err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\")\r\n\t\t}\r\n\t\tn += res.GetSkippedResults()\r\n\t\tif !res.GetMoreResults() {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif err := callNext(c, res, newQ.offset-n, q.count); err != nil {\r\n\t\t\treturn 0, err\r\n\t\t}\r\n\t}\r\n\tn -= q.offset\r\n\tif n < 0 {\r\n\t\t\r\n\t\t\r\n\t\tn = 0\r\n\t}\r\n\treturn int(n), nil\r\n}","code-length":439,"reference":"\/\/ Count returns the number of results for the query.\n\/\/\n\/\/ The running time and number of API calls made by Count scale linearly with\n\/\/ the sum of the query's offset and limit. Unless the result count is\n\/\/ expected to be small, it is best to specify a limit; otherwise Count will\n\/\/ continue until it finishes counting or the provided context expires.","result":"Count the results of a query.","score":[0.0,0.05]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *Query) Run(c context.Context) *Iterator {\r\n\tif q.err != nil {\r\n\t\treturn &Iterator{err: q.err}\r\n\t}\r\n\tt := &Iterator{\r\n\t\tc:      c,\r\n\t\tlimit:  q.limit,\r\n\t\tcount:  q.count,\r\n\t\tq:      q,\r\n\t\tprevCC: q.start,\r\n\t}\r\n\tvar req pb.Query\r\n\tif err := q.toProto(&req, internal.FullyQualifiedAppID(c)); err != nil {\r\n\t\tt.err = err\r\n\t\treturn t\r\n\t}\r\n\tif err := internal.Call(c, \"datastore_v3\", \"RunQuery\", &req, &t.res); err != nil {\r\n\t\tt.err = err\r\n\t\treturn t\r\n\t}\r\n\toffset := q.offset - t.res.GetSkippedResults()\r\n\tvar count int32\r\n\tif t.count > 0 && (t.limit < 0 || t.count < t.limit) {\r\n\t\tcount = t.count\r\n\t} else {\r\n\t\tcount = t.limit\r\n\t}\r\n\tfor offset > 0 && t.res.GetMoreResults() {\r\n\t\tt.prevCC = t.res.CompiledCursor\r\n\t\tif err := callNext(t.c, &t.res, offset, count); err != nil {\r\n\t\t\tt.err = err\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tskip := t.res.GetSkippedResults()\r\n\t\tif skip < 0 {\r\n\t\t\tt.err = errors.New(\"datastore: internal error: negative number of skipped_results\")\r\n\t\t\tbreak\r\n\t\t}\r\n\t\toffset -= skip\r\n\t}\r\n\tif offset < 0 {\r\n\t\tt.err = errors.New(\"datastore: internal error: query offset was overshot\")\r\n\t}\r\n\treturn t\r\n}","code-length":490,"reference":"\/\/ Run runs the query in the given context.","result":"Run a query.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Iterator) Next(dst interface{}) (*Key, error) {\r\n\tk, e, err := t.next()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif dst != nil && !t.q.keysOnly {\r\n\t\terr = loadEntity(dst, e)\r\n\t}\r\n\treturn k, err\r\n}","code-length":104,"reference":"\/\/ Next returns the key of the next result. When there are no more results,\n\/\/ Done is returned as the error.\n\/\/\n\/\/ If the query is not keys only and dst is non-nil, it also loads the entity\n\/\/ stored for that key into the struct pointer or PropertyLoadSaver dst, with\n\/\/ the same semantics and possible errors as for the Get function.","result":"Load the next value of the iterator.","score":[0.0001,0.0422]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Iterator) Cursor() (Cursor, error) {\r\n\tif t.err != nil && t.err != Done {\r\n\t\treturn Cursor{}, t.err\r\n\t}\r\n\t\r\n\t\r\n\tskipped := t.res.GetSkippedResults()\r\n\tif t.i == 0 && skipped == 0 {\r\n\t\tif t.prevCC == nil {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\treturn Cursor{&zeroCC}, nil\r\n\t\t}\r\n\t\treturn Cursor{t.prevCC}, nil\r\n\t}\r\n\tif t.i == len(t.res.Result) {\r\n\t\treturn Cursor{t.res.CompiledCursor}, nil\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tq := t.q.clone()\r\n\tq.start = t.prevCC\r\n\tq.offset = skipped + int32(t.i)\r\n\tq.limit = 0\r\n\tq.keysOnly = len(q.projection) == 0\r\n\tt1 := q.Run(t.c)\r\n\t_, _, err := t1.next()\r\n\tif err != Done {\r\n\t\tif err == nil {\r\n\t\t\terr = fmt.Errorf(\"datastore: internal error: zero-limit query did not have zero results\")\r\n\t\t}\r\n\t\treturn Cursor{}, err\r\n\t}\r\n\treturn Cursor{t1.res.CompiledCursor}, nil\r\n}","code-length":370,"reference":"\/\/ Cursor returns a cursor for the iterator's current location.","result":"Avoid the need for the cursor to be closed.","score":[0.1707,0.2581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c Cursor) String() string {\r\n\tif c.cc == nil {\r\n\t\treturn \"\"\r\n\t}\r\n\tb, err := proto.Marshal(c.cc)\r\n\tif err != nil {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tpanic(fmt.Sprintf(\"datastore: internal error: malformed cursor: %v\", err))\r\n\t}\r\n\treturn strings.TrimRight(base64.URLEncoding.EncodeToString(b), \"=\")\r\n}","code-length":124,"reference":"\/\/ String returns a base-64 string representation of a cursor.","result":"Return a string representation of the cursor.","score":[0.2462,0.5269]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DecodeCursor(s string) (Cursor, error) {\r\n\tif s == \"\" {\r\n\t\treturn Cursor{&zeroCC}, nil\r\n\t}\r\n\tif n := len(s) % 4; n != 0 {\r\n\t\ts += strings.Repeat(\"=\", 4-n)\r\n\t}\r\n\tb, err := base64.URLEncoding.DecodeString(s)\r\n\tif err != nil {\r\n\t\treturn Cursor{}, err\r\n\t}\r\n\tcc := &pb.CompiledCursor{}\r\n\tif err := proto.Unmarshal(b, cc); err != nil {\r\n\t\treturn Cursor{}, err\r\n\t}\r\n\treturn Cursor{cc}, nil\r\n}","code-length":176,"reference":"\/\/ Decode decodes a cursor from its base-64 string representation.","result":"Decode a cursor from a string.","score":[0.2194,0.3288]}
{"code":"\/*is used to<extra_id_0>\r\nfunc saveEntity(defaultAppID string, key *Key, src interface{}) (*pb.EntityProto, error) {\r\n\tvar err error\r\n\tvar props []Property\r\n\tif e, ok := src.(PropertyLoadSaver); ok {\r\n\t\tprops, err = e.Save()\r\n\t} else {\r\n\t\tprops, err = SaveStruct(src)\r\n\t}\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn propertiesToProto(defaultAppID, key, props)\r\n}","code-length":141,"reference":"\/\/ saveEntity saves an EntityProto into a PropertyLoadSaver or struct pointer.","result":"Save entity.","score":[0,0.0495]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Namespace(c context.Context, namespace string) (context.Context, error) {\r\n\tif !validNamespace.MatchString(namespace) {\r\n\t\treturn nil, fmt.Errorf(\"appengine: namespace %q does not match \/%s\/\", namespace, validNamespace)\r\n\t}\r\n\treturn internal.NamespacedContext(c, namespace), nil\r\n}","code-length":95,"reference":"\/\/ Namespace returns a replacement context that operates within the given namespace.","result":"Create a new namespace.","score":[0.0514,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cfg *TypeConfig) typeof(name string) string {\r\n\tif cfg.Var != nil {\r\n\t\tif t := cfg.Var[name]; t != \"\" {\r\n\t\t\treturn t\r\n\t\t}\r\n\t}\r\n\tif cfg.Func != nil {\r\n\t\tif t := cfg.Func[name]; t != \"\" {\r\n\t\t\treturn \"func()\" + t\r\n\t\t}\r\n\t}\r\n\treturn \"\"\r\n}","code-length":119,"reference":"\/\/ typeof returns the type of the given name, which may be of\n\/\/ the form \"x\" or \"p.X\".","result":"Generate the type string for the type definition.","score":[0.055,0.0838]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (typ *Type) dot(cfg *TypeConfig, name string) string {\r\n\tif typ.Field != nil {\r\n\t\tif t := typ.Field[name]; t != \"\" {\r\n\t\t\treturn t\r\n\t\t}\r\n\t}\r\n\tif typ.Method != nil {\r\n\t\tif t := typ.Method[name]; t != \"\" {\r\n\t\t\treturn t\r\n\t\t}\r\n\t}\r\n\tfor _, e := range typ.Embed {\r\n\t\tetyp := cfg.Type[e]\r\n\t\tif etyp != nil {\r\n\t\t\tif t := etyp.dot(cfg, name); t != \"\" {\r\n\t\t\t\treturn t\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn \"\"\r\n}","code-length":195,"reference":"\/\/ dot returns the type of \"typ.name\", making its decision\n\/\/ using the type information in cfg.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc joinFunc(in, out []string) string {\r\n\touts := \"\"\r\n\tif len(out) == 1 {\r\n\t\touts = \" \" + out[0]\r\n\t} else if len(out) > 1 {\r\n\t\touts = \" (\" + join(out) + \")\"\r\n\t}\r\n\treturn \"func(\" + join(in) + \")\" + outs\r\n}","code-length":102,"reference":"\/\/ joinFunc is the inverse of splitFunc.","result":"Join functions.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc validPropertyName(name string) bool {\r\n\tif name == \"\" {\r\n\t\treturn false\r\n\t}\r\n\tfor _, s := range strings.Split(name, \".\") {\r\n\t\tif s == \"\" {\r\n\t\t\treturn false\r\n\t\t}\r\n\t\tfirst := true\r\n\t\tfor _, c := range s {\r\n\t\t\tif first {\r\n\t\t\t\tfirst = false\r\n\t\t\t\tif c != '_' && !unicode.IsLetter(c) {\r\n\t\t\t\t\treturn false\r\n\t\t\t\t}\r\n\t\t\t} else {\r\n\t\t\t\tif c != '_' && !unicode.IsLetter(c) && !unicode.IsDigit(c) {\r\n\t\t\t\t\treturn false\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":203,"reference":"\/\/ validPropertyName returns whether name consists of one or more valid Go\n\/\/ identifiers joined by \".\".","result":"Check if a property name is valid.","score":[0.0387,0.0312]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getStructCodec(t reflect.Type) (*structCodec, error) {\r\n\tstructCodecsMutex.Lock()\r\n\tdefer structCodecsMutex.Unlock()\r\n\treturn getStructCodecLocked(t)\r\n}","code-length":62,"reference":"\/\/ getStructCodec returns the structCodec for the given struct type.","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadStruct(dst interface{}, p []Property) error {\r\n\tx, err := newStructPLS(dst)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn x.Load(p)\r\n}","code-length":68,"reference":"\/\/ LoadStruct loads the properties from p to dst.\n\/\/ dst must be a struct pointer.","result":"Load a struct.","score":[0.0054,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SaveStruct(src interface{}) ([]Property, error) {\r\n\tx, err := newStructPLS(src)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn x.Save()\r\n}","code-length":69,"reference":"\/\/ SaveStruct returns the properties from src as a slice of Properties.\n\/\/ src must be a struct pointer.","result":"Save a struct.","score":[0.002,0.0287]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ServingURL(c context.Context, key appengine.BlobKey, opts *ServingURLOptions) (*url.URL, error) {\r\n\treq := &pb.ImagesGetUrlBaseRequest{\r\n\t\tBlobKey: (*string)(&key),\r\n\t}\r\n\tif opts != nil && opts.Secure {\r\n\t\treq.CreateSecureUrl = &opts.Secure\r\n\t}\r\n\tres := &pb.ImagesGetUrlBaseResponse{}\r\n\tif err := internal.Call(c, \"images\", \"GetUrlBase\", req, res); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tu := *res.Url\r\n\tif opts != nil && opts.Size > 0 {\r\n\t\tu += fmt.Sprintf(\"=s%d\", opts.Size)\r\n\t\tif opts.Crop {\r\n\t\t\tu += \"-c\"\r\n\t\t}\r\n\t}\r\n\treturn url.Parse(u)\r\n}","code-length":249,"reference":"\/\/ ServingURL returns a URL that will serve an image from Blobstore.","result":"Generate the URL for serving images.","score":[0.071,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DeleteServingURL(c context.Context, key appengine.BlobKey) error {\r\n\treq := &pb.ImagesDeleteUrlBaseRequest{\r\n\t\tBlobKey: (*string)(&key),\r\n\t}\r\n\tres := &pb.ImagesDeleteUrlBaseResponse{}\r\n\treturn internal.Call(c, \"images\", \"DeleteUrlBase\", req, res)\r\n}","code-length":99,"reference":"\/\/ DeleteServingURL deletes the serving URL for an image.","result":"Delete serving URLs.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CurrentOAuth(c context.Context, scopes ...string) (*User, error) {\r\n\treq := &pb.GetOAuthUserRequest{}\r\n\tif len(scopes) != 1 || scopes[0] != \"\" {\r\n\t\t\r\n\t\t\r\n\t\treq.Scopes = scopes\r\n\t}\r\n\tres := &pb.GetOAuthUserResponse{}\r\n\terr := internal.Call(c, \"user\", \"GetOAuthUser\", req, res)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &User{\r\n\t\tEmail:      *res.Email,\r\n\t\tAuthDomain: *res.AuthDomain,\r\n\t\tAdmin:      res.GetIsAdmin(),\r\n\t\tID:         *res.UserId,\r\n\t\tClientID:   res.GetClientId(),\r\n\t}, nil\r\n}","code-length":212,"reference":"\/\/ CurrentOAuth returns the user associated with the OAuth consumer making this\n\/\/ request. If the OAuth consumer did not make a valid OAuth request, or the\n\/\/ scopes is non-empty and the current user does not have at least one of the\n\/\/ scopes, this method will return an error.","result":"Get the current user.","score":[0.0,0.0324]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OAuthConsumerKey(c context.Context) (string, error) {\r\n\treq := &pb.CheckOAuthSignatureRequest{}\r\n\tres := &pb.CheckOAuthSignatureResponse{}\r\n\terr := internal.Call(c, \"user\", \"CheckOAuthSignature\", req, res)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn *res.OauthConsumerKey, err\r\n}","code-length":108,"reference":"\/\/ OAuthConsumerKey returns the OAuth consumer key provided with the current\n\/\/ request. This method will return an error if the OAuth request was invalid.","result":"Generate the consumer key.","score":[0.002,0.0437]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *User) String() string {\r\n\tif u.AuthDomain != \"\" && strings.HasSuffix(u.Email, \"@\"+u.AuthDomain) {\r\n\t\treturn u.Email[:len(u.Email)-len(\"@\"+u.AuthDomain)]\r\n\t}\r\n\tif u.FederatedIdentity != \"\" {\r\n\t\treturn u.FederatedIdentity\r\n\t}\r\n\treturn u.Email\r\n}","code-length":111,"reference":"\/\/ String returns a displayable name for the user.","result":"Generate the user.","score":[0.0781,0.2232]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoginURL(c context.Context, dest string) (string, error) {\r\n\treturn LoginURLFederated(c, dest, \"\")\r\n}","code-length":45,"reference":"\/\/ LoginURL returns a URL that, when visited, prompts the user to sign in,\n\/\/ then redirects the user to the URL specified by dest.","result":"Generate the login URL.","score":[0.0017,0.0218]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoginURLFederated(c context.Context, dest, identity string) (string, error) {\r\n\treq := &pb.CreateLoginURLRequest{\r\n\t\tDestinationUrl: proto.String(dest),\r\n\t}\r\n\tif identity != \"\" {\r\n\t\treq.FederatedIdentity = proto.String(identity)\r\n\t}\r\n\tres := &pb.CreateLoginURLResponse{}\r\n\tif err := internal.Call(c, \"user\", \"CreateLoginURL\", req, res); err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn *res.LoginUrl, nil\r\n}","code-length":155,"reference":"\/\/ LoginURLFederated is like LoginURL but accepts a user's OpenID identifier.","result":"Create a login url for a user.","score":[0.0912,0.0472]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LogoutURL(c context.Context, dest string) (string, error) {\r\n\treq := &pb.CreateLogoutURLRequest{\r\n\t\tDestinationUrl: proto.String(dest),\r\n\t}\r\n\tres := &pb.CreateLogoutURLResponse{}\r\n\tif err := internal.Call(c, \"user\", \"CreateLogoutURL\", req, res); err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn *res.LogoutUrl, nil\r\n}","code-length":123,"reference":"\/\/ LogoutURL returns a URL that, when visited, signs the user out,\n\/\/ then redirects the user to the URL specified by dest.","result":"Create a new logout URL.","score":[0.0066,0.0236]}
{"code":"\/*is used to<extra_id_0>\r\nfunc insertContext(f *ast.File, call *ast.CallExpr, ctx *ast.Ident) {\r\n\tif ctx == nil {\r\n\t\t\r\n\t\tctx = ast.NewIdent(\"ctx\")\r\n\t} else {\r\n\t\t\r\n\t\tctx = ast.NewIdent(ctx.Name)\r\n\t}\r\n\tcall.Args = append([]ast.Expr{ctx}, call.Args...)\r\n}","code-length":108,"reference":"\/\/ ctx may be nil.","result":"Insert the context.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(host string, client *http.Client) (*Client, error) {\r\n\t\r\n\twrapClient := new(http.Client)\r\n\t*wrapClient = *client\r\n\tt := client.Transport\r\n\tif t == nil {\r\n\t\tt = http.DefaultTransport\r\n\t}\r\n\twrapClient.Transport = &headerAddingRoundTripper{t}\r\n\turl := url.URL{\r\n\t\tScheme: \"https\",\r\n\t\tHost:   host,\r\n\t\tPath:   \"\/_ah\/remote_api\",\r\n\t}\r\n\tif host == \"localhost\" || strings.HasPrefix(host, \"localhost:\") {\r\n\t\turl.Scheme = \"http\"\r\n\t}\r\n\tu := url.String()\r\n\tappID, err := getAppID(wrapClient, u)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"unable to contact server: %v\", err)\r\n\t}\r\n\treturn &Client{\r\n\t\thc:    wrapClient,\r\n\t\turl:   u,\r\n\t\tappID: appID,\r\n\t}, nil\r\n}","code-length":283,"reference":"\/\/ NewClient returns a client for the given host. All communication will\n\/\/ be performed over SSL unless the host is localhost.","result":"Create a new client.","score":[0.0035,0.0248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) NewContext(parent context.Context) context.Context {\r\n\tctx := internal.WithCallOverride(parent, c.call)\r\n\tctx = internal.WithLogOverride(ctx, c.logf)\r\n\tctx = internal.WithAppIDOverride(ctx, c.appID)\r\n\treturn ctx\r\n}","code-length":88,"reference":"\/\/ NewContext returns a copy of parent that will cause App Engine API\n\/\/ calls to be sent to the client's remote host.","result":"Create a new context.","score":[0.0028,0.0237]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRemoteContext(host string, client *http.Client) (context.Context, error) {\r\n\tc, err := NewClient(host, client)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn c.NewContext(context.Background()), nil\r\n}","code-length":82,"reference":"\/\/ NewRemoteContext returns a context that gives access to the production\n\/\/ APIs for the application at the given host. All communication will be\n\/\/ performed over SSL unless the host is localhost.","result":"Create a new remote context.","score":[0.0009,0.0166]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Debugf(ctx context.Context, format string, args ...interface{}) {\r\n\tinternal.Logf(ctx, 0, format, args...)\r\n}","code-length":45,"reference":"\/\/ Debugf formats its arguments according to the format, analogous to fmt.Printf,\n\/\/ and records the text as a log message at Debug level. The message will be associated\n\/\/ with the request linked with the provided context.","result":"Debug functions.","score":[0.0,0.0145]}
{"code":"\/*is used to<extra_id_0>\r\nfunc guestbookKey(ctx context.Context) *datastore.Key {\r\n\t\r\n\treturn datastore.NewKey(ctx, \"Guestbook\", \"default_guestbook\", 0, nil)\r\n}","code-length":55,"reference":"\/\/ guestbookKey returns the key used for all guestbook entries.","result":"Generate the key for the guestbook key.","score":[0.1769,0.2062]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (opt *RetryOptions) toRetryParameters() *pb.TaskQueueRetryParameters {\r\n\tparams := &pb.TaskQueueRetryParameters{}\r\n\tif opt.RetryLimit > 0 {\r\n\t\tparams.RetryLimit = proto.Int32(opt.RetryLimit)\r\n\t}\r\n\tif opt.AgeLimit > 0 {\r\n\t\tparams.AgeLimitSec = proto.Int64(int64(opt.AgeLimit.Seconds()))\r\n\t}\r\n\tif opt.MinBackoff > 0 {\r\n\t\tparams.MinBackoffSec = proto.Float64(opt.MinBackoff.Seconds())\r\n\t}\r\n\tif opt.MaxBackoff > 0 {\r\n\t\tparams.MaxBackoffSec = proto.Float64(opt.MaxBackoff.Seconds())\r\n\t}\r\n\tif opt.MaxDoublings > 0 || (opt.MaxDoublings == 0 && opt.ApplyZeroMaxDoublings) {\r\n\t\tparams.MaxDoublings = proto.Int32(opt.MaxDoublings)\r\n\t}\r\n\treturn params\r\n}","code-length":258,"reference":"\/\/ toRetryParameter converts RetryOptions to pb.TaskQueueRetryParameters.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPOSTTask(path string, params url.Values) *Task {\r\n\th := make(http.Header)\r\n\th.Set(\"Content-Type\", \"application\/x-www-form-urlencoded\")\r\n\treturn &Task{\r\n\t\tPath:    path,\r\n\t\tPayload: []byte(params.Encode()),\r\n\t\tHeader:  h,\r\n\t\tMethod:  \"POST\",\r\n\t}\r\n}","code-length":114,"reference":"\/\/ NewPOSTTask creates a Task that will POST to a path with the given form data.","result":"Create a task.","score":[0.0054,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseRequestHeaders(h http.Header) *RequestHeaders {\r\n\tret := &RequestHeaders{\r\n\t\tQueueName: h.Get(\"X-AppEngine-QueueName\"),\r\n\t\tTaskName:  h.Get(\"X-AppEngine-TaskName\"),\r\n\t}\r\n\tret.TaskRetryCount, _ = strconv.ParseInt(h.Get(\"X-AppEngine-TaskRetryCount\"), 10, 64)\r\n\tret.TaskExecutionCount, _ = strconv.ParseInt(h.Get(\"X-AppEngine-TaskExecutionCount\"), 10, 64)\r\n\tetaSecs, _ := strconv.ParseInt(h.Get(\"X-AppEngine-TaskETA\"), 10, 64)\r\n\tif etaSecs != 0 {\r\n\t\tret.TaskETA = time.Unix(etaSecs, 0)\r\n\t}\r\n\tret.TaskPreviousResponse, _ = strconv.Atoi(h.Get(\"X-AppEngine-TaskPreviousResponse\"))\r\n\tret.TaskRetryReason = h.Get(\"X-AppEngine-TaskRetryReason\")\r\n\tif h.Get(\"X-AppEngine-FailFast\") != \"\" {\r\n\t\tret.FailFast = true\r\n\t}\r\n\treturn ret\r\n}","code-length":297,"reference":"\/\/ ParseRequestHeaders parses the special HTTP request headers available to push\n\/\/ task request handlers. This function silently ignores values of the wrong\n\/\/ format.","result":"Parse the request headers.","score":[0.002,0.0655]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Add(c context.Context, task *Task, queueName string) (*Task, error) {\r\n\treq, err := newAddReq(c, task, queueName)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tres := &pb.TaskQueueAddResponse{}\r\n\tif err := internal.Call(c, \"taskqueue\", \"Add\", req, res); err != nil {\r\n\t\tapiErr, ok := err.(*internal.APIError)\r\n\t\tif ok && alreadyAddedErrors[pb.TaskQueueServiceError_ErrorCode(apiErr.Code)] {\r\n\t\t\treturn nil, ErrTaskAlreadyAdded\r\n\t\t}\r\n\t\treturn nil, err\r\n\t}\r\n\tresultTask := *task\r\n\tresultTask.Method = task.method()\r\n\tif task.Name == \"\" {\r\n\t\tresultTask.Name = string(res.ChosenTaskName)\r\n\t}\r\n\treturn &resultTask, nil\r\n}","code-length":242,"reference":"\/\/ Add adds the task to a named queue.\n\/\/ An empty queue name means that the default queue will be used.\n\/\/ Add returns an equivalent Task with defaults filled in, including setting\n\/\/ the task's Name field to the chosen name if the original was empty.","result":"Add a task to a task queue.","score":[0.0011,0.0683]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AddMulti(c context.Context, tasks []*Task, queueName string) ([]*Task, error) {\r\n\treq := &pb.TaskQueueBulkAddRequest{\r\n\t\tAddRequest: make([]*pb.TaskQueueAddRequest, len(tasks)),\r\n\t}\r\n\tme, any := make(appengine.MultiError, len(tasks)), false\r\n\tfor i, t := range tasks {\r\n\t\treq.AddRequest[i], me[i] = newAddReq(c, t, queueName)\r\n\t\tany = any || me[i] != nil\r\n\t}\r\n\tif any {\r\n\t\treturn nil, me\r\n\t}\r\n\tres := &pb.TaskQueueBulkAddResponse{}\r\n\tif err := internal.Call(c, \"taskqueue\", \"BulkAdd\", req, res); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif len(res.Taskresult) != len(tasks) {\r\n\t\treturn nil, errors.New(\"taskqueue: server error\")\r\n\t}\r\n\ttasksOut := make([]*Task, len(tasks))\r\n\tfor i, tr := range res.Taskresult {\r\n\t\ttasksOut[i] = new(Task)\r\n\t\t*tasksOut[i] = *tasks[i]\r\n\t\ttasksOut[i].Method = tasksOut[i].method()\r\n\t\tif tasksOut[i].Name == \"\" {\r\n\t\t\ttasksOut[i].Name = string(tr.ChosenTaskName)\r\n\t\t}\r\n\t\tif *tr.Result != pb.TaskQueueServiceError_OK {\r\n\t\t\tif alreadyAddedErrors[*tr.Result] {\r\n\t\t\t\tme[i] = ErrTaskAlreadyAdded\r\n\t\t\t} else {\r\n\t\t\t\tme[i] = &internal.APIError{\r\n\t\t\t\t\tService: \"taskqueue\",\r\n\t\t\t\t\tCode:    int32(*tr.Result),\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tany = true\r\n\t\t}\r\n\t}\r\n\tif any {\r\n\t\treturn tasksOut, me\r\n\t}\r\n\treturn tasksOut, nil\r\n}","code-length":524,"reference":"\/\/ AddMulti adds multiple tasks to a named queue.\n\/\/ An empty queue name means that the default queue will be used.\n\/\/ AddMulti returns a slice of equivalent tasks with defaults filled in, including setting\n\/\/ each task's Name field to the chosen name if the original was empty.\n\/\/ If a given task is badly formed or could not be added, an appengine.MultiError is returned.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Delete(c context.Context, task *Task, queueName string) error {\r\n\terr := DeleteMulti(c, []*Task{task}, queueName)\r\n\tif me, ok := err.(appengine.MultiError); ok {\r\n\t\treturn me[0]\r\n\t}\r\n\treturn err\r\n}","code-length":85,"reference":"\/\/ Delete deletes a task from a named queue.","result":"Delete a task.","score":[0.0657,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DeleteMulti(c context.Context, tasks []*Task, queueName string) error {\r\n\ttaskNames := make([][]byte, len(tasks))\r\n\tfor i, t := range tasks {\r\n\t\ttaskNames[i] = []byte(t.Name)\r\n\t}\r\n\tif queueName == \"\" {\r\n\t\tqueueName = \"default\"\r\n\t}\r\n\treq := &pb.TaskQueueDeleteRequest{\r\n\t\tQueueName: []byte(queueName),\r\n\t\tTaskName:  taskNames,\r\n\t}\r\n\tres := &pb.TaskQueueDeleteResponse{}\r\n\tif err := internal.Call(c, \"taskqueue\", \"Delete\", req, res); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif a, b := len(req.TaskName), len(res.Result); a != b {\r\n\t\treturn fmt.Errorf(\"taskqueue: internal error: requested deletion of %d tasks, got %d results\", a, b)\r\n\t}\r\n\tme, any := make(appengine.MultiError, len(res.Result)), false\r\n\tfor i, ec := range res.Result {\r\n\t\tif ec != pb.TaskQueueServiceError_OK {\r\n\t\t\tme[i] = &internal.APIError{\r\n\t\t\t\tService: \"taskqueue\",\r\n\t\t\t\tCode:    int32(ec),\r\n\t\t\t}\r\n\t\t\tany = true\r\n\t\t}\r\n\t}\r\n\tif any {\r\n\t\treturn me\r\n\t}\r\n\treturn nil\r\n}","code-length":382,"reference":"\/\/ DeleteMulti deletes multiple tasks from a named queue.\n\/\/ If a given task could not be deleted, an appengine.MultiError is returned.\n\/\/ Each task is deleted independently; one may fail to delete while the others\n\/\/ are sucessfully deleted.","result":"Delete multiple tasks in a single transaction.","score":[0.0023,0.086]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Lease(c context.Context, maxTasks int, queueName string, leaseTime int) ([]*Task, error) {\r\n\treturn lease(c, maxTasks, queueName, leaseTime, false, nil)\r\n}","code-length":58,"reference":"\/\/ Lease leases tasks from a queue.\n\/\/ leaseTime is in seconds.\n\/\/ The number of tasks fetched will be at most maxTasks.","result":"Generate the code.","score":[0,0.0238]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LeaseByTag(c context.Context, maxTasks int, queueName string, leaseTime int, tag string) ([]*Task, error) {\r\n\treturn lease(c, maxTasks, queueName, leaseTime, true, []byte(tag))\r\n}","code-length":65,"reference":"\/\/ LeaseByTag leases tasks from a queue, grouped by tag.\n\/\/ If tag is empty, then the returned tasks are grouped by the tag of the task with earliest ETA.\n\/\/ leaseTime is in seconds.\n\/\/ The number of tasks fetched will be at most maxTasks.","result":"Avoid the following code.","score":[0.0,0.0239]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Purge(c context.Context, queueName string) error {\r\n\tif queueName == \"\" {\r\n\t\tqueueName = \"default\"\r\n\t}\r\n\treq := &pb.TaskQueuePurgeQueueRequest{\r\n\t\tQueueName: []byte(queueName),\r\n\t}\r\n\tres := &pb.TaskQueuePurgeQueueResponse{}\r\n\treturn internal.Call(c, \"taskqueue\", \"PurgeQueue\", req, res)\r\n}","code-length":114,"reference":"\/\/ Purge removes all tasks from a queue.","result":"Purge a queue.","score":[0.1207,0.3407]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ModifyLease(c context.Context, task *Task, queueName string, leaseTime int) error {\r\n\tif queueName == \"\" {\r\n\t\tqueueName = \"default\"\r\n\t}\r\n\treq := &pb.TaskQueueModifyTaskLeaseRequest{\r\n\t\tQueueName:    []byte(queueName),\r\n\t\tTaskName:     []byte(task.Name),\r\n\t\tEtaUsec:      proto.Int64(task.ETA.UnixNano() \/ 1e3),\r\n\t\tLeaseSeconds: proto.Float64(float64(leaseTime)),\r\n\t}\r\n\tres := &pb.TaskQueueModifyTaskLeaseResponse{}\r\n\tif err := internal.Call(c, \"taskqueue\", \"ModifyTaskLease\", req, res); err != nil {\r\n\t\treturn err\r\n\t}\r\n\ttask.ETA = time.Unix(0, *res.UpdatedEtaUsec*1e3)\r\n\treturn nil\r\n}","code-length":234,"reference":"\/\/ ModifyLease modifies the lease of a task.\n\/\/ Used to request more processing time, or to abandon processing.\n\/\/ leaseTime is in seconds and must not be negative.","result":"Modify the lease of a task.","score":[0.0174,0.2242]}
{"code":"\/*is used to<extra_id_0>\r\nfunc QueueStats(c context.Context, queueNames []string) ([]QueueStatistics, error) {\r\n\treq := &pb.TaskQueueFetchQueueStatsRequest{\r\n\t\tQueueName: make([][]byte, len(queueNames)),\r\n\t}\r\n\tfor i, q := range queueNames {\r\n\t\tif q == \"\" {\r\n\t\t\tq = \"default\"\r\n\t\t}\r\n\t\treq.QueueName[i] = []byte(q)\r\n\t}\r\n\tres := &pb.TaskQueueFetchQueueStatsResponse{}\r\n\tif err := internal.Call(c, \"taskqueue\", \"FetchQueueStats\", req, res); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tqs := make([]QueueStatistics, len(res.Queuestats))\r\n\tfor i, qsg := range res.Queuestats {\r\n\t\tqs[i] = QueueStatistics{\r\n\t\t\tTasks: int(*qsg.NumTasks),\r\n\t\t}\r\n\t\tif eta := *qsg.OldestEtaUsec; eta > -1 {\r\n\t\t\tqs[i].OldestETA = time.Unix(0, eta*1e3)\r\n\t\t}\r\n\t\tif si := qsg.ScannerInfo; si != nil {\r\n\t\t\tqs[i].Executed1Minute = int(*si.ExecutedLastMinute)\r\n\t\t\tqs[i].InFlight = int(si.GetRequestsInFlight())\r\n\t\t\tqs[i].EnforcedRate = si.GetEnforcedRate()\r\n\t\t}\r\n\t}\r\n\treturn qs, nil\r\n}","code-length":394,"reference":"\/\/ QueueStats retrieves statistics about queues.","result":"Fetch queue stats.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsTimeoutError(err error) bool {\r\n\tif err == context.DeadlineExceeded {\r\n\t\treturn true\r\n\t}\r\n\tif t, ok := err.(interface {\r\n\t\tIsTimeout() bool\r\n\t}); ok {\r\n\t\treturn t.IsTimeout()\r\n\t}\r\n\treturn false\r\n}","code-length":89,"reference":"\/\/ IsTimeoutError reports whether err is a timeout error.","result":"Check if the error is timeout.","score":[0.1171,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Func(key string, i interface{}) *Function {\r\n\tf := &Function{fv: reflect.ValueOf(i)}\r\n\t\r\n\t_, file, _, _ := runtime.Caller(1)\r\n\tfk, err := fileKey(file)\r\n\tif err != nil {\r\n\t\t\r\n\t\tstdlog.Printf(\"delay: %v\", err)\r\n\t}\r\n\tf.key = fk + \":\" + key\r\n\tt := f.fv.Type()\r\n\tif t.Kind() != reflect.Func {\r\n\t\tf.err = errors.New(\"not a function\")\r\n\t\treturn f\r\n\t}\r\n\tif t.NumIn() == 0 || !isContext(t.In(0)) {\r\n\t\tf.err = errFirstArg\r\n\t\treturn f\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tfor i := 0; i < t.NumIn(); i++ {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif t.In(i).Kind() == reflect.Interface {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tgob.Register(reflect.Zero(t.In(i)).Interface())\r\n\t}\r\n\tif old := funcs[f.key]; old != nil {\r\n\t\told.err = fmt.Errorf(\"multiple functions registered for %s in %s\", key, file)\r\n\t}\r\n\tfuncs[f.key] = f\r\n\treturn f\r\n}","code-length":367,"reference":"\/\/ Func declares a new Function. The second argument must be a function with a\n\/\/ first argument of type context.Context.\n\/\/ This function must be called at program initialization time. That means it\n\/\/ must be called in a global variable declaration or from an init function.\n\/\/ This restriction is necessary because the instance that delays a function\n\/\/ call may not be the one that executes it. Only the code executed at program\n\/\/ initialization time is guaranteed to have been run by an instance before it\n\/\/ receives a request.","result":"Register a function in the gob package.","score":[0.0,0.0234]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *Function) Task(args ...interface{}) (*taskqueue.Task, error) {\r\n\tif f.err != nil {\r\n\t\treturn nil, fmt.Errorf(\"delay: func is invalid: %v\", f.err)\r\n\t}\r\n\tnArgs := len(args) + 1\r\n\tft := f.fv.Type()\r\n\tminArgs := ft.NumIn()\r\n\tif ft.IsVariadic() {\r\n\t\tminArgs--\r\n\t}\r\n\tif nArgs < minArgs {\r\n\t\treturn nil, fmt.Errorf(\"delay: too few arguments to func: %d < %d\", nArgs, minArgs)\r\n\t}\r\n\tif !ft.IsVariadic() && nArgs > minArgs {\r\n\t\treturn nil, fmt.Errorf(\"delay: too many arguments to func: %d > %d\", nArgs, minArgs)\r\n\t}\r\n\t\r\n\tfor i := 1; i < nArgs; i++ {\r\n\t\tat := reflect.TypeOf(args[i-1])\r\n\t\tvar dt reflect.Type\r\n\t\tif i < minArgs {\r\n\t\t\t\r\n\t\t\tdt = ft.In(i)\r\n\t\t} else {\r\n\t\t\t\r\n\t\t\tdt = ft.In(minArgs).Elem()\r\n\t\t}\r\n\t\t\r\n\t\tif at == nil {\r\n\t\t\t\r\n\t\t\tswitch dt.Kind() {\r\n\t\t\tcase reflect.Chan, reflect.Func, reflect.Interface, reflect.Map, reflect.Ptr, reflect.Slice:\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\treturn nil, fmt.Errorf(\"delay: argument %d has wrong type: %v is not nilable\", i, dt)\r\n\t\t}\r\n\t\tswitch at.Kind() {\r\n\t\tcase reflect.Chan, reflect.Func, reflect.Interface, reflect.Map, reflect.Ptr, reflect.Slice:\r\n\t\t\tav := reflect.ValueOf(args[i-1])\r\n\t\t\tif av.IsNil() {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\targs[i-1] = nil\r\n\t\t\t}\r\n\t\t}\r\n\t\tif !at.AssignableTo(dt) {\r\n\t\t\treturn nil, fmt.Errorf(\"delay: argument %d has wrong type: %v is not assignable to %v\", i, at, dt)\r\n\t\t}\r\n\t}\r\n\tinv := invocation{\r\n\t\tKey:  f.key,\r\n\t\tArgs: args,\r\n\t}\r\n\tbuf := new(bytes.Buffer)\r\n\tif err := gob.NewEncoder(buf).Encode(inv); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"delay: gob encoding failed: %v\", err)\r\n\t}\r\n\treturn &taskqueue.Task{\r\n\t\tPath:    path,\r\n\t\tPayload: buf.Bytes(),\r\n\t}, nil\r\n}","code-length":702,"reference":"\/\/ Task creates a Task that will invoke the function.\n\/\/ Its parameters may be tweaked before adding it to a queue.\n\/\/ Users should not modify the Path or Payload fields of the returned Task.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RequestHeaders(c context.Context) (*taskqueue.RequestHeaders, error) {\r\n\tif ret, ok := c.Value(headersContextKey).(*taskqueue.RequestHeaders); ok {\r\n\t\treturn ret, nil\r\n\t}\r\n\treturn nil, errOutsideDelayFunc\r\n}","code-length":79,"reference":"\/\/ Request returns the special task-queue HTTP request headers for the current\n\/\/ task queue handler. Returns an error if called from outside a delay.Func.","result":"Store request headers.","score":[0.0003,0.0219]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WithContext(parent context.Context, req *http.Request) context.Context {\r\n\treturn internal.WithContext(parent, req)\r\n}","code-length":42,"reference":"\/\/ WithContext returns a copy of the parent context\n\/\/ and associates it with an in-flight HTTP request.\n\/\/ This function is cheap.","result":"Create a new context.","score":[0.0028,0.0237]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WithAPICallFunc(ctx context.Context, f APICallFunc) context.Context {\r\n\treturn internal.WithCallOverride(ctx, internal.CallOverrideFunc(f))\r\n}","code-length":51,"reference":"\/\/ WithAPICallFunc returns a copy of the parent context\n\/\/ that will cause API calls to invoke f instead of their normal operation.\n\/\/\n\/\/ This is intended for advanced users only.","result":"Generate the code.","score":[0.0,0.0172]}
{"code":"\/*is used to<extra_id_0>\r\nfunc APICall(ctx context.Context, service, method string, in, out proto.Message) error {\r\n\treturn internal.Call(ctx, service, method, in, out)\r\n}","code-length":52,"reference":"\/\/ APICall performs an API call.\n\/\/\n\/\/ This is not intended for general use; it is exported for use in conjunction\n\/\/ with WithAPICallFunc.","result":"Generate the code.","score":[0,0.0219]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ModuleHostname(c context.Context, module, version, instance string) (string, error) {\r\n\treq := &modpb.GetHostnameRequest{}\r\n\tif module != \"\" {\r\n\t\treq.Module = &module\r\n\t}\r\n\tif version != \"\" {\r\n\t\treq.Version = &version\r\n\t}\r\n\tif instance != \"\" {\r\n\t\treq.Instance = &instance\r\n\t}\r\n\tres := &modpb.GetHostnameResponse{}\r\n\tif err := internal.Call(c, \"modules\", \"GetHostname\", req, res); err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn *res.Hostname, nil\r\n}","code-length":174,"reference":"\/\/ ModuleHostname returns a hostname of a module instance.\n\/\/ If module is the empty string, it refers to the module of the current instance.\n\/\/ If version is empty, it refers to the version of the current instance if valid,\n\/\/ or the default version of the module of the current instance.\n\/\/ If instance is empty, ModuleHostname returns the load-balancing hostname.","result":"Generate the hostname .","score":[0.0,0.0175]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AccessToken(c context.Context, scopes ...string) (token string, expiry time.Time, err error) {\r\n\treq := &pb.GetAccessTokenRequest{Scope: scopes}\r\n\tres := &pb.GetAccessTokenResponse{}\r\n\terr = internal.Call(c, \"app_identity_service\", \"GetAccessToken\", req, res)\r\n\tif err != nil {\r\n\t\treturn \"\", time.Time{}, err\r\n\t}\r\n\treturn res.GetAccessToken(), time.Unix(res.GetExpirationTime(), 0), nil\r\n}","code-length":137,"reference":"\/\/ AccessToken generates an OAuth2 access token for the specified scopes on\n\/\/ behalf of service account of this application. This token will expire after\n\/\/ the returned time.","result":"Generate the access token.","score":[0.0007,0.0566]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PublicCertificates(c context.Context) ([]Certificate, error) {\r\n\treq := &pb.GetPublicCertificateForAppRequest{}\r\n\tres := &pb.GetPublicCertificateForAppResponse{}\r\n\tif err := internal.Call(c, \"app_identity_service\", \"GetPublicCertificatesForApp\", req, res); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar cs []Certificate\r\n\tfor _, pc := range res.PublicCertificateList {\r\n\t\tcs = append(cs, Certificate{\r\n\t\t\tKeyName: pc.GetKeyName(),\r\n\t\t\tData:    []byte(pc.GetX509CertificatePem()),\r\n\t\t})\r\n\t}\r\n\treturn cs, nil\r\n}","code-length":185,"reference":"\/\/ PublicCertificates retrieves the public certificates for the app.\n\/\/ They can be used to verify a signature returned by SignBytes.","result":"Get the public certificates from the app identity service.","score":[0.0711,0.1894]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ServiceAccount(c context.Context) (string, error) {\r\n\treq := &pb.GetServiceAccountNameRequest{}\r\n\tres := &pb.GetServiceAccountNameResponse{}\r\n\terr := internal.Call(c, \"app_identity_service\", \"GetServiceAccountName\", req, res)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn res.GetServiceAccountName(), err\r\n}","code-length":109,"reference":"\/\/ ServiceAccount returns a string representing the service account name, in\n\/\/ the form of an email address (typically app_id@appspot.gserviceaccount.com).","result":"Generate the service account name.","score":[0.0246,0.1381]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SignBytes(c context.Context, bytes []byte) (keyName string, signature []byte, err error) {\r\n\treq := &pb.SignForAppRequest{BytesToSign: bytes}\r\n\tres := &pb.SignForAppResponse{}\r\n\tif err := internal.Call(c, \"app_identity_service\", \"SignForApp\", req, res); err != nil {\r\n\t\treturn \"\", nil, err\r\n\t}\r\n\treturn res.GetKeyName(), res.GetSignatureBytes(), nil\r\n}","code-length":131,"reference":"\/\/ SignBytes signs bytes using a private key unique to your application.","result":"Sign bytes.","score":[0,0.0455]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *reader) fetch(off int64) error {\r\n\treq := &blobpb.FetchDataRequest{\r\n\t\tBlobKey:    proto.String(string(r.blobKey)),\r\n\t\tStartIndex: proto.Int64(off),\r\n\t\tEndIndex:   proto.Int64(off + readBufferSize - 1),\r\n\t}\r\n\tres := &blobpb.FetchDataResponse{}\r\n\tif err := internal.Call(r.c, \"blobstore\", \"FetchData\", req, res); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif len(res.Data) == 0 {\r\n\t\treturn io.EOF\r\n\t}\r\n\tr.buf, r.r, r.off = res.Data, 0, off\r\n\treturn nil\r\n}","code-length":200,"reference":"\/\/ fetch fetches readBufferSize bytes starting at the given offset. On success,\n\/\/ the data is saved as r.buf.","result":"Avoid the need for the function .","score":[0.0346,0.0562]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *reader) seek(off int64) (int64, error) {\r\n\tdelta := off - r.off\r\n\tif delta >= 0 && delta < int64(len(r.buf)) {\r\n\t\tr.r = int(delta)\r\n\t\treturn off, nil\r\n\t}\r\n\tr.buf, r.r, r.off = nil, 0, off\r\n\treturn off, nil\r\n}","code-length":112,"reference":"\/\/ seek seeks to the given offset with an effective whence equal to SEEK_SET.\n\/\/ It discards the read buffer if the invariant cannot be maintained.","result":"Avoid the need for the reader.","score":[0.0082,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc multiKeyToProto(appID string, key []*Key) []*pb.Reference {\r\n\tret := make([]*pb.Reference, len(key))\r\n\tfor i, k := range key {\r\n\t\tret[i] = keyToProto(appID, k)\r\n\t}\r\n\treturn ret\r\n}","code-length":87,"reference":"\/\/ multiKeyToProto is a batch version of keyToProto.","result":"Convert keys to proto.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc referenceValueToKey(r *pb.PropertyValue_ReferenceValue) (k *Key, err error) {\r\n\tappID := r.GetApp()\r\n\tnamespace := r.GetNameSpace()\r\n\tfor _, e := range r.Pathelement {\r\n\t\tk = &Key{\r\n\t\t\tkind:      e.GetType(),\r\n\t\t\tstringID:  e.GetName(),\r\n\t\t\tintID:     e.GetId(),\r\n\t\t\tparent:    k,\r\n\t\t\tappID:     appID,\r\n\t\t\tnamespace: namespace,\r\n\t\t}\r\n\t\tif !k.valid() {\r\n\t\t\treturn nil, ErrInvalidKey\r\n\t\t}\r\n\t}\r\n\treturn\r\n}","code-length":183,"reference":"\/\/ It's unfortunate that the two semantically equivalent concepts pb.Reference\n\/\/ and pb.PropertyValue_ReferenceValue aren't the same type. For example, the\n\/\/ two have different protobuf field numbers.\n\/\/ referenceValueToKey is the same as protoToKey except the input is a\n\/\/ PropertyValue_ReferenceValue instead of a Reference.","result":"Generate the key from a reference value.","score":[0.0008,0.0243]}
{"code":"\/*is used to<extra_id_0>\r\nfunc keyToReferenceValue(defaultAppID string, k *Key) *pb.PropertyValue_ReferenceValue {\r\n\tref := keyToProto(defaultAppID, k)\r\n\tpe := make([]*pb.PropertyValue_ReferenceValue_PathElement, len(ref.Path.Element))\r\n\tfor i, e := range ref.Path.Element {\r\n\t\tpe[i] = &pb.PropertyValue_ReferenceValue_PathElement{\r\n\t\t\tType: e.Type,\r\n\t\t\tId:   e.Id,\r\n\t\t\tName: e.Name,\r\n\t\t}\r\n\t}\r\n\treturn &pb.PropertyValue_ReferenceValue{\r\n\t\tApp:         ref.App,\r\n\t\tNameSpace:   ref.NameSpace,\r\n\t\tPathelement: pe,\r\n\t}\r\n}","code-length":198,"reference":"\/\/ keyToReferenceValue is the same as keyToProto except the output is a\n\/\/ PropertyValue_ReferenceValue instead of a Reference.","result":"Convert a Key to a Value.","score":[0.0311,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Put(c context.Context, key *Key, src interface{}) (*Key, error) {\r\n\tk, err := PutMulti(c, []*Key{key}, []interface{}{src})\r\n\tif err != nil {\r\n\t\tif me, ok := err.(appengine.MultiError); ok {\r\n\t\t\treturn nil, me[0]\r\n\t\t}\r\n\t\treturn nil, err\r\n\t}\r\n\treturn k[0], nil\r\n}","code-length":125,"reference":"\/\/ Put saves the entity src into the datastore with key k. src must be a struct\n\/\/ pointer or implement PropertyLoadSaver; if a struct pointer then any\n\/\/ unexported fields of that struct will be skipped. If k is an incomplete key,\n\/\/ the returned key will be a unique key generated by the datastore.","result":"Store the contents of a key in the store.","score":[0.001,0.0487]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PutMulti(c context.Context, key []*Key, src interface{}) ([]*Key, error) {\r\n\tv := reflect.ValueOf(src)\r\n\tmultiArgType, _ := checkMultiArg(v)\r\n\tif multiArgType == multiArgTypeInvalid {\r\n\t\treturn nil, errors.New(\"datastore: src has invalid type\")\r\n\t}\r\n\tif len(key) != v.Len() {\r\n\t\treturn nil, errors.New(\"datastore: key and src slices have different length\")\r\n\t}\r\n\tif len(key) == 0 {\r\n\t\treturn nil, nil\r\n\t}\r\n\tappID := internal.FullyQualifiedAppID(c)\r\n\tif err := multiValid(key); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treq := &pb.PutRequest{}\r\n\tfor i := range key {\r\n\t\telem := v.Index(i)\r\n\t\tif multiArgType == multiArgTypePropertyLoadSaver || multiArgType == multiArgTypeStruct {\r\n\t\t\telem = elem.Addr()\r\n\t\t}\r\n\t\tsProto, err := saveEntity(appID, key[i], elem.Interface())\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treq.Entity = append(req.Entity, sProto)\r\n\t}\r\n\tres := &pb.PutResponse{}\r\n\tif err := internal.Call(c, \"datastore_v3\", \"Put\", req, res); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif len(key) != len(res.Key) {\r\n\t\treturn nil, errors.New(\"datastore: internal error: server returned the wrong number of keys\")\r\n\t}\r\n\tret := make([]*Key, len(key))\r\n\tfor i := range ret {\r\n\t\tvar err error\r\n\t\tret[i], err = protoToKey(res.Key[i])\r\n\t\tif err != nil || ret[i].Incomplete() {\r\n\t\t\treturn nil, errors.New(\"datastore: internal error: server returned an invalid key\")\r\n\t\t}\r\n\t}\r\n\treturn ret, nil\r\n}","code-length":542,"reference":"\/\/ PutMulti is a batch version of Put.\n\/\/\n\/\/ src must satisfy the same conditions as the dst argument to GetMulti.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Delete(c context.Context, key *Key) error {\r\n\terr := DeleteMulti(c, []*Key{key})\r\n\tif me, ok := err.(appengine.MultiError); ok {\r\n\t\treturn me[0]\r\n\t}\r\n\treturn err\r\n}","code-length":80,"reference":"\/\/ Delete deletes the entity for the given key.","result":"Delete a single item.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DeleteMulti(c context.Context, key []*Key) error {\r\n\tif len(key) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\tif err := multiValid(key); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treq := &pb.DeleteRequest{\r\n\t\tKey: multiKeyToProto(internal.FullyQualifiedAppID(c), key),\r\n\t}\r\n\tres := &pb.DeleteResponse{}\r\n\treturn internal.Call(c, \"datastore_v3\", \"Delete\", req, res)\r\n}","code-length":145,"reference":"\/\/ DeleteMulti is a batch version of Delete.","result":"Delete multiple keys.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc deploy() error {\r\n\tvlogf(\"Running command %v\", flag.Args())\r\n\tcmd := exec.Command(flag.Arg(0), flag.Args()[1:]...)\r\n\tcmd.Stdin, cmd.Stdout, cmd.Stderr = os.Stdin, os.Stdout, os.Stderr\r\n\tif err := cmd.Run(); err != nil {\r\n\t\treturn fmt.Errorf(\"unable to run %q: %v\", strings.Join(flag.Args(), \" \"), err)\r\n\t}\r\n\treturn nil\r\n}","code-length":138,"reference":"\/\/ deploy calls the provided command to deploy the app from the temporary directory.","result":"Deploy a new application.","score":[0,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (qr *Result) Next() (*Record, error) {\r\n\tif qr.err != nil {\r\n\t\treturn nil, qr.err\r\n\t}\r\n\tif len(qr.logs) > 0 {\r\n\t\tlr := qr.logs[0]\r\n\t\tqr.logs = qr.logs[1:]\r\n\t\treturn lr, nil\r\n\t}\r\n\tif qr.request.Offset == nil && qr.resultsSeen {\r\n\t\treturn nil, Done\r\n\t}\r\n\tif err := qr.run(); err != nil {\r\n\t\t\r\n\t\treturn nil, err\r\n\t}\r\n\treturn qr.Next()\r\n}","code-length":168,"reference":"\/\/ Next returns the next log record,","result":"Return the next record in the result.","score":[0.2284,0.2143]}
{"code":"\/*is used to<extra_id_0>\r\nfunc protoToAppLogs(logLines []*pb.LogLine) []AppLog {\r\n\tappLogs := make([]AppLog, len(logLines))\r\n\tfor i, line := range logLines {\r\n\t\tappLogs[i] = AppLog{\r\n\t\t\tTime:    time.Unix(0, *line.Time*1e3),\r\n\t\t\tLevel:   int(*line.Level),\r\n\t\t\tMessage: *line.LogMessage,\r\n\t\t}\r\n\t}\r\n\treturn appLogs\r\n}","code-length":135,"reference":"\/\/ protoToAppLogs takes as input an array of pointers to LogLines, the internal\n\/\/ Protocol Buffer representation of a single application-level log,\n\/\/ and converts it to an array of AppLogs, the external representation\n\/\/ of an application-level log.","result":"Convert logLines to AppLogs.","score":[0.0001,0.0282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc protoToRecord(rl *pb.RequestLog) *Record {\r\n\toffset, err := proto.Marshal(rl.Offset)\r\n\tif err != nil {\r\n\t\toffset = nil\r\n\t}\r\n\treturn &Record{\r\n\t\tAppID:             *rl.AppId,\r\n\t\tModuleID:          rl.GetModuleId(),\r\n\t\tVersionID:         *rl.VersionId,\r\n\t\tRequestID:         rl.RequestId,\r\n\t\tOffset:            offset,\r\n\t\tIP:                *rl.Ip,\r\n\t\tNickname:          rl.GetNickname(),\r\n\t\tAppEngineRelease:  string(rl.GetAppEngineRelease()),\r\n\t\tStartTime:         time.Unix(0, *rl.StartTime*1e3),\r\n\t\tEndTime:           time.Unix(0, *rl.EndTime*1e3),\r\n\t\tLatency:           time.Duration(*rl.Latency) * time.Microsecond,\r\n\t\tMCycles:           *rl.Mcycles,\r\n\t\tMethod:            *rl.Method,\r\n\t\tResource:          *rl.Resource,\r\n\t\tHTTPVersion:       *rl.HttpVersion,\r\n\t\tStatus:            *rl.Status,\r\n\t\tResponseSize:      *rl.ResponseSize,\r\n\t\tReferrer:          rl.GetReferrer(),\r\n\t\tUserAgent:         rl.GetUserAgent(),\r\n\t\tURLMapEntry:       *rl.UrlMapEntry,\r\n\t\tCombined:          *rl.Combined,\r\n\t\tHost:              rl.GetHost(),\r\n\t\tCost:              rl.GetCost(),\r\n\t\tTaskQueueName:     rl.GetTaskQueueName(),\r\n\t\tTaskName:          rl.GetTaskName(),\r\n\t\tWasLoadingRequest: rl.GetWasLoadingRequest(),\r\n\t\tPendingTime:       time.Duration(rl.GetPendingTime()) * time.Microsecond,\r\n\t\tFinished:          rl.GetFinished(),\r\n\t\tAppLogs:           protoToAppLogs(rl.Line),\r\n\t\tInstanceID:        string(rl.GetCloneKey()),\r\n\t}\r\n}","code-length":513,"reference":"\/\/ protoToRecord converts a RequestLog, the internal Protocol Buffer\n\/\/ representation of a single request-level log, to a Record, its\n\/\/ corresponding external representation.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (params *Query) Run(c context.Context) *Result {\r\n\treq, err := makeRequest(params, internal.FullyQualifiedAppID(c), appengine.VersionID(c))\r\n\treturn &Result{\r\n\t\tcontext: c,\r\n\t\trequest: req,\r\n\t\terr:     err,\r\n\t}\r\n}","code-length":92,"reference":"\/\/ Run starts a query for log records, which contain request and application\n\/\/ level log information.","result":"Run the query.","score":[0.0038,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Result) run() error {\r\n\tres := &pb.LogReadResponse{}\r\n\tif err := internal.Call(r.context, \"logservice\", \"Read\", r.request, res); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tr.logs = make([]*Record, len(res.Log))\r\n\tr.request.Offset = res.Offset\r\n\tr.resultsSeen = true\r\n\tfor i, log := range res.Log {\r\n\t\tr.logs[i] = protoToRecord(log)\r\n\t}\r\n\treturn nil\r\n}","code-length":153,"reference":"\/\/ run takes the query Result produced by a call to Run and updates it with\n\/\/ more Records. The updated Result contains a new set of logs as well as an\n\/\/ offset to where more logs can be found. We also convert the items in the\n\/\/ response from their internal representations to external versions of the\n\/\/ same structs.","result":"Run the log service .","score":[0.0,0.0266]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Current(c context.Context) *User {\r\n\th := internal.IncomingHeaders(c)\r\n\tu := &User{\r\n\t\tEmail:             h.Get(\"X-AppEngine-User-Email\"),\r\n\t\tAuthDomain:        h.Get(\"X-AppEngine-Auth-Domain\"),\r\n\t\tID:                h.Get(\"X-AppEngine-User-Id\"),\r\n\t\tAdmin:             h.Get(\"X-AppEngine-User-Is-Admin\") == \"1\",\r\n\t\tFederatedIdentity: h.Get(\"X-AppEngine-Federated-Identity\"),\r\n\t\tFederatedProvider: h.Get(\"X-AppEngine-Federated-Provider\"),\r\n\t}\r\n\tif u.Email == \"\" && u.FederatedIdentity == \"\" {\r\n\t\treturn nil\r\n\t}\r\n\treturn u\r\n}","code-length":216,"reference":"\/\/ Current returns the currently logged-in user,\n\/\/ or nil if the user is not signed in.","result":"Get the current user from the current user store.","score":[0.0659,0.2296]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsAdmin(c context.Context) bool {\r\n\th := internal.IncomingHeaders(c)\r\n\treturn h.Get(\"X-AppEngine-User-Is-Admin\") == \"1\"\r\n}","code-length":58,"reference":"\/\/ IsAdmin returns true if the current user is signed in and\n\/\/ is currently registered as an administrator of the application.","result":"Check if the user is an admin.","score":[0.0373,0.122]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isErrFieldMismatch(err error) bool {\r\n\t_, ok := err.(*datastore.ErrFieldMismatch)\r\n\treturn ok\r\n}","code-length":44,"reference":"\/\/ isErrFieldMismatch returns whether err is a datastore.ErrFieldMismatch.\n\/\/\n\/\/ The blobstore stores blob metadata in the datastore. When loading that\n\/\/ metadata, it may contain fields that we don't care about. datastore.Get will\n\/\/ return datastore.ErrFieldMismatch in that case, so we ignore that specific\n\/\/ error.","result":"Generate the code.","score":[0.0,0.0117]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Stat(c context.Context, blobKey appengine.BlobKey) (*BlobInfo, error) {\r\n\tc, _ = appengine.Namespace(c, \"\")\r\n\tdskey := datastore.NewKey(c, blobInfoKind, string(blobKey), 0, nil)\r\n\tbi := &BlobInfo{\r\n\t\tBlobKey: blobKey,\r\n\t}\r\n\tif err := datastore.Get(c, dskey, bi); err != nil && !isErrFieldMismatch(err) {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn bi, nil\r\n}","code-length":150,"reference":"\/\/ Stat returns the BlobInfo for a provided blobKey. If no blob was found for\n\/\/ that key, Stat returns datastore.ErrNoSuchEntity.","result":"Check the existence of the blobKey.","score":[0.0188,0.0513]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Send(response http.ResponseWriter, blobKey appengine.BlobKey) {\r\n\thdr := response.Header()\r\n\thdr.Set(\"X-AppEngine-BlobKey\", string(blobKey))\r\n\tif hdr.Get(\"Content-Type\") == \"\" {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\thdr.Set(\"Content-Type\", \"application\/vnd.google.appengine.auto\")\r\n\t}\r\n}","code-length":112,"reference":"\/\/ Send sets the headers on response to instruct App Engine to send a blob as\n\/\/ the response body. This is more efficient than reading and writing it out\n\/\/ manually and isn't subject to normal response size limits.","result":"Send the response to the client.","score":[0.0013,0.0683]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UploadURL(c context.Context, successPath string, opts *UploadURLOptions) (*url.URL, error) {\r\n\treq := &blobpb.CreateUploadURLRequest{\r\n\t\tSuccessPath: proto.String(successPath),\r\n\t}\r\n\tif opts != nil {\r\n\t\tif n := opts.MaxUploadBytes; n != 0 {\r\n\t\t\treq.MaxUploadSizeBytes = &n\r\n\t\t}\r\n\t\tif n := opts.MaxUploadBytesPerBlob; n != 0 {\r\n\t\t\treq.MaxUploadSizePerBlobBytes = &n\r\n\t\t}\r\n\t\tif s := opts.StorageBucket; s != \"\" {\r\n\t\t\treq.GsBucketName = &s\r\n\t\t}\r\n\t}\r\n\tres := &blobpb.CreateUploadURLResponse{}\r\n\tif err := internal.Call(c, \"blobstore\", \"CreateUploadURL\", req, res); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn url.Parse(*res.Url)\r\n}","code-length":258,"reference":"\/\/ UploadURL creates an upload URL for the form that the user will\n\/\/ fill out, passing the application path to load when the POST of the\n\/\/ form is completed. These URLs expire and should not be reused. The\n\/\/ opts parameter may be nil.","result":"Create a new URL for the blobstore blob.","score":[0.0025,0.0748]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Delete(c context.Context, blobKey appengine.BlobKey) error {\r\n\treturn DeleteMulti(c, []appengine.BlobKey{blobKey})\r\n}","code-length":50,"reference":"\/\/ Delete deletes a blob.","result":"Delete blobs.","score":[0.1116,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DeleteMulti(c context.Context, blobKey []appengine.BlobKey) error {\r\n\ts := make([]string, len(blobKey))\r\n\tfor i, b := range blobKey {\r\n\t\ts[i] = string(b)\r\n\t}\r\n\treq := &blobpb.DeleteBlobRequest{\r\n\t\tBlobKey: s,\r\n\t}\r\n\tres := &basepb.VoidProto{}\r\n\tif err := internal.Call(c, \"blobstore\", \"DeleteBlob\", req, res); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":158,"reference":"\/\/ DeleteMulti deletes multiple blobs.","result":"Delete multiple blobs.","score":[0.2964,0.6134]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewReader(c context.Context, blobKey appengine.BlobKey) Reader {\r\n\treturn openBlob(c, blobKey)\r\n}","code-length":42,"reference":"\/\/ NewReader returns a reader for a blob. It always succeeds; if the blob does\n\/\/ not exist then an error will be reported upon first read.","result":"Generate generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Handle(f func(c context.Context, m *Message)) {\r\n\thttp.HandleFunc(\"\/_ah\/xmpp\/message\/chat\/\", func(_ http.ResponseWriter, r *http.Request) {\r\n\t\tf(appengine.NewContext(r), &Message{\r\n\t\t\tSender: r.FormValue(\"from\"),\r\n\t\t\tTo:     []string{r.FormValue(\"to\")},\r\n\t\t\tBody:   r.FormValue(\"body\"),\r\n\t\t})\r\n\t})\r\n}","code-length":135,"reference":"\/\/ Handle arranges for f to be called for incoming XMPP messages.\n\/\/ Only messages of type \"chat\" or \"normal\" will be handled.","result":"Handle the message.","score":[0.0005,0.0238]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) Send(c context.Context) error {\r\n\treq := &pb.XmppMessageRequest{\r\n\t\tJid:    m.To,\r\n\t\tBody:   &m.Body,\r\n\t\tRawXml: &m.RawXML,\r\n\t}\r\n\tif m.Type != \"\" && m.Type != \"chat\" {\r\n\t\treq.Type = &m.Type\r\n\t}\r\n\tif m.Sender != \"\" {\r\n\t\treq.FromJid = &m.Sender\r\n\t}\r\n\tres := &pb.XmppMessageResponse{}\r\n\tif err := internal.Call(c, \"xmpp\", \"SendMessage\", req, res); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif len(res.Status) != len(req.Jid) {\r\n\t\treturn fmt.Errorf(\"xmpp: sent message to %d JIDs, but only got %d statuses back\", len(req.Jid), len(res.Status))\r\n\t}\r\n\tme, any := make(appengine.MultiError, len(req.Jid)), false\r\n\tfor i, st := range res.Status {\r\n\t\tif st != pb.XmppMessageResponse_NO_ERROR {\r\n\t\t\tme[i] = errors.New(st.String())\r\n\t\t\tany = true\r\n\t\t}\r\n\t}\r\n\tif any {\r\n\t\treturn me\r\n\t}\r\n\treturn nil\r\n}","code-length":368,"reference":"\/\/ Send sends a message.\n\/\/ If any failures occur with specific recipients, the error will be an appengine.MultiError.","result":"Send a message to the server.","score":[0.0291,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Invite(c context.Context, to, from string) error {\r\n\treq := &pb.XmppInviteRequest{\r\n\t\tJid: &to,\r\n\t}\r\n\tif from != \"\" {\r\n\t\treq.FromJid = &from\r\n\t}\r\n\tres := &pb.XmppInviteResponse{}\r\n\treturn internal.Call(c, \"xmpp\", \"SendInvite\", req, res)\r\n}","code-length":113,"reference":"\/\/ Invite sends an invitation. If the from address is an empty string\n\/\/ the default (yourapp@appspot.com\/bot) will be used.","result":"Send an email.","score":[0.0014,0.0546]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Presence) Send(c context.Context) error {\r\n\treq := &pb.XmppSendPresenceRequest{\r\n\t\tJid: &p.To,\r\n\t}\r\n\tif p.State != \"\" {\r\n\t\treq.Show = &p.State\r\n\t}\r\n\tif p.Type != \"\" {\r\n\t\treq.Type = &p.Type\r\n\t}\r\n\tif p.Sender != \"\" {\r\n\t\treq.FromJid = &p.Sender\r\n\t}\r\n\tif p.Status != \"\" {\r\n\t\treq.Status = &p.Status\r\n\t}\r\n\tres := &pb.XmppSendPresenceResponse{}\r\n\treturn internal.Call(c, \"xmpp\", \"SendPresence\", req, res)\r\n}","code-length":199,"reference":"\/\/ Send sends a presence update.","result":"Send the presence to the server.","score":[0.2296,0.1667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetPresence(c context.Context, to string, from string) (string, error) {\r\n\treq := &pb.PresenceRequest{\r\n\t\tJid: &to,\r\n\t}\r\n\tif from != \"\" {\r\n\t\treq.FromJid = &from\r\n\t}\r\n\tres := &pb.PresenceResponse{}\r\n\tif err := internal.Call(c, \"xmpp\", \"GetPresence\", req, res); err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tif !*res.IsAvailable || res.Presence == nil {\r\n\t\treturn \"\", ErrPresenceUnavailable\r\n\t}\r\n\tpresence, ok := presenceMap[*res.Presence]\r\n\tif ok {\r\n\t\treturn presence, nil\r\n\t}\r\n\treturn \"\", fmt.Errorf(\"xmpp: unknown presence %v\", *res.Presence)\r\n}","code-length":217,"reference":"\/\/ GetPresence retrieves a user's presence.\n\/\/ If the from address is an empty string the default\n\/\/ (yourapp@appspot.com\/bot) will be used.\n\/\/ Possible return values are \"\", \"away\", \"dnd\", \"chat\", \"xa\".\n\/\/ ErrPresenceUnavailable is returned if the presence is unavailable.","result":"Get the presence of a user.","score":[0.0009,0.0681]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetPresenceMulti(c context.Context, to []string, from string) ([]string, error) {\r\n\treq := &pb.BulkPresenceRequest{\r\n\t\tJid: to,\r\n\t}\r\n\tif from != \"\" {\r\n\t\treq.FromJid = &from\r\n\t}\r\n\tres := &pb.BulkPresenceResponse{}\r\n\tif err := internal.Call(c, \"xmpp\", \"BulkGetPresence\", req, res); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tpresences := make([]string, 0, len(res.PresenceResponse))\r\n\terrs := appengine.MultiError{}\r\n\taddResult := func(presence string, err error) {\r\n\t\tpresences = append(presences, presence)\r\n\t\terrs = append(errs, err)\r\n\t}\r\n\tanyErr := false\r\n\tfor _, subres := range res.PresenceResponse {\r\n\t\tif !subres.GetValid() {\r\n\t\t\tanyErr = true\r\n\t\t\taddResult(\"\", ErrInvalidJID)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif !*subres.IsAvailable || subres.Presence == nil {\r\n\t\t\tanyErr = true\r\n\t\t\taddResult(\"\", ErrPresenceUnavailable)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tpresence, ok := presenceMap[*subres.Presence]\r\n\t\tif ok {\r\n\t\t\taddResult(presence, nil)\r\n\t\t} else {\r\n\t\t\tanyErr = true\r\n\t\t\taddResult(\"\", fmt.Errorf(\"xmpp: unknown presence %q\", *subres.Presence))\r\n\t\t}\r\n\t}\r\n\tif anyErr {\r\n\t\treturn presences, errs\r\n\t}\r\n\treturn presences, nil\r\n}","code-length":445,"reference":"\/\/ GetPresenceMulti retrieves multiple users' presence.\n\/\/ If the from address is an empty string the default\n\/\/ (yourapp@appspot.com\/bot) will be used.\n\/\/ Possible return values are \"\", \"away\", \"dnd\", \"chat\", \"xa\".\n\/\/ If any presence is unavailable, an appengine.MultiError is returned","result":"Get multiple presence requests.","score":[0.0,0.0262]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newStructFLS(p interface{}) (FieldLoadSaver, error) {\r\n\tv := reflect.ValueOf(p)\r\n\tif v.Kind() != reflect.Ptr || v.IsNil() || v.Elem().Kind() != reflect.Struct {\r\n\t\treturn nil, ErrInvalidDocumentType\r\n\t}\r\n\tcodec, err := loadCodec(v.Elem().Type())\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn structFLS{v.Elem(), codec}, nil\r\n}","code-length":138,"reference":"\/\/ newStructFLS returns a FieldLoadSaver for the struct pointer p.","result":"Create a new struct FLS .","score":[0.1179,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SaveStruct(src interface{}) ([]Field, error) {\r\n\tf, _, err := saveStructWithMeta(src)\r\n\treturn f, err\r\n}","code-length":50,"reference":"\/\/ SaveStruct returns the fields from src as a slice of Field.\n\/\/ src must be a struct pointer.","result":"Save a struct.","score":[0.002,0.0287]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Namespaces(ctx context.Context) ([]string, error) {\r\n\t\r\n\tq := NewQuery(namespaceKind).KeysOnly()\r\n\tkeys, err := q.GetAll(ctx, nil)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\t\r\n\treturn keyNames(keys), nil\r\n}","code-length":96,"reference":"\/\/ Namespaces returns all the datastore namespaces.","result":"Fetch the list of all namespaces in the namespace namespace.","score":[0.1291,0.2055]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Kinds(ctx context.Context) ([]string, error) {\r\n\t\r\n\tq := NewQuery(kindKind).KeysOnly()\r\n\tkeys, err := q.GetAll(ctx, nil)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn keyNames(keys), nil\r\n}","code-length":90,"reference":"\/\/ Kinds returns the names of all the kinds in the current namespace.","result":"Fetch the list of kinds of a service.","score":[0.0978,0.16]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RunInTransaction(c context.Context, f func(tc context.Context) error, opts *TransactionOptions) error {\r\n\txg := false\r\n\tif opts != nil {\r\n\t\txg = opts.XG\r\n\t}\r\n\treadOnly := false\r\n\tif opts != nil {\r\n\t\treadOnly = opts.ReadOnly\r\n\t}\r\n\tattempts := 3\r\n\tif opts != nil && opts.Attempts > 0 {\r\n\t\tattempts = opts.Attempts\r\n\t}\r\n\tvar t *pb.Transaction\r\n\tvar err error\r\n\tfor i := 0; i < attempts; i++ {\r\n\t\tif t, err = internal.RunTransactionOnce(c, f, xg, readOnly, t); err != internal.ErrConcurrentTransaction {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn ErrConcurrentTransaction\r\n}","code-length":217,"reference":"\/\/ RunInTransaction runs f in a transaction. It calls f with a transaction\n\/\/ context tc that f should use for all App Engine operations.\n\/\/\n\/\/ If f returns nil, RunInTransaction attempts to commit the transaction,\n\/\/ returning nil if it succeeds. If the commit fails due to a conflicting\n\/\/ transaction, RunInTransaction retries f, each time with a new transaction\n\/\/ context. It gives up and returns ErrConcurrentTransaction after three\n\/\/ failed attempts. The number of attempts can be configured by specifying\n\/\/ TransactionOptions.Attempts.\n\/\/\n\/\/ If f returns non-nil, then any datastore changes will not be applied and\n\/\/ RunInTransaction returns that same error. The function f is not retried.\n\/\/\n\/\/ Note that when f returns, the transaction is not yet committed. Calling code\n\/\/ must be careful not to assume that any of f's changes have been committed\n\/\/ until RunInTransaction returns nil.\n\/\/\n\/\/ Since f may be called multiple times, f should usually be idempotent.\n\/\/ datastore.Get is not idempotent when unmarshaling slice fields.\n\/\/\n\/\/ Nested transactions are not supported; c may not be a transaction context.","result":"Run a transaction in a transaction.","score":[0.0,0.018]}
{"code":"\/*is used to<extra_id_0>\r\nfunc imports(f *ast.File, path string) bool {\r\n\treturn importSpec(f, path) != nil\r\n}","code-length":39,"reference":"\/\/ imports returns true if f imports path.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc importSpec(f *ast.File, path string) *ast.ImportSpec {\r\n\tfor _, s := range f.Imports {\r\n\t\tif importPath(s) == path {\r\n\t\t\treturn s\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":76,"reference":"\/\/ importSpec returns the import spec if f imports path,\n\/\/ or nil otherwise.","result":"Generate the import spec.","score":[0.0371,0.1442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc declImports(gen *ast.GenDecl, path string) bool {\r\n\tif gen.Tok != token.IMPORT {\r\n\t\treturn false\r\n\t}\r\n\tfor _, spec := range gen.Specs {\r\n\t\timpspec := spec.(*ast.ImportSpec)\r\n\t\tif importPath(impspec) == path {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":113,"reference":"\/\/ declImports reports whether gen contains an import of path.","result":"Check if the import is imported.","score":[0.0991,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isPkgDot(t ast.Expr, pkg, name string) bool {\r\n\tsel, ok := t.(*ast.SelectorExpr)\r\n\treturn ok && isTopName(sel.X, pkg) && sel.Sel.String() == name\r\n}","code-length":69,"reference":"\/\/ isPkgDot returns true if t is the expression \"pkg.name\"\n\/\/ where pkg is an imported identifier.","result":"Check if a package name is a package name.","score":[0.0596,0.0617]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isTopName(n ast.Expr, name string) bool {\r\n\tid, ok := n.(*ast.Ident)\r\n\treturn ok && id.Name == name && id.Obj == nil\r\n}","code-length":58,"reference":"\/\/ isTopName returns true if n is a top-level unresolved identifier with the given name.","result":"Detect top.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isName(n ast.Expr, name string) bool {\r\n\tid, ok := n.(*ast.Ident)\r\n\treturn ok && id.String() == name\r\n}","code-length":51,"reference":"\/\/ isName returns true if n is an identifier with the given name.","result":"Check if the name is valid.","score":[0.0791,0.122]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isCall(t ast.Expr, pkg, name string) bool {\r\n\tcall, ok := t.(*ast.CallExpr)\r\n\treturn ok && isPkgDot(call.Fun, pkg, name)\r\n}","code-length":61,"reference":"\/\/ isCall returns true if t is a call to pkg.name.","result":"Check if call is call.","score":[0.0952,0.1442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc refersTo(n ast.Node, x *ast.Ident) bool {\r\n\tid, ok := n.(*ast.Ident)\r\n\t\r\n\t\r\n\treturn ok && id.Obj == x.Obj && id.Name == x.Name\r\n}","code-length":70,"reference":"\/\/ refersTo returns true if n is a reference to the same object as x.","result":"Check if a node refers to a ident.","score":[0.0762,0.2207]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isEmptyString(n ast.Expr) bool {\r\n\tlit, ok := n.(*ast.BasicLit)\r\n\treturn ok && lit.Kind == token.STRING && len(lit.Value) == 2\r\n}","code-length":60,"reference":"\/\/ isEmptyString returns true if n is an empty string literal.","result":"Check if empty string .","score":[0.1133,0.2457]}
{"code":"\/*is used to<extra_id_0>\r\nfunc countUses(x *ast.Ident, scope []ast.Stmt) int {\r\n\tcount := 0\r\n\tff := func(n interface{}) {\r\n\t\tif n, ok := n.(ast.Node); ok && refersTo(n, x) {\r\n\t\t\tcount++\r\n\t\t}\r\n\t}\r\n\tfor _, n := range scope {\r\n\t\twalk(n, ff)\r\n\t}\r\n\treturn count\r\n}","code-length":119,"reference":"\/\/ countUses returns the number of uses of the identifier x in scope.","result":"Count the number of uses in a scope.","score":[0.2575,0.24]}
{"code":"\/*is used to<extra_id_0>\r\nfunc assignsTo(x *ast.Ident, scope []ast.Stmt) bool {\r\n\tassigned := false\r\n\tff := func(n interface{}) {\r\n\t\tif assigned {\r\n\t\t\treturn\r\n\t\t}\r\n\t\tswitch n := n.(type) {\r\n\t\tcase *ast.UnaryExpr:\r\n\t\t\t\r\n\t\t\tif n.Op == token.AND && refersTo(n.X, x) {\r\n\t\t\t\tassigned = true\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\tcase *ast.AssignStmt:\r\n\t\t\tfor _, l := range n.Lhs {\r\n\t\t\t\tif refersTo(l, x) {\r\n\t\t\t\t\tassigned = true\r\n\t\t\t\t\treturn\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tfor _, n := range scope {\r\n\t\tif assigned {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\twalk(n, ff)\r\n\t}\r\n\treturn assigned\r\n}","code-length":249,"reference":"\/\/ assignsTo returns true if any of the code in scope assigns to or takes the address of x.","result":"Detect if a variable is assigned to a variable .","score":[0.0525,0.1412]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newPkgDot(pos token.Pos, pkg, name string) ast.Expr {\r\n\treturn &ast.SelectorExpr{\r\n\t\tX: &ast.Ident{\r\n\t\t\tNamePos: pos,\r\n\t\t\tName:    pkg,\r\n\t\t},\r\n\t\tSel: &ast.Ident{\r\n\t\t\tNamePos: pos,\r\n\t\t\tName:    name,\r\n\t\t},\r\n\t}\r\n}","code-length":113,"reference":"\/\/ newPkgDot returns an ast.Expr referring to \"pkg.name\" at position pos.","result":"Create a new package.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc renameTop(f *ast.File, old, new string) bool {\r\n\tvar fixed bool\r\n\t\r\n\t\r\n\tfor _, s := range f.Imports {\r\n\t\tif s.Name != nil {\r\n\t\t\tif s.Name.Name == old {\r\n\t\t\t\ts.Name.Name = new\r\n\t\t\t\tfixed = true\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\t_, thisName := path.Split(importPath(s))\r\n\t\t\tif thisName == old {\r\n\t\t\t\ts.Name = ast.NewIdent(new)\r\n\t\t\t\tfixed = true\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor _, d := range f.Decls {\r\n\t\tswitch d := d.(type) {\r\n\t\tcase *ast.FuncDecl:\r\n\t\t\tif d.Recv == nil && d.Name.Name == old {\r\n\t\t\t\td.Name.Name = new\r\n\t\t\t\td.Name.Obj.Name = new\r\n\t\t\t\tfixed = true\r\n\t\t\t}\r\n\t\tcase *ast.GenDecl:\r\n\t\t\tfor _, s := range d.Specs {\r\n\t\t\t\tswitch s := s.(type) {\r\n\t\t\t\tcase *ast.TypeSpec:\r\n\t\t\t\t\tif s.Name.Name == old {\r\n\t\t\t\t\t\ts.Name.Name = new\r\n\t\t\t\t\t\ts.Name.Obj.Name = new\r\n\t\t\t\t\t\tfixed = true\r\n\t\t\t\t\t}\r\n\t\t\t\tcase *ast.ValueSpec:\r\n\t\t\t\t\tfor _, n := range s.Names {\r\n\t\t\t\t\t\tif n.Name == old {\r\n\t\t\t\t\t\t\tn.Name = new\r\n\t\t\t\t\t\t\tn.Obj.Name = new\r\n\t\t\t\t\t\t\tfixed = true\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\twalk(f, func(n interface{}) {\r\n\t\tid, ok := n.(*ast.Ident)\r\n\t\tif ok && isTopName(id, old) {\r\n\t\t\tid.Name = new\r\n\t\t\tfixed = true\r\n\t\t}\r\n\t\tif ok && id.Obj != nil && id.Name == old && id.Obj.Name == new {\r\n\t\t\tid.Name = id.Obj.Name\r\n\t\t\tfixed = true\r\n\t\t}\r\n\t})\r\n\treturn fixed\r\n}","code-length":597,"reference":"\/\/ renameTop renames all references to the top-level name old.\n\/\/ It returns true if it makes any changes.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc matchLen(x, y string) int {\r\n\ti := 0\r\n\tfor i < len(x) && i < len(y) && x[i] == y[i] {\r\n\t\ti++\r\n\t}\r\n\treturn i\r\n}","code-length":72,"reference":"\/\/ matchLen returns the length of the longest prefix shared by x and y.","result":"Match strings .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc deleteImport(f *ast.File, path string) (deleted bool) {\r\n\toldImport := importSpec(f, path)\r\n\t\r\n\tfor i, decl := range f.Decls {\r\n\t\tgen, ok := decl.(*ast.GenDecl)\r\n\t\tif !ok || gen.Tok != token.IMPORT {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tfor j, spec := range gen.Specs {\r\n\t\t\timpspec := spec.(*ast.ImportSpec)\r\n\t\t\tif oldImport != impspec {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tdeleted = true\r\n\t\t\tcopy(gen.Specs[j:], gen.Specs[j+1:])\r\n\t\t\tgen.Specs = gen.Specs[:len(gen.Specs)-1]\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tif len(gen.Specs) == 0 {\r\n\t\t\t\tcopy(f.Decls[i:], f.Decls[i+1:])\r\n\t\t\t\tf.Decls = f.Decls[:len(f.Decls)-1]\r\n\t\t\t} else if len(gen.Specs) == 1 {\r\n\t\t\t\tgen.Lparen = token.NoPos\r\n\t\t\t}\r\n\t\t\tif j > 0 {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tgen.Specs[j-1].(*ast.ImportSpec).EndPos = impspec.End()\r\n\t\t\t}\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor i, imp := range f.Imports {\r\n\t\tif imp == oldImport {\r\n\t\t\tcopy(f.Imports[i:], f.Imports[i+1:])\r\n\t\t\tf.Imports = f.Imports[:len(f.Imports)-1]\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\treturn\r\n}","code-length":463,"reference":"\/\/ deleteImport deletes the import path from the file f, if present.","result":"Delete import.","score":[0,0.0455]}
{"code":"\/*is used to<extra_id_0>\r\nfunc rewriteImport(f *ast.File, oldPath, newPath string) (rewrote bool) {\r\n\tfor _, imp := range f.Imports {\r\n\t\tif importPath(imp) == oldPath {\r\n\t\t\trewrote = true\r\n\t\t\t\r\n\t\t\t\r\n\t\t\timp.EndPos = imp.End()\r\n\t\t\timp.Path.Value = strconv.Quote(newPath)\r\n\t\t}\r\n\t}\r\n\treturn\r\n}","code-length":117,"reference":"\/\/ rewriteImport rewrites any import of path oldPath to path newPath.","result":"Rewrite import.","score":[0,0.0495]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DefaultTicket() string {\r\n\tdefaultTicketOnce.Do(func() {\r\n\t\tif IsDevAppServer() {\r\n\t\t\tdefaultTicket = \"testapp\" + defaultTicketSuffix\r\n\t\t\treturn\r\n\t\t}\r\n\t\tappID := partitionlessAppID()\r\n\t\tescAppID := strings.Replace(strings.Replace(appID, \":\", \"_\", -1), \".\", \"_\", -1)\r\n\t\tmajVersion := VersionID(nil)\r\n\t\tif i := strings.Index(majVersion, \".\"); i > 0 {\r\n\t\t\tmajVersion = majVersion[:i]\r\n\t\t}\r\n\t\tdefaultTicket = fmt.Sprintf(\"%s\/%s.%s.%s\", escAppID, ModuleName(nil), majVersion, InstanceID())\r\n\t})\r\n\treturn defaultTicket\r\n}","code-length":204,"reference":"\/\/ DefaultTicket returns a ticket used for background context or dev_appserver.","result":"Generate a ticket for the default app.","score":[0.1427,0.2411]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *context) flushLog(force bool) (flushed bool) {\r\n\tc.pendingLogs.Lock()\r\n\t\r\n\tn, rem := 0, 30<<20\r\n\tfor ; n < len(c.pendingLogs.lines); n++ {\r\n\t\tll := c.pendingLogs.lines[n]\r\n\t\t\r\n\t\tnb := proto.Size(ll) + 3\r\n\t\tif nb > rem {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\trem -= nb\r\n\t}\r\n\tlines := c.pendingLogs.lines[:n]\r\n\tc.pendingLogs.lines = c.pendingLogs.lines[n:]\r\n\tc.pendingLogs.Unlock()\r\n\tif len(lines) == 0 && !force {\r\n\t\t\r\n\t\treturn false\r\n\t}\r\n\trescueLogs := false\r\n\tdefer func() {\r\n\t\tif rescueLogs {\r\n\t\t\tc.pendingLogs.Lock()\r\n\t\t\tc.pendingLogs.lines = append(lines, c.pendingLogs.lines...)\r\n\t\t\tc.pendingLogs.Unlock()\r\n\t\t}\r\n\t}()\r\n\tbuf, err := proto.Marshal(&logpb.UserAppLogGroup{\r\n\t\tLogLine: lines,\r\n\t})\r\n\tif err != nil {\r\n\t\tlog.Printf(\"internal.flushLog: marshaling UserAppLogGroup: %v\", err)\r\n\t\trescueLogs = true\r\n\t\treturn false\r\n\t}\r\n\treq := &logpb.FlushRequest{\r\n\t\tLogs: buf,\r\n\t}\r\n\tres := &basepb.VoidProto{}\r\n\tc.pendingLogs.Lock()\r\n\tc.pendingLogs.flushes++\r\n\tc.pendingLogs.Unlock()\r\n\tif err := Call(toContext(c), \"logservice\", \"Flush\", req, res); err != nil {\r\n\t\tlog.Printf(\"internal.flushLog: Flush RPC: %v\", err)\r\n\t\trescueLogs = true\r\n\t\treturn false\r\n\t}\r\n\treturn true\r\n}","code-length":508,"reference":"\/\/ flushLog attempts to flush any pending logs to the appserver.\n\/\/ It should not be called concurrently.","result":"Flush log.","score":[0,0.0305]}
{"code":"\/*is used to<extra_id_0>\r\nfunc withDeadline(parent context.Context, deadline time.Time) (context.Context, context.CancelFunc) {\r\n\tif deadline.IsZero() {\r\n\t\treturn parent, func() {}\r\n\t}\r\n\treturn context.WithDeadline(parent, deadline)\r\n}","code-length":74,"reference":"\/\/ withDeadline is like context.WithDeadline, except it ignores the zero deadline.","result":"Create a context with a deadline.","score":[0.0839,0.0476]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cn *Conn) KeepAlive() error {\r\n\treq := &pb.GetSocketNameRequest{\r\n\t\tSocketDescriptor: &cn.desc,\r\n\t}\r\n\tres := &pb.GetSocketNameReply{}\r\n\treturn internal.Call(cn.ctx, \"remote_socket\", \"GetSocketName\", req, res)\r\n}","code-length":90,"reference":"\/\/ KeepAlive signals that the connection is still in use.\n\/\/ It may be called to prevent the socket being closed due to inactivity.","result":"Keep alive connections.","score":[0,0.0228]}
{"code":"\/*is used to<extra_id_0>\r\nfunc applyTransaction(pb proto.Message, t *pb.Transaction) {\r\n\tv := reflect.ValueOf(pb)\r\n\tif f, ok := transactionSetters[v.Type()]; ok {\r\n\t\tf.Call([]reflect.Value{v, reflect.ValueOf(t)})\r\n\t}\r\n}","code-length":87,"reference":"\/\/ applyTransaction applies the transaction t to message pb\n\/\/ by using the relevant setter passed to RegisterTransactionSetter.","result":"Apply a transaction.","score":[0,0.0303]}
{"code":"\/*is used to<extra_id_0>\r\nfunc analyze(tags []string) (*app, error) {\r\n\tctxt := buildContext(tags)\r\n\thasMain, appFiles, err := checkMain(ctxt)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tgopath := filepath.SplitList(ctxt.GOPATH)\r\n\tim, err := imports(ctxt, *rootDir, gopath)\r\n\treturn &app{\r\n\t\thasMain:  hasMain,\r\n\t\tappFiles: appFiles,\r\n\t\timports:  im,\r\n\t}, err\r\n}","code-length":150,"reference":"\/\/ analyze checks the app for building with the given build tags and returns hasMain,\n\/\/ app files, and a map of full directory import names to original import names.","result":"Analyze the app .","score":[0.0007,0.0547]}
{"code":"\/*is used to<extra_id_0>\r\nfunc buildContext(tags []string) *build.Context {\r\n\treturn &build.Context{\r\n\t\tGOARCH:    build.Default.GOARCH,\r\n\t\tGOOS:      build.Default.GOOS,\r\n\t\tGOROOT:    build.Default.GOROOT,\r\n\t\tGOPATH:    build.Default.GOPATH,\r\n\t\tCompiler:  build.Default.Compiler,\r\n\t\tBuildTags: append(build.Default.BuildTags, tags...),\r\n\t}\r\n}","code-length":134,"reference":"\/\/ buildContext returns the context for building the source.","result":"Build context.","score":[0,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc synthesizeMain(tw *tar.Writer, appFiles []string) error {\r\n\tappMap := make(map[string]bool)\r\n\tfor _, f := range appFiles {\r\n\t\tappMap[f] = true\r\n\t}\r\n\tvar f string\r\n\tfor i := 0; i < 100; i++ {\r\n\t\tf = fmt.Sprintf(\"app_main%d.go\", i)\r\n\t\tif !appMap[filepath.Join(*rootDir, f)] {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif appMap[filepath.Join(*rootDir, f)] {\r\n\t\treturn fmt.Errorf(\"unable to find unique name for %v\", f)\r\n\t}\r\n\thdr := &tar.Header{\r\n\t\tName: f,\r\n\t\tMode: 0644,\r\n\t\tSize: int64(len(newMain)),\r\n\t}\r\n\tif err := tw.WriteHeader(hdr); err != nil {\r\n\t\treturn fmt.Errorf(\"unable to write header for %v: %v\", f, err)\r\n\t}\r\n\tif _, err := tw.Write([]byte(newMain)); err != nil {\r\n\t\treturn fmt.Errorf(\"unable to write %v to tar file: %v\", f, err)\r\n\t}\r\n\treturn nil\r\n}","code-length":334,"reference":"\/\/ synthesizeMain generates a new main func and writes it to the tarball.","result":"Generate the main package.","score":[0.04,0.124]}
{"code":"\/*is used to<extra_id_0>\r\nfunc findInGopath(dir string, gopath []string) (string, error) {\r\n\tfor _, v := range gopath {\r\n\t\tdst := filepath.Join(v, \"src\", dir)\r\n\t\tif _, err := os.Stat(dst); err == nil {\r\n\t\t\treturn dst, nil\r\n\t\t}\r\n\t}\r\n\treturn \"\", fmt.Errorf(\"unable to find package %v in gopath %v\", dir, gopath)\r\n}","code-length":124,"reference":"\/\/ findInGopath searches the gopath for the named import directory.","result":"Find the package in the gopath.","score":[0.1179,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc copyTree(tw *tar.Writer, dstDir, srcDir string) error {\r\n\tentries, err := ioutil.ReadDir(srcDir)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"unable to read dir %v: %v\", srcDir, err)\r\n\t}\r\n\tfor _, entry := range entries {\r\n\t\tn := entry.Name()\r\n\t\tif skipFiles[n] {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\ts := filepath.Join(srcDir, n)\r\n\t\td := filepath.Join(dstDir, n)\r\n\t\tif entry.IsDir() {\r\n\t\t\tif err := copyTree(tw, d, s); err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"unable to copy dir %v to %v: %v\", s, d, err)\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif err := copyFile(tw, d, s); err != nil {\r\n\t\t\treturn fmt.Errorf(\"unable to copy dir %v to %v: %v\", s, d, err)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":287,"reference":"\/\/ copyTree copies srcDir to tar file dstDir, ignoring skipFiles.","result":"Copy files in a directory.","score":[0,0.1053]}
{"code":"\/*is used to<extra_id_0>\r\nfunc copyFile(tw *tar.Writer, dst, src string) error {\r\n\ts, err := os.Open(src)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"unable to open %v: %v\", src, err)\r\n\t}\r\n\tdefer s.Close()\r\n\tfi, err := s.Stat()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"unable to stat %v: %v\", src, err)\r\n\t}\r\n\thdr, err := tar.FileInfoHeader(fi, dst)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"unable to create tar header for %v: %v\", dst, err)\r\n\t}\r\n\thdr.Name = dst\r\n\tif err := tw.WriteHeader(hdr); err != nil {\r\n\t\treturn fmt.Errorf(\"unable to write header for %v: %v\", dst, err)\r\n\t}\r\n\t_, err = io.Copy(tw, s)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"unable to copy %v to %v: %v\", src, dst, err)\r\n\t}\r\n\treturn nil\r\n}","code-length":293,"reference":"\/\/ copyFile copies src to tar file dst.","result":"Copy files.","score":[0,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkMain(ctxt *build.Context) (bool, []string, error) {\r\n\tpkg, err := ctxt.ImportDir(*rootDir, 0)\r\n\tif err != nil {\r\n\t\treturn false, nil, fmt.Errorf(\"unable to analyze source: %v\", err)\r\n\t}\r\n\tif !pkg.IsCommand() {\r\n\t\terrorf(\"Your app's package needs to be changed from %q to \\\"main\\\".\\n\", pkg.Name)\r\n\t}\r\n\t\r\n\tvar hasMain bool\r\n\tvar appFiles []string\r\n\tfor _, f := range pkg.GoFiles {\r\n\t\tn := filepath.Join(*rootDir, f)\r\n\t\tappFiles = append(appFiles, n)\r\n\t\tif hasMain, err = readFile(n); err != nil {\r\n\t\t\treturn false, nil, fmt.Errorf(\"error parsing %q: %v\", n, err)\r\n\t\t}\r\n\t}\r\n\treturn hasMain, appFiles, nil\r\n}","code-length":251,"reference":"\/\/ checkMain verifies that there is a single \"main\" function.\n\/\/ It also returns a list of all Go source files in the app.","result":"Check the main package .","score":[0.0054,0.0226]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isMain(f *ast.FuncDecl) bool {\r\n\tft := f.Type\r\n\treturn f.Name.Name == \"main\" && f.Recv == nil && ft.Params.NumFields() == 0 && ft.Results.NumFields() == 0\r\n}","code-length":72,"reference":"\/\/ isMain returns whether the given function declaration is a main function.\n\/\/ Such a function must be called \"main\", not have a receiver, and have no arguments or return types.","result":"Check if main is a function.","score":[0.005,0.0702]}
{"code":"\/*is used to<extra_id_0>\r\nfunc readFile(filename string) (hasMain bool, err error) {\r\n\tvar src []byte\r\n\tsrc, err = ioutil.ReadFile(filename)\r\n\tif err != nil {\r\n\t\treturn\r\n\t}\r\n\tfset := token.NewFileSet()\r\n\tfile, err := parser.ParseFile(fset, filename, src, 0)\r\n\tfor _, decl := range file.Decls {\r\n\t\tfuncDecl, ok := decl.(*ast.FuncDecl)\r\n\t\tif !ok {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif !isMain(funcDecl) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\thasMain = true\r\n\t\tbreak\r\n\t}\r\n\treturn\r\n}","code-length":189,"reference":"\/\/ readFile reads and parses the Go source code file and returns whether it has a main function.","result":"Check if the file has a main function .","score":[0.1049,0.2989]}
{"code":"\/*is used to<extra_id_0>\r\nfunc initField(val reflect.Value, index []int) reflect.Value {\r\n\tfor _, i := range index[:len(index)-1] {\r\n\t\tval = val.Field(i)\r\n\t\tif val.Kind() == reflect.Ptr {\r\n\t\t\tif val.IsNil() {\r\n\t\t\t\tval.Set(reflect.New(val.Type().Elem()))\r\n\t\t\t}\r\n\t\t\tval = val.Elem()\r\n\t\t}\r\n\t}\r\n\treturn val.Field(index[len(index)-1])\r\n}","code-length":144,"reference":"\/\/ initField is similar to reflect's Value.FieldByIndex, in that it\n\/\/ returns the nested struct field corresponding to index, but it\n\/\/ initialises any nil pointers encountered when traversing the structure.","result":"Initialize the field .","score":[0.0004,0.0353]}
{"code":"\/*is used to<extra_id_0>\r\nfunc loadEntity(dst interface{}, src *pb.EntityProto) (err error) {\r\n\tent, err := protoToEntity(src)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif e, ok := dst.(PropertyLoadSaver); ok {\r\n\t\treturn e.Load(ent.Properties)\r\n\t}\r\n\treturn LoadStruct(dst, ent.Properties)\r\n}","code-length":111,"reference":"\/\/ loadEntity loads an EntityProto into PropertyLoadSaver or struct pointer.","result":"Load entity properties.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc validIndexNameOrDocID(s string) bool {\r\n\tif strings.HasPrefix(s, \"!\") {\r\n\t\treturn false\r\n\t}\r\n\tfor _, c := range s {\r\n\t\tif c < 0x21 || 0x7f <= c {\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":97,"reference":"\/\/ validIndexNameOrDocID is the Go equivalent of Python's\n\/\/ _ValidateVisiblePrintableAsciiNotReserved.","result":"Validate the index name.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Open(name string) (*Index, error) {\r\n\tif !validIndexNameOrDocID(name) {\r\n\t\treturn nil, fmt.Errorf(\"search: invalid index name %q\", name)\r\n\t}\r\n\treturn &Index{\r\n\t\tspec: pb.IndexSpec{\r\n\t\t\tName: &name,\r\n\t\t},\r\n\t}, nil\r\n}","code-length":101,"reference":"\/\/ Open opens the index with the given name. The index is created if it does\n\/\/ not already exist.\n\/\/\n\/\/ The name is a human-readable ASCII string. It must contain no whitespace\n\/\/ characters and not start with \"!\".","result":"Open the index.","score":[0.0,0.0269]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (x *Index) Put(c context.Context, id string, src interface{}) (string, error) {\r\n\tids, err := x.PutMulti(c, []string{id}, []interface{}{src})\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn ids[0], nil\r\n}","code-length":91,"reference":"\/\/ Put saves src to the index. If id is empty, a new ID is allocated by the\n\/\/ service and returned. If id is not empty, any existing index entry for that\n\/\/ ID is replaced.\n\/\/\n\/\/ The ID is a human-readable ASCII string. It must contain no whitespace\n\/\/ characters and not start with \"!\".\n\/\/\n\/\/ src must be a non-nil struct pointer or implement the FieldLoadSaver\n\/\/ interface.","result":"Store the source in the index.","score":[0.0,0.0226]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (x *Index) Get(c context.Context, id string, dst interface{}) error {\r\n\tif id == \"\" || !validIndexNameOrDocID(id) {\r\n\t\treturn fmt.Errorf(\"search: invalid ID %q\", id)\r\n\t}\r\n\treq := &pb.ListDocumentsRequest{\r\n\t\tParams: &pb.ListDocumentsParams{\r\n\t\t\tIndexSpec:  &x.spec,\r\n\t\t\tStartDocId: proto.String(id),\r\n\t\t\tLimit:      proto.Int32(1),\r\n\t\t},\r\n\t}\r\n\tres := &pb.ListDocumentsResponse{}\r\n\tif err := internal.Call(c, \"search\", \"ListDocuments\", req, res); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif res.Status == nil || res.Status.GetCode() != pb.SearchServiceError_OK {\r\n\t\treturn fmt.Errorf(\"search: %s: %s\", res.Status.GetCode(), res.Status.GetErrorDetail())\r\n\t}\r\n\tif len(res.Document) != 1 || res.Document[0].GetId() != id {\r\n\t\treturn ErrNoSuchDocument\r\n\t}\r\n\treturn loadDoc(dst, res.Document[0], nil)\r\n}","code-length":314,"reference":"\/\/ Get loads the document with the given ID into dst.\n\/\/\n\/\/ The ID is a human-readable ASCII string. It must be non-empty, contain no\n\/\/ whitespace characters and not start with \"!\".\n\/\/\n\/\/ dst must be a non-nil struct pointer or implement the FieldLoadSaver\n\/\/ interface.\n\/\/\n\/\/ ErrFieldMismatch is returned when a field is to be loaded into a different\n\/\/ type than the one it was stored from, or when a field is missing or\n\/\/ unexported in the destination struct. ErrFieldMismatch is only returned if\n\/\/ dst is a struct pointer. It is up to the callee to decide whether this error\n\/\/ is fatal, recoverable, or ignorable.","result":"Return a value from a function that returns a value.","score":[0.0,0.0241]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (x *Index) Delete(c context.Context, id string) error {\r\n\treturn x.DeleteMulti(c, []string{id})\r\n}","code-length":46,"reference":"\/\/ Delete deletes a document from the index.","result":"Delete the index.","score":[0.1207,0.3407]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (x *Index) DeleteMulti(c context.Context, ids []string) error {\r\n\tif len(ids) > maxDocumentsPerPutDelete {\r\n\t\treturn ErrTooManyDocuments\r\n\t}\r\n\treq := &pb.DeleteDocumentRequest{\r\n\t\tParams: &pb.DeleteDocumentParams{\r\n\t\t\tDocId:     ids,\r\n\t\t\tIndexSpec: &x.spec,\r\n\t\t},\r\n\t}\r\n\tres := &pb.DeleteDocumentResponse{}\r\n\tif err := internal.Call(c, \"search\", \"DeleteDocument\", req, res); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif len(res.Status) != len(ids) {\r\n\t\treturn fmt.Errorf(\"search: internal error: wrong number of results (%d, expected %d)\",\r\n\t\t\tlen(res.Status), len(ids))\r\n\t}\r\n\tmultiErr, hasErr := make(appengine.MultiError, len(ids)), false\r\n\tfor i, s := range res.Status {\r\n\t\tif s.GetCode() != pb.SearchServiceError_OK {\r\n\t\t\tmultiErr[i] = fmt.Errorf(\"search: %s: %s\", s.GetCode(), s.GetErrorDetail())\r\n\t\t\thasErr = true\r\n\t\t}\r\n\t}\r\n\tif hasErr {\r\n\t\treturn multiErr\r\n\t}\r\n\treturn nil\r\n}","code-length":354,"reference":"\/\/ DeleteMulti deletes multiple documents from the index.\n\/\/\n\/\/ The returned error may be an instance of appengine.MultiError, in which case\n\/\/ it will be the same size as srcs and the individual errors inside will\n\/\/ correspond with the items in srcs.","result":"Delete documents in a multi.","score":[0.0001,0.0374]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (x *Index) Search(c context.Context, query string, opts *SearchOptions) *Iterator {\r\n\tt := &Iterator{\r\n\t\tc:           c,\r\n\t\tindex:       x,\r\n\t\tsearchQuery: query,\r\n\t\tmore:        moreSearch,\r\n\t}\r\n\tif opts != nil {\r\n\t\tif opts.Cursor != \"\" {\r\n\t\t\tif opts.Offset != 0 {\r\n\t\t\t\treturn errIter(\"at most one of Cursor and Offset may be specified\")\r\n\t\t\t}\r\n\t\t\tt.searchCursor = proto.String(string(opts.Cursor))\r\n\t\t}\r\n\t\tt.limit = opts.Limit\r\n\t\tt.fields = opts.Fields\r\n\t\tt.idsOnly = opts.IDsOnly\r\n\t\tt.sort = opts.Sort\r\n\t\tt.exprs = opts.Expressions\r\n\t\tt.refinements = opts.Refinements\r\n\t\tt.facetOpts = opts.Facets\r\n\t\tt.searchOffset = opts.Offset\r\n\t\tt.countAccuracy = opts.CountAccuracy\r\n\t}\r\n\treturn t\r\n}","code-length":285,"reference":"\/\/ Search searches the index for the given query.","result":"Search the index.","score":[0.0657,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Iterator) fetchMore() {\r\n\tif t.err == nil && len(t.listRes)+len(t.searchRes) == 0 && t.more != nil {\r\n\t\tt.err = t.more(t)\r\n\t}\r\n}","code-length":73,"reference":"\/\/ fetchMore retrieves more results, if there are no errors or pending results.","result":"Fetch more.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Iterator) Next(dst interface{}) (string, error) {\r\n\tt.fetchMore()\r\n\tif t.err != nil {\r\n\t\treturn \"\", t.err\r\n\t}\r\n\tvar doc *pb.Document\r\n\tvar exprs []*pb.Field\r\n\tswitch {\r\n\tcase len(t.listRes) != 0:\r\n\t\tdoc = t.listRes[0]\r\n\t\tt.listRes = t.listRes[1:]\r\n\tcase len(t.searchRes) != 0:\r\n\t\tdoc = t.searchRes[0].Document\r\n\t\texprs = t.searchRes[0].Expression\r\n\t\tt.searchCursor = t.searchRes[0].Cursor\r\n\t\tt.searchRes = t.searchRes[1:]\r\n\tdefault:\r\n\t\treturn \"\", Done\r\n\t}\r\n\tif doc == nil {\r\n\t\treturn \"\", errors.New(\"search: internal error: no document returned\")\r\n\t}\r\n\tif !t.idsOnly && dst != nil {\r\n\t\tif err := loadDoc(dst, doc, exprs); err != nil {\r\n\t\t\treturn \"\", err\r\n\t\t}\r\n\t}\r\n\treturn doc.GetId(), nil\r\n}","code-length":311,"reference":"\/\/ Next returns the ID of the next result. When there are no more results,\n\/\/ Done is returned as the error.\n\/\/\n\/\/ dst must be a non-nil struct pointer, implement the FieldLoadSaver\n\/\/ interface, or be a nil interface value. If a non-nil dst is provided, it\n\/\/ will be filled with the indexed fields. dst is ignored if this iterator was\n\/\/ created with an IDsOnly option.","result":"Fetch the next document from the server.","score":[0.0,0.0235]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Iterator) Facets() ([][]FacetResult, error) {\r\n\tt.fetchMore()\r\n\tif t.err != nil && t.err != Done {\r\n\t\treturn nil, t.err\r\n\t}\r\n\tvar facets [][]FacetResult\r\n\tfor _, f := range t.facetRes {\r\n\t\tfres := make([]FacetResult, 0, len(f.Value))\r\n\t\tfor _, v := range f.Value {\r\n\t\t\tref := v.Refinement\r\n\t\t\tfacet := FacetResult{\r\n\t\t\t\tFacet: Facet{Name: ref.GetName()},\r\n\t\t\t\tCount: int(v.GetCount()),\r\n\t\t\t}\r\n\t\t\tif ref.Value != nil {\r\n\t\t\t\tfacet.Value = Atom(*ref.Value)\r\n\t\t\t} else {\r\n\t\t\t\tfacet.Value = protoToRange(ref.Range)\r\n\t\t\t}\r\n\t\t\tfres = append(fres, facet)\r\n\t\t}\r\n\t\tfacets = append(facets, fres)\r\n\t}\r\n\treturn facets, nil\r\n}","code-length":279,"reference":"\/\/ Facets returns the facets found within the search results, if any facets\n\/\/ were requested in the SearchOptions.","result":"Generate the code for the facets function.","score":[0.0455,0.0843]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DefaultBucketName(c context.Context) (string, error) {\r\n\treq := &aipb.GetDefaultGcsBucketNameRequest{}\r\n\tres := &aipb.GetDefaultGcsBucketNameResponse{}\r\n\terr := internal.Call(c, \"app_identity_service\", \"GetDefaultGcsBucketName\", req, res)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"file: no default bucket name returned in RPC response: %v\", res)\r\n\t}\r\n\treturn res.GetDefaultGcsBucketName(), nil\r\n}","code-length":141,"reference":"\/\/ DefaultBucketName returns the name of this application's\n\/\/ default Google Cloud Storage bucket.","result":"Generate the default bucket name.","score":[0.0472,0.0763]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (k *Key) valid() bool {\r\n\tif k == nil {\r\n\t\treturn false\r\n\t}\r\n\tfor ; k != nil; k = k.parent {\r\n\t\tif k.kind == \"\" || k.appID == \"\" {\r\n\t\t\treturn false\r\n\t\t}\r\n\t\tif k.stringID != \"\" && k.intID != 0 {\r\n\t\t\treturn false\r\n\t\t}\r\n\t\tif k.parent != nil {\r\n\t\t\tif k.parent.Incomplete() {\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\t\tif k.parent.appID != k.appID || k.parent.namespace != k.namespace {\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":200,"reference":"\/\/ valid returns whether the key is valid.","result":"Check if the key is valid.","score":[0.433,0.5088]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (k *Key) Equal(o *Key) bool {\r\n\tfor k != nil && o != nil {\r\n\t\tif k.kind != o.kind || k.stringID != o.stringID || k.intID != o.intID || k.appID != o.appID || k.namespace != o.namespace {\r\n\t\t\treturn false\r\n\t\t}\r\n\t\tk, o = k.parent, o.parent\r\n\t}\r\n\treturn k == o\r\n}","code-length":126,"reference":"\/\/ Equal returns whether two keys are equal.","result":"Compare two objects .","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (k *Key) root() *Key {\r\n\tfor k.parent != nil {\r\n\t\tk = k.parent\r\n\t}\r\n\treturn k\r\n}","code-length":51,"reference":"\/\/ root returns the furthest ancestor of a key, which may be itself.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (k *Key) marshal(b *bytes.Buffer) {\r\n\tif k.parent != nil {\r\n\t\tk.parent.marshal(b)\r\n\t}\r\n\tb.WriteByte('\/')\r\n\tb.WriteString(k.kind)\r\n\tb.WriteByte(',')\r\n\tif k.stringID != \"\" {\r\n\t\tb.WriteString(k.stringID)\r\n\t} else {\r\n\t\tb.WriteString(strconv.FormatInt(k.intID, 10))\r\n\t}\r\n}","code-length":142,"reference":"\/\/ marshal marshals the key's string representation to the buffer.","result":"Generate the key .","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (k *Key) String() string {\r\n\tif k == nil {\r\n\t\treturn \"\"\r\n\t}\r\n\tb := bytes.NewBuffer(make([]byte, 0, 512))\r\n\tk.marshal(b)\r\n\treturn b.String()\r\n}","code-length":76,"reference":"\/\/ String returns a string representation of the key.","result":"Generate the key string.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (k *Key) Encode() string {\r\n\tref := keyToProto(\"\", k)\r\n\tb, err := proto.Marshal(ref)\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\t\r\n\treturn strings.TrimRight(base64.URLEncoding.EncodeToString(b), \"=\")\r\n}","code-length":93,"reference":"\/\/ Encode returns an opaque representation of the key\n\/\/ suitable for use in HTML and URLs.\n\/\/ This is compatible with the Python and Java runtimes.","result":"Encode the key.","score":[0.0002,0.0407]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DecodeKey(encoded string) (*Key, error) {\r\n\t\r\n\tif m := len(encoded) % 4; m != 0 {\r\n\t\tencoded += strings.Repeat(\"=\", 4-m)\r\n\t}\r\n\tb, err := base64.URLEncoding.DecodeString(encoded)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tref := new(pb.Reference)\r\n\tif err := proto.Unmarshal(b, ref); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn protoToKey(ref)\r\n}","code-length":155,"reference":"\/\/ DecodeKey decodes a key from the opaque representation returned by Encode.","result":"Decode a key.","score":[0.0203,0.1689]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewIncompleteKey(c context.Context, kind string, parent *Key) *Key {\r\n\treturn NewKey(c, kind, \"\", 0, parent)\r\n}","code-length":48,"reference":"\/\/ NewIncompleteKey creates a new incomplete key.\n\/\/ kind cannot be empty.","result":"Create a new key.","score":[0.0677,0.3348]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewKey(c context.Context, kind, stringID string, intID int64, parent *Key) *Key {\r\n\t\r\n\t\r\n\tvar namespace string\r\n\tif parent != nil {\r\n\t\tnamespace = parent.namespace\r\n\t} else {\r\n\t\tnamespace = internal.NamespaceFromContext(c)\r\n\t}\r\n\treturn &Key{\r\n\t\tkind:      kind,\r\n\t\tstringID:  stringID,\r\n\t\tintID:     intID,\r\n\t\tparent:    parent,\r\n\t\tappID:     internal.FullyQualifiedAppID(c),\r\n\t\tnamespace: namespace,\r\n\t}\r\n}","code-length":167,"reference":"\/\/ NewKey creates a new key.\n\/\/ kind cannot be empty.\n\/\/ Either one or both of stringID and intID must be zero. If both are zero,\n\/\/ the key returned is incomplete.\n\/\/ parent must either be a complete key or nil.","result":"Create a new key.","score":[0.0,0.0807]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AllocateIDs(c context.Context, kind string, parent *Key, n int) (low, high int64, err error) {\r\n\tif kind == \"\" {\r\n\t\treturn 0, 0, errors.New(\"datastore: AllocateIDs given an empty kind\")\r\n\t}\r\n\tif n < 0 {\r\n\t\treturn 0, 0, fmt.Errorf(\"datastore: AllocateIDs given a negative count: %d\", n)\r\n\t}\r\n\tif n == 0 {\r\n\t\treturn 0, 0, nil\r\n\t}\r\n\treq := &pb.AllocateIdsRequest{\r\n\t\tModelKey: keyToProto(\"\", NewIncompleteKey(c, kind, parent)),\r\n\t\tSize:     proto.Int64(int64(n)),\r\n\t}\r\n\tres := &pb.AllocateIdsResponse{}\r\n\tif err := internal.Call(c, \"datastore_v3\", \"AllocateIds\", req, res); err != nil {\r\n\t\treturn 0, 0, err\r\n\t}\r\n\t\r\n\t\r\n\tlow = res.GetStart()\r\n\thigh = res.GetEnd() + 1\r\n\tif low+int64(n) != high {\r\n\t\treturn 0, 0, fmt.Errorf(\"datastore: internal error: could not allocate %d IDs\", n)\r\n\t}\r\n\treturn low, high, nil\r\n}","code-length":332,"reference":"\/\/ AllocateIDs returns a range of n integer IDs with the given kind and parent\n\/\/ combination. kind cannot be empty; parent may be nil. The IDs in the range\n\/\/ returned will not be used by the datastore's automatic ID sequence generator\n\/\/ and may be used with NewKey without conflict.\n\/\/\n\/\/ The range is inclusive at the low end and exclusive at the high end. In\n\/\/ other words, valid intIDs x satisfy low <= x && x < high.\n\/\/\n\/\/ If no error is returned, low + n == high.","result":"Allocate IDs in the datastore.","score":[0.0,0.0174]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsOverQuota(err error) bool {\r\n\tcallErr, ok := err.(*internal.CallError)\r\n\treturn ok && callErr.Code == 4\r\n}","code-length":50,"reference":"\/\/ IsOverQuota reports whether err represents an API call failure\n\/\/ due to insufficient available quota.","result":"Test the types.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ClassicContextFromContext(ctx netcontext.Context) (appengine.Context, error) {\r\n\tc := fromContext(ctx)\r\n\tif c == nil {\r\n\t\treturn nil, errNotAppEngineContext\r\n\t}\r\n\treturn c, nil\r\n}","code-length":74,"reference":"\/\/ This is only for classic App Engine adapters.","result":"Create a new context.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Send(c context.Context, msg *Message) error {\r\n\treturn send(c, \"Send\", msg)\r\n}","code-length":39,"reference":"\/\/ Send sends an email message.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SendToAdmins(c context.Context, msg *Message) error {\r\n\treturn send(c, \"SendToAdmins\", msg)\r\n}","code-length":45,"reference":"\/\/ SendToAdmins sends an email message to the application's administrators.","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Report) Failures() int {\r\n\tcount := 0\r\n\tfor _, p := range r.Packages {\r\n\t\tfor _, t := range p.Tests {\r\n\t\t\tif t.Result == FAIL {\r\n\t\t\t\tcount++\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn count\r\n}","code-length":92,"reference":"\/\/ Failures counts the number of failed tests in this report","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc decodeFieldNumberAndTyp3(bz []byte) (num uint32, typ Typ3, n int, err error) {\r\n\t\r\n\tvar value64 = uint64(0)\r\n\tvalue64, n, err = DecodeUvarint(bz)\r\n\tif err != nil {\r\n\t\treturn\r\n\t}\r\n\t\r\n\ttyp = Typ3(value64 & 0x07)\r\n\t\r\n\tvar num64 uint64\r\n\tnum64 = value64 >> 3\r\n\tif num64 > (1<<29 - 1) {\r\n\t\terr = fmt.Errorf(\"invalid field num %v\", num64)\r\n\t\treturn\r\n\t}\r\n\tnum = uint32(num64)\r\n\treturn\r\n}","code-length":185,"reference":"\/\/ Read field key.","result":"Decode field numbers and typ.","score":[0.2403,0.122]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkTyp3(rt reflect.Type, typ Typ3, fopts FieldOptions) (err error) {\r\n\ttypWanted := typeToTyp3(rt, fopts)\r\n\tif typ != typWanted {\r\n\t\terr = fmt.Errorf(\"unexpected Typ3. want %v, got %v\", typWanted, typ)\r\n\t}\r\n\treturn\r\n}","code-length":102,"reference":"\/\/ Error if typ doesn't match rt.","result":"Check the Typ.","score":[0,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc decodeTyp3(bz []byte) (typ Typ3, n int, err error) {\r\n\tif len(bz) == 0 {\r\n\t\terr = fmt.Errorf(\"EOF while reading typ3 byte\")\r\n\t\treturn\r\n\t}\r\n\tif bz[0]&0xF8 != 0 {\r\n\t\terr = fmt.Errorf(\"invalid typ3 byte: %v\", Typ3(bz[0]).String())\r\n\t\treturn\r\n\t}\r\n\ttyp = Typ3(bz[0])\r\n\tn = 1\r\n\treturn\r\n}","code-length":144,"reference":"\/\/ Read typ3 byte.","result":"Decode a typ.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPrefixBytes(prefixBytes []byte) PrefixBytes {\r\n\tpb := PrefixBytes{}\r\n\tcopy(pb[:], prefixBytes)\r\n\treturn pb\r\n}","code-length":49,"reference":"\/\/ Copy into PrefixBytes","result":"Create a new prefix bytes.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getLengthStr(info *TypeInfo) string {\r\n\tswitch info.Type.Kind() {\r\n\tcase reflect.Array,\r\n\t\treflect.Int8,\r\n\t\treflect.Int16, reflect.Int32, reflect.Int64,\r\n\t\treflect.Float32, reflect.Float64,\r\n\t\treflect.Complex64, reflect.Complex128:\r\n\t\ts := info.Type.Size()\r\n\t\treturn fmt.Sprintf(\"0x%X\", s)\r\n\tdefault:\r\n\t\treturn \"variable\"\r\n\t}\r\n}","code-length":147,"reference":"\/\/ A heuristic to guess the size of a registered type and return it as a string.\n\/\/ If the size is not fixed it returns \"variable\".","result":"Generate the length string.","score":[0.0012,0.0405]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cdc *Codec) collectImplementers_nolock(info *TypeInfo) {\r\n\tfor _, cinfo := range cdc.concreteInfos {\r\n\t\tif cinfo.PtrToType.Implements(info.Type) {\r\n\t\t\tinfo.Implementers[cinfo.Prefix] = append(\r\n\t\t\t\tinfo.Implementers[cinfo.Prefix], cinfo)\r\n\t\t}\r\n\t}\r\n}","code-length":109,"reference":"\/\/ Find all conflicting prefixes for concrete types\n\/\/ that \"implement\" the interface.  \"Implement\" in quotes because\n\/\/ we only consider the pointer, for extra safety.","result":"Collect implementers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cdc *Codec) checkConflictsInPrio_nolock(iinfo *TypeInfo) error {\r\n\tfor _, cinfos := range iinfo.Implementers {\r\n\t\tif len(cinfos) < 2 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tfor _, cinfo := range cinfos {\r\n\t\t\tvar inPrio = false\r\n\t\t\tfor _, disfix := range iinfo.InterfaceInfo.Priority {\r\n\t\t\t\tif cinfo.GetDisfix() == disfix {\r\n\t\t\t\t\tinPrio = true\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tif !inPrio {\r\n\t\t\t\treturn fmt.Errorf(\"%v conflicts with %v other(s). Add it to the priority list for %v.\",\r\n\t\t\t\t\tcinfo.Type, len(cinfos), iinfo.Type)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":234,"reference":"\/\/ Ensure that prefix-conflicting implementing concrete types\n\/\/ are all registered in the priority list.\n\/\/ Returns an error if a disamb conflict is found.","result":"Check if the type is compatible with the interface type.","score":[0.0319,0.0851]}
{"code":"\/*is used to<extra_id_0>\r\nfunc constructConcreteType(cinfo *TypeInfo) (crv, irvSet reflect.Value) {\r\n\t\r\n\tif cinfo.PointerPreferred {\r\n\t\tcPtrRv := reflect.New(cinfo.Type)\r\n\t\tcrv = cPtrRv.Elem()\r\n\t\tirvSet = cPtrRv\r\n\t} else {\r\n\t\tcrv = reflect.New(cinfo.Type).Elem()\r\n\t\tirvSet = crv\r\n\t}\r\n\treturn\r\n}","code-length":133,"reference":"\/\/ constructConcreteType creates the concrete value as\n\/\/ well as the corresponding settable value for it.\n\/\/ Return irvSet which should be set on caller's interface rv.","result":"Construct concrete type.","score":[0.0001,0.0203]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cdc *Codec) MarshalBinaryLengthPrefixedWriter(w io.Writer, o interface{}) (n int64, err error) {\r\n\tvar bz, _n = []byte(nil), int(0)\r\n\tbz, err = cdc.MarshalBinaryLengthPrefixed(o)\r\n\tif err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\t_n, err = w.Write(bz)\r\n\tn = int64(_n)\r\n\treturn\r\n}","code-length":127,"reference":"\/\/ MarshalBinaryLengthPrefixedWriter writes the bytes as would be returned from\n\/\/ MarshalBinaryLengthPrefixed to the writer w.","result":"Marshal the object to a binary length prefixed writer.","score":[0.0666,0.0654]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cdc *Codec) MarshalBinaryBare(o interface{}) ([]byte, error) {\r\n\t\r\n\tvar rv, _, isNilPtr = derefPointers(reflect.ValueOf(o))\r\n\tif isNilPtr {\r\n\t\t\r\n\t\t\r\n\t\tpanic(\"MarshalBinaryBare cannot marshal a nil pointer directly. Try wrapping in a struct?\")\r\n\t}\r\n\t\r\n\tvar bz []byte\r\n\tbuf := new(bytes.Buffer)\r\n\trt := rv.Type()\r\n\tinfo, err := cdc.getTypeInfo_wlock(rt)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\terr = cdc.encodeReflectBinary(buf, info, rv, FieldOptions{BinFieldNum: 1}, true)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tbz = buf.Bytes()\r\n\t\r\n\tif info.Registered {\r\n\t\tpb := info.Prefix.Bytes()\r\n\t\tbz = append(pb, bz...)\r\n\t}\r\n\treturn bz, nil\r\n}","code-length":274,"reference":"\/\/ MarshalBinaryBare encodes the object o according to the Amino spec.\n\/\/ MarshalBinaryBare doesn't prefix the byte-length of the encoding,\n\/\/ so the caller must handle framing.","result":"Marshal the binary data.","score":[0.001,0.0202]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cdc *Codec) UnmarshalBinaryLengthPrefixed(bz []byte, ptr interface{}) error {\r\n\tif len(bz) == 0 {\r\n\t\treturn errors.New(\"UnmarshalBinaryLengthPrefixed cannot decode empty bytes\")\r\n\t}\r\n\t\r\n\tu64, n := binary.Uvarint(bz)\r\n\tif n < 0 {\r\n\t\treturn fmt.Errorf(\"Error reading msg byte-length prefix: got code %v\", n)\r\n\t}\r\n\tif u64 > uint64(len(bz)-n) {\r\n\t\treturn fmt.Errorf(\"Not enough bytes to read in UnmarshalBinaryLengthPrefixed, want %v more bytes but only have %v\",\r\n\t\t\tu64, len(bz)-n)\r\n\t} else if u64 < uint64(len(bz)-n) {\r\n\t\treturn fmt.Errorf(\"Bytes left over in UnmarshalBinaryLengthPrefixed, should read %v more bytes but have %v\",\r\n\t\t\tu64, len(bz)-n)\r\n\t}\r\n\tbz = bz[n:]\r\n\t\r\n\treturn cdc.UnmarshalBinaryBare(bz, ptr)\r\n}","code-length":278,"reference":"\/\/ Like UnmarshalBinaryBare, but will first decode the byte-length prefix.\n\/\/ UnmarshalBinaryLengthPrefixed will panic if ptr is a nil-pointer.\n\/\/ Returns an error if not all of bz is consumed.","result":"Unmarshal binary data.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cdc *Codec) UnmarshalBinaryBare(bz []byte, ptr interface{}) error {\r\n\trv := reflect.ValueOf(ptr)\r\n\tif rv.Kind() != reflect.Ptr {\r\n\t\tpanic(\"Unmarshal expects a pointer\")\r\n\t}\r\n\trv = rv.Elem()\r\n\trt := rv.Type()\r\n\tinfo, err := cdc.getTypeInfo_wlock(rt)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif info.Registered {\r\n\t\tpb := info.Prefix.Bytes()\r\n\t\tif len(bz) < 4 {\r\n\t\t\treturn fmt.Errorf(\"UnmarshalBinaryBare expected to read prefix bytes %X (since it is registered concrete) but got %X\", pb, bz)\r\n\t\t} else if !bytes.Equal(bz[:4], pb) {\r\n\t\t\treturn fmt.Errorf(\"UnmarshalBinaryBare expected to read prefix bytes %X (since it is registered concrete) but got %X...\", pb, bz[:4])\r\n\t\t}\r\n\t\tbz = bz[4:]\r\n\t}\r\n\t\r\n\tn, err := cdc.decodeReflectBinary(bz, info, rv, FieldOptions{BinFieldNum: 1}, true)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"unmarshal to %v failed after %d bytes (%v): %X\", info.Type, n, err, bz)\r\n\t}\r\n\tif n != len(bz) {\r\n\t\treturn fmt.Errorf(\"unmarshal to %v didn't read all bytes. Expected to read %v, only read %v: %X\", info.Type, len(bz), n, bz)\r\n\t}\r\n\treturn nil\r\n}","code-length":421,"reference":"\/\/ UnmarshalBinaryBare will panic if ptr is a nil-pointer.","result":"Unmarshal binary data.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cdc *Codec) MustMarshalJSON(o interface{}) []byte {\r\n\tbz, err := cdc.MarshalJSON(o)\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\treturn bz\r\n}","code-length":69,"reference":"\/\/ MustMarshalJSON panics if an error occurs. Besides tha behaves exactly like MarshalJSON.","result":"Encode JSON.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cdc *Codec) MustUnmarshalJSON(bz []byte, ptr interface{}) {\r\n\tif err := cdc.UnmarshalJSON(bz, ptr); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n}","code-length":63,"reference":"\/\/ MustUnmarshalJSON panics if an error occurs. Besides tha behaves exactly like UnmarshalJSON.","result":"Parse json.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cdc *Codec) MarshalJSONIndent(o interface{}, prefix, indent string) ([]byte, error) {\r\n\tbz, err := cdc.MarshalJSON(o)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar out bytes.Buffer\r\n\terr = json.Indent(&out, bz, prefix, indent)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn out.Bytes(), nil\r\n}","code-length":127,"reference":"\/\/ MarshalJSONIndent calls json.Indent on the output of cdc.MarshalJSON\n\/\/ using the given prefix and indent string.","result":"Serialize the object.","score":[0.0038,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newDataReader(r io.Reader) *internalDataReader {\r\n\tbuffered := bufio.NewReader(r)\r\n\treader := internalDataReader{\r\n\t\twrapped:r,\r\n\t\tbuffered:buffered,\r\n\t}\r\n\treturn &reader\r\n}","code-length":73,"reference":"\/\/ newDataReader creates a new DataReader reading from 'r'.","result":"Create a new reader.","score":[0.1294,0.3464]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *internalDataReader) Read(data []byte) (n int, err error) {\r\n\tconst IAC = 255\r\n\tconst SB = 250\r\n\tconst SE = 240\r\n\tconst WILL = 251\r\n\tconst WONT = 252\r\n\tconst DO   = 253\r\n\tconst DONT = 254\r\n\tp := data\r\n\tfor len(p) > 0 {\r\n\t\tvar b byte\r\n\t\tb, err = r.buffered.ReadByte()\r\n\t\tif nil != err {\r\n\t\t\treturn n, err\r\n\t\t}\r\n\t\tif IAC == b {\r\n\t\t\tvar peeked []byte\r\n\t\t\tpeeked, err = r.buffered.Peek(1)\r\n\t\t\tif nil != err {\r\n\t\t\t\treturn n, err\r\n\t\t\t}\r\n\t\t\tswitch peeked[0] {\r\n\t\t\tcase WILL, WONT, DO, DONT:\r\n\t\t\t\t_, err = r.buffered.Discard(2)\r\n\t\t\t\tif nil != err {\r\n\t\t\t\t\treturn n, err\r\n\t\t\t\t}\r\n\t\t\tcase IAC:\r\n\t\t\t\tp[0] = IAC\r\n\t\t\t\tn++\r\n\t\t\t\tp = p[1:]\r\n\t\t\t\t_, err = r.buffered.Discard(1)\r\n\t\t\t\tif nil != err {\r\n\t\t\t\t\treturn n, err\r\n\t\t\t\t}\r\n\t\t\tcase SB:\r\n\t\t\t\tfor {\r\n\t\t\t\t\tvar b2 byte\r\n\t\t\t\t\tb2, err = r.buffered.ReadByte()\r\n\t\t\t\t\tif nil != err {\r\n\t\t\t\t\t\treturn n, err\r\n\t\t\t\t\t}\r\n\t\t\t\t\tif IAC == b2 {\r\n\t\t\t\t\t\tpeeked, err = r.buffered.Peek(1)\r\n\t\t\t\t\t\tif nil != err {\r\n\t\t\t\t\t\t\treturn n, err\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\tif IAC == peeked[0] {\r\n\t\t\t\t\t\t\t_, err = r.buffered.Discard(1)\r\n\t\t\t\t\t\t\tif nil != err {\r\n\t\t\t\t\t\t\t\treturn n, err\r\n\t\t\t\t\t\t\t}\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\tif SE == peeked[0] {\r\n\t\t\t\t\t\t\t_, err = r.buffered.Discard(1)\r\n\t\t\t\t\t\t\tif nil != err {\r\n\t\t\t\t\t\t\t\treturn n, err\r\n\t\t\t\t\t\t\t}\r\n\t\t\t\t\t\t\tbreak\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\tcase SE:\r\n\t\t\t\t_, err = r.buffered.Discard(1)\r\n\t\t\t\tif nil != err {\r\n\t\t\t\t\treturn n, err\r\n\t\t\t\t}\r\n\t\t\tdefault:\r\n\t\t\t\t\r\n\t\t\t\terr = errCorrupted\r\n\t\t\t\treturn n, err\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\tp[0] = b\r\n\t\t\tn++\r\n\t\t\tp = p[1:]\r\n\t\t}\r\n\t}\r\n\treturn n, nil\r\n}","code-length":724,"reference":"\/\/ Read reads the TELNET escaped data from the  wrapped io.Reader, and \"un-escapes\" it into 'data'.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (server *Server) ListenAndServeTLS(certFile string, keyFile string) error {\r\n\taddr := server.Addr\r\n\tif \"\" == addr {\r\n\t\taddr = \":telnets\"\r\n\t}\r\n\tlistener, err := net.Listen(\"tcp\", addr)\r\n\tif nil != err {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tvar tlsConfig *tls.Config = nil\r\n\tif nil == server.TLSConfig {\r\n\t\ttlsConfig = &tls.Config{}\r\n\t} else {\r\n\t\ttlsConfig = &tls.Config{\r\n\t\t\tRand:                     server.TLSConfig.Rand,\r\n\t\t\tTime:                     server.TLSConfig.Time,\r\n\t\t\tCertificates:             server.TLSConfig.Certificates,\r\n\t\t\tNameToCertificate:        server.TLSConfig.NameToCertificate,\r\n\t\t\tGetCertificate:           server.TLSConfig.GetCertificate,\r\n\t\t\tRootCAs:                  server.TLSConfig.RootCAs,\r\n\t\t\tNextProtos:               server.TLSConfig.NextProtos,\r\n\t\t\tServerName:               server.TLSConfig.ServerName,\r\n\t\t\tClientAuth:               server.TLSConfig.ClientAuth,\r\n\t\t\tClientCAs:                server.TLSConfig.ClientCAs,\r\n\t\t\tInsecureSkipVerify:       server.TLSConfig.InsecureSkipVerify,\r\n\t\t\tCipherSuites:             server.TLSConfig.CipherSuites,\r\n\t\t\tPreferServerCipherSuites: server.TLSConfig.PreferServerCipherSuites,\r\n\t\t\tSessionTicketsDisabled:   server.TLSConfig.SessionTicketsDisabled,\r\n\t\t\tSessionTicketKey:         server.TLSConfig.SessionTicketKey,\r\n\t\t\tClientSessionCache:       server.TLSConfig.ClientSessionCache,\r\n\t\t\tMinVersion:               server.TLSConfig.MinVersion,\r\n\t\t\tMaxVersion:               server.TLSConfig.MaxVersion,\r\n\t\t\tCurvePreferences:         server.TLSConfig.CurvePreferences,\r\n\t\t}\r\n\t}\r\n\ttlsConfigHasCertificate := len(tlsConfig.Certificates) > 0 || nil != tlsConfig.GetCertificate\r\n\tif \"\" == certFile || \"\" == keyFile || !tlsConfigHasCertificate {\r\n\t\ttlsConfig.Certificates = make([]tls.Certificate, 1)\r\n\t\tvar err error\r\n\t\ttlsConfig.Certificates[0], err = tls.LoadX509KeyPair(certFile, keyFile)\r\n\t\tif nil != err {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\ttlsListener := tls.NewListener(listener, tlsConfig)\r\n\treturn server.Serve(tlsListener)\r\n}","code-length":631,"reference":"\/\/ ListenAndServeTLS acts identically to ListenAndServe, except that it\n\/\/ uses the TELNET protocol over TLS.\n\/\/\n\/\/ From a TELNET protocol point-of-view, it allows for 'secured telnet', also known as TELNETS,\n\/\/ which by default listens to port 992.","result":"Code too long,keep in 512.","score":[0,0.0137]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (fn ProducerFunc) Produce(ctx telnet.Context, name string, args ...string) Handler {\r\n\treturn fn(ctx, name, args...)\r\n}","code-length":47,"reference":"\/\/ Produce makes ProducerFunc fit the Producer interface.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PromoteHandlerFunc(fn HandlerFunc, args ...string) Handler {\r\n\tstdin,      stdinPipe := io.Pipe()\r\n\tstdoutPipe, stdout    := io.Pipe()\r\n\tstderrPipe, stderr    := io.Pipe()\r\n\targsCopy := make([]string, len(args))\r\n\tfor i, datum := range args {\r\n\t\targsCopy[i] = datum\r\n\t}\r\n\thandler := internalPromotedHandlerFunc{\r\n\t\terr:nil,\r\n\t\tfn:fn,\r\n\t\tstdin:stdin,\r\n\t\tstdout:stdout,\r\n\t\tstderr:stderr,\r\n\t\tstdinPipe:stdinPipe,\r\n\t\tstdoutPipe:stdoutPipe,\r\n\t\tstderrPipe:stderrPipe,\r\n\t\targs:argsCopy,\r\n\t}\r\n\treturn &handler\r\n}","code-length":207,"reference":"\/\/ PromoteHandlerFunc turns a HandlerFunc into a Handler.","result":"Promote a function to a handler function.","score":[0.1665,0.1266]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Serve(listener net.Listener, handler Handler) error {\r\n\tserver := &Server{Handler: handler}\r\n\treturn server.Serve(listener)\r\n}","code-length":47,"reference":"\/\/ Serve accepts an incoming TELNET or TELNETS client connection on the net.Listener `listener`.","result":"Serve the server.","score":[0.0124,0.0775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (server *Server) Serve(listener net.Listener) error {\r\n\tdefer listener.Close()\r\n\tlogger := server.logger()\r\n\thandler := server.Handler\r\n\tif nil == handler {\r\n\t\tlogger.Debug(\"Defaulted handler to EchoHandler.\")\r\n\t\thandler = EchoHandler\r\n\t}\r\n\tfor {\r\n\t\t\r\n\t\tlogger.Debugf(\"Listening at %q.\", listener.Addr())\r\n\t\tconn, err := listener.Accept()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tlogger.Debugf(\"Received new connection from %q.\", conn.RemoteAddr())\r\n\t\t\r\n\t\t\r\n\t\tgo server.handle(conn, handler)\r\n\t\tlogger.Debugf(\"Spawned handler to handle connection from %q.\", conn.RemoteAddr())\r\n\t}\r\n}","code-length":215,"reference":"\/\/ Serve accepts an incoming TELNET client connection on the net.Listener `listener`.","result":"Serve the server.","score":[0.0242,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Parser) Fail(msg string) {\r\n\tp.WriteUsage(os.Stderr)\r\n\tfmt.Fprintln(os.Stderr, \"error:\", msg)\r\n\tos.Exit(-1)\r\n}","code-length":63,"reference":"\/\/ Fail prints usage information to stderr and exits with non-zero status","result":"Parse error messages.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Parser) WriteUsage(w io.Writer) {\r\n\tvar positionals, options []*spec\r\n\tfor _, spec := range p.specs {\r\n\t\tif spec.positional {\r\n\t\t\tpositionals = append(positionals, spec)\r\n\t\t} else {\r\n\t\t\toptions = append(options, spec)\r\n\t\t}\r\n\t}\r\n\tif p.version != \"\" {\r\n\t\tfmt.Fprintln(w, p.version)\r\n\t}\r\n\tfmt.Fprintf(w, \"Usage: %s\", p.config.Program)\r\n\t\r\n\tfor _, spec := range options {\r\n\t\t\r\n\t\tfmt.Fprint(w, \" \")\r\n\t\tif !spec.required {\r\n\t\t\tfmt.Fprint(w, \"[\")\r\n\t\t}\r\n\t\tfmt.Fprint(w, synopsis(spec, \"--\"+spec.long))\r\n\t\tif !spec.required {\r\n\t\t\tfmt.Fprint(w, \"]\")\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor _, spec := range positionals {\r\n\t\t\r\n\t\tfmt.Fprint(w, \" \")\r\n\t\tup := strings.ToUpper(spec.long)\r\n\t\tif spec.multiple {\r\n\t\t\tif !spec.required {\r\n\t\t\t\tfmt.Fprint(w, \"[\")\r\n\t\t\t}\r\n\t\t\tfmt.Fprintf(w, \"%s [%s ...]\", up, up)\r\n\t\t\tif !spec.required {\r\n\t\t\t\tfmt.Fprint(w, \"]\")\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\tfmt.Fprint(w, up)\r\n\t\t}\r\n\t}\r\n\tfmt.Fprint(w, \"\\n\")\r\n}","code-length":441,"reference":"\/\/ WriteUsage writes usage information to the given writer","result":"Write the usage of the parser.","score":[0.1392,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Parser) WriteHelp(w io.Writer) {\r\n\tvar positionals, options []*spec\r\n\tfor _, spec := range p.specs {\r\n\t\tif spec.positional {\r\n\t\t\tpositionals = append(positionals, spec)\r\n\t\t} else {\r\n\t\t\toptions = append(options, spec)\r\n\t\t}\r\n\t}\r\n\tif p.description != \"\" {\r\n\t\tfmt.Fprintln(w, p.description)\r\n\t}\r\n\tp.WriteUsage(w)\r\n\t\r\n\tif len(positionals) > 0 {\r\n\t\tfmt.Fprint(w, \"\\nPositional arguments:\\n\")\r\n\t\tfor _, spec := range positionals {\r\n\t\t\tleft := \"  \" + strings.ToUpper(spec.long)\r\n\t\t\tfmt.Fprint(w, left)\r\n\t\t\tif spec.help != \"\" {\r\n\t\t\t\tif len(left)+2 < colWidth {\r\n\t\t\t\t\tfmt.Fprint(w, strings.Repeat(\" \", colWidth-len(left)))\r\n\t\t\t\t} else {\r\n\t\t\t\t\tfmt.Fprint(w, \"\\n\"+strings.Repeat(\" \", colWidth))\r\n\t\t\t\t}\r\n\t\t\t\tfmt.Fprint(w, spec.help)\r\n\t\t\t}\r\n\t\t\tfmt.Fprint(w, \"\\n\")\r\n\t\t}\r\n\t}\r\n\t\r\n\tfmt.Fprint(w, \"\\nOptions:\\n\")\r\n\tfor _, spec := range options {\r\n\t\tprintOption(w, spec)\r\n\t}\r\n\t\r\n\tprintOption(w, &spec{boolean: true, long: \"help\", short: \"h\", help: \"display this help and exit\"})\r\n\tif p.version != \"\" {\r\n\t\tprintOption(w, &spec{boolean: true, long: \"version\", help: \"display version and exit\"})\r\n\t}\r\n}","code-length":474,"reference":"\/\/ WriteHelp writes the usage string followed by the full help string for each option","result":"Write the help to the writer.","score":[0.0567,0.2238]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MustParse(dest ...interface{}) *Parser {\r\n\tp, err := NewParser(Config{}, dest...)\r\n\tif err != nil {\r\n\t\tfmt.Println(err)\r\n\t\tos.Exit(-1)\r\n\t}\r\n\terr = p.Parse(flags())\r\n\tif err == ErrHelp {\r\n\t\tp.WriteHelp(os.Stdout)\r\n\t\tos.Exit(0)\r\n\t}\r\n\tif err == ErrVersion {\r\n\t\tfmt.Println(p.version)\r\n\t\tos.Exit(0)\r\n\t}\r\n\tif err != nil {\r\n\t\tp.Fail(err.Error())\r\n\t}\r\n\treturn p\r\n}","code-length":184,"reference":"\/\/ MustParse processes command line arguments and exits upon failure","result":"Parse a string or a list of strings.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Parse(dest ...interface{}) error {\r\n\tp, err := NewParser(Config{}, dest...)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn p.Parse(flags())\r\n}","code-length":65,"reference":"\/\/ Parse processes command line arguments and stores them in dest","result":"Parse the source.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc walkFields(v reflect.Value, visit func(field reflect.StructField, val reflect.Value, owner reflect.Type) bool) {\r\n\tt := v.Type()\r\n\tfor i := 0; i < t.NumField(); i++ {\r\n\t\tfield := t.Field(i)\r\n\t\tval := v.Field(i)\r\n\t\texpand := visit(field, val, t)\r\n\t\tif expand && field.Type.Kind() == reflect.Struct {\r\n\t\t\twalkFields(val, visit)\r\n\t\t}\r\n\t}\r\n}","code-length":146,"reference":"\/\/ walkFields calls a function for each field of a struct, recursively expanding struct fields.","result":"Walk the fields of a struct .","score":[0.0806,0.2641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Parser) Parse(args []string) error {\r\n\t\r\n\tfor _, arg := range args {\r\n\t\tif arg == \"-h\" || arg == \"--help\" {\r\n\t\t\treturn ErrHelp\r\n\t\t}\r\n\t\tif arg == \"--version\" {\r\n\t\t\treturn ErrVersion\r\n\t\t}\r\n\t\tif arg == \"--\" {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\t\r\n\treturn process(p.specs, args)\r\n}","code-length":130,"reference":"\/\/ Parse processes the given command line option, storing the results in the field\n\/\/ of the structs from which NewParser was constructed","result":"Parse the command line.","score":[0.0036,0.0711]}
{"code":"\/*is used to<extra_id_0>\r\nfunc setSlice(dest reflect.Value, values []string, trunc bool) error {\r\n\tif !dest.CanSet() {\r\n\t\treturn fmt.Errorf(\"field is not writable\")\r\n\t}\r\n\tvar ptr bool\r\n\telem := dest.Type().Elem()\r\n\tif elem.Kind() == reflect.Ptr && !elem.Implements(textUnmarshalerType) {\r\n\t\tptr = true\r\n\t\telem = elem.Elem()\r\n\t}\r\n\t\r\n\tif trunc && !dest.IsNil() {\r\n\t\tdest.SetLen(0)\r\n\t}\r\n\tfor _, s := range values {\r\n\t\tv := reflect.New(elem)\r\n\t\tif err := scalar.ParseValue(v.Elem(), s); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif !ptr {\r\n\t\t\tv = v.Elem()\r\n\t\t}\r\n\t\tdest.Set(reflect.Append(dest, v))\r\n\t}\r\n\treturn nil\r\n}","code-length":256,"reference":"\/\/ parse a value as the appropriate type and store it in the struct","result":"Set a slice of strings to a field.","score":[0.0656,0.0373]}
{"code":"\/*is used to<extra_id_0>\r\nfunc canParse(t reflect.Type) (parseable, boolean, multiple bool) {\r\n\tparseable = scalar.CanParse(t)\r\n\tboolean = isBoolean(t)\r\n\tif parseable {\r\n\t\treturn\r\n\t}\r\n\t\r\n\tif t.Kind() == reflect.Ptr {\r\n\t\tt = t.Elem()\r\n\t}\r\n\t\r\n\tif t.Kind() == reflect.Slice {\r\n\t\tmultiple = true\r\n\t\tt = t.Elem()\r\n\t}\r\n\tparseable = scalar.CanParse(t)\r\n\tboolean = isBoolean(t)\r\n\tif parseable {\r\n\t\treturn\r\n\t}\r\n\t\r\n\tif t.Kind() == reflect.Ptr {\r\n\t\tt = t.Elem()\r\n\t}\r\n\tparseable = scalar.CanParse(t)\r\n\tboolean = isBoolean(t)\r\n\tif parseable {\r\n\t\treturn\r\n\t}\r\n\treturn false, false, false\r\n}","code-length":251,"reference":"\/\/ canParse returns true if the type can be parsed from a string","result":"Check if a type can be parsed.","score":[0.1604,0.3597]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isBoolean(t reflect.Type) bool {\r\n\tswitch {\r\n\tcase t.Implements(textUnmarshalerType):\r\n\t\treturn false\r\n\tcase t.Kind() == reflect.Bool:\r\n\t\treturn true\r\n\tcase t.Kind() == reflect.Ptr && t.Elem().Kind() == reflect.Bool:\r\n\t\treturn true\r\n\tdefault:\r\n\t\treturn false\r\n\t}\r\n}","code-length":109,"reference":"\/\/ isBoolean returns true if the type can be parsed from a single string","result":"Check if a type is a boolean .","score":[0.0863,0.1493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFromMap(m map[string]interface{}) *Tree {\r\n\tt := &Tree{root: &node{}}\r\n\tfor k, v := range m {\r\n\t\tt.Insert(k, v)\r\n\t}\r\n\treturn t\r\n}","code-length":73,"reference":"\/\/ NewFromMap returns a new tree containing the keys\n\/\/ from an existing map","result":"Create a new tree from a map.","score":[0.1315,0.2373]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Tree) Insert(s string, v interface{}) (interface{}, bool) {\r\n\tvar parent *node\r\n\tn := t.root\r\n\tsearch := s\r\n\tfor {\r\n\t\t\r\n\t\tif len(search) == 0 {\r\n\t\t\tif n.isLeaf() {\r\n\t\t\t\told := n.leaf.val\r\n\t\t\t\tn.leaf.val = v\r\n\t\t\t\treturn old, true\r\n\t\t\t}\r\n\t\t\tn.leaf = &leafNode{\r\n\t\t\t\tkey: s,\r\n\t\t\t\tval: v,\r\n\t\t\t}\r\n\t\t\tt.size++\r\n\t\t\treturn nil, false\r\n\t\t}\r\n\t\t\r\n\t\tparent = n\r\n\t\tn = n.getEdge(search[0])\r\n\t\t\r\n\t\tif n == nil {\r\n\t\t\te := edge{\r\n\t\t\t\tlabel: search[0],\r\n\t\t\t\tnode: &node{\r\n\t\t\t\t\tleaf: &leafNode{\r\n\t\t\t\t\t\tkey: s,\r\n\t\t\t\t\t\tval: v,\r\n\t\t\t\t\t},\r\n\t\t\t\t\tprefix: search,\r\n\t\t\t\t},\r\n\t\t\t}\r\n\t\t\tparent.addEdge(e)\r\n\t\t\tt.size++\r\n\t\t\treturn nil, false\r\n\t\t}\r\n\t\t\r\n\t\tcommonPrefix := longestPrefix(search, n.prefix)\r\n\t\tif commonPrefix == len(n.prefix) {\r\n\t\t\tsearch = search[commonPrefix:]\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tt.size++\r\n\t\tchild := &node{\r\n\t\t\tprefix: search[:commonPrefix],\r\n\t\t}\r\n\t\tparent.updateEdge(search[0], child)\r\n\t\t\r\n\t\tchild.addEdge(edge{\r\n\t\t\tlabel: n.prefix[commonPrefix],\r\n\t\t\tnode:  n,\r\n\t\t})\r\n\t\tn.prefix = n.prefix[commonPrefix:]\r\n\t\t\r\n\t\tleaf := &leafNode{\r\n\t\t\tkey: s,\r\n\t\t\tval: v,\r\n\t\t}\r\n\t\t\r\n\t\tsearch = search[commonPrefix:]\r\n\t\tif len(search) == 0 {\r\n\t\t\tchild.leaf = leaf\r\n\t\t\treturn nil, false\r\n\t\t}\r\n\t\t\r\n\t\tchild.addEdge(edge{\r\n\t\t\tlabel: search[0],\r\n\t\t\tnode: &node{\r\n\t\t\t\tleaf:   leaf,\r\n\t\t\t\tprefix: search,\r\n\t\t\t},\r\n\t\t})\r\n\t\treturn nil, false\r\n\t}\r\n}","code-length":636,"reference":"\/\/ Insert is used to add a newentry or update\n\/\/ an existing entry. Returns if updated.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Tree) Delete(s string) (interface{}, bool) {\r\n\tvar parent *node\r\n\tvar label byte\r\n\tn := t.root\r\n\tsearch := s\r\n\tfor {\r\n\t\t\r\n\t\tif len(search) == 0 {\r\n\t\t\tif !n.isLeaf() {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\tgoto DELETE\r\n\t\t}\r\n\t\t\r\n\t\tparent = n\r\n\t\tlabel = search[0]\r\n\t\tn = n.getEdge(label)\r\n\t\tif n == nil {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\t\r\n\t\tif strings.HasPrefix(search, n.prefix) {\r\n\t\t\tsearch = search[len(n.prefix):]\r\n\t\t} else {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\treturn nil, false\r\nDELETE:\r\n\t\r\n\tleaf := n.leaf\r\n\tn.leaf = nil\r\n\tt.size--\r\n\t\r\n\tif parent != nil && len(n.edges) == 0 {\r\n\t\tparent.delEdge(label)\r\n\t}\r\n\t\r\n\tif n != t.root && len(n.edges) == 1 {\r\n\t\tn.mergeChild()\r\n\t}\r\n\t\r\n\tif parent != nil && parent != t.root && len(parent.edges) == 1 && !parent.isLeaf() {\r\n\t\tparent.mergeChild()\r\n\t}\r\n\treturn leaf.val, true\r\n}","code-length":381,"reference":"\/\/ Delete is used to delete a key, returning the previous\n\/\/ value and if it was deleted","result":"Delete a string from a tree.","score":[0.0311,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Tree) DeletePrefix(s string) int {\r\n\treturn t.deletePrefix(nil, t.root, s)\r\n}","code-length":43,"reference":"\/\/ DeletePrefix is used to delete the subtree under a prefix\n\/\/ Returns how many nodes were deleted\n\/\/ Use this to delete large subtrees efficiently","result":"Delete the prefix.","score":[0.0002,0.0422]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Tree) deletePrefix(parent, n *node, prefix string) int {\r\n\t\r\n\tif len(prefix) == 0 {\r\n\t\t\r\n\t\tsubTreeSize := 0\r\n\t\t\r\n\t\trecursiveWalk(n, func(s string, v interface{}) bool {\r\n\t\t\tsubTreeSize++\r\n\t\t\treturn false\r\n\t\t})\r\n\t\tif n.isLeaf() {\r\n\t\t\tn.leaf = nil\r\n\t\t}\r\n\t\tn.edges = nil\r\n\t\t\r\n\t\tif parent != nil && parent != t.root && len(parent.edges) == 1 && !parent.isLeaf() {\r\n\t\t\tparent.mergeChild()\r\n\t\t}\r\n\t\tt.size -= subTreeSize\r\n\t\treturn subTreeSize\r\n\t}\r\n\t\r\n\tlabel := prefix[0]\r\n\tchild := n.getEdge(label)\r\n\tif child == nil || (!strings.HasPrefix(child.prefix, prefix) && !strings.HasPrefix(prefix, child.prefix)) {\r\n\t\treturn 0\r\n\t}\r\n\t\r\n\tif len(child.prefix) > len(prefix) {\r\n\t\tprefix = prefix[len(prefix):]\r\n\t} else {\r\n\t\tprefix = prefix[len(child.prefix):]\r\n\t}\r\n\treturn t.deletePrefix(n, child, prefix)\r\n}","code-length":345,"reference":"\/\/ delete does a recursive deletion","result":"Delete a prefix from a node.","score":[0.193,0.1667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Tree) Get(s string) (interface{}, bool) {\r\n\tn := t.root\r\n\tsearch := s\r\n\tfor {\r\n\t\t\r\n\t\tif len(search) == 0 {\r\n\t\t\tif n.isLeaf() {\r\n\t\t\t\treturn n.leaf.val, true\r\n\t\t\t}\r\n\t\t\tbreak\r\n\t\t}\r\n\t\t\r\n\t\tn = n.getEdge(search[0])\r\n\t\tif n == nil {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\t\r\n\t\tif strings.HasPrefix(search, n.prefix) {\r\n\t\t\tsearch = search[len(n.prefix):]\r\n\t\t} else {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\treturn nil, false\r\n}","code-length":202,"reference":"\/\/ Get is used to lookup a specific key, returning\n\/\/ the value and if it was found","result":"Get the value of a string.","score":[0.0439,0.1879]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Tree) LongestPrefix(s string) (string, interface{}, bool) {\r\n\tvar last *leafNode\r\n\tn := t.root\r\n\tsearch := s\r\n\tfor {\r\n\t\t\r\n\t\tif n.isLeaf() {\r\n\t\t\tlast = n.leaf\r\n\t\t}\r\n\t\t\r\n\t\tif len(search) == 0 {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\t\r\n\t\tn = n.getEdge(search[0])\r\n\t\tif n == nil {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\t\r\n\t\tif strings.HasPrefix(search, n.prefix) {\r\n\t\t\tsearch = search[len(n.prefix):]\r\n\t\t} else {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif last != nil {\r\n\t\treturn last.key, last.val, true\r\n\t}\r\n\treturn \"\", nil, false\r\n}","code-length":241,"reference":"\/\/ LongestPrefix is like Get, but instead of an\n\/\/ exact match, it will return the longest prefix match.","result":"Find longest prefix of a string.","score":[0.0346,0.1444]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Tree) Minimum() (string, interface{}, bool) {\r\n\tn := t.root\r\n\tfor {\r\n\t\tif n.isLeaf() {\r\n\t\t\treturn n.leaf.key, n.leaf.val, true\r\n\t\t}\r\n\t\tif len(n.edges) > 0 {\r\n\t\t\tn = n.edges[0].node\r\n\t\t} else {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\treturn \"\", nil, false\r\n}","code-length":132,"reference":"\/\/ Minimum is used to return the minimum value in the tree","result":"Find the minimum value of a key in a.","score":[0.1933,0.2698]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Tree) WalkPrefix(prefix string, fn WalkFn) {\r\n\tn := t.root\r\n\tsearch := prefix\r\n\tfor {\r\n\t\t\r\n\t\tif len(search) == 0 {\r\n\t\t\trecursiveWalk(n, fn)\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\tn = n.getEdge(search[0])\r\n\t\tif n == nil {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\t\r\n\t\tif strings.HasPrefix(search, n.prefix) {\r\n\t\t\tsearch = search[len(n.prefix):]\r\n\t\t} else if strings.HasPrefix(n.prefix, search) {\r\n\t\t\t\r\n\t\t\trecursiveWalk(n, fn)\r\n\t\t\treturn\r\n\t\t} else {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n}","code-length":215,"reference":"\/\/ WalkPrefix is used to walk the tree under a prefix","result":"Walk the tree.","score":[0.0284,0.1838]}
{"code":"\/*is used to<extra_id_0>\r\nfunc recursiveWalk(n *node, fn WalkFn) bool {\r\n\t\r\n\tif n.leaf != nil && fn(n.leaf.key, n.leaf.val) {\r\n\t\treturn true\r\n\t}\r\n\t\r\n\tfor _, e := range n.edges {\r\n\t\tif recursiveWalk(e.node, fn) {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":115,"reference":"\/\/ recursiveWalk is used to do a pre-order walk of a node\n\/\/ recursively. Returns true if the walk should be aborted","result":"Recursively walk a node recursively.","score":[0.0135,0.1555]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Tree) ToMap() map[string]interface{} {\r\n\tout := make(map[string]interface{}, t.size)\r\n\tt.Walk(func(k string, v interface{}) bool {\r\n\t\tout[k] = v\r\n\t\treturn false\r\n\t})\r\n\treturn out\r\n}","code-length":89,"reference":"\/\/ ToMap is used to walk the tree and convert it into a map","result":"Generate the map to return.","score":[0.0523,0.1145]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkip(ip string) (iptype uint32, ipnum *big.Int, ipindex uint32) {\r\n\tiptype = 0\r\n\tipnum = big.NewInt(0)\r\n\tipnumtmp := big.NewInt(0)\r\n\tipindex = 0\r\n\tipaddress := net.ParseIP(ip)\r\n\t\r\n\tif ipaddress != nil {\r\n\t\tv4 := ipaddress.To4()\r\n\t\t\r\n\t\tif v4 != nil {\r\n\t\t\tiptype = 4\r\n\t\t\tipnum.SetBytes(v4)\r\n\t\t} else {\r\n\t\t\tv6 := ipaddress.To16()\r\n\t\t\t\r\n\t\t\tif v6 != nil {\r\n\t\t\t\tiptype = 6\r\n\t\t\t\tipnum.SetBytes(v6)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif iptype == 4 {\r\n\t\tif meta.ipv4indexbaseaddr > 0 {\r\n\t\t\tipnumtmp.Rsh(ipnum, 16)\r\n\t\t\tipnumtmp.Lsh(ipnumtmp, 3)\r\n\t\t\tipindex = uint32(ipnumtmp.Add(ipnumtmp, big.NewInt(int64(meta.ipv4indexbaseaddr))).Uint64())\r\n\t\t}\r\n\t} else if iptype == 6 {\r\n\t\tif meta.ipv6indexbaseaddr > 0 {\r\n\t\t\tipnumtmp.Rsh(ipnum, 112)\r\n\t\t\tipnumtmp.Lsh(ipnumtmp, 3)\r\n\t\t\tipindex = uint32(ipnumtmp.Add(ipnumtmp, big.NewInt(int64(meta.ipv6indexbaseaddr))).Uint64())\r\n\t\t}\r\n\t}\r\n\treturn \r\n}","code-length":430,"reference":"\/\/ get IP type and calculate IP number; calculates index too if exists","result":"Check if the ip is valid .","score":[0.0685,0.121]}
{"code":"\/*is used to<extra_id_0>\r\nfunc readuint32(pos uint32) uint32 {\r\n\tpos2 := int64(pos)\r\n\tvar retval uint32\r\n\tdata := make([]byte, 4)\r\n\t_, err := f.ReadAt(data, pos2 - 1)\r\n\tif err != nil {\r\n\t\tfmt.Println(\"File read failed:\", err)\r\n\t}\r\n\tbuf := bytes.NewReader(data)\r\n\terr = binary.Read(buf, binary.LittleEndian, &retval)\r\n\tif err != nil {\r\n\t\tfmt.Println(\"Binary read failed:\", err)\r\n\t}\r\n\treturn retval\r\n}","code-length":165,"reference":"\/\/ read unsigned 32-bit integer","result":"Read uint.","score":[0,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc readuint128(pos uint32) *big.Int {\r\n\tpos2 := int64(pos)\r\n\tretval := big.NewInt(0)\r\n\tdata := make([]byte, 16)\r\n\t_, err := f.ReadAt(data, pos2 - 1)\r\n\tif err != nil {\r\n\t\tfmt.Println(\"File read failed:\", err)\r\n\t}\r\n\t\r\n\t\r\n\tfor i, j := 0, len(data)-1; i < j; i, j = i+1, j-1 {\r\n\t\tdata[i], data[j] = data[j], data[i]\r\n\t}\r\n\tretval.SetBytes(data)\r\n\treturn retval\r\n}","code-length":186,"reference":"\/\/ read unsigned 128-bit integer","result":"Read uint.","score":[0,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc loadmessage (mesg string) IP2Locationrecord {\r\n\tvar x IP2Locationrecord\r\n\t\r\n\tx.Country_short = mesg\r\n\tx.Country_long = mesg\r\n\tx.Region = mesg\r\n\tx.City = mesg\r\n\tx.Isp = mesg\r\n\tx.Domain = mesg\r\n\tx.Zipcode = mesg\r\n\tx.Timezone = mesg\r\n\tx.Netspeed = mesg\r\n\tx.Iddcode = mesg\r\n\tx.Areacode = mesg\r\n\tx.Weatherstationcode = mesg\r\n\tx.Weatherstationname = mesg\r\n\tx.Mcc = mesg\r\n\tx.Mnc = mesg\r\n\tx.Mobilebrand = mesg\r\n\tx.Usagetype = mesg\r\n\t\r\n\treturn x\r\n}","code-length":220,"reference":"\/\/ populate record with message","result":"Load a message.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Printrecord(x IP2Locationrecord) {\r\n\tfmt.Printf(\"country_short: %s\\n\", x.Country_short)\r\n\tfmt.Printf(\"country_long: %s\\n\", x.Country_long)\r\n\tfmt.Printf(\"region: %s\\n\", x.Region)\r\n\tfmt.Printf(\"city: %s\\n\", x.City)\r\n\tfmt.Printf(\"isp: %s\\n\", x.Isp)\r\n\tfmt.Printf(\"latitude: %f\\n\", x.Latitude)\r\n\tfmt.Printf(\"longitude: %f\\n\", x.Longitude)\r\n\tfmt.Printf(\"domain: %s\\n\", x.Domain)\r\n\tfmt.Printf(\"zipcode: %s\\n\", x.Zipcode)\r\n\tfmt.Printf(\"timezone: %s\\n\", x.Timezone)\r\n\tfmt.Printf(\"netspeed: %s\\n\", x.Netspeed)\r\n\tfmt.Printf(\"iddcode: %s\\n\", x.Iddcode)\r\n\tfmt.Printf(\"areacode: %s\\n\", x.Areacode)\r\n\tfmt.Printf(\"weatherstationcode: %s\\n\", x.Weatherstationcode)\r\n\tfmt.Printf(\"weatherstationname: %s\\n\", x.Weatherstationname)\r\n\tfmt.Printf(\"mcc: %s\\n\", x.Mcc)\r\n\tfmt.Printf(\"mnc: %s\\n\", x.Mnc)\r\n\tfmt.Printf(\"mobilebrand: %s\\n\", x.Mobilebrand)\r\n\tfmt.Printf(\"elevation: %f\\n\", x.Elevation)\r\n\tfmt.Printf(\"usagetype: %s\\n\", x.Usagetype)\r\n}","code-length":426,"reference":"\/\/ for debugging purposes","result":"Print the record.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Main(gc draw2d.GraphicContext, ext string) (string, error) {\r\n\tgc.Save()\r\n\tgc.Scale(0.5, 0.5)\r\n\t\r\n\tDraw(gc)\r\n\tgc.Restore()\r\n\t\r\n\treturn samples.Output(\"gopher\", ext), nil\r\n}","code-length":89,"reference":"\/\/ Main draws a left hand and ear of a gopher. Afterwards it returns\n\/\/ the filename. This should only be used during testing.","result":"Generate the program.","score":[0.0004,0.0228]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SaveToPdfFile(filePath string, pdf *gofpdf.Fpdf) error {\r\n\treturn pdf.OutputFileAndClose(filePath)\r\n}","code-length":45,"reference":"\/\/ SaveToPdfFile creates and saves a pdf document to a file","result":"Generate the file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Path) CubicCurveTo(cx1, cy1, cx2, cy2, x, y float64) {\r\n\tif len(p.Components) == 0 {\r\n\t\tp.MoveTo(x, y)\r\n\t} else {\r\n\t\tp.appendToPath(CubicCurveToCmp, cx1, cy1, cx2, cy2, x, y)\r\n\t}\r\n\tp.x = x\r\n\tp.y = y\r\n}","code-length":127,"reference":"\/\/ CubicCurveTo adds a cubic bezier curve to the current path","result":"Create a new path.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Path) ArcTo(cx, cy, rx, ry, startAngle, angle float64) {\r\n\tendAngle := startAngle + angle\r\n\tclockWise := true\r\n\tif angle < 0 {\r\n\t\tclockWise = false\r\n\t}\r\n\t\r\n\tif clockWise {\r\n\t\tfor endAngle < startAngle {\r\n\t\t\tendAngle += math.Pi * 2.0\r\n\t\t}\r\n\t} else {\r\n\t\tfor startAngle < endAngle {\r\n\t\t\tstartAngle += math.Pi * 2.0\r\n\t\t}\r\n\t}\r\n\tstartX := cx + math.Cos(startAngle)*rx\r\n\tstartY := cy + math.Sin(startAngle)*ry\r\n\tif len(p.Components) > 0 {\r\n\t\tp.LineTo(startX, startY)\r\n\t} else {\r\n\t\tp.MoveTo(startX, startY)\r\n\t}\r\n\tp.appendToPath(ArcToCmp, cx, cy, rx, ry, startAngle, angle)\r\n\tp.x = cx + math.Cos(endAngle)*rx\r\n\tp.y = cy + math.Sin(endAngle)*ry\r\n}","code-length":307,"reference":"\/\/ ArcTo adds an arc to the path","result":"Create a new path.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Path) String() string {\r\n\ts := \"\"\r\n\tj := 0\r\n\tfor _, cmd := range p.Components {\r\n\t\tswitch cmd {\r\n\t\tcase MoveToCmp:\r\n\t\t\ts += fmt.Sprintf(\"MoveTo: %f, %f\\n\", p.Points[j], p.Points[j+1])\r\n\t\t\tj = j + 2\r\n\t\tcase LineToCmp:\r\n\t\t\ts += fmt.Sprintf(\"LineTo: %f, %f\\n\", p.Points[j], p.Points[j+1])\r\n\t\t\tj = j + 2\r\n\t\tcase QuadCurveToCmp:\r\n\t\t\ts += fmt.Sprintf(\"QuadCurveTo: %f, %f, %f, %f\\n\", p.Points[j], p.Points[j+1], p.Points[j+2], p.Points[j+3])\r\n\t\t\tj = j + 4\r\n\t\tcase CubicCurveToCmp:\r\n\t\t\ts += fmt.Sprintf(\"CubicCurveTo: %f, %f, %f, %f, %f, %f\\n\", p.Points[j], p.Points[j+1], p.Points[j+2], p.Points[j+3], p.Points[j+4], p.Points[j+5])\r\n\t\t\tj = j + 6\r\n\t\tcase ArcToCmp:\r\n\t\t\ts += fmt.Sprintf(\"ArcTo: %f, %f, %f, %f, %f, %f\\n\", p.Points[j], p.Points[j+1], p.Points[j+2], p.Points[j+3], p.Points[j+4], p.Points[j+5])\r\n\t\t\tj = j + 6\r\n\t\tcase CloseCmp:\r\n\t\t\ts += \"Close\\n\"\r\n\t\t}\r\n\t}\r\n\treturn s\r\n}","code-length":473,"reference":"\/\/ String returns a debug text view of the path","result":"Generate the string representation of the path.","score":[0.1488,0.2635]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (path *Path) VerticalFlip() *Path {\r\n\tp := path.Copy()\r\n\tj := 0\r\n\tfor _, cmd := range p.Components {\r\n\t\tswitch cmd {\r\n\t\tcase MoveToCmp, LineToCmp:\r\n\t\t\tp.Points[j+1] = -p.Points[j+1]\r\n\t\t\tj = j + 2\r\n\t\tcase QuadCurveToCmp:\r\n\t\t\tp.Points[j+1] = -p.Points[j+1]\r\n\t\t\tp.Points[j+3] = -p.Points[j+3]\r\n\t\t\tj = j + 4\r\n\t\tcase CubicCurveToCmp:\r\n\t\t\tp.Points[j+1] = -p.Points[j+1]\r\n\t\t\tp.Points[j+3] = -p.Points[j+3]\r\n\t\t\tp.Points[j+5] = -p.Points[j+5]\r\n\t\t\tj = j + 6\r\n\t\tcase ArcToCmp:\r\n\t\t\tp.Points[j+1] = -p.Points[j+1]\r\n\t\t\tp.Points[j+3] = -p.Points[j+3]\r\n\t\t\tp.Points[j+4] = -p.Points[j+4]\r\n\t\t\tp.Points[j+5] = -p.Points[j+5]\r\n\t\t\tj = j + 6\r\n\t\tcase CloseCmp:\r\n\t\t}\r\n\t}\r\n\tp.y = -p.y\r\n\treturn p\r\n}","code-length":391,"reference":"\/\/ Returns new Path with flipped y axes","result":"Flip the y coordinate of the path.","score":[0.14,0.1266]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewGlyphCache() *GlyphCacheImp {\r\n\tglyphs := make(map[string]map[rune]*Glyph)\r\n\treturn &GlyphCacheImp {\r\n\t\tglyphs: glyphs,\r\n\t}\r\n}","code-length":63,"reference":"\/\/ NewGlyphCache initializes a GlyphCache","result":"Create a glyph cache.","score":[0.2488,0.102]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (glyphCache *GlyphCacheImp) Fetch(gc draw2d.GraphicContext, fontName string, chr rune) *Glyph {\r\n\tif glyphCache.glyphs[fontName] == nil {\r\n\t\tglyphCache.glyphs[fontName] = make(map[rune]*Glyph, 60)\r\n\t}\r\n\tif glyphCache.glyphs[fontName][chr] == nil {\r\n\t\tglyphCache.glyphs[fontName][chr] = renderGlyph(gc, fontName, chr)\r\n\t}\r\n\treturn glyphCache.glyphs[fontName][chr].Copy()\r\n}","code-length":151,"reference":"\/\/ Fetch fetches a glyph from the cache, calling renderGlyph first if it doesn't already exist","result":"Cache the glyph cache.","score":[0.0189,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc renderGlyph(gc draw2d.GraphicContext, fontName string, chr rune) *Glyph {\r\n\tgc.Save()\r\n\tdefer gc.Restore()\r\n\tgc.BeginPath()\r\n\twidth := gc.CreateStringPath(string(chr), 0, 0)\r\n\tpath := gc.GetPath()\r\n\treturn &Glyph{\r\n\t\tPath:  &path,\r\n\t\tWidth: width,\r\n\t}\r\n}","code-length":115,"reference":"\/\/ renderGlyph renders a glyph then caches and returns it","result":"Render glyph .","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Glyph) Copy() *Glyph {\r\n\treturn &Glyph{\r\n\t\tPath:  g.Path.Copy(),\r\n\t\tWidth: g.Width,\r\n\t}\r\n}","code-length":57,"reference":"\/\/ Copy Returns a copy of a Glyph","result":"Copy glyph objects.","score":[0.0771,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Glyph) Fill(gc draw2d.GraphicContext, x, y float64) float64 {\r\n\tgc.Save()\r\n\tgc.BeginPath()\r\n\tgc.Translate(x, y)\r\n\tgc.Fill(g.Path)\r\n\tgc.Restore()\r\n\treturn g.Width\r\n}","code-length":88,"reference":"\/\/ Fill copies a glyph from the cache, and fills it","result":"Fill the path.","score":[0.0337,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Main(gc draw2d.GraphicContext, ext string) (string, error) {\r\n\tgc.SetFillRule(draw2d.FillRuleWinding)\r\n\tgc.Clear()\r\n\t\r\n\tfor x := 5.0; x < 297; x += 10 {\r\n\t\tDraw(gc, x, 0, x, 210)\r\n\t}\r\n\tgc.ClearRect(100, 75, 197, 135)\r\n\tdraw2dkit.Ellipse(gc, 148.5, 105, 35, 25)\r\n\tgc.SetFillColor(color.RGBA{0xff, 0xff, 0x44, 0xff})\r\n\tgc.FillStroke()\r\n\t\r\n\treturn samples.Output(\"line\", ext), nil\r\n}","code-length":192,"reference":"\/\/ Main draws vertically spaced lines and returns the filename.\n\/\/ This should only be used during testing.","result":"Generate the sample file.","score":[0.0096,0.0301]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Draw(gc draw2d.GraphicContext, x0, y0, x1, y1 float64) {\r\n\t\r\n\tgc.MoveTo(x0, y0)\r\n\tgc.LineTo(x1, y1)\r\n\tgc.Stroke()\r\n}","code-length":76,"reference":"\/\/ Draw vertically spaced lines","result":"Draw the draw.","score":[0.2096,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Painter) Paint(ss []raster.Span, done bool) {\r\n\t\r\n\tsslen := len(ss)\r\n\tclenrequired := sslen * 8\r\n\tvlenrequired := sslen * 4\r\n\tif clenrequired >= (cap(p.colors) - len(p.colors)) {\r\n\t\tp.Flush()\r\n\t\tif clenrequired >= cap(p.colors) {\r\n\t\t\tp.vertices = make([]int32, 0, vlenrequired+(vlenrequired\/2))\r\n\t\t\tp.colors = make([]uint8, 0, clenrequired+(clenrequired\/2))\r\n\t\t}\r\n\t}\r\n\tvi := len(p.vertices)\r\n\tci := len(p.colors)\r\n\tp.vertices = p.vertices[0 : vi+vlenrequired]\r\n\tp.colors = p.colors[0 : ci+clenrequired]\r\n\tvar (\r\n\t\tcolors   []uint8\r\n\t\tvertices []int32\r\n\t)\r\n\tfor _, s := range ss {\r\n\t\ta := uint8((s.Alpha * p.ca \/ M16) >> 8)\r\n\t\tcolors = p.colors[ci:]\r\n\t\tcolors[0] = p.cr\r\n\t\tcolors[1] = p.cg\r\n\t\tcolors[2] = p.cb\r\n\t\tcolors[3] = a\r\n\t\tcolors[4] = p.cr\r\n\t\tcolors[5] = p.cg\r\n\t\tcolors[6] = p.cb\r\n\t\tcolors[7] = a\r\n\t\tci += 8\r\n\t\tvertices = p.vertices[vi:]\r\n\t\tvertices[0] = int32(s.X0)\r\n\t\tvertices[1] = int32(s.Y)\r\n\t\tvertices[2] = int32(s.X1)\r\n\t\tvertices[3] = int32(s.Y)\r\n\t\tvi += 4\r\n\t}\r\n}","code-length":492,"reference":"\/\/ Paint satisfies the Painter interface by painting ss onto an image.RGBA.","result":"Draw the graphics .","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Painter) SetColor(c color.Color) {\r\n\tr, g, b, a := c.RGBA()\r\n\tif a == 0 {\r\n\t\tp.cr = 0\r\n\t\tp.cg = 0\r\n\t\tp.cb = 0\r\n\t\tp.ca = a\r\n\t} else {\r\n\t\tp.cr = uint8((r * M16 \/ a) >> 8)\r\n\t\tp.cg = uint8((g * M16 \/ a) >> 8)\r\n\t\tp.cb = uint8((b * M16 \/ a) >> 8)\r\n\t\tp.ca = a\r\n\t}\r\n}","code-length":168,"reference":"\/\/ SetColor sets the color to paint the spans.","result":"Set the color of the painters.","score":[0.1833,0.431]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPainter() *Painter {\r\n\tp := new(Painter)\r\n\tp.vertices = make([]int32, 0, 1024)\r\n\tp.colors = make([]uint8, 0, 1024)\r\n\treturn p\r\n}","code-length":67,"reference":"\/\/ NewRGBAPainter creates a new RGBAPainter for the given image.","result":"Create a new instance of the new painter.","score":[0.1693,0.3221]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gc *GraphicContext) GetStringBounds(s string) (left, top, right, bottom float64) {\r\n\tf, err := gc.loadCurrentFont()\r\n\tif err != nil {\r\n\t\tlog.Println(err)\r\n\t\treturn 0, 0, 0, 0\r\n\t}\r\n\ttop, left, bottom, right = 10e6, 10e6, -10e6, -10e6\r\n\tcursor := 0.0\r\n\tprev, hasPrev := truetype.Index(0), false\r\n\tfor _, rune := range s {\r\n\t\tindex := f.Index(rune)\r\n\t\tif hasPrev {\r\n\t\t\tcursor += fUnitsToFloat64(f.Kern(fixed.Int26_6(gc.Current.Scale), prev, index))\r\n\t\t}\r\n\t\tif err := gc.glyphBuf.Load(gc.Current.Font, fixed.Int26_6(gc.Current.Scale), index, font.HintingNone); err != nil {\r\n\t\t\tlog.Println(err)\r\n\t\t\treturn 0, 0, 0, 0\r\n\t\t}\r\n\t\te0 := 0\r\n\t\tfor _, e1 := range gc.glyphBuf.Ends {\r\n\t\t\tps := gc.glyphBuf.Points[e0:e1]\r\n\t\t\tfor _, p := range ps {\r\n\t\t\t\tx, y := pointToF64Point(p)\r\n\t\t\t\ttop = math.Min(top, y)\r\n\t\t\t\tbottom = math.Max(bottom, y)\r\n\t\t\t\tleft = math.Min(left, x+cursor)\r\n\t\t\t\tright = math.Max(right, x+cursor)\r\n\t\t\t}\r\n\t\t}\r\n\t\tcursor += fUnitsToFloat64(f.HMetric(fixed.Int26_6(gc.Current.Scale), index).AdvanceWidth)\r\n\t\tprev, hasPrev = index, true\r\n\t}\r\n\treturn left, top, right, bottom\r\n}","code-length":488,"reference":"\/\/ GetStringBounds returns the approximate pixel bounds of the string s at x, y.\n\/\/ The the left edge of the em square of the first character of s\n\/\/ and the baseline intersect at 0, 0 in the returned coordinates.\n\/\/ Therefore the top and left coordinates may well be negative.","result":"Create a string bounds.","score":[0.0,0.0106]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gc *GraphicContext) recalc() {\r\n\tgc.Current.Scale = gc.Current.FontSize * float64(gc.DPI) * (64.0 \/ 72.0)\r\n}","code-length":56,"reference":"\/\/ recalc recalculates scale and bounds values from the font size, screen\n\/\/ resolution and font metrics, and invalidates the glyph cache.","result":"Recalc the current scale.","score":[0.0035,0.0495]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gc *GraphicContext) SetFont(font *truetype.Font) {\r\n\tgc.Current.Font = font\r\n}","code-length":41,"reference":"\/\/ SetFont sets the font used to draw text.","result":"Set the font in the current context.","score":[0.1716,0.1705]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gc *GraphicContext) ClearRect(x1, y1, x2, y2 int) {\r\n\tmask := gc.newMask(x1, y1, x2-x1, y2-y1)\r\n\tnewGroup := &Group{\r\n\t\tGroups: gc.svg.Groups,\r\n\t\tMask:   \"url(#\" + mask.Id + \")\",\r\n\t}\r\n\t\r\n\tgc.svg.Groups = []*Group{newGroup}\r\n}","code-length":126,"reference":"\/\/ ClearRect fills the specified rectangle with a default transparent color","result":"Clear the rectangle.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gc *GraphicContext) drawString(text string, drawType drawType, x, y float64) float64 {\r\n\tswitch gc.svg.FontMode {\r\n\tcase PathFontMode:\r\n\t\tw := gc.CreateStringPath(text, x, y)\r\n\t\tgc.drawPaths(drawType)\r\n\t\tgc.Current.Path.Clear()\r\n\t\treturn w\r\n\tcase SvgFontMode:\r\n\t\tgc.embedSvgFont(text)\r\n\t}\r\n\t\r\n\tsvgText := Text{}\r\n\tgroup := gc.newGroup(drawType)\r\n\t\r\n\tsvgText.Text = text\r\n\tsvgText.FontSize = gc.Current.FontSize\r\n\tsvgText.X = x\r\n\tsvgText.Y = y\r\n\tsvgText.FontFamily = gc.Current.FontData.Name\r\n\t\r\n\tgroup.Texts = []*Text{&svgText}\r\n\tleft, _, right, _ := gc.GetStringBounds(text)\r\n\treturn right - left\r\n}","code-length":260,"reference":"\/\/ Add text element to svg and returns its expected width","result":"Draw a string in the current context.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gc *GraphicContext) newGroup(drawType drawType) *Group {\r\n\tgroup := Group{}\r\n\t\r\n\tif drawType&stroked == stroked {\r\n\t\tgroup.Stroke = toSvgRGBA(gc.Current.StrokeColor)\r\n\t\tgroup.StrokeWidth = toSvgLength(gc.Current.LineWidth)\r\n\t\tgroup.StrokeLinecap = gc.Current.Cap.String()\r\n\t\tgroup.StrokeLinejoin = gc.Current.Join.String()\r\n\t\tif len(gc.Current.Dash) > 0 {\r\n\t\t\tgroup.StrokeDasharray = toSvgArray(gc.Current.Dash)\r\n\t\t\tgroup.StrokeDashoffset = toSvgLength(gc.Current.DashOffset)\r\n\t\t}\r\n\t}\r\n\tif drawType&filled == filled {\r\n\t\tgroup.Fill = toSvgRGBA(gc.Current.FillColor)\r\n\t\tgroup.FillRule = toSvgFillRule(gc.Current.FillRule)\r\n\t}\r\n\tgroup.Transform = toSvgTransform(gc.Current.Tr)\r\n\t\r\n\tgc.svg.Groups = append(gc.svg.Groups, &group)\r\n\treturn &group\r\n}","code-length":306,"reference":"\/\/ Creates new group from current context\n\/\/ attach it to svg and return","result":"Create a new group in the SVG.","score":[0.084,0.1921]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gc *GraphicContext) newMask(x, y, width, height int) *Mask {\r\n\tmask := &Mask{}\r\n\tmask.X = float64(x)\r\n\tmask.Y = float64(y)\r\n\tmask.Width = toSvgLength(float64(width))\r\n\tmask.Height = toSvgLength(float64(height))\r\n\t\r\n\tgc.svg.Masks = append(gc.svg.Masks, mask)\r\n\tmask.Id = \"mask-\" + strconv.Itoa(len(gc.svg.Masks))\r\n\treturn mask\r\n}","code-length":154,"reference":"\/\/ creates new mask attached to svg","result":"Create a new mask in the graphics context.","score":[0.1964,0.3599]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gc *GraphicContext) embedSvgFont(text string) *Font {\r\n\tfontName := gc.Current.FontData.Name\r\n\tgc.loadCurrentFont()\r\n\t\r\n\tsvgFont := (*Font)(nil)\r\n\tfor _, font := range gc.svg.Fonts {\r\n\t\tif font.Name == fontName {\r\n\t\t\tsvgFont = font\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif svgFont == nil {\r\n\t\t\r\n\t\tsvgFont = &Font{}\r\n\t\t\r\n\t\tgc.svg.Fonts = append(gc.svg.Fonts, svgFont)\r\n\t}\r\n\t\r\n\tgc.Save()\r\n\tdefer gc.Restore()\r\n\tgc.SetFontSize(2048)\r\n\tdefer gc.SetDPI(gc.GetDPI())\r\n\tgc.SetDPI(92)\r\nfilling:\r\n\tfor _, rune := range text {\r\n\t\tfor _, g := range svgFont.Glyphs {\r\n\t\t\tif g.Rune == Rune(rune) {\r\n\t\t\t\tcontinue filling\r\n\t\t\t}\r\n\t\t}\r\n\t\tglyph := gc.glyphCache.Fetch(gc, gc.GetFontName(), rune)\r\n\t\t\r\n\t\tglypPath := glyph.Path.VerticalFlip()\r\n\t\tsvgFont.Glyphs = append(svgFont.Glyphs, &Glyph{\r\n\t\t\tRune:      Rune(rune),\r\n\t\t\tDesc:      toSvgPathDesc(glypPath),\r\n\t\t\tHorizAdvX: glyph.Width,\r\n\t\t})\r\n\t}\r\n\t\r\n\tsvgFont.Id = \"font-\" + strconv.Itoa(len(gc.svg.Fonts))\r\n\tsvgFont.Name = fontName\r\n\t\r\n\tsvgFont.Face = &Face{Family: fontName, Units: 2048, HorizAdvX: 2048}\r\n\treturn svgFont\r\n}","code-length":476,"reference":"\/\/ Embed svg font definition to svg tree itself\n\/\/ Or update existing if already exists for curent font data","result":"Embed SVG fonts.","score":[0.0014,0.0546]}
{"code":"\/*is used to<extra_id_0>\r\nfunc TraceQuad(t Liner, quad []float64, flatteningThreshold float64) error {\r\n\tif len(quad) < 6 {\r\n\t\treturn errors.New(\"quad length must be >= 6\")\r\n\t}\r\n\t\r\n\tvar curves [CurveRecursionLimit * 6]float64\r\n\tcopy(curves[0:6], quad[0:6])\r\n\ti := 0\r\n\t\r\n\tvar c []float64\r\n\tvar dx, dy, d float64\r\n\tfor i >= 0 {\r\n\t\tc = curves[i:]\r\n\t\tdx = c[4] - c[0]\r\n\t\tdy = c[5] - c[1]\r\n\t\td = math.Abs(((c[2]-c[4])*dy - (c[3]-c[5])*dx))\r\n\t\t\r\n\t\tif (d*d) <= flatteningThreshold*(dx*dx+dy*dy) || i == len(curves)-6 {\r\n\t\t\tt.LineTo(c[4], c[5])\r\n\t\t\ti -= 6\r\n\t\t} else {\r\n\t\t\t\r\n\t\t\tSubdivideQuad(c, curves[i+6:], curves[i:])\r\n\t\t\ti += 6\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":326,"reference":"\/\/ TraceQuad generate lines subdividing the curve using a Liner\n\/\/ flattening_threshold helps determines the flattening expectation of the curve","result":"Trace the quads.","score":[0.0014,0.0546]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cs *ContextStack) GetFontName() string {\r\n\tfontData := cs.FontData\r\n\treturn fmt.Sprintf(\"%s:%d:%d:%9.2f\", fontData.Name, fontData.Family, fontData.Style, cs.FontSize)\r\n}","code-length":74,"reference":"\/\/ GetFontName gets the current FontData with fontSize as a string","result":"Generate the font name.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewStackGraphicContext() *StackGraphicContext {\r\n\tgc := &StackGraphicContext{}\r\n\tgc.Current = new(ContextStack)\r\n\tgc.Current.Tr = draw2d.NewIdentityMatrix()\r\n\tgc.Current.Path = new(draw2d.Path)\r\n\tgc.Current.LineWidth = 1.0\r\n\tgc.Current.StrokeColor = image.Black\r\n\tgc.Current.FillColor = image.White\r\n\tgc.Current.Cap = draw2d.RoundCap\r\n\tgc.Current.FillRule = draw2d.FillRuleEvenOdd\r\n\tgc.Current.Join = draw2d.RoundJoin\r\n\tgc.Current.FontSize = 10\r\n\tgc.Current.FontData = DefaultFontData\r\n\treturn gc\r\n}","code-length":195,"reference":"\/**\n * Create a new Graphic context from an image\n *\/","result":"Create a new stack graphic context.","score":[0.1728,0.3571]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFolderFontCache(folder string) *FolderFontCache {\r\n\treturn &FolderFontCache{\r\n\t\tfonts:  make(map[string]*truetype.Font),\r\n\t\tfolder: folder,\r\n\t\tnamer:  FontFileName,\r\n\t}\r\n}","code-length":77,"reference":"\/\/ NewFolderFontCache creates FolderFontCache","result":"Create a new folder font cache.","score":[0,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSyncFolderFontCache(folder string) *SyncFolderFontCache {\r\n\treturn &SyncFolderFontCache{\r\n\t\tfonts:  make(map[string]*truetype.Font),\r\n\t\tfolder: folder,\r\n\t\tnamer:  FontFileName,\r\n\t}\r\n}","code-length":80,"reference":"\/\/ NewSyncFolderFontCache creates SyncFolderFontCache","result":"Create a new folder font cache.","score":[0,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Main(gc draw2d.GraphicContext, ext string) (string, error) {\r\n\tgc.SetStrokeColor(image.Black)\r\n\tgc.SetFillColor(image.White)\r\n\tgc.Save()\r\n\t\r\n\tgc.Translate(-60, 65)\r\n\tgc.Rotate(-30 * (math.Pi \/ 180.0))\r\n\tDraw(gc, 48, 48, 240, 72)\r\n\tgc.Restore()\r\n\t\r\n\treturn samples.Output(\"gopher2\", ext), nil\r\n}","code-length":138,"reference":"\/\/ Main draws a rotated face of the gopher. Afterwards it returns\n\/\/ the filename. This should only be used during testing.","result":"Generate the code.","score":[0.0007,0.0249]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPdf(orientationStr, unitStr, sizeStr string) *gofpdf.Fpdf {\r\n\tpdf := gofpdf.New(orientationStr, unitStr, sizeStr, draw2d.GetFontFolder())\r\n\t\r\n\tpdf.SetMargins(0, 0, 0)\r\n\tpdf.SetDrawColor(0, 0, 0)\r\n\tpdf.SetFillColor(255, 255, 255)\r\n\tpdf.SetLineCapStyle(\"round\")\r\n\tpdf.SetLineJoinStyle(\"round\")\r\n\tpdf.SetLineWidth(1)\r\n\tpdf.AddPage()\r\n\treturn pdf\r\n}","code-length":157,"reference":"\/\/ NewPdf creates a new pdf document with the draw2d fontfolder, adds\n\/\/ a page and set fill color to white.","result":"Create a new pdf object.","score":[0.0202,0.1627]}
{"code":"\/*is used to<extra_id_0>\r\nfunc clearRect(gc *GraphicContext, x1, y1, x2, y2 float64) {\r\n\t\r\n\tf := gc.Current.FillColor\r\n\tx, y := gc.pdf.GetXY()\r\n\t\r\n\tgc.SetFillColor(white)\r\n\tdraw2dkit.Rectangle(gc, x1, y1, x2, y2)\r\n\tgc.Fill()\r\n\t\r\n\tgc.SetFillColor(f)\r\n\tgc.pdf.MoveTo(x, y)\r\n}","code-length":137,"reference":"\/\/ clearRect draws a white rectangle","result":"Clear the rectangle.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewGraphicContext(pdf *gofpdf.Fpdf) *GraphicContext {\r\n\tgc := &GraphicContext{draw2dbase.NewStackGraphicContext(), pdf, DPI}\r\n\tgc.SetDPI(DPI)\r\n\treturn gc\r\n}","code-length":71,"reference":"\/\/ NewGraphicContext creates a new pdf GraphicContext","result":"Create the graphic context.","score":[0,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gc *GraphicContext) Clear() {\r\n\twidth, height := gc.pdf.GetPageSize()\r\n\tclearRect(gc, 0, 0, width, height)\r\n}","code-length":52,"reference":"\/\/ Clear draws a white rectangle over the whole page","result":"Clear the graphics context.","score":[0.0848,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gc *GraphicContext) GetStringBounds(s string) (left, top, right, bottom float64) {\r\n\t_, h := gc.pdf.GetFontSize()\r\n\td := gc.pdf.GetFontDesc(\"\", \"\")\r\n\tif d.Ascent == 0 {\r\n\t\t\r\n\t\ttop = 0.81 * h\r\n\t} else {\r\n\t\ttop = -float64(d.Ascent) * h \/ float64(d.Ascent-d.Descent)\r\n\t}\r\n\treturn 0, top, gc.pdf.GetStringWidth(s), top + h\r\n}","code-length":154,"reference":"\/\/ GetStringBounds returns the approximate pixel bounds of the string s at x, y.\n\/\/ The left edge of the em square of the first character of s\n\/\/ and the baseline intersect at 0, 0 in the returned coordinates.\n\/\/ Therefore the top and left coordinates may well be negative.","result":"Get the string bounds of a string.","score":[0.0006,0.0429]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gc *GraphicContext) CreateStringPath(text string, x, y float64) (cursor float64) {\r\n\t\r\n\tleft, top, right, bottom := gc.GetStringBounds(text)\r\n\tw := right - left\r\n\th := bottom - top\r\n\t\r\n\tmargin := gc.pdf.GetCellMargin()\r\n\tgc.pdf.MoveTo(x-left-margin, y+top)\r\n\tgc.pdf.CellFormat(w, h, text, \"\", 0, \"BL\", false, 0, \"\")\r\n\treturn w\r\n}","code-length":145,"reference":"\/\/ CreateStringPath creates a path from the string s at x, y, and returns the string width.","result":"Create a string path.","score":[0.0147,0.1628]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gc *GraphicContext) FillStringAt(text string, x, y float64) (cursor float64) {\r\n\treturn gc.CreateStringPath(text, x, y)\r\n}","code-length":54,"reference":"\/\/ FillStringAt draws a string at x, y","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gc *GraphicContext) SetStrokeColor(c color.Color) {\r\n\tgc.StackGraphicContext.SetStrokeColor(c)\r\n\tgc.pdf.SetDrawColor(rgb(c))\r\n}","code-length":59,"reference":"\/\/ overwrite StackGraphicContext methods\n\/\/ SetStrokeColor sets the stroke color","result":"Set the stroke color of the graphics context.","score":[0.2228,0.3221]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gc *GraphicContext) SetFillColor(c color.Color) {\r\n\tgc.StackGraphicContext.SetFillColor(c)\r\n\tgc.pdf.SetFillColor(rgb(c))\r\n\tgc.pdf.SetTextColor(rgb(c))\r\n}","code-length":73,"reference":"\/\/ SetFillColor sets the fill and text color","result":"Set fill color in the graphics context.","score":[0.1843,0.2532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gc *GraphicContext) SetLineDash(Dash []float64, DashOffset float64) {\r\n\tgc.StackGraphicContext.SetLineDash(Dash, DashOffset)\r\n\tgc.pdf.SetDashPattern(Dash, DashOffset)\r\n}","code-length":71,"reference":"\/\/ SetLineDash sets the line dash pattern","result":"Set line dash in the stack.","score":[0.2558,0.4574]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gc *GraphicContext) SetLineWidth(LineWidth float64) {\r\n\tgc.StackGraphicContext.SetLineWidth(LineWidth)\r\n\tgc.pdf.SetLineWidth(LineWidth)\r\n}","code-length":59,"reference":"\/\/ SetLineWidth sets the line width","result":"Set the line width of the graphics context.","score":[0.2861,0.5091]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Main(gc draw2d.GraphicContext, ext string) (string, error) {\r\n\t\r\n\tDraw(gc, fmt.Sprintf(\"Hello World %d dpi\", gc.GetDPI()))\r\n\t\r\n\treturn samples.Output(\"helloworld\", ext), nil\r\n}","code-length":78,"reference":"\/\/ Main draws \"Hello World\" and returns the filename. This should only be\n\/\/ used during testing.","result":"Generate the main function.","score":[0.0124,0.0637]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Draw(gc draw2d.GraphicContext, text string) {\r\n\t\r\n\tdraw2dkit.RoundedRectangle(gc, 5, 5, 135, 95, 10, 10)\r\n\tgc.FillStroke()\r\n\t\r\n\tgc.SetFontData(draw2d.FontData{Name: \"luxi\", Family: draw2d.FontFamilyMono, Style: draw2d.FontStyleBold | draw2d.FontStyleItalic})\r\n\t\r\n\tgc.SetFillColor(image.Black)\r\n\tgc.SetFontSize(14)\r\n\t\r\n\tgc.FillStringAt(\"Hello World\", 8, 52)\r\n}","code-length":167,"reference":"\/\/ Draw \"Hello World\"","result":"Draw a text.","score":[0.2925,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SaveToPngFile(filePath string, m image.Image) error {\r\n\t\r\n\tf, err := os.Create(filePath)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer f.Close()\r\n\t\r\n\tb := bufio.NewWriter(f)\r\n\t\r\n\terr = png.Encode(b, m)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = b.Flush()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":152,"reference":"\/\/ SaveToPngFile create and save an image to a file using PNG format","result":"Save image to png file.","score":[0.0686,0.2587]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadFromPngFile(filePath string) (image.Image, error) {\r\n\t\r\n\tf, err := os.OpenFile(filePath, 0, 0)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer f.Close()\r\n\tb := bufio.NewReader(f)\r\n\timg, err := png.Decode(b)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn img, nil\r\n}","code-length":131,"reference":"\/\/ LoadFromPngFile Open a png file","result":"Load image from png file.","score":[0.1967,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Resource(folder, filename, ext string) string {\r\n\tvar root string\r\n\tif ext == \"pdf\" || ext == \"svg\" {\r\n\t\troot = \"..\/\"\r\n\t}\r\n\treturn fmt.Sprintf(\"%sresource\/%s\/%s\", root, folder, filename)\r\n}","code-length":81,"reference":"\/\/ Resource returns a resource filename for testing.","result":"Generate the resource .","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Output(name, ext string) string {\r\n\tvar root string\r\n\tif ext == \"pdf\" || ext == \"svg\" {\r\n\t\troot = \"..\/\"\r\n\t}\r\n\treturn fmt.Sprintf(\"%soutput\/samples\/%s.%s\", root, name, ext)\r\n}","code-length":81,"reference":"\/\/ Output returns the output filename for testing.","result":"Generate the output.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Main(gc draw2d.GraphicContext, ext string) (string, error) {\r\n\tgc.Save()\r\n\t\r\n\tgc.Translate(0, 200)\r\n\tgc.Scale(0.35, -0.35)\r\n\tgc.Translate(70, -200)\r\n\t\r\n\ttiger := samples.Resource(\"image\", \"tiger.ps\", ext)\r\n\t\r\n\tDraw(gc, tiger)\r\n\tgc.Restore()\r\n\t\r\n\treturn samples.Output(\"postscript\", ext), nil\r\n}","code-length":144,"reference":"\/\/ Main draws the tiger","result":"Generate the main function.","score":[0.2488,0.2041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Draw(gc draw2d.GraphicContext, filename string) {\r\n\t\r\n\tsrc, err := os.OpenFile(filename, 0, 0)\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tdefer src.Close()\r\n\tbytes, err := ioutil.ReadAll(src)\r\n\treader := strings.NewReader(string(bytes))\r\n\t\r\n\tinterpreter := ps.NewInterpreter(gc)\r\n\tinterpreter.Execute(reader)\r\n}","code-length":131,"reference":"\/\/ Draw a tiger","result":"Draw a file.","score":[0.4137,0.4808]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Main(gc draw2d.GraphicContext, ext string) (string, error) {\r\n\t\r\n\tDraw(gc, 297, 210)\r\n\t\r\n\treturn samples.Output(\"geometry\", ext), nil\r\n}","code-length":64,"reference":"\/\/ Main draws geometry and returns the filename. This should only be\n\/\/ used during testing.","result":"Draw the main function.","score":[0.0159,0.1014]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Bubble(gc draw2d.GraphicContext, x, y, width, height float64) {\r\n\tsx, sy := width\/100, height\/100\r\n\tgc.MoveTo(x+sx*50, y)\r\n\tgc.QuadCurveTo(x, y, x, y+sy*37.5)\r\n\tgc.QuadCurveTo(x, y+sy*75, x+sx*25, y+sy*75)\r\n\tgc.QuadCurveTo(x+sx*25, y+sy*95, x+sx*5, y+sy*100)\r\n\tgc.QuadCurveTo(x+sx*35, y+sy*95, x+sx*40, y+sy*75)\r\n\tgc.QuadCurveTo(x+sx*100, y+sy*75, x+sx*100, y+sy*37.5)\r\n\tgc.QuadCurveTo(x+sx*100, y, x+sx*50, y)\r\n\tgc.Stroke()\r\n}","code-length":250,"reference":"\/\/ Bubble draws a text balloon.","result":"Draw a bubble.","score":[0.1502,0.3289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Dash(gc draw2d.GraphicContext, x, y, width, height float64) {\r\n\tsx, sy := width\/162, height\/205\r\n\tgc.SetStrokeColor(image.Black)\r\n\tgc.SetLineDash([]float64{height \/ 10, height \/ 50, height \/ 50, height \/ 50}, -50.0)\r\n\tgc.SetLineCap(draw2d.ButtCap)\r\n\tgc.SetLineJoin(draw2d.RoundJoin)\r\n\tgc.SetLineWidth(height \/ 50)\r\n\tgc.MoveTo(x+sx*60.0, y)\r\n\tgc.LineTo(x+sx*60.0, y)\r\n\tgc.LineTo(x+sx*162, y+sy*205)\r\n\trLineTo(gc, sx*-102.4, 0)\r\n\tgc.CubicCurveTo(x+sx*-17, y+sy*205, x+sx*-17, y+sy*103, x+sx*60.0, y+sy*103.0)\r\n\tgc.Stroke()\r\n\tgc.SetLineDash(nil, 0.0)\r\n}","code-length":290,"reference":"\/\/ Dash draws a line with a dash pattern","result":"Draw a dashed image.","score":[0.0915,0.3007]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CubicCurve(gc draw2d.GraphicContext, x, y, width, height float64) {\r\n\tsx, sy := width\/162, height\/205\r\n\tx0, y0 := x, y+sy*100.0\r\n\tx1, y1 := x+sx*75, y+sy*205\r\n\tx2, y2 := x+sx*125, y\r\n\tx3, y3 := x+sx*205, y+sy*100\r\n\tgc.SetStrokeColor(image.Black)\r\n\tgc.SetFillColor(color.NRGBA{0xAA, 0xAA, 0xAA, 0xFF})\r\n\tgc.SetLineWidth(width \/ 10)\r\n\tgc.MoveTo(x0, y0)\r\n\tgc.CubicCurveTo(x1, y1, x2, y2, x3, y3)\r\n\tgc.Stroke()\r\n\tgc.SetStrokeColor(color.NRGBA{0xFF, 0x33, 0x33, 0x88})\r\n\tgc.SetLineWidth(width \/ 20)\r\n\t\r\n\tgc.MoveTo(x0, y0)\r\n\tgc.LineTo(x1, y1)\r\n\tgc.LineTo(x2, y2)\r\n\tgc.LineTo(x3, y3)\r\n\tgc.Stroke()\r\n}","code-length":336,"reference":"\/\/ CubicCurve draws a cubic curve with its control points.","result":"Draw a cubic curve.","score":[0.1008,0.3132]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FillStroke(gc draw2d.GraphicContext, x, y, width, height float64) {\r\n\tsx, sy := width\/210, height\/215\r\n\tgc.MoveTo(x+sx*113.0, y)\r\n\tgc.LineTo(x+sx*215.0, y+sy*215)\r\n\trLineTo(gc, sx*-100, 0)\r\n\tgc.CubicCurveTo(x+sx*35, y+sy*215, x+sx*35, y+sy*113, x+sx*113.0, y+sy*113)\r\n\tgc.Close()\r\n\tgc.MoveTo(x+sx*50.0, y)\r\n\trLineTo(gc, sx*51.2, sy*51.2)\r\n\trLineTo(gc, sx*-51.2, sy*51.2)\r\n\trLineTo(gc, sx*-51.2, sy*-51.2)\r\n\tgc.Close()\r\n\tgc.SetLineWidth(width \/ 20.0)\r\n\tgc.SetFillColor(color.NRGBA{0, 0, 0xFF, 0xFF})\r\n\tgc.SetStrokeColor(image.Black)\r\n\tgc.FillStroke()\r\n}","code-length":316,"reference":"\/\/ FillStroke first fills and afterwards strokes a path.","result":"Draw a filled.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FillStyle(gc draw2d.GraphicContext, x, y, width, height float64) {\r\n\tsx, sy := width\/232, height\/220\r\n\tgc.SetLineWidth(width \/ 40)\r\n\tdraw2dkit.Rectangle(gc, x+sx*0, y+sy*12, x+sx*232, y+sy*70)\r\n\tvar wheel1, wheel2 draw2d.Path\r\n\twheel1.ArcTo(x+sx*52, y+sy*70, sx*40, sy*40, 0, 2*math.Pi)\r\n\twheel2.ArcTo(x+sx*180, y+sy*70, sx*40, sy*40, 0, -2*math.Pi)\r\n\tgc.SetFillRule(draw2d.FillRuleEvenOdd)\r\n\tgc.SetFillColor(color.NRGBA{0, 0xB2, 0, 0xFF})\r\n\tgc.SetStrokeColor(image.Black)\r\n\tgc.FillStroke(&wheel1, &wheel2)\r\n\tdraw2dkit.Rectangle(gc, x, y+sy*140, x+sx*232, y+sy*198)\r\n\twheel1.Clear()\r\n\twheel1.ArcTo(x+sx*52, y+sy*198, sx*40, sy*40, 0, 2*math.Pi)\r\n\twheel2.Clear()\r\n\twheel2.ArcTo(x+sx*180, y+sy*198, sx*40, sy*40, 0, -2*math.Pi)\r\n\tgc.SetFillRule(draw2d.FillRuleWinding)\r\n\tgc.SetFillColor(color.NRGBA{0, 0, 0xE5, 0xFF})\r\n\tgc.FillStroke(&wheel1, &wheel2)\r\n}","code-length":446,"reference":"\/\/ FillStyle demonstrates the difference between even odd and non zero winding rule.","result":"Draw the background.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PathTransform(gc draw2d.GraphicContext, x, y, width, height float64) {\r\n\tgc.Save()\r\n\tgc.SetLineWidth(width \/ 10)\r\n\tgc.Translate(x+width\/2, y+height\/2)\r\n\tgc.Scale(1, 4)\r\n\tgc.ArcTo(0, 0, width\/8, height\/8, 0, math.Pi*2)\r\n\tgc.Close()\r\n\tgc.Stroke()\r\n\tgc.Restore()\r\n}","code-length":134,"reference":"\/\/ PathTransform scales a path differently in horizontal and vertical direction.","result":"Draw a path transform.","score":[0.0785,0.182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Star(gc draw2d.GraphicContext, x, y, width, height float64) {\r\n\tgc.Save()\r\n\tgc.Translate(x+width\/2, y+height\/2)\r\n\tgc.SetLineWidth(width \/ 40)\r\n\tfor i := 0.0; i < 360; i = i + 10 {\r\n\t\tgc.Save()\r\n\t\tgc.Rotate(i * (math.Pi \/ 180.0))\r\n\t\tgc.MoveTo(0, 0)\r\n\t\tgc.LineTo(width\/2, 0)\r\n\t\tgc.Stroke()\r\n\t\tgc.Restore()\r\n\t}\r\n\tgc.Restore()\r\n}","code-length":176,"reference":"\/\/ Star draws many lines from a center.","result":"Draw a circle.","score":[0.0771,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Draw(gc draw2d.GraphicContext, width, height float64) {\r\n\tmx, my := width*0.025, height*0.025\r\n\tdx, dy := (width-2*mx)\/4, (height-2*my)\/3\r\n\tw, h := dx-2*mx, dy-2*my\r\n\tx0, y := 2*mx, 2*my\r\n\tx := x0\r\n\tBubble(gc, x, y, w, h)\r\n\tx += dx\r\n\tCurveRectangle(gc, x, y, w, h, color.NRGBA{0x80, 0, 0, 0x80}, color.NRGBA{0x80, 0x80, 0xFF, 0xFF})\r\n\tx += dx\r\n\tDash(gc, x, y, w, h)\r\n\tx += dx\r\n\tArc(gc, x, y, w, h)\r\n\tx = x0\r\n\ty += dy\r\n\tArcNegative(gc, x, y, w, h)\r\n\tx += dx\r\n\tCubicCurve(gc, x, y, w, h)\r\n\tx += dx\r\n\tFillString(gc, x, y, w, h)\r\n\tx += dx\r\n\tFillStroke(gc, x, y, w, h)\r\n\tx = x0\r\n\ty += dy\r\n\tFillStyle(gc, x, y, w, h)\r\n\tx += dx\r\n\tPathTransform(gc, x, y, w, h)\r\n\tx += dx\r\n\tStar(gc, x, y, w, h)\r\n\tx += dx\r\n\tgopher2.Draw(gc, x, y, w, h\/2)\r\n}","code-length":426,"reference":"\/\/ Draw all figures in a nice 4x3 grid.","result":"Draw the image.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ConvertPath(path *draw2d.Path, pdf Vectorizer) {\r\n\tvar startX, startY float64 = 0, 0\r\n\ti := 0\r\n\tfor _, cmp := range path.Components {\r\n\t\tswitch cmp {\r\n\t\tcase draw2d.MoveToCmp:\r\n\t\t\tstartX, startY = path.Points[i], path.Points[i+1]\r\n\t\t\tpdf.MoveTo(startX, startY)\r\n\t\t\ti += 2\r\n\t\tcase draw2d.LineToCmp:\r\n\t\t\tpdf.LineTo(path.Points[i], path.Points[i+1])\r\n\t\t\ti += 2\r\n\t\tcase draw2d.QuadCurveToCmp:\r\n\t\t\tpdf.CurveTo(path.Points[i], path.Points[i+1], path.Points[i+2], path.Points[i+3])\r\n\t\t\ti += 4\r\n\t\tcase draw2d.CubicCurveToCmp:\r\n\t\t\tpdf.CurveBezierCubicTo(path.Points[i], path.Points[i+1], path.Points[i+2], path.Points[i+3], path.Points[i+4], path.Points[i+5])\r\n\t\t\ti += 6\r\n\t\tcase draw2d.ArcToCmp:\r\n\t\t\tpdf.ArcTo(path.Points[i], path.Points[i+1], path.Points[i+2], path.Points[i+3],\r\n\t\t\t\t0,\r\n\t\t\t\tpath.Points[i+4]*deg,\r\n\t\t\t\t(path.Points[i+4]-path.Points[i+5])*deg)\r\n\t\t\ti += 6\r\n\t\tcase draw2d.CloseCmp:\r\n\t\t\tpdf.LineTo(startX, startY)\r\n\t\t\tpdf.ClosePath()\r\n\t\t}\r\n\t}\r\n}","code-length":462,"reference":"\/\/ ConvertPath converts a paths to the pdf api","result":"Convert a path to a PDF.","score":[0.1392,0.3628]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Main(gc draw2d.GraphicContext, ext string) (string, error) {\r\n\t\r\n\tconst offset = 75.0\r\n\tx := 35.0\r\n\tcaps := []draw2d.LineCap{draw2d.ButtCap, draw2d.SquareCap, draw2d.RoundCap}\r\n\tjoins := []draw2d.LineJoin{draw2d.BevelJoin, draw2d.MiterJoin, draw2d.RoundJoin}\r\n\tfor i := range caps {\r\n\t\tDraw(gc, caps[i], joins[i], x, 50, x, 160, offset)\r\n\t\tx += offset\r\n\t}\r\n\t\r\n\treturn samples.Output(\"linecapjoin\", ext), nil\r\n}","code-length":188,"reference":"\/\/ Main draws the different line caps and joins.\n\/\/ This should only be used during testing.","result":"Generate the main code.","score":[0.0124,0.0637]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Draw(gc draw2d.GraphicContext, cap draw2d.LineCap, join draw2d.LineJoin,\r\n\tx0, y0, x1, y1, offset float64) {\r\n\tgc.SetLineCap(cap)\r\n\tgc.SetLineJoin(join)\r\n\t\r\n\tgc.SetStrokeColor(color.NRGBA{0x33, 0x33, 0x33, 0xFF})\r\n\tgc.SetLineWidth(30.0)\r\n\tgc.MoveTo(x0, y0)\r\n\tgc.LineTo((x0+x1)\/2+offset, (y0+y1)\/2)\r\n\tgc.LineTo(x1, y1)\r\n\tgc.Stroke()\r\n\t\r\n\tgc.SetStrokeColor(color.NRGBA{0xFF, 0x33, 0x33, 0xFF})\r\n\tgc.SetLineWidth(2.56)\r\n\tgc.MoveTo(x0, y0)\r\n\tgc.LineTo((x0+x1)\/2+offset, (y0+y1)\/2)\r\n\tgc.LineTo(x1, y1)\r\n\tgc.Stroke()\r\n}","code-length":294,"reference":"\/\/ Draw a line with an angle with specified line cap and join","result":"Draw the line.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DrawContour(path draw2d.PathBuilder, ps []truetype.Point, dx, dy float64) {\r\n\tif len(ps) == 0 {\r\n\t\treturn\r\n\t}\r\n\tstartX, startY := pointToF64Point(ps[0])\r\n\tpath.MoveTo(startX+dx, startY+dy)\r\n\tq0X, q0Y, on0 := startX, startY, true\r\n\tfor _, p := range ps[1:] {\r\n\t\tqX, qY := pointToF64Point(p)\r\n\t\ton := p.Flags&0x01 != 0\r\n\t\tif on {\r\n\t\t\tif on0 {\r\n\t\t\t\tpath.LineTo(qX+dx, qY+dy)\r\n\t\t\t} else {\r\n\t\t\t\tpath.QuadCurveTo(q0X+dx, q0Y+dy, qX+dx, qY+dy)\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\tif on0 {\r\n\t\t\t\t\r\n\t\t\t} else {\r\n\t\t\t\tmidX := (q0X + qX) \/ 2\r\n\t\t\t\tmidY := (q0Y + qY) \/ 2\r\n\t\t\t\tpath.QuadCurveTo(q0X+dx, q0Y+dy, midX+dx, midY+dy)\r\n\t\t\t}\r\n\t\t}\r\n\t\tq0X, q0Y, on0 = qX, qY, on\r\n\t}\r\n\t\r\n\tif on0 {\r\n\t\tpath.LineTo(startX+dx, startY+dy)\r\n\t} else {\r\n\t\tpath.QuadCurveTo(q0X+dx, q0Y+dy, startX+dx, startY+dy)\r\n\t}\r\n}","code-length":441,"reference":"\/\/ DrawContour draws the given closed contour at the given sub-pixel offset.","result":"Draw a contour.","score":[0,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Flatten(path *draw2d.Path, flattener Flattener, scale float64) {\r\n\t\r\n\tvar startX, startY float64 = 0, 0\r\n\t\r\n\tvar x, y float64 = 0, 0\r\n\ti := 0\r\n\tfor _, cmp := range path.Components {\r\n\t\tswitch cmp {\r\n\t\tcase draw2d.MoveToCmp:\r\n\t\t\tx, y = path.Points[i], path.Points[i+1]\r\n\t\t\tstartX, startY = x, y\r\n\t\t\tif i != 0 {\r\n\t\t\t\tflattener.End()\r\n\t\t\t}\r\n\t\t\tflattener.MoveTo(x, y)\r\n\t\t\ti += 2\r\n\t\tcase draw2d.LineToCmp:\r\n\t\t\tx, y = path.Points[i], path.Points[i+1]\r\n\t\t\tflattener.LineTo(x, y)\r\n\t\t\tflattener.LineJoin()\r\n\t\t\ti += 2\r\n\t\tcase draw2d.QuadCurveToCmp:\r\n\t\t\tTraceQuad(flattener, path.Points[i-2:], 0.5)\r\n\t\t\tx, y = path.Points[i+2], path.Points[i+3]\r\n\t\t\tflattener.LineTo(x, y)\r\n\t\t\ti += 4\r\n\t\tcase draw2d.CubicCurveToCmp:\r\n\t\t\tTraceCubic(flattener, path.Points[i-2:], 0.5)\r\n\t\t\tx, y = path.Points[i+4], path.Points[i+5]\r\n\t\t\tflattener.LineTo(x, y)\r\n\t\t\ti += 6\r\n\t\tcase draw2d.ArcToCmp:\r\n\t\t\tx, y = TraceArc(flattener, path.Points[i], path.Points[i+1], path.Points[i+2], path.Points[i+3], path.Points[i+4], path.Points[i+5], scale)\r\n\t\t\tflattener.LineTo(x, y)\r\n\t\t\ti += 6\r\n\t\tcase draw2d.CloseCmp:\r\n\t\t\tflattener.LineTo(startX, startY)\r\n\t\t\tflattener.Close()\r\n\t\t}\r\n\t}\r\n\tflattener.End()\r\n}","code-length":582,"reference":"\/\/ Flatten convert curves into straight segments keeping join segments info","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gc *GraphicContext) Clear() {\r\n\twidth, height := gc.img.Bounds().Dx(), gc.img.Bounds().Dy()\r\n\tgc.ClearRect(0, 0, width, height)\r\n}","code-length":63,"reference":"\/\/ Clear fills the current canvas with a default transparent color","result":"Clear the graphic context.","score":[0.066,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gc *GraphicContext) ClearRect(x1, y1, x2, y2 int) {\r\n\timageColor := image.NewUniform(gc.Current.FillColor)\r\n\tdraw.Draw(gc.img, image.Rect(x1, y1, x2, y2), imageColor, image.ZP, draw.Over)\r\n}","code-length":93,"reference":"\/\/ ClearRect fills the current canvas with a default transparent color at the specified rectangle","result":"Clear the current graphics context.","score":[0.046,0.0714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DrawImage(src image.Image, dest draw.Image, tr draw2d.Matrix, op draw.Op, filter ImageFilter) {\r\n\tvar transformer draw.Transformer\r\n\tswitch filter {\r\n\tcase LinearFilter:\r\n\t\ttransformer = draw.NearestNeighbor\r\n\tcase BilinearFilter:\r\n\t\ttransformer = draw.BiLinear\r\n\tcase BicubicFilter:\r\n\t\ttransformer = draw.CatmullRom\r\n\t}\r\n\ttransformer.Transform(dest, f64.Aff3{tr[0], tr[1], tr[4], tr[2], tr[3], tr[5]}, src, src.Bounds(), op, nil)\r\n}","code-length":169,"reference":"\/\/ DrawImage draws an image into dest using an affine transformation matrix, an op and a filter","result":"Filter ImageFilter.","score":[0,0.0323]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Main(gc draw2d.GraphicContext, ext string) (string, error) {\r\n\t\r\n\tconst margin = 30\r\n\t\r\n\tconst lineWidth = 3\r\n\t\r\n\tgopher := samples.Resource(\"image\", \"gopher.png\", ext)\r\n\t\r\n\terr := Draw(gc, gopher, 297, 210, margin, lineWidth)\r\n\t\r\n\treturn samples.Output(\"frameimage\", ext), err\r\n}","code-length":119,"reference":"\/\/ Main draws the image frame and returns the filename.\n\/\/ This should only be used during testing.","result":"Generate the main function.","score":[0.0096,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Draw(gc draw2d.GraphicContext, png string,\r\n\tdw, dh, margin, lineWidth float64) error {\r\n\t\r\n\tdraw2dkit.RoundedRectangle(gc, lineWidth, lineWidth, dw-lineWidth, dh-lineWidth, 100, 100)\r\n\tgc.SetLineWidth(lineWidth)\r\n\tgc.FillStroke()\r\n\t\r\n\tsource, err := draw2dimg.LoadFromPngFile(png)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tsw, sh := float64(source.Bounds().Dx()), float64(source.Bounds().Dy())\r\n\t\r\n\t\r\n\tscale := math.Min((dw-margin*2)\/sw, (dh-margin*2)\/sh)\r\n\tgc.Save()\r\n\tgc.Translate((dw-sw*scale)\/2, (dh-sh*scale)\/2)\r\n\tgc.Scale(scale, scale)\r\n\tgc.Rotate(0.2)\r\n\tgc.DrawImage(source)\r\n\tgc.Restore()\r\n\treturn nil\r\n}","code-length":275,"reference":"\/\/ Draw the image frame with certain parameters.","result":"Draw the image.","score":[0.109,0.25]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Draw(gc draw2d.GraphicContext, x, y float64) {\r\n\t\r\n\tgc.SetFillColor(color.RGBA{0x44, 0xff, 0x44, 0xff})\r\n\tgc.SetStrokeColor(color.RGBA{0x44, 0x44, 0x44, 0xff})\r\n\t\r\n\tgc.SetLineCap(draw2d.RoundCap)\r\n\tgc.SetLineWidth(5)\r\n\t\r\n\tgc.MoveTo(x+30, y+70)\r\n\tgc.ArcTo(x+80, y+70, 50, 50, 180*(math.Pi\/180), 180*(math.Pi\/180))\r\n\tgc.Close()\r\n\tgc.FillStroke()\r\n\tgc.MoveTo(x+60, y+25)\r\n\tgc.LineTo(x+50, y+10)\r\n\tgc.MoveTo(x+100, y+25)\r\n\tgc.LineTo(x+110, y+10)\r\n\tgc.Stroke()\r\n\t\r\n\tdraw2dkit.Circle(gc, x+60, y+45, 5)\r\n\tgc.FillStroke()\r\n\t\r\n\tdraw2dkit.Circle(gc, x+100, y+45, 5)\r\n\tgc.FillStroke()\r\n\t\r\n\tdraw2dkit.RoundedRectangle(gc, x+30, y+75, x+30+100, y+75+90, 10, 10)\r\n\tgc.FillStroke()\r\n\tdraw2dkit.Rectangle(gc, x+30, y+75, x+30+100, y+75+80)\r\n\tgc.FillStroke()\r\n\t\r\n\tdraw2dkit.RoundedRectangle(gc, x+5, y+80, x+5+20, y+80+70, 10, 10)\r\n\tgc.FillStroke()\r\n\t\r\n\tdraw2dkit.RoundedRectangle(gc, x+135, y+80, x+135+20, y+80+70, 10, 10)\r\n\tgc.FillStroke()\r\n\t\r\n\tdraw2dkit.RoundedRectangle(gc, x+50, y+150, x+50+20, y+150+50, 10, 10)\r\n\tgc.FillStroke()\r\n\t\r\n\tdraw2dkit.RoundedRectangle(gc, x+90, y+150, x+90+20, y+150+50, 10, 10)\r\n\tgc.FillStroke()\r\n}","code-length":610,"reference":"\/\/ Draw the droid on a certain position.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ChecksumString32S(s string, seed uint32) uint32 {\r\n\tif len(s) == 0 {\r\n\t\treturn Checksum32S(nil, seed)\r\n\t}\r\n\tss := (*reflect.StringHeader)(unsafe.Pointer(&s))\r\n\treturn Checksum32S((*[maxInt32]byte)(unsafe.Pointer(ss.Data))[:len(s):len(s)], seed)\r\n}","code-length":113,"reference":"\/\/ ChecksumString32S returns the checksum of the input data, without creating a copy, with the specific seed.","result":"Calculate the checksum.","score":[0.0038,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ChecksumString64S(s string, seed uint64) uint64 {\r\n\tif len(s) == 0 {\r\n\t\treturn Checksum64S(nil, seed)\r\n\t}\r\n\tss := (*reflect.StringHeader)(unsafe.Pointer(&s))\r\n\treturn Checksum64S((*[maxInt32]byte)(unsafe.Pointer(ss.Data))[:len(s):len(s)], seed)\r\n}","code-length":113,"reference":"\/\/ ChecksumString64S returns the checksum of the input data, without creating a copy, with the specific seed.","result":"Calculate the checksum.","score":[0.0038,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewS32(seed uint32) (xx *XXHash32) {\r\n\txx = &XXHash32{\r\n\t\tseed: seed,\r\n\t}\r\n\txx.Reset()\r\n\treturn\r\n}","code-length":62,"reference":"\/\/ NewS32 creates a new hash.Hash32 computing the 32bit xxHash checksum starting with the specific seed.","result":"Generate a new hash.","score":[0.0225,0.1267]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewS64(seed uint64) (xx *XXHash64) {\r\n\txx = &XXHash64{\r\n\t\tseed: seed,\r\n\t}\r\n\txx.Reset()\r\n\treturn\r\n}","code-length":62,"reference":"\/\/ NewS64 creates a new hash.Hash64 computing the 64bit xxHash checksum starting with the specific seed.","result":"Generate the hash function.","score":[0.0159,0.0338]}
{"code":"\/*is used to<extra_id_0>\r\nfunc round64(h, v uint64) uint64 {\r\n\th += v * prime64x2\r\n\th = rotl64_31(h)\r\n\th *= prime64x1\r\n\treturn h\r\n}","code-length":63,"reference":"\/\/ borrowed from cespare","result":"Round up the number.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Checksum32S(in []byte, seed uint32) (h uint32) {\r\n\tvar i int\r\n\tif len(in) > 15 {\r\n\t\tvar (\r\n\t\t\tv1 = seed + prime32x1 + prime32x2\r\n\t\t\tv2 = seed + prime32x2\r\n\t\t\tv3 = seed + 0\r\n\t\t\tv4 = seed - prime32x1\r\n\t\t)\r\n\t\tfor ; i < len(in)-15; i += 16 {\r\n\t\t\tin := in[i : i+16 : len(in)]\r\n\t\t\tv1 += u32(in[0:4:len(in)]) * prime32x2\r\n\t\t\tv1 = rotl32_13(v1) * prime32x1\r\n\t\t\tv2 += u32(in[4:8:len(in)]) * prime32x2\r\n\t\t\tv2 = rotl32_13(v2) * prime32x1\r\n\t\t\tv3 += u32(in[8:12:len(in)]) * prime32x2\r\n\t\t\tv3 = rotl32_13(v3) * prime32x1\r\n\t\t\tv4 += u32(in[12:16:len(in)]) * prime32x2\r\n\t\t\tv4 = rotl32_13(v4) * prime32x1\r\n\t\t}\r\n\t\th = rotl32_1(v1) + rotl32_7(v2) + rotl32_12(v3) + rotl32_18(v4)\r\n\t} else {\r\n\t\th = seed + prime32x5\r\n\t}\r\n\th += uint32(len(in))\r\n\tfor ; i <= len(in)-4; i += 4 {\r\n\t\tin := in[i : i+4 : len(in)]\r\n\t\th += u32(in[0:4:len(in)]) * prime32x3\r\n\t\th = rotl32_17(h) * prime32x4\r\n\t}\r\n\tfor ; i < len(in); i++ {\r\n\t\th += uint32(in[i]) * prime32x5\r\n\t\th = rotl32_11(h) * prime32x1\r\n\t}\r\n\th ^= h >> 15\r\n\th *= prime32x2\r\n\th ^= h >> 13\r\n\th *= prime32x3\r\n\th ^= h >> 16\r\n\treturn\r\n}","code-length":605,"reference":"\/\/ Checksum32S returns the checksum of the input bytes with the specific seed.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Checksum64S(in []byte, seed uint64) uint64 {\r\n\tif len(in) == 0 && seed == 0 {\r\n\t\treturn 0xef46db3751d8e999\r\n\t}\r\n\tif len(in) > 31 {\r\n\t\treturn checksum64(in, seed)\r\n\t}\r\n\treturn checksum64Short(in, seed)\r\n}","code-length":102,"reference":"\/\/ Checksum64S returns the 64bit xxhash checksum for a single input","result":"Generate the checksum.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getStage() (stage int, advanceStage func() error, resetEnv func() error) {\r\n\tvar origValue string\r\n\tstage = 0\r\n\tdaemonStage := os.Getenv(stageVar)\r\n\tstageTag := strings.SplitN(daemonStage, \":\", 2)\r\n\tstageInfo := strings.SplitN(stageTag[0], \"\/\", 3)\r\n\tif len(stageInfo) == 3 {\r\n\t\tstageStr, tm, check := stageInfo[0], stageInfo[1], stageInfo[2]\r\n\t\thash := sha1.New()\r\n\t\thash.Write([]byte(stageStr + \"\/\" + tm + \"\/\"))\r\n\t\tif check != hex.EncodeToString(hash.Sum([]byte{})) {\r\n\t\t\t\r\n\t\t\torigValue = daemonStage\r\n\t\t} else {\r\n\t\t\tstage, _ = strconv.Atoi(stageStr)\r\n\t\t\tif len(stageTag) == 2 {\r\n\t\t\t\torigValue = stageTag[1]\r\n\t\t\t}\r\n\t\t}\r\n\t} else {\r\n\t\torigValue = daemonStage\r\n\t}\r\n\tadvanceStage = func() error {\r\n\t\tbase := fmt.Sprintf(\"%d\/%09d\/\", stage+1, time.Now().Nanosecond())\r\n\t\thash := sha1.New()\r\n\t\thash.Write([]byte(base))\r\n\t\ttag := base + hex.EncodeToString(hash.Sum([]byte{}))\r\n\t\tif err := os.Setenv(stageVar, tag+\":\"+origValue); err != nil {\r\n\t\t\treturn fmt.Errorf(\"can't set %s: %s\", stageVar, err)\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\tresetEnv = func() error {\r\n\t\treturn os.Setenv(stageVar, origValue)\r\n\t}\r\n\treturn stage, advanceStage, resetEnv\r\n}","code-length":467,"reference":"\/\/ Returns the current stage in the \"daemonization process\", that's kept in\n\/\/ an environment variable. The variable is instrumented with a digital\n\/\/ signature, to avoid misbehavior if it was present in the user's\n\/\/ environment. The original value is restored after the last stage, so that\n\/\/ there's no final effect on the environment the application receives.","result":"Get the current stage of the daemon.","score":[0.0002,0.0587]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New() *Glg {\r\n\tg := &Glg{\r\n\t\tlevelCounter: new(uint32),\r\n\t\tbuffer: sync.Pool{\r\n\t\t\tNew: func() interface{} {\r\n\t\t\t\treturn bytes.NewBuffer(make([]byte, 0, bufferSize))\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n\tatomic.StoreUint32(g.levelCounter, uint32(FATAL))\r\n\tfor lev, log := range map[LEVEL]*logger{\r\n\t\t\r\n\t\tPRINT: {\r\n\t\t\tstd:     os.Stdout,\r\n\t\t\tcolor:   Colorless,\r\n\t\t\tisColor: true,\r\n\t\t\tmode:    STD,\r\n\t\t},\r\n\t\tLOG: {\r\n\t\t\tstd:     os.Stdout,\r\n\t\t\tcolor:   Colorless,\r\n\t\t\tisColor: true,\r\n\t\t\tmode:    STD,\r\n\t\t},\r\n\t\tINFO: {\r\n\t\t\tstd:     os.Stdout,\r\n\t\t\tcolor:   Green,\r\n\t\t\tisColor: true,\r\n\t\t\tmode:    STD,\r\n\t\t},\r\n\t\tDEBG: {\r\n\t\t\tstd:     os.Stdout,\r\n\t\t\tcolor:   Purple,\r\n\t\t\tisColor: true,\r\n\t\t\tmode:    STD,\r\n\t\t},\r\n\t\tOK: {\r\n\t\t\tstd:     os.Stdout,\r\n\t\t\tcolor:   Cyan,\r\n\t\t\tisColor: true,\r\n\t\t\tmode:    STD,\r\n\t\t},\r\n\t\tWARN: {\r\n\t\t\tstd:     os.Stdout,\r\n\t\t\tcolor:   Orange,\r\n\t\t\tisColor: true,\r\n\t\t\tmode:    STD,\r\n\t\t},\r\n\t\t\r\n\t\tERR: {\r\n\t\t\tstd:     os.Stderr,\r\n\t\t\tcolor:   Red,\r\n\t\t\tisColor: true,\r\n\t\t\tmode:    STD,\r\n\t\t},\r\n\t\tFAIL: {\r\n\t\t\tstd:     os.Stderr,\r\n\t\t\tcolor:   Red,\r\n\t\t\tisColor: true,\r\n\t\t\tmode:    STD,\r\n\t\t},\r\n\t\tFATAL: {\r\n\t\t\tstd:     os.Stderr,\r\n\t\t\tcolor:   Red,\r\n\t\t\tisColor: true,\r\n\t\t\tmode:    STD,\r\n\t\t},\r\n\t} {\r\n\t\tlog.tag = lev.String()\r\n\t\tlog.updateMode()\r\n\t\tg.logger.Store(lev, log)\r\n\t}\r\n\treturn g\r\n}","code-length":649,"reference":"\/\/ New returns plain glg instance","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Get() *Glg {\r\n\tonce.Do(func() {\r\n\t\tfastime.SetFormat(timeFormat)\r\n\t\tglg = New()\r\n\t})\r\n\treturn glg\r\n}","code-length":61,"reference":"\/\/ Get returns singleton glg instance","result":"Get the glg.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Glg) SetMode(mode MODE) *Glg {\r\n\tg.logger.Range(func(key, val interface{}) bool {\r\n\t\tl := val.(*logger)\r\n\t\tl.mode = mode\r\n\t\tl.updateMode()\r\n\t\tg.logger.Store(key.(LEVEL), l)\r\n\t\treturn true\r\n\t})\r\n\treturn g\r\n}","code-length":109,"reference":"\/\/ SetMode sets glg logging mode","result":"Set the mode of the logger.","score":[0.193,0.1667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Glg) SetPrefix(pref string) *Glg {\r\n\tv, ok := g.logger.Load(PRINT)\r\n\tif ok {\r\n\t\tvalue := v.(*logger)\r\n\t\tvalue.tag = pref\r\n\t\tg.logger.Store(PRINT, value)\r\n\t}\r\n\treturn g\r\n}","code-length":93,"reference":"\/\/ SetPrefix set Print logger prefix","result":"Set the prefix of the logger.","score":[0.193,0.1667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Glg) GetCurrentMode(level LEVEL) MODE {\r\n\tl, ok := g.logger.Load(level)\r\n\tif ok {\r\n\t\treturn l.(*logger).mode\r\n\t}\r\n\treturn NONE\r\n}","code-length":69,"reference":"\/\/ GetCurrentMode returns current logging mode","result":"Get the current mode of the logger.","score":[0.1921,0.1639]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Glg) InitWriter() *Glg {\r\n\tg.logger.Range(func(key, val interface{}) bool {\r\n\t\tl := val.(*logger)\r\n\t\tl.writer = nil\r\n\t\tl.updateMode()\r\n\t\tg.logger.Store(key.(LEVEL), l)\r\n\t\treturn true\r\n\t})\r\n\treturn g\r\n}","code-length":106,"reference":"\/\/ InitWriter is initialize glg writer","result":"Initialize the writer.","score":[0,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Glg) SetWriter(writer io.Writer) *Glg {\r\n\tif writer == nil {\r\n\t\treturn g\r\n\t}\r\n\tg.logger.Range(func(key, val interface{}) bool {\r\n\t\tl := val.(*logger)\r\n\t\tl.writer = writer\r\n\t\tl.updateMode()\r\n\t\tg.logger.Store(key.(LEVEL), l)\r\n\t\treturn true\r\n\t})\r\n\treturn g\r\n}","code-length":129,"reference":"\/\/ SetWriter sets writer to glg std writers","result":"Set the logger writer.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Glg) SetLevelColor(level LEVEL, color func(string) string) *Glg {\r\n\tlev, ok := g.logger.Load(level)\r\n\tif ok {\r\n\t\tl := lev.(*logger)\r\n\t\tl.color = color\r\n\t\tg.logger.Store(level, l)\r\n\t}\r\n\treturn g\r\n}","code-length":102,"reference":"\/\/ SetLevelColor sets the color for each level","result":"Set the color of the level.","score":[0.1956,0.1923]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Glg) SetLevelWriter(level LEVEL, writer io.Writer) *Glg {\r\n\tif writer == nil {\r\n\t\treturn g\r\n\t}\r\n\tlev, ok := g.logger.Load(level)\r\n\tif ok {\r\n\t\tl := lev.(*logger)\r\n\t\tl.writer = writer\r\n\t\tl.updateMode()\r\n\t\tg.logger.Store(level, l)\r\n\t}\r\n\treturn g\r\n}","code-length":127,"reference":"\/\/ SetLevelWriter sets writer to glg std writer per logging level","result":"Set the level writer.","score":[0.0555,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Glg) AddStdLevel(tag string, mode MODE, isColor bool) *Glg {\r\n\tatomic.AddUint32(g.levelCounter, 1)\r\n\tlev := LEVEL(atomic.LoadUint32(g.levelCounter))\r\n\tg.levelMap.Store(tag, lev)\r\n\tl := &logger{\r\n\t\twriter:  nil,\r\n\t\tstd:     os.Stdout,\r\n\t\tcolor:   Colorless,\r\n\t\tisColor: isColor,\r\n\t\tmode:    mode,\r\n\t\ttag:     tag,\r\n\t}\r\n\tl.updateMode()\r\n\tg.logger.Store(lev, l)\r\n\treturn g\r\n}","code-length":183,"reference":"\/\/ AddStdLevel adds std log level and returns LEVEL","result":"Add a std level to the console.","score":[0.1443,0.1705]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Glg) EnableColor() *Glg {\r\n\tg.logger.Range(func(key, val interface{}) bool {\r\n\t\tl := val.(*logger)\r\n\t\tl.isColor = true\r\n\t\tl.updateMode()\r\n\t\tg.logger.Store(key.(LEVEL), l)\r\n\t\treturn true\r\n\t})\r\n\treturn g\r\n}","code-length":107,"reference":"\/\/ EnableColor enables color output","result":"Enable color.","score":[0,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Glg) EnableLevelColor(lv LEVEL) *Glg {\r\n\tins, ok := g.logger.Load(lv)\r\n\tif ok {\r\n\t\tl := ins.(*logger)\r\n\t\tl.isColor = true\r\n\t\tl.updateMode()\r\n\t\tg.logger.Store(lv, l)\r\n\t}\r\n\treturn g\r\n}","code-length":104,"reference":"\/\/ EnableLevelColor enables color output","result":"Enable level color.","score":[0,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Glg) DisableLevelColor(lv LEVEL) *Glg {\r\n\tins, ok := g.logger.Load(lv)\r\n\tif ok {\r\n\t\tl := ins.(*logger)\r\n\t\tl.isColor = false\r\n\t\tl.updateMode()\r\n\t\tg.logger.Store(lv, l)\r\n\t}\r\n\treturn g\r\n}","code-length":104,"reference":"\/\/ DisableLevelColor disables color output","result":"Disable level color.","score":[0,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Glg) RawString(data []byte) string {\r\n\tstr := *(*string)(unsafe.Pointer(&data))\r\n\treturn str[strings.Index(str, sep)+sepl : len(str)-rcl]\r\n}","code-length":69,"reference":"\/\/ RawString returns raw log string exclude time & tags","result":"Generate the raw string.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Glg) TagStringToLevel(tag string) LEVEL {\r\n\tl, ok := g.levelMap.Load(tag)\r\n\tif !ok {\r\n\t\treturn 255\r\n\t}\r\n\treturn l.(LEVEL)\r\n}","code-length":70,"reference":"\/\/ TagStringToLevel converts level string to Glg.LEVEL","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Println(val ...interface{}) error {\r\n\treturn glg.out(PRINT, blankFormat(len(val)), val...)\r\n}","code-length":43,"reference":"\/\/ Println outputs fixed line Print log","result":"Print to the console.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Glg) Fatal(val ...interface{}) {\r\n\terr := g.out(FATAL, blankFormat(len(val)), val...)\r\n\tif err != nil {\r\n\t\terr = g.Error(err.Error())\r\n\t\tif err != nil {\r\n\t\t\tpanic(err)\r\n\t\t}\r\n\t}\r\n\texit(1)\r\n}","code-length":104,"reference":"\/\/ Fatal outputs Failed log and exit program","result":"Print errors to the console.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Glg) Fatalf(format string, val ...interface{}) {\r\n\terr := g.out(FATAL, format, val...)\r\n\tif err != nil {\r\n\t\terr = g.Error(err.Error())\r\n\t\tif err != nil {\r\n\t\t\tpanic(err)\r\n\t\t}\r\n\t}\r\n\texit(1)\r\n}","code-length":101,"reference":"\/\/ Fatalf outputs formatted Failed log and exit program","result":"Print a message.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Glg) isModeEnable(l LEVEL) bool {\r\n\treturn g.GetCurrentMode(l) != NONE\r\n}","code-length":42,"reference":"\/\/ isModeEnable returns the level has already turned on the logging","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CaptureMetrics(hnd http.Handler, w http.ResponseWriter, r *http.Request) Metrics {\r\n\treturn CaptureMetricsFn(w, func(ww http.ResponseWriter) {\r\n\t\thnd.ServeHTTP(ww, r)\r\n\t})\r\n}","code-length":73,"reference":"\/\/ CaptureMetrics wraps the given hnd, executes it with the given w and r, and\n\/\/ returns the metrics it captured from it.","result":"Capture metrics.","score":[0,0.0239]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (da *cedar) get(key []byte, from, pos int) *int {\r\n\tfor ; pos < len(key); pos++ {\r\n\t\tif value := da.Array[from].Value; value >= 0 && value != ValueLimit {\r\n\t\t\tto := da.follow(from, 0)\r\n\t\t\tda.Array[to].Value = value\r\n\t\t}\r\n\t\tfrom = da.follow(from, key[pos])\r\n\t}\r\n\tto := from\r\n\tif da.Array[from].Value < 0 {\r\n\t\tto = da.follow(from, 0)\r\n\t}\r\n\treturn &da.Array[to].Value\r\n}","code-length":173,"reference":"\/\/ Get value by key, insert the key if not exist","result":"Get the value of a key in the cedar.","score":[0.138,0.1852]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (da *Cedar) Save(out io.Writer, dataType string) error {\r\n\tswitch dataType {\r\n\tcase \"gob\", \"GOB\":\r\n\t\tdataEecoder := gob.NewEncoder(out)\r\n\t\treturn dataEecoder.Encode(da.cedar)\r\n\tcase \"json\", \"JSON\":\r\n\t\tdataEecoder := json.NewEncoder(out)\r\n\t\treturn dataEecoder.Encode(da.cedar)\r\n\t}\r\n\treturn ErrInvalidDataType\r\n}","code-length":136,"reference":"\/\/ Save saves the cedar to an io.Writer,\n\/\/ where dataType is either \"json\" or \"gob\".","result":"Save the cedar.","score":[0.0064,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (da *Cedar) SaveToFile(fileName string, dataType string) error {\r\n\tfile, err := os.OpenFile(fileName, os.O_CREATE|os.O_WRONLY, 0666)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer file.Close()\r\n\tout := bufio.NewWriter(file)\r\n\tdefer out.Flush()\r\n\tda.Save(out, dataType)\r\n\treturn nil\r\n}","code-length":123,"reference":"\/\/ SaveToFile saves the cedar to a file,\n\/\/ where dataType is either \"json\" or \"gob\".","result":"Save the data to a file.","score":[0.0571,0.25]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (da *Cedar) Load(in io.Reader, dataType string) error {\r\n\tswitch dataType {\r\n\tcase \"gob\", \"GOB\":\r\n\t\tdataDecoder := gob.NewDecoder(in)\r\n\t\treturn dataDecoder.Decode(da.cedar)\r\n\tcase \"json\", \"JSON\":\r\n\t\tdataDecoder := json.NewDecoder(in)\r\n\t\treturn dataDecoder.Decode(da.cedar)\r\n\t}\r\n\treturn ErrInvalidDataType\r\n}","code-length":128,"reference":"\/\/ Load loads the cedar from an io.Writer,\n\/\/ where dataType is either \"json\" or \"gob\".","result":"Load the data.","score":[0.0064,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (da *Cedar) LoadFromFile(fileName string, dataType string) error {\r\n\tfile, err := os.OpenFile(fileName, os.O_RDONLY, 0600)\r\n\tdefer file.Close()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tin := bufio.NewReader(file)\r\n\treturn da.Load(in, dataType)\r\n}","code-length":105,"reference":"\/\/ LoadFromFile loads the cedar from a file,\n\/\/ where dataType is either \"json\" or \"gob\".","result":"Load data from file.","score":[0.0159,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (da *Cedar) Key(id int) (key []byte, err error) {\r\n\tfor id > 0 {\r\n\t\tfrom := da.Array[id].Check\r\n\t\tif from < 0 {\r\n\t\t\treturn nil, ErrNoPath\r\n\t\t}\r\n\t\tif char := byte(da.Array[from].base() ^ id); char != 0 {\r\n\t\t\tkey = append(key, char)\r\n\t\t}\r\n\t\tid = from\r\n\t}\r\n\tif id != 0 || len(key) == 0 {\r\n\t\treturn nil, ErrInvalidKey\r\n\t}\r\n\tfor i := 0; i < len(key)\/2; i++ {\r\n\t\tkey[i], key[len(key)-i-1] = key[len(key)-i-1], key[i]\r\n\t}\r\n\treturn key, nil\r\n}","code-length":221,"reference":"\/\/ Key returns the key of the node with the given `id`.\n\/\/ It will return ErrNoPath, if the node does not exist.","result":"Generate the key .","score":[0.0039,0.0474]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (da *Cedar) Value(id int) (value int, err error) {\r\n\tvalue = da.Array[id].Value\r\n\tif value >= 0 {\r\n\t\treturn value, nil\r\n\t}\r\n\tto := da.Array[id].base()\r\n\tif da.Array[to].Check == id && da.Array[to].Value >= 0 {\r\n\t\treturn da.Array[to].Value, nil\r\n\t}\r\n\treturn 0, ErrNoValue\r\n}","code-length":128,"reference":"\/\/ Value returns the value of the node with the given `id`.\n\/\/ It will return ErrNoValue, if the node does not have a value.","result":"Get the value of a value in the C.","score":[0.0482,0.1496]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (da *Cedar) Delete(key []byte) error {\r\n\t\r\n\tto, err := da.Jump(key, 0)\r\n\tif err != nil {\r\n\t\treturn ErrNoPath\r\n\t}\r\n\tif da.Array[to].Value < 0 {\r\n\t\tbase := da.Array[to].base()\r\n\t\tif da.Array[base].Check == to {\r\n\t\t\tto = base\r\n\t\t}\r\n\t}\r\n\tfor to > 0 {\r\n\t\tfrom := da.Array[to].Check\r\n\t\tbase := da.Array[from].base()\r\n\t\tlabel := byte(to ^ base)\r\n\t\t\r\n\t\tif da.Ninfos[to].Sibling != 0 || da.Ninfos[from].Child != label {\r\n\t\t\t\r\n\t\t\tda.popSibling(from, base, label)\r\n\t\t\t\r\n\t\t\tda.pushEnode(to)\r\n\t\t\tbreak\r\n\t\t}\r\n\t\t\r\n\t\tda.pushEnode(to)\r\n\t\t\r\n\t\tto = from\r\n\t}\r\n\treturn nil\r\n}","code-length":278,"reference":"\/\/ Delete removes a key-value pair from the cedar.\n\/\/ It will return ErrNoPath, if the key has not been added.","result":"Delete a key.","score":[0.0012,0.0521]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v *Version) Set(version string) error {\r\n\tmetadata := splitOff(&version, \"+\")\r\n\tpreRelease := PreRelease(splitOff(&version, \"-\"))\r\n\tdotParts := strings.SplitN(version, \".\", 3)\r\n\tif len(dotParts) != 3 {\r\n\t\treturn fmt.Errorf(\"%s is not in dotted-tri format\", version)\r\n\t}\r\n\tif err := validateIdentifier(string(preRelease)); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to validate pre-release: %v\", err)\r\n\t}\r\n\tif err := validateIdentifier(metadata); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to validate metadata: %v\", err)\r\n\t}\r\n\tparsed := make([]int64, 3, 3)\r\n\tfor i, v := range dotParts[:3] {\r\n\t\tval, err := strconv.ParseInt(v, 10, 64)\r\n\t\tparsed[i] = val\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tv.Metadata = metadata\r\n\tv.PreRelease = preRelease\r\n\tv.Major = parsed[0]\r\n\tv.Minor = parsed[1]\r\n\tv.Patch = parsed[2]\r\n\treturn nil\r\n}","code-length":328,"reference":"\/\/ Set parses and updates v from the given version string. Implements flag.Value","result":"Set the version in the package.","score":[0.0791,0.122]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v Version) Compare(versionB Version) int {\r\n\tif cmp := recursiveCompare(v.Slice(), versionB.Slice()); cmp != 0 {\r\n\t\treturn cmp\r\n\t}\r\n\treturn preReleaseCompare(v, versionB)\r\n}","code-length":70,"reference":"\/\/ Compare tests if v is less than, equal to, or greater than versionB,\n\/\/ returning -1, 0, or +1 respectively.","result":"Compare two versions.","score":[0.001,0.026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v Version) Slice() []int64 {\r\n\treturn []int64{v.Major, v.Minor, v.Patch}\r\n}","code-length":43,"reference":"\/\/ Slice converts the comparable parts of the semver into a slice of integers.","result":"Generate the version string.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v *Version) BumpMajor() {\r\n\tv.Major += 1\r\n\tv.Minor = 0\r\n\tv.Patch = 0\r\n\tv.PreRelease = PreRelease(\"\")\r\n\tv.Metadata = \"\"\r\n}","code-length":67,"reference":"\/\/ BumpMajor increments the Major field by 1 and resets all other fields to their default values","result":"Bump major version number.","score":[0,0.0318]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v *Version) BumpMinor() {\r\n\tv.Minor += 1\r\n\tv.Patch = 0\r\n\tv.PreRelease = PreRelease(\"\")\r\n\tv.Metadata = \"\"\r\n}","code-length":59,"reference":"\/\/ BumpMinor increments the Minor field by 1 and resets all other fields to their default values","result":"Bump the minor version number.","score":[0.0218,0.1187]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v *Version) BumpPatch() {\r\n\tv.Patch += 1\r\n\tv.PreRelease = PreRelease(\"\")\r\n\tv.Metadata = \"\"\r\n}","code-length":51,"reference":"\/\/ BumpPatch increments the Patch field by 1 and resets all other fields to their default values","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc validateIdentifier(id string) error {\r\n\tif id != \"\" && !reIdentifier.MatchString(id) {\r\n\t\treturn fmt.Errorf(\"%s is not a valid semver identifier\", id)\r\n\t}\r\n\treturn nil\r\n}","code-length":67,"reference":"\/\/ validateIdentifier makes sure the provided identifier satisfies semver spec","result":"Validate the identifier.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newStream(bufsize int, replay bool) *Stream {\r\n\treturn &Stream{\r\n\t\tAutoReplay:  replay,\r\n\t\tsubscribers: make([]*Subscriber, 0),\r\n\t\tregister:    make(chan *Subscriber),\r\n\t\tderegister:  make(chan *Subscriber),\r\n\t\tevent:       make(chan *Event, bufsize),\r\n\t\tquit:        make(chan bool),\r\n\t\tEventlog:    make(EventLog, 0),\r\n\t}\r\n}","code-length":132,"reference":"\/\/ newStream returns a new stream","result":"Create a new stream.","score":[0.274,0.3233]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (str *Stream) addSubscriber(eventid string) *Subscriber {\r\n\tsub := &Subscriber{\r\n\t\teventid:    eventid,\r\n\t\tquit:       str.deregister,\r\n\t\tconnection: make(chan *Event, 64),\r\n\t}\r\n\tstr.register <- sub\r\n\treturn sub\r\n}","code-length":91,"reference":"\/\/ addSubscriber will create a new subscriber on a stream","result":"Register a new subscriber.","score":[0.1008,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New() *Server {\r\n\treturn &Server{\r\n\t\tBufferSize: DefaultBufferSize,\r\n\t\tAutoStream: false,\r\n\t\tAutoReplay: true,\r\n\t\tStreams:    make(map[string]*Stream),\r\n\t}\r\n}","code-length":71,"reference":"\/\/ New will create a server and setup defaults","result":"Create a new server.","score":[0.0915,0.3007]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Server) Close() {\r\n\ts.mu.Lock()\r\n\tdefer s.mu.Unlock()\r\n\tfor id := range s.Streams {\r\n\t\ts.Streams[id].quit <- true\r\n\t\tdelete(s.Streams, id)\r\n\t}\r\n}","code-length":80,"reference":"\/\/ Close shuts down the server, closes all of the streams and connections","result":"Close the server.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Server) CreateStream(id string) *Stream {\r\n\ts.mu.Lock()\r\n\tdefer s.mu.Unlock()\r\n\tif s.Streams[id] != nil {\r\n\t\treturn s.Streams[id]\r\n\t}\r\n\tstr := newStream(s.BufferSize, s.AutoReplay)\r\n\tstr.run()\r\n\ts.Streams[id] = str\r\n\treturn str\r\n}","code-length":114,"reference":"\/\/ CreateStream will create a new stream and register it","result":"Create a new stream.","score":[0.1008,0.3132]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Server) RemoveStream(id string) {\r\n\ts.mu.Lock()\r\n\tdefer s.mu.Unlock()\r\n\tif s.Streams[id] != nil {\r\n\t\ts.Streams[id].close()\r\n\t\tdelete(s.Streams, id)\r\n\t}\r\n}","code-length":85,"reference":"\/\/ RemoveStream will remove a stream","result":"Remove streams from the server.","score":[0,0.1695]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Server) StreamExists(id string) bool {\r\n\ts.mu.Lock()\r\n\tdefer s.mu.Unlock()\r\n\treturn s.Streams[id] != nil\r\n}","code-length":57,"reference":"\/\/ StreamExists checks whether a stream by a given id exists","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Server) Publish(id string, event *Event) {\r\n\ts.mu.Lock()\r\n\tdefer s.mu.Unlock()\r\n\tif s.Streams[id] != nil {\r\n\t\ts.Streams[id].event <- s.process(event)\r\n\t}\r\n}","code-length":82,"reference":"\/\/ Publish sends a mesage to every client in a streamID","result":"Publish events to the server.","score":[0.0861,0.0962]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(url string) *Client {\r\n\treturn &Client{\r\n\t\tURL:        url,\r\n\t\tConnection: &http.Client{},\r\n\t\tHeaders:    make(map[string]string),\r\n\t\tsubscribed: make(map[chan *Event]chan bool),\r\n\t}\r\n}","code-length":85,"reference":"\/\/ NewClient creates a new client","result":"Create a new client.","score":[0.274,0.5077]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Subscribe(stream string, handler func(msg *Event)) error {\r\n\toperation := func() error {\r\n\t\tresp, err := c.request(stream)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdefer resp.Body.Close()\r\n\t\treader := NewEventStreamReader(resp.Body)\r\n\t\tfor {\r\n\t\t\t\r\n\t\t\tevent, err := reader.ReadEvent()\r\n\t\t\tif err != nil {\r\n\t\t\t\tif err == io.EOF {\r\n\t\t\t\t\treturn nil\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\tif c.disconnectcb != nil {\r\n\t\t\t\t\tc.disconnectcb(c)\r\n\t\t\t\t}\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif msg, err := c.processEvent(event); err == nil {\r\n\t\t\t\tif len(msg.ID) > 0 {\r\n\t\t\t\t\tc.EventID = string(msg.ID)\r\n\t\t\t\t} else {\r\n\t\t\t\t\tmsg.ID = []byte(c.EventID)\r\n\t\t\t\t}\r\n\t\t\t\thandler(msg)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn backoff.Retry(operation, backoff.NewExponentialBackOff())\r\n}","code-length":315,"reference":"\/\/ Subscribe to a data stream","result":"Subscribe to events.","score":[0.2124,0.3289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) SubscribeChan(stream string, ch chan *Event) error {\r\n\tvar connected bool\r\n\terrch := make(chan error)\r\n\tc.mu.Lock()\r\n\tc.subscribed[ch] = make(chan bool)\r\n\tc.mu.Unlock()\r\n\tgo func() {\r\n\t\toperation := func() error {\r\n\t\t\tresp, err := c.request(stream)\r\n\t\t\tif err != nil {\r\n\t\t\t\tc.cleanup(resp, ch)\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif resp.StatusCode != 200 {\r\n\t\t\t\tc.cleanup(resp, ch)\r\n\t\t\t\treturn errors.New(\"could not connect to stream\")\r\n\t\t\t}\r\n\t\t\tif !connected {\r\n\t\t\t\terrch <- nil\r\n\t\t\t\tconnected = true\r\n\t\t\t}\r\n\t\t\treader := NewEventStreamReader(resp.Body)\r\n\t\t\tfor {\r\n\t\t\t\t\r\n\t\t\t\tevent, err := reader.ReadEvent()\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tif err == io.EOF {\r\n\t\t\t\t\t\tc.cleanup(resp, ch)\r\n\t\t\t\t\t\treturn nil\r\n\t\t\t\t\t}\r\n\t\t\t\t\t\r\n\t\t\t\t\tif c.disconnectcb != nil {\r\n\t\t\t\t\t\tc.disconnectcb(c)\r\n\t\t\t\t\t}\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\tif msg, err := c.processEvent(event); err == nil {\r\n\t\t\t\t\tif len(msg.ID) > 0 {\r\n\t\t\t\t\t\tc.EventID = string(msg.ID)\r\n\t\t\t\t\t} else {\r\n\t\t\t\t\t\tmsg.ID = []byte(c.EventID)\r\n\t\t\t\t\t}\r\n\t\t\t\t\tselect {\r\n\t\t\t\t\tcase <-c.subscribed[ch]:\r\n\t\t\t\t\t\tc.cleanup(resp, ch)\r\n\t\t\t\t\t\treturn nil\r\n\t\t\t\t\tcase ch <- msg:\r\n\t\t\t\t\t\t\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\terr := backoff.Retry(operation, backoff.NewExponentialBackOff())\r\n\t\tif err != nil && !connected {\r\n\t\t\terrch <- err\r\n\t\t}\r\n\t}()\r\n\terr := <-errch\r\n\tclose(errch)\r\n\treturn err\r\n}","code-length":556,"reference":"\/\/ SubscribeChan sends all events to the provided channel","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) SubscribeRaw(handler func(msg *Event)) error {\r\n\treturn c.Subscribe(\"\", handler)\r\n}","code-length":41,"reference":"\/\/ SubscribeRaw to an sse endpoint","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Unsubscribe(ch chan *Event) {\r\n\tc.mu.Lock()\r\n\tdefer c.mu.Unlock()\r\n\tif c.subscribed[ch] != nil {\r\n\t\tc.subscribed[ch] <- true\r\n\t}\r\n}","code-length":74,"reference":"\/\/ Unsubscribe unsubscribes a channel","result":"Unsubscribe from a channel.","score":[0.2959,0.2041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewEventStreamReader(eventStream io.Reader) *EventStreamReader {\r\n\tscanner := bufio.NewScanner(eventStream)\r\n\tsplit := func(data []byte, atEOF bool) (int, []byte, error) {\r\n\t\tif atEOF && len(data) == 0 {\r\n\t\t\treturn 0, nil, nil\r\n\t\t}\r\n\t\t\r\n\t\tif i := bytes.Index(data, []byte(\"\\r\\n\\r\\n\")); i >= 0 {\r\n\t\t\treturn i + 1, data[0:i], nil\r\n\t\t}\r\n\t\tif i := bytes.Index(data, []byte(\"\\r\\r\")); i >= 0 {\r\n\t\t\treturn i + 1, data[0:i], nil\r\n\t\t}\r\n\t\tif i := bytes.Index(data, []byte(\"\\n\\n\")); i >= 0 {\r\n\t\t\treturn i + 1, data[0:i], nil\r\n\t\t}\r\n\t\t\r\n\t\tif atEOF {\r\n\t\t\treturn len(data), data, nil\r\n\t\t}\r\n\t\t\r\n\t\treturn 0, nil, nil\r\n\t}\r\n\t\r\n\tscanner.Split(split)\r\n\treturn &EventStreamReader{\r\n\t\tscanner: scanner,\r\n\t}\r\n}","code-length":316,"reference":"\/\/ NewEventStreamReader creates an instance of EventStreamReader.","result":"Create a new EventStreamReader .","score":[0,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *EventStreamReader) ReadEvent() ([]byte, error) {\r\n\tif e.scanner.Scan() {\r\n\t\tevent := e.scanner.Bytes()\r\n\t\treturn event, nil\r\n\t}\r\n\tif err := e.scanner.Err(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn nil, io.EOF\r\n}","code-length":101,"reference":"\/\/ ReadEvent scans the EventStream for events.","result":"Read the event.","score":[0.1076,0.2841]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Server) HTTPHandler(w http.ResponseWriter, r *http.Request) {\r\n\tflusher, err := w.(http.Flusher)\r\n\tif !err {\r\n\t\thttp.Error(w, \"Streaming unsupported!\", http.StatusInternalServerError)\r\n\t\treturn\r\n\t}\r\n\tw.Header().Set(\"Content-Type\", \"text\/event-stream\")\r\n\tw.Header().Set(\"Cache-Control\", \"no-cache\")\r\n\tw.Header().Set(\"Connection\", \"keep-alive\")\r\n\tw.Header().Set(\"Access-Control-Allow-Origin\", \"*\")\r\n\t\r\n\tstreamID := r.URL.Query().Get(\"stream\")\r\n\tif streamID == \"\" {\r\n\t\thttp.Error(w, \"Please specify a stream!\", http.StatusInternalServerError)\r\n\t\treturn\r\n\t}\r\n\tstream := s.getStream(streamID)\r\n\tif stream == nil && !s.AutoStream {\r\n\t\thttp.Error(w, \"Stream not found!\", http.StatusInternalServerError)\r\n\t\treturn\r\n\t} else if stream == nil && s.AutoStream {\r\n\t\tstream = s.CreateStream(streamID)\r\n\t}\r\n\teventid := r.Header.Get(\"Last-Event-ID\")\r\n\tif eventid == \"\" {\r\n\t\teventid = \"0\"\r\n\t}\r\n\t\r\n\tsub := stream.addSubscriber(eventid)\r\n\tdefer sub.close()\r\n\tnotify := w.(http.CloseNotifier).CloseNotify()\r\n\tgo func() {\r\n\t\t<-notify\r\n\t\tsub.close()\r\n\t}()\r\n\t\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase ev, ok := <-sub.connection:\r\n\t\t\tif !ok {\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif len(ev.Data) == 0 {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif s.EventTTL != 0 && time.Now().After(ev.timestamp.Add(s.EventTTL)) {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tfmt.Fprintf(w, \"id: %s\\n\", ev.ID)\r\n\t\t\tfmt.Fprintf(w, \"data: %s\\n\", ev.Data)\r\n\t\t\tif len(ev.Event) > 0 {\r\n\t\t\t\tfmt.Fprintf(w, \"event: %s\\n\", ev.Event)\r\n\t\t\t}\r\n\t\t\tif len(ev.Retry) > 0 {\r\n\t\t\t\tfmt.Fprintf(w, \"retry: %s\\n\", ev.Retry)\r\n\t\t\t}\r\n\t\t\tfmt.Fprint(w, \"\\n\")\r\n\t\t\tflusher.Flush()\r\n\t\t}\r\n\t}\r\n}","code-length":690,"reference":"\/\/ HTTPHandler serves new connections with events for a given stream ...","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *EventLog) Add(ev *Event) {\r\n\tev.ID = []byte(e.currentindex())\r\n\tev.timestamp = time.Now()\r\n\t(*e) = append((*e), ev)\r\n}","code-length":66,"reference":"\/\/ Add event to eventlog","result":"Add events to the EventLog.","score":[0.2857,0.5889]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *EventLog) Replay(s *Subscriber) {\r\n\tfor i := 0; i < len((*e)); i++ {\r\n\t\tif string((*e)[i].ID) >= s.eventid {\r\n\t\t\ts.connection <- (*e)[i]\r\n\t\t}\r\n\t}\r\n}","code-length":88,"reference":"\/\/ Replay events to a subscriber","result":"Replay the event.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc readKey(path string) (crypto.Signer, error) {\r\n\tb, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\td, _ := pem.Decode(b)\r\n\tif d == nil {\r\n\t\treturn nil, fmt.Errorf(\"no block found in %q\", path)\r\n\t}\r\n\tswitch d.Type {\r\n\tcase rsaPrivateKey:\r\n\t\treturn x509.ParsePKCS1PrivateKey(d.Bytes)\r\n\tcase ecPrivateKey:\r\n\t\treturn x509.ParseECPrivateKey(d.Bytes)\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"%q is unsupported\", d.Type)\r\n\t}\r\n}","code-length":189,"reference":"\/\/ readKey reads a private rsa key from path.\n\/\/ The key is expected to be in PEM format.","result":"Read a key from a file.","score":[0.0346,0.113]}
{"code":"\/*is used to<extra_id_0>\r\nfunc writeKey(path string, k *ecdsa.PrivateKey) error {\r\n\tf, err := os.OpenFile(path, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0600)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tbytes, err := x509.MarshalECPrivateKey(k)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tb := &pem.Block{Type: ecPrivateKey, Bytes: bytes}\r\n\tif err := pem.Encode(f, b); err != nil {\r\n\t\tf.Close()\r\n\t\treturn err\r\n\t}\r\n\treturn f.Close()\r\n}","code-length":180,"reference":"\/\/ writeKey writes k to the specified path in PEM format.\n\/\/ If file does not exists, it will be created with 0600 mod.","result":"Write the private key to a file.","score":[0.0169,0.0673]}
{"code":"\/*is used to<extra_id_0>\r\nfunc anyKey(filename string, gen bool) (crypto.Signer, error) {\r\n\tk, err := readKey(filename)\r\n\tif err == nil {\r\n\t\treturn k, nil\r\n\t}\r\n\tif !os.IsNotExist(err) || !gen {\r\n\t\treturn nil, err\r\n\t}\r\n\tecKey, err := ecdsa.GenerateKey(elliptic.P256(), rand.Reader)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn ecKey, writeKey(filename, ecKey)\r\n}","code-length":149,"reference":"\/\/ anyKey reads the key from file or generates a new one if gen == true.\n\/\/ It returns an error if filename exists but cannot be read.\n\/\/ A newly generated key is also stored to filename.","result":"Read and write keys.","score":[0,0.0145]}
{"code":"\/*is used to<extra_id_0>\r\nfunc sameDir(existing, filename string) string {\r\n\treturn filepath.Join(filepath.Dir(existing), filename)\r\n}","code-length":39,"reference":"\/\/ sameDir returns filename path placing it in the same dir as existing file.","result":"Generate the generated code.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc printAccount(w io.Writer, a *acme.Account, kp string) {\r\n\ttw := tabwriter.NewWriter(w, 0, 8, 0, '\\t', 0)\r\n\tfmt.Fprintln(tw, \"URI:\\t\", a.URI)\r\n\tfmt.Fprintln(tw, \"Key:\\t\", kp)\r\n\tfmt.Fprintln(tw, \"Contact:\\t\", strings.Join(a.Contact, \", \"))\r\n\tfmt.Fprintln(tw, \"Terms:\\t\", a.CurrentTerms)\r\n\tagreed := a.AgreedTerms\r\n\tif a.AgreedTerms == \"\" {\r\n\t\tagreed = \"no\"\r\n\t} else if a.AgreedTerms == a.CurrentTerms {\r\n\t\tagreed = \"yes\"\r\n\t}\r\n\tfmt.Fprintln(tw, \"Accepted:\\t\", agreed)\r\n\t\r\n\ttw.Flush()\r\n}","code-length":230,"reference":"\/\/ printAccount outputs account into into w using tabwriter.","result":"Print the account.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc tmpl(w io.Writer, text string, data interface{}) {\r\n\tt := template.New(\"top\")\r\n\tt.Funcs(template.FuncMap{\r\n\t\t\"trim\":       strings.TrimSpace,\r\n\t\t\"capitalize\": capitalize,\r\n\t})\r\n\ttemplate.Must(t.Parse(text))\r\n\tew := &errWriter{w: w}\r\n\terr := t.Execute(ew, data)\r\n\tif ew.err != nil {\r\n\t\t\r\n\t\tif strings.Contains(ew.err.Error(), \"pipe\") {\r\n\t\t\tos.Exit(1)\r\n\t\t}\r\n\t\tfatalf(\"writing output: %v\", ew.err)\r\n\t}\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n}","code-length":207,"reference":"\/\/ tmpl executes the given template text on data, writing the result to w.","result":"Generate the template .","score":[0.0312,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc printUsage(w io.Writer) {\r\n\tbw := bufio.NewWriter(w)\r\n\ttmpl(bw, usageTemplate, commands)\r\n\tbw.Flush()\r\n}","code-length":56,"reference":"\/\/ printUsage prints usageTemplate to w.","result":"Print usage.","score":[0,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FromRequest(r *http.Request) string {\r\n\t\r\n\txRealIP := r.Header.Get(\"X-Real-Ip\")\r\n\txForwardedFor := r.Header.Get(\"X-Forwarded-For\")\r\n\t\r\n\tif xRealIP == \"\" && xForwardedFor == \"\" {\r\n\t\tvar remoteIP string\r\n\t\t\r\n\t\t\r\n\t\tif strings.ContainsRune(r.RemoteAddr, ':') {\r\n\t\t\tremoteIP, _, _ = net.SplitHostPort(r.RemoteAddr)\r\n\t\t} else {\r\n\t\t\tremoteIP = r.RemoteAddr\r\n\t\t}\r\n\t\treturn remoteIP\r\n\t}\r\n\t\r\n\tfor _, address := range strings.Split(xForwardedFor, \",\") {\r\n\t\taddress = strings.TrimSpace(address)\r\n\t\tisPrivate, err := isPrivateAddress(address)\r\n\t\tif !isPrivate && err == nil {\r\n\t\t\treturn address\r\n\t\t}\r\n\t}\r\n\t\r\n\treturn xRealIP\r\n}","code-length":259,"reference":"\/\/ FromRequest return client's real public IP address from http request headers.","result":"Generate the FromRequest function .","score":[0.0593,0.0442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ClearParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandClear, p, nil)\r\n}","code-length":49,"reference":"\/\/ Do executes DOMStorage.clear against the provided context.","result":"Remove the comments.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *DisableParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandDisable, nil, nil)\r\n}","code-length":49,"reference":"\/\/ Do executes DOMStorage.disable against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *RemoveDOMStorageItemParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandRemoveDOMStorageItem, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes DOMStorage.removeDOMStorageItem against the provided context.","result":"Remove the file.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetDOMStorageItemParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetDOMStorageItem, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes DOMStorage.setDOMStorageItem against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *DeliverPushMessageParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandDeliverPushMessage, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes ServiceWorker.deliverPushMessage against the provided context.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *DispatchSyncEventParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandDispatchSyncEvent, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes ServiceWorker.dispatchSyncEvent against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *InspectWorkerParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandInspectWorker, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes ServiceWorker.inspectWorker against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetForceUpdateOnPageLoadParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetForceUpdateOnPageLoad, p, nil)\r\n}","code-length":59,"reference":"\/\/ Do executes ServiceWorker.setForceUpdateOnPageLoad against the provided context.","result":"Set force update on page load.","score":[0,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SkipWaitingParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSkipWaiting, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes ServiceWorker.skipWaiting against the provided context.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StartWorkerParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStartWorker, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes ServiceWorker.startWorker against the provided context.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StopAllWorkersParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStopAllWorkers, nil, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes ServiceWorker.stopAllWorkers against the provided context.","result":"Stop all workers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StopWorkerParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStopWorker, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes ServiceWorker.stopWorker against the provided context.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *UnregisterParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandUnregister, p, nil)\r\n}","code-length":49,"reference":"\/\/ Do executes ServiceWorker.unregister against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *UpdateRegistrationParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandUpdateRegistration, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes ServiceWorker.updateRegistration against the provided context.","result":"Update registration.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *BindParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandBind, p, nil)\r\n}","code-length":49,"reference":"\/\/ Do executes Tethering.bind against the provided context.","result":"Generate code for the generated code.","score":[0.1383,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *UnbindParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandUnbind, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Tethering.unbind against the provided context.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *ExceptionDetails) Error() string {\r\n\t\r\n\t\r\n\treturn fmt.Sprintf(\"encountered exception '%s' (%d:%d)\", e.Text, e.LineNumber, e.ColumnNumber)\r\n}","code-length":63,"reference":"\/\/ Error satisfies the error interface.","result":"Generate the error message.","score":[0.274,0.3233]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ReleaseAnimationsParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandReleaseAnimations, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Animation.releaseAnimations against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SeekAnimationsParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSeekAnimations, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Animation.seekAnimations against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetPausedParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetPaused, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Animation.setPaused against the provided context.","result":"Set the paused state.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetPlaybackRateParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetPlaybackRate, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Animation.setPlaybackRate against the provided context.","result":"Set the playback rate.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetTimingParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetTiming, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Animation.setTiming against the provided context.","result":"Set the timing.","score":[0.0771,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PrepareForLeakDetectionParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandPrepareForLeakDetection, nil, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Memory.prepareForLeakDetection against the provided context.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ForciblyPurgeJavaScriptMemoryParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandForciblyPurgeJavaScriptMemory, nil, nil)\r\n}","code-length":59,"reference":"\/\/ Do executes Memory.forciblyPurgeJavaScriptMemory against the provided context.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetPressureNotificationsSuppressedParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetPressureNotificationsSuppressed, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Memory.setPressureNotificationsSuppressed against the provided context.","result":"Set the pressure notifications suppressed.","score":[0.1319,0.1299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SimulatePressureNotificationParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSimulatePressureNotification, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Memory.simulatePressureNotification against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p StartSamplingParams) WithSamplingInterval(samplingInterval int64) *StartSamplingParams {\r\n\tp.SamplingInterval = samplingInterval\r\n\treturn &p\r\n}","code-length":49,"reference":"\/\/ WithSamplingInterval average number of bytes between samples.","result":"Create the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p StartSamplingParams) WithSuppressRandomness(suppressRandomness bool) *StartSamplingParams {\r\n\tp.SuppressRandomness = suppressRandomness\r\n\treturn &p\r\n}","code-length":52,"reference":"\/\/ WithSuppressRandomness do not randomize intervals between samples.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StartSamplingParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStartSampling, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Memory.startSampling against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StopSamplingParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStopSampling, nil, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Memory.stopSampling against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ClearDeviceOrientationOverrideParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandClearDeviceOrientationOverride, nil, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes DeviceOrientation.clearDeviceOrientationOverride against the provided context.","result":"Clear device orientation override.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetDeviceOrientationOverrideParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetDeviceOrientationOverride, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes DeviceOrientation.setDeviceOrientationOverride against the provided context.","result":"Set device orientation.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StartViolationsReportParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStartViolationsReport, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Log.startViolationsReport against the provided context.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StopViolationsReportParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStopViolationsReport, nil, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Log.stopViolationsReport against the provided context.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t Modifier) String() string {\r\n\tswitch t {\r\n\tcase ModifierNone:\r\n\t\treturn \"None\"\r\n\tcase ModifierAlt:\r\n\t\treturn \"Alt\"\r\n\tcase ModifierCtrl:\r\n\t\treturn \"Ctrl\"\r\n\tcase ModifierMeta:\r\n\t\treturn \"Meta\"\r\n\tcase ModifierShift:\r\n\t\treturn \"Shift\"\r\n\t}\r\n\treturn fmt.Sprintf(\"Modifier(%d)\", t)\r\n}","code-length":122,"reference":"\/\/ String returns the Modifier as string value.","result":"Generate the string representation of the modifier.","score":[0.1665,0.1266]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p GetPartialAXTreeParams) WithNodeID(nodeID cdp.NodeID) *GetPartialAXTreeParams {\r\n\tp.NodeID = nodeID\r\n\treturn &p\r\n}","code-length":52,"reference":"\/\/ WithNodeID identifier of the node to get the partial accessibility tree\n\/\/ for.","result":"Generate the generated code.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p GetPartialAXTreeParams) WithBackendNodeID(backendNodeID cdp.BackendNodeID) *GetPartialAXTreeParams {\r\n\tp.BackendNodeID = backendNodeID\r\n\treturn &p\r\n}","code-length":56,"reference":"\/\/ WithBackendNodeID identifier of the backend node to get the partial\n\/\/ accessibility tree for.","result":"Generate the generated code.","score":[0.0204,0.036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p GetPartialAXTreeParams) WithObjectID(objectID runtime.RemoteObjectID) *GetPartialAXTreeParams {\r\n\tp.ObjectID = objectID\r\n\treturn &p\r\n}","code-length":52,"reference":"\/\/ WithObjectID JavaScript object id of the node wrapper to get the partial\n\/\/ accessibility tree for.","result":"Generate the generated code.","score":[0.0124,0.0318]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p GetPartialAXTreeParams) WithFetchRelatives(fetchRelatives bool) *GetPartialAXTreeParams {\r\n\tp.FetchRelatives = fetchRelatives\r\n\treturn &p\r\n}","code-length":56,"reference":"\/\/ WithFetchRelatives whether to fetch this nodes ancestors, siblings and\n\/\/ children. Defaults to true.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetTimeDomainParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetTimeDomain, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Performance.setTimeDomain against the provided context.","result":"Set the time domain.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p ProfileSnapshotParams) WithClipRect(clipRect *dom.Rect) *ProfileSnapshotParams {\r\n\tp.ClipRect = clipRect\r\n\treturn &p\r\n}","code-length":51,"reference":"\/\/ WithClipRect the clip rectangle to apply when replaying the snapshot.","result":"Generate the code.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ReleaseSnapshotParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandReleaseSnapshot, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes LayerTree.releaseSnapshot against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ClearObjectStoreParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandClearObjectStore, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes IndexedDB.clearObjectStore against the provided context.","result":"Remove the comment.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *DeleteDatabaseParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandDeleteDatabase, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes IndexedDB.deleteDatabase against the provided context.","result":"Remove comments.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *DeleteObjectStoreEntriesParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandDeleteObjectStoreEntries, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes IndexedDB.deleteObjectStoreEntries against the provided context.","result":"Remove unused variables.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p RequestDataParams) WithKeyRange(keyRange *KeyRange) *RequestDataParams {\r\n\tp.KeyRange = keyRange\r\n\treturn &p\r\n}","code-length":49,"reference":"\/\/ WithKeyRange key range.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetSamplingIntervalParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetSamplingInterval, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Profiler.setSamplingInterval against the provided context.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StartParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStart, nil, nil)\r\n}","code-length":49,"reference":"\/\/ Do executes Profiler.start against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p StartPreciseCoverageParams) WithCallCount(callCount bool) *StartPreciseCoverageParams {\r\n\tp.CallCount = callCount\r\n\treturn &p\r\n}","code-length":52,"reference":"\/\/ WithCallCount collect accurate call counts beyond simple 'covered' or 'not\n\/\/ covered'.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p StartPreciseCoverageParams) WithDetailed(detailed bool) *StartPreciseCoverageParams {\r\n\tp.Detailed = detailed\r\n\treturn &p\r\n}","code-length":51,"reference":"\/\/ WithDetailed collect block-based coverage.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StartPreciseCoverageParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStartPreciseCoverage, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Profiler.startPreciseCoverage against the provided context.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StartTypeProfileParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStartTypeProfile, nil, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Profiler.startTypeProfile against the provided context.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StopPreciseCoverageParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStopPreciseCoverage, nil, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Profiler.stopPreciseCoverage against the provided context.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StopTypeProfileParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStopTypeProfile, nil, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Profiler.stopTypeProfile against the provided context.","result":"Stop type profile.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetIgnoreCertificateErrorsParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetIgnoreCertificateErrors, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Security.setIgnoreCertificateErrors against the provided context.","result":"Set ignore certificate errors.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *AddInspectedHeapObjectParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandAddInspectedHeapObject, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes HeapProfiler.addInspectedHeapObject against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *CollectGarbageParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandCollectGarbage, nil, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes HeapProfiler.collectGarbage against the provided context.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p StartSamplingParams) WithSamplingInterval(samplingInterval float64) *StartSamplingParams {\r\n\tp.SamplingInterval = samplingInterval\r\n\treturn &p\r\n}","code-length":49,"reference":"\/\/ WithSamplingInterval average sample interval in bytes. Poisson\n\/\/ distribution is used for the intervals. The default value is 32768 bytes.","result":"Create the code.","score":[0.001,0.026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StartTrackingHeapObjectsParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStartTrackingHeapObjects, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes HeapProfiler.startTrackingHeapObjects against the provided context.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p StopTrackingHeapObjectsParams) WithReportProgress(reportProgress bool) *StopTrackingHeapObjectsParams {\r\n\tp.ReportProgress = reportProgress\r\n\treturn &p\r\n}","code-length":52,"reference":"\/\/ WithReportProgress if true 'reportHeapSnapshotProgress' events will be\n\/\/ generated while snapshot is being taken when the tracking is stopped.","result":"Generate the generated code.","score":[0.007,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StopTrackingHeapObjectsParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStopTrackingHeapObjects, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes HeapProfiler.stopTrackingHeapObjects against the provided context.","result":"Stop tracking heap objects.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p TakeHeapSnapshotParams) WithReportProgress(reportProgress bool) *TakeHeapSnapshotParams {\r\n\tp.ReportProgress = reportProgress\r\n\treturn &p\r\n}","code-length":50,"reference":"\/\/ WithReportProgress if true 'reportHeapSnapshotProgress' events will be\n\/\/ generated while snapshot is being taken.","result":"Generate the generated code.","score":[0.0204,0.036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *TakeHeapSnapshotParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandTakeHeapSnapshot, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes HeapProfiler.takeHeapSnapshot against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p GrantPermissionsParams) WithBrowserContextID(browserContextID target.BrowserContextID) *GrantPermissionsParams {\r\n\tp.BrowserContextID = browserContextID\r\n\treturn &p\r\n}","code-length":56,"reference":"\/\/ WithBrowserContextID browserContext to override permissions. When omitted,\n\/\/ default browser context is used.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *GrantPermissionsParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandGrantPermissions, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Browser.grantPermissions against the provided context.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p ResetPermissionsParams) WithBrowserContextID(browserContextID target.BrowserContextID) *ResetPermissionsParams {\r\n\tp.BrowserContextID = browserContextID\r\n\treturn &p\r\n}","code-length":56,"reference":"\/\/ WithBrowserContextID browserContext to reset permissions. When omitted,\n\/\/ default browser context is used.","result":"Reset permissions.","score":[0.0012,0.1465]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ResetPermissionsParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandResetPermissions, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Browser.resetPermissions against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *CrashParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandCrash, nil, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Browser.crash against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *CrashGpuProcessParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandCrashGpuProcess, nil, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Browser.crashGpuProcess against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p GetHistogramsParams) WithQuery(query string) *GetHistogramsParams {\r\n\tp.Query = query\r\n\treturn &p\r\n}","code-length":46,"reference":"\/\/ WithQuery requested substring in name. Only histograms which have query as\n\/\/ a substring in their name are extracted. An empty or absent query returns all\n\/\/ histograms.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p GetWindowForTargetParams) WithTargetID(targetID target.ID) *GetWindowForTargetParams {\r\n\tp.TargetID = targetID\r\n\treturn &p\r\n}","code-length":54,"reference":"\/\/ WithTargetID devtools agent host id. If called as a part of the session,\n\/\/ associated targetId is used.","result":"Generate the generated code.","score":[0.0075,0.0286]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetWindowBoundsParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetWindowBounds, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Browser.setWindowBounds against the provided context.","result":"Set the window bounds.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetDockTileParams) WithImage(image string) *SetDockTileParams {\r\n\tp.Image = image\r\n\treturn &p\r\n}","code-length":48,"reference":"\/\/ WithImage png encoded image.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetDockTileParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetDockTile, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Browser.setDockTile against the provided context.","result":"Set the dock tile.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *DeleteCacheParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandDeleteCache, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes CacheStorage.deleteCache against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *DeleteEntryParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandDeleteEntry, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes CacheStorage.deleteEntry against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p RequestEntriesParams) WithPathFilter(pathFilter string) *RequestEntriesParams {\r\n\tp.PathFilter = pathFilter\r\n\treturn &p\r\n}","code-length":48,"reference":"\/\/ WithPathFilter if present, only return the entries containing this\n\/\/ substring in the path.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *DiscardSearchResultsParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandDiscardSearchResults, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes DOM.discardSearchResults against the provided context.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *FocusParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandFocus, p, nil)\r\n}","code-length":49,"reference":"\/\/ Do executes DOM.focus against the provided context.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *MarkUndoableStateParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandMarkUndoableState, nil, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes DOM.markUndoableState against the provided context.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p PerformSearchParams) WithIncludeUserAgentShadowDOM(includeUserAgentShadowDOM bool) *PerformSearchParams {\r\n\tp.IncludeUserAgentShadowDOM = includeUserAgentShadowDOM\r\n\treturn &p\r\n}","code-length":56,"reference":"\/\/ WithIncludeUserAgentShadowDOM true to search in user agent shadow DOM.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *RedoParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandRedo, nil, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes DOM.redo against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *RemoveAttributeParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandRemoveAttribute, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes DOM.removeAttribute against the provided context.","result":"Remove the empty string.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *RemoveNodeParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandRemoveNode, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes DOM.removeNode against the provided context.","result":"Remove a file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *RequestChildNodesParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandRequestChildNodes, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes DOM.requestChildNodes against the provided context.","result":"Request children.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p ResolveNodeParams) WithNodeID(nodeID cdp.NodeID) *ResolveNodeParams {\r\n\tp.NodeID = nodeID\r\n\treturn &p\r\n}","code-length":48,"reference":"\/\/ WithNodeID ID of the node to resolve.","result":"Resolve the node.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p ResolveNodeParams) WithBackendNodeID(backendNodeID cdp.BackendNodeID) *ResolveNodeParams {\r\n\tp.BackendNodeID = backendNodeID\r\n\treturn &p\r\n}","code-length":52,"reference":"\/\/ WithBackendNodeID backend identifier of the node to resolve.","result":"Resolve nodes.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p ResolveNodeParams) WithExecutionContextID(executionContextID runtime.ExecutionContextID) *ResolveNodeParams {\r\n\tp.ExecutionContextID = executionContextID\r\n\treturn &p\r\n}","code-length":55,"reference":"\/\/ WithExecutionContextID execution context in which to resolve the node.","result":"Resolve nodes.","score":[0,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetAttributeValueParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetAttributeValue, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes DOM.setAttributeValue against the provided context.","result":"Set the value of the attribute.","score":[0.1383,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetAttributesAsTextParams) WithName(name string) *SetAttributesAsTextParams {\r\n\tp.Name = name\r\n\treturn &p\r\n}","code-length":48,"reference":"\/\/ WithName attribute name to replace with new attributes derived from text\n\/\/ in case text parsed successfully.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetAttributesAsTextParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetAttributesAsText, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes DOM.setAttributesAsText against the provided context.","result":"Set attributes as text.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetFileInputFilesParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetFileInputFiles, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes DOM.setFileInputFiles against the provided context.","result":"Set file input files.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetInspectedNodeParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetInspectedNode, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes DOM.setInspectedNode against the provided context.","result":"Set the inspected node.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetNodeValueParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetNodeValue, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes DOM.setNodeValue against the provided context.","result":"Set node value.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetOuterHTMLParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetOuterHTML, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes DOM.setOuterHTML against the provided context.","result":"Set the outer html.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *UndoParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandUndo, nil, nil)\r\n}","code-length":49,"reference":"\/\/ Do executes DOM.undo against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ForcePseudoStateParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandForcePseudoState, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes CSS.forcePseudoState against the provided context.","result":"Force pseudo state.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetEffectivePropertyValueForNodeParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetEffectivePropertyValueForNode, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes CSS.setEffectivePropertyValueForNode against the provided context.","result":"Set the effective property value of a node.","score":[0.1389,0.125]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StartRuleUsageTrackingParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStartRuleUsageTracking, nil, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes CSS.startRuleUsageTracking against the provided context.","result":"Start rule usage tracking.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *CloseParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandClose, p, nil)\r\n}","code-length":49,"reference":"\/\/ Do executes IO.close against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ClearDataForOriginParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandClearDataForOrigin, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Storage.clearDataForOrigin against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *TrackCacheStorageForOriginParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandTrackCacheStorageForOrigin, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Storage.trackCacheStorageForOrigin against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *TrackIndexedDBForOriginParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandTrackIndexedDBForOrigin, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Storage.trackIndexedDBForOrigin against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *UntrackCacheStorageForOriginParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandUntrackCacheStorageForOrigin, p, nil)\r\n}","code-length":59,"reference":"\/\/ Do executes Storage.untrackCacheStorageForOrigin against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *UntrackIndexedDBForOriginParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandUntrackIndexedDBForOrigin, p, nil)\r\n}","code-length":59,"reference":"\/\/ Do executes Storage.untrackIndexedDBForOrigin against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *HideHighlightParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandHideHighlight, nil, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Overlay.hideHighlight against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *HighlightFrameParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandHighlightFrame, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Overlay.highlightFrame against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p HighlightNodeParams) WithNodeID(nodeID cdp.NodeID) *HighlightNodeParams {\r\n\tp.NodeID = nodeID\r\n\treturn &p\r\n}","code-length":48,"reference":"\/\/ WithNodeID identifier of the node to highlight.","result":"Generate code for the generated code.","score":[0.1383,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p HighlightNodeParams) WithBackendNodeID(backendNodeID cdp.BackendNodeID) *HighlightNodeParams {\r\n\tp.BackendNodeID = backendNodeID\r\n\treturn &p\r\n}","code-length":52,"reference":"\/\/ WithBackendNodeID identifier of the backend node to highlight.","result":"Generate code for the generated code.","score":[0.1171,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p HighlightNodeParams) WithObjectID(objectID runtime.RemoteObjectID) *HighlightNodeParams {\r\n\tp.ObjectID = objectID\r\n\treturn &p\r\n}","code-length":48,"reference":"\/\/ WithObjectID JavaScript object id of the node to be highlighted.","result":"Generate code for the generated code.","score":[0.0839,0.0476]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p HighlightNodeParams) WithSelector(selector string) *HighlightNodeParams {\r\n\tp.Selector = selector\r\n\treturn &p\r\n}","code-length":44,"reference":"\/\/ WithSelector selectors to highlight relevant nodes.","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *HighlightNodeParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandHighlightNode, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Overlay.highlightNode against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *HighlightQuadParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandHighlightQuad, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Overlay.highlightQuad against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *HighlightRectParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandHighlightRect, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Overlay.highlightRect against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetInspectModeParams) WithHighlightConfig(highlightConfig *HighlightConfig) *SetInspectModeParams {\r\n\tp.HighlightConfig = highlightConfig\r\n\treturn &p\r\n}","code-length":52,"reference":"\/\/ WithHighlightConfig a descriptor for the highlight appearance of\n\/\/ hovered-over nodes. May be omitted if enabled == false.","result":"Generate the generated code.","score":[0.0075,0.0286]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetInspectModeParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetInspectMode, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Overlay.setInspectMode against the provided context.","result":"Set the default behavior.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetShowAdHighlightsParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetShowAdHighlights, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Overlay.setShowAdHighlights against the provided context.","result":"Set the show ad highlights.","score":[0.1319,0.1299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetPausedInDebuggerMessageParams) WithMessage(message string) *SetPausedInDebuggerMessageParams {\r\n\tp.Message = message\r\n\treturn &p\r\n}","code-length":50,"reference":"\/\/ WithMessage the message to display, also triggers resume and step over\n\/\/ controls.","result":"Generate the generated code.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetPausedInDebuggerMessageParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetPausedInDebuggerMessage, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Overlay.setPausedInDebuggerMessage against the provided context.","result":"Set the paused state of the in.","score":[0.14,0.1266]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetShowDebugBordersParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetShowDebugBorders, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Overlay.setShowDebugBorders against the provided context.","result":"Set show debug borders.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetShowFPSCounterParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetShowFPSCounter, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Overlay.setShowFPSCounter against the provided context.","result":"Set the showFPSCounter.","score":[0.0771,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetShowPaintRectsParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetShowPaintRects, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Overlay.setShowPaintRects against the provided context.","result":"Set show paint rects.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetShowScrollBottleneckRectsParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetShowScrollBottleneckRects, p, nil)\r\n}","code-length":61,"reference":"\/\/ Do executes Overlay.setShowScrollBottleneckRects against the provided context.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetShowHitTestBordersParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetShowHitTestBorders, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Overlay.setShowHitTestBorders against the provided context.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetShowViewportSizeOnResizeParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetShowViewportSizeOnResize, p, nil)\r\n}","code-length":59,"reference":"\/\/ Do executes Overlay.setShowViewportSizeOnResize against the provided context.","result":"Set the size of the viewport.","score":[0.1383,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ClearBrowserCacheParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandClearBrowserCache, nil, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Network.clearBrowserCache against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ClearBrowserCookiesParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandClearBrowserCookies, nil, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Network.clearBrowserCookies against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p ContinueInterceptedRequestParams) WithErrorReason(errorReason ErrorReason) *ContinueInterceptedRequestParams {\r\n\tp.ErrorReason = errorReason\r\n\treturn &p\r\n}","code-length":52,"reference":"\/\/ WithErrorReason if set this causes the request to fail with the given\n\/\/ reason. Passing Aborted for requests marked with isNavigationRequest also\n\/\/ cancels the navigation. Must not be set in response to an authChallenge.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p ContinueInterceptedRequestParams) WithRawResponse(rawResponse string) *ContinueInterceptedRequestParams {\r\n\tp.RawResponse = rawResponse\r\n\treturn &p\r\n}","code-length":51,"reference":"\/\/ WithRawResponse if set the requests completes using with the provided\n\/\/ base64 encoded raw response, including HTTP status line and headers etc...\n\/\/ Must not be set in response to an authChallenge.","result":"Generate the generated code.","score":[0.0002,0.0166]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p ContinueInterceptedRequestParams) WithURL(url string) *ContinueInterceptedRequestParams {\r\n\tp.URL = url\r\n\treturn &p\r\n}","code-length":48,"reference":"\/\/ WithURL if set the request url will be modified in a way that's not\n\/\/ observable by page. Must not be set in response to an authChallenge.","result":"Create a new function.","score":[0.0008,0.0195]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p ContinueInterceptedRequestParams) WithMethod(method string) *ContinueInterceptedRequestParams {\r\n\tp.Method = method\r\n\treturn &p\r\n}","code-length":48,"reference":"\/\/ WithMethod if set this allows the request method to be overridden. Must\n\/\/ not be set in response to an authChallenge.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p ContinueInterceptedRequestParams) WithPostData(postData string) *ContinueInterceptedRequestParams {\r\n\tp.PostData = postData\r\n\treturn &p\r\n}","code-length":51,"reference":"\/\/ WithPostData if set this allows postData to be set. Must not be set in\n\/\/ response to an authChallenge.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p ContinueInterceptedRequestParams) WithHeaders(headers Headers) *ContinueInterceptedRequestParams {\r\n\tp.Headers = headers\r\n\treturn &p\r\n}","code-length":48,"reference":"\/\/ WithHeaders if set this allows the request headers to be changed. Must not\n\/\/ be set in response to an authChallenge.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p ContinueInterceptedRequestParams) WithAuthChallengeResponse(authChallengeResponse *AuthChallengeResponse) *ContinueInterceptedRequestParams {\r\n\tp.AuthChallengeResponse = authChallengeResponse\r\n\treturn &p\r\n}","code-length":59,"reference":"\/\/ WithAuthChallengeResponse response to a requestIntercepted with an\n\/\/ authChallenge. Must not be set otherwise.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ContinueInterceptedRequestParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandContinueInterceptedRequest, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Network.continueInterceptedRequest against the provided context.","result":"Continue intercepted request.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p DeleteCookiesParams) WithURL(url string) *DeleteCookiesParams {\r\n\tp.URL = url\r\n\treturn &p\r\n}","code-length":44,"reference":"\/\/ WithURL if specified, deletes all the cookies with the given name where\n\/\/ domain and path match provided URL.","result":"Set the cookie url.","score":[0.0059,0.0815]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p DeleteCookiesParams) WithDomain(domain string) *DeleteCookiesParams {\r\n\tp.Domain = domain\r\n\treturn &p\r\n}","code-length":44,"reference":"\/\/ WithDomain if specified, deletes only cookies with the exact domain.","result":"Return the params that are used to delete the cookie.","score":[0.0982,0.0917]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p DeleteCookiesParams) WithPath(path string) *DeleteCookiesParams {\r\n\tp.Path = path\r\n\treturn &p\r\n}","code-length":44,"reference":"\/\/ WithPath if specified, deletes only cookies with the exact path.","result":"Delete cookies by path.","score":[0.066,0.1456]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *DeleteCookiesParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandDeleteCookies, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Network.deleteCookies against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p EmulateNetworkConditionsParams) WithConnectionType(connectionType ConnectionType) *EmulateNetworkConditionsParams {\r\n\tp.ConnectionType = connectionType\r\n\treturn &p\r\n}","code-length":53,"reference":"\/\/ WithConnectionType connection type if known.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *EmulateNetworkConditionsParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandEmulateNetworkConditions, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Network.emulateNetworkConditions against the provided context.","result":"Emulate network conditions.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *EnableParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandEnable, p, nil)\r\n}","code-length":49,"reference":"\/\/ Do executes Network.enable against the provided context.","result":"Enable a service.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p GetCookiesParams) WithUrls(urls []string) *GetCookiesParams {\r\n\tp.Urls = urls\r\n\treturn &p\r\n}","code-length":45,"reference":"\/\/ WithUrls the list of URLs for which applicable cookies will be fetched.","result":"Generate the code.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ReplayXHRParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandReplayXHR, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Network.replayXHR against the provided context.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetBlockedURLSParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetBlockedURLS, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Network.setBlockedURLs against the provided context.","result":"Set the blocked URLs.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetBypassServiceWorkerParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetBypassServiceWorker, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Network.setBypassServiceWorker against the provided context.","result":"Set bypass.","score":[0,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetCacheDisabledParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetCacheDisabled, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Network.setCacheDisabled against the provided context.","result":"Set cache disabled.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetCookieParams) WithURL(url string) *SetCookieParams {\r\n\tp.URL = url\r\n\treturn &p\r\n}","code-length":44,"reference":"\/\/ WithURL the request-URI to associate with the setting of the cookie. This\n\/\/ value can affect the default domain and path values of the created cookie.","result":"Set the URL of the cookie.","score":[0.0129,0.1494]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetCookieParams) WithDomain(domain string) *SetCookieParams {\r\n\tp.Domain = domain\r\n\treturn &p\r\n}","code-length":44,"reference":"\/\/ WithDomain cookie domain.","result":"Set domain in cookies.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetCookieParams) WithPath(path string) *SetCookieParams {\r\n\tp.Path = path\r\n\treturn &p\r\n}","code-length":44,"reference":"\/\/ WithPath cookie path.","result":"Set path in cookies.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetCookieParams) WithSecure(secure bool) *SetCookieParams {\r\n\tp.Secure = secure\r\n\treturn &p\r\n}","code-length":44,"reference":"\/\/ WithSecure true if cookie is secure.","result":"Set secure cookie.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetCookieParams) WithHTTPOnly(httpOnly bool) *SetCookieParams {\r\n\tp.HTTPOnly = httpOnly\r\n\treturn &p\r\n}","code-length":48,"reference":"\/\/ WithHTTPOnly true if cookie is http-only.","result":"Set the HTTPOnly flag.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetCookieParams) WithSameSite(sameSite CookieSameSite) *SetCookieParams {\r\n\tp.SameSite = sameSite\r\n\treturn &p\r\n}","code-length":50,"reference":"\/\/ WithSameSite cookie SameSite type.","result":"Set the same site of the cookie.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetCookieParams) WithExpires(expires *cdp.TimeSinceEpoch) *SetCookieParams {\r\n\tp.Expires = expires\r\n\treturn &p\r\n}","code-length":50,"reference":"\/\/ WithExpires cookie expiration date, session cookie if not set.","result":"Set cookie parameters.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetCookiesParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetCookies, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Network.setCookies against the provided context.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetDataSizeLimitsForTestParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetDataSizeLimitsForTest, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Network.setDataSizeLimitsForTest against the provided context.","result":"Set data size limits for test.","score":[0,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetExtraHTTPHeadersParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetExtraHTTPHeaders, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Network.setExtraHTTPHeaders against the provided context.","result":"Set extra http headers.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetRequestInterceptionParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetRequestInterception, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Network.setRequestInterception against the provided context.","result":"Set the interception.","score":[0.0771,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ClearDeviceMetricsOverrideParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandClearDeviceMetricsOverride, nil, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Emulation.clearDeviceMetricsOverride against the provided context.","result":"Clear the device metrics override.","score":[0.1319,0.0649]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ClearGeolocationOverrideParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandClearGeolocationOverride, nil, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Emulation.clearGeolocationOverride against the provided context.","result":"Remove the comments.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ResetPageScaleFactorParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandResetPageScaleFactor, nil, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Emulation.resetPageScaleFactor against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetFocusEmulationEnabledParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetFocusEmulationEnabled, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Emulation.setFocusEmulationEnabled against the provided context.","result":"Set the focus emulation.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetCPUThrottlingRateParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetCPUThrottlingRate, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Emulation.setCPUThrottlingRate against the provided context.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetDefaultBackgroundColorOverrideParams) WithColor(color *cdp.RGBA) *SetDefaultBackgroundColorOverrideParams {\r\n\tp.Color = color\r\n\treturn &p\r\n}","code-length":52,"reference":"\/\/ WithColor rGBA of the default background color. If not specified, any\n\/\/ existing override will be cleared.","result":"Set the default background color.","score":[0.0559,0.2376]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetDefaultBackgroundColorOverrideParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetDefaultBackgroundColorOverride, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Emulation.setDefaultBackgroundColorOverride against the provided context.","result":"Set the default background color.","score":[0.1319,0.1299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetDeviceMetricsOverrideParams) WithScale(scale float64) *SetDeviceMetricsOverrideParams {\r\n\tp.Scale = scale\r\n\treturn &p\r\n}","code-length":49,"reference":"\/\/ WithScale scale to apply to resulting view image.","result":"Set the scale parameter.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetDeviceMetricsOverrideParams) WithDontSetVisibleSize(dontSetVisibleSize bool) *SetDeviceMetricsOverrideParams {\r\n\tp.DontSetVisibleSize = dontSetVisibleSize\r\n\treturn &p\r\n}","code-length":63,"reference":"\/\/ WithDontSetVisibleSize do not set visible view size, rely upon explicit\n\/\/ setVisibleSize call.","result":"Set device metrics.","score":[0,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetDeviceMetricsOverrideParams) WithScreenOrientation(screenOrientation *ScreenOrientation) *SetDeviceMetricsOverrideParams {\r\n\tp.ScreenOrientation = screenOrientation\r\n\treturn &p\r\n}","code-length":54,"reference":"\/\/ WithScreenOrientation screen orientation override.","result":"Set device metrics.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetDeviceMetricsOverrideParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetDeviceMetricsOverride, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Emulation.setDeviceMetricsOverride against the provided context.","result":"Set device metrics.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetScrollbarsHiddenParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetScrollbarsHidden, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Emulation.setScrollbarsHidden against the provided context.","result":"Set scrollbars visibility.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetDocumentCookieDisabledParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetDocumentCookieDisabled, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Emulation.setDocumentCookieDisabled against the provided context.","result":"Set document cookie disabled.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetEmitTouchEventsForMouseParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetEmitTouchEventsForMouse, p, nil)\r\n}","code-length":59,"reference":"\/\/ Do executes Emulation.setEmitTouchEventsForMouse against the provided context.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetEmulatedMediaParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetEmulatedMedia, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Emulation.setEmulatedMedia against the provided context.","result":"Set emulated media.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetGeolocationOverrideParams) WithLatitude(latitude float64) *SetGeolocationOverrideParams {\r\n\tp.Latitude = latitude\r\n\treturn &p\r\n}","code-length":51,"reference":"\/\/ WithLatitude mock latitude.","result":"Set the latitude of the location.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetGeolocationOverrideParams) WithLongitude(longitude float64) *SetGeolocationOverrideParams {\r\n\tp.Longitude = longitude\r\n\treturn &p\r\n}","code-length":51,"reference":"\/\/ WithLongitude mock longitude.","result":"Set the longitude parameter.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetGeolocationOverrideParams) WithAccuracy(accuracy float64) *SetGeolocationOverrideParams {\r\n\tp.Accuracy = accuracy\r\n\treturn &p\r\n}","code-length":53,"reference":"\/\/ WithAccuracy mock accuracy.","result":"Set the location.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetGeolocationOverrideParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetGeolocationOverride, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Emulation.setGeolocationOverride against the provided context.","result":"Set the location of the location of the location.","score":[0.1219,0.1235]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetPageScaleFactorParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetPageScaleFactor, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Emulation.setPageScaleFactor against the provided context.","result":"Set the page scale factor.","score":[0.1319,0.1299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetScriptExecutionDisabledParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetScriptExecutionDisabled, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Emulation.setScriptExecutionDisabled against the provided context.","result":"Set script execution disabled.","score":[0,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetTouchEmulationEnabledParams) WithMaxTouchPoints(maxTouchPoints int64) *SetTouchEmulationEnabledParams {\r\n\tp.MaxTouchPoints = maxTouchPoints\r\n\treturn &p\r\n}","code-length":59,"reference":"\/\/ WithMaxTouchPoints maximum touch points supported. Defaults to one.","result":"Set the touch emulation enabled.","score":[0.108,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetTouchEmulationEnabledParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetTouchEmulationEnabled, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Emulation.setTouchEmulationEnabled against the provided context.","result":"Set touch emulation enabled.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetVirtualTimePolicyParams) WithBudget(budget float64) *SetVirtualTimePolicyParams {\r\n\tp.Budget = budget\r\n\treturn &p\r\n}","code-length":50,"reference":"\/\/ WithBudget if set, after this many virtual milliseconds have elapsed\n\/\/ virtual time will be paused and a virtualTimeBudgetExpired event is sent.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetVirtualTimePolicyParams) WithMaxVirtualTimeTaskStarvationCount(maxVirtualTimeTaskStarvationCount int64) *SetVirtualTimePolicyParams {\r\n\tp.MaxVirtualTimeTaskStarvationCount = maxVirtualTimeTaskStarvationCount\r\n\treturn &p\r\n}","code-length":73,"reference":"\/\/ WithMaxVirtualTimeTaskStarvationCount if set this specifies the maximum\n\/\/ number of tasks that can be run before virtual is forced forwards to prevent\n\/\/ deadlock.","result":"Set the max virtual time task starvation count.","score":[0.0197,0.0858]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetVirtualTimePolicyParams) WithWaitForNavigation(waitForNavigation bool) *SetVirtualTimePolicyParams {\r\n\tp.WaitForNavigation = waitForNavigation\r\n\treturn &p\r\n}","code-length":53,"reference":"\/\/ WithWaitForNavigation if set the virtual time policy change should be\n\/\/ deferred until any frame starts navigating. Note any previous deferred policy\n\/\/ change is superseded.","result":"Set the time policy.","score":[0.0012,0.1035]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetUserAgentOverrideParams) WithAcceptLanguage(acceptLanguage string) *SetUserAgentOverrideParams {\r\n\tp.AcceptLanguage = acceptLanguage\r\n\treturn &p\r\n}","code-length":49,"reference":"\/\/ WithAcceptLanguage browser langugage to emulate.","result":"Set the AcceptLanguage parameter.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetUserAgentOverrideParams) WithPlatform(platform string) *SetUserAgentOverrideParams {\r\n\tp.Platform = platform\r\n\treturn &p\r\n}","code-length":46,"reference":"\/\/ WithPlatform the platform navigator.platform should return.","result":"Set the platform .","score":[0.2134,0.2799]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetUserAgentOverrideParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetUserAgentOverride, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Emulation.setUserAgentOverride against the provided context.","result":"Set the user agent.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *DispatchKeyEventParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandDispatchKeyEvent, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Input.dispatchKeyEvent against the provided context.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *InsertTextParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandInsertText, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Input.insertText against the provided context.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p DispatchMouseEventParams) WithButtons(buttons int64) *DispatchMouseEventParams {\r\n\tp.Buttons = buttons\r\n\treturn &p\r\n}","code-length":47,"reference":"\/\/ WithButtons a number indicating which buttons are pressed on the mouse\n\/\/ when a mouse event is triggered. Left=1, Right=2, Middle=4, Back=8,\n\/\/ Forward=16, None=0.","result":"Create a new function.","score":[0.0013,0.021]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *DispatchMouseEventParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandDispatchMouseEvent, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Input.dispatchMouseEvent against the provided context.","result":"Dispatch mouse events.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *DispatchTouchEventParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandDispatchTouchEvent, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Input.dispatchTouchEvent against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *EmulateTouchFromMouseEventParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandEmulateTouchFromMouseEvent, p, nil)\r\n}","code-length":59,"reference":"\/\/ Do executes Input.emulateTouchFromMouseEvent against the provided context.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetIgnoreInputEventsParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetIgnoreInputEvents, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Input.setIgnoreInputEvents against the provided context.","result":"Set ignore input events.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SynthesizePinchGestureParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSynthesizePinchGesture, p, nil)\r\n}","code-length":61,"reference":"\/\/ Do executes Input.synthesizePinchGesture against the provided context.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SynthesizeScrollGestureParams) WithXOverscroll(xOverscroll float64) *SynthesizeScrollGestureParams {\r\n\tp.XOverscroll = xOverscroll\r\n\treturn &p\r\n}","code-length":69,"reference":"\/\/ WithXOverscroll the number of additional pixels to scroll back along the X\n\/\/ axis, in addition to the given distance.","result":"Generate code that generates code that generates code that generates code that generates code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SynthesizeScrollGestureParams) WithYOverscroll(yOverscroll float64) *SynthesizeScrollGestureParams {\r\n\tp.YOverscroll = yOverscroll\r\n\treturn &p\r\n}","code-length":69,"reference":"\/\/ WithYOverscroll the number of additional pixels to scroll back along the Y\n\/\/ axis, in addition to the given distance.","result":"Generate code that generates code that generates code that generates code that generates code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SynthesizeScrollGestureParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSynthesizeScrollGesture, p, nil)\r\n}","code-length":59,"reference":"\/\/ Do executes Input.synthesizeScrollGesture against the provided context.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SynthesizeTapGestureParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSynthesizeTapGesture, p, nil)\r\n}","code-length":59,"reference":"\/\/ Do executes Input.synthesizeTapGesture against the provided context.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t MethodType) Domain() string {\r\n\treturn string(t[:strings.IndexByte(string(t), '.')])\r\n}","code-length":42,"reference":"\/\/ Domain returns the Chrome DevTools Protocol domain of the event or command.","result":"Generate the generated code.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p GetEventListenersParams) WithDepth(depth int64) *GetEventListenersParams {\r\n\tp.Depth = depth\r\n\treturn &p\r\n}","code-length":45,"reference":"\/\/ WithDepth the maximum depth at which Node children should be retrieved,\n\/\/ defaults to 1. Use -1 for the entire subtree or provide an integer larger\n\/\/ than 0.","result":"Get events from the server.","score":[0.0016,0.0182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *RemoveDOMBreakpointParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandRemoveDOMBreakpoint, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes DOMDebugger.removeDOMBreakpoint against the provided context.","result":"Remove the DOM breakpoint.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p RemoveEventListenerBreakpointParams) WithTargetName(targetName string) *RemoveEventListenerBreakpointParams {\r\n\tp.TargetName = targetName\r\n\treturn &p\r\n}","code-length":49,"reference":"\/\/ WithTargetName eventTarget interface name.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *RemoveEventListenerBreakpointParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandRemoveEventListenerBreakpoint, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes DOMDebugger.removeEventListenerBreakpoint against the provided context.","result":"Remove event listeners.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *RemoveInstrumentationBreakpointParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandRemoveInstrumentationBreakpoint, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes DOMDebugger.removeInstrumentationBreakpoint against the provided context.","result":"Remove the breakpoint.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *RemoveXHRBreakpointParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandRemoveXHRBreakpoint, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes DOMDebugger.removeXHRBreakpoint against the provided context.","result":"Remove the XHR breakpoint.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetDOMBreakpointParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetDOMBreakpoint, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes DOMDebugger.setDOMBreakpoint against the provided context.","result":"Set the DOM breakpoint.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetEventListenerBreakpointParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetEventListenerBreakpoint, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes DOMDebugger.setEventListenerBreakpoint against the provided context.","result":"Set the event listener breakpoint.","score":[0.1319,0.1299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetInstrumentationBreakpointParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetInstrumentationBreakpoint, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes DOMDebugger.setInstrumentationBreakpoint against the provided context.","result":"Set the breakpoint of the instrumentation.","score":[0.1383,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetXHRBreakpointParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetXHRBreakpoint, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes DOMDebugger.setXHRBreakpoint against the provided context.","result":"Set the XHR breakpoint.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WithExecutor(parent context.Context, executor Executor) context.Context {\r\n\treturn context.WithValue(parent, executorKey, executor)\r\n}","code-length":44,"reference":"\/\/ WithExecutor sets the message executor for the context.","result":"Create a new executor.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Execute(ctx context.Context, method string, params easyjson.Marshaler, res easyjson.Unmarshaler) error {\r\n\tif executor := ctx.Value(executorKey); executor != nil {\r\n\t\treturn executor.(Executor).Execute(ctx, method, params, res)\r\n\t}\r\n\treturn ErrInvalidContext\r\n}","code-length":84,"reference":"\/\/ Execute uses the context's message executor to send a command or event\n\/\/ method marshaling the provided parameters, and unmarshaling to res.","result":"Execute the method .","score":[0.0036,0.0711]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *Node) AttributeValue(name string) string {\r\n\tn.RLock()\r\n\tdefer n.RUnlock()\r\n\tfor i := 0; i < len(n.Attributes); i += 2 {\r\n\t\tif n.Attributes[i] == name {\r\n\t\t\treturn n.Attributes[i+1]\r\n\t\t}\r\n\t}\r\n\treturn \"\"\r\n}","code-length":103,"reference":"\/\/ AttributeValue returns the named attribute for the node.","result":"Check if the node has an attribute.","score":[0.1214,0.0568]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *Node) xpath(stopAtDocument, stopAtID bool) string {\r\n\tn.RLock()\r\n\tdefer n.RUnlock()\r\n\tp := \"\"\r\n\tpos := \"\"\r\n\tid := n.AttributeValue(\"id\")\r\n\tswitch {\r\n\tcase n.Parent == nil:\r\n\t\treturn n.LocalName\r\n\tcase stopAtDocument && n.NodeType == NodeTypeDocument:\r\n\t\treturn \"\"\r\n\tcase stopAtID && id != \"\":\r\n\t\tp = \"\/\"\r\n\t\tpos = `[@id='` + id + `']`\r\n\tcase n.Parent != nil:\r\n\t\tvar i int\r\n\t\tvar found bool\r\n\t\tn.Parent.RLock()\r\n\t\tfor j := 0; j < len(n.Parent.Children); j++ {\r\n\t\t\tif n.Parent.Children[j].LocalName == n.LocalName {\r\n\t\t\t\ti++\r\n\t\t\t}\r\n\t\t\tif n.Parent.Children[j].NodeID == n.NodeID {\r\n\t\t\t\tfound = true\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tn.Parent.RUnlock()\r\n\t\tif found {\r\n\t\t\tpos = \"[\" + strconv.Itoa(i) + \"]\"\r\n\t\t}\r\n\t\tp = n.Parent.xpath(stopAtDocument, stopAtID)\r\n\t}\r\n\treturn p + \"\/\" + n.LocalName + pos\r\n}","code-length":356,"reference":"\/\/ xpath builds the xpath string.","result":"Prevent recursive call .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t NodeType) String() string {\r\n\tswitch t {\r\n\tcase NodeTypeElement:\r\n\t\treturn \"Element\"\r\n\tcase NodeTypeAttribute:\r\n\t\treturn \"Attribute\"\r\n\tcase NodeTypeText:\r\n\t\treturn \"Text\"\r\n\tcase NodeTypeCDATA:\r\n\t\treturn \"CDATA\"\r\n\tcase NodeTypeEntityReference:\r\n\t\treturn \"EntityReference\"\r\n\tcase NodeTypeEntity:\r\n\t\treturn \"Entity\"\r\n\tcase NodeTypeProcessingInstruction:\r\n\t\treturn \"ProcessingInstruction\"\r\n\tcase NodeTypeComment:\r\n\t\treturn \"Comment\"\r\n\tcase NodeTypeDocument:\r\n\t\treturn \"Document\"\r\n\tcase NodeTypeDocumentType:\r\n\t\treturn \"DocumentType\"\r\n\tcase NodeTypeDocumentFragment:\r\n\t\treturn \"DocumentFragment\"\r\n\tcase NodeTypeNotation:\r\n\t\treturn \"Notation\"\r\n\t}\r\n\treturn fmt.Sprintf(\"NodeType(%d)\", t)\r\n}","code-length":235,"reference":"\/\/ String returns the NodeType as string value.","result":"Avoid recursion.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetSinkToUseParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetSinkToUse, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Cast.setSinkToUse against the provided context.","result":"Set the sink to use.","score":[0.1319,0.1299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StartTabMirroringParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStartTabMirroring, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Cast.startTabMirroring against the provided context.","result":"Start a new tab mirror.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StopCastingParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStopCasting, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Cast.stopCasting against the provided context.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StartObservingParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStartObserving, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes BackgroundService.startObserving against the provided context.","result":"Start observing.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StopObservingParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStopObserving, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes BackgroundService.stopObserving against the provided context.","result":"Stop the observing.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetRecordingParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetRecording, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes BackgroundService.setRecording against the provided context.","result":"Set the recording.","score":[0.0771,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ClearEventsParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandClearEvents, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes BackgroundService.clearEvents against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p CallFunctionOnParams) WithObjectID(objectID RemoteObjectID) *CallFunctionOnParams {\r\n\tp.ObjectID = objectID\r\n\treturn &p\r\n}","code-length":48,"reference":"\/\/ WithObjectID identifier of the object to call function on. Either objectId\n\/\/ or executionContextId should be specified.","result":"Generate the generated code.","score":[0.0096,0.0301]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p CallFunctionOnParams) WithArguments(arguments []*CallArgument) *CallFunctionOnParams {\r\n\tp.Arguments = arguments\r\n\treturn &p\r\n}","code-length":49,"reference":"\/\/ WithArguments call arguments. All call arguments must belong to the same\n\/\/ JavaScript world as the target object.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p CallFunctionOnParams) WithExecutionContextID(executionContextID ExecutionContextID) *CallFunctionOnParams {\r\n\tp.ExecutionContextID = executionContextID\r\n\treturn &p\r\n}","code-length":55,"reference":"\/\/ WithExecutionContextID specifies execution context which global object\n\/\/ will be used to call function on. Either executionContextId or objectId\n\/\/ should be specified.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p CallFunctionOnParams) WithObjectGroup(objectGroup string) *CallFunctionOnParams {\r\n\tp.ObjectGroup = objectGroup\r\n\treturn &p\r\n}","code-length":50,"reference":"\/\/ WithObjectGroup symbolic group name that can be used to release multiple\n\/\/ objects. If objectGroup is not specified and objectId is, objectGroup will be\n\/\/ inherited from object.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *DiscardConsoleEntriesParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandDiscardConsoleEntries, nil, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Runtime.discardConsoleEntries against the provided context.","result":"Discard console entries.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p EvaluateParams) WithContextID(contextID ExecutionContextID) *EvaluateParams {\r\n\tp.ContextID = contextID\r\n\treturn &p\r\n}","code-length":47,"reference":"\/\/ WithContextID specifies in which execution context to perform evaluation.\n\/\/ If the parameter is omitted the evaluation will be performed in the context\n\/\/ of the inspected page.","result":"Create a new function.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p GetPropertiesParams) WithOwnProperties(ownProperties bool) *GetPropertiesParams {\r\n\tp.OwnProperties = ownProperties\r\n\treturn &p\r\n}","code-length":48,"reference":"\/\/ WithOwnProperties if true, returns properties belonging only to the\n\/\/ element itself, not to its prototype chain.","result":"Generate the code for generating the code.","score":[0.0336,0.0296]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p GetPropertiesParams) WithGeneratePreview(generatePreview bool) *GetPropertiesParams {\r\n\tp.GeneratePreview = generatePreview\r\n\treturn &p\r\n}","code-length":48,"reference":"\/\/ WithGeneratePreview whether preview should be generated for the results.","result":"Generate the code.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p GlobalLexicalScopeNamesParams) WithExecutionContextID(executionContextID ExecutionContextID) *GlobalLexicalScopeNamesParams {\r\n\tp.ExecutionContextID = executionContextID\r\n\treturn &p\r\n}","code-length":59,"reference":"\/\/ WithExecutionContextID specifies in which execution context to lookup\n\/\/ global scope variables.","result":"Generate code for generating the template.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p QueryObjectsParams) WithObjectGroup(objectGroup string) *QueryObjectsParams {\r\n\tp.ObjectGroup = objectGroup\r\n\treturn &p\r\n}","code-length":48,"reference":"\/\/ WithObjectGroup symbolic group name that can be used to release the\n\/\/ results.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ReleaseObjectParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandReleaseObject, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Runtime.releaseObject against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ReleaseObjectGroupParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandReleaseObjectGroup, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Runtime.releaseObjectGroup against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *RunIfWaitingForDebuggerParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandRunIfWaitingForDebugger, nil, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Runtime.runIfWaitingForDebugger against the provided context.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetCustomObjectFormatterEnabledParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetCustomObjectFormatterEnabled, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Runtime.setCustomObjectFormatterEnabled against the provided context.","result":"Set custom object formatter enabled.","score":[0,0.0649]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetMaxCallStackSizeToCaptureParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetMaxCallStackSizeToCapture, p, nil)\r\n}","code-length":59,"reference":"\/\/ Do executes Runtime.setMaxCallStackSizeToCapture against the provided context.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *TerminateExecutionParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandTerminateExecution, nil, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Runtime.terminateExecution against the provided context.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *AddBindingParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandAddBinding, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Runtime.addBinding against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *RemoveBindingParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandRemoveBinding, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Runtime.removeBinding against the provided context.","result":"Remove the comment.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *EndParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandEnd, nil, nil)\r\n}","code-length":49,"reference":"\/\/ Do executes Tracing.end against the provided context.","result":"Generate the end params.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *RecordClockSyncMarkerParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandRecordClockSyncMarker, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Tracing.recordClockSyncMarker against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p StartParams) WithBufferUsageReportingInterval(bufferUsageReportingInterval float64) *StartParams {\r\n\tp.BufferUsageReportingInterval = bufferUsageReportingInterval\r\n\treturn &p\r\n}","code-length":55,"reference":"\/\/ WithBufferUsageReportingInterval if set, the agent will issue bufferUsage\n\/\/ events at this interval, specified in milliseconds.","result":"Create a new instance of the service.","score":[0.0387,0.0312]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p BeginFrameParams) WithNoDisplayUpdates(noDisplayUpdates bool) *BeginFrameParams {\r\n\tp.NoDisplayUpdates = noDisplayUpdates\r\n\treturn &p\r\n}","code-length":52,"reference":"\/\/ WithNoDisplayUpdates whether updates should not be committed and drawn\n\/\/ onto the display. False by default. If true, only side effects of the\n\/\/ BeginFrame will be run, such as layout and animations, but any visual updates\n\/\/ may not be visible on the display or in screenshots.","result":"Create a new function.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p BeginFrameParams) WithScreenshot(screenshot *ScreenshotParams) *BeginFrameParams {\r\n\tp.Screenshot = screenshot\r\n\treturn &p\r\n}","code-length":46,"reference":"\/\/ WithScreenshot if set, a screenshot of the frame will be captured and\n\/\/ returned in the response. Otherwise, no screenshot will be captured. Note\n\/\/ that capturing a screenshot can fail, for example, during renderer\n\/\/ initialization. In such a case, no screenshot data will be returned.","result":"Create a new function.","score":[0.0,0.0115]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *BringToFrontParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandBringToFront, nil, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Page.bringToFront against the provided context.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p CaptureScreenshotParams) WithClip(clip *Viewport) *CaptureScreenshotParams {\r\n\tp.Clip = clip\r\n\treturn &p\r\n}","code-length":45,"reference":"\/\/ WithClip capture the screenshot of a given region only.","result":"Generate the code.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p CaptureScreenshotParams) WithFromSurface(fromSurface bool) *CaptureScreenshotParams {\r\n\tp.FromSurface = fromSurface\r\n\treturn &p\r\n}","code-length":48,"reference":"\/\/ WithFromSurface capture the screenshot from the surface, rather than the\n\/\/ view. Defaults to true.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p CreateIsolatedWorldParams) WithWorldName(worldName string) *CreateIsolatedWorldParams {\r\n\tp.WorldName = worldName\r\n\treturn &p\r\n}","code-length":52,"reference":"\/\/ WithWorldName an optional name which is reported in the Execution Context.","result":"Generate the code.","score":[0.0203,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p CreateIsolatedWorldParams) WithGrantUniveralAccess(grantUniveralAccess bool) *CreateIsolatedWorldParams {\r\n\tp.GrantUniveralAccess = grantUniveralAccess\r\n\treturn &p\r\n}","code-length":64,"reference":"\/\/ WithGrantUniveralAccess whether or not universal access should be granted\n\/\/ to the isolated world. This is a powerful option, use with caution.","result":"Create the isolated world.","score":[0.0057,0.1395]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ResetNavigationHistoryParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandResetNavigationHistory, nil, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Page.resetNavigationHistory against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p HandleJavaScriptDialogParams) WithPromptText(promptText string) *HandleJavaScriptDialogParams {\r\n\tp.PromptText = promptText\r\n\treturn &p\r\n}","code-length":50,"reference":"\/\/ WithPromptText the text to enter into the dialog prompt before accepting.\n\/\/ Used only if this is a prompt dialog.","result":"Generate code for the generated code.","score":[0.0158,0.0256]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *HandleJavaScriptDialogParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandHandleJavaScriptDialog, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Page.handleJavaScriptDialog against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p NavigateParams) WithReferrer(referrer string) *NavigateParams {\r\n\tp.Referrer = referrer\r\n\treturn &p\r\n}","code-length":47,"reference":"\/\/ WithReferrer referrer URL.","result":"Set the referrer.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p NavigateParams) WithTransitionType(transitionType TransitionType) *NavigateParams {\r\n\tp.TransitionType = transitionType\r\n\treturn &p\r\n}","code-length":49,"reference":"\/\/ WithTransitionType intended transition type.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p NavigateParams) WithFrameID(frameID cdp.FrameID) *NavigateParams {\r\n\tp.FrameID = frameID\r\n\treturn &p\r\n}","code-length":52,"reference":"\/\/ WithFrameID frame id to navigate, if not specified navigates the top\n\/\/ frame.","result":"Generate code for the generated code.","score":[0.0509,0.0379]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *NavigateToHistoryEntryParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandNavigateToHistoryEntry, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Page.navigateToHistoryEntry against the provided context.","result":"Navigate to history entry.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p PrintToPDFParams) WithLandscape(landscape bool) *PrintToPDFParams {\r\n\tp.Landscape = landscape\r\n\treturn &p\r\n}","code-length":50,"reference":"\/\/ WithLandscape paper orientation. Defaults to false.","result":"Print to the screen.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p PrintToPDFParams) WithDisplayHeaderFooter(displayHeaderFooter bool) *PrintToPDFParams {\r\n\tp.DisplayHeaderFooter = displayHeaderFooter\r\n\treturn &p\r\n}","code-length":54,"reference":"\/\/ WithDisplayHeaderFooter display header and footer. Defaults to false.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p PrintToPDFParams) WithPrintBackground(printBackground bool) *PrintToPDFParams {\r\n\tp.PrintBackground = printBackground\r\n\treturn &p\r\n}","code-length":50,"reference":"\/\/ WithPrintBackground print background graphics. Defaults to false.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p PrintToPDFParams) WithScale(scale float64) *PrintToPDFParams {\r\n\tp.Scale = scale\r\n\treturn &p\r\n}","code-length":47,"reference":"\/\/ WithScale scale of the webpage rendering. Defaults to 1.","result":"Print to pdf.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p PrintToPDFParams) WithPaperWidth(paperWidth float64) *PrintToPDFParams {\r\n\tp.PaperWidth = paperWidth\r\n\treturn &p\r\n}","code-length":51,"reference":"\/\/ WithPaperWidth paper width in inches. Defaults to 8.5 inches.","result":"Print to the screen.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p PrintToPDFParams) WithPaperHeight(paperHeight float64) *PrintToPDFParams {\r\n\tp.PaperHeight = paperHeight\r\n\treturn &p\r\n}","code-length":51,"reference":"\/\/ WithPaperHeight paper height in inches. Defaults to 11 inches.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p PrintToPDFParams) WithIgnoreInvalidPageRanges(ignoreInvalidPageRanges bool) *PrintToPDFParams {\r\n\tp.IgnoreInvalidPageRanges = ignoreInvalidPageRanges\r\n\treturn &p\r\n}","code-length":58,"reference":"\/\/ WithIgnoreInvalidPageRanges whether to silently ignore invalid but\n\/\/ successfully parsed page ranges, such as '3-2'. Defaults to false.","result":"Print to the screen.","score":[0.0075,0.0286]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p PrintToPDFParams) WithFooterTemplate(footerTemplate string) *PrintToPDFParams {\r\n\tp.FooterTemplate = footerTemplate\r\n\treturn &p\r\n}","code-length":50,"reference":"\/\/ WithFooterTemplate HTML template for the print footer. Should use the same\n\/\/ format as the headerTemplate.","result":"Generate the generated code.","score":[0.0124,0.0318]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p PrintToPDFParams) WithPreferCSSPageSize(preferCSSPageSize bool) *PrintToPDFParams {\r\n\tp.PreferCSSPageSize = preferCSSPageSize\r\n\treturn &p\r\n}","code-length":57,"reference":"\/\/ WithPreferCSSPageSize whether or not to prefer page size as defined by\n\/\/ css. Defaults to false, in which case the content will be scaled to fit the\n\/\/ paper size.","result":"Print html.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p ReloadParams) WithScriptToEvaluateOnLoad(scriptToEvaluateOnLoad string) *ReloadParams {\r\n\tp.ScriptToEvaluateOnLoad = scriptToEvaluateOnLoad\r\n\treturn &p\r\n}","code-length":58,"reference":"\/\/ WithScriptToEvaluateOnLoad if set, the script will be injected into all\n\/\/ frames of the inspected page after reload. Argument will be ignored if\n\/\/ reloading dataURL origin.","result":"Generate the code.","score":[0.0001,0.0196]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ReloadParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandReload, p, nil)\r\n}","code-length":49,"reference":"\/\/ Do executes Page.reload against the provided context.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *RemoveScriptToEvaluateOnNewDocumentParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandRemoveScriptToEvaluateOnNewDocument, p, nil)\r\n}","code-length":61,"reference":"\/\/ Do executes Page.removeScriptToEvaluateOnNewDocument against the provided context.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ScreencastFrameAckParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandScreencastFrameAck, p, nil)\r\n}","code-length":59,"reference":"\/\/ Do executes Page.screencastFrameAck against the provided context.","result":"Send the frame ack.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetAdBlockingEnabledParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetAdBlockingEnabled, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Page.setAdBlockingEnabled against the provided context.","result":"Set the ad blocking enabled flag.","score":[0.1383,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetBypassCSPParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetBypassCSP, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Page.setBypassCSP against the provided context.","result":"Set bypass.","score":[0,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetFontFamiliesParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetFontFamilies, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Page.setFontFamilies against the provided context.","result":"Set font families.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetFontSizesParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetFontSizes, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Page.setFontSizes against the provided context.","result":"Set font sizes.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetDocumentContentParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetDocumentContent, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Page.setDocumentContent against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetDownloadBehaviorParams) WithDownloadPath(downloadPath string) *SetDownloadBehaviorParams {\r\n\tp.DownloadPath = downloadPath\r\n\treturn &p\r\n}","code-length":50,"reference":"\/\/ WithDownloadPath the default path to save downloaded files to. This is\n\/\/ required if behavior is set to 'allow'.","result":"Set the download behavior.","score":[0.0059,0.0815]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetDownloadBehaviorParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetDownloadBehavior, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Page.setDownloadBehavior against the provided context.","result":"Set the download behavior.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetLifecycleEventsEnabledParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetLifecycleEventsEnabled, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Page.setLifecycleEventsEnabled against the provided context.","result":"Set the lifecycle events enabled flag.","score":[0.1383,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p StartScreencastParams) WithFormat(format ScreencastFormat) *StartScreencastParams {\r\n\tp.Format = format\r\n\treturn &p\r\n}","code-length":54,"reference":"\/\/ WithFormat image compression format.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p StartScreencastParams) WithMaxWidth(maxWidth int64) *StartScreencastParams {\r\n\tp.MaxWidth = maxWidth\r\n\treturn &p\r\n}","code-length":54,"reference":"\/\/ WithMaxWidth maximum screenshot width.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p StartScreencastParams) WithMaxHeight(maxHeight int64) *StartScreencastParams {\r\n\tp.MaxHeight = maxHeight\r\n\treturn &p\r\n}","code-length":54,"reference":"\/\/ WithMaxHeight maximum screenshot height.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p StartScreencastParams) WithEveryNthFrame(everyNthFrame int64) *StartScreencastParams {\r\n\tp.EveryNthFrame = everyNthFrame\r\n\treturn &p\r\n}","code-length":63,"reference":"\/\/ WithEveryNthFrame send every n-th frame.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StartScreencastParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStartScreencast, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Page.startScreencast against the provided context.","result":"Start the screenc.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StopLoadingParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStopLoading, nil, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Page.stopLoading against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetWebLifecycleStateParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetWebLifecycleState, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Page.setWebLifecycleState against the provided context.","result":"Set the state of the web application.","score":[0.14,0.1266]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StopScreencastParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStopScreencast, nil, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Page.stopScreencast against the provided context.","result":"Stop the screenc.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetProduceCompilationCacheParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetProduceCompilationCache, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Page.setProduceCompilationCache against the provided context.","result":"Set the produce compilation cache.","score":[0.1319,0.1299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *AddCompilationCacheParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandAddCompilationCache, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Page.addCompilationCache against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ClearCompilationCacheParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandClearCompilationCache, nil, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Page.clearCompilationCache against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p GenerateTestReportParams) WithGroup(group string) *GenerateTestReportParams {\r\n\tp.Group = group\r\n\treturn &p\r\n}","code-length":46,"reference":"\/\/ WithGroup specifies the endpoint group to deliver the report to.","result":"Generate test report .","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *WaitForDebuggerParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandWaitForDebugger, nil, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Page.waitForDebugger against the provided context.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ActivateTargetParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandActivateTarget, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Target.activateTarget against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p ExposeDevToolsProtocolParams) WithBindingName(bindingName string) *ExposeDevToolsProtocolParams {\r\n\tp.BindingName = bindingName\r\n\treturn &p\r\n}","code-length":54,"reference":"\/\/ WithBindingName binding name, 'cdp' if not specified.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ExposeDevToolsProtocolParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandExposeDevToolsProtocol, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Target.exposeDevToolsProtocol against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p CreateTargetParams) WithBrowserContextID(browserContextID BrowserContextID) *CreateTargetParams {\r\n\tp.BrowserContextID = browserContextID\r\n\treturn &p\r\n}","code-length":54,"reference":"\/\/ WithBrowserContextID the browser context to create the page in.","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p DetachFromTargetParams) WithSessionID(sessionID SessionID) *DetachFromTargetParams {\r\n\tp.SessionID = sessionID\r\n\treturn &p\r\n}","code-length":49,"reference":"\/\/ WithSessionID session to detach.","result":"Remove the temporary file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *DetachFromTargetParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandDetachFromTarget, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Target.detachFromTarget against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *DisposeBrowserContextParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandDisposeBrowserContext, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Target.disposeBrowserContext against the provided context.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SendMessageToTargetParams) WithSessionID(sessionID SessionID) *SendMessageToTargetParams {\r\n\tp.SessionID = sessionID\r\n\treturn &p\r\n}","code-length":50,"reference":"\/\/ WithSessionID identifier of the session.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SendMessageToTargetParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSendMessageToTarget, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Target.sendMessageToTarget against the provided context.","result":"Send a message to a target.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetAutoAttachParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetAutoAttach, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Target.setAutoAttach against the provided context.","result":"Set the auto attach mode.","score":[0.1319,0.1299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetDiscoverTargetsParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetDiscoverTargets, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Target.setDiscoverTargets against the provided context.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetRemoteLocationsParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetRemoteLocations, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Target.setRemoteLocations against the provided context.","result":"Set remote locations.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p EnableParams) WithPatterns(patterns []*RequestPattern) *EnableParams {\r\n\tp.Patterns = patterns\r\n\treturn &p\r\n}","code-length":45,"reference":"\/\/ WithPatterns if specified, only requests matching any of these patterns\n\/\/ will produce fetchRequested event and will be paused until clients response.\n\/\/ If not set, all requests will be affected.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p EnableParams) WithHandleAuthRequests(handleAuthRequests bool) *EnableParams {\r\n\tp.HandleAuthRequests = handleAuthRequests\r\n\treturn &p\r\n}","code-length":50,"reference":"\/\/ WithHandleAuthRequests if true, authRequired events will be issued and\n\/\/ requests will be paused expecting a call to continueWithAuth.","result":"Enable.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *FailRequestParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandFailRequest, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Fetch.failRequest against the provided context.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p FulfillRequestParams) WithBody(body string) *FulfillRequestParams {\r\n\tp.Body = body\r\n\treturn &p\r\n}","code-length":47,"reference":"\/\/ WithBody a response body.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p FulfillRequestParams) WithResponsePhrase(responsePhrase string) *FulfillRequestParams {\r\n\tp.ResponsePhrase = responsePhrase\r\n\treturn &p\r\n}","code-length":51,"reference":"\/\/ WithResponsePhrase a textual representation of responseCode. If absent, a\n\/\/ standard phrase mathcing responseCode is used.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *FulfillRequestParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandFulfillRequest, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Fetch.fulfillRequest against the provided context.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p ContinueRequestParams) WithURL(url string) *ContinueRequestParams {\r\n\tp.URL = url\r\n\treturn &p\r\n}","code-length":44,"reference":"\/\/ WithURL if set, the request url will be modified in a way that's not\n\/\/ observable by page.","result":"Create a new function.","score":[0.0075,0.0286]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p ContinueRequestParams) WithMethod(method string) *ContinueRequestParams {\r\n\tp.Method = method\r\n\treturn &p\r\n}","code-length":44,"reference":"\/\/ WithMethod if set, the request method is overridden.","result":"Create a new function.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p ContinueRequestParams) WithPostData(postData string) *ContinueRequestParams {\r\n\tp.PostData = postData\r\n\treturn &p\r\n}","code-length":47,"reference":"\/\/ WithPostData if set, overrides the post data in the request.","result":"Create a new function.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p ContinueRequestParams) WithHeaders(headers []*HeaderEntry) *ContinueRequestParams {\r\n\tp.Headers = headers\r\n\treturn &p\r\n}","code-length":47,"reference":"\/\/ WithHeaders if set, overrides the request headrts.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ContinueRequestParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandContinueRequest, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Fetch.continueRequest against the provided context.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ContinueWithAuthParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandContinueWithAuth, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Fetch.continueWithAuth against the provided context.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ContinueToLocationParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandContinueToLocation, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Debugger.continueToLocation against the provided context.","result":"Continue to location.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p EvaluateOnCallFrameParams) WithIncludeCommandLineAPI(includeCommandLineAPI bool) *EvaluateOnCallFrameParams {\r\n\tp.IncludeCommandLineAPI = includeCommandLineAPI\r\n\treturn &p\r\n}","code-length":56,"reference":"\/\/ WithIncludeCommandLineAPI specifies whether command line API should be\n\/\/ available to the evaluated expression, defaults to false.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PauseParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandPause, nil, nil)\r\n}","code-length":49,"reference":"\/\/ Do executes Debugger.pause against the provided context.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *PauseOnAsyncCallParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandPauseOnAsyncCall, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Debugger.pauseOnAsyncCall against the provided context.","result":"Pause on async call.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *RemoveBreakpointParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandRemoveBreakpoint, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Debugger.removeBreakpoint against the provided context.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *ResumeParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandResume, nil, nil)\r\n}","code-length":49,"reference":"\/\/ Do executes Debugger.resume against the provided context.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetAsyncCallStackDepthParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetAsyncCallStackDepth, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Debugger.setAsyncCallStackDepth against the provided context.","result":"Set the async call stack depth.","score":[0.1383,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetBlackboxPatternsParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetBlackboxPatterns, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Debugger.setBlackboxPatterns against the provided context.","result":"Set the blacklist patterns.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetBlackboxedRangesParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetBlackboxedRanges, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Debugger.setBlackboxedRanges against the provided context.","result":"Set the range.","score":[0.0771,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetBreakpointByURLParams) WithURL(url string) *SetBreakpointByURLParams {\r\n\tp.URL = url\r\n\treturn &p\r\n}","code-length":48,"reference":"\/\/ WithURL URL of the resources to set breakpoint on.","result":"Set the breakpoint.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetBreakpointByURLParams) WithURLRegex(urlRegex string) *SetBreakpointByURLParams {\r\n\tp.URLRegex = urlRegex\r\n\treturn &p\r\n}","code-length":52,"reference":"\/\/ WithURLRegex regex pattern for the URLs of the resources to set\n\/\/ breakpoints on. Either url or urlRegex must be specified.","result":"Set the breakpoint.","score":[0.0007,0.0498]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetBreakpointByURLParams) WithScriptHash(scriptHash string) *SetBreakpointByURLParams {\r\n\tp.ScriptHash = scriptHash\r\n\treturn &p\r\n}","code-length":52,"reference":"\/\/ WithScriptHash script hash of the resources to set breakpoint on.","result":"Generate the generated code.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetBreakpointByURLParams) WithColumnNumber(columnNumber int64) *SetBreakpointByURLParams {\r\n\tp.ColumnNumber = columnNumber\r\n\treturn &p\r\n}","code-length":53,"reference":"\/\/ WithColumnNumber offset in the line to set breakpoint at.","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetBreakpointOnFunctionCallParams) WithCondition(condition string) *SetBreakpointOnFunctionCallParams {\r\n\tp.Condition = condition\r\n\treturn &p\r\n}","code-length":50,"reference":"\/\/ WithCondition expression to use as a breakpoint condition. When specified,\n\/\/ debugger will stop on the breakpoint if this expression evaluates to true.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetBreakpointsActiveParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetBreakpointsActive, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Debugger.setBreakpointsActive against the provided context.","result":"Set breakpoints active.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetPauseOnExceptionsParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetPauseOnExceptions, p, nil)\r\n}","code-length":55,"reference":"\/\/ Do executes Debugger.setPauseOnExceptions against the provided context.","result":"Set pause on exceptions.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetReturnValueParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetReturnValue, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Debugger.setReturnValue against the provided context.","result":"Set the return value.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p SetScriptSourceParams) WithDryRun(dryRun bool) *SetScriptSourceParams {\r\n\tp.DryRun = dryRun\r\n\treturn &p\r\n}","code-length":47,"reference":"\/\/ WithDryRun if true the change will not actually be applied. Dry run may be\n\/\/ used to get result description without actually modifying the code.","result":"Set the script source .","score":[0.0036,0.0209]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetSkipAllPausesParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetSkipAllPauses, p, nil)\r\n}","code-length":57,"reference":"\/\/ Do executes Debugger.setSkipAllPauses against the provided context.","result":"Set skip all clauses.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *SetVariableValueParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandSetVariableValue, p, nil)\r\n}","code-length":53,"reference":"\/\/ Do executes Debugger.setVariableValue against the provided context.","result":"Set the variable value.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p StepIntoParams) WithBreakOnAsyncCall(breakOnAsyncCall bool) *StepIntoParams {\r\n\tp.BreakOnAsyncCall = breakOnAsyncCall\r\n\treturn &p\r\n}","code-length":56,"reference":"\/\/ WithBreakOnAsyncCall debugger will issue additional Debugger.paused\n\/\/ notification if any async task is scheduled before next pause.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StepIntoParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStepInto, p, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Debugger.stepInto against the provided context.","result":"Generate code for the generated code.","score":[0.1383,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StepOutParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStepOut, nil, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Debugger.stepOut against the provided context.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *StepOverParams) Do(ctx context.Context) (err error) {\r\n\treturn cdp.Execute(ctx, CommandStepOver, nil, nil)\r\n}","code-length":51,"reference":"\/\/ Do executes Debugger.stepOver against the provided context.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (nb *NotifyBundle) Listen(n Network, a ma.Multiaddr) {\r\n\tif nb.ListenF != nil {\r\n\t\tnb.ListenF(n, a)\r\n\t}\r\n}","code-length":59,"reference":"\/\/ Listen calls ListenF if it is not null.","result":"Listen on a network.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (nb *NotifyBundle) ListenClose(n Network, a ma.Multiaddr) {\r\n\tif nb.ListenCloseF != nil {\r\n\t\tnb.ListenCloseF(n, a)\r\n\t}\r\n}","code-length":62,"reference":"\/\/ ListenClose calls ListenCloseF if it is not null.","result":"Listen for close events.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (nb *NotifyBundle) Connected(n Network, c Conn) {\r\n\tif nb.ConnectedF != nil {\r\n\t\tnb.ConnectedF(n, c)\r\n\t}\r\n}","code-length":57,"reference":"\/\/ Connected calls ConnectedF if it is not null.","result":"Notify the bundle that the bundle is connected.","score":[0.1226,0.0562]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (nb *NotifyBundle) Disconnected(n Network, c Conn) {\r\n\tif nb.DisconnectedF != nil {\r\n\t\tnb.DisconnectedF(n, c)\r\n\t}\r\n}","code-length":57,"reference":"\/\/ Disconnected calls DisconnectedF if it is not null.","result":"Avoid recursive calls to the notify bundle.","score":[0.1214,0.0568]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (nb *NotifyBundle) OpenedStream(n Network, s Stream) {\r\n\tif nb.OpenedStreamF != nil {\r\n\t\tnb.OpenedStreamF(n, s)\r\n\t}\r\n}","code-length":60,"reference":"\/\/ OpenedStream calls OpenedStreamF if it is not null.","result":"Notify the bundle.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (nb *NotifyBundle) ClosedStream(n Network, s Stream) {\r\n\tif nb.ClosedStreamF != nil {\r\n\t\tnb.ClosedStreamF(n, s)\r\n\t}\r\n}","code-length":59,"reference":"\/\/ ClosedStream calls ClosedStreamF if it is not null.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WithNoDial(ctx context.Context, reason string) context.Context {\r\n\treturn context.WithValue(ctx, noDial, reason)\r\n}","code-length":45,"reference":"\/\/ WithNoDial constructs a new context with an option that instructs the network\n\/\/ to not attempt a new dial when opening a stream.","result":"Generate the code.","score":[0.0004,0.0228]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetNoDial(ctx context.Context) (nodial bool, reason string) {\r\n\tv := ctx.Value(noDial)\r\n\tif v != nil {\r\n\t\treturn true, v.(string)\r\n\t}\r\n\treturn false, \"\"\r\n}","code-length":74,"reference":"\/\/ GetNoDial returns true if the no dial option is set in the context.","result":"Get the no dial value.","score":[0.0818,0.1951]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WithDialPeerTimeout(ctx context.Context, timeout time.Duration) context.Context {\r\n\treturn context.WithValue(ctx, dialPeerTimeoutCtxKey{}, timeout)\r\n}","code-length":52,"reference":"\/\/ WithDialPeerTimeout returns a new context with the DialPeer timeout applied.\n\/\/\n\/\/ This timeout overrides the default DialPeerTimeout and applies per-dial\n\/\/ independently.","result":"Set the dial peer timeout.","score":[0.0054,0.0226]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (drv *Driver) Open(name string) (driver.Conn, error) {\r\n\tconn, err := drv.Driver.Open(name)\r\n\tif err != nil {\r\n\t\treturn conn, err\r\n\t}\r\n\twrapped := &Conn{conn, drv.hooks}\r\n\tif isExecer(conn) && isQueryer(conn) && isSessionResetter(conn) {\r\n\t\treturn &ExecerQueryerContextWithSessionResetter{wrapped,\r\n\t\t\t&ExecerContext{wrapped}, &QueryerContext{wrapped},\r\n\t\t\t&SessionResetter{wrapped}}, nil\r\n\t} else if isExecer(conn) && isQueryer(conn) {\r\n\t\treturn &ExecerQueryerContext{wrapped, &ExecerContext{wrapped},\r\n\t\t\t&QueryerContext{wrapped}}, nil\r\n\t} else if isExecer(conn) {\r\n\t\t\r\n\t\t\r\n\t\treturn &ExecerContext{wrapped}, nil\r\n\t} else if isQueryer(conn) {\r\n\t\t\r\n\t\t\r\n\t\treturn &QueryerContext{wrapped}, nil\r\n\t}\r\n\treturn wrapped, nil\r\n}","code-length":285,"reference":"\/\/ Open opens a connection","result":"Create a driver context with the driver hooks.","score":[0.1389,0.0943]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FixedSizeRingBuf) Prevpos(from int) int {\r\n\tif from >= f.N || from < 0 {\r\n\t\treturn -2\r\n\t}\r\n\tif f.Readable == 0 {\r\n\t\treturn -1\r\n\t}\r\n\tif from == f.Beg {\r\n\t\treturn -1\r\n\t}\r\n\ta0, a1, b0, b1 := f.LegalPos()\r\n\tswitch {\r\n\tcase from == a0:\r\n\t\treturn -1\r\n\tcase from > a0 && from <= a1:\r\n\t\treturn from - 1\r\n\tcase from == b0:\r\n\t\treturn a1\r\n\tcase from > b0 && from <= b1:\r\n\t\treturn from - 1\r\n\t}\r\n\treturn -1\r\n}","code-length":207,"reference":"\/\/ Prevpos returns the index of the element before\n\/\/ from, or -1 if no more and from is the\n\/\/ first in the ring. Returns -2 on bad\n\/\/ from position.","result":"Avoid recursion.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FixedSizeRingBuf) Last() int {\r\n\tif f.Readable == 0 {\r\n\t\treturn -1\r\n\t}\r\n\tlast := f.Beg + f.Readable - 1\r\n\tif last < f.N {\r\n\t\t\r\n\t\treturn last\r\n\t}\r\n\treturn last % f.N\r\n}","code-length":92,"reference":"\/\/ Last returns the index of the last element,\n\/\/ or -1 if the ring is empty.","result":"Get the last element in the ring buffer.","score":[0.0839,0.2329]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FixedSizeRingBuf) DeleteMostRecentBytes(n int) {\r\n\tif n <= 0 {\r\n\t\treturn\r\n\t}\r\n\tif n >= f.Readable {\r\n\t\tf.Readable = 0\r\n\t\treturn\r\n\t}\r\n\tf.Readable -= n\r\n}","code-length":83,"reference":"\/\/ DeleteMostRecentBytes trims back the last n bytes written.","result":"Delete bytes from the ring buffer.","score":[0.1392,0.1149]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFloat64RingBuf(maxViewItems int) *Float64RingBuf {\r\n\tn := maxViewItems\r\n\tr := &Float64RingBuf{\r\n\t\tN:        n,\r\n\t\tBeg:      0,\r\n\t\tReadable: 0,\r\n\t}\r\n\tr.A = make([]float64, n, n)\r\n\treturn r\r\n}","code-length":101,"reference":"\/\/ constructor. NewFloat64RingBuf will allocate internally\n\/\/ a slice of maxViewItems float64.","result":"Create a new ring buffer.","score":[0.0593,0.0442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Float64RingBuf) TwoContig(makeCopy bool) (first []float64, second []float64) {\r\n\textent := b.Beg + b.Readable\r\n\tif extent <= b.N {\r\n\t\t\r\n\t\t\r\n\t\treturn b.A[b.Beg:(b.Beg + b.Readable)], second\r\n\t}\r\n\treturn b.A[b.Beg:b.N], b.A[0:(extent % b.N)]\r\n}","code-length":126,"reference":"\/\/ TwoContig returns all readable float64, but in two separate slices,\n\/\/ to avoid copying. The two slices are from the same buffer, but\n\/\/ are not contiguous. Either or both may be empty slices.","result":"Create the ringbuffer.","score":[0.0,0.0157]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Float64RingBuf) Earliest() (v float64, ok bool) {\r\n\tif b.Readable == 0 {\r\n\t\treturn\r\n\t}\r\n\treturn b.A[b.Beg], true\r\n}","code-length":66,"reference":"\/\/ Earliest returns the earliest written value v. ok will be\n\/\/ true unless the ring is empty, in which case ok will be false,\n\/\/ and v will be zero.","result":"Compute the latest value in the ring buffer.","score":[0.0139,0.1296]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Float64RingBuf) Values() []float64 {\r\n\tfirst, second := b.TwoContig(false)\r\n\tif len(first) == 0 {\r\n\t\treturn second\r\n\t}\r\n\tif len(second) == 0 {\r\n\t\treturn first\r\n\t}\r\n\tout := make([]float64, len(first) + len(second))\r\n\tcopy(out, first)\r\n\tcopy(out[len(first):], second)\r\n\treturn out\r\n}","code-length":132,"reference":"\/\/ Values returns all readable float64 in a single buffer. Calling this function\n\/\/ might allocate a new buffer to store the elements contiguously.","result":"Collect values.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewAtomicFixedSizeRingBuf(maxViewInBytes int) *AtomicFixedSizeRingBuf {\r\n\tn := maxViewInBytes\r\n\tr := &AtomicFixedSizeRingBuf{\r\n\t\tUse: 0,\r\n\t\t\r\n\t\tN:        n,\r\n\t\tBeg:      0,\r\n\t\treadable: 0,\r\n\t}\r\n\tr.A[0] = make([]byte, n, n)\r\n\tr.A[1] = make([]byte, n, n)\r\n\treturn r\r\n}","code-length":136,"reference":"\/\/ constructor. NewAtomicFixedSizeRingBuf will allocate internally\n\/\/ two buffers of size maxViewInBytes.","result":"Create a new atomic buffer.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *AtomicFixedSizeRingBuf) Reset() {\r\n\tb.tex.Lock()\r\n\tdefer b.tex.Unlock()\r\n\tb.Beg = 0\r\n\tb.readable = 0\r\n\tb.Use = 0\r\n}","code-length":68,"reference":"\/\/ Reset quickly forgets any data stored in the ring buffer. The\n\/\/ data is still there, but the ring buffer will ignore it and\n\/\/ overwrite those buffers as new data comes in.","result":"Reset the ringbuffer.","score":[0.0,0.0324]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPointerRingBuf(sliceN int) *PointerRingBuf {\r\n\tn := sliceN\r\n\tr := &PointerRingBuf{\r\n\t\tN:        n,\r\n\t\tBeg:      0,\r\n\t\tReadable: 0,\r\n\t}\r\n\tr.A = make([]interface{}, n, n)\r\n\treturn r\r\n}","code-length":96,"reference":"\/\/ constructor. NewPointerRingBuf will allocate internally\n\/\/ a slice of size sliceN","result":"Create a pointer ring buffer.","score":[0.0593,0.0442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *PointerRingBuf) TwoContig() (first []interface{}, second []interface{}) {\r\n\textent := b.Beg + b.Readable\r\n\tif extent <= b.N {\r\n\t\t\r\n\t\t\r\n\t\treturn b.A[b.Beg:(b.Beg + b.Readable)], second\r\n\t}\r\n\treturn b.A[b.Beg:b.N], b.A[0:(extent % b.N)]\r\n}","code-length":121,"reference":"\/\/ TwoContig returns all readable pointers, but in two separate slices,\n\/\/ to avoid copying. The two slices are from the same buffer, but\n\/\/ are not contiguous. Either or both may be empty slices.","result":"Create a two.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Reader) NumPage() int {\r\n\treturn int(r.Trailer().Key(\"Root\").Key(\"Pages\").Key(\"Count\").Int64())\r\n}","code-length":49,"reference":"\/\/ NumPage returns the number of pages in the PDF file.","result":"Generate the code.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p Page) Font(name string) Font {\r\n\treturn Font{p.Resources().Key(\"Font\").Key(name)}\r\n}","code-length":42,"reference":"\/\/ Font returns the font with the given name associated with the page.","result":"Generate the generated code.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f Font) Width(code int) float64 {\r\n\tfirst := f.FirstChar()\r\n\tlast := f.LastChar()\r\n\tif code < first || last < code {\r\n\t\treturn 0\r\n\t}\r\n\treturn f.V.Key(\"Widths\").Index(code - first).Float64()\r\n}","code-length":88,"reference":"\/\/ Width returns the width of the given code point.","result":"Calculate the width of a character.","score":[0.2042,0.2662]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f Font) Encoder() TextEncoding {\r\n\tenc := f.V.Key(\"Encoding\")\r\n\tswitch enc.Kind() {\r\n\tcase Name:\r\n\t\tswitch enc.Name() {\r\n\t\tcase \"WinAnsiEncoding\":\r\n\t\t\treturn &byteEncoder{&winAnsiEncoding}\r\n\t\tcase \"MacRomanEncoding\":\r\n\t\t\treturn &byteEncoder{&macRomanEncoding}\r\n\t\tcase \"Identity-H\":\r\n\t\t\t\r\n\t\t\treturn &nopEncoder{}\r\n\t\tdefault:\r\n\t\t\tprintln(\"unknown encoding\", enc.Name())\r\n\t\t\treturn &nopEncoder{}\r\n\t\t}\r\n\tcase Dict:\r\n\t\treturn &dictEncoder{enc.Key(\"Differences\")}\r\n\tcase Null:\r\n\t\t\r\n\tdefault:\r\n\t\tprintln(\"unexpected encoding\", enc.String())\r\n\t\treturn &nopEncoder{}\r\n\t}\r\n\ttoUnicode := f.V.Key(\"ToUnicode\")\r\n\tif toUnicode.Kind() == Dict {\r\n\t\tm := readCmap(toUnicode)\r\n\t\tif m == nil {\r\n\t\t\treturn &nopEncoder{}\r\n\t\t}\r\n\t\treturn m\r\n\t}\r\n\treturn &byteEncoder{&pdfDocEncoding}\r\n}","code-length":322,"reference":"\/\/ Encoder returns the encoding between font code point sequences and UTF-8.","result":"Encode text.","score":[0,0.0455]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Interpret(strm Value, do func(stk *Stack, op string)) {\r\n\trd := strm.Reader()\r\n\tb := newBuffer(rd, 0)\r\n\tb.allowEOF = true\r\n\tb.allowObjptr = false\r\n\tb.allowStream = false\r\n\tvar stk Stack\r\n\tvar dicts []dict\r\nReading:\r\n\tfor {\r\n\t\ttok := b.readToken()\r\n\t\tif tok == io.EOF {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif kw, ok := tok.(keyword); ok {\r\n\t\t\tswitch kw {\r\n\t\t\tcase \"null\", \"[\", \"]\", \"<<\", \">>\":\r\n\t\t\t\tbreak\r\n\t\t\tdefault:\r\n\t\t\t\tfor i := len(dicts) - 1; i >= 0; i-- {\r\n\t\t\t\t\tif v, ok := dicts[i][name(kw)]; ok {\r\n\t\t\t\t\t\tstk.Push(Value{nil, objptr{}, v})\r\n\t\t\t\t\t\tcontinue Reading\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t\tdo(&stk, string(kw))\r\n\t\t\t\tcontinue\r\n\t\t\tcase \"dict\":\r\n\t\t\t\tstk.Pop()\r\n\t\t\t\tstk.Push(Value{nil, objptr{}, make(dict)})\r\n\t\t\t\tcontinue\r\n\t\t\tcase \"currentdict\":\r\n\t\t\t\tif len(dicts) == 0 {\r\n\t\t\t\t\tpanic(\"no current dictionary\")\r\n\t\t\t\t}\r\n\t\t\t\tstk.Push(Value{nil, objptr{}, dicts[len(dicts)-1]})\r\n\t\t\t\tcontinue\r\n\t\t\tcase \"begin\":\r\n\t\t\t\td := stk.Pop()\r\n\t\t\t\tif d.Kind() != Dict {\r\n\t\t\t\t\tpanic(\"cannot begin non-dict\")\r\n\t\t\t\t}\r\n\t\t\t\tdicts = append(dicts, d.data.(dict))\r\n\t\t\t\tcontinue\r\n\t\t\tcase \"end\":\r\n\t\t\t\tif len(dicts) <= 0 {\r\n\t\t\t\t\tpanic(\"mismatched begin\/end\")\r\n\t\t\t\t}\r\n\t\t\t\tdicts = dicts[:len(dicts)-1]\r\n\t\t\t\tcontinue\r\n\t\t\tcase \"def\":\r\n\t\t\t\tif len(dicts) <= 0 {\r\n\t\t\t\t\tpanic(\"def without open dict\")\r\n\t\t\t\t}\r\n\t\t\t\tval := stk.Pop()\r\n\t\t\t\tkey, ok := stk.Pop().data.(name)\r\n\t\t\t\tif !ok {\r\n\t\t\t\t\tpanic(\"def of non-name\")\r\n\t\t\t\t}\r\n\t\t\t\tdicts[len(dicts)-1][key] = val.data\r\n\t\t\t\tcontinue\r\n\t\t\tcase \"pop\":\r\n\t\t\t\tstk.Pop()\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t}\r\n\t\tb.unreadToken(tok)\r\n\t\tobj := b.readObject()\r\n\t\tstk.Push(Value{nil, objptr{}, obj})\r\n\t}\r\n}","code-length":717,"reference":"\/\/ Interpret interprets the content in a stream as a basic PostScript program,\n\/\/ pushing values onto a stack and then calling the do function to execute\n\/\/ operators. The do function may push or pop values from the stack as needed\n\/\/ to implement op.\n\/\/\n\/\/ Interpret handles the operators \"dict\", \"currentdict\", \"begin\", \"end\", \"def\", and \"pop\" itself.\n\/\/\n\/\/ Interpret is not a full-blown PostScript interpreter. Its job is to handle the\n\/\/ very limited PostScript found in certain supporting file formats embedded\n\/\/ in PDF files, such as cmap files that describe the mapping from font code\n\/\/ points to Unicode code points.\n\/\/\n\/\/ There is no support for executable blocks, among other limitations.\n\/\/","result":"Code too long,keep in 512.","score":[0.0,0.0092]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Open(file string) (*Reader, error) {\r\n\t\r\n\tf, err := os.Open(file)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tfi, err := f.Stat()\r\n\tif err != nil {\r\n\t\tf.Close()\r\n\t\treturn nil, err\r\n\t}\r\n\treturn NewReader(f, fi.Size())\r\n}","code-length":112,"reference":"\/\/ Open opens a file for reading.","result":"Open a file .","score":[0.2362,0.3814]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewReader(f io.ReaderAt, size int64) (*Reader, error) {\r\n\treturn NewReaderEncrypted(f, size, nil)\r\n}","code-length":45,"reference":"\/\/ NewReader opens a file for reading, using the data in f with the given total size.","result":"Generate the code.","score":[0.0038,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewReaderEncrypted(f io.ReaderAt, size int64, pw func() string) (*Reader, error) {\r\n\tbuf := make([]byte, 10)\r\n\tf.ReadAt(buf, 0)\r\n\tif !bytes.HasPrefix(buf, []byte(\"%PDF-1.\")) || buf[7] < '0' || buf[7] > '7' || buf[8] != '\\r' && buf[8] != '\\n' {\r\n\t\treturn nil, fmt.Errorf(\"not a PDF file: invalid header\")\r\n\t}\r\n\tend := size\r\n\tconst endChunk = 100\r\n\tbuf = make([]byte, endChunk)\r\n\tf.ReadAt(buf, end-endChunk)\r\n\tfor len(buf) > 0 && buf[len(buf)-1] == '\\n' || buf[len(buf)-1] == '\\r' {\r\n\t\tbuf = buf[:len(buf)-1]\r\n\t}\r\n\tbuf = bytes.TrimRight(buf, \"\\r\\n\\t \")\r\n\tif !bytes.HasSuffix(buf, []byte(\"%%EOF\")) {\r\n\t\treturn nil, fmt.Errorf(\"not a PDF file: missing %%%%EOF\")\r\n\t}\r\n\ti := findLastLine(buf, \"startxref\")\r\n\tif i < 0 {\r\n\t\treturn nil, fmt.Errorf(\"malformed PDF file: missing final startxref\")\r\n\t}\r\n\tr := &Reader{\r\n\t\tf:   f,\r\n\t\tend: end,\r\n\t}\r\n\tpos := end - endChunk + int64(i)\r\n\tb := newBuffer(io.NewSectionReader(f, pos, end-pos), pos)\r\n\tif b.readToken() != keyword(\"startxref\") {\r\n\t\treturn nil, fmt.Errorf(\"malformed PDF file: missing startxref\")\r\n\t}\r\n\tstartxref, ok := b.readToken().(int64)\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"malformed PDF file: startxref not followed by integer\")\r\n\t}\r\n\tb = newBuffer(io.NewSectionReader(r.f, startxref, r.end-startxref), startxref)\r\n\txref, trailerptr, trailer, err := readXref(r, b)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tr.xref = xref\r\n\tr.trailer = trailer\r\n\tr.trailerptr = trailerptr\r\n\tif trailer[\"Encrypt\"] == nil {\r\n\t\treturn r, nil\r\n\t}\r\n\terr = r.initEncrypt(\"\")\r\n\tif err == nil {\r\n\t\treturn r, nil\r\n\t}\r\n\tif pw == nil || err != ErrInvalidPassword {\r\n\t\treturn nil, err\r\n\t}\r\n\tfor {\r\n\t\tnext := pw()\r\n\t\tif next == \"\" {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif r.initEncrypt(next) == nil {\r\n\t\t\treturn r, nil\r\n\t\t}\r\n\t}\r\n\treturn nil, err\r\n}","code-length":760,"reference":"\/\/ NewReaderEncrypted opens a file for reading, using the data in f with the given total size.\n\/\/ If the PDF is encrypted, NewReaderEncrypted calls pw repeatedly to obtain passwords\n\/\/ to try. If pw returns the empty string, NewReaderEncrypted stops trying to decrypt\n\/\/ the file and returns an error.","result":"Code too long,keep in 512.","score":[0.0,0.0108]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Reader) Trailer() Value {\r\n\treturn Value{r, r.trailerptr, r.trailer}\r\n}","code-length":42,"reference":"\/\/ Trailer returns the file's Trailer value.","result":"Test the error .","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v Value) Kind() ValueKind {\r\n\tswitch v.data.(type) {\r\n\tdefault:\r\n\t\treturn Null\r\n\tcase bool:\r\n\t\treturn Bool\r\n\tcase int64:\r\n\t\treturn Integer\r\n\tcase float64:\r\n\t\treturn Real\r\n\tcase string:\r\n\t\treturn String\r\n\tcase name:\r\n\t\treturn Name\r\n\tcase dict:\r\n\t\treturn Dict\r\n\tcase array:\r\n\t\treturn Array\r\n\tcase stream:\r\n\t\treturn Stream\r\n\t}\r\n}","code-length":147,"reference":"\/\/ Kind reports the kind of value underlying v.","result":"Check the type of the value.","score":[0.1392,0.1149]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newBuffer(r io.Reader, offset int64) *buffer {\r\n\treturn &buffer{\r\n\t\tr:           r,\r\n\t\toffset:      offset,\r\n\t\tbuf:         make([]byte, 0, 4096),\r\n\t\tallowObjptr: true,\r\n\t\tallowStream: true,\r\n\t}\r\n}","code-length":92,"reference":"\/\/ newBuffer returns a new buffer reading from r at the given offset.","result":"Create a new buffer.","score":[0.0476,0.155]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ResultSet) Paginate(perPage, page int) (*PaginationInfo, error) {\r\n\tinfo := new(PaginationInfo)\r\n\t\r\n\tsess := r.Collection.Connection.Session.Copy()\r\n\tcount, err := sess.DB(r.Collection.Database).C(r.Collection.Name).Find(r.Params).Count()\r\n\tsess.Close()\r\n\tif err != nil {\r\n\t\treturn info, err\r\n\t}\r\n\t\r\n\ttotalPages := int(math.Ceil(float64(count) \/ float64(perPage)))\r\n\tif page < 1 {\r\n\t\tpage = 1\r\n\t} else if page > totalPages {\r\n\t\tpage = totalPages\r\n\t}\r\n\tskip := (page - 1) * perPage\r\n\tr.Query.Skip(skip).Limit(perPage)\r\n\tinfo.TotalPages = totalPages\r\n\tinfo.PerPage = perPage\r\n\tinfo.Current = page\r\n\tinfo.TotalRecords = count\r\n\tif info.Current < info.TotalPages {\r\n\t\tinfo.RecordsOnPage = info.PerPage\r\n\t} else {\r\n\t\tinfo.RecordsOnPage = int(math.Mod(float64(count), float64(perPage)))\r\n\t\tif info.RecordsOnPage == 0 && count > 0 {\r\n\t\t\tinfo.RecordsOnPage = perPage\r\n\t\t}\r\n\t}\r\n\treturn info, nil\r\n}","code-length":356,"reference":"\/\/ Set skip + limit on the current query and generates a PaginationInfo struct with info for your front end","result":"Paginate the result set .","score":[0.012,0.0541]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CascadeDelete(collection *Collection, doc interface{}) {\r\n\t\r\n\tif conv, ok := doc.(interface {\r\n\t\tGetCascade(*Collection) []*CascadeConfig\r\n\t}); ok {\r\n\t\ttoCascade := conv.GetCascade(collection)\r\n\t\t\r\n\t\tfor _, conf := range toCascade {\r\n\t\t\tif len(conf.ReferenceQuery) == 0 {\r\n\t\t\t\tid, err := reflections.GetField(doc, \"Id\")\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tpanic(err)\r\n\t\t\t\t}\r\n\t\t\t\tconf.ReferenceQuery = []*ReferenceField{&ReferenceField{\"_id\", id}}\r\n\t\t\t}\r\n\t\t\tcascadeDeleteWithConfig(conf)\r\n\t\t}\r\n\t}\r\n}","code-length":201,"reference":"\/\/ Deletes references to a document from its related documents","result":"Delete documents in a collection.","score":[0.1051,0.1579]}
{"code":"\/*is used to<extra_id_0>\r\nfunc cascadeDeleteWithConfig(conf *CascadeConfig) (*mgo.ChangeInfo, error) {\r\n\tswitch conf.RelType {\r\n\tcase REL_ONE:\r\n\t\tupdate := map[string]map[string]interface{}{\r\n\t\t\t\"$set\": map[string]interface{}{},\r\n\t\t}\r\n\t\tif len(conf.ThroughProp) > 0 {\r\n\t\t\tupdate[\"$set\"][conf.ThroughProp] = nil\r\n\t\t} else {\r\n\t\t\tfor _, p := range conf.Properties {\r\n\t\t\t\tupdate[\"$set\"][p] = nil\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn conf.Collection.Collection().UpdateAll(conf.Query, update)\r\n\tcase REL_MANY:\r\n\t\tupdate := map[string]map[string]interface{}{\r\n\t\t\t\"$pull\": map[string]interface{}{},\r\n\t\t}\r\n\t\tq := bson.M{}\r\n\t\tfor _, f := range conf.ReferenceQuery {\r\n\t\t\tq[f.BsonName] = f.Value\r\n\t\t}\r\n\t\tupdate[\"$pull\"][conf.ThroughProp] = q\r\n\t\treturn conf.Collection.Collection().UpdateAll(conf.Query, update)\r\n\t}\r\n\treturn &mgo.ChangeInfo{}, errors.New(\"Invalid relation type\")\r\n}","code-length":340,"reference":"\/\/ Runs a cascaded delete operation with one configuration","result":"Delete a relation.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc cascadeSaveWithConfig(conf *CascadeConfig, doc Document) (*mgo.ChangeInfo, error) {\r\n\t\r\n\tdata := conf.Data\r\n\tswitch conf.RelType {\r\n\tcase REL_ONE:\r\n\t\tif len(conf.OldQuery) > 0 {\r\n\t\t\tupdate1 := map[string]map[string]interface{}{\r\n\t\t\t\t\"$set\": map[string]interface{}{},\r\n\t\t\t}\r\n\t\t\tif len(conf.ThroughProp) > 0 {\r\n\t\t\t\tupdate1[\"$set\"][conf.ThroughProp] = nil\r\n\t\t\t} else {\r\n\t\t\t\tfor _, p := range conf.Properties {\r\n\t\t\t\t\tupdate1[\"$set\"][p] = nil\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tret, err := conf.Collection.Collection().UpdateAll(conf.OldQuery, update1)\r\n\t\t\tif conf.RemoveOnly {\r\n\t\t\t\treturn ret, err\r\n\t\t\t}\r\n\t\t}\r\n\t\tupdate := make(map[string]interface{})\r\n\t\tif len(conf.ThroughProp) > 0 {\r\n\t\t\tm := bson.M{}\r\n\t\t\tm[conf.ThroughProp] = data\r\n\t\t\tupdate[\"$set\"] = m\r\n\t\t} else {\r\n\t\t\tupdate[\"$set\"] = data\r\n\t\t}\r\n\t\t\r\n\t\treturn conf.Collection.Collection().UpdateAll(conf.Query, update)\r\n\tcase REL_MANY:\r\n\t\tupdate1 := map[string]map[string]interface{}{\r\n\t\t\t\"$pull\": map[string]interface{}{},\r\n\t\t}\r\n\t\tq := bson.M{}\r\n\t\tfor _, f := range conf.ReferenceQuery {\r\n\t\t\tq[f.BsonName] = f.Value\r\n\t\t}\r\n\t\tupdate1[\"$pull\"][conf.ThroughProp] = q\r\n\t\tif len(conf.OldQuery) > 0 {\r\n\t\t\tret, err := conf.Collection.Collection().UpdateAll(conf.OldQuery, update1)\r\n\t\t\tif conf.RemoveOnly {\r\n\t\t\t\treturn ret, err\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tconf.Collection.Collection().UpdateAll(conf.Query, update1)\r\n\t\tupdate2 := map[string]map[string]interface{}{\r\n\t\t\t\"$push\": map[string]interface{}{},\r\n\t\t}\r\n\t\tupdate2[\"$push\"][conf.ThroughProp] = data\r\n\t\treturn conf.Collection.Collection().UpdateAll(conf.Query, update2)\r\n\t}\r\n\treturn &mgo.ChangeInfo{}, errors.New(\"Invalid relation type\")\r\n}","code-length":666,"reference":"\/\/ Runs a cascaded save operation with one configuration","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MapFromCascadeProperties(properties []string, doc Document) map[string]interface{} {\r\n\tdata := make(map[string]interface{})\r\n\tfor _, prop := range properties {\r\n\t\tsplit := strings.Split(prop, \".\")\r\n\t\tif len(split) == 1 {\r\n\t\t\tdata[prop], _ = dotaccess.Get(doc, prop)\r\n\t\t} else {\r\n\t\t\tactualProp := split[len(split)-1]\r\n\t\t\tsplit := append([]string{}, split[:len(split)-1]...)\r\n\t\t\tcurData := data\r\n\t\t\tfor _, s := range split {\r\n\t\t\t\tif _, ok := curData[s]; ok {\r\n\t\t\t\t\tif mapped, ok := curData[s].(map[string]interface{}); ok {\r\n\t\t\t\t\t\tcurData = mapped\r\n\t\t\t\t\t} else {\r\n\t\t\t\t\t\tpanic(\"Cannot access non-map property via dot notation\")\r\n\t\t\t\t\t}\r\n\t\t\t\t} else {\r\n\t\t\t\t\tcurData[s] = make(map[string]interface{})\r\n\t\t\t\t\tif mapped, ok := curData[s].(map[string]interface{}); ok {\r\n\t\t\t\t\t\tcurData = mapped\r\n\t\t\t\t\t} else {\r\n\t\t\t\t\t\tpanic(\"Cannot access non-map property via dot notation\")\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tval, _ := dotaccess.Get(doc, prop)\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tcurData[actualProp] = val\r\n\t\t}\r\n\t}\r\n\treturn data\r\n}","code-length":401,"reference":"\/\/ If you need to, you can use this to construct the data map that will be cascaded down to\n\/\/ related documents. Doing this is not recommended unless the cascaded fields are dynamic.","result":"Cascade the map from cascade properties.","score":[0.0022,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Connection) Connect() (err error) {\r\n\tdefer func() {\r\n\t\tif r := recover(); r != nil {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tif e, ok := r.(error); ok {\r\n\t\t\t\terr = e\r\n\t\t\t} else if e, ok := r.(string); ok {\r\n\t\t\t\terr = errors.New(e)\r\n\t\t\t} else {\r\n\t\t\t\terr = errors.New(fmt.Sprint(r))\r\n\t\t\t}\r\n\t\t}\r\n\t}()\r\n\tif m.Config.DialInfo == nil {\r\n\t\tif m.Config.DialInfo, err = mgo.ParseURL(m.Config.ConnectionString); err != nil {\r\n\t\t\tpanic(fmt.Sprintf(\"cannot parse given URI %s due to error: %s\", m.Config.ConnectionString, err.Error()))\r\n\t\t}\r\n\t}\r\n\tsession, err := mgo.DialWithInfo(m.Config.DialInfo)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tm.Session = session\r\n\tm.Session.SetMode(mgo.Monotonic, true)\r\n\treturn nil\r\n}","code-length":301,"reference":"\/\/ Connect to the database using the provided config","result":"Connect to the database.","score":[0.1885,0.3007]}
{"code":"\/*is used to<extra_id_0>\r\nfunc lowerInitial(str string) string {\r\n\tfor i, v := range str {\r\n\t\treturn string(unicode.ToLower(v)) + str[i+1:]\r\n\t}\r\n\treturn \"\"\r\n}","code-length":62,"reference":"\/\/Lower cases first char of string","result":"Lower the first character of a string.","score":[0.1921,0.1639]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Collection) Find(query interface{}) *ResultSet {\r\n\tcol := c.Collection()\r\n\t\r\n\tq := col.Find(query)\r\n\tresultset := new(ResultSet)\r\n\tresultset.Query = q\r\n\tresultset.Params = query\r\n\tresultset.Collection = c\r\n\treturn resultset\r\n}","code-length":92,"reference":"\/\/ This doesn't actually do any DB interaction, it just creates the result set so we can\n\/\/ start looping through on the iterator","result":"Find the collection.","score":[0.0004,0.0228]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) RawInformationQuery(from, to, id, iqType, requestNamespace, body string) (string, error) {\r\n\tconst xmlIQ = \"<iq from='%s' to='%s' id='%s' type='%s'><query xmlns='%s'>%s<\/query><\/iq>\"\r\n\t_, err := fmt.Fprintf(c.conn, xmlIQ, xmlEscape(from), xmlEscape(to), id, iqType, requestNamespace, body)\r\n\treturn id, err\r\n}","code-length":129,"reference":"\/\/ RawInformationQuery sends an information query request to the server.","result":"Query raw information.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Options) NewClient() (*Client, error) {\r\n\thost := o.Host\r\n\tc, err := connect(host, o.User, o.Password)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif strings.LastIndex(o.Host, \":\") > 0 {\r\n\t\thost = host[:strings.LastIndex(o.Host, \":\")]\r\n\t}\r\n\tclient := new(Client)\r\n\tif o.NoTLS {\r\n\t\tclient.conn = c\r\n\t} else {\r\n\t\tvar tlsconn *tls.Conn\r\n\t\tif o.TLSConfig != nil {\r\n\t\t\ttlsconn = tls.Client(c, o.TLSConfig)\r\n\t\t} else {\r\n\t\t\tDefaultConfig.ServerName = host\r\n\t\t\tnewconfig := DefaultConfig\r\n\t\t\tnewconfig.ServerName = host\r\n\t\t\ttlsconn = tls.Client(c, &newconfig)\r\n\t\t}\r\n\t\tif err = tlsconn.Handshake(); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tinsecureSkipVerify := DefaultConfig.InsecureSkipVerify\r\n\t\tif o.TLSConfig != nil {\r\n\t\t\tinsecureSkipVerify = o.TLSConfig.InsecureSkipVerify\r\n\t\t}\r\n\t\tif !insecureSkipVerify {\r\n\t\t\tif err = tlsconn.VerifyHostname(host); err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t}\r\n\t\tclient.conn = tlsconn\r\n\t}\r\n\tif err := client.init(&o); err != nil {\r\n\t\tclient.Close()\r\n\t\treturn nil, err\r\n\t}\r\n\treturn client, nil\r\n}","code-length":427,"reference":"\/\/ NewClient establishes a new Client connection based on a set of Options.","result":"Create a new client.","score":[0.0476,0.0826]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Close() error {\r\n\tif c.conn != (*tls.Conn)(nil) {\r\n\t\treturn c.conn.Close()\r\n\t}\r\n\treturn nil\r\n}","code-length":59,"reference":"\/\/ Close closes the XMPP connection","result":"Close the client.","score":[0.1786,0.1754]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) startTLSIfRequired(f *streamFeatures, o *Options, domain string) (*streamFeatures, error) {\r\n\t\r\n\tswitch {\r\n\tcase f.StartTLS == nil:\r\n\t\t\r\n\t\treturn f, nil\r\n\tcase !o.StartTLS && f.StartTLS.Required == nil:\r\n\t\treturn f, nil\r\n\tcase f.StartTLS.Required != nil:\r\n\t\t\r\n\tcase !o.StartTLS:\r\n\t\t\r\n\t}\r\n\tvar err error\r\n\tfmt.Fprintf(c.conn, \"<starttls xmlns='urn:ietf:params:xml:ns:xmpp-tls'\/>\\n\")\r\n\tvar k tlsProceed\r\n\tif err = c.p.DecodeElement(&k, nil); err != nil {\r\n\t\treturn f, errors.New(\"unmarshal <proceed>: \" + err.Error())\r\n\t}\r\n\ttc := o.TLSConfig\r\n\tif tc == nil {\r\n\t\ttc = new(tls.Config)\r\n\t\t*tc = DefaultConfig\r\n\t\t\r\n\t\ttc.ServerName = domain\r\n\t}\r\n\tt := tls.Client(c.conn, tc)\r\n\tif err = t.Handshake(); err != nil {\r\n\t\treturn f, errors.New(\"starttls handshake: \" + err.Error())\r\n\t}\r\n\tc.conn = t\r\n\t\r\n\ttf, err := c.startStream(o, domain)\r\n\tif err != nil {\r\n\t\treturn f, err\r\n\t}\r\n\treturn tf, nil\r\n}","code-length":394,"reference":"\/\/ startTlsIfRequired examines the server's stream features and, if STARTTLS is required or supported, performs the TLS handshake.\n\/\/ f will be updated if the handshake completes, as the new stream's features are typically different from the original.","result":"Start TLS if required.","score":[0.0001,0.0289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) startStream(o *Options, domain string) (*streamFeatures, error) {\r\n\tif o.Debug {\r\n\t\tc.p = xml.NewDecoder(tee{c.conn, DebugWriter})\r\n\t} else {\r\n\t\tc.p = xml.NewDecoder(c.conn)\r\n\t}\r\n\t_, err := fmt.Fprintf(c.conn, \"<?xml version='1.0'?>\\n\"+\r\n\t\t\"<stream:stream to='%s' xmlns='%s'\\n\"+\r\n\t\t\" xmlns:stream='%s' version='1.0'>\\n\",\r\n\t\txmlEscape(domain), nsClient, nsStream)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tse, err := nextStart(c.p)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif se.Name.Space != nsStream || se.Name.Local != \"stream\" {\r\n\t\treturn nil, fmt.Errorf(\"expected <stream> but got <%v> in %v\", se.Name.Local, se.Name.Space)\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tf := new(streamFeatures)\r\n\tif err = c.p.DecodeElement(f, nil); err != nil {\r\n\t\treturn f, errors.New(\"unmarshal <features>: \" + err.Error())\r\n\t}\r\n\treturn f, nil\r\n}","code-length":370,"reference":"\/\/ startStream will start a new XML decoder for the connection, signal the start of a stream to the server and verify that the server has\n\/\/ also started the stream; if o.Debug is true, startStream will tee decoded XML data to stderr.  The features advertised by the server\n\/\/ will be returned.","result":"Avoid the need for the following code.","score":[0.0004,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) IsEncrypted() bool {\r\n\t_, ok := c.conn.(*tls.Conn)\r\n\treturn ok\r\n}","code-length":44,"reference":"\/\/ IsEncrypted will return true if the client is connected using a TLS transport, either because it used.\n\/\/ TLS to connect from the outset, or because it successfully used STARTTLS to promote a TCP connection to TLS.","result":"Check if the client is encrypted.","score":[0.0029,0.0907]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Recv() (stanza interface{}, err error) {\r\n\tfor {\r\n\t\t_, val, err := next(c.p)\r\n\t\tif err != nil {\r\n\t\t\treturn Chat{}, err\r\n\t\t}\r\n\t\tswitch v := val.(type) {\r\n\t\tcase *clientMessage:\r\n\t\t\tstamp, _ := time.Parse(\r\n\t\t\t\t\"2006-01-02T15:04:05Z\",\r\n\t\t\t\tv.Delay.Stamp,\r\n\t\t\t)\r\n\t\t\tchat := Chat{\r\n\t\t\t\tRemote:    v.From,\r\n\t\t\t\tType:      v.Type,\r\n\t\t\t\tText:      v.Body,\r\n\t\t\t\tSubject:   v.Subject,\r\n\t\t\t\tThread:    v.Thread,\r\n\t\t\t\tOther:     v.OtherStrings(),\r\n\t\t\t\tOtherElem: v.Other,\r\n\t\t\t\tStamp:     stamp,\r\n\t\t\t}\r\n\t\t\treturn chat, nil\r\n\t\tcase *clientQuery:\r\n\t\t\tvar r Roster\r\n\t\t\tfor _, item := range v.Item {\r\n\t\t\t\tr = append(r, Contact{item.Jid, item.Name, item.Group})\r\n\t\t\t}\r\n\t\t\treturn Chat{Type: \"roster\", Roster: r}, nil\r\n\t\tcase *clientPresence:\r\n\t\t\treturn Presence{v.From, v.To, v.Type, v.Show, v.Status}, nil\r\n\t\tcase *clientIQ:\r\n\t\t\t\r\n\t\t\tif bytes.Equal(bytes.TrimSpace(v.Query), []byte(`<ping xmlns='urn:xmpp:ping'\/>`)) || bytes.Equal(bytes.TrimSpace(v.Query), []byte(`<ping xmlns=\"urn:xmpp:ping\"\/>`)) {\r\n\t\t\t\terr := c.SendResultPing(v.ID, v.From)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn Chat{}, err\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn IQ{ID: v.ID, From: v.From, To: v.To, Type: v.Type, Query: v.Query}, nil\r\n\t\t}\r\n\t}\r\n}","code-length":544,"reference":"\/\/ Recv waits to receive the next XMPP stanza.\n\/\/ Return type is either a presence notification or a chat message.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Send(chat Chat) (n int, err error) {\r\n\tvar subtext = ``\r\n\tvar thdtext = ``\r\n\tif chat.Subject != `` {\r\n\t\tsubtext = `<subject>` + xmlEscape(chat.Subject) + `<\/subject>`\r\n\t}\r\n\tif chat.Thread != `` {\r\n\t\tthdtext = `<thread>` + xmlEscape(chat.Thread) + `<\/thread>`\r\n\t}\r\n\tstanza := \"<message to='%s' type='%s' id='%s' xml:lang='en'>\" + subtext + \"<body>%s<\/body>\" + thdtext + \"<\/message>\"\r\n\treturn fmt.Fprintf(c.conn, stanza,\r\n\t\txmlEscape(chat.Remote), xmlEscape(chat.Type), cnonce(), xmlEscape(chat.Text))\r\n}","code-length":213,"reference":"\/\/ Send sends the message wrapped inside an XMPP message stanza body.","result":"Send messages to a remote server.","score":[0.071,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) SendOrg(org string) (n int, err error) {\r\n\treturn fmt.Fprint(c.conn, org)\r\n}","code-length":47,"reference":"\/\/ SendOrg sends the original text without being wrapped in an XMPP message stanza.","result":"Send the message to the org.","score":[0.0605,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) SendKeepAlive() (n int, err error) {\r\n\treturn fmt.Fprintf(c.conn, \" \")\r\n}","code-length":44,"reference":"\/\/ SendKeepAlive sends a \"whitespace keepalive\" as described in chapter 4.6.1 of RFC6120.","result":"Send the keep alive message.","score":[0,0.041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) SendHtml(chat Chat) (n int, err error) {\r\n\treturn fmt.Fprintf(c.conn, \"<message to='%s' type='%s' xml:lang='en'>\"+\r\n\t\t\"<body>%s<\/body>\"+\r\n\t\t\"<html xmlns='http:scape(chat.Text), chat.Text)\r\n}","code-length":96,"reference":"\/\/ SendHtml sends the message as HTML as defined by XEP-0071","result":"Send html messages.","score":[0,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc nextStart(p *xml.Decoder) (xml.StartElement, error) {\r\n\tfor {\r\n\t\tt, err := p.Token()\r\n\t\tif err != nil || t == nil {\r\n\t\t\treturn xml.StartElement{}, err\r\n\t\t}\r\n\t\tswitch t := t.(type) {\r\n\t\tcase xml.StartElement:\r\n\t\t\treturn t, nil\r\n\t\t}\r\n\t}\r\n}","code-length":118,"reference":"\/\/ Scan XML token stream to find next StartElement.","result":"Detect the next start element.","score":[0.108,0.1163]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) JoinProtectedMUC(jid, nick string, password string, history_type, history int, history_date *time.Time) (n int, err error) {\r\n\tif nick == \"\" {\r\n\t\tnick = c.jid\r\n\t}\r\n\tswitch history_type {\r\n\tcase NoHistory:\r\n\t\treturn fmt.Fprintf(c.conn, \"<presence to='%s\/%s'>\\n\"+\r\n\t\t\t\"<x xmlns='%s'>\\n\"+\r\n\t\t\t\"<password>%s<\/password>\"+\r\n\t\t\t\"<\/x>\\n\"+\r\n\t\t\t\"<\/presence>\",\r\n\t\t\txmlEscape(jid), xmlEscape(nick), nsMUC, xmlEscape(password))\r\n\tcase CharHistory:\r\n\t\treturn fmt.Fprintf(c.conn, \"<presence to='%s\/%s'>\\n\"+\r\n\t\t\t\"<x xmlns='%s'>\\n\"+\r\n\t\t\t\"<password>%s<\/password>\\n\"+\r\n\t\t\t\"<history maxchars='%d'\/><\/x>\\n\"+\r\n\t\t\t\"<\/presence>\",\r\n\t\t\txmlEscape(jid), xmlEscape(nick), nsMUC, xmlEscape(password), history)\r\n\tcase StanzaHistory:\r\n\t\treturn fmt.Fprintf(c.conn, \"<presence to='%s\/%s'>\\n\"+\r\n\t\t\t\"<x xmlns='%s'>\\n\"+\r\n\t\t\t\"<password>%s<\/password>\\n\"+\r\n\t\t\t\"<history maxstanzas='%d'\/><\/x>\\n\"+\r\n\t\t\t\"<\/presence>\",\r\n\t\t\txmlEscape(jid), xmlEscape(nick), nsMUC, xmlEscape(password), history)\r\n\tcase SecondsHistory:\r\n\t\treturn fmt.Fprintf(c.conn, \"<presence to='%s\/%s'>\\n\"+\r\n\t\t\t\"<x xmlns='%s'>\\n\"+\r\n\t\t\t\"<password>%s<\/password>\\n\"+\r\n\t\t\t\"<history seconds='%d'\/><\/x>\\n\"+\r\n\t\t\t\"<\/presence>\",\r\n\t\t\txmlEscape(jid), xmlEscape(nick), nsMUC, xmlEscape(password), history)\r\n\tcase SinceHistory:\r\n\t\tif history_date != nil {\r\n\t\t\treturn fmt.Fprintf(c.conn, \"<presence to='%s\/%s'>\\n\"+\r\n\t\t\t\t\"<x xmlns='%s'>\\n\"+\r\n\t\t\t\t\"<password>%s<\/password>\\n\"+\r\n\t\t\t\t\"<history since='%s'\/><\/x>\\n\"+\r\n\t\t\t\t\"<\/presence>\",\r\n\t\t\t\txmlEscape(jid), xmlEscape(nick), nsMUC, xmlEscape(password), history_date.Format(time.RFC3339))\r\n\t\t}\r\n\t}\r\n\treturn 0, errors.New(\"Unknown history option\")\r\n}","code-length":695,"reference":"\/\/ xep-0045 7.2.6","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) LeaveMUC(jid string) (n int, err error) {\r\n\treturn fmt.Fprintf(c.conn, \"<presence from='%s' to='%s' type='unavailable' \/>\",\r\n\t\tc.jid, xmlEscape(jid))\r\n}","code-length":76,"reference":"\/\/ xep-0045 7.14","result":"Remove the MUC from the user.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) AttachBuffer(filename string, buf []byte, inline bool) error {\r\n\tm.Attachments[filename] = &Attachment{\r\n\t\tFilename: filename,\r\n\t\tData:     buf,\r\n\t\tInline:   inline,\r\n\t}\r\n\treturn nil\r\n}","code-length":81,"reference":"\/\/ AttachBuffer attaches a binary attachment.","result":"Set the attachment in the message.","score":[0,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) Attach(file string) error {\r\n\treturn m.attach(file, false)\r\n}","code-length":37,"reference":"\/\/ Attach attaches a file.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) Inline(file string) error {\r\n\treturn m.attach(file, true)\r\n}","code-length":37,"reference":"\/\/ Inline includes a file as an inline attachment.","result":"Create a new message.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) AddHeader(key string, value string) Header {\r\n\tnewHeader := Header{Key: key, Value: value}\r\n\tm.Headers = append(m.Headers, newHeader)\r\n\treturn newHeader\r\n}","code-length":67,"reference":"\/\/ Ads a Header to message","result":"Add headers to a message.","score":[0.2339,0.4331]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) Tolist() []string {\r\n\ttolist := m.To\r\n\tfor _, cc := range m.Cc {\r\n\t\ttolist = append(tolist, cc)\r\n\t}\r\n\tfor _, bcc := range m.Bcc {\r\n\t\ttolist = append(tolist, bcc)\r\n\t}\r\n\treturn tolist\r\n}","code-length":103,"reference":"\/\/ Tolist returns all the recipients of the email","result":"Generate the Tolist function.","score":[0.1088,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) Bytes() []byte {\r\n\tbuf := bytes.NewBuffer(nil)\r\n\tbuf.WriteString(\"From: \" + m.From.String() + \"\\r\\n\")\r\n\tt := time.Now()\r\n\tbuf.WriteString(\"Date: \" + t.Format(time.RFC1123Z) + \"\\r\\n\")\r\n\tbuf.WriteString(\"To: \" + strings.Join(m.To, \",\") + \"\\r\\n\")\r\n\tif len(m.Cc) > 0 {\r\n\t\tbuf.WriteString(\"Cc: \" + strings.Join(m.Cc, \",\") + \"\\r\\n\")\r\n\t}\r\n\t\r\n\tvar coder = base64.StdEncoding\r\n\tvar subject = \"=?UTF-8?B?\" + coder.EncodeToString([]byte(m.Subject)) + \"?=\"\r\n\tbuf.WriteString(\"Subject: \" + subject + \"\\r\\n\")\r\n\tif len(m.ReplyTo) > 0 {\r\n\t\tbuf.WriteString(\"Reply-To: \" + m.ReplyTo + \"\\r\\n\")\r\n\t}\r\n\tbuf.WriteString(\"MIME-Version: 1.0\\r\\n\")\r\n\t\r\n\tif len(m.Headers) > 0 {\r\n\t\tfor _, header := range m.Headers {\r\n\t\t\tbuf.WriteString(fmt.Sprintf(\"%s: %s\\r\\n\", header.Key, header.Value))\r\n\t\t}\r\n\t}\r\n\tboundary := \"f46d043c813270fc6b04c2d223da\"\r\n\tif len(m.Attachments) > 0 {\r\n\t\tbuf.WriteString(\"Content-Type: multipart\/mixed; boundary=\" + boundary + \"\\r\\n\")\r\n\t\tbuf.WriteString(\"\\r\\n--\" + boundary + \"\\r\\n\")\r\n\t}\r\n\tbuf.WriteString(fmt.Sprintf(\"Content-Type: %s; charset=utf-8\\r\\n\\r\\n\", m.BodyContentType))\r\n\tbuf.WriteString(m.Body)\r\n\tbuf.WriteString(\"\\r\\n\")\r\n\tif len(m.Attachments) > 0 {\r\n\t\tfor _, attachment := range m.Attachments {\r\n\t\t\tbuf.WriteString(\"\\r\\n\\r\\n--\" + boundary + \"\\r\\n\")\r\n\t\t\tif attachment.Inline {\r\n\t\t\t\tbuf.WriteString(\"Content-Type: message\/rfc822\\r\\n\")\r\n\t\t\t\tbuf.WriteString(\"Content-Disposition: inline; filename=\\\"\" + attachment.Filename + \"\\\"\\r\\n\\r\\n\")\r\n\t\t\t\tbuf.Write(attachment.Data)\r\n\t\t\t} else {\r\n\t\t\t\text := filepath.Ext(attachment.Filename)\r\n\t\t\t\tmimetype := mime.TypeByExtension(ext)\r\n\t\t\t\tif mimetype != \"\" {\r\n\t\t\t\t\tmime := fmt.Sprintf(\"Content-Type: %s\\r\\n\", mimetype)\r\n\t\t\t\t\tbuf.WriteString(mime)\r\n\t\t\t\t} else {\r\n\t\t\t\t\tbuf.WriteString(\"Content-Type: application\/octet-stream\\r\\n\")\r\n\t\t\t\t}\r\n\t\t\t\tbuf.WriteString(\"Content-Transfer-Encoding: base64\\r\\n\")\r\n\t\t\t\tbuf.WriteString(\"Content-Disposition: attachment; filename=\\\"=?UTF-8?B?\")\r\n\t\t\t\tbuf.WriteString(coder.EncodeToString([]byte(attachment.Filename)))\r\n\t\t\t\tbuf.WriteString(\"?=\\\"\\r\\n\\r\\n\")\r\n\t\t\t\tb := make([]byte, base64.StdEncoding.EncodedLen(len(attachment.Data)))\r\n\t\t\t\tbase64.StdEncoding.Encode(b, attachment.Data)\r\n\t\t\t\t\r\n\t\t\t\tfor i, l := 0, len(b); i < l; i++ {\r\n\t\t\t\t\tbuf.WriteByte(b[i])\r\n\t\t\t\t\tif (i+1)%76 == 0 {\r\n\t\t\t\t\t\tbuf.WriteString(\"\\r\\n\")\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tbuf.WriteString(\"\\r\\n--\" + boundary)\r\n\t\t}\r\n\t\tbuf.WriteString(\"--\")\r\n\t}\r\n\treturn buf.Bytes()\r\n}","code-length":1026,"reference":"\/\/ Bytes returns the mail data","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Send(addr string, auth smtp.Auth, m *Message) error {\r\n\treturn smtp.SendMail(addr, auth, m.From.Address, m.Tolist(), m.Bytes())\r\n}","code-length":57,"reference":"\/\/ Send sends the message.","result":"Send messages.","score":[0.1116,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Envelope) GetHeader(name string) string {\r\n\tif e.header == nil {\r\n\t\treturn \"\"\r\n\t}\r\n\treturn decodeHeader(e.header.Get(name))\r\n}","code-length":61,"reference":"\/\/ GetHeader processes the specified header for RFC 2047 encoded words and returns the result as a\n\/\/ UTF-8 string","result":"Get the header of an envelope.","score":[0.0223,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Envelope) GetHeaderValues(name string) []string {\r\n\tif e.header == nil {\r\n\t\treturn []string{}\r\n\t}\r\n\trawValues := (*e.header)[textproto.CanonicalMIMEHeaderKey(name)]\r\n\tvar values []string\r\n\tfor _, v := range rawValues {\r\n\t\tvalues = append(values, decodeHeader(v))\r\n\t}\r\n\treturn values\r\n}","code-length":115,"reference":"\/\/ GetHeaderValues processes the specified header for RFC 2047 encoded words and returns all existing\n\/\/ values as a list of UTF-8 strings","result":"Get the header values of an envelope.","score":[0.0232,0.0935]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Envelope) SetHeader(name string, value []string) error {\r\n\tif name == \"\" {\r\n\t\treturn fmt.Errorf(\"Provide non-empty header name\")\r\n\t}\r\n\tfor i, v := range value {\r\n\t\tif i == 0 {\r\n\t\t\te.header.Set(name, mime.BEncoding.Encode(\"utf-8\", v))\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\te.header.Add(name, mime.BEncoding.Encode(\"utf-8\", v))\r\n\t}\r\n\treturn nil\r\n}","code-length":147,"reference":"\/\/ SetHeader sets given header name to the given value.\n\/\/ If the header exists already, all existing values are replaced.","result":"Set the header of the envelope.","score":[0.0248,0.1026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Envelope) AddHeader(name string, value string) error {\r\n\tif name == \"\" {\r\n\t\treturn fmt.Errorf(\"Provide non-empty header name\")\r\n\t}\r\n\te.header.Add(name, mime.BEncoding.Encode(\"utf-8\", value))\r\n\treturn nil\r\n}","code-length":86,"reference":"\/\/ AddHeader appends given header value to header name without changing existing values.\n\/\/ If the header does not exist already, it will be created.","result":"Add header to the envelope.","score":[0.0058,0.087]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Envelope) DeleteHeader(name string) error {\r\n\tif name == \"\" {\r\n\t\treturn fmt.Errorf(\"Provide non-empty header name\")\r\n\t}\r\n\te.header.Del(name)\r\n\treturn nil\r\n}","code-length":70,"reference":"\/\/ DeleteHeader deletes given header.","result":"Delete header from envelope.","score":[0,0.102]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Envelope) AddressList(key string) ([]*mail.Address, error) {\r\n\tif e.header == nil {\r\n\t\treturn nil, fmt.Errorf(\"No headers available\")\r\n\t}\r\n\tif !AddressHeaders[strings.ToLower(key)] {\r\n\t\treturn nil, fmt.Errorf(\"%s is not an address header\", key)\r\n\t}\r\n\tstr := decodeToUTF8Base64Header(e.header.Get(key))\r\n\tif str == \"\" {\r\n\t\treturn nil, mail.ErrHeaderNotPresent\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tret, err := mail.ParseAddressList(str)\r\n\tswitch {\r\n\tcase err == nil:\r\n\t\t\r\n\tcase err.Error() == \"mail: expected comma\":\r\n\t\tret, err = mail.ParseAddressList(ensureCommaDelimitedAddresses(str))\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\tdefault:\r\n\t\treturn nil, err\r\n\t}\r\n\treturn ret, nil\r\n}","code-length":271,"reference":"\/\/ AddressList returns a mail.Address slice with RFC 2047 encoded names converted to UTF-8","result":"Parse address list from envelope.","score":[0,0.0382]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Envelope) Clone() *Envelope {\r\n\tif e == nil {\r\n\t\treturn nil\r\n\t}\r\n\tnewEnvelope := &Envelope{\r\n\t\te.Text,\r\n\t\te.HTML,\r\n\t\te.Root.Clone(nil),\r\n\t\te.Attachments,\r\n\t\te.Inlines,\r\n\t\te.OtherParts,\r\n\t\te.Errors,\r\n\t\te.header,\r\n\t}\r\n\treturn newEnvelope\r\n}","code-length":130,"reference":"\/\/ Clone returns a clone of the current Envelope","result":"Clone envelope.","score":[0.0151,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReadEnvelope(r io.Reader) (*Envelope, error) {\r\n\t\r\n\troot, err := ReadParts(r)\r\n\tif err != nil {\r\n\t\treturn nil, errors.WithMessage(err, \"Failed to ReadParts\")\r\n\t}\r\n\treturn EnvelopeFromPart(root)\r\n}","code-length":85,"reference":"\/\/ ReadEnvelope is a wrapper around ReadParts and EnvelopeFromPart.  It parses the content of the\n\/\/ provided reader into an Envelope, downconverting HTML to plain text if needed, and sorting the\n\/\/ attachments, inlines and other parts into their respective slices. Errors are collected from all\n\/\/ Parts and placed into the Envelope.Errors slice.","result":"Read envelope data.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EnvelopeFromPart(root *Part) (*Envelope, error) {\r\n\te := &Envelope{\r\n\t\tRoot:   root,\r\n\t\theader: &root.Header,\r\n\t}\r\n\tif detectMultipartMessage(root) {\r\n\t\t\r\n\t\tif err := parseMultiPartBody(root, e); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t} else {\r\n\t\tif detectBinaryBody(root) {\r\n\t\t\t\r\n\t\t\tif root.Disposition == cdInline {\r\n\t\t\t\te.Inlines = append(e.Inlines, root)\r\n\t\t\t} else {\r\n\t\t\t\te.Attachments = append(e.Attachments, root)\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\t\r\n\t\t\tif err := parseTextOnlyBody(root, e); err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\tif e.Text == \"\" && e.HTML != \"\" {\r\n\t\t\r\n\t\te.Root.addWarning(\r\n\t\t\tErrorPlainTextFromHTML,\r\n\t\t\t\"Message did not contain a text\/plain part\")\r\n\t\tvar err error\r\n\t\tif e.Text, err = html2text.FromString(e.HTML); err != nil {\r\n\t\t\t\r\n\t\t\te.Text = \"\"\r\n\t\t\tp := e.Root.BreadthMatchFirst(matchHTMLBodyPart)\r\n\t\t\tp.addError(\r\n\t\t\t\tErrorPlainTextFromHTML,\r\n\t\t\t\t\"Failed to downconvert HTML: %v\",\r\n\t\t\t\terr)\r\n\t\t}\r\n\t}\r\n\t\r\n\tif e.Root != nil {\r\n\t\t_ = e.Root.DepthMatchAll(func(part *Part) bool {\r\n\t\t\t\r\n\t\t\tfor i := range part.Errors {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\te.Errors = append(e.Errors, part.Errors[i])\r\n\t\t\t}\r\n\t\t\treturn false\r\n\t\t})\r\n\t}\r\n\treturn e, nil\r\n}","code-length":511,"reference":"\/\/ EnvelopeFromPart uses the provided Part tree to build an Envelope, downconverting HTML to plain\n\/\/ text if needed, and sorting the attachments, inlines and other parts into their respective\n\/\/ slices.  Errors are collected from all Parts and placed into the Envelopes Errors slice.","result":"Parse the envelope from a multipart message.","score":[0.0008,0.062]}
{"code":"\/*is used to<extra_id_0>\r\nfunc parseTextOnlyBody(root *Part, e *Envelope) error {\r\n\t\r\n\tvar charset string\r\n\tvar isHTML bool\r\n\tif ctype := root.Header.Get(hnContentType); ctype != \"\" {\r\n\t\tif mediatype, mparams, _, err := parseMediaType(ctype); err == nil {\r\n\t\t\tisHTML = (mediatype == ctTextHTML)\r\n\t\t\tif mparams[hpCharset] != \"\" {\r\n\t\t\t\tcharset = mparams[hpCharset]\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\tif isHTML {\r\n\t\trawHTML := string(root.Content)\r\n\t\t\r\n\t\te.HTML = rawHTML\r\n\t\tif charset == \"\" {\r\n\t\t\t\r\n\t\t\tif charset = coding.FindCharsetInHTML(rawHTML); charset != \"\" {\r\n\t\t\t\t\r\n\t\t\t\tif convHTML, err := coding.ConvertToUTF8String(charset, root.Content); err == nil {\r\n\t\t\t\t\t\r\n\t\t\t\t\te.HTML = convHTML\r\n\t\t\t\t} else {\r\n\t\t\t\t\t\r\n\t\t\t\t\troot.addWarning(ErrorCharsetConversion, err.Error())\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\treturn nil\r\n\t\t}\r\n\t} else {\r\n\t\te.Text = string(root.Content)\r\n\t}\r\n\treturn nil\r\n}","code-length":335,"reference":"\/\/ parseTextOnlyBody parses a plain text message in root that has MIME-like headers, but\n\/\/ only contains a single part - no boundaries, etc.  The result is placed in e.","result":"Parse text only body.","score":[0.0006,0.0547]}
{"code":"\/*is used to<extra_id_0>\r\nfunc parseMultiPartBody(root *Part, e *Envelope) error {\r\n\t\r\n\tctype := root.Header.Get(hnContentType)\r\n\tmediatype, params, _, err := parseMediaType(ctype)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"Unable to parse media type: %v\", err)\r\n\t}\r\n\tif !strings.HasPrefix(mediatype, ctMultipartPrefix) {\r\n\t\treturn fmt.Errorf(\"Unknown mediatype: %v\", mediatype)\r\n\t}\r\n\tboundary := params[hpBoundary]\r\n\tif boundary == \"\" {\r\n\t\treturn fmt.Errorf(\"Unable to locate boundary param in Content-Type header\")\r\n\t}\r\n\t\r\n\tif mediatype == ctMultipartAltern {\r\n\t\tp := root.BreadthMatchFirst(func(p *Part) bool {\r\n\t\t\treturn p.ContentType == ctTextPlain && p.Disposition != cdAttachment\r\n\t\t})\r\n\t\tif p != nil {\r\n\t\t\te.Text = string(p.Content)\r\n\t\t}\r\n\t} else {\r\n\t\t\r\n\t\tparts := root.DepthMatchAll(func(p *Part) bool {\r\n\t\t\treturn p.ContentType == ctTextPlain && p.Disposition != cdAttachment\r\n\t\t})\r\n\t\tfor i, p := range parts {\r\n\t\t\tif i > 0 {\r\n\t\t\t\te.Text += \"\\n--\\n\"\r\n\t\t\t}\r\n\t\t\te.Text += string(p.Content)\r\n\t\t}\r\n\t}\r\n\t\r\n\tp := root.BreadthMatchFirst(matchHTMLBodyPart)\r\n\tif p != nil {\r\n\t\te.HTML += string(p.Content)\r\n\t}\r\n\t\r\n\te.Attachments = root.BreadthMatchAll(func(p *Part) bool {\r\n\t\treturn p.Disposition == cdAttachment || p.ContentType == ctAppOctetStream\r\n\t})\r\n\t\r\n\te.Inlines = root.BreadthMatchAll(func(p *Part) bool {\r\n\t\treturn p.Disposition == cdInline && !strings.HasPrefix(p.ContentType, ctMultipartPrefix)\r\n\t})\r\n\t\r\n\te.OtherParts = root.BreadthMatchAll(func(p *Part) bool {\r\n\t\tif strings.HasPrefix(p.ContentType, ctMultipartPrefix) {\r\n\t\t\treturn false\r\n\t\t}\r\n\t\tif p.Disposition != \"\" {\r\n\t\t\treturn false\r\n\t\t}\r\n\t\tif p.ContentType == ctAppOctetStream {\r\n\t\t\treturn false\r\n\t\t}\r\n\t\treturn p.ContentType != ctTextPlain && p.ContentType != ctTextHTML\r\n\t})\r\n\treturn nil\r\n}","code-length":663,"reference":"\/\/ parseMultiPartBody parses a multipart message in root.  The result is placed in e.","result":"Code too long,keep in 512.","score":[0.0397,0.0382]}
{"code":"\/*is used to<extra_id_0>\r\nfunc matchHTMLBodyPart(p *Part) bool {\r\n\treturn p.ContentType == ctTextHTML && p.Disposition != cdAttachment\r\n}","code-length":42,"reference":"\/\/ Used by Part matchers to locate the HTML body.  Not inlined because it's used in multiple places.","result":"Match HTML body parts.","score":[0.0096,0.0301]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ensureCommaDelimitedAddresses(s string) string {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\ts = strings.Join(strings.Fields(s), \" \")\r\n\tinQuotes := false\r\n\tinDomain := false\r\n\tescapeSequence := false\r\n\tsb := strings.Builder{}\r\n\tfor _, r := range s {\r\n\t\tif escapeSequence {\r\n\t\t\tescapeSequence = false\r\n\t\t\tsb.WriteRune(r)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif r == '\"' {\r\n\t\t\tinQuotes = !inQuotes\r\n\t\t\tsb.WriteRune(r)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif inQuotes {\r\n\t\t\tif r == '\\\\' {\r\n\t\t\t\tescapeSequence = true\r\n\t\t\t\tsb.WriteRune(r)\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\tif r == '@' {\r\n\t\t\t\tinDomain = true\r\n\t\t\t\tsb.WriteRune(r)\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tif inDomain {\r\n\t\t\t\tif r == ';' {\r\n\t\t\t\t\tsb.WriteRune(r)\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t\tif r == ',' {\r\n\t\t\t\t\tinDomain = false\r\n\t\t\t\t\tsb.WriteRune(r)\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\tif r == ' ' {\r\n\t\t\t\t\tinDomain = false\r\n\t\t\t\t\tsb.WriteRune(',')\r\n\t\t\t\t\tsb.WriteRune(r)\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\tsb.WriteRune(r)\r\n\t}\r\n\treturn sb.String()\r\n}","code-length":424,"reference":"\/\/ Used by AddressList to ensure that address lists are properly delimited","result":"Delimited addresses.","score":[0,0.0455]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p MailBuilder) Date(date time.Time) MailBuilder {\r\n\tp.date = date\r\n\treturn p\r\n}","code-length":41,"reference":"\/\/ Date returns a copy of MailBuilder with the specified Date header.","result":"Generate the generated code.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p MailBuilder) From(name, addr string) MailBuilder {\r\n\tp.from = mail.Address{Name: name, Address: addr}\r\n\treturn p\r\n}","code-length":52,"reference":"\/\/ From returns a copy of MailBuilder with the specified From header.","result":"Create a new mail builder.","score":[0.0593,0.0442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p MailBuilder) Subject(subject string) MailBuilder {\r\n\tp.subject = subject\r\n\treturn p\r\n}","code-length":39,"reference":"\/\/ Subject returns a copy of MailBuilder with the specified Subject header.","result":"Create a new mail builder.","score":[0.0593,0.0442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p MailBuilder) To(name, addr string) MailBuilder {\r\n\tp.to = append(p.to, mail.Address{Name: name, Address: addr})\r\n\treturn p\r\n}","code-length":58,"reference":"\/\/ To returns a copy of MailBuilder with this name & address appended to the To header.  name may be\n\/\/ empty.","result":"Create a new mail builder.","score":[0.008,0.0246]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p MailBuilder) ToAddrs(to []mail.Address) MailBuilder {\r\n\tp.to = to\r\n\treturn p\r\n}","code-length":43,"reference":"\/\/ ToAddrs returns a copy of MailBuilder with the specified To addresses.","result":"Create a new file.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p MailBuilder) CC(name, addr string) MailBuilder {\r\n\tp.cc = append(p.cc, mail.Address{Name: name, Address: addr})\r\n\treturn p\r\n}","code-length":58,"reference":"\/\/ CC returns a copy of MailBuilder with this name & address appended to the CC header.  name may be\n\/\/ empty.","result":"Create a new CC.","score":[0.0035,0.0248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p MailBuilder) CCAddrs(cc []mail.Address) MailBuilder {\r\n\tp.cc = cc\r\n\treturn p\r\n}","code-length":43,"reference":"\/\/ CCAddrs returns a copy of MailBuilder with the specified CC addresses.","result":"Generate the generated code.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p MailBuilder) ReplyTo(name, addr string) MailBuilder {\r\n\tp.replyTo = mail.Address{Name: name, Address: addr}\r\n\treturn p\r\n}","code-length":54,"reference":"\/\/ ReplyTo returns a copy of MailBuilder with this name & address appended to the To header.  name\n\/\/ may be empty.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p MailBuilder) Header(name, value string) MailBuilder {\r\n\t\r\n\th := textproto.MIMEHeader{}\r\n\tfor k, v := range p.header {\r\n\t\th[k] = v\r\n\t}\r\n\th.Add(name, value)\r\n\tp.header = h\r\n\treturn p\r\n}","code-length":93,"reference":"\/\/ Header returns a copy of MailBuilder with the specified value added to the named header.","result":"Add a header to a mail builder.","score":[0.0531,0.0993]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p MailBuilder) AddAttachment(b []byte, contentType string, fileName string) MailBuilder {\r\n\tpart := NewPart(contentType)\r\n\tpart.Content = b\r\n\tpart.FileName = fileName\r\n\tpart.Disposition = cdAttachment\r\n\tp.attachments = append(p.attachments, part)\r\n\treturn p\r\n}","code-length":89,"reference":"\/\/ AddAttachment returns a copy of MailBuilder that includes the specified attachment.","result":"Add attachments.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p MailBuilder) AddFileAttachment(path string) MailBuilder {\r\n\t\r\n\tif p.err != nil {\r\n\t\treturn p\r\n\t}\r\n\tf, err := os.Open(path)\r\n\tif err != nil {\r\n\t\tp.err = err\r\n\t\treturn p\r\n\t}\r\n\tb, err := ioutil.ReadAll(f)\r\n\tif err != nil {\r\n\t\tp.err = err\r\n\t\treturn p\r\n\t}\r\n\tname := filepath.Base(path)\r\n\tctype := mime.TypeByExtension(filepath.Ext(name))\r\n\treturn p.AddAttachment(b, ctype, name)\r\n}","code-length":175,"reference":"\/\/ AddFileAttachment returns a copy of MailBuilder that includes the specified attachment.\n\/\/ fileName, will be populated from the base name of path.  Content type will be detected from the\n\/\/ path extension.","result":"Add file attachments.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p MailBuilder) AddInline(\r\n\tb []byte,\r\n\tcontentType string,\r\n\tfileName string,\r\n\tcontentID string,\r\n) MailBuilder {\r\n\tpart := NewPart(contentType)\r\n\tpart.Content = b\r\n\tpart.FileName = fileName\r\n\tpart.Disposition = cdInline\r\n\tpart.ContentID = contentID\r\n\tp.inlines = append(p.inlines, part)\r\n\treturn p\r\n}","code-length":120,"reference":"\/\/ AddInline returns a copy of MailBuilder that includes the specified inline.  fileName and\n\/\/ contentID may be left empty.","result":"\tcontentID string.","score":[0.0001,0.0275]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p MailBuilder) Equals(o MailBuilder) bool {\r\n\treturn reflect.DeepEqual(p, o)\r\n}","code-length":39,"reference":"\/\/ Equals uses the reflect package to test two MailBuilder structs for equality, primarily for unit\n\/\/ tests.","result":"Compare mail builder.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Part) Encode(writer io.Writer) error {\r\n\tif p.Header == nil {\r\n\t\tp.Header = make(textproto.MIMEHeader)\r\n\t}\r\n\tcte := p.setupMIMEHeaders()\r\n\t\r\n\tb := bufio.NewWriter(writer)\r\n\tp.encodeHeader(b)\r\n\tif len(p.Content) > 0 {\r\n\t\tb.Write(crnl)\r\n\t\tif err := p.encodeContent(b, cte); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tif p.FirstChild == nil {\r\n\t\treturn b.Flush()\r\n\t}\r\n\t\r\n\tendMarker := []byte(\"\\r\\n--\" + p.Boundary + \"--\")\r\n\tmarker := endMarker[:len(endMarker)-2]\r\n\tc := p.FirstChild\r\n\tfor c != nil {\r\n\t\tb.Write(marker)\r\n\t\tb.Write(crnl)\r\n\t\tif err := c.Encode(b); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tc = c.NextSibling\r\n\t}\r\n\tb.Write(endMarker)\r\n\tb.Write(crnl)\r\n\treturn b.Flush()\r\n}","code-length":325,"reference":"\/\/ Encode writes this Part and all its children to the specified writer in MIME format.","result":"Encode the content.","score":[0.0064,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Part) encodeHeader(b *bufio.Writer) {\r\n\tkeys := make([]string, 0, len(p.Header))\r\n\tfor k := range p.Header {\r\n\t\tkeys = append(keys, k)\r\n\t}\r\n\tsort.Strings(keys)\r\n\tfor _, k := range keys {\r\n\t\tfor _, v := range p.Header[k] {\r\n\t\t\tencv := v\r\n\t\t\tswitch selectTransferEncoding([]byte(v), true) {\r\n\t\t\tcase teBase64:\r\n\t\t\t\tencv = mime.BEncoding.Encode(utf8, v)\r\n\t\t\tcase teQuoted:\r\n\t\t\t\tencv = mime.QEncoding.Encode(utf8, v)\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\twb := stringutil.Wrap(76, k, \":_\", encv, \"\\r\\n\")\r\n\t\t\twb[len(k)+1] = ' '\r\n\t\t\tb.Write(wb)\r\n\t\t}\r\n\t}\r\n}","code-length":259,"reference":"\/\/ encodeHeader writes out a sorted list of headers.","result":"Encode the content.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Part) encodeContent(b *bufio.Writer, cte transferEncoding) (err error) {\r\n\tswitch cte {\r\n\tcase teBase64:\r\n\t\tenc := base64.StdEncoding\r\n\t\ttext := make([]byte, enc.EncodedLen(len(p.Content)))\r\n\t\tbase64.StdEncoding.Encode(text, p.Content)\r\n\t\t\r\n\t\tlineLen := 76\r\n\t\tfor len(text) > 0 {\r\n\t\t\tif lineLen > len(text) {\r\n\t\t\t\tlineLen = len(text)\r\n\t\t\t}\r\n\t\t\tif _, err = b.Write(text[:lineLen]); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tb.Write(crnl)\r\n\t\t\ttext = text[lineLen:]\r\n\t\t}\r\n\tcase teQuoted:\r\n\t\tqp := quotedprintable.NewWriter(b)\r\n\t\tif _, err = qp.Write(p.Content); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\terr = qp.Close()\r\n\tdefault:\r\n\t\t_, err = b.Write(p.Content)\r\n\t}\r\n\treturn err\r\n}","code-length":310,"reference":"\/\/ encodeContent writes out the content in the selected encoding.","result":"Encode the content.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc selectTransferEncoding(content []byte, quoteLineBreaks bool) transferEncoding {\r\n\tif len(content) == 0 {\r\n\t\treturn te7Bit\r\n\t}\r\n\t\r\n\tthreshold := b64Percent * len(content) \/ 100\r\n\tbincount := 0\r\n\tfor _, b := range content {\r\n\t\tif (b < ' ' || '~' < b) && b != '\\t' {\r\n\t\t\tif !quoteLineBreaks && (b == '\\r' || b == '\\n') {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tbincount++\r\n\t\t\tif bincount >= threshold {\r\n\t\t\t\treturn teBase64\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif bincount == 0 {\r\n\t\treturn te7Bit\r\n\t}\r\n\treturn teQuoted\r\n}","code-length":209,"reference":"\/\/ selectTransferEncoding scans content for non-ASCII characters and selects 'b' or 'q' encoding.","result":"Select transfer encoding .","score":[0,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc setParamValue(p map[string]string, k, v string) {\r\n\tif v != \"\" {\r\n\t\tp[k] = v\r\n\t}\r\n}","code-length":51,"reference":"\/\/ setParamValue will ignore empty values","result":"Set the value of a parameter.","score":[0,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewBase64Cleaner(r io.Reader) *Base64Cleaner {\r\n\treturn &Base64Cleaner{\r\n\t\tErrors: make([]error, 0),\r\n\t\tr:      r,\r\n\t}\r\n}","code-length":66,"reference":"\/\/ NewBase64Cleaner returns a Base64Cleaner object for the specified reader.  Base64Cleaner\n\/\/ implements the io.Reader interface.","result":"Clean base.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc decodeToUTF8Base64Header(input string) string {\r\n\tif !strings.Contains(input, \"=?\") {\r\n\t\t\r\n\t\treturn input\r\n\t}\r\n\ttokens := strings.FieldsFunc(input, whiteSpaceRune)\r\n\toutput := make([]string, len(tokens))\r\n\tfor i, token := range tokens {\r\n\t\tif len(token) > 4 && strings.Contains(token, \"=?\") {\r\n\t\t\t\r\n\t\t\tprefix := \"\"\r\n\t\t\tsuffix := \"\"\r\n\t\t\tif token[0] == '(' {\r\n\t\t\t\tprefix = \"(\"\r\n\t\t\t\ttoken = token[1:]\r\n\t\t\t}\r\n\t\t\tif token[len(token)-1] == ')' {\r\n\t\t\t\tsuffix = \")\"\r\n\t\t\t\ttoken = token[:len(token)-1]\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\toutput[i] = prefix + mime.BEncoding.Encode(\"UTF-8\", decodeHeader(token)) + suffix\r\n\t\t} else {\r\n\t\t\toutput[i] = token\r\n\t\t}\r\n\t}\r\n\t\r\n\treturn strings.Join(output, \" \")\r\n}","code-length":283,"reference":"\/\/ decodeToUTF8Base64Header decodes a MIME header per RFC 2047, reencoding to =?utf-8b?","result":"Decode a base.","score":[0.0203,0.1689]}
{"code":"\/*is used to<extra_id_0>\r\nfunc parseMediaType(ctype string) (mtype string, params map[string]string, invalidParams []string, err error) {\r\n\tmtype, params, err = mime.ParseMediaType(ctype)\r\n\tif err != nil {\r\n\t\t\r\n\t\tmctype := fixMangledMediaType(ctype, \";\")\r\n\t\tmtype, params, err = mime.ParseMediaType(mctype)\r\n\t\tif err != nil {\r\n\t\t\t\r\n\t\t\tmctype := fixMangledMediaType(ctype, \" \")\r\n\t\t\tif strings.Contains(mctype, `name=\"\"`) {\r\n\t\t\t\tmctype = strings.Replace(mctype, `name=\"\"`, `name=\" \"`, -1)\r\n\t\t\t}\r\n\t\t\tmtype, params, err = mime.ParseMediaType(mctype)\r\n\t\t\tif err != nil {\r\n\t\t\t\t\r\n\t\t\t\tmtype, params, err = mime.ParseMediaType(fixUnquotedSpecials(mctype))\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn \"\", nil, nil, errors.WithStack(err)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif mtype == ctPlaceholder {\r\n\t\tmtype = \"\"\r\n\t}\r\n\tfor name, value := range params {\r\n\t\tif value != pvPlaceholder {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tinvalidParams = append(invalidParams, name)\r\n\t\tdelete(params, name)\r\n\t}\r\n\treturn mtype, params, invalidParams, err\r\n}","code-length":374,"reference":"\/\/ parseMediaType is a more tolerant implementation of Go's mime.ParseMediaType function.","result":"Parse media types.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc fixMangledMediaType(mtype, sep string) string {\r\n\tif mtype == \"\" {\r\n\t\treturn \"\"\r\n\t}\r\n\tparts := strings.Split(mtype, sep)\r\n\tmtype = \"\"\r\n\tfor i, p := range parts {\r\n\t\tswitch i {\r\n\t\tcase 0:\r\n\t\t\tif p == \"\" {\r\n\t\t\t\t\r\n\t\t\t\tp = ctPlaceholder\r\n\t\t\t}\r\n\t\tdefault:\r\n\t\t\tif !strings.Contains(p, \"=\") {\r\n\t\t\t\tp = p + \"=\" + pvPlaceholder\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tp = rfc2047AttributeName(p)\r\n\t\t\tpair := strings.Split(p, \"=\")\r\n\t\t\tif strings.Contains(mtype, pair[0]+\"=\") {\r\n\t\t\t\t\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tif strings.ContainsAny(pair[0], \"()<>@,;:\\\"\\\\\/[]?\") {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t}\r\n\t\tmtype += p\r\n\t\t\r\n\t\t\r\n\t\tif i != len(parts)-1 && !strings.HasSuffix(mtype, \";\") {\r\n\t\t\tmtype += \";\"\r\n\t\t}\r\n\t}\r\n\tif strings.HasSuffix(mtype, \";\") {\r\n\t\tmtype = mtype[:len(mtype)-1]\r\n\t}\r\n\treturn mtype\r\n}","code-length":367,"reference":"\/\/ fixMangledMediaType is used to insert ; separators into media type strings that lack them, and\n\/\/ remove repeated parameters.","result":"Fix media types that contain invalid characters.","score":[0.03,0.1367]}
{"code":"\/*is used to<extra_id_0>\r\nfunc detectMultipartMessage(root *Part) bool {\r\n\t\r\n\tctype := root.Header.Get(hnContentType)\r\n\tmediatype, _, _, err := parseMediaType(ctype)\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\t\r\n\t\r\n\treturn strings.HasPrefix(mediatype, ctMultipartPrefix)\r\n}","code-length":98,"reference":"\/\/ detectMultipartMessage returns true if the message has a recognized multipart Content-Type header","result":"Detect multipart messages.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc detectBinaryBody(root *Part) bool {\r\n\tif detectTextHeader(root.Header, true) {\r\n\t\treturn false\r\n\t}\r\n\tisBin := detectAttachmentHeader(root.Header)\r\n\tif !isBin {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tmediatype, _, _, _ := parseMediaType(root.Header.Get(hnContentType))\r\n\t\tmediatype = strings.ToLower(mediatype)\r\n\t\tif mediatype != ctTextPlain && mediatype != ctTextHTML {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn isBin\r\n}","code-length":161,"reference":"\/\/ detectBinaryBody returns true if the mail header defines a binary body.","result":"Detect binary body.","score":[0.0287,0.1689]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Part) BreadthMatchFirst(matcher PartMatcher) *Part {\r\n\tq := list.New()\r\n\tq.PushBack(p)\r\n\t\r\n\tfor q.Len() > 0 {\r\n\t\te := q.Front()\r\n\t\tp := e.Value.(*Part)\r\n\t\tif matcher(p) {\r\n\t\t\treturn p\r\n\t\t}\r\n\t\tq.Remove(e)\r\n\t\tc := p.FirstChild\r\n\t\tfor c != nil {\r\n\t\t\tq.PushBack(c)\r\n\t\t\tc = c.NextSibling\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":171,"reference":"\/\/ BreadthMatchFirst performs a breadth first search of the Part tree and returns the first part\n\/\/ that causes the given matcher to return true","result":"Match the part in a subtree.","score":[0.0107,0.0649]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Part) BreadthMatchAll(matcher PartMatcher) []*Part {\r\n\tq := list.New()\r\n\tq.PushBack(p)\r\n\tmatches := make([]*Part, 0, 10)\r\n\t\r\n\tfor q.Len() > 0 {\r\n\t\te := q.Front()\r\n\t\tp := e.Value.(*Part)\r\n\t\tif matcher(p) {\r\n\t\t\tmatches = append(matches, p)\r\n\t\t}\r\n\t\tq.Remove(e)\r\n\t\tc := p.FirstChild\r\n\t\tfor c != nil {\r\n\t\t\tq.PushBack(c)\r\n\t\t\tc = c.NextSibling\r\n\t\t}\r\n\t}\r\n\treturn matches\r\n}","code-length":192,"reference":"\/\/ BreadthMatchAll performs a breadth first search of the Part tree and returns all parts that cause\n\/\/ the given matcher to return true","result":"Match all parts in a document.","score":[0.015,0.1151]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Part) DepthMatchFirst(matcher PartMatcher) *Part {\r\n\troot := p\r\n\tfor {\r\n\t\tif matcher(p) {\r\n\t\t\treturn p\r\n\t\t}\r\n\t\tc := p.FirstChild\r\n\t\tif c != nil {\r\n\t\t\tp = c\r\n\t\t} else {\r\n\t\t\tfor p.NextSibling == nil {\r\n\t\t\t\tif p == root {\r\n\t\t\t\t\treturn nil\r\n\t\t\t\t}\r\n\t\t\t\tp = p.Parent\r\n\t\t\t}\r\n\t\t\tp = p.NextSibling\r\n\t\t}\r\n\t}\r\n}","code-length":159,"reference":"\/\/ DepthMatchFirst performs a depth first search of the Part tree and returns the first part that\n\/\/ causes the given matcher to return true","result":"Generate code for the generated code.","score":[0.0081,0.0216]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Part) DepthMatchAll(matcher PartMatcher) []*Part {\r\n\troot := p\r\n\tmatches := make([]*Part, 0, 10)\r\n\tfor {\r\n\t\tif matcher(p) {\r\n\t\t\tmatches = append(matches, p)\r\n\t\t}\r\n\t\tc := p.FirstChild\r\n\t\tif c != nil {\r\n\t\t\tp = c\r\n\t\t} else {\r\n\t\t\tfor p.NextSibling == nil {\r\n\t\t\t\tif p == root {\r\n\t\t\t\t\treturn matches\r\n\t\t\t\t}\r\n\t\t\t\tp = p.Parent\r\n\t\t\t}\r\n\t\t\tp = p.NextSibling\r\n\t\t}\r\n\t}\r\n}","code-length":180,"reference":"\/\/ DepthMatchAll performs a depth first search of the Part tree and returns all parts that causes\n\/\/ the given matcher to return true","result":"Match all parts in a tree.","score":[0.015,0.1151]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ToASCII(s string) string {\r\n\t\r\n\ttr := transform.Chain(norm.NFD, runes.Remove(runes.In(unicode.Mn)), runes.Map(mapLatinSpecial),\r\n\t\tnorm.NFC)\r\n\tr, _, _ := transform.String(tr, s)\r\n\treturn r\r\n}","code-length":92,"reference":"\/\/ ToASCII converts unicode to ASCII by stripping accents and converting some special characters\n\/\/ into their ASCII approximations.  Anything else will be replaced with an underscore.","result":"Convert to ASCII.","score":[0.0001,0.0407]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPart(contentType string) *Part {\r\n\treturn &Part{\r\n\t\tHeader:      make(textproto.MIMEHeader),\r\n\t\tContentType: contentType,\r\n\t}\r\n}","code-length":56,"reference":"\/\/ NewPart creates a new Part object.","result":"Create a new part.","score":[0.2134,0.4395]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Part) AddChild(child *Part) {\r\n\tif p == child {\r\n\t\t\r\n\t\treturn\r\n\t}\r\n\tif p != nil {\r\n\t\tif p.FirstChild == nil {\r\n\t\t\t\r\n\t\t\tp.FirstChild = child\r\n\t\t} else {\r\n\t\t\t\r\n\t\t\tcurrent := p.FirstChild\r\n\t\t\tfor current.NextSibling != nil {\r\n\t\t\t\tcurrent = current.NextSibling\r\n\t\t\t}\r\n\t\t\tif current == child {\r\n\t\t\t\t\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tcurrent.NextSibling = child\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor c := child; c != nil; c = c.NextSibling {\r\n\t\tif c == c.NextSibling {\r\n\t\t\t\r\n\t\t\treturn\r\n\t\t}\r\n\t\tc.Parent = p\r\n\t}\r\n}","code-length":227,"reference":"\/\/ AddChild adds a child part to either FirstChild or the end of the children NextSibling chain.\n\/\/ The child may have siblings and children attached.  This method will set the Parent field on\n\/\/ child and all its siblings. Safe to call on nil.","result":"Add a child to a part.","score":[0.0005,0.0487]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Part) TextContent() bool {\r\n\tif p.ContentType == \"\" {\r\n\t\t\r\n\t\treturn true\r\n\t}\r\n\treturn strings.HasPrefix(p.ContentType, \"text\/\") ||\r\n\t\tstrings.HasPrefix(p.ContentType, ctMultipartPrefix)\r\n}","code-length":81,"reference":"\/\/ TextContent indicates whether the content is text based on its content type.  This value\n\/\/ determines what content transfer encoding scheme to use.","result":"Check if the part is text.","score":[0.0114,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Part) setupHeaders(r *bufio.Reader, defaultContentType string) error {\r\n\theader, err := readHeader(r, p)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tp.Header = header\r\n\tctype := header.Get(hnContentType)\r\n\tif ctype == \"\" {\r\n\t\tif defaultContentType == \"\" {\r\n\t\t\tp.addWarning(ErrorMissingContentType, \"MIME parts should have a Content-Type header\")\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tctype = defaultContentType\r\n\t}\r\n\t\r\n\tmtype, mparams, minvalidParams, err := parseMediaType(ctype)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif mtype == \"\" && len(mparams) > 0 {\r\n\t\tp.addWarning(\r\n\t\t\tErrorMissingContentType,\r\n\t\t\t\"Content-Type header has parameters but no content type\")\r\n\t}\r\n\tfor i := range minvalidParams {\r\n\t\tp.addWarning(\r\n\t\t\tErrorMalformedHeader,\r\n\t\t\t\"Content-Type header has malformed parameter %q\",\r\n\t\t\tminvalidParams[i])\r\n\t}\r\n\tp.ContentType = mtype\r\n\t\r\n\tp.setupContentHeaders(mparams)\r\n\tp.Boundary = mparams[hpBoundary]\r\n\tp.ContentID = coding.FromIDHeader(header.Get(hnContentID))\r\n\treturn nil\r\n}","code-length":367,"reference":"\/\/ setupHeaders reads the header, then populates the MIME header values for this Part.","result":"Parse the MIME part.","score":[0.0371,0.1966]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Part) setupContentHeaders(mediaParams map[string]string) {\r\n\t\r\n\tdisposition, dparams, _, err := parseMediaType(p.Header.Get(hnContentDisposition))\r\n\tif err == nil {\r\n\t\t\r\n\t\tp.Disposition = disposition\r\n\t\tp.FileName = decodeHeader(dparams[hpFilename])\r\n\t}\r\n\tif p.FileName == \"\" && mediaParams[hpName] != \"\" {\r\n\t\tp.FileName = decodeHeader(mediaParams[hpName])\r\n\t}\r\n\tif p.FileName == \"\" && mediaParams[hpFile] != \"\" {\r\n\t\tp.FileName = decodeHeader(mediaParams[hpFile])\r\n\t}\r\n\tif p.Charset == \"\" {\r\n\t\tp.Charset = mediaParams[hpCharset]\r\n\t}\r\n\tif p.FileModDate.IsZero() {\r\n\t\tp.FileModDate, _ = time.Parse(time.RFC822, mediaParams[hpModDate])\r\n\t}\r\n}","code-length":255,"reference":"\/\/ setupContentHeaders uses Content-Type media params and Content-Disposition headers to populate\n\/\/ the disposition, filename, and charset fields.","result":"Disposition header.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Part) convertFromDetectedCharset(r io.Reader) (io.Reader, error) {\r\n\t\r\n\tvar cd *chardet.Detector\r\n\tswitch p.ContentType {\r\n\tcase \"text\/html\":\r\n\t\tcd = chardet.NewHtmlDetector()\r\n\tdefault:\r\n\t\tcd = chardet.NewTextDetector()\r\n\t}\r\n\tbuf, err := ioutil.ReadAll(r)\r\n\tif err != nil {\r\n\t\treturn nil, errors.WithStack(err)\r\n\t}\r\n\tcs, err := cd.DetectBest(buf)\r\n\tswitch err {\r\n\tcase nil:\r\n\t\t\r\n\tcase chardet.NotDetectedError:\r\n\t\tp.addWarning(ErrorCharsetDeclaration, \"charset could not be detected: %v\", err)\r\n\tdefault:\r\n\t\treturn nil, errors.WithStack(err)\r\n\t}\r\n\t\r\n\tr = bytes.NewReader(buf)\r\n\tif cs == nil || cs.Confidence < minCharsetConfidence {\r\n\t\t\r\n\t\treturn p.convertFromStatedCharset(r), nil\r\n\t}\r\n\t\r\n\tif p.Charset != \"\" && !strings.EqualFold(cs.Charset, p.Charset) {\r\n\t\tp.addWarning(ErrorCharsetDeclaration,\r\n\t\t\t\"declared charset %q, detected %q, confidence %d\",\r\n\t\t\tp.Charset, cs.Charset, cs.Confidence)\r\n\t}\r\n\treader, err := coding.NewCharsetReader(cs.Charset, r)\r\n\tif err != nil {\r\n\t\t\r\n\t\tp.addWarning(ErrorCharsetConversion, err.Error())\r\n\t} else {\r\n\t\tr = reader\r\n\t\tp.OrigCharset = p.Charset\r\n\t\tp.Charset = cs.Charset\r\n\t}\r\n\treturn r, nil\r\n}","code-length":463,"reference":"\/\/ convertFromDetectedCharset attempts to detect the character set for the given part, and returns\n\/\/ an io.Reader that will convert from that charset to UTF-8. If the charset cannot be detected,\n\/\/ this method adds a warning to the part and automatically falls back to using\n\/\/ `convertFromStatedCharset` and returns the reader from that method.","result":"Convert from detected charset.","score":[0.0,0.0301]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Part) Clone(parent *Part) *Part {\r\n\tif p == nil {\r\n\t\treturn nil\r\n\t}\r\n\tnewPart := &Part{\r\n\t\tPartID:      p.PartID,\r\n\t\tHeader:      p.Header,\r\n\t\tParent:      parent,\r\n\t\tBoundary:    p.Boundary,\r\n\t\tContentID:   p.ContentID,\r\n\t\tContentType: p.ContentType,\r\n\t\tDisposition: p.Disposition,\r\n\t\tFileName:    p.FileName,\r\n\t\tCharset:     p.Charset,\r\n\t\tErrors:      p.Errors,\r\n\t\tContent:     p.Content,\r\n\t\tEpilogue:    p.Epilogue,\r\n\t}\r\n\tnewPart.FirstChild = p.FirstChild.Clone(newPart)\r\n\tnewPart.NextSibling = p.NextSibling.Clone(parent)\r\n\treturn newPart\r\n}","code-length":237,"reference":"\/\/ Clone returns a clone of the current Part.","result":"Clone the part.","score":[0.0657,0.1786]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReadParts(r io.Reader) (*Part, error) {\r\n\tbr := bufio.NewReader(r)\r\n\troot := &Part{PartID: \"0\"}\r\n\t\r\n\terr := root.setupHeaders(br, `text\/plain; charset=\"us-ascii\"`)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif strings.HasPrefix(root.ContentType, ctMultipartPrefix) {\r\n\t\t\r\n\t\terr = parseParts(root, br)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t} else {\r\n\t\t\r\n\t\tif err := root.decodeContent(br); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\treturn root, nil\r\n}","code-length":209,"reference":"\/\/ ReadParts reads a MIME document from the provided reader and parses it into tree of Part objects.","result":"Read parts from a file.","score":[0.0212,0.1198]}
{"code":"\/*is used to<extra_id_0>\r\nfunc parseParts(parent *Part, reader *bufio.Reader) error {\r\n\tfirstRecursion := parent.Parent == nil\r\n\t\r\n\tbr := newBoundaryReader(reader, parent.Boundary)\r\n\tfor indexPartID := 1; true; indexPartID++ {\r\n\t\tnext, err := br.Next()\r\n\t\tif err != nil && errors.Cause(err) != io.EOF {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif !next {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tp := &Part{}\r\n\t\t\r\n\t\tif firstRecursion {\r\n\t\t\tp.PartID = strconv.Itoa(indexPartID)\r\n\t\t} else {\r\n\t\t\tp.PartID = parent.PartID + \".\" + strconv.Itoa(indexPartID)\r\n\t\t}\r\n\t\t\r\n\t\tbbr := bufio.NewReader(br)\r\n\t\terr = p.setupHeaders(bbr, \"\")\r\n\t\tif errors.Cause(err) == errEmptyHeaderBlock {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tif _, err = br.Next(); err != nil {\r\n\t\t\t\tif errors.Cause(err) == io.EOF || strings.HasSuffix(err.Error(), \"EOF\") {\r\n\t\t\t\t\t\r\n\t\t\t\t\t\r\n\t\t\t\t\tparent.addWarning(ErrorMissingBoundary, \"Boundary %q was not closed correctly\",\r\n\t\t\t\t\t\tparent.Boundary)\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\treturn errors.WithMessage(err, fmt.Sprintf(\"error at boundary %v\", parent.Boundary))\r\n\t\t\t}\r\n\t\t} else if err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\tparent.AddChild(p)\r\n\t\tif p.Boundary == \"\" {\r\n\t\t\t\r\n\t\t\tif err := p.decodeContent(bbr); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\t\r\n\t\t\terr = parseParts(p, bbr)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\tepilogue, err := ioutil.ReadAll(reader)\r\n\tif err != nil {\r\n\t\treturn errors.WithStack(err)\r\n\t}\r\n\tparent.Epilogue = epilogue\r\n\t\r\n\t\r\n\tif !firstRecursion {\r\n\t\tparent.PartID += \".0\"\r\n\t}\r\n\treturn nil\r\n}","code-length":623,"reference":"\/\/ parseParts recursively parses a MIME multipart document and sets each Parts PartID.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UUID() string {\r\n\tuuid := make([]byte, 16)\r\n\tuuidMutex.Lock()\r\n\t_, _ = uuidRand.Read(uuid)\r\n\tuuidMutex.Unlock()\r\n\t\r\n\tuuid[8] = uuid[8]&^0xc0 | 0x80\r\n\t\r\n\tuuid[6] = uuid[6]&^0xf0 | 0x40\r\n\treturn fmt.Sprintf(\"%x-%x-%x-%x-%x\", uuid[0:4], uuid[4:6], uuid[6:8], uuid[8:10], uuid[10:])\r\n}","code-length":156,"reference":"\/\/ UUID generates a random UUID according to RFC 4122.","result":"Generate a random UUID.","score":[0.1008,0.3132]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewQPCleaner(r io.Reader) *QPCleaner {\r\n\treturn &QPCleaner{\r\n\t\tin: bufio.NewReader(r),\r\n\t}\r\n}","code-length":60,"reference":"\/\/ NewQPCleaner returns a QPCleaner for the specified reader.","result":"Create a new leaner.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Error) Error() string {\r\n\tsev := \"W\"\r\n\tif e.Severe {\r\n\t\tsev = \"E\"\r\n\t}\r\n\treturn fmt.Sprintf(\"[%s] %s: %s\", sev, e.Name, e.Detail)\r\n}","code-length":84,"reference":"\/\/ Error formats the enmime.Error as a string.","result":"Generate the error message.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Part) addError(name string, detailFmt string, args ...interface{}) {\r\n\tp.Errors = append(\r\n\t\tp.Errors,\r\n\t\t&Error{\r\n\t\t\tname,\r\n\t\t\tfmt.Sprintf(detailFmt, args...),\r\n\t\t\ttrue,\r\n\t\t})\r\n}","code-length":89,"reference":"\/\/ addWarning builds a severe Error and appends to the Part error slice.","result":"Add errors to part.","score":[0.0337,0.124]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Part) addWarning(name string, detailFmt string, args ...interface{}) {\r\n\tp.Errors = append(\r\n\t\tp.Errors,\r\n\t\t&Error{\r\n\t\t\tname,\r\n\t\t\tfmt.Sprintf(detailFmt, args...),\r\n\t\t\tfalse,\r\n\t\t})\r\n}","code-length":90,"reference":"\/\/ addWarning builds a non-severe Error and appends to the Part error slice.","result":"Add a warning to the part.","score":[0.0941,0.2566]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Wrap(max int, strs ...string) []byte {\r\n\tinput := make([]byte, 0)\r\n\toutput := make([]byte, 0)\r\n\tfor _, s := range strs {\r\n\t\tinput = append(input, []byte(s)...)\r\n\t}\r\n\tif len(input) < max {\r\n\t\t\r\n\t\treturn input\r\n\t}\r\n\tls := -1\r\n\tlw := -1\r\n\tll := 0\r\n\tfor i := 0; i < len(input); i++ {\r\n\t\tll++\r\n\t\tswitch input[i] {\r\n\t\tcase ' ', '\\t':\r\n\t\t\tls = i\r\n\t\t}\r\n\t\tif ll >= max {\r\n\t\t\tif ls >= 0 {\r\n\t\t\t\toutput = append(output, input[lw+1:ls]...)\r\n\t\t\t\toutput = append(output, '\\r', '\\n', ' ')\r\n\t\t\t\tlw = ls\r\n\t\t\t\tll = 1\r\n\t\t\t\t\r\n\t\t\t\ti = lw + 1\r\n\t\t\t\tls = -1\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn append(output, input[lw+1:]...)\r\n}","code-length":301,"reference":"\/\/ Wrap builds a byte slice from strs, wrapping on word boundaries before max chars","result":"Wrap strings .","score":[0.0075,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ConvertToUTF8String(charset string, textBytes []byte) (string, error) {\r\n\tif strings.ToLower(charset) == utf8 {\r\n\t\treturn string(textBytes), nil\r\n\t}\r\n\tcsentry, ok := encodings[strings.ToLower(charset)]\r\n\tif !ok {\r\n\t\treturn \"\", fmt.Errorf(\"Unsupported charset %q\", charset)\r\n\t}\r\n\tinput := bytes.NewReader(textBytes)\r\n\treader := transform.NewReader(input, csentry.e.NewDecoder())\r\n\toutput, err := ioutil.ReadAll(reader)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn string(output), nil\r\n}","code-length":183,"reference":"\/\/ ConvertToUTF8String uses the provided charset to decode a slice of bytes into a normal\n\/\/ UTF-8 string.","result":"Convert text bytes to UTF.","score":[0.0212,0.0599]}
{"code":"\/*is used to<extra_id_0>\r\nfunc JoinAddress(addrs []mail.Address) string {\r\n\tif len(addrs) == 0 {\r\n\t\treturn \"\"\r\n\t}\r\n\tbuf := &bytes.Buffer{}\r\n\tfor i, a := range addrs {\r\n\t\tif i > 0 {\r\n\t\t\t_, _ = buf.WriteString(\", \")\r\n\t\t}\r\n\t\t_, _ = buf.WriteString(a.String())\r\n\t}\r\n\treturn buf.String()\r\n}","code-length":124,"reference":"\/\/ JoinAddress formats a slice of Address structs such that they can be used in a To or Cc header.","result":"Join addresses.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (md *markdown) Printf(format string, args ...interface{}) {\r\n\tfmt.Fprintf(md, format, args...)\r\n}","code-length":43,"reference":"\/\/ Printf implements fmt.Printf for markdown","result":"Generate markdown.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EnvelopeToMarkdown(w io.Writer, e *enmime.Envelope, name string) error {\r\n\tmd := &markdown{bufio.NewWriter(w)}\r\n\tmd.H1(name)\r\n\t\r\n\tmd.H2(\"Header\")\r\n\tif e.Root != nil && e.Root.Header != nil {\r\n\t\tkeys := make([]string, 0, len(e.Root.Header))\r\n\t\tfor k := range e.Root.Header {\r\n\t\t\tswitch strings.ToLower(k) {\r\n\t\t\tcase \"from\", \"to\", \"cc\", \"bcc\", \"reply-to\", \"subject\":\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tkeys = append(keys, k)\r\n\t\t}\r\n\t\tsort.Strings(keys)\r\n\t\tfor _, k := range keys {\r\n\t\t\tmd.Printf(\"    %v: %v\\n\", k, e.GetHeader(k))\r\n\t\t}\r\n\t}\r\n\tmd.Println()\r\n\tmd.H2(\"Envelope\")\r\n\tfor _, hkey := range addressHeaders {\r\n\t\taddrlist, err := e.AddressList(hkey)\r\n\t\tif err != nil {\r\n\t\t\tif err == mail.ErrHeaderNotPresent {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tmd.H3(hkey)\r\n\t\tfor _, addr := range addrlist {\r\n\t\t\tmd.Printf(\"- %v `<%v>`\\n\", addr.Name, addr.Address)\r\n\t\t}\r\n\t\tmd.Println()\r\n\t}\r\n\tmd.H3(\"Subject\")\r\n\tmd.Println(e.GetHeader(\"Subject\"))\r\n\tmd.Println()\r\n\tmd.H2(\"Body Text\")\r\n\tmd.Println(e.Text)\r\n\tmd.Println()\r\n\tmd.H2(\"Body HTML\")\r\n\tmd.Println(e.HTML)\r\n\tmd.Println()\r\n\tmd.H2(\"Attachment List\")\r\n\tfor _, a := range e.Attachments {\r\n\t\tmd.Printf(\"- %v (%v)\\n\", a.FileName, a.ContentType)\r\n\t\tif a.ContentID != \"\" {\r\n\t\t\tmd.Printf(\"  Content-ID: %s\\n\", a.ContentID)\r\n\t\t}\r\n\t}\r\n\tmd.Println()\r\n\tmd.H2(\"Inline List\")\r\n\tfor _, a := range e.Inlines {\r\n\t\tmd.Printf(\"- %v (%v)\\n\", a.FileName, a.ContentType)\r\n\t\tif a.ContentID != \"\" {\r\n\t\t\tmd.Printf(\"  Content-ID: %s\\n\", a.ContentID)\r\n\t\t}\r\n\t}\r\n\tmd.Println()\r\n\tmd.H2(\"Other Part List\")\r\n\tfor _, a := range e.OtherParts {\r\n\t\tmd.Printf(\"- %v (%v)\\n\", a.FileName, a.ContentType)\r\n\t\tif a.ContentID != \"\" {\r\n\t\t\tmd.Printf(\"  Content-ID: %s\\n\", a.ContentID)\r\n\t\t}\r\n\t}\r\n\tmd.Println()\r\n\tmd.H2(\"MIME Part Tree\")\r\n\tif e.Root == nil {\r\n\t\tmd.Println(\"Message was not MIME encoded\")\r\n\t} else {\r\n\t\tFormatPart(md, e.Root, \"    \")\r\n\t}\r\n\tif len(e.Errors) > 0 {\r\n\t\tmd.Println()\r\n\t\tmd.H2(\"Errors\")\r\n\t\tfor _, perr := range e.Errors {\r\n\t\t\tmd.Println(\"-\", perr)\r\n\t\t}\r\n\t}\r\n\treturn md.Flush()\r\n}","code-length":951,"reference":"\/\/ EnvelopeToMarkdown renders the contents of an enmime.Envelope in Markdown format. Used by\n\/\/ mime-dump and mime-extractor commands.","result":"Code too long,keep in 512.","score":[0.0178,0.0299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FormatPart(w io.Writer, p *enmime.Part, indent string) {\r\n\tif p == nil {\r\n\t\treturn\r\n\t}\r\n\tsibling := p.NextSibling\r\n\tchild := p.FirstChild\r\n\t\r\n\tmyindent := indent + \"`-- \"\r\n\tchildindent := indent + \"    \"\r\n\tif sibling != nil {\r\n\t\tmyindent = indent + \"|-- \"\r\n\t\tchildindent = indent + \"|   \"\r\n\t}\r\n\tif p.Parent == nil {\r\n\t\t\r\n\t\tmyindent = indent\r\n\t\tchildindent = indent\r\n\t}\r\n\t\r\n\tctype := \"MISSING TYPE\"\r\n\tif p.ContentType != \"\" {\r\n\t\tctype = p.ContentType\r\n\t}\r\n\tdisposition := \"\"\r\n\tif p.Disposition != \"\" {\r\n\t\tdisposition = fmt.Sprintf(\", disposition: %s\", p.Disposition)\r\n\t}\r\n\tfilename := \"\"\r\n\tif p.FileName != \"\" {\r\n\t\tfilename = fmt.Sprintf(\", filename: %q\", p.FileName)\r\n\t}\r\n\terrors := \"\"\r\n\tif len(p.Errors) > 0 {\r\n\t\terrors = fmt.Sprintf(\" (errors: %v)\", len(p.Errors))\r\n\t}\r\n\tfmt.Fprintf(w, \"%s%s%s%s%s\\n\", myindent, ctype, disposition, filename, errors)\r\n\t\r\n\tFormatPart(w, child, childindent)\r\n\tFormatPart(w, sibling, indent)\r\n}","code-length":387,"reference":"\/\/ FormatPart pretty prints the Part tree","result":"Format the content.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newBoundaryReader(reader *bufio.Reader, boundary string) *boundaryReader {\r\n\tfullBoundary := []byte(\"\\n--\" + boundary + \"--\")\r\n\treturn &boundaryReader{\r\n\t\tr:        reader,\r\n\t\tnlPrefix: fullBoundary[:len(fullBoundary)-2],\r\n\t\tprefix:   fullBoundary[1 : len(fullBoundary)-2],\r\n\t\tfinal:    fullBoundary[1:],\r\n\t\tbuffer:   new(bytes.Buffer),\r\n\t}\r\n}","code-length":131,"reference":"\/\/ newBoundaryReader returns an initialized boundaryReader","result":"Create a new boundary reader.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *boundaryReader) Read(dest []byte) (n int, err error) {\r\n\tif b.buffer.Len() >= len(dest) {\r\n\t\t\r\n\t\treturn b.buffer.Read(dest)\r\n\t}\r\n\tpeek, err := b.r.Peek(peekBufferSize)\r\n\tpeekEOF := (err == io.EOF)\r\n\tif err != nil && !peekEOF && err != bufio.ErrBufferFull {\r\n\t\t\r\n\t\treturn 0, errors.WithStack(err)\r\n\t}\r\n\tvar nCopy int\r\n\tidx, complete := locateBoundary(peek, b.nlPrefix)\r\n\tif idx != -1 {\r\n\t\t\r\n\t\tnCopy = idx\r\n\t\tif !complete && nCopy == 0 {\r\n\t\t\t\r\n\t\t\tnCopy = 1\r\n\t\t}\r\n\t} else {\r\n\t\t\r\n\t\tif nCopy = len(peek) - len(b.nlPrefix) - 1; nCopy <= 0 {\r\n\t\t\tnCopy = 0\r\n\t\t\tif peekEOF {\r\n\t\t\t\t\r\n\t\t\t\treturn 0, errors.WithStack(io.ErrUnexpectedEOF)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif nCopy > 0 {\r\n\t\tif _, err = io.CopyN(b.buffer, b.r, int64(nCopy)); err != nil {\r\n\t\t\treturn 0, errors.WithStack(err)\r\n\t\t}\r\n\t}\r\n\tn, err = b.buffer.Read(dest)\r\n\tif err == io.EOF && !complete {\r\n\t\t\r\n\t\treturn n, nil\r\n\t}\r\n\treturn n, err\r\n}","code-length":420,"reference":"\/\/ Read returns a buffer containing the content up until boundary","result":"Read the boundary.","score":[0.0337,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *boundaryReader) Next() (bool, error) {\r\n\tif b.finished {\r\n\t\treturn false, nil\r\n\t}\r\n\tif b.partsRead > 0 {\r\n\t\t\r\n\t\t_, _ = io.Copy(ioutil.Discard, b)\r\n\t}\r\n\tfor {\r\n\t\tline, err := b.r.ReadSlice('\\n')\r\n\t\tif err != nil && err != io.EOF {\r\n\t\t\treturn false, errors.WithStack(err)\r\n\t\t}\r\n\t\tif len(line) > 0 && (line[0] == '\\r' || line[0] == '\\n') {\r\n\t\t\t\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif b.isTerminator(line) {\r\n\t\t\tb.finished = true\r\n\t\t\treturn false, nil\r\n\t\t}\r\n\t\tif err != io.EOF && b.isDelimiter(line) {\r\n\t\t\t\r\n\t\t\tb.partsRead++\r\n\t\t\treturn true, nil\r\n\t\t}\r\n\t\tif err == io.EOF {\r\n\t\t\t\r\n\t\t\treturn false, io.EOF\r\n\t\t}\r\n\t\tif b.partsRead == 0 {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tb.finished = true\r\n\t\treturn false, errors.Errorf(\"expecting boundary %q, got %q\", string(b.prefix), string(line))\r\n\t}\r\n}","code-length":365,"reference":"\/\/ Next moves over the boundary to the next part, returns true if there is another part to be read.","result":"Read the next boundary.","score":[0.0083,0.1019]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Parse(buf []byte, offset int) (interface{}, error) {\r\n\tobj, _, err := parseReturningOffset(buf, offset)\r\n\treturn obj, err\r\n}","code-length":53,"reference":"\/\/ Parse converts a byte array containing R SEXP to a golang object.\n\/\/ This can be converted to native golang types.","result":"Parse the input .","score":[0.0035,0.0248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Assign(symbol string, value interface{}) ([]byte, error) {\r\n\tswitch value.(type) {\r\n\tcase []float64:\r\n\t\treturn assignDoubleArray(symbol, value.([]float64))\r\n\tcase []int32:\r\n\t\treturn assignIntArray(symbol, value.([]int32))\r\n\tcase []string:\r\n\t\treturn assignStrArray(symbol, value.([]string))\r\n\tcase []byte:\r\n\t\treturn assignByteArray(symbol, value.([]byte))\r\n\tcase string:\r\n\t\treturn assignStr(symbol, value.(string))\r\n\tcase int32:\r\n\t\treturn assignInt(symbol, value.(int32))\r\n\tcase float64:\r\n\t\treturn assignDouble(symbol, value.(float64))\r\n\tdefault:\r\n\t\treturn nil, errors.New(\"session assign: type is not supported\")\r\n\t}\r\n}","code-length":233,"reference":"\/\/ Assign produces a command to assign a value to a variable within a go session","result":"Assign a value to a session.","score":[0.1207,0.248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRClient(host string, port int64) (RClient, error) {\r\n\treturn NewRClientWithAuth(host, port, \"\", \"\")\r\n}","code-length":48,"reference":"\/\/ NewRClient creates a RClient which will run commands on the RServe server located at the provided host and port","result":"Create a new RClient.","score":[0.0059,0.1019]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRClientWithAuth(host string, port int64, user, password string) (RClient, error) {\r\n\taddr, err := net.ResolveTCPAddr(\"tcp\", host+\":\"+strconv.FormatInt(port, 10))\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\trClient := &roger{\r\n\t\taddress:  addr,\r\n\t\tuser:     user,\r\n\t\tpassword: password,\r\n\t}\r\n\tif _, err = rClient.Eval(\"'Test session connection'\"); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn rClient, nil\r\n}","code-length":169,"reference":"\/\/ NewRClientWithAuth creates a RClient with the specified credentials and RServe server details","result":"Create a new RClient with auth.","score":[0.0941,0.3049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Register(identifier string, generator func() string) {\r\n\tfakeType := inflect.Camelize(identifier)\r\n\tcustomGenerators[fakeType] = generator\r\n}","code-length":49,"reference":"\/\/ Register allows user to add his own data generators for special cases\n\/\/ that we could not cover with the generators that fako includes by default.","result":"Register custom generators.","score":[0.0001,0.0203]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Fuzz(e interface{}) {\r\n\tty := reflect.TypeOf(e)\r\n\tif ty.Kind() == reflect.Ptr {\r\n\t\tty = ty.Elem()\r\n\t}\r\n\tif ty.Kind() == reflect.Struct {\r\n\t\tvalue := reflect.ValueOf(e).Elem()\r\n\t\tfor i := 0; i < ty.NumField(); i++ {\r\n\t\t\tfield := value.Field(i)\r\n\t\t\tif field.CanSet() {\r\n\t\t\t\tfield.Set(fuzzValueFor(field.Kind()))\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":162,"reference":"\/\/ Fuzz Fills passed interface with random data based on the struct field type,\n\/\/ take a look at fuzzValueFor for details on supported data types.","result":"Generate fuzz code.","score":[0,0.0211]}
{"code":"\/*is used to<extra_id_0>\r\nfunc findFakeFunctionFor(fako string) func() string {\r\n\tresult := func() string { return \"\" }\r\n\tfor kind, function := range allGenerators() {\r\n\t\tif fako == kind {\r\n\t\t\tresult = function\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\treturn result\r\n}","code-length":88,"reference":"\/\/findFakeFunctionFor returns a faker function for a fako identifier","result":"Find the fake function for a given fako string.","score":[0.2697,0.625]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (opts *Options) Apply(options ...Option) error {\r\n\tfor _, o := range options {\r\n\t\tif err := o(opts); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":72,"reference":"\/\/ Apply applies the given options to this Options","result":"Avoid recursive call.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (opts *Options) ToOption() Option {\r\n\treturn func(nopts *Options) error {\r\n\t\t*nopts = *opts\r\n\t\tif opts.Other != nil {\r\n\t\t\tnopts.Other = make(map[interface{}]interface{}, len(opts.Other))\r\n\t\t\tfor k, v := range opts.Other {\r\n\t\t\t\tnopts.Other[k] = v\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n}","code-length":129,"reference":"\/\/ ToOption converts this Options to a single Option.","result":"Convert the options to a map of interface.","score":[0.1733,0.4213]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *eventChannel) waitThenClose() {\r\n\t<-e.ctx.Done()\r\n\te.mu.Lock()\r\n\tclose(e.ch)\r\n\t\r\n\t\r\n\te.ch = nil\r\n\te.mu.Unlock()\r\n}","code-length":76,"reference":"\/\/ waitThenClose is spawned in a goroutine when the channel is registered. This\n\/\/ safely cleans up the channel when the context has been canceled.","result":"Wait for the channel to be closed.","score":[0.0175,0.0431]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *eventChannel) send(ctx context.Context, ev *QueryEvent) {\r\n\te.mu.Lock()\r\n\t\r\n\tif e.ch == nil {\r\n\t\te.mu.Unlock()\r\n\t\treturn\r\n\t}\r\n\t\r\n\tselect {\r\n\tcase e.ch <- ev:\r\n\tcase <-e.ctx.Done():\r\n\tcase <-ctx.Done():\r\n\t}\r\n\te.mu.Unlock()\r\n}","code-length":124,"reference":"\/\/ send sends an event on the event channel, aborting if either the passed or\n\/\/ the internal context expire.","result":"Send events to the eventChannel.","score":[0.012,0.0811]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMovingAverage(age ...float64) MovingAverage {\r\n\tif len(age) == 0 || age[0] == AVG_METRIC_AGE {\r\n\t\treturn new(SimpleEWMA)\r\n\t}\r\n\treturn &VariableEWMA{\r\n\t\tdecay: 2 \/ (age[0] + 1),\r\n\t}\r\n}","code-length":95,"reference":"\/\/ NewMovingAverage constructs a MovingAverage that computes an average with the\n\/\/ desired characteristics in the moving window or exponential decay. If no\n\/\/ age is given, it constructs a default exponentially weighted implementation\n\/\/ that consumes minimal memory. The age is related to the decay factor alpha\n\/\/ by the formula given for the DECAY constant. It signifies the average age\n\/\/ of the samples as time goes to infinity.","result":"Create a new MovingAverage object.","score":[0.0,0.0155]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *VariableEWMA) Set(value float64) {\r\n\te.value = value\r\n\tif e.count <= WARMUP_SAMPLES {\r\n\t\te.count = WARMUP_SAMPLES + 1\r\n\t}\r\n}","code-length":72,"reference":"\/\/ Set sets the EWMA's value.","result":"Set the value of the variable.","score":[0.2296,0.1667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc calcKeys50(pass, salt []byte, kdfCount int) [][]byte {\r\n\tif len(salt) > maxPbkdf2Salt {\r\n\t\tsalt = salt[:maxPbkdf2Salt]\r\n\t}\r\n\tkeys := make([][]byte, 3)\r\n\tif len(keys) == 0 {\r\n\t\treturn keys\r\n\t}\r\n\tprf := hmac.New(sha256.New, pass)\r\n\tprf.Write(salt)\r\n\tprf.Write([]byte{0, 0, 0, 1})\r\n\tt := prf.Sum(nil)\r\n\tu := append([]byte(nil), t...)\r\n\tkdfCount--\r\n\tfor i, iter := range []int{kdfCount, 16, 16} {\r\n\t\tfor iter > 0 {\r\n\t\t\tprf.Reset()\r\n\t\t\tprf.Write(u)\r\n\t\t\tu = prf.Sum(u[:0])\r\n\t\t\tfor j := range u {\r\n\t\t\t\tt[j] ^= u[j]\r\n\t\t\t}\r\n\t\t\titer--\r\n\t\t}\r\n\t\tkeys[i] = append([]byte(nil), t...)\r\n\t}\r\n\tpwcheck := keys[2]\r\n\tfor i, v := range pwcheck[pwCheckSize:] {\r\n\t\tpwcheck[i&(pwCheckSize-1)] ^= v\r\n\t}\r\n\tkeys[2] = pwcheck[:pwCheckSize]\r\n\treturn keys\r\n}","code-length":373,"reference":"\/\/ calcKeys50 calculates the keys used in RAR 5 archive processing.\n\/\/ The returned slice of byte slices contains 3 keys.\n\/\/ Key 0 is used for block or file decryption.\n\/\/ Key 1 is optionally used for file checksum calculation.\n\/\/ Key 2 is optionally used for password checking.","result":"Calculate the keys.","score":[0.0,0.0331]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *archive50) getKeys(b *readBuf) (keys [][]byte, err error) {\r\n\tif len(*b) < 17 {\r\n\t\treturn nil, errCorruptEncrypt\r\n\t}\r\n\t\r\n\tkdfCount := int(b.byte())\r\n\tif kdfCount > maxKdfCount {\r\n\t\treturn nil, errCorruptEncrypt\r\n\t}\r\n\tkdfCount = 1 << uint(kdfCount)\r\n\tsalt := b.bytes(16)\r\n\t\r\n\tfor _, v := range a.keyCache {\r\n\t\tif kdfCount == v.kdfCount && bytes.Equal(salt, v.salt) {\r\n\t\t\treturn v.keys, nil\r\n\t\t}\r\n\t}\r\n\t\r\n\tkeys = calcKeys50(a.pass, salt, kdfCount)\r\n\t\r\n\tcopy(a.keyCache[1:], a.keyCache[:])\r\n\ta.keyCache[0].kdfCount = kdfCount\r\n\ta.keyCache[0].salt = append([]byte(nil), salt...)\r\n\ta.keyCache[0].keys = keys\r\n\treturn keys, nil\r\n}","code-length":289,"reference":"\/\/ getKeys reads kdfcount and salt from b and returns the corresponding encryption keys.","result":"Generate the keys .","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkPassword(b *readBuf, keys [][]byte) error {\r\n\tif len(*b) < 12 {\r\n\t\treturn nil\r\n\t}\r\n\tpwcheck := b.bytes(8)\r\n\tsum := b.bytes(4)\r\n\tcsum := sha256.Sum256(pwcheck)\r\n\tif bytes.Equal(sum, csum[:len(sum)]) && !bytes.Equal(pwcheck, keys[2]) {\r\n\t\treturn errBadPassword\r\n\t}\r\n\treturn nil\r\n}","code-length":136,"reference":"\/\/ checkPassword calculates if a password is correct given password check data and keys.","result":"Check the password.","score":[0,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *archive50) parseFileEncryptionRecord(b readBuf, f *fileBlockHeader) error {\r\n\tif ver := b.uvarint(); ver != 0 {\r\n\t\treturn errUnknownEncMethod\r\n\t}\r\n\tflags := b.uvarint()\r\n\tkeys, err := a.getKeys(&b)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tf.key = keys[0]\r\n\tif len(b) < 16 {\r\n\t\treturn errCorruptEncrypt\r\n\t}\r\n\tf.iv = b.bytes(16)\r\n\tif flags&file5EncCheckPresent > 0 {\r\n\t\tif err := checkPassword(&b, keys); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tif flags&file5EncUseMac > 0 {\r\n\t\ta.checksum.key = keys[1]\r\n\t}\r\n\treturn nil\r\n}","code-length":238,"reference":"\/\/ parseFileEncryptionRecord processes the optional file encryption record from a file header.","result":"Generate the file encryption record.","score":[0.0927,0.1327]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *archive50) parseEncryptionBlock(b readBuf) error {\r\n\tif ver := b.uvarint(); ver != 0 {\r\n\t\treturn errUnknownEncMethod\r\n\t}\r\n\tflags := b.uvarint()\r\n\tkeys, err := a.getKeys(&b)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif flags&enc5CheckPresent > 0 {\r\n\t\tif err := checkPassword(&b, keys); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\ta.blockKey = keys[0]\r\n\treturn nil\r\n}","code-length":164,"reference":"\/\/ parseEncryptionBlock calculates the key for block encryption.","result":"Parse the encryption block.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newArchive50(r *bufio.Reader, password string) fileBlockReader {\r\n\ta := new(archive50)\r\n\ta.v = r\r\n\ta.pass = []byte(password)\r\n\ta.buf = make([]byte, 100)\r\n\treturn a\r\n}","code-length":80,"reference":"\/\/ newArchive50 creates a new fileBlockReader for a Version 5 archive.","result":"Create a new archive.","score":[0.0869,0.1942]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cr *cipherBlockReader) Read(p []byte) (n int, err error) {\r\n\tfor {\r\n\t\tif cr.n < len(cr.outbuf) {\r\n\t\t\t\r\n\t\t\tn = copy(p, cr.outbuf[cr.n:])\r\n\t\t\tcr.n += n\r\n\t\t\treturn n, nil\r\n\t\t}\r\n\t\tif cr.err != nil {\r\n\t\t\terr = cr.err\r\n\t\t\tcr.err = nil\r\n\t\t\treturn 0, err\r\n\t\t}\r\n\t\tif len(p) >= cap(cr.outbuf) {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\t\r\n\t\tn, cr.err = cr.read(cr.outbuf[:cap(cr.outbuf)])\r\n\t\tcr.outbuf = cr.outbuf[:n]\r\n\t\tcr.n = 0\r\n\t}\r\n\t\r\n\treturn cr.read(p)\r\n}","code-length":243,"reference":"\/\/ Read reads and decrypts data into p.\n\/\/ If the input is not a multiple of the cipher block size,\n\/\/ the trailing bytes will be ignored.","result":"Read from a cipher block.","score":[0.0032,0.0584]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cr *cipherBlockReader) ReadByte() (byte, error) {\r\n\tfor {\r\n\t\tif cr.n < len(cr.outbuf) {\r\n\t\t\tc := cr.outbuf[cr.n]\r\n\t\t\tcr.n++\r\n\t\t\treturn c, nil\r\n\t\t}\r\n\t\tif cr.err != nil {\r\n\t\t\terr := cr.err\r\n\t\t\tcr.err = nil\r\n\t\t\treturn 0, err\r\n\t\t}\r\n\t\t\r\n\t\tvar n int\r\n\t\tn, cr.err = cr.read(cr.outbuf[:cap(cr.outbuf)])\r\n\t\tcr.outbuf = cr.outbuf[:n]\r\n\t\tcr.n = 0\r\n\t}\r\n}","code-length":195,"reference":"\/\/ ReadByte returns the next decrypted byte.","result":"Decrypt the cipher block.","score":[0.1509,0.1493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newCipherBlockReader(r io.Reader, mode cipher.BlockMode) *cipherBlockReader {\r\n\tcr := &cipherBlockReader{r: r, mode: mode}\r\n\tcr.outbuf = make([]byte, 0, mode.BlockSize())\r\n\tcr.inbuf = make([]byte, 0, mode.BlockSize())\r\n\treturn cr\r\n}","code-length":95,"reference":"\/\/ newCipherBlockReader returns a cipherBlockReader that decrypts the given io.Reader using\n\/\/ the provided block mode cipher.","result":"Create a cipherBlockReader.","score":[0.0038,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newAesDecryptReader(r io.Reader, key, iv []byte) *cipherBlockReader {\r\n\tblock, err := aes.NewCipher(key)\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tmode := cipher.NewCBCDecrypter(block, iv)\r\n\treturn newCipherBlockReader(r, mode)\r\n}","code-length":99,"reference":"\/\/ newAesDecryptReader returns a cipherBlockReader that decrypts input from a given io.Reader using AES.\n\/\/ It will panic if the provided key is invalid.","result":"Decrypt blocks from a block of data.","score":[0.0201,0.1146]}
{"code":"\/*is used to<extra_id_0>\r\nfunc limitByteReader(r byteReader, n int64) *limitedByteReader {\r\n\treturn &limitedByteReader{limitedReader{r, n, io.ErrUnexpectedEOF}, r}\r\n}","code-length":54,"reference":"\/\/ limitByteReader returns a limitedByteReader that reads from r and stops with\n\/\/ io.EOF after n bytes.\n\/\/ If r returns an io.EOF before reading n bytes, io.ErrUnexpectedEOF is returned.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FileHeader) Mode() os.FileMode {\r\n\tvar m os.FileMode\r\n\tif f.IsDir {\r\n\t\tm = os.ModeDir\r\n\t}\r\n\tif f.HostOS == HostOSWindows {\r\n\t\tif f.IsDir {\r\n\t\t\tm |= 0777\r\n\t\t} else if f.Attributes&1 > 0 {\r\n\t\t\tm |= 0444\r\n\t\t} else {\r\n\t\t\tm |= 0666\r\n\t\t}\r\n\t\treturn m\r\n\t}\r\n\t\r\n\tm |= os.FileMode(f.Attributes) & os.ModePerm\r\n\t\r\n\tif f.HostOS != HostOSUnix {\r\n\t\treturn m\r\n\t}\r\n\tif f.Attributes&0x200 != 0 {\r\n\t\tm |= os.ModeSticky\r\n\t}\r\n\tif f.Attributes&0x400 != 0 {\r\n\t\tm |= os.ModeSetgid\r\n\t}\r\n\tif f.Attributes&0x800 != 0 {\r\n\t\tm |= os.ModeSetuid\r\n\t}\r\n\t\r\n\tif f.Attributes&0xF000 == 0xA000 {\r\n\t\tm |= os.ModeSymlink\r\n\t}\r\n\treturn m\r\n}","code-length":315,"reference":"\/\/ Mode returns an os.FileMode for the file, calculated from the Attributes field.","result":"Determine the file mode.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *packedFileReader) nextBlockInFile() error {\r\n\th, err := f.r.next()\r\n\tif err != nil {\r\n\t\tif err == io.EOF {\r\n\t\t\t\r\n\t\t\treturn errUnexpectedArcEnd\r\n\t\t}\r\n\t\treturn err\r\n\t}\r\n\tif h.first || h.Name != f.h.Name {\r\n\t\treturn errInvalidFileBlock\r\n\t}\r\n\tf.h = h\r\n\treturn nil\r\n}","code-length":130,"reference":"\/\/ nextBlockInFile reads the next file block in the current file at the current\n\/\/ archive file position, or returns an error if there is a problem.\n\/\/ It is invalid to call this when already at the last block in the current file.","result":"Generate the code.","score":[0.0,0.0125]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *packedFileReader) next() (*fileBlockHeader, error) {\r\n\tif f.h != nil {\r\n\t\t\r\n\t\tfor !f.h.last {\r\n\t\t\t\r\n\t\t\tif _, err := io.Copy(ioutil.Discard, f.r); err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\tif err := f.nextBlockInFile(); err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tif _, err := io.Copy(ioutil.Discard, f.r); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\tvar err error\r\n\tf.h, err = f.r.next()\r\n\tif err != nil {\r\n\t\tif err == errArchiveEnd {\r\n\t\t\treturn nil, io.EOF\r\n\t\t}\r\n\t\treturn nil, err\r\n\t}\r\n\tif !f.h.first {\r\n\t\treturn nil, errInvalidFileBlock\r\n\t}\r\n\treturn f.h, nil\r\n}","code-length":282,"reference":"\/\/ next advances to the next packed file in the RAR archive.","result":"Read the next file block in the file.","score":[0.1658,0.3845]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *packedFileReader) Read(p []byte) (int, error) {\r\n\tn, err := f.r.Read(p)\r\n\tfor err == io.EOF {\r\n\t\tif n > 0 {\r\n\t\t\treturn n, nil\r\n\t\t}\r\n\t\tif f.h == nil || f.h.last {\r\n\t\t\treturn 0, io.EOF\r\n\t\t}\r\n\t\tif err := f.nextBlockInFile(); err != nil {\r\n\t\t\treturn 0, err\r\n\t\t}\r\n\t\tn, err = f.r.Read(p)\r\n\t}\r\n\treturn n, err\r\n}","code-length":170,"reference":"\/\/ Read reads the packed data for the current file into p.","result":"Read the file.","score":[0.0242,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Reader) Read(p []byte) (int, error) {\r\n\tn, err := r.r.Read(p)\r\n\tif err == io.EOF && r.cksum != nil && !r.cksum.valid() {\r\n\t\treturn n, errBadFileChecksum\r\n\t}\r\n\treturn n, err\r\n}","code-length":93,"reference":"\/\/ Read reads from the current file in the RAR archive.","result":"Read from a file.","score":[0.066,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Reader) Next() (*FileHeader, error) {\r\n\tif r.solidr != nil {\r\n\t\t\r\n\t\tif _, err := io.Copy(ioutil.Discard, r.solidr); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\th, err := r.pr.next()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tr.solidr = nil\r\n\tbr := byteReader(&r.pr)\r\n\t\r\n\tif len(h.key) > 0 && len(h.iv) > 0 {\r\n\t\tbr = newAesDecryptReader(br, h.key, h.iv)\r\n\t}\r\n\tr.r = br\r\n\t\r\n\tif h.decoder != nil {\r\n\t\terr = r.dr.init(br, h.decoder, h.winSize, !h.solid)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tr.r = &r.dr\r\n\t\tif r.pr.r.isSolid() {\r\n\t\t\tr.solidr = r.r\r\n\t\t}\r\n\t}\r\n\tif h.UnPackedSize >= 0 && !h.UnKnownSize {\r\n\t\t\r\n\t\tr.r = &limitedReader{r.r, h.UnPackedSize, errShortFile}\r\n\t}\r\n\tr.cksum = h.cksum\r\n\tif r.cksum != nil {\r\n\t\tr.r = io.TeeReader(r.r, h.cksum)\r\n\t}\r\n\tfh := new(FileHeader)\r\n\t*fh = h.FileHeader\r\n\treturn fh, nil\r\n}","code-length":442,"reference":"\/\/ Next advances to the next file in the archive.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewReader(r io.Reader, password string) (*Reader, error) {\r\n\tbr, ok := r.(*bufio.Reader)\r\n\tif !ok {\r\n\t\tbr = bufio.NewReader(r)\r\n\t}\r\n\tfbr, err := newFileBlockReader(br, password)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\trr := new(Reader)\r\n\trr.init(fbr)\r\n\treturn rr, nil\r\n}","code-length":131,"reference":"\/\/ NewReader creates a Reader reading from r.\n\/\/ NewReader only supports single volume archives.\n\/\/ Multi-volume archives must use OpenReader.","result":"Create a file block reader.","score":[0.0098,0.0966]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OpenReader(name, password string) (*ReadCloser, error) {\r\n\tv, err := openVolume(name, password)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\trc := new(ReadCloser)\r\n\trc.v = v\r\n\trc.Reader.init(v)\r\n\treturn rc, nil\r\n}","code-length":99,"reference":"\/\/ OpenReader opens a RAR archive specified by the name and returns a ReadCloser.","result":"Open a volume to open a reader.","score":[0.0707,0.1128]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getV3Filter(code []byte) (v3Filter, error) {\r\n\t\r\n\tc := crc32.ChecksumIEEE(code)\r\n\tfor _, f := range standardV3Filters {\r\n\t\tif f.crc == c && f.len == len(code) {\r\n\t\t\treturn f.f, nil\r\n\t\t}\r\n\t}\r\n\t\r\n\tf := new(vmFilter)\r\n\tr := newRarBitReader(bytes.NewReader(code[1:]))\r\n\t\r\n\tn, err := r.readBits(1)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif n > 0 {\r\n\t\tm, err := r.readUint32()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tf.static = make([]byte, m+1)\r\n\t\terr = r.readFull(f.static)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\tf.code, err = readCommands(r)\r\n\tif err == io.EOF {\r\n\t\terr = nil\r\n\t}\r\n\treturn f.execute, err\r\n}","code-length":316,"reference":"\/\/ getV3Filter returns a V3 filter function from a code byte slice.","result":"Commands .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *decoder29) init(r io.ByteReader, reset bool) error {\r\n\tif d.br == nil {\r\n\t\td.br = newRarBitReader(r)\r\n\t} else {\r\n\t\td.br.reset(r)\r\n\t}\r\n\td.eof = false\r\n\tif reset {\r\n\t\td.initFilters()\r\n\t\td.lz.reset()\r\n\t\td.ppm.reset()\r\n\t\td.decode = nil\r\n\t}\r\n\tif d.decode == nil {\r\n\t\treturn d.readBlockHeader()\r\n\t}\r\n\treturn nil\r\n}","code-length":168,"reference":"\/\/ init intializes the decoder for decoding a new file.","result":"Initialize the decoder.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *decoder29) readBlockHeader() error {\r\n\td.br.alignByte()\r\n\tn, err := d.br.readBits(1)\r\n\tif err == nil {\r\n\t\tif n > 0 {\r\n\t\t\td.decode = d.ppm.decode\r\n\t\t\terr = d.ppm.init(d.br)\r\n\t\t} else {\r\n\t\t\td.decode = d.lz.decode\r\n\t\t\terr = d.lz.init(d.br)\r\n\t\t}\r\n\t}\r\n\tif err == io.EOF {\r\n\t\terr = errDecoderOutOfData\r\n\t}\r\n\treturn err\r\n}","code-length":175,"reference":"\/\/ readBlockHeader determines and initializes the current decoder for a new decode block.","result":"Read block header.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc readCodeLengthTable(br bitReader, codeLength []byte, addOld bool) error {\r\n\tvar bitlength [20]byte\r\n\tfor i := 0; i < len(bitlength); i++ {\r\n\t\tn, err := br.readBits(4)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif n == 0xf {\r\n\t\t\tcnt, err := br.readBits(4)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif cnt > 0 {\r\n\t\t\t\t\r\n\t\t\t\ti += cnt + 1\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t}\r\n\t\tbitlength[i] = byte(n)\r\n\t}\r\n\tvar bl huffmanDecoder\r\n\tbl.init(bitlength[:])\r\n\tfor i := 0; i < len(codeLength); i++ {\r\n\t\tl, err := bl.readSym(br)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif l < 16 {\r\n\t\t\tif addOld {\r\n\t\t\t\tcodeLength[i] = (codeLength[i] + byte(l)) & 0xf\r\n\t\t\t} else {\r\n\t\t\t\tcodeLength[i] = byte(l)\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvar count int\r\n\t\tvar value byte\r\n\t\tswitch l {\r\n\t\tcase 16, 18:\r\n\t\t\tcount, err = br.readBits(3)\r\n\t\t\tcount += 3\r\n\t\tdefault:\r\n\t\t\tcount, err = br.readBits(7)\r\n\t\t\tcount += 11\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif l < 18 {\r\n\t\t\tif i == 0 {\r\n\t\t\t\treturn errInvalidLengthTable\r\n\t\t\t}\r\n\t\t\tvalue = codeLength[i-1]\r\n\t\t}\r\n\t\tfor ; count > 0 && i < len(codeLength); i++ {\r\n\t\t\tcodeLength[i] = value\r\n\t\t\tcount--\r\n\t\t}\r\n\t\ti--\r\n\t}\r\n\treturn nil\r\n}","code-length":555,"reference":"\/\/ readCodeLengthTable reads a new code length table into codeLength from br.\n\/\/ If addOld is set the old table is added to the new one.","result":"Code too long,keep in 512.","score":[0,0.0209]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *context) shrinkStates(states []state, size int) []state {\r\n\ti1 := units2Index[(len(states)+1)>>1]\r\n\ti2 := units2Index[(size+1)>>1]\r\n\tif size == 1 {\r\n\t\t\r\n\t\tn := c.statesIndex()\r\n\t\tc.s[1] = states[0]\r\n\t\tstates = c.s[1:]\r\n\t\tc.a.addFreeBlock(n, i1)\r\n\t} else if i1 != i2 {\r\n\t\tif n := c.a.removeFreeBlock(i2); n > 0 {\r\n\t\t\t\r\n\t\t\tcopy(c.a.states[n:], states[:size])\r\n\t\t\tstates = c.a.states[n:]\r\n\t\t\t\r\n\t\t\tc.a.addFreeBlock(c.statesIndex(), i1)\r\n\t\t\tc.setStatesIndex(n)\r\n\t\t} else {\r\n\t\t\t\r\n\t\t\tn = c.statesIndex() + index2Units[i2]<<1\r\n\t\t\tu := index2Units[i1] - index2Units[i2]\r\n\t\t\tc.a.freeUnits(n, u)\r\n\t\t}\r\n\t}\r\n\tc.setNumStates(size)\r\n\treturn states[:size]\r\n}","code-length":335,"reference":"\/\/ shrinkStates shrinks the state list down to size states","result":"Shrink states.","score":[0,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *context) expandStates() []state {\r\n\tstates := c.states()\r\n\tns := len(states)\r\n\tif ns == 1 {\r\n\t\ts := states[0]\r\n\t\tn := c.a.allocUnits(1)\r\n\t\tif n == 0 {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tc.setStatesIndex(n)\r\n\t\tstates = c.a.states[n:]\r\n\t\tstates[0] = s\r\n\t} else if ns&0x1 == 0 {\r\n\t\tu := ns >> 1\r\n\t\ti1 := units2Index[u]\r\n\t\ti2 := units2Index[u+1]\r\n\t\tif i1 != i2 {\r\n\t\t\tn := c.a.allocUnits(i2)\r\n\t\t\tif n == 0 {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\tcopy(c.a.states[n:], states)\r\n\t\t\tc.a.addFreeBlock(c.statesIndex(), i1)\r\n\t\t\tc.setStatesIndex(n)\r\n\t\t\tstates = c.a.states[n:]\r\n\t\t}\r\n\t}\r\n\tc.setNumStates(ns + 1)\r\n\treturn states[:ns+1]\r\n}","code-length":324,"reference":"\/\/ expandStates expands the states list by one","result":"Expand states in the context.","score":[0.1568,0.1948]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *subAllocator) pushByte(c byte) int32 {\r\n\tsi := a.heap1Lo \/ 6\r\n\toi := a.heap1Lo % 6\r\n\tswitch oi {\r\n\tcase 0:\r\n\t\ta.states[si].sym = c\r\n\tcase 1:\r\n\t\ta.states[si].freq = c\r\n\tdefault:\r\n\t\tn := (uint(oi) - 2) * 8\r\n\t\tmask := ^(uint32(0xFF) << n)\r\n\t\tsucc := uint32(a.states[si].succ) & mask\r\n\t\tsucc |= uint32(c) << n\r\n\t\ta.states[si].succ = int32(succ)\r\n\t}\r\n\ta.heap1Lo++\r\n\tif a.heap1Lo >= a.heap1Hi {\r\n\t\treturn 0\r\n\t}\r\n\treturn -a.heap1Lo\r\n}","code-length":236,"reference":"\/\/ pushByte puts a byte on the heap and returns a state.succ index that\n\/\/ can be used to retrieve it.","result":"Push byte to subAllocator.","score":[0.0054,0.0518]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *subAllocator) succByte(i int32) byte {\r\n\ti = -i\r\n\tsi := i \/ 6\r\n\toi := i % 6\r\n\tswitch oi {\r\n\tcase 0:\r\n\t\treturn a.states[si].sym\r\n\tcase 1:\r\n\t\treturn a.states[si].freq\r\n\tdefault:\r\n\t\tn := (uint(oi) - 2) * 8\r\n\t\tsucc := uint32(a.states[si].succ) >> n\r\n\t\treturn byte(succ & 0xff)\r\n\t}\r\n}","code-length":152,"reference":"\/\/ succByte returns a byte from the heap given a state.succ index","result":"Get the byte corresponding to the byte in the subAllocator.","score":[0.1057,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *subAllocator) succContext(i int32) *context {\r\n\tif i <= 0 {\r\n\t\treturn nil\r\n\t}\r\n\treturn &context{i: i, s: a.states[i : i+2 : i+2], a: a}\r\n}","code-length":78,"reference":"\/\/ succContext returns a context given a state.succ index","result":"Create a new context.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc calcAes30Params(pass []uint16, salt []byte) (key, iv []byte) {\r\n\tp := make([]byte, 0, len(pass)*2+len(salt))\r\n\tfor _, v := range pass {\r\n\t\tp = append(p, byte(v), byte(v>>8))\r\n\t}\r\n\tp = append(p, salt...)\r\n\thash := sha1.New()\r\n\tiv = make([]byte, 16)\r\n\ts := make([]byte, 0, hash.Size())\r\n\tfor i := 0; i < hashRounds; i++ {\r\n\t\thash.Write(p)\r\n\t\thash.Write([]byte{byte(i), byte(i >> 8), byte(i >> 16)})\r\n\t\tif i%(hashRounds\/16) == 0 {\r\n\t\t\ts = hash.Sum(s[:0])\r\n\t\t\tiv[i\/(hashRounds\/16)] = s[4*4+3]\r\n\t\t}\r\n\t}\r\n\tkey = hash.Sum(s[:0])\r\n\tkey = key[:16]\r\n\tfor k := key; len(k) >= 4; k = k[4:] {\r\n\t\tk[0], k[1], k[2], k[3] = k[3], k[2], k[1], k[0]\r\n\t}\r\n\treturn key, iv\r\n}","code-length":352,"reference":"\/\/ Calculates the key and iv for AES decryption given a password and salt.","result":"Calculate the aes params.","score":[0.0262,0.1966]}
{"code":"\/*is used to<extra_id_0>\r\nfunc parseDosTime(t uint32) time.Time {\r\n\tn := int(t)\r\n\tsec := n & 0x1f << 1\r\n\tmin := n >> 5 & 0x3f\r\n\thr := n >> 11 & 0x1f\r\n\tday := n >> 16 & 0x1f\r\n\tmon := time.Month(n >> 21 & 0x0f)\r\n\tyr := n>>25&0x7f + 1980\r\n\treturn time.Date(yr, mon, day, hr, min, sec, 0, time.Local)\r\n}","code-length":147,"reference":"\/\/ parseDosTime converts a 32bit DOS time value to time.Time","result":"Parse dos time.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc decodeName(buf []byte) string {\r\n\ti := bytes.IndexByte(buf, 0)\r\n\tif i < 0 {\r\n\t\treturn string(buf)\r\n\t}\r\n\tname := buf[:i]\r\n\tencName := readBuf(buf[i+1:])\r\n\tif len(encName) < 2 {\r\n\t\treturn \"\"\r\n\t}\r\n\thighByte := uint16(encName.byte()) << 8\r\n\tflags := encName.byte()\r\n\tflagBits := 8\r\n\tvar wchars []uint16\r\n\tfor len(wchars) < len(name) && len(encName) > 0 {\r\n\t\tif flagBits == 0 {\r\n\t\t\tflags = encName.byte()\r\n\t\t\tflagBits = 8\r\n\t\t\tif len(encName) == 0 {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tswitch flags >> 6 {\r\n\t\tcase 0:\r\n\t\t\twchars = append(wchars, uint16(encName.byte()))\r\n\t\tcase 1:\r\n\t\t\twchars = append(wchars, uint16(encName.byte())|highByte)\r\n\t\tcase 2:\r\n\t\t\tif len(encName) < 2 {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\twchars = append(wchars, encName.uint16())\r\n\t\tcase 3:\r\n\t\t\tn := encName.byte()\r\n\t\t\tb := name[len(wchars):]\r\n\t\t\tif l := int(n&0x7f) + 2; l < len(b) {\r\n\t\t\t\tb = b[:l]\r\n\t\t\t}\r\n\t\t\tif n&0x80 > 0 {\r\n\t\t\t\tif len(encName) < 1 {\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t\tec := encName.byte()\r\n\t\t\t\tfor _, c := range b {\r\n\t\t\t\t\twchars = append(wchars, uint16(c+ec)|highByte)\r\n\t\t\t\t}\r\n\t\t\t} else {\r\n\t\t\t\tfor _, c := range b {\r\n\t\t\t\t\twchars = append(wchars, uint16(c))\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\tflags <<= 2\r\n\t\tflagBits -= 2\r\n\t}\r\n\treturn string(utf16.Decode(wchars))\r\n}","code-length":585,"reference":"\/\/ decodeName decodes a non-unicode filename from a file header.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc readExtTimes(f *fileBlockHeader, b *readBuf) {\r\n\tif len(*b) < 2 {\r\n\t\treturn\r\n\t}\r\n\tflags := b.uint16()\r\n\tts := []*time.Time{&f.ModificationTime, &f.CreationTime, &f.AccessTime}\r\n\tfor i, t := range ts {\r\n\t\tn := flags >> uint((3-i)*4)\r\n\t\tif n&0x8 == 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif i != 0 {\r\n\t\t\tif len(*b) < 4 {\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\t*t = parseDosTime(b.uint32())\r\n\t\t}\r\n\t\tif n&0x4 > 0 {\r\n\t\t\t*t = t.Add(time.Second)\r\n\t\t}\r\n\t\tn &= 0x3\r\n\t\tif n == 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif len(*b) < int(n) {\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\td := time.Duration(0)\r\n\t\tfor j := 3 - n; j < n; j++ {\r\n\t\t\td |= time.Duration(b.byte()) << (j * 8)\r\n\t\t}\r\n\t\td *= 100\r\n\t\t*t = t.Add(d)\r\n\t}\r\n}","code-length":358,"reference":"\/\/ readExtTimes reads and parses the optional extra time field from the file header.","result":"Read extTimes in the file block.","score":[0.072,0.1936]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *archive15) readBlockHeader() (*blockHeader15, error) {\r\n\tvar err error\r\n\tb := a.buf[:7]\r\n\tr := io.Reader(a.v)\r\n\tif a.encrypted {\r\n\t\tsalt := a.buf[:saltSize]\r\n\t\t_, err = io.ReadFull(r, salt)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tkey, iv := a.getKeys(salt)\r\n\t\tr = newAesDecryptReader(r, key, iv)\r\n\t\terr = readFull(r, b)\r\n\t} else {\r\n\t\t_, err = io.ReadFull(r, b)\r\n\t}\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tcrc := b.uint16()\r\n\thash := crc32.NewIEEE()\r\n\thash.Write(b)\r\n\th := new(blockHeader15)\r\n\th.htype = b.byte()\r\n\th.flags = b.uint16()\r\n\tsize := b.uint16()\r\n\tif size < 7 {\r\n\t\treturn nil, errCorruptHeader\r\n\t}\r\n\tsize -= 7\r\n\tif int(size) > cap(a.buf) {\r\n\t\ta.buf = readBuf(make([]byte, size))\r\n\t}\r\n\th.data = a.buf[:size]\r\n\tif err := readFull(r, h.data); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\thash.Write(h.data)\r\n\tif crc != uint16(hash.Sum32()) {\r\n\t\treturn nil, errBadHeaderCrc\r\n\t}\r\n\tif h.flags&blockHasData > 0 {\r\n\t\tif len(h.data) < 4 {\r\n\t\t\treturn nil, errCorruptHeader\r\n\t\t}\r\n\t\th.dataSize = int64(h.data.uint32())\r\n\t}\r\n\tif (h.htype == blockService || h.htype == blockFile) && h.flags&fileLargeData > 0 {\r\n\t\tif len(h.data) < 25 {\r\n\t\t\treturn nil, errCorruptHeader\r\n\t\t}\r\n\t\tb := h.data[21:25]\r\n\t\th.dataSize |= int64(b.uint32()) << 32\r\n\t}\r\n\treturn h, nil\r\n}","code-length":614,"reference":"\/\/ readBlockHeader returns the next block header in the archive.\n\/\/ It will return io.EOF if there were no bytes read.","result":"Code too long,keep in 512.","score":[0.0098,0.0258]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newArchive15(r *bufio.Reader, password string) fileBlockReader {\r\n\ta := new(archive15)\r\n\ta.v = r\r\n\ta.pass = utf16.Encode([]rune(password))\r\n\ta.checksum.Hash32 = crc32.NewIEEE()\r\n\ta.buf = readBuf(make([]byte, 100))\r\n\treturn a\r\n}","code-length":106,"reference":"\/\/ newArchive15 creates a new fileBlockReader for a Version 1.5 archive","result":"Create a new archive.","score":[0.0785,0.1456]}
{"code":"\/*is used to<extra_id_0>\r\nfunc readFilter5Data(br bitReader) (int, error) {\r\n\t\r\n\t\r\n\tbytes, err := br.readBits(2)\r\n\tif err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\tbytes++\r\n\tvar data int\r\n\tfor i := 0; i < bytes; i++ {\r\n\t\tn, err := br.readBits(8)\r\n\t\tif err != nil {\r\n\t\t\treturn 0, err\r\n\t\t}\r\n\t\tdata |= n << (uint(i) * 8)\r\n\t}\r\n\treturn data, nil\r\n}","code-length":158,"reference":"\/\/ readFilter5Data reads an encoded integer used in V5 filters.","result":"Read the filter.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *window) writeByte(c byte) {\r\n\tw.buf[w.w] = c\r\n\tw.w = (w.w + 1) & w.mask\r\n}","code-length":55,"reference":"\/\/ writeByte writes c to the end of the window","result":"Write to a byte buffer.","score":[0.0884,0.1053]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *window) copyBytes(len, off int) {\r\n\tlen &= w.mask\r\n\tn := w.available()\r\n\tif len > n {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tw.l = len - n\r\n\t\tw.o = off\r\n\t\tlen = n\r\n\t}\r\n\ti := (w.w - off) & w.mask\r\n\tfor ; len > 0; len-- {\r\n\t\tw.buf[w.w] = w.buf[i]\r\n\t\tw.w = (w.w + 1) & w.mask\r\n\t\ti = (i + 1) & w.mask\r\n\t}\r\n}","code-length":177,"reference":"\/\/ copyBytes copies len bytes at off distance from the end\n\/\/ to the end of the window.","result":"Copy bytes into a window.","score":[0.0212,0.0898]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *window) read(p []byte) (n int) {\r\n\tif w.r > w.w {\r\n\t\tn = copy(p, w.buf[w.r:])\r\n\t\tw.r = (w.r + n) & w.mask\r\n\t\tp = p[n:]\r\n\t}\r\n\tif w.r < w.w {\r\n\t\tl := copy(p, w.buf[w.r:w.w])\r\n\t\tw.r += l\r\n\t\tn += l\r\n\t}\r\n\tif w.l > 0 && n > 0 {\r\n\t\t\r\n\t\t\r\n\t\tl := w.l\r\n\t\tw.l = 0\r\n\t\tw.copyBytes(l, w.o)\r\n\t}\r\n\treturn n\r\n}","code-length":209,"reference":"\/\/ read reads bytes from the beginning of the window into p","result":"Read from a buffer.","score":[0.0432,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *decodeReader) queueFilter(f *filterBlock) error {\r\n\tif f.reset {\r\n\t\td.filters = nil\r\n\t}\r\n\tif len(d.filters) >= maxQueuedFilters {\r\n\t\treturn errTooManyFilters\r\n\t}\r\n\t\r\n\tf.offset &= d.win.mask\r\n\tf.length &= d.win.mask\r\n\t\r\n\tfor _, fb := range d.filters {\r\n\t\tif f.offset < fb.offset {\r\n\t\t\t\r\n\t\t\treturn errInvalidFilter\r\n\t\t}\r\n\t\tf.offset -= fb.offset\r\n\t}\r\n\td.filters = append(d.filters, f)\r\n\treturn nil\r\n}","code-length":184,"reference":"\/\/ queueFilter adds a filterBlock to the end decodeReader's filters.","result":"Queue filters.","score":[0.0092,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *decodeReader) processFilters() (err error) {\r\n\tf := d.filters[0]\r\n\tif f.offset > 0 {\r\n\t\treturn nil\r\n\t}\r\n\td.filters = d.filters[1:]\r\n\tif d.win.buffered() < f.length {\r\n\t\t\r\n\t\terr = d.readErr()\r\n\t\tif err == nil || err == io.EOF {\r\n\t\t\treturn errInvalidFilter\r\n\t\t}\r\n\t\treturn err\r\n\t}\r\n\tif cap(d.buf) < f.length {\r\n\t\td.buf = make([]byte, f.length)\r\n\t}\r\n\td.outbuf = d.buf[:f.length]\r\n\tn := d.win.read(d.outbuf)\r\n\tfor {\r\n\t\t\r\n\t\td.outbuf, err = f.filter(d.outbuf, d.tot)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif cap(d.outbuf) > cap(d.buf) {\r\n\t\t\t\r\n\t\t\td.buf = d.outbuf\r\n\t\t}\r\n\t\tif len(d.filters) == 0 {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tf = d.filters[0]\r\n\t\tif f.offset != 0 {\r\n\t\t\t\r\n\t\t\tf.offset -= n\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tif f.length != len(d.outbuf) {\r\n\t\t\treturn errInvalidFilter\r\n\t\t}\r\n\t\td.filters = d.filters[1:]\r\n\t\tif cap(d.outbuf) < cap(d.buf) {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\td.outbuf = append(d.buf[:0], d.outbuf...)\r\n\t\t}\r\n\t}\r\n}","code-length":468,"reference":"\/\/ processFilters processes any filters valid at the current read index\n\/\/ and stores the output in outbuf.","result":"Process filters.","score":[0,0.0305]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *decodeReader) fill() {\r\n\tif d.err != nil {\r\n\t\treturn\r\n\t}\r\n\tvar fl []*filterBlock\r\n\tfl, d.err = d.dec.fill(&d.win)\r\n\tfor _, f := range fl {\r\n\t\terr := d.queueFilter(f)\r\n\t\tif err != nil {\r\n\t\t\td.err = err\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":126,"reference":"\/\/ fill fills the decodeReader's window","result":"Fill the filter block.","score":[0.1938,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *decodeReader) Read(p []byte) (n int, err error) {\r\n\tif len(d.outbuf) == 0 {\r\n\t\t\r\n\t\tif d.win.buffered() == 0 {\r\n\t\t\t\r\n\t\t\td.fill()\r\n\t\t\tif d.win.buffered() == 0 {\r\n\t\t\t\treturn 0, d.readErr()\r\n\t\t\t}\r\n\t\t} else if len(d.filters) > 0 {\r\n\t\t\tf := d.filters[0]\r\n\t\t\tif f.offset == 0 && f.length > d.win.buffered() {\r\n\t\t\t\td.fill()\r\n\t\t\t}\r\n\t\t}\r\n\t\tif len(d.filters) > 0 {\r\n\t\t\tif err := d.processFilters(); err != nil {\r\n\t\t\t\treturn 0, err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif len(d.outbuf) > 0 {\r\n\t\t\r\n\t\tn = copy(p, d.outbuf)\r\n\t\td.outbuf = d.outbuf[n:]\r\n\t} else if len(d.filters) > 0 {\r\n\t\tf := d.filters[0]\r\n\t\tif f.offset < len(p) {\r\n\t\t\t\r\n\t\t\tp = p[:f.offset]\r\n\t\t}\r\n\t\tn = d.win.read(p)\r\n\t\tf.offset -= n\r\n\t} else {\r\n\t\tn = d.win.read(p)\r\n\t}\r\n\td.tot += int64(n)\r\n\treturn n, nil\r\n}","code-length":401,"reference":"\/\/ Read decodes data and stores it in p.","result":"Read from a buffer.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc readFull(r io.Reader, buf []byte) error {\r\n\t_, err := io.ReadFull(r, buf)\r\n\tif err == io.EOF {\r\n\t\treturn io.ErrUnexpectedEOF\r\n\t}\r\n\treturn err\r\n}","code-length":72,"reference":"\/\/ readFull wraps io.ReadFull to return io.ErrUnexpectedEOF instead\n\/\/ of io.EOF when 0 bytes are read.","result":"Read a full buffer.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc findSig(br *bufio.Reader) (int, error) {\r\n\tfor n := 0; n <= maxSfxSize; {\r\n\t\tb, err := br.ReadSlice(sigPrefix[0])\r\n\t\tn += len(b)\r\n\t\tif err == bufio.ErrBufferFull {\r\n\t\t\tcontinue\r\n\t\t} else if err != nil {\r\n\t\t\tif err == io.EOF {\r\n\t\t\t\terr = errNoSig\r\n\t\t\t}\r\n\t\t\treturn 0, err\r\n\t\t}\r\n\t\tb, err = br.Peek(len(sigPrefix[1:]) + 2)\r\n\t\tif err != nil {\r\n\t\t\tif err == io.EOF {\r\n\t\t\t\terr = errNoSig\r\n\t\t\t}\r\n\t\t\treturn 0, err\r\n\t\t}\r\n\t\tif !bytes.HasPrefix(b, []byte(sigPrefix[1:])) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tb = b[len(sigPrefix)-1:]\r\n\t\tvar ver int\r\n\t\tswitch {\r\n\t\tcase b[0] == 0:\r\n\t\t\tver = fileFmt15\r\n\t\tcase b[0] == 1 && b[1] == 0:\r\n\t\t\tver = fileFmt50\r\n\t\tdefault:\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t_, _ = br.ReadSlice('\\x00')\r\n\t\treturn ver, nil\r\n\t}\r\n\treturn 0, errNoSig\r\n}","code-length":374,"reference":"\/\/ findSig searches for the RAR signature and version at the beginning of a file.\n\/\/ It searches no more than maxSfxSize bytes.","result":"Find the signature in the file.","score":[0.0161,0.0939]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v *vm) execute(cmd []command) {\r\n\tv.ip = 0\r\n\tfor n := 0; n < maxCommands; n++ {\r\n\t\tip := v.ip\r\n\t\tif ip >= uint32(len(cmd)) {\r\n\t\t\treturn\r\n\t\t}\r\n\t\tins := cmd[ip]\r\n\t\tins.f(v, ins.bm, ins.op)\r\n\t\tif v.ipMod {\r\n\t\t\t\r\n\t\t\tv.ipMod = false\r\n\t\t} else {\r\n\t\t\tv.ip++\r\n\t\t}\r\n\t}\r\n}","code-length":158,"reference":"\/\/ execute runs a list of commands on the vm.","result":"Execute commands.","score":[0,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newVM(mem []byte) *vm {\r\n\tv := new(vm)\r\n\tif cap(mem) < vmSize+4 {\r\n\t\tv.m = make([]byte, vmSize+4)\r\n\t\tcopy(v.m, mem)\r\n\t} else {\r\n\t\tv.m = mem[:vmSize+4]\r\n\t\tfor i := len(mem); i < len(v.m); i++ {\r\n\t\t\tv.m[i] = 0\r\n\t\t}\r\n\t}\r\n\tv.r[7] = vmSize\r\n\treturn v\r\n}","code-length":157,"reference":"\/\/ newVM creates a new RAR virtual machine using the byte slice as memory.","result":"Create a new VM.","score":[0.0371,0.2265]}
{"code":"\/*is used to<extra_id_0>\r\nfunc limitBitReader(br bitReader, n int, err error) bitReader {\r\n\treturn &limitedBitReader{br, n, err}\r\n}","code-length":45,"reference":"\/\/ limitBitReader returns a bitReader that reads from br and stops with io.EOF after n bits.\n\/\/ If br returns an io.EOF before reading n bits, err is returned.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *rarBitReader) readUint32() (uint32, error) {\r\n\tn, err := r.readBits(2)\r\n\tif err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\tif n != 1 {\r\n\t\tn, err = r.readBits(4 << uint(n))\r\n\t\treturn uint32(n), err\r\n\t}\r\n\tn, err = r.readBits(4)\r\n\tif err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\tif n == 0 {\r\n\t\tn, err = r.readBits(8)\r\n\t\tn |= -1 << 8\r\n\t\treturn uint32(n), err\r\n\t}\r\n\tnlow, err := r.readBits(4)\r\n\tn = n<<4 | nlow\r\n\treturn uint32(n), err\r\n}","code-length":226,"reference":"\/\/ readUint32 reads a RAR V3 encoded uint32","result":"From the rarBitReader.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc step3(word *snowballword.SnowballWord) bool {\r\n\t\r\n\t\r\n\tsuffix, _ := word.RemoveFirstSuffixIn(word.R2start, \"\u043e\u0441\u0442\", \"\u043e\u0441\u0442\u044c\")\r\n\tif suffix != \"\" {\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":97,"reference":"\/\/ Step 3 is the removal of the derivational suffix.\n\/\/","result":"Generate the step.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Stem(word string, stemStopwWords bool) string {\r\n\tword = strings.ToLower(strings.TrimSpace(word))\r\n\t\r\n\tif len(word) <= 2 || (stemStopwWords == false && isStopWord(word)) {\r\n\t\treturn word\r\n\t}\r\n\t\r\n\tif specialVersion := stemSpecialWord(word); specialVersion != \"\" {\r\n\t\tword = specialVersion\r\n\t\treturn word\r\n\t}\r\n\tw := snowballword.New(word)\r\n\t\r\n\t\r\n\t\r\n\tpreprocess(w)\r\n\tstep0(w)\r\n\tstep1a(w)\r\n\tstep1b(w)\r\n\tstep1c(w)\r\n\tstep2(w)\r\n\tstep3(w)\r\n\tstep4(w)\r\n\tstep5(w)\r\n\tpostprocess(w)\r\n\treturn w.String()\r\n}","code-length":235,"reference":"\/\/ Stem an English word.  This is the only exported\n\/\/ function in this package.\n\/\/","result":"Generate the stemmer.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc step6(word *snowballword.SnowballWord) bool {\r\n\t\r\n\t\r\n\t\r\n\t i >= 0; i-- {\r\n\t\tr := word.RS[i]\r\n\t\tif isLowerVowel(r) == false {\r\n\t\t\tnumNonVowels += 1\r\n\t\t} else {\r\n\t\t\t\r\n\t\t\tif (r == 233 || r == 232) && numNonVowels > 0 {\r\n\t\t\t\t\r\n\t\t\t\tword.RS[i] = 101\r\n\t\t\t\treturn true\r\n\t\t\t}\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":166,"reference":"\/\/ Step 6 Un-accent\n\/\/","result":"Replace step.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc step5(word *snowballword.SnowballWord) bool {\r\n\tsuffix, _ := word.FirstSuffix(\"enn\", \"onn\", \"ett\", \"ell\", \"eill\")\r\n\tif suffix != \"\" {\r\n\t\tword.RemoveLastNRunes(1)\r\n\t}\r\n\treturn false\r\n}","code-length":90,"reference":"\/\/ Step 5 Undouble non-vowel endings\n\/\/","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc step2a(word *snowballword.SnowballWord) bool {\r\n\tsuffix, suffixRunes := word.FirstSuffixIn(word.RVstart, len(word.RS), \"ya\", \"ye\", \"yan\", \"yen\", \"yeron\", \"yendo\", \"yo\", \"y\u00f3\", \"yas\", \"yes\", \"yais\", \"yamos\")\r\n\tif suffix != \"\" {\r\n\t\tidx := len(word.RS) - len(suffixRunes) - 1\r\n\t\tif idx >= 0 && word.RS[idx] == 117 {\r\n\t\t\tword.RemoveLastNRunes(len(suffixRunes))\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":193,"reference":"\/\/ Step 2a is the removal of verb suffixes beginning y,\n\/\/ Search for the longest among the following suffixes\n\/\/ in RV, and if found, delete if preceded by u.\n\/\/","result":"Step .","score":[0.0,0.0172]}
{"code":"\/*is used to<extra_id_0>\r\nfunc step4(word *snowballword.SnowballWord) bool {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif word.HasSuffixRunes([]rune(\"\u043d\u043d\")) {\r\n\t\tword.RemoveLastNRunes(1)\r\n\t\treturn true\r\n\t}\r\n\t\r\n\tsuffix, _ := word.RemoveFirstSuffix(\"\u0435\u0439\u0448\u0435\", \"\u0435\u0439\u0448\")\r\n\tif suffix != \"\" {\r\n\t\t\r\n\t\tif word.HasSuffixRunes([]rune(\"\u043d\u043d\")) {\r\n\t\t\tword.RemoveLastNRunes(1)\r\n\t\t}\r\n\t\treturn true\r\n\t}\r\n\t\r\n\tif rsLen := len(word.RS); rsLen > 0 && word.RS[rsLen-1] == '\u044c' {\r\n\t\tword.RemoveLastNRunes(1)\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":249,"reference":"\/\/ Step 4 is the undoubling of double non-vowel endings\n\/\/ and removal of superlative endings.\n\/\/","result":"Remove the last step.","score":[0.0124,0.0955]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Stem(word, language string, stemStopWords bool) (stemmed string, err error) {\r\n\tvar f func(string, bool) string\r\n\tswitch language {\r\n\tcase \"english\":\r\n\t\tf = english.Stem\r\n\tcase \"spanish\":\r\n\t\tf = spanish.Stem\r\n\tcase \"french\":\r\n\t\tf = french.Stem\r\n\tcase \"russian\":\r\n\t\tf = russian.Stem\r\n\tcase \"swedish\":\r\n\t\tf = swedish.Stem\r\n\tcase \"norwegian\":\r\n\t\tf = norwegian.Stem\r\n\tdefault:\r\n\t\terr = fmt.Errorf(\"Unknown language: %s\", language)\r\n\t\treturn\r\n\t}\r\n\tstemmed = f(word, stemStopWords)\r\n\treturn\r\n}","code-length":218,"reference":"\/\/ Stem a word in the specified language.\n\/\/","result":"Generate the stemmed string .","score":[0.108,0.1163]}
{"code":"\/*is used to<extra_id_0>\r\nfunc step1c(w *snowballword.SnowballWord) bool {\r\n\trsLen := len(w.RS)\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif len(w.RS) > 2 && (w.RS[rsLen-1] == 121 || w.RS[rsLen-1] == 89) && !isLowerVowel(w.RS[rsLen-2]) {\r\n\t\tw.RS[rsLen-1] = 105\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":147,"reference":"\/\/ Step 1c is the normalization of various \"y\" endings.\n\/\/","result":"Generate the code.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc step3(w *snowballword.SnowballWord) bool {\r\n\tsuffix, suffixRunes := w.FirstSuffix(\r\n\t\t\"ational\", \"tional\", \"alize\", \"icate\", \"ative\",\r\n\t\t\"iciti\", \"ical\", \"ful\", \"ness\",\r\n\t)\r\n\t\r\n\tif suffix == \"\" || len(suffixRunes) > len(w.RS)-w.R1start {\r\n\t\treturn false\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif suffix == \"ative\" {\r\n\t\t\r\n\t\t\r\n\t\tif len(w.RS)-w.R2start >= 5 {\r\n\t\t\tw.RemoveLastNRunes(len(suffixRunes))\r\n\t\t\treturn true\r\n\t\t}\r\n\t\treturn false\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tvar repl string\r\n\tswitch suffix {\r\n\tcase \"ational\":\r\n\t\trepl = \"ate\"\r\n\tcase \"tional\":\r\n\t\trepl = \"tion\"\r\n\tcase \"alize\":\r\n\t\trepl = \"al\"\r\n\tcase \"icate\", \"iciti\", \"ical\":\r\n\t\trepl = \"ic\"\r\n\tcase \"ful\", \"ness\":\r\n\t\trepl = \"\"\r\n\t}\r\n\tw.ReplaceSuffixRunes(suffixRunes, []rune(repl), true)\r\n\treturn true\r\n}","code-length":356,"reference":"\/\/ Step 3 is the stemming of various longer sufficies\n\/\/ found in R1.\n\/\/","result":"Replace suffix of word.","score":[0.0204,0.036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isStopWord(word string) bool {\r\n\tswitch word {\r\n\tcase \"au\", \"aux\", \"avec\", \"ce\", \"ces\", \"dans\", \"de\", \"des\", \"du\",\r\n\t\t\"elle\", \"en\", \"et\", \"eux\", \"il\", \"je\", \"la\", \"le\", \"leur\",\r\n\t\t\"lui\", \"ma\", \"mais\", \"me\", \"m\u00eame\", \"mes\", \"moi\", \"mon\", \"ne\",\r\n\t\t\"nos\", \"notre\", \"nous\", \"on\", \"ou\", \"par\", \"pas\", \"pour\", \"qu\",\r\n\t\t\"que\", \"qui\", \"sa\", \"se\", \"ses\", \"son\", \"sur\", \"ta\", \"te\",\r\n\t\t\"tes\", \"toi\", \"ton\", \"tu\", \"un\", \"une\", \"vos\", \"votre\", \"vous\",\r\n\t\t\"c\", \"d\", \"j\", \"l\", \"\u00e0\", \"m\", \"n\", \"s\", \"t\", \"y\", \"\u00e9t\u00e9\",\r\n\t\t\"\u00e9t\u00e9e\", \"\u00e9t\u00e9es\", \"\u00e9t\u00e9s\", \"\u00e9tant\", \"\u00e9tante\", \"\u00e9tants\", \"\u00e9tantes\",\r\n\t\t\"suis\", \"es\", \"est\", \"sommes\", \"\u00eates\", \"sont\", \"serai\",\r\n\t\t\"seras\", \"sera\", \"serons\", \"serez\", \"seront\", \"serais\",\r\n\t\t\"serait\", \"serions\", \"seriez\", \"seraient\", \"\u00e9tais\", \"\u00e9tait\",\r\n\t\t\"\u00e9tions\", \"\u00e9tiez\", \"\u00e9taient\", \"fus\", \"fut\", \"f\u00fbmes\", \"f\u00fbtes\",\r\n\t\t\"furent\", \"sois\", \"soit\", \"soyons\", \"soyez\", \"soient\", \"fusse\",\r\n\t\t\"fusses\", \"f\u00fbt\", \"fussions\", \"fussiez\", \"fussent\", \"ayant\",\r\n\t\t\"ayante\", \"ayantes\", \"ayants\", \"eu\", \"eue\", \"eues\", \"eus\",\r\n\t\t\"ai\", \"as\", \"avons\", \"avez\", \"ont\", \"aurai\", \"auras\", \"aura\",\r\n\t\t\"aurons\", \"aurez\", \"auront\", \"aurais\", \"aurait\", \"aurions\",\r\n\t\t\"auriez\", \"auraient\", \"avais\", \"avait\", \"avions\", \"aviez\",\r\n\t\t\"avaient\", \"eut\", \"e\u00fbmes\", \"e\u00fbtes\", \"eurent\", \"aie\", \"aies\",\r\n\t\t\"ait\", \"ayons\", \"ayez\", \"aient\", \"eusse\", \"eusses\", \"e\u00fbt\",\r\n\t\t\"eussions\", \"eussiez\", \"eussent\":\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":769,"reference":"\/\/ Return `true` if the input `word` is a French stop word.\n\/\/","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc capitalizeYUI(word *snowballword.SnowballWord) {\r\n\t\r\n\tvowelPreviously := false\r\n\t\r\n\tvowelNext := func(j int) bool {\r\n\t\treturn (j+1 < len(word.RS) && isLowerVowel(word.RS[j+1]))\r\n\t}\r\n\t\r\n\tfor i := 0; i < len(word.RS); i++ {\r\n\t\t\r\n\t\tif isLowerVowel(word.RS[i]) == false {\r\n\t\t\tvowelPreviously = false\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvowelHere := true\r\n\t\tswitch word.RS[i] {\r\n\t\tcase 121:\r\n\t\t\t\r\n\t\t\tif vowelPreviously || vowelNext(i) {\r\n\t\t\t\tword.RS[i] = 89\r\n\t\t\t\tvowelHere = false\r\n\t\t\t}\r\n\t\tcase 117:\r\n\t\t\t\r\n\t\t\tif (vowelPreviously && vowelNext(i)) || (i >= 1 && word.RS[i-1] == 113) {\r\n\t\t\t\tword.RS[i] = 85\r\n\t\t\t\tvowelHere = false\r\n\t\t\t}\r\n\t\tcase 105:\r\n\t\t\t\r\n\t\t\tif vowelPreviously && vowelNext(i) {\r\n\t\t\t\tword.RS[i] = 73\r\n\t\t\t\tvowelHere = false\r\n\t\t\t}\r\n\t\t}\r\n\t\tvowelPreviously = vowelHere\r\n\t}\r\n}","code-length":372,"reference":"\/\/ Capitalize Y, I, and U runes that are acting as consanants.\n\/\/ Put into upper case \"u\" or \"i\" preceded and followed by a\n\/\/ vowel, and \"y\" preceded or followed by a vowel. \"u\" after q is\n\/\/ also put into upper case.\n\/\/","result":"Capitalize YUI words.","score":[0.0,0.012]}
{"code":"\/*is used to<extra_id_0>\r\nfunc step2(w *snowballword.SnowballWord) bool {\r\n\t\r\n\tsuffix, suffixRunes := w.FirstSuffix(\r\n\t\t\"ational\", \"fulness\", \"iveness\", \"ization\", \"ousness\",\r\n\t\t\"biliti\", \"lessli\", \"tional\", \"alism\", \"aliti\", \"ation\",\r\n\t\t\"entli\", \"fulli\", \"iviti\", \"ousli\", \"anci\", \"abli\",\r\n\t\t\"alli\", \"ator\", \"enci\", \"izer\", \"bli\", \"ogi\", \"li\",\r\n\t)\r\n\t\r\n\tif suffix == \"\" || len(suffixRunes) > len(w.RS)-w.R1start {\r\n\t\treturn false\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tswitch suffix {\r\n\tcase \"li\":\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\trsLen := len(w.RS)\r\n\t\tif rsLen >= 3 {\r\n\t\t\tswitch w.RS[rsLen-3] {\r\n\t\t\tcase 99, 100, 101, 103, 104, 107, 109, 110, 114, 116:\r\n\t\t\t\tw.RemoveLastNRunes(len(suffixRunes))\r\n\t\t\t\treturn true\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn false\r\n\tcase \"ogi\":\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\trsLen := len(w.RS)\r\n\t\tif rsLen >= 4 && w.RS[rsLen-4] == 108 {\r\n\t\t\tw.ReplaceSuffixRunes(suffixRunes, []rune(\"og\"), true)\r\n\t\t}\r\n\t\treturn true\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tvar repl string\r\n\tswitch suffix {\r\n\tcase \"tional\":\r\n\t\trepl = \"tion\"\r\n\tcase \"enci\":\r\n\t\trepl = \"ence\"\r\n\tcase \"anci\":\r\n\t\trepl = \"ance\"\r\n\tcase \"abli\":\r\n\t\trepl = \"able\"\r\n\tcase \"entli\":\r\n\t\trepl = \"ent\"\r\n\tcase \"izer\", \"ization\":\r\n\t\trepl = \"ize\"\r\n\tcase \"ational\", \"ation\", \"ator\":\r\n\t\trepl = \"ate\"\r\n\tcase \"alism\", \"aliti\", \"alli\":\r\n\t\trepl = \"al\"\r\n\tcase \"fulness\":\r\n\t\trepl = \"ful\"\r\n\tcase \"ousli\", \"ousness\":\r\n\t\trepl = \"ous\"\r\n\tcase \"iveness\", \"iviti\":\r\n\t\trepl = \"ive\"\r\n\tcase \"biliti\", \"bli\":\r\n\t\trepl = \"ble\"\r\n\tcase \"fulli\":\r\n\t\trepl = \"ful\"\r\n\tcase \"lessli\":\r\n\t\trepl = \"less\"\r\n\t}\r\n\tw.ReplaceSuffixRunes(suffixRunes, []rune(repl), true)\r\n\treturn true\r\n}","code-length":756,"reference":"\/\/ Step 2 is the stemming of various endings found in\n\/\/ R1 including \"al\", \"ness\", and \"li\".\n\/\/","result":"Code too long,keep in 512.","score":[0.0146,0.0284]}
{"code":"\/*is used to<extra_id_0>\r\nfunc step3(word *snowballword.SnowballWord) bool {\r\n\tsuffix, suffixRunes := word.FirstSuffixIfIn(word.RVstart, len(word.RS),\r\n\t\t\"os\", \"a\", \"o\", \"\u00e1\", \"\u00ed\", \"\u00f3\", \"e\", \"\u00e9\",\r\n\t)\r\n\t\r\n\t\r\n\tif suffix == \"\" {\r\n\t\treturn false\r\n\t}\r\n\t\r\n\tword.RemoveLastNRunes(len(suffixRunes))\r\n\tif suffix == \"e\" || suffix == \"\u00e9\" {\r\n\t\t\r\n\t\t\r\n\t\tguSuffix, _ := word.FirstSuffix(\"gu\")\r\n\t\tif guSuffix != \"\" {\r\n\t\t\tword.RemoveLastNRunes(1)\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":215,"reference":"\/\/ Step 3 is the removal of residual suffixes.\n\/\/","result":"Remove the last run of the step.","score":[0.1251,0.1546]}
{"code":"\/*is used to<extra_id_0>\r\nfunc step0(w *snowballword.SnowballWord) bool {\r\n\tsuffix, suffixRunes := w.FirstSuffix(\"'s'\", \"'s\", \"'\")\r\n\tif suffix == \"\" {\r\n\t\treturn false\r\n\t}\r\n\tw.RemoveLastNRunes(len(suffixRunes))\r\n\treturn true\r\n}","code-length":92,"reference":"\/\/ Step 0 is to strip off apostrophes and \"s\".\n\/\/","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc VnvSuffix(word *snowballword.SnowballWord, f isVowelFunc, start int) int {\r\n\tfor i := 1; i < len(word.RS[start:]); i++ {\r\n\t\tj := start + i\r\n\t\tif f(word.RS[j-1]) && !f(word.RS[j]) {\r\n\t\t\treturn j + 1\r\n\t\t}\r\n\t}\r\n\treturn len(word.RS)\r\n}","code-length":124,"reference":"\/\/ Finds the region after the first non-vowel following a vowel,\n\/\/ or a the null region at the end of the word if there is no\n\/\/ such non-vowel.  Returns the index in the Word where the\n\/\/ region starts; optionally skips the first `start` characters.\n\/\/","result":"Generate the VnvSuffix function.","score":[0.0,0.0115]}
{"code":"\/*is used to<extra_id_0>\r\nfunc step1(w *snowballword.SnowballWord) bool {\r\n\t\r\n\tsuffixes := []string{\r\n\t\t\"heterna\", \"hetens\", \"anden\", \"heten\", \"heter\", \"arnas\",\r\n\t\t\"ernas\", \"ornas\", \"andes\", \"arens\", \"andet\", \"arna\", \"erna\",\r\n\t\t\"orna\", \"ande\", \"arne\", \"aste\", \"aren\", \"ades\", \"erns\", \"ade\",\r\n\t\t\"are\", \"ern\", \"ens\", \"het\", \"ast\", \"ad\", \"en\", \"ar\", \"er\",\r\n\t\t\"or\", \"as\", \"es\", \"at\", \"a\", \"e\", \"s\",\r\n\t}\r\n\t\r\n\t\r\n\tsuffix, suffixRunes := w.FirstSuffixIn(w.R1start, len(w.RS), suffixes...)\r\n\t\r\n\tif suffix == \"\" || len(suffixRunes) > len(w.RS)-w.R1start {\r\n\t\treturn false\r\n\t}\r\n\tif suffix == \"s\" {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\trsLen := len(w.RS)\r\n\t\tif rsLen >= 2 {\r\n\t\t\tswitch w.RS[rsLen-2] {\r\n\t\t\tcase 'b', 'c', 'd', 'f', 'g', 'h', 'j', 'k',\r\n\t\t\t\t'l', 'm', 'n', 'o', 'p', 'r', 't', 'v', 'y':\r\n\t\t\t\tw.RemoveLastNRunes(len(suffixRunes))\r\n\t\t\t\treturn true\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn false\r\n\t}\r\n\t\r\n\tw.RemoveLastNRunes(len(suffixRunes))\r\n\treturn true\r\n}","code-length":458,"reference":"\/\/ Step 1 is the stemming of various endings found in\n\/\/ R1 including \"heterna\", \"ornas\", and \"andet\".\n\/\/","result":"Remove the last word from the word list.","score":[0.0351,0.0559]}
{"code":"\/*is used to<extra_id_0>\r\nfunc step2a(word *snowballword.SnowballWord) bool {\r\n\t\r\n\t\r\n\tsuffix, suffixRunes := word.FirstSuffixIn(word.RVstart, len(word.RS),\r\n\t\t\"issantes\", \"issaIent\", \"issions\", \"issants\", \"issante\",\r\n\t\t\"iraIent\", \"issons\", \"issiez\", \"issent\", \"issant\", \"issait\",\r\n\t\t\"issais\", \"irions\", \"issez\", \"isses\", \"iront\", \"irons\", \"iriez\",\r\n\t\t\"irent\", \"irait\", \"irais\", \"\u00eetes\", \"\u00eemes\", \"isse\", \"irez\",\r\n\t\t\"iras\", \"irai\", \"ira\", \"ies\", \"\u00eet\", \"it\", \"is\", \"ir\", \"ie\", \"i\",\r\n\t)\r\n\tif suffix != \"\" {\r\n\t\tsLen := len(suffixRunes)\r\n\t\tidx := len(word.RS) - sLen - 1\r\n\t\tif idx >= 0 && word.FitsInRV(sLen+1) && isLowerVowel(word.RS[idx]) == false {\r\n\t\t\tword.RemoveLastNRunes(len(suffixRunes))\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":344,"reference":"\/\/ Step 2a is the removal of Verb suffixes beginning\n\/\/ with \"i\" in the RV region.\n\/\/","result":"Var step.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc removePerfectiveGerundEnding(word *snowballword.SnowballWord) bool {\r\n\tsuffix, suffixRunes := word.FirstSuffixIn(word.RVstart, len(word.RS),\r\n\t\t\"\u0438\u0432\u0448\u0438\u0441\u044c\", \"\u044b\u0432\u0448\u0438\u0441\u044c\", \"\u0432\u0448\u0438\u0441\u044c\", \"\u0438\u0432\u0448\u0438\", \"\u044b\u0432\u0448\u0438\", \"\u0432\u0448\u0438\", \"\u0438\u0432\", \"\u044b\u0432\", \"\u0432\",\r\n\t)\r\n\tswitch suffix {\r\n\tcase \"\u0432\", \"\u0432\u0448\u0438\", \"\u0432\u0448\u0438\u0441\u044c\":\r\n\t\t\r\n\t\t\r\n\t\tif precededByARinRV(word, len(suffixRunes)) == false {\r\n\t\t\tsuffix = \"\"\r\n\t\t}\r\n\t}\r\n\tif suffix != \"\" {\r\n\t\tword.RemoveLastNRunes(len(suffixRunes))\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":275,"reference":"\/\/ Remove perfective gerund endings and return true if one was removed.\n\/\/","result":"Remove the perfective gerund ending.","score":[0.0759,0.2095]}
{"code":"\/*is used to<extra_id_0>\r\nfunc removeAdjectivalEnding(word *snowballword.SnowballWord) bool {\r\n\t\r\n\t\r\n\t\r\n\tsuffix, _ := word.RemoveFirstSuffixIn(word.RVstart,\r\n\t\t\"\u0438\u043c\u0438\", \"\u044b\u043c\u0438\", \"\u0435\u0433\u043e\", \"\u043e\u0433\u043e\", \"\u0435\u043c\u0443\", \"\u043e\u043c\u0443\", \"\u0435\u0435\", \"\u0438\u0435\",\r\n\t\t\"\u044b\u0435\", \"\u043e\u0435\", \"\u0435\u0439\", \"\u0438\u0439\", \"\u044b\u0439\", \"\u043e\u0439\", \"\u0435\u043c\", \"\u0438\u043c\", \"\u044b\u043c\",\r\n\t\t\"\u043e\u043c\", \"\u0438\u0445\", \"\u044b\u0445\", \"\u0443\u044e\", \"\u044e\u044e\", \"\u0430\u044f\", \"\u044f\u044f\", \"\u043e\u044e\", \"\u0435\u044e\",\r\n\t)\r\n\tif suffix != \"\" {\r\n\t\t\r\n\t\t\r\n\t\tnewSuffix, newSuffixRunes := word.FirstSuffixIn(word.RVstart, len(word.RS),\r\n\t\t\t\"\u0438\u0432\u0448\", \"\u044b\u0432\u0448\", \"\u0443\u044e\u0449\",\r\n\t\t\t\"\u0435\u043c\", \"\u043d\u043d\", \"\u0432\u0448\", \"\u044e\u0449\", \"\u0449\",\r\n\t\t)\r\n\t\tswitch newSuffix {\r\n\t\tcase \"\u0435\u043c\", \"\u043d\u043d\", \"\u0432\u0448\", \"\u044e\u0449\", \"\u0449\":\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tif precededByARinRV(word, len(newSuffixRunes)) == false {\r\n\t\t\t\tnewSuffix = \"\"\r\n\t\t\t}\r\n\t\t}\r\n\t\tif newSuffix != \"\" {\r\n\t\t\tword.RemoveLastNRunes(len(newSuffixRunes))\r\n\t\t}\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":493,"reference":"\/\/ Remove adjectival endings and return true if one was removed.\n\/\/","result":"Remove adjectival ending.","score":[0.0287,0.1689]}
{"code":"\/*is used to<extra_id_0>\r\nfunc step2b(word *snowballword.SnowballWord) bool {\r\n\tsuffix, suffixRunes := word.FirstSuffixIn(word.RVstart, len(word.RS),\r\n\t\t\"i\u00e9semos\", \"i\u00e9ramos\", \"ir\u00edamos\", \"er\u00edamos\", \"ar\u00edamos\", \"\u00e1semos\",\r\n\t\t\"\u00e1ramos\", \"\u00e1bamos\", \"isteis\", \"ir\u00edais\", \"iremos\", \"ieseis\",\r\n\t\t\"ierais\", \"er\u00edais\", \"eremos\", \"asteis\", \"ar\u00edais\", \"aremos\",\r\n\t\t\"\u00edamos\", \"ir\u00edas\", \"ir\u00edan\", \"ir\u00e9is\", \"ieses\", \"iesen\", \"ieron\",\r\n\t\t\"ieras\", \"ieran\", \"iendo\", \"er\u00edas\", \"er\u00edan\", \"er\u00e9is\", \"aseis\",\r\n\t\t\"ar\u00edas\", \"ar\u00edan\", \"ar\u00e9is\", \"arais\", \"abais\", \"\u00edais\", \"iste\",\r\n\t\t\"ir\u00eda\", \"ir\u00e1s\", \"ir\u00e1n\", \"imos\", \"iese\", \"iera\", \"idos\", \"idas\",\r\n\t\t\"er\u00eda\", \"er\u00e1s\", \"er\u00e1n\", \"aste\", \"ases\", \"asen\", \"ar\u00eda\", \"ar\u00e1s\",\r\n\t\t\"ar\u00e1n\", \"aron\", \"aras\", \"aran\", \"ando\", \"amos\", \"ados\", \"adas\",\r\n\t\t\"abas\", \"aban\", \"\u00edas\", \"\u00edan\", \"\u00e9is\", \"\u00e1is\", \"ir\u00e9\", \"ir\u00e1\", \"ido\",\r\n\t\t\"ida\", \"er\u00e9\", \"er\u00e1\", \"emos\", \"ase\", \"ar\u00e9\", \"ar\u00e1\", \"ara\", \"ado\",\r\n\t\t\"ada\", \"aba\", \"\u00eds\", \"\u00eda\", \"i\u00f3\", \"ir\", \"id\", \"es\", \"er\", \"en\",\r\n\t\t\"ed\", \"as\", \"ar\", \"an\", \"ad\",\r\n\t)\r\n\tswitch suffix {\r\n\tcase \"\":\r\n\t\treturn false\r\n\tcase \"en\", \"es\", \"\u00e9is\", \"emos\":\r\n\t\t\r\n\t\tword.RemoveLastNRunes(len(suffixRunes))\r\n\t\tguSuffix, _ := word.FirstSuffix(\"gu\")\r\n\t\tif guSuffix != \"\" {\r\n\t\t\tword.RemoveLastNRunes(1)\r\n\t\t}\r\n\tdefault:\r\n\t\t\r\n\t\tword.RemoveLastNRunes(len(suffixRunes))\r\n\t}\r\n\treturn true\r\n}","code-length":708,"reference":"\/\/ Step 2b is the removal of verb suffixes beginning y,\n\/\/ Search for the longest among the following suffixes\n\/\/ in RV, and if found, delete if preceded by u.\n\/\/","result":"Code too long,keep in 512.","score":[0.0011,0.0171]}
{"code":"\/*is used to<extra_id_0>\r\nfunc step4(word *snowballword.SnowballWord) bool {\r\n\thadChange := false\r\n\tif word.String() == \"voudrion\" {\r\n\t\tlog.Println(\"...\", word)\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tif idx := len(word.RS) - 1; idx >= 1 && word.RS[idx] == 115 {\r\n\t\tswitch word.RS[idx-1] {\r\n\t\tcase 97, 105, 111, 117, 232, 115:\r\n\t\t\t\r\n\t\t\treturn false\r\n\t\tdefault:\r\n\t\t\tword.RemoveLastNRunes(1)\r\n\t\t\thadChange = true\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tsuffix, suffixRunes := word.FirstSuffixIn(word.RVstart, len(word.RS),\r\n\t\t\"I\u00e8re\", \"i\u00e8re\", \"Ier\", \"ier\", \"ion\", \"e\", \"\u00eb\",\r\n\t)\r\n\tswitch suffix {\r\n\tcase \"\":\r\n\t\treturn hadChange\r\n\tcase \"ion\":\r\n\t\t\r\n\t\tconst sLen int = 3\r\n\t\tidx := len(word.RS) - sLen - 1\r\n\t\tif word.FitsInR2(sLen) && idx >= 0 && word.FitsInRV(sLen+1) {\r\n\t\t\tif word.RS[idx] == 115 || word.RS[idx] == 116 {\r\n\t\t\t\tword.RemoveLastNRunes(sLen)\r\n\t\t\t\treturn true\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn hadChange\r\n\tcase \"ier\", \"i\u00e8re\", \"Ier\", \"I\u00e8re\":\r\n\t\t\r\n\t\tword.ReplaceSuffixRunes(suffixRunes, []rune(\"i\"), true)\r\n\t\treturn true\r\n\tcase \"e\":\r\n\t\tword.RemoveLastNRunes(1)\r\n\t\treturn true\r\n\tcase \"\u00eb\":\r\n\t\t\r\n\t\tidx := len(word.RS) - 1\r\n\t\tif idx >= 2 && word.RS[idx-2] == 103 && word.RS[idx-1] == 117 {\r\n\t\t\tword.RemoveLastNRunes(1)\r\n\t\t\treturn true\r\n\t\t}\r\n\t\treturn hadChange\r\n\t}\r\n\treturn true\r\n}","code-length":593,"reference":"\/\/ Step 4 is the cleaning up of residual suffixes.\n\/\/","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc step5(w *snowballword.SnowballWord) bool {\r\n\t\r\n\tlri := len(w.RS) - 1\r\n\t\r\n\t\r\n\t\r\n\tif w.R1start > lri {\r\n\t\treturn false\r\n\t}\r\n\tif w.RS[lri] == 101 {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif w.R2start <= lri || !endsShortSyllable(w, lri) {\r\n\t\t\tw.ReplaceSuffix(\"e\", \"\", true)\r\n\t\t\treturn true\r\n\t\t}\r\n\t\treturn false\r\n\t} else if w.R2start <= lri && w.RS[lri] == 108 && lri-1 >= 0 && w.RS[lri-1] == 108 {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tw.ReplaceSuffix(\"l\", \"\", true)\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":242,"reference":"\/\/ Step 5 is the stemming of \"e\" and \"l\" sufficies\n\/\/ found in R2.\n\/\/","result":"Generate the step.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Stem(word string, stemStopwWords bool) string {\r\n\tword = strings.ToLower(strings.TrimSpace(word))\r\n\t\r\n\tif len(word) <= 2 || (stemStopwWords == false && isStopWord(word)) {\r\n\t\treturn word\r\n\t}\r\n\tw := snowballword.New(word)\r\n\t\r\n\t\r\n\t\r\n\tpreprocess(w)\r\n\tstep0(w)\r\n\tchangeInStep1 := step1(w)\r\n\tif changeInStep1 == false {\r\n\t\tchangeInStep2a := step2a(w)\r\n\t\tif changeInStep2a == false {\r\n\t\t\tstep2b(w)\r\n\t\t}\r\n\t}\r\n\tstep3(w)\r\n\tpostprocess(w)\r\n\treturn w.String()\r\n}","code-length":217,"reference":"\/\/ Stem an Spanish word.  This is the only exported\n\/\/ function in this package.\n\/\/","result":"Generate the stemmer.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Stem(word string, stemStopwWords bool) string {\r\n\tword = strings.ToLower(strings.TrimSpace(word))\r\n\tw := snowballword.New(word)\r\n\t\r\n\tif len(w.RS) <= 2 || (stemStopwWords == false && isStopWord(word)) {\r\n\t\treturn word\r\n\t}\r\n\tpreprocess(w)\r\n\tstep1(w)\r\n\tstep2(w)\r\n\tstep3(w)\r\n\tstep4(w)\r\n\treturn w.String()\r\n}","code-length":146,"reference":"\/\/ Stem an Russian word.  This is the only exported\n\/\/ function in this package.\n\/\/","result":"Generate Stem.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isStopWord(word string) bool {\r\n\tswitch word {\r\n\tcase \"ut\", \"f\u00e5\", \"hadde\", \"hva\", \"tilbake\", \"vil\", \"han\", \"meget\", \"men\", \"vi\", \"en\", \"f\u00f8r\",\r\n\t\t\"samme\", \"stille\", \"inn\", \"er\", \"kan\", \"makt\", \"ved\", \"fors\u00f8ke\", \"hvis\", \"part\", \"rett\",\r\n\t\t\"m\u00e5te\", \"denne\", \"mer\", \"i\", \"lang\", \"ny\", \"hans\", \"hvilken\", \"tid\", \"vite\", \"her\", \"opp\",\r\n\t\t\"var\", \"navn\", \"mye\", \"om\", \"sant\", \"tilstand\", \"der\", \"ikke\", \"mest\", \"punkt\", \"hvem\",\r\n\t\t\"skulle\", \"mange\", \"over\", \"v\u00e5rt\", \"alle\", \"arbeid\", \"lik\", \"like\", \"g\u00e5\", \"n\u00e5r\", \"siden\",\r\n\t\t\"\u00e5\", \"begge\", \"bruke\", \"eller\", \"og\", \"til\", \"da\", \"et\", \"hvorfor\", \"n\u00e5\", \"sist\", \"slutt\",\r\n\t\t\"deres\", \"det\", \"hennes\", \"s\u00e5\", \"mens\", \"bra\", \"din\", \"fordi\", \"gj\u00f8re\", \"god\", \"ha\", \"start\",\r\n\t\t\"andre\", \"m\u00e5\", \"med\", \"under\", \"meg\", \"oss\", \"innen\", \"p\u00e5\", \"verdi\", \"ville\", \"kunne\", \"uten\",\r\n\t\t\"v\u00e5r\", \"slik\", \"ene\", \"folk\", \"min\", \"riktig\", \"enhver\", \"bort\", \"enn\", \"nei\", \"som\", \"v\u00e5re\", \"disse\",\r\n\t\t\"gjorde\", \"lage\", \"si\", \"du\", \"fra\", \"ogs\u00e5\", \"hvordan\", \"av\", \"eneste\", \"for\", \"hvor\", \"f\u00f8rst\", \"hver\":\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":572,"reference":"\/\/ Return `true` if the input `word` is a Norwegian stop word.\n\/\/","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isStopWord(word string) bool {\r\n\tswitch word {\r\n\tcase \"och\", \"det\", \"att\", \"i\", \"en\", \"jag\", \"hon\", \"som\", \"han\",\r\n\t\t\"p\u00e5\", \"den\", \"med\", \"var\", \"sig\", \"f\u00f6r\", \"s\u00e5\", \"till\", \"\u00e4r\", \"men\",\r\n\t\t\"ett\", \"om\", \"hade\", \"de\", \"av\", \"icke\", \"mig\", \"du\", \"henne\", \"d\u00e5\",\r\n\t\t\"sin\", \"nu\", \"har\", \"inte\", \"hans\", \"honom\", \"skulle\", \"hennes\",\r\n\t\t\"d\u00e4r\", \"min\", \"man\", \"ej\", \"vid\", \"kunde\", \"n\u00e5got\", \"fr\u00e5n\", \"ut\",\r\n\t\t\"n\u00e4r\", \"efter\", \"upp\", \"vi\", \"dem\", \"vara\", \"vad\", \"\u00f6ver\", \"\u00e4n\",\r\n\t\t\"dig\", \"kan\", \"sina\", \"h\u00e4r\", \"ha\", \"mot\", \"alla\", \"under\", \"n\u00e5gon\",\r\n\t\t\"eller\", \"allt\", \"mycket\", \"sedan\", \"ju\", \"denna\", \"sj\u00e4lv\", \"detta\",\r\n\t\t\"\u00e5t\", \"utan\", \"varit\", \"hur\", \"ingen\", \"mitt\", \"ni\", \"bli\", \"blev\",\r\n\t\t\"oss\", \"din\", \"dessa\", \"n\u00e5gra\", \"deras\", \"blir\", \"mina\", \"samma\",\r\n\t\t\"vilken\", \"er\", \"s\u00e5dan\", \"v\u00e5r\", \"blivit\", \"dess\", \"inom\", \"mellan\",\r\n\t\t\"s\u00e5dant\", \"varf\u00f6r\", \"varje\", \"vilka\", \"ditt\", \"vem\", \"vilket\",\r\n\t\t\"sitta\", \"s\u00e5dana\", \"vart\", \"dina\", \"vars\", \"v\u00e5rt\", \"v\u00e5ra\",\r\n\t\t\"ert\", \"era\", \"vilkas\":\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":581,"reference":"\/\/ Return `true` if the input `word` is a Swedish stop word.\n\/\/","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(in string) (word *SnowballWord) {\r\n\tword = &SnowballWord{RS: []rune(in)}\r\n\tword.R1start = len(word.RS)\r\n\tword.R2start = len(word.RS)\r\n\tword.RVstart = len(word.RS)\r\n\treturn\r\n}","code-length":95,"reference":"\/\/ Create a new SnowballWord struct","result":"Create a new SnowballWord.","score":[0.3991,0.5077]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *SnowballWord) RemoveLastNRunes(n int) {\r\n\tw.RS = w.RS[:len(w.RS)-n]\r\n\tw.resetR1R2()\r\n}","code-length":61,"reference":"\/\/ Remove the last `n` runes from the SnowballWord.\n\/\/","result":"Remove last n runs of words.","score":[0.1179,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *SnowballWord) resetR1R2() {\r\n\trsLen := len(w.RS)\r\n\tif w.R1start > rsLen {\r\n\t\tw.R1start = rsLen\r\n\t}\r\n\tif w.R2start > rsLen {\r\n\t\tw.R2start = rsLen\r\n\t}\r\n\tif w.RVstart > rsLen {\r\n\t\tw.RVstart = rsLen\r\n\t}\r\n}","code-length":127,"reference":"\/\/ Resets R1start and R2start to ensure they\n\/\/ are within bounds of the current rune slice.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *SnowballWord) slice(start, stop int) []rune {\r\n\tstartMin := 0\r\n\tif start < startMin {\r\n\t\tstart = startMin\r\n\t}\r\n\tmax := len(w.RS) - 1\r\n\tif start > max {\r\n\t\tstart = max\r\n\t}\r\n\tif stop > max {\r\n\t\tstop = max\r\n\t}\r\n\treturn w.RS[start:stop]\r\n}","code-length":123,"reference":"\/\/ Return a slice of w.RS, allowing the start\n\/\/ and stop to be out of bounds.\n\/\/","result":"Avoid recursion.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *SnowballWord) FitsInR1(x int) bool {\r\n\treturn w.R1start <= len(w.RS)-x\r\n}","code-length":49,"reference":"\/\/ Returns true if `x` runes would fit into R1.\n\/\/","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *SnowballWord) FitsInR2(x int) bool {\r\n\treturn w.R2start <= len(w.RS)-x\r\n}","code-length":49,"reference":"\/\/ Returns true if `x` runes would fit into R2.\n\/\/","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *SnowballWord) FitsInRV(x int) bool {\r\n\treturn w.RVstart <= len(w.RS)-x\r\n}","code-length":49,"reference":"\/\/ Returns true if `x` runes would fit into RV.\n\/\/","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *SnowballWord) FirstPrefix(prefixes ...string) (foundPrefix string, foundPrefixRunes []rune) {\r\n\tfound := false\r\n\trsLen := len(w.RS)\r\n\tfor _, prefix := range prefixes {\r\n\t\tprefixRunes := []rune(prefix)\r\n\t\tif len(prefixRunes) > rsLen {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tfound = true\r\n\t\tfor i, r := range prefixRunes {\r\n\t\t\tif i > rsLen-1 || (w.RS)[i] != r {\r\n\t\t\t\tfound = false\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif found {\r\n\t\t\tfoundPrefix = prefix\r\n\t\t\tfoundPrefixRunes = prefixRunes\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\treturn\r\n}","code-length":220,"reference":"\/\/ Return the first prefix found or the empty string.","result":"Find the first prefix of a.","score":[0.2042,0.2662]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *SnowballWord) HasSuffixRunes(suffixRunes []rune) bool {\r\n\treturn w.HasSuffixRunesIn(0, len(w.RS), suffixRunes)\r\n}","code-length":58,"reference":"\/\/ Return true if `w` ends with `suffixRunes`\n\/\/","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *SnowballWord) FirstSuffixIfIn(startPos, endPos int, suffixes ...string) (suffix string, suffixRunes []rune) {\r\n\tfor _, suffix := range suffixes {\r\n\t\tsuffixRunes := []rune(suffix)\r\n\t\tif w.HasSuffixRunesIn(0, endPos, suffixRunes) {\r\n\t\t\tif endPos-len(suffixRunes) >= startPos {\r\n\t\t\t\treturn suffix, suffixRunes\r\n\t\t\t} else {\r\n\t\t\t\t\r\n\t\t\t\tsuffixRunes = suffixRunes[:0]\r\n\t\t\t\treturn \"\", suffixRunes\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\tsuffixRunes = suffixRunes[:0]\r\n\treturn \"\", suffixRunes\r\n}","code-length":192,"reference":"\/\/ Find the first suffix that ends at `endPos` in the word among\n\/\/ those provided; then,\n\/\/ check to see if it begins after startPos.  If it does, return\n\/\/ it, else return the empty string and empty rune slice.  This\n\/\/ may seem a counterintuitive manner to do this.  However, it\n\/\/ matches what is required most of the time by the Snowball\n\/\/ stemmer steps.\n\/\/","result":"Find the first suffix of a word.","score":[0.0001,0.0679]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *SnowballWord) RemoveFirstSuffixIfIn(startPos int, suffixes ...string) (suffix string, suffixRunes []rune) {\r\n\tsuffix, suffixRunes = w.FirstSuffixIfIn(startPos, len(w.RS), suffixes...)\r\n\tif suffix != \"\" {\r\n\t\tw.RemoveLastNRunes(len(suffixRunes))\r\n\t}\r\n\treturn\r\n}","code-length":108,"reference":"\/\/ Find the first suffix in the word among those provided; then,\n\/\/ check to see if it begins after startPos.  If it does,\n\/\/ remove it.\n\/\/","result":"Remove suffix.","score":[0,0.0197]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *SnowballWord) RemoveFirstSuffix(suffixes ...string) (suffix string, suffixRunes []rune) {\r\n\treturn w.RemoveFirstSuffixIn(0, suffixes...)\r\n}","code-length":57,"reference":"\/\/ Removes the first suffix found","result":"Generate the code.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *SnowballWord) FirstSuffix(suffixes ...string) (suffix string, suffixRunes []rune) {\r\n\treturn w.FirstSuffixIfIn(0, len(w.RS), suffixes...)\r\n}","code-length":62,"reference":"\/\/ Return the first suffix found or the empty string.","result":"Generate the code.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc preprocess(word *snowballword.SnowballWord) {\r\n\t\r\n\tnormalizeApostrophes(word)\r\n\ttrimLeftApostrophes(word)\r\n\t\r\n\t\r\n\tcapitalizeYs(word)\r\n\t\r\n\tr1start, r2start := r1r2(word)\r\n\tword.R1start = r1start\r\n\tword.R2start = r2start\r\n}","code-length":118,"reference":"\/\/ Applies various transformations necessary for the\n\/\/ other, subsequent stemming steps.  Most important\n\/\/ of which is defining the two regions R1 & R2.\n\/\/","result":"Preprocess the word.","score":[0.0002,0.0211]}
{"code":"\/*is used to<extra_id_0>\r\nfunc step0(word *snowballword.SnowballWord) bool {\r\n\t\r\n\tsuffix1, suffix1Runes := word.FirstSuffixIn(word.RVstart, len(word.RS),\r\n\t\t\"selas\", \"selos\", \"sela\", \"selo\", \"las\", \"les\",\r\n\t\t\"los\", \"nos\", \"me\", \"se\", \"la\", \"le\", \"lo\",\r\n\t)\r\n\t\r\n\tif suffix1 == \"\" {\r\n\t\treturn false\r\n\t}\r\n\t\r\n\tsuffix2, suffix2Runes := word.FirstSuffixIn(word.RVstart, len(word.RS)-len(suffix1),\r\n\t\t\"i\u00e9ndo\", \"iendo\", \"yendo\", \"ando\", \"\u00e1ndo\",\r\n\t\t\"\u00e1r\", \"\u00e9r\", \"\u00edr\", \"ar\", \"er\", \"ir\",\r\n\t)\r\n\tswitch suffix2 {\r\n\tcase \"\":\r\n\t\t\r\n\t\treturn false\r\n\tcase \"i\u00e9ndo\", \"\u00e1ndo\", \"\u00e1r\", \"\u00e9r\", \"\u00edr\":\r\n\t\t\r\n\t\t\r\n\t\tvar suffix2repl string\r\n\t\tswitch suffix2 {\r\n\t\tcase \"\":\r\n\t\t\treturn false\r\n\t\tcase \"i\u00e9ndo\":\r\n\t\t\tsuffix2repl = \"iendo\"\r\n\t\tcase \"\u00e1ndo\":\r\n\t\t\tsuffix2repl = \"ando\"\r\n\t\tcase \"\u00e1r\":\r\n\t\t\tsuffix2repl = \"ar\"\r\n\t\tcase \"\u00edr\":\r\n\t\t\tsuffix2repl = \"ir\"\r\n\t\t}\r\n\t\tword.RemoveLastNRunes(len(suffix1Runes))\r\n\t\tword.ReplaceSuffixRunes(suffix2Runes, []rune(suffix2repl), true)\r\n\t\treturn true\r\n\tcase \"ando\", \"iendo\", \"ar\", \"er\", \"ir\":\r\n\t\tword.RemoveLastNRunes(len(suffix1Runes))\r\n\t\treturn true\r\n\tcase \"yendo\":\r\n\t\t\r\n\t\t\r\n\t\tfor i := 0; i < len(word.RS)-(len(suffix1)+len(suffix2)); i++ {\r\n\t\t\t\r\n\t\t\tif word.RS[i] == 117 {\r\n\t\t\t\tword.RemoveLastNRunes(len(suffix1Runes))\r\n\t\t\t\treturn true\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":627,"reference":"\/\/ Step 0 is the removal of attached pronouns\n\/\/","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc step1b(w *snowballword.SnowballWord) bool {\r\n\tsuffix, suffixRunes := w.FirstSuffix(\"eedly\", \"ingly\", \"edly\", \"ing\", \"eed\", \"ed\")\r\n\tswitch suffix {\r\n\tcase \"\":\r\n\t\t\r\n\t\treturn false\r\n\tcase \"eed\", \"eedly\":\r\n\t\t\r\n\t\tif len(suffixRunes) <= len(w.RS)-w.R1start {\r\n\t\t\tw.ReplaceSuffixRunes(suffixRunes, []rune(\"ee\"), true)\r\n\t\t}\r\n\t\treturn true\r\n\tcase \"ed\", \"edly\", \"ing\", \"ingly\":\r\n\t\thasLowerVowel := false\r\n\t\tfor i := 0; i < len(w.RS)-len(suffixRunes); i++ {\r\n\t\t\tif isLowerVowel(w.RS[i]) {\r\n\t\t\t\thasLowerVowel = true\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif hasLowerVowel {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\toriginalR1start := w.R1start\r\n\t\t\toriginalR2start := w.R2start\r\n\t\t\t\r\n\t\t\tw.RemoveLastNRunes(len(suffixRunes))\r\n\t\t\t\r\n\t\t\tnewSuffix, newSuffixRunes := w.FirstSuffix(\"at\", \"bl\", \"iz\", \"bb\", \"dd\", \"ff\", \"gg\", \"mm\", \"nn\", \"pp\", \"rr\", \"tt\")\r\n\t\t\tswitch newSuffix {\r\n\t\t\tcase \"\":\r\n\t\t\t\t\r\n\t\t\t\tif isShortWord(w) {\r\n\t\t\t\t\t\r\n\t\t\t\t\t\r\n\t\t\t\t\tw.RS = append(w.RS, []rune(\"e\")...)\r\n\t\t\t\t\tw.R1start = len(w.RS)\r\n\t\t\t\t\tw.R2start = len(w.RS)\r\n\t\t\t\t\treturn true\r\n\t\t\t\t}\r\n\t\t\tcase \"at\", \"bl\", \"iz\":\r\n\t\t\t\t\r\n\t\t\t\tw.ReplaceSuffixRunes(newSuffixRunes, []rune(newSuffix+\"e\"), true)\r\n\t\t\tcase \"bb\", \"dd\", \"ff\", \"gg\", \"mm\", \"nn\", \"pp\", \"rr\", \"tt\":\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tw.RemoveLastNRunes(1)\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\trsLen := len(w.RS)\r\n\t\t\tif originalR1start < rsLen {\r\n\t\t\t\tw.R1start = originalR1start\r\n\t\t\t} else {\r\n\t\t\t\tw.R1start = rsLen\r\n\t\t\t}\r\n\t\t\tif originalR2start < rsLen {\r\n\t\t\t\tw.R2start = originalR2start\r\n\t\t\t} else {\r\n\t\t\t\tw.R2start = rsLen\r\n\t\t\t}\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":749,"reference":"\/\/ Step 1b is the normalization of various \"ly\" and \"ed\" sufficies.\n\/\/","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc step2b(word *snowballword.SnowballWord) bool {\r\n\t\r\n\t\r\n\tsuffix, suffixRunes := word.FirstSuffixIn(word.RVstart, len(word.RS),\r\n\t\t\"eraIent\", \"assions\", \"erions\", \"assiez\", \"assent\",\r\n\t\t\"\u00e8rent\", \"eront\", \"erons\", \"eriez\", \"erait\", \"erais\",\r\n\t\t\"asses\", \"antes\", \"aIent\", \"\u00e2tes\", \"\u00e2mes\", \"ions\",\r\n\t\t\"erez\", \"eras\", \"erai\", \"asse\", \"ants\", \"ante\", \"\u00e9es\",\r\n\t\t\"iez\", \"era\", \"ant\", \"ait\", \"ais\", \"\u00e9s\", \"\u00e9e\", \"\u00e2t\",\r\n\t\t\"ez\", \"er\", \"as\", \"ai\", \"\u00e9\", \"a\",\r\n\t)\r\n\tswitch suffix {\r\n\tcase \"ions\":\r\n\t\t\r\n\t\tsuffixLen := len(suffixRunes)\r\n\t\tif word.FitsInR2(suffixLen) {\r\n\t\t\tword.RemoveLastNRunes(suffixLen)\r\n\t\t\treturn true\r\n\t\t}\r\n\t\treturn false\r\n\tcase \"\u00e9\", \"\u00e9e\", \"\u00e9es\", \"\u00e9s\", \"\u00e8rent\", \"er\", \"era\",\r\n\t\t\"erai\", \"eraIent\", \"erais\", \"erait\", \"eras\", \"erez\",\r\n\t\t\"eriez\", \"erions\", \"erons\", \"eront\", \"ez\", \"iez\":\r\n\t\t\r\n\t\tword.RemoveLastNRunes(len(suffixRunes))\r\n\t\treturn true\r\n\tcase \"\u00e2mes\", \"\u00e2t\", \"\u00e2tes\", \"a\", \"ai\", \"aIent\",\r\n\t\t\"ais\", \"ait\", \"ant\", \"ante\", \"antes\", \"ants\", \"as\",\r\n\t\t\"asse\", \"assent\", \"asses\", \"assiez\", \"assions\":\r\n\t\t\r\n\t\tword.RemoveLastNRunes(len(suffixRunes))\r\n\t\t\r\n\t\t\r\n\t\tidx := len(word.RS) - 1\r\n\t\tif idx >= 0 && word.RS[idx] == 101 && word.FitsInRV(1) {\r\n\t\t\tword.RemoveLastNRunes(1)\r\n\t\t}\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":624,"reference":"\/\/ Step 2b is the removal of Verb suffixes in RV\n\/\/ that do not begin with \"i\".\n\/\/","result":"Code too long,keep in 512.","score":[0.0146,0.0284]}
{"code":"\/*is used to<extra_id_0>\r\nfunc capitalizeYs(word *snowballword.SnowballWord) (numCapitalizations int) {\r\n\tfor i, r := range word.RS {\r\n\t\t\r\n\t\tif r == 121 && (i == 0 || isLowerVowel(word.RS[i-1])) {\r\n\t\t\tword.RS[i] = 89\r\n\t\t\tnumCapitalizations += 1\r\n\t\t}\r\n\t}\r\n\treturn\r\n}","code-length":117,"reference":"\/\/ Capitalize all 'Y's preceded by vowels or starting a word\n\/\/","result":"Do the actual capitalization.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc uncapitalizeYs(word *snowballword.SnowballWord) {\r\n\tfor i, r := range word.RS {\r\n\t\t\r\n\t\tif r == 89 {\r\n\t\t\tword.RS[i] = 121\r\n\t\t}\r\n\t}\r\n\treturn\r\n}","code-length":84,"reference":"\/\/ Uncapitalize all 'Y's\n\/\/","result":"Remove camelcase.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc stemSpecialWord(word string) (stemmed string) {\r\n\tswitch word {\r\n\tcase \"skis\":\r\n\t\tstemmed = \"ski\"\r\n\tcase \"skies\":\r\n\t\tstemmed = \"sky\"\r\n\tcase \"dying\":\r\n\t\tstemmed = \"die\"\r\n\tcase \"lying\":\r\n\t\tstemmed = \"lie\"\r\n\tcase \"tying\":\r\n\t\tstemmed = \"tie\"\r\n\tcase \"idly\":\r\n\t\tstemmed = \"idl\"\r\n\tcase \"gently\":\r\n\t\tstemmed = \"gentl\"\r\n\tcase \"ugly\":\r\n\t\tstemmed = \"ugli\"\r\n\tcase \"early\":\r\n\t\tstemmed = \"earli\"\r\n\tcase \"only\":\r\n\t\tstemmed = \"onli\"\r\n\tcase \"singly\":\r\n\t\tstemmed = \"singl\"\r\n\tcase \"sky\":\r\n\t\tstemmed = \"sky\"\r\n\tcase \"news\":\r\n\t\tstemmed = \"news\"\r\n\tcase \"howe\":\r\n\t\tstemmed = \"howe\"\r\n\tcase \"atlas\":\r\n\t\tstemmed = \"atlas\"\r\n\tcase \"cosmos\":\r\n\t\tstemmed = \"cosmos\"\r\n\tcase \"bias\":\r\n\t\tstemmed = \"bias\"\r\n\tcase \"andes\":\r\n\t\tstemmed = \"andes\"\r\n\tcase \"inning\":\r\n\t\tstemmed = \"inning\"\r\n\tcase \"innings\":\r\n\t\tstemmed = \"inning\"\r\n\tcase \"outing\":\r\n\t\tstemmed = \"outing\"\r\n\tcase \"outings\":\r\n\t\tstemmed = \"outing\"\r\n\tcase \"canning\":\r\n\t\tstemmed = \"canning\"\r\n\tcase \"cannings\":\r\n\t\tstemmed = \"canning\"\r\n\tcase \"herring\":\r\n\t\tstemmed = \"herring\"\r\n\tcase \"herrings\":\r\n\t\tstemmed = \"herring\"\r\n\tcase \"earring\":\r\n\t\tstemmed = \"earring\"\r\n\tcase \"earrings\":\r\n\t\tstemmed = \"earring\"\r\n\tcase \"proceed\":\r\n\t\tstemmed = \"proceed\"\r\n\tcase \"proceeds\":\r\n\t\tstemmed = \"proceed\"\r\n\tcase \"proceeded\":\r\n\t\tstemmed = \"proceed\"\r\n\tcase \"proceeding\":\r\n\t\tstemmed = \"proceed\"\r\n\tcase \"exceed\":\r\n\t\tstemmed = \"exceed\"\r\n\tcase \"exceeds\":\r\n\t\tstemmed = \"exceed\"\r\n\tcase \"exceeded\":\r\n\t\tstemmed = \"exceed\"\r\n\tcase \"exceeding\":\r\n\t\tstemmed = \"exceed\"\r\n\tcase \"succeed\":\r\n\t\tstemmed = \"succeed\"\r\n\tcase \"succeeds\":\r\n\t\tstemmed = \"succeed\"\r\n\tcase \"succeeded\":\r\n\t\tstemmed = \"succeed\"\r\n\tcase \"succeeding\":\r\n\t\tstemmed = \"succeed\"\r\n\t}\r\n\treturn\r\n}","code-length":808,"reference":"\/\/ Returns the stemmed version of a word if it is a special\n\/\/ case, otherwise returns the empty string.\n\/\/","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isShortWord(w *snowballword.SnowballWord) (isShort bool) {\r\n\t\r\n\tif w.R1start < len(w.RS) {\r\n\t\treturn\r\n\t}\r\n\t\r\n\treturn endsShortSyllable(w, len(w.RS))\r\n}","code-length":85,"reference":"\/\/ A word is called short if it ends in a short syllable, and if R1 is null.\n\/\/","result":"Check if a word is a short word.","score":[0.0691,0.2855]}
{"code":"\/*is used to<extra_id_0>\r\nfunc step1a(w *snowballword.SnowballWord) bool {\r\n\tsuffix, suffixRunes := w.FirstSuffix(\"sses\", \"ied\", \"ies\", \"us\", \"ss\", \"s\")\r\n\tswitch suffix {\r\n\tcase \"sses\":\r\n\t\t\r\n\t\tw.ReplaceSuffixRunes(suffixRunes, []rune(\"ss\"), true)\r\n\t\treturn true\r\n\tcase \"ies\", \"ied\":\r\n\t\t\r\n\t\t\r\n\t\tvar repl string\r\n\t\tif len(w.RS) > 4 {\r\n\t\t\trepl = \"i\"\r\n\t\t} else {\r\n\t\t\trepl = \"ie\"\r\n\t\t}\r\n\t\tw.ReplaceSuffixRunes(suffixRunes, []rune(repl), true)\r\n\t\treturn true\r\n\tcase \"us\", \"ss\":\r\n\t\t\r\n\t\treturn false\r\n\tcase \"s\":\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tfor i := 0; i < len(w.RS)-2; i++ {\r\n\t\t\tif isLowerVowel(w.RS[i]) {\r\n\t\t\t\tw.RemoveLastNRunes(len(suffixRunes))\r\n\t\t\t\treturn true\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":326,"reference":"\/\/ Step 1a is normalization of various special \"s\"-endings.\n\/\/","result":"Remove the first word.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Set(key string, value interface{}) {\r\n\tgid := curGoroutineID()\r\n\tdataLock.Lock()\r\n\tif data[gid] == nil {\r\n\t\tdata[gid] = Values{}\r\n\t}\r\n\tdata[gid][key] = value\r\n\tdataLock.Unlock()\r\n}","code-length":87,"reference":"\/\/ Set sets the value by key and associates it with the current goroutine.","result":"Set a value in the map.","score":[0.067,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Get(key string) interface{} {\r\n\tgid := curGoroutineID()\r\n\tdataLock.RLock()\r\n\tif data[gid] == nil {\r\n\t\tdataLock.RUnlock()\r\n\t\treturn nil\r\n\t}\r\n\tvalue := data[gid][key]\r\n\tdataLock.RUnlock()\r\n\treturn value\r\n}","code-length":97,"reference":"\/\/ Get gets the value by key as it exists for the current goroutine.","result":"Get a value from a map.","score":[0.0605,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Cleanup() {\r\n\tgid := curGoroutineID()\r\n\tdataLock.Lock()\r\n\tdelete(data, gid)\r\n\tdataLock.Unlock()\r\n}","code-length":52,"reference":"\/\/ Cleanup removes all data associated with this goroutine. If this is not\n\/\/ called, the data may persist for the lifetime of your application. This\n\/\/ must be called from the very first goroutine to invoke Set","result":"Clean up the code.","score":[0.0001,0.0145]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getValues() Values {\r\n\tgid := curGoroutineID()\r\n\tdataLock.Lock()\r\n\tvalues := data[gid]\r\n\tdataLock.Unlock()\r\n\treturn values\r\n}","code-length":58,"reference":"\/\/ getValues unlinks two goroutines","result":"Get the values of the current goroutine.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc linkGRs(parentData Values) {\r\n\tchildID := curGoroutineID()\r\n\tdataLock.Lock()\r\n\tdata[childID] = parentData\r\n\tdataLock.Unlock()\r\n}","code-length":61,"reference":"\/\/ linkGRs links two goroutines together, allowing the child to access the\n\/\/ data present in the parent.","result":"Link GRs.","score":[0,0.0305]}
{"code":"\/*is used to<extra_id_0>\r\nfunc unlinkGRs() {\r\n\tchildID := curGoroutineID()\r\n\tdataLock.Lock()\r\n\tdelete(data, childID)\r\n\tdataLock.Unlock()\r\n}","code-length":56,"reference":"\/\/ unlinkGRs unlinks two goroutines","result":"Remove all the GRs from the map.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AppUri(appName, path string, config helpersinternal.CurlConfig) string {\r\n\turiCreator := &helpersinternal.AppUriCreator{CurlConfig: config}\r\n\treturn uriCreator.AppUri(appName, path)\r\n}","code-length":65,"reference":"\/\/ Gets an app's endpoint with the specified path","result":"Generate the app URI.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CurlAppWithTimeout(cfg helpersinternal.CurlConfig, appName, path string, timeout time.Duration, args ...string) string {\r\n\tappCurler := helpersinternal.NewAppCurler(Curl, cfg)\r\n\treturn appCurler.CurlAndWait(cfg, appName, path, timeout, args...)\r\n}","code-length":82,"reference":"\/\/ Curls an app's endpoint and exit successfully before the specified timeout","result":"Generate the code.","score":[0.0203,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CurlApp(cfg helpersinternal.CurlConfig, appName, path string, args ...string) string {\r\n\tappCurler := helpersinternal.NewAppCurler(Curl, cfg)\r\n\treturn appCurler.CurlAndWait(cfg, appName, path, CURL_TIMEOUT, args...)\r\n}","code-length":77,"reference":"\/\/ Curls an app's endpoint and exit successfully before the default timeout","result":"Generate the code.","score":[0.0203,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CurlAppRoot(cfg helpersinternal.CurlConfig, appName string) string {\r\n\tappCurler := helpersinternal.NewAppCurler(Curl, cfg)\r\n\treturn appCurler.CurlAndWait(cfg, appName, \"\/\", CURL_TIMEOUT)\r\n}","code-length":70,"reference":"\/\/ Curls an app's root endpoint and exit successfully before the default timeout","result":"Generate the app root.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetTags(prefix rune, str string, terminator ...rune) (tags []Tag) {\r\n\t\r\n\tif len(terminator) == 0 {\r\n\t\tterminator = []rune(\" \")\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\ttermIndexes := []int{-1}\r\n\tfor i, char := range str {\r\n\t\tif isTerminator(char, terminator...) {\r\n\t\t\ttermIndexes = append(termIndexes, i)\r\n\t\t}\r\n\t}\r\n\t\r\n\ttermIndexes = append(termIndexes, len(str))\r\n\t\r\n\tfor i, t := range termIndexes {\r\n\t\t\r\n\t\tif t >= (len(str) - 1) {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif str[t+1] == byte(prefix) {\r\n\t\t\ttagText := strings.TrimLeft(str[t+2:termIndexes[i+1]], string(prefix))\r\n\t\t\tif tagText == \"\" {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tindex := t + 1\r\n\t\t\ttags = append(tags, Tag{prefix, tagText, index})\r\n\t\t}\r\n\t}\r\n\treturn\r\n}","code-length":302,"reference":"\/\/ GetTags returns a slice of Tags, that is all characters after rune char up\n\/\/ to occurrence of space or another occurrence of rune char. Additionally you\n\/\/ can provide a coma separated unicode characters to be used as terminating\n\/\/ sequence.","result":"Get the tags from the string.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetTagsAsUniqueStrings(prefix rune, str string, terminator ...rune) (strs []string) {\r\n\ttags := GetTags(prefix, str, terminator...)\r\n\tfor _, tag := range tags {\r\n\t\tstrs = append(strs, tag.Tag)\r\n\t}\r\n\treturn uniquify(strs)\r\n}","code-length":88,"reference":"\/\/ GetTagsAsUniqueStrings gets all tags as a slice of unique strings. This is\n\/\/ here to have a means of being somewhat backwards compatible with previous\n\/\/ versions of mention","result":"Generate the tag names as unique strings.","score":[0.0095,0.1343]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isTerminator(r rune, terminator ...rune) bool {\r\n\tfor _, t := range terminator {\r\n\t\tif r == t {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn unicode.IsSpace(r) || !unicode.IsPrint(r)\r\n}","code-length":81,"reference":"\/\/ Is given rune listed as a terminator","result":"Check if the string is a terminator.","score":[0.14,0.1266]}
{"code":"\/*is used to<extra_id_0>\r\nfunc uniquify(in []string) (out []string) {\r\n\tfor _, i := range in {\r\n\t\tif i == \"\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tfor _, o := range out {\r\n\t\t\tif i == o {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t}\r\n\t\tout = append(out, i)\r\n\t}\r\n\treturn\r\n}","code-length":112,"reference":"\/\/ Ensures the given slice of strings are unique and that none are empty\n\/\/ strings","result":"Generate the unique string in the input array.","score":[0.0608,0.0987]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(config Config) gin.HandlerFunc {\r\n\tlocation := newLocation(config)\r\n\treturn func(c *gin.Context) {\r\n\t\tlocation.applyToContext(c)\r\n\t}\r\n}","code-length":62,"reference":"\/\/ New returns the location middleware with user-defined custom configuration.","result":"Create a new location.","score":[0,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Get(c *gin.Context) *url.URL {\r\n\tv, ok := c.Get(key)\r\n\tif !ok {\r\n\t\treturn nil\r\n\t}\r\n\tvv, ok := v.(*url.URL)\r\n\tif !ok {\r\n\t\treturn nil\r\n\t}\r\n\treturn vv\r\n}","code-length":92,"reference":"\/\/ Get returns the Location information for the incoming http.Request from the\n\/\/ context. If the location is not set a nil value is returned.","result":"Get the URL from the context.","score":[0.0145,0.1082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GenerateRSAKeyPair(bits int, src io.Reader) (PrivKey, PubKey, error) {\r\n\tif bits < 512 {\r\n\t\treturn nil, nil, ErrRsaKeyTooSmall\r\n\t}\r\n\tpriv, err := rsa.GenerateKey(src, bits)\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\tpk := &priv.PublicKey\r\n\treturn &RsaPrivateKey{sk: priv}, &RsaPublicKey{pk}, nil\r\n}","code-length":129,"reference":"\/\/ GenerateRSAKeyPair generates a new rsa private and public key","result":"Generate a new RSA keypair.","score":[0.125,0.4178]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pk *RsaPublicKey) Verify(data, sig []byte) (bool, error) {\r\n\thashed := sha256.Sum256(data)\r\n\terr := rsa.VerifyPKCS1v15(pk.k, crypto.SHA256, hashed[:], sig)\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\treturn true, nil\r\n}","code-length":102,"reference":"\/\/ Verify compares a signature against input data","result":"Verify the signature.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pk *RsaPublicKey) Encrypt(b []byte) ([]byte, error) {\r\n\treturn rsa.EncryptPKCS1v15(rand.Reader, pk.k, b)\r\n}","code-length":55,"reference":"\/\/ Encrypt returns encrypted bytes from the inpu data","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (sk *RsaPrivateKey) Sign(message []byte) ([]byte, error) {\r\n\thashed := sha256.Sum256(message)\r\n\treturn rsa.SignPKCS1v15(rand.Reader, sk.sk, crypto.SHA256, hashed[:])\r\n}","code-length":75,"reference":"\/\/ Sign returns a signature of the input data","result":"Sign the message.","score":[0.0657,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (sk *RsaPrivateKey) GetPublic() PubKey {\r\n\tif sk.pk == nil {\r\n\t\tsk.pk = &sk.sk.PublicKey\r\n\t}\r\n\treturn &RsaPublicKey{sk.pk}\r\n}","code-length":66,"reference":"\/\/ GetPublic returns a public key","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (sk *RsaPrivateKey) Decrypt(b []byte) ([]byte, error) {\r\n\treturn rsa.DecryptPKCS1v15(rand.Reader, sk.sk, b)\r\n}","code-length":55,"reference":"\/\/ Decrypt returns decrypted bytes of the input encrypted bytes","result":"Generate the code.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UnmarshalRsaPrivateKey(b []byte) (PrivKey, error) {\r\n\tsk, err := x509.ParsePKCS1PrivateKey(b)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif sk.N.BitLen() < 512 {\r\n\t\treturn nil, ErrRsaKeyTooSmall\r\n\t}\r\n\treturn &RsaPrivateKey{sk: sk}, nil\r\n}","code-length":111,"reference":"\/\/ UnmarshalRsaPrivateKey returns a private key from the input x509 bytes","result":"Unmarshal rsa private keys.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GenerateKeyPair(typ, bits int) (PrivKey, PubKey, error) {\r\n\treturn GenerateKeyPairWithReader(typ, bits, rand.Reader)\r\n}","code-length":47,"reference":"\/\/ GenerateKeyPair generates a private and public key","result":"Generate the public key.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GenerateKeyPairWithReader(typ, bits int, src io.Reader) (PrivKey, PubKey, error) {\r\n\tswitch typ {\r\n\tcase RSA:\r\n\t\treturn GenerateRSAKeyPair(bits, src)\r\n\tcase Ed25519:\r\n\t\treturn GenerateEd25519Key(src)\r\n\tcase Secp256k1:\r\n\t\treturn GenerateSecp256k1Key(src)\r\n\tcase ECDSA:\r\n\t\treturn GenerateECDSAKeyPair(src)\r\n\tdefault:\r\n\t\treturn nil, nil, ErrBadKeyType\r\n\t}\r\n}","code-length":145,"reference":"\/\/ GenerateKeyPairWithReader returns a keypair of the given type and bitsize","result":"Generate a new keypair.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GenerateEKeyPair(curveName string) ([]byte, GenSharedKey, error) {\r\n\tvar curve elliptic.Curve\r\n\tswitch curveName {\r\n\tcase \"P-256\":\r\n\t\tcurve = elliptic.P256()\r\n\tcase \"P-384\":\r\n\t\tcurve = elliptic.P384()\r\n\tcase \"P-521\":\r\n\t\tcurve = elliptic.P521()\r\n\t}\r\n\tpriv, x, y, err := elliptic.GenerateKey(curve, rand.Reader)\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\tpubKey := elliptic.Marshal(curve, x, y)\r\n\tdone := func(theirPub []byte) ([]byte, error) {\r\n\t\t\r\n\t\tx, y := elliptic.Unmarshal(curve, theirPub)\r\n\t\tif x == nil {\r\n\t\t\treturn nil, fmt.Errorf(\"malformed public key: %d %v\", len(theirPub), theirPub)\r\n\t\t}\r\n\t\tif !curve.IsOnCurve(x, y) {\r\n\t\t\treturn nil, errors.New(\"invalid public key\")\r\n\t\t}\r\n\t\t\r\n\t\tsecret, _ := curve.ScalarMult(x, y, priv)\r\n\t\treturn secret.Bytes(), nil\r\n\t}\r\n\treturn pubKey, done, nil\r\n}","code-length":353,"reference":"\/\/ GenerateEKeyPair returns an ephemeral public key and returns a function that will compute\n\/\/ the shared secret key.  Used in the identify module.\n\/\/\n\/\/ Focuses only on ECDH now, but can be made more general in the future.","result":"Generate a new ECPublicKey.","score":[0.0,0.0275]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UnmarshalPublicKey(data []byte) (PubKey, error) {\r\n\tpmes := new(pb.PublicKey)\r\n\terr := proto.Unmarshal(data, pmes)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tum, ok := PubKeyUnmarshallers[pmes.GetType()]\r\n\tif !ok {\r\n\t\treturn nil, ErrBadKeyType\r\n\t}\r\n\treturn um(pmes.GetData())\r\n}","code-length":123,"reference":"\/\/ UnmarshalPublicKey converts a protobuf serialized public key into its\n\/\/ representative object","result":"Unmarshal public keys.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MarshalPublicKey(k PubKey) ([]byte, error) {\r\n\tpbmes := new(pb.PublicKey)\r\n\tpbmes.Type = k.Type()\r\n\tdata, err := k.Raw()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tpbmes.Data = data\r\n\treturn proto.Marshal(pbmes)\r\n}","code-length":101,"reference":"\/\/ MarshalPublicKey converts a public key object into a protobuf serialized\n\/\/ public key","result":"Marshal public keys.","score":[0.0104,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UnmarshalPrivateKey(data []byte) (PrivKey, error) {\r\n\tpmes := new(pb.PrivateKey)\r\n\terr := proto.Unmarshal(data, pmes)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tum, ok := PrivKeyUnmarshallers[pmes.GetType()]\r\n\tif !ok {\r\n\t\treturn nil, ErrBadKeyType\r\n\t}\r\n\treturn um(pmes.GetData())\r\n}","code-length":125,"reference":"\/\/ UnmarshalPrivateKey converts a protobuf serialized private key into its\n\/\/ representative object","result":"Unmarshal private keys.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MarshalPrivateKey(k PrivKey) ([]byte, error) {\r\n\tpbmes := new(pb.PrivateKey)\r\n\tpbmes.Type = k.Type()\r\n\tdata, err := k.Raw()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tpbmes.Data = data\r\n\treturn proto.Marshal(pbmes)\r\n}","code-length":102,"reference":"\/\/ MarshalPrivateKey converts a key object into its protobuf serialized form.","result":"Marshal private keys.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc KeyEqual(k1, k2 Key) bool {\r\n\tif k1 == k2 {\r\n\t\treturn true\r\n\t}\r\n\tb1, err1 := k1.Bytes()\r\n\tb2, err2 := k2.Bytes()\r\n\treturn bytes.Equal(b1, b2) && err1 == err2\r\n}","code-length":93,"reference":"\/\/ KeyEqual checks whether two","result":"Compare keys.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GenerateECDSAKeyPair(src io.Reader) (PrivKey, PubKey, error) {\r\n\treturn GenerateECDSAKeyPairWithCurve(ECDSACurve, src)\r\n}","code-length":51,"reference":"\/\/ GenerateECDSAKeyPair generates a new ecdsa private and public key","result":"Generate the ECDSA keys.","score":[0,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GenerateECDSAKeyPairWithCurve(curve elliptic.Curve, src io.Reader) (PrivKey, PubKey, error) {\r\n\tpriv, err := ecdsa.GenerateKey(curve, src)\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\treturn &ECDSAPrivateKey{priv}, &ECDSAPublicKey{&priv.PublicKey}, nil\r\n}","code-length":102,"reference":"\/\/ GenerateECDSAKeyPairWithCurve generates a new ecdsa private and public key with a speicified curve","result":"Generate ECDSA keys.","score":[0,0.0775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ECDSAKeyPairFromKey(priv *ecdsa.PrivateKey) (PrivKey, PubKey, error) {\r\n\tif priv == nil {\r\n\t\treturn nil, nil, ErrNilPrivateKey\r\n\t}\r\n\treturn &ECDSAPrivateKey{priv}, &ECDSAPublicKey{&priv.PublicKey}, nil\r\n}","code-length":82,"reference":"\/\/ ECDSAKeyPairFromKey generates a new ecdsa private and public key from an input private key","result":"Generate ECDSA keys.","score":[0,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UnmarshalECDSAPrivateKey(data []byte) (PrivKey, error) {\r\n\tpriv, err := x509.ParseECPrivateKey(data)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &ECDSAPrivateKey{priv}, nil\r\n}","code-length":77,"reference":"\/\/ UnmarshalECDSAPrivateKey returns a private key from x509 bytes","result":"Parse ECDSA private keys.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UnmarshalECDSAPublicKey(data []byte) (PubKey, error) {\r\n\tpubIfc, err := x509.ParsePKIXPublicKey(data)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tpub, ok := pubIfc.(*ecdsa.PublicKey)\r\n\tif !ok {\r\n\t\treturn nil, ErrNotECDSAPubKey\r\n\t}\r\n\treturn &ECDSAPublicKey{pub}, nil\r\n}","code-length":120,"reference":"\/\/ UnmarshalECDSAPublicKey returns the public key from x509 bytes","result":"Parse ECDSA public keys.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ePriv *ECDSAPrivateKey) Equals(o Key) bool {\r\n\toPriv, ok := o.(*ECDSAPrivateKey)\r\n\tif !ok {\r\n\t\treturn false\r\n\t}\r\n\treturn ePriv.priv.D.Cmp(oPriv.priv.D) == 0\r\n}","code-length":82,"reference":"\/\/ Equals compares to private keys","result":"Compare ECDSA private keys.","score":[0.1938,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ePriv *ECDSAPrivateKey) Sign(data []byte) ([]byte, error) {\r\n\thash := sha256.Sum256(data)\r\n\tr, s, err := ecdsa.Sign(rand.Reader, ePriv.priv, hash[:])\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn asn1.Marshal(ECDSASig{\r\n\t\tR: r,\r\n\t\tS: s,\r\n\t})\r\n}","code-length":126,"reference":"\/\/ Sign returns the signature of the input data","result":"Sign ECDSA private keys.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ePub *ECDSAPublicKey) Equals(o Key) bool {\r\n\toPub, ok := o.(*ECDSAPublicKey)\r\n\tif !ok {\r\n\t\treturn false\r\n\t}\r\n\treturn ePub.pub.X != nil && ePub.pub.Y != nil && oPub.pub.X != nil && oPub.pub.Y != nil &&\r\n\t\t0 == ePub.pub.X.Cmp(oPub.pub.X) && 0 == ePub.pub.Y.Cmp(oPub.pub.Y)\r\n}","code-length":143,"reference":"\/\/ Equals compares to public keys","result":"Compare ECDSAPublicKey objects.","score":[0,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ePub *ECDSAPublicKey) Verify(data, sigBytes []byte) (bool, error) {\r\n\tsig := new(ECDSASig)\r\n\tif _, err := asn1.Unmarshal(sigBytes, sig); err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\tif sig == nil {\r\n\t\treturn false, ErrNilSig\r\n\t}\r\n\thash := sha256.Sum256(data)\r\n\treturn ecdsa.Verify(ePub.pub, hash[:], sig.R, sig.S), nil\r\n}","code-length":143,"reference":"\/\/ Verify compares data to a signature","result":"Verify ECDSA public keys.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GenerateSecp256k1Key(src io.Reader) (PrivKey, PubKey, error) {\r\n\tprivk, err := btcec.NewPrivateKey(btcec.S256())\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\tk := (*Secp256k1PrivateKey)(privk)\r\n\treturn k, k.GetPublic(), nil\r\n}","code-length":105,"reference":"\/\/ GenerateSecp256k1Key generates a new Secp256k1 private and public key pair","result":"Generate the key.","score":[0,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UnmarshalSecp256k1PrivateKey(data []byte) (PrivKey, error) {\r\n\tif len(data) != btcec.PrivKeyBytesLen {\r\n\t\treturn nil, fmt.Errorf(\"expected secp256k1 data size to be %d\", btcec.PrivKeyBytesLen)\r\n\t}\r\n\tprivk, _ := btcec.PrivKeyFromBytes(btcec.S256(), data)\r\n\treturn (*Secp256k1PrivateKey)(privk), nil\r\n}","code-length":122,"reference":"\/\/ UnmarshalSecp256k1PrivateKey returns a private key from bytes","result":"Unmarshal secp.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UnmarshalSecp256k1PublicKey(data []byte) (PubKey, error) {\r\n\tk, err := btcec.ParsePubKey(data, btcec.S256())\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn (*Secp256k1PublicKey)(k), nil\r\n}","code-length":86,"reference":"\/\/ UnmarshalSecp256k1PublicKey returns a public key from bytes","result":"Unmarshal the public key bytes.","score":[0.1865,0.2435]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (k *Secp256k1PrivateKey) Equals(o Key) bool {\r\n\tsk, ok := o.(*Secp256k1PrivateKey)\r\n\tif !ok {\r\n\t\treturn false\r\n\t}\r\n\treturn k.D.Cmp(sk.D) == 0\r\n}","code-length":80,"reference":"\/\/ Equals compares two private keys","result":"Compare keys.","score":[0,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (k *Secp256k1PrivateKey) Sign(data []byte) ([]byte, error) {\r\n\thash := sha256.Sum256(data)\r\n\tsig, err := (*btcec.PrivateKey)(k).Sign(hash[:])\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn sig.Serialize(), nil\r\n}","code-length":99,"reference":"\/\/ Sign returns a signature from input data","result":"Sign the data.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (k *Secp256k1PublicKey) Equals(o Key) bool {\r\n\tsk, ok := o.(*Secp256k1PublicKey)\r\n\tif !ok {\r\n\t\treturn false\r\n\t}\r\n\treturn (*btcec.PublicKey)(k).IsEqual((*btcec.PublicKey)(sk))\r\n}","code-length":88,"reference":"\/\/ Equals compares two public keys","result":"Compare keys.","score":[0,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (k *Secp256k1PublicKey) Verify(data []byte, sigStr []byte) (bool, error) {\r\n\tsig, err := btcec.ParseDERSignature(sigStr, btcec.S256())\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\thash := sha256.Sum256(data)\r\n\treturn sig.Verify(hash[:], (*btcec.PublicKey)(k)), nil\r\n}","code-length":116,"reference":"\/\/ Verify compares a signature against the input data","result":"Verify the signature of a public key.","score":[0.1716,0.2273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (k *Ed25519PrivateKey) Raw() ([]byte, error) {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tbuf := make([]byte, len(k.k))\r\n\tcopy(buf, k.k)\r\n\treturn buf, nil\r\n}","code-length":75,"reference":"\/\/ Raw private key bytes.","result":"Generate the raw key.","score":[0,0.102]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (k *Ed25519PrivateKey) Sign(msg []byte) ([]byte, error) {\r\n\treturn ed25519.Sign(k.k, msg), nil\r\n}","code-length":49,"reference":"\/\/ Sign returns a signature from an input message.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (k *Ed25519PublicKey) Equals(o Key) bool {\r\n\tedk, ok := o.(*Ed25519PublicKey)\r\n\tif !ok {\r\n\t\treturn false\r\n\t}\r\n\treturn bytes.Equal(k.k, edk.k)\r\n}","code-length":76,"reference":"\/\/ Equals compares two ed25519 public keys.","result":"Compare ed.","score":[0,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (k *Ed25519PublicKey) Verify(data []byte, sig []byte) (bool, error) {\r\n\treturn ed25519.Verify(k.k, data, sig), nil\r\n}","code-length":54,"reference":"\/\/ Verify checks a signature agains the input data.","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UnmarshalEd25519PublicKey(data []byte) (PubKey, error) {\r\n\tif len(data) != 32 {\r\n\t\treturn nil, errors.New(\"expect ed25519 public key data size to be 32\")\r\n\t}\r\n\treturn &Ed25519PublicKey{\r\n\t\tk: ed25519.PublicKey(data),\r\n\t}, nil\r\n}","code-length":92,"reference":"\/\/ UnmarshalEd25519PublicKey returns a public key from input bytes.","result":"Unmarshal ed.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UnmarshalEd25519PrivateKey(data []byte) (PrivKey, error) {\r\n\tswitch len(data) {\r\n\tcase ed25519.PrivateKeySize + ed25519.PublicKeySize:\r\n\t\t\r\n\t\tredundantPk := data[ed25519.PrivateKeySize:]\r\n\t\tpk := data[ed25519.PrivateKeySize-ed25519.PublicKeySize : ed25519.PrivateKeySize]\r\n\t\tif !bytes.Equal(pk, redundantPk) {\r\n\t\t\treturn nil, errors.New(\"expected redundant ed25519 public key to be redundant\")\r\n\t\t}\r\n\t\t\r\n\t\tnewKey := make([]byte, ed25519.PrivateKeySize)\r\n\t\tcopy(newKey, data[:ed25519.PrivateKeySize])\r\n\t\tdata = newKey\r\n\tcase ed25519.PrivateKeySize:\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\r\n\t\t\t\"expected ed25519 data size to be %d or %d, got %d\",\r\n\t\t\ted25519.PrivateKeySize,\r\n\t\t\ted25519.PrivateKeySize+ed25519.PublicKeySize,\r\n\t\t\tlen(data),\r\n\t\t)\r\n\t}\r\n\treturn &Ed25519PrivateKey{\r\n\t\tk: ed25519.PrivateKey(data),\r\n\t}, nil\r\n}","code-length":304,"reference":"\/\/ UnmarshalEd25519PrivateKey returns a private key from input bytes.","result":"Unmarshal ed.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EditScriptForStrings(source []rune, target []rune, op Options) EditScript {\r\n\treturn backtrace(len(source), len(target),\r\n\t\tMatrixForStrings(source, target, op), op)\r\n}","code-length":64,"reference":"\/\/ EditScriptForStrings returns an optimal edit script to turn source into\n\/\/ target.","result":"Generate the string matrix.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EditScriptForMatrix(matrix [][]int, op Options) EditScript {\r\n\treturn backtrace(len(matrix)-1, len(matrix[0])-1, matrix, op)\r\n}","code-length":54,"reference":"\/\/ EditScriptForMatrix returns an optimal edit script based on the given\n\/\/ Levenshtein matrix.","result":"Generate the code.","score":[0.0104,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WriteMatrix(source []rune, target []rune, matrix [][]int, writer io.Writer) {\r\n\tfmt.Fprintf(writer, \"    \")\r\n\tfor _, targetRune := range target {\r\n\t\tfmt.Fprintf(writer, \"  %c\", targetRune)\r\n\t}\r\n\tfmt.Fprintf(writer, \"\\n\")\r\n\tfmt.Fprintf(writer, \"  %2d\", matrix[0][0])\r\n\tfor j, _ := range target {\r\n\t\tfmt.Fprintf(writer, \" %2d\", matrix[0][j+1])\r\n\t}\r\n\tfmt.Fprintf(writer, \"\\n\")\r\n\tfor i, sourceRune := range source {\r\n\t\tfmt.Fprintf(writer, \"%c %2d\", sourceRune, matrix[i+1][0])\r\n\t\tfor j, _ := range target {\r\n\t\t\tfmt.Fprintf(writer, \" %2d\", matrix[i+1][j+1])\r\n\t\t}\r\n\t\tfmt.Fprintf(writer, \"\\n\")\r\n\t}\r\n}","code-length":273,"reference":"\/\/ WriteMatrix writes a visual representation of the given matrix for the given\n\/\/ strings to the given writer.","result":"Write the matrix to a file.","score":[0.0313,0.1412]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(path string) (Lockfile, error) {\r\n\tif !filepath.IsAbs(path) {\r\n\t\treturn Lockfile(\"\"), ErrNeedAbsPath\r\n\t}\r\n\treturn Lockfile(path), nil\r\n}","code-length":66,"reference":"\/\/ New describes a new filename located at the given absolute path.","result":"Create a new lockfile.","score":[0.0611,0.1674]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l Lockfile) GetOwner() (*os.Process, error) {\r\n\tname := string(l)\r\n\t\r\n\tcontent, err := ioutil.ReadFile(name)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tpid, err := scanPidLine(content)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\trunning, err := isRunning(pid)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif running {\r\n\t\tproc, err := os.FindProcess(pid)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn proc, nil\r\n\t}\r\n\treturn nil, ErrDeadOwner\r\n}","code-length":207,"reference":"\/\/ GetOwner returns who owns the lockfile.","result":"Get the owner of the lockfile.","score":[0.2311,0.2717]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l Lockfile) TryLock() error {\r\n\tname := string(l)\r\n\t\r\n\t\r\n\t\r\n\tif !filepath.IsAbs(name) {\r\n\t\tpanic(ErrNeedAbsPath)\r\n\t}\r\n\ttmplock, err := ioutil.TempFile(filepath.Dir(name), filepath.Base(name)+\".\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tcleanup := func() {\r\n\t\t_ = tmplock.Close()\r\n\t\t_ = os.Remove(tmplock.Name())\r\n\t}\r\n\tdefer cleanup()\r\n\tif err := writePidLine(tmplock, os.Getpid()); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif err := os.Link(tmplock.Name(), name); err != nil {\r\n\t\tif !os.IsExist(err) {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tfiTmp, err := os.Lstat(tmplock.Name())\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfiLock, err := os.Lstat(name)\r\n\tif err != nil {\r\n\t\t\r\n\t\tif os.IsNotExist(err) {\r\n\t\t\treturn ErrNotExist\r\n\t\t}\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif os.SameFile(fiTmp, fiLock) {\r\n\t\treturn nil\r\n\t}\r\n\tproc, err := l.GetOwner()\r\n\tswitch err {\r\n\tdefault:\r\n\t\t\r\n\t\treturn err\r\n\tcase nil:\r\n\t\tif proc.Pid != os.Getpid() {\r\n\t\t\treturn ErrBusy\r\n\t\t}\r\n\tcase ErrDeadOwner, ErrInvalidPid:\r\n\t\t\r\n\t}\r\n\t\r\n\terr = os.Remove(name)\r\n\tif err != nil {\r\n\t\t\r\n\t\tif !os.IsNotExist(err) {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\t\r\n\treturn l.TryLock()\r\n}","code-length":537,"reference":"\/\/ TryLock tries to own the lock.\n\/\/ It Returns nil, if successful and and error describing the reason, it didn't work out.\n\/\/ Please note, that existing lockfiles containing pids of dead processes\n\/\/ and lockfiles containing no pid at all are simply deleted.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l Lockfile) Unlock() error {\r\n\tproc, err := l.GetOwner()\r\n\tswitch err {\r\n\tcase ErrInvalidPid, ErrDeadOwner:\r\n\t\treturn ErrRogueDeletion\r\n\tcase nil:\r\n\t\tif proc.Pid == os.Getpid() {\r\n\t\t\t\r\n\t\t\treturn os.Remove(string(l))\r\n\t\t}\r\n\t\t\r\n\t\treturn ErrRogueDeletion\r\n\tdefault:\r\n\t\t\r\n\t\t\r\n\t\tif os.IsNotExist(err) {\r\n\t\t\treturn ErrRogueDeletion\r\n\t\t}\r\n\t\t\r\n\t\treturn err\r\n\t}\r\n}","code-length":168,"reference":"\/\/ Unlock a lock again, if we owned it. Returns any error that happend during release of lock.","result":"Unlock a lockfile.","score":[0.0039,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewBase(configs ...baseConfigFunc) *Base {\r\n\tb := &Base{\r\n\t\tclock: glock.NewRealClock(),\r\n\t\tconfig:    NewConfig(),\r\n\t\tlogLevel:  LevelDebug,\r\n\t\tsequence:  0,\r\n\t\tBaseAttrs: NewAttrs(),\r\n\t\tloggers:      make([]Logger, 0),\r\n\t\thookPreQueue: make([]HookPreQueue, 0),\r\n\t}\r\n\tfor _, f := range configs {\r\n\t\tf(b)\r\n\t}\r\n\treturn b\r\n}","code-length":150,"reference":"\/\/ NewBase creates a new instance of Base with default values set.","result":"Create a new base instance.","score":[0.0838,0.3319]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Base) SetFallbackLogger(logger Logger) error {\r\n\tif logger == nil {\r\n\t\tif b.fallbackLogger != nil && b.fallbackLogger.IsInitialized() {\r\n\t\t\tb.fallbackLogger.ShutdownLogger()\r\n\t\t}\r\n\t\tb.fallbackLogger = nil\r\n\t\treturn nil\r\n\t}\r\n\tif !logger.IsInitialized() {\r\n\t\terr := logger.InitLogger()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\t\r\n\tif b.fallbackLogger != nil && b.fallbackLogger.IsInitialized() {\r\n\t\tb.fallbackLogger.ShutdownLogger()\r\n\t}\r\n\tb.fallbackLogger = logger\r\n\treturn nil\r\n}","code-length":192,"reference":"\/\/ SetFallbackLogger sets a Logger to be used if there aren't any loggers added or any of\n\/\/ the added loggers are in a degraded or unhealthy state.  A Logger passed to SetFallbackLogger\n\/\/ will be initialized if it hasn't been already.  In addition, if the Logger fails to initialize\n\/\/ completely the fallback logger will fail to be set.","result":"Set the fallback logger on the base .","score":[0.0005,0.0679]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Base) AddLogger(logger Logger) error {\r\n\tif b.IsInitialized() && !logger.IsInitialized() {\r\n\t\terr := logger.InitLogger()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t} else if !b.IsInitialized() && logger.IsInitialized() {\r\n\t\terr := logger.ShutdownLogger()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tb.loggers = append(b.loggers, logger)\r\n\tif hook, ok := logger.(HookPreQueue); ok {\r\n\t\tb.hookPreQueue = append(b.hookPreQueue, hook)\r\n\t}\r\n\tlogger.SetBase(b)\r\n\treturn nil\r\n}","code-length":201,"reference":"\/\/ AddLogger adds a new logger instance to the Base","result":"Add a logger to the base .","score":[0.1769,0.5799]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Base) LogWithTime(level LogLevel, ts time.Time, m *Attrs, msg string, a ...interface{}) error {\r\n\tif !b.shouldLog(level) {\r\n\t\treturn nil\r\n\t}\r\n\tif !b.isInitialized {\r\n\t\treturn ErrNotInitialized\r\n\t}\r\n\tif len(b.config.FilenameAttr) > 0 || len(b.config.LineNumberAttr) > 0 {\r\n\t\tfile, line := getCallerInfo()\r\n\t\tif m == nil {\r\n\t\t\tm = NewAttrs()\r\n\t\t}\r\n\t\tif len(b.config.FilenameAttr) > 0 {\r\n\t\t\tm.SetAttr(b.config.FilenameAttr, file)\r\n\t\t}\r\n\t\tif len(b.config.LineNumberAttr) > 0 {\r\n\t\t\tm.SetAttr(b.config.LineNumberAttr, line)\r\n\t\t}\r\n\t}\r\n\tif len(b.config.SequenceAttr) > 0 {\r\n\t\tif m == nil {\r\n\t\t\tm = NewAttrs()\r\n\t\t}\r\n\t\tseq := atomic.AddUint64(&b.sequence, 1)\r\n\t\tm.SetAttr(b.config.SequenceAttr, seq)\r\n\t}\r\n\tnm := newMessage(ts, b, level, m, msg, a...)\r\n\tfor _, hook := range b.hookPreQueue {\r\n\t\terr := hook.PreQueue(nm)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn b.queue.queueMessage(nm)\r\n}","code-length":400,"reference":"\/\/ LogWithTime will log a message at the provided level to all added loggers with the timestamp set to the\n\/\/ value of ts.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Base) Log(level LogLevel, m *Attrs, msg string, a ...interface{}) error {\r\n\treturn b.LogWithTime(level, b.clock.Now(), m, msg, a...)\r\n}","code-length":61,"reference":"\/\/ Log will log a message at the provided level to all added loggers with the timestamp set to the time\n\/\/ Log was called.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Base) Warnm(m *Attrs, msg string, a ...interface{}) error {\r\n\treturn b.Warningm(m, msg, a...)\r\n}","code-length":50,"reference":"\/\/ Warnm is a short-hand version of Warningm","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTemplateWithFuncMap(tpl string, funcMap template.FuncMap) (*Template, error) {\r\n\tvar levels = []LogLevel{LevelNone, LevelDebug, LevelInfo, LevelWarning, LevelError, LevelFatal}\r\n\ttpls := make(map[LogLevel]*template.Template, 0)\r\n\tfor _, level := range levels {\r\n\t\t\r\n\t\t_, forceReset := funcMap[\"color\"]\r\n\t\tfMap := getFuncMap(level, forceReset)\r\n\t\tfor name, f := range funcMap {\r\n\t\t\tfMap[name] = f\r\n\t\t}\r\n\t\tparsedTpl, err := template.New(getLevelName(level)).\r\n\t\t\tFuncs(fMap).\r\n\t\t\tParse(tpl)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\ttpls[level] = parsedTpl\r\n\t}\r\n\tnewTpl := &Template{\r\n\t\ttpls: tpls,\r\n\t}\r\n\treturn newTpl, nil\r\n}","code-length":260,"reference":"\/\/ NewTemplateWithFuncMap creates a new Template from the given string and a template FuncMap. The FuncMap available\n\/\/ to the template during evaluation will also include the default values, if not overridden. An error is returned\n\/\/ if the template fails to compile.","result":"Create a template with a funcMap.","score":[0.0006,0.0947]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Template) Execute(msg *TemplateMsg, colorize bool) (string, error) {\r\n\ttplLevel := msg.Level\r\n\tif !colorize {\r\n\t\ttplLevel = LevelNone\r\n\t}\r\n\tvar buf bytes.Buffer\r\n\texecTpl := t.tpls[tplLevel]\r\n\tif execTpl == nil {\r\n\t\treturn \"\", ErrUnknownLevel\r\n\t}\r\n\terr := execTpl.Execute(&buf, msg)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn buf.String(), nil\r\n}","code-length":151,"reference":"\/\/ Execute takes a TemplateMsg and applies it to the Go template.  If colorize is true the template\n\/\/ will insert ANSI color codes within the resulting string.","result":"Generate code for the template .","score":[0.007,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTemplateMsg(timestamp time.Time, level LogLevel, m map[string]interface{}, msg string) *TemplateMsg {\r\n\tmsgAttrs := m\r\n\tif msgAttrs == nil {\r\n\t\tmsgAttrs = make(map[string]interface{})\r\n\t}\r\n\ttplMsg := &TemplateMsg{\r\n\t\tTimestamp: timestamp,\r\n\t\tMessage:   msg,\r\n\t\tLevel:     level,\r\n\t\tLevelName: level.String(),\r\n\t\tAttrs:     msgAttrs,\r\n\t}\r\n\treturn tplMsg\r\n}","code-length":143,"reference":"\/\/ NewTemplateMsg will create a new TemplateMsg with values from the given parameters","result":"Create a template message.","score":[0.0337,0.155]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLogAdapterFor(base WrappableLogger, attrs *Attrs) *LogAdapter {\r\n\tif attrs == nil {\r\n\t\tattrs = NewAttrs()\r\n\t}\r\n\treturn &LogAdapter{\r\n\t\tbase:  base,\r\n\t\tattrs: attrs,\r\n\t}\r\n}","code-length":81,"reference":"\/\/ NewLogAdapterFor creates a LogAdapter that wraps the given loger with the\n\/\/ given attributes.","result":"Create a new log adapter.","score":[0.0325,0.1339]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (la *LogAdapter) SetAttr(key string, value interface{}) {\r\n\tla.attrs.SetAttr(key, value)\r\n}","code-length":44,"reference":"\/\/ SetAttr sets the attribute key to value for this LogAdapter only","result":"Set the log attrs.","score":[0.0432,0.1674]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (la *LogAdapter) LogWithTime(level LogLevel, ts time.Time, attrs *Attrs, msg string, a ...interface{}) error {\r\n\tif la.logLevel != nil && level > *la.logLevel {\r\n\t\treturn nil\r\n\t}\r\n\tmergedAttrs := la.attrs.clone()\r\n\tmergedAttrs.MergeAttrs(attrs)\r\n\treturn la.base.LogWithTime(level, ts, mergedAttrs, msg, a...)\r\n}","code-length":120,"reference":"\/\/ LogWithTime will log a message at the provided level to all loggers added\n\/\/ to the Base associated with this LogAdapter. It is similar to Log except\n\/\/ the timestamp will be set to the value of ts.","result":"Log the message.","score":[0.0,0.0282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (la *LogAdapter) Log(level LogLevel, attrs *Attrs, msg string, a ...interface{}) error {\r\n\tif la.logLevel != nil && level > *la.logLevel {\r\n\t\treturn nil\r\n\t}\r\n\tmergedAttrs := la.attrs.clone()\r\n\tmergedAttrs.MergeAttrs(attrs)\r\n\treturn la.base.Log(level, mergedAttrs, msg, a...)\r\n}","code-length":109,"reference":"\/\/ Log will log a message at the provided level to all loggers added\n\/\/ to the Base associated with this LogAdapter","result":"Log the message.","score":[0.0009,0.0498]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (la *LogAdapter) Dbgm(m *Attrs, msg string, a ...interface{}) error {\r\n\treturn la.Debugm(m, msg, a...)\r\n}","code-length":51,"reference":"\/\/ Dbgm is a short-hand version of Debugm","result":"Generate the log file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewAttrsFromMap(attrs map[string]interface{}) *Attrs {\r\n\tnewAttrs := NewAttrs()\r\n\tfor attrKey, attrVal := range attrs {\r\n\t\tnewAttrs.SetAttr(attrKey, attrVal)\r\n\t}\r\n\treturn newAttrs\r\n}","code-length":76,"reference":"\/\/ NewAttrsFromMap will create a new Attrs struct with the given attributes pre-populated","result":"Create a newAttrsFromMap function.","score":[0.0337,0.2112]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewAttrsFromAttrs(attrs ...*Attrs) *Attrs {\r\n\tnewAttrs := NewAttrs()\r\n\tfor _, attr := range attrs {\r\n\t\tnewAttrs.MergeAttrs(attr)\r\n\t}\r\n\treturn newAttrs\r\n}","code-length":68,"reference":"\/\/ NewAttrsFromAttrs is a convenience function that will accept zero or more existing Attrs, create\n\/\/ a new Attrs and then merge all the supplied Attrs values into the new Attrs instance.","result":"Create a newAttrs.","score":[0.0,0.0344]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Attrs) MergeAttrs(attrs *Attrs) {\r\n\tif attrs == nil {\r\n\t\treturn\r\n\t}\r\n\ta.attrsLock.Lock()\r\n\tdefer a.attrsLock.Unlock()\r\n\tfor hash, val := range attrs.attrs {\r\n\t\ta.attrs[hash] = val\r\n\t}\r\n}","code-length":93,"reference":"\/\/ MergeAttrs accepts another existing Attrs and merges the attributes into its own.","result":"Merge attributes.","score":[0,0.042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Attrs) SetAttr(key string, value interface{}) *Attrs {\r\n\ta.attrsLock.Lock()\r\n\tdefer a.attrsLock.Unlock()\r\n\tvalVal := reflect.ValueOf(value)\r\n\tswitch valVal.Kind() {\r\n\tcase reflect.Func:\r\n\t\tvalue = valVal.Type().String()\r\n\t}\r\n\thash := getAttrHash(key)\r\n\ta.attrs[hash] = value\r\n\treturn a\r\n}","code-length":126,"reference":"\/\/ SetAttr will set key to the provided value.  If the attribute already exists the value will\n\/\/ be replaced with the new value.","result":"Set the value of an attribute.","score":[0.0136,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Attrs) GetAttr(key string) interface{} {\r\n\ta.attrsLock.RLock()\r\n\tdefer a.attrsLock.RUnlock()\r\n\treturn a.attrs[getAttrHash(key)]\r\n}","code-length":64,"reference":"\/\/ GetAttr gets the value of the attribute with the provided name.  If the attribute does not\n\/\/ exist, nil will be returned","result":"Get the value of an attribute.","score":[0.0234,0.1482]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Attrs) RemoveAttr(key string) {\r\n\ta.attrsLock.Lock()\r\n\tdefer a.attrsLock.Unlock()\r\n\tdelete(a.attrs, getAttrHash(key))\r\n}","code-length":60,"reference":"\/\/ RemoveAttr will remove the attribute with the provided name.","result":"Remove attributes from the Attrs object.","score":[0.0991,0.1562]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Attrs) Attrs() map[string]interface{} {\r\n\ta.attrsLock.RLock()\r\n\tdefer a.attrsLock.RUnlock()\r\n\tattrs := make(map[string]interface{})\r\n\tfor hash, val := range a.attrs {\r\n\t\tkey, _ := getHashAttr(hash)\r\n\t\tattrs[key] = val\r\n\t}\r\n\treturn attrs\r\n}","code-length":110,"reference":"\/\/ Attrs will return a map of the attributes added to the struct.","result":"Return the map of attributes.","score":[0.0759,0.2587]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Debugm(m *Attrs, msg string, a ...interface{}) error {\r\n\treturn curDefault.Debugm(m, msg, a...)\r\n}","code-length":46,"reference":"\/\/ Debugm executes the same function on the default Base instance","result":"Debug debug messages.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Infom(m *Attrs, msg string, a ...interface{}) error {\r\n\treturn curDefault.Infom(m, msg, a...)\r\n}","code-length":46,"reference":"\/\/ Infom executes the same function on the default Base instance","result":"Generate the default infom function.","score":[0.1023,0.2457]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Warningm(m *Attrs, msg string, a ...interface{}) error {\r\n\treturn curDefault.Warningm(m, msg, a...)\r\n}","code-length":46,"reference":"\/\/ Warningm executes the same function on the default Base instance","result":"Generate the default error message.","score":[0.1023,0.1803]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Errm(m *Attrs, msg string, a ...interface{}) error {\r\n\treturn Errorm(m, msg, a...)\r\n}","code-length":43,"reference":"\/\/ Errm executes the same function on the default Base instance","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Errorm(m *Attrs, msg string, a ...interface{}) error {\r\n\treturn curDefault.Errorm(m, msg, a...)\r\n}","code-length":46,"reference":"\/\/ Errorm executes the same function on the default Base instance","result":"Avoid errors in the generated code.","score":[0.0839,0.0476]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Fatalm(m *Attrs, msg string, a ...interface{}) error {\r\n\treturn curDefault.Fatalm(m, msg, a...)\r\n}","code-length":46,"reference":"\/\/ Fatalm executes the same function on the default Base instance","result":"Print error messages.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Dief(exitCode int, msg string, a ...interface{}) {\r\n\tcurDefault.Dief(exitCode, msg, a...)\r\n}","code-length":45,"reference":"\/\/ Dief executes the same function on the default Base instance","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Diem(exitCode int, m *Attrs, msg string, a ...interface{}) {\r\n\tcurDefault.Diem(exitCode, m, msg, a...)\r\n}","code-length":51,"reference":"\/\/ Diem executes the same function on the default Base instance","result":"Set default exit code.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ToLogLevel(level string) (LogLevel, error) {\r\n\tlowLevel := strings.ToLower(level)\r\n\tswitch lowLevel {\r\n\tcase \"dbg\":\r\n\t\tfallthrough\r\n\tcase \"debug\":\r\n\t\treturn LevelDebug, nil\r\n\tcase \"info\":\r\n\t\treturn LevelInfo, nil\r\n\tcase \"warn\":\r\n\t\tfallthrough\r\n\tcase \"warning\":\r\n\t\treturn LevelWarning, nil\r\n\tcase \"err\":\r\n\t\tfallthrough\r\n\tcase \"error\":\r\n\t\treturn LevelError, nil\r\n\tcase \"fatal\":\r\n\t\treturn LevelFatal, nil\r\n\tcase \"none\":\r\n\t\treturn LevelNone, nil\r\n\t}\r\n\treturn 0, ErrUnknownLevel\r\n}","code-length":194,"reference":"\/\/ ToLogLevel will take a string and return the appropriate log level for\n\/\/ the string if known.  If the string is not recognized it will return\n\/\/ an ErrUnknownLevel error.","result":"Convert a string to a log level.","score":[0.0082,0.0524]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CallErr(f func() error) error {\r\n\tcheckRun()\r\n\terrChan := make(chan error)\r\n\tcallQueue <- func() {\r\n\t\terrChan <- f()\r\n\t}\r\n\treturn <-errChan\r\n}","code-length":69,"reference":"\/\/ CallErr queues function f on the main thread and returns an error returned by f.","result":"Call the function with error handling.","score":[0.048,0.1]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts ...Option) (*StackdriverHook, error) {\r\n\tvar err error\r\n\tsh := &StackdriverHook{\r\n\t\tlevels: logrus.AllLevels,\r\n\t}\r\n\t\r\n\tfor _, o := range opts {\r\n\t\terr = o(sh)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\t\r\n\tif sh.service == nil && sh.agentClient == nil {\r\n\t\treturn nil, errors.New(\"no stackdriver service was provided\")\r\n\t}\r\n\tif sh.resource == nil && sh.agentClient == nil {\r\n\t\treturn nil, errors.New(\"the monitored resource was not provided\")\r\n\t}\r\n\tif sh.projectID == \"\" && sh.agentClient == nil {\r\n\t\treturn nil, errors.New(\"the project id was not provided\")\r\n\t}\r\n\t\r\n\tif sh.logName == \"\" {\r\n\t\terr = LogName(DefaultName)(sh)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\tif sh.errorReportingLogName == \"\" {\r\n\t\tsh.errorReportingLogName = sh.logName + \"_errors\"\r\n\t}\r\n\treturn sh, nil\r\n}","code-length":333,"reference":"\/\/ New creates a StackdriverHook using the provided options that is suitible\n\/\/ for using with logrus for logging to Google Stackdriver.","result":"Create a new hook.","score":[0.0035,0.1265]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (sh *StackdriverHook) Fire(entry *logrus.Entry) error {\r\n\tsh.waitGroup.Add(1)\r\n\tgo func(entry *logrus.Entry) {\r\n\t\tdefer sh.waitGroup.Done()\r\n\t\tvar httpReq *logging.HttpRequest\r\n\t\t\r\n\t\tlabels := make(map[string]string, len(entry.Data))\r\n\t\tfor k, v := range entry.Data {\r\n\t\t\tswitch x := v.(type) {\r\n\t\t\tcase string:\r\n\t\t\t\tlabels[k] = x\r\n\t\t\tcase *http.Request:\r\n\t\t\t\thttpReq = &logging.HttpRequest{\r\n\t\t\t\t\tReferer:       x.Referer(),\r\n\t\t\t\t\tRemoteIp:      x.RemoteAddr,\r\n\t\t\t\t\tRequestMethod: x.Method,\r\n\t\t\t\t\tRequestUrl:    x.URL.String(),\r\n\t\t\t\t\tUserAgent:     x.UserAgent(),\r\n\t\t\t\t}\r\n\t\t\tcase *logging.HttpRequest:\r\n\t\t\t\thttpReq = x\r\n\t\t\tdefault:\r\n\t\t\t\tlabels[k] = fmt.Sprintf(\"%v\", v)\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tif sh.agentClient != nil {\r\n\t\t\tsh.sendLogMessageViaAgent(entry, labels, httpReq)\r\n\t\t} else {\r\n\t\t\tsh.sendLogMessageViaAPI(entry, labels, httpReq)\r\n\t\t}\r\n\t}(sh.copyEntry(entry))\r\n\treturn nil\r\n}","code-length":370,"reference":"\/\/ Fire writes the message to the Stackdriver entry service.","result":"Send logs to Stackdriver.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Levels(levels ...logrus.Level) Option {\r\n\treturn func(sh *StackdriverHook) error {\r\n\t\tsh.levels = levels\r\n\t\treturn nil\r\n\t}\r\n}","code-length":58,"reference":"\/\/ Levels is an option that sets the logrus levels that the StackdriverHook\n\/\/ will create log entries for.","result":"Set the log levels.","score":[0.0089,0.0857]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ProjectID(projectID string) Option {\r\n\treturn func(sh *StackdriverHook) error {\r\n\t\tsh.projectID = projectID\r\n\t\treturn nil\r\n\t}\r\n}","code-length":57,"reference":"\/\/ ProjectID is an option that sets the project ID which is needed for the log\n\/\/ name.","result":"Identify the project ID.","score":[0.0136,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EntriesService(service *logging.EntriesService) Option {\r\n\treturn func(sh *StackdriverHook) error {\r\n\t\tsh.service = service\r\n\t\treturn nil\r\n\t}\r\n}","code-length":58,"reference":"\/\/ EntriesService is an option that sets the Google API entry service to use\n\/\/ with Stackdriver.","result":"Set up the service for logging.","score":[0.0367,0.0943]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoggingService(service *logging.Service) Option {\r\n\treturn func(sh *StackdriverHook) error {\r\n\t\tsh.service = service.Entries\r\n\t\treturn nil\r\n\t}\r\n}","code-length":59,"reference":"\/\/ LoggingService is an option that sets the Google API logging service to use.","result":"Set the service to the logging service.","score":[0.0999,0.2797]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ErrorService(errorService *errorReporting.Service) Option {\r\n\treturn func(sh *StackdriverHook) error {\r\n\t\tsh.errorService = errorService\r\n\t\treturn nil\r\n\t}\r\n}","code-length":61,"reference":"\/\/ ErrorService is an option that sets the Google API error reporting service to use.","result":"Set the error reporting service.","score":[0.0509,0.2679]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HTTPClient(client *http.Client) Option {\r\n\treturn func(sh *StackdriverHook) error {\r\n\t\t\r\n\t\tl, err := logging.New(client)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\te, err := errorReporting.New(client)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t} else {\r\n\t\t\tErrorService(e)\r\n\t\t}\r\n\t\treturn LoggingService(l)(sh)\r\n\t}\r\n}","code-length":144,"reference":"\/\/ HTTPClient is an option that sets the http.Client to be used when creating\n\/\/ the Stackdriver service.","result":"Set the http client.","score":[0.0096,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MonitoredResource(resource *logging.MonitoredResource) Option {\r\n\treturn func(sh *StackdriverHook) error {\r\n\t\tsh.resource = resource\r\n\t\treturn nil\r\n\t}\r\n}","code-length":60,"reference":"\/\/ MonitoredResource is an option that sets the monitored resource to send with\n\/\/ each log entry.","result":"Set the resource in the log.","score":[0.0367,0.0943]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ErrorReportingLogName(name string) Option {\r\n\treturn func(sh *StackdriverHook) error {\r\n\t\tsh.errorReportingLogName = name\r\n\t\treturn nil\r\n\t}\r\n}","code-length":59,"reference":"\/\/ ErrorReportingLogName is an option that sets the log name to send\n\/\/ with each error message for error reporting.\n\/\/ Only used when ErrorReportingService has been set.","result":"Specify the error reporting log name.","score":[0.0065,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Labels(labels map[string]string) Option {\r\n\treturn func(sh *StackdriverHook) error {\r\n\t\tsh.labels = labels\r\n\t\treturn nil\r\n\t}\r\n}","code-length":57,"reference":"\/\/ Labels is an option that sets the labels to send with each log entry.","result":"Generate the generated code.","score":[0.0204,0.036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PartialSuccess(enabled bool) Option {\r\n\treturn func(sh *StackdriverHook) error {\r\n\t\tsh.partialSuccess = enabled\r\n\t\treturn nil\r\n\t}\r\n}","code-length":55,"reference":"\/\/ PartialSuccess is an option that toggles whether or not to write partial log\n\/\/ entries.","result":"Enable partial success .","score":[0.0159,0.0338]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GoogleComputeCredentials(serviceAccount string) Option {\r\n\treturn func(sh *StackdriverHook) error {\r\n\t\tvar err error\r\n\t\t\r\n\t\tscopes, err := metadata.Scopes(serviceAccount)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\tfor _, s := range requiredScopes {\r\n\t\t\tif !sliceContains(scopes, s) {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\treturn fmt.Errorf(\"missing required scope %s in compute metadata\", s)\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn HTTPClient(&http.Client{\r\n\t\t\tTransport: &oauth2.Transport{\r\n\t\t\t\tSource: google.ComputeTokenSource(serviceAccount),\r\n\t\t\t},\r\n\t\t})(sh)\r\n\t}\r\n}","code-length":213,"reference":"\/\/ GoogleComputeCredentials is an option that loads the Google Service Account\n\/\/ credentials from the GCE metadata associated with the GCE compute instance.\n\/\/ If serviceAccount is empty, then the default service account credentials\n\/\/ associated with the GCE instance will be used.","result":"Authenticate to compute service accounts.","score":[0.0001,0.0255]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c Codec) NewEncoder(w io.Writer) *Encoder {\r\n\treturn NewEncoder(c.NewEmitter(w))\r\n}","code-length":40,"reference":"\/\/ NewEncoder returns a new encoder that outputs to w.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c Codec) NewDecoder(r io.Reader) *Decoder {\r\n\treturn NewDecoder(c.NewParser(r))\r\n}","code-length":40,"reference":"\/\/ NewDecoder returns a new decoder that takes input from r.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c Codec) NewStreamEncoder(w io.Writer) *StreamEncoder {\r\n\treturn NewStreamEncoder(c.NewEmitter(w))\r\n}","code-length":45,"reference":"\/\/ NewStreamEncoder returns a new stream encoder that outputs to w.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c Codec) NewStreamDecoder(r io.Reader) *StreamDecoder {\r\n\treturn NewStreamDecoder(c.NewParser(r))\r\n}","code-length":45,"reference":"\/\/ NewStreamDecoder returns a new stream decoder that takes input from r.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (reg *Registry) Register(mimetype string, codec Codec) {\r\n\tdefer reg.mutex.Unlock()\r\n\treg.mutex.Lock()\r\n\tif reg.codecs == nil {\r\n\t\treg.codecs = make(map[string]Codec)\r\n\t}\r\n\treg.codecs[mimetype] = codec\r\n}","code-length":90,"reference":"\/\/ Register adds a codec for a mimetype to r.","result":"Register a codec.","score":[0.0471,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (reg *Registry) Unregister(mimetype string) {\r\n\tdefer reg.mutex.Unlock()\r\n\treg.mutex.Lock()\r\n\tdelete(reg.codecs, mimetype)\r\n}","code-length":56,"reference":"\/\/ Unregister removes the codec for a mimetype from r.","result":"Unregister the registered mimetype.","score":[0.0848,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (reg *Registry) Lookup(mimetype string) (codec Codec, ok bool) {\r\n\treg.mutex.RLock()\r\n\tcodec, ok = reg.codecs[mimetype]\r\n\treg.mutex.RUnlock()\r\n\treturn\r\n}","code-length":69,"reference":"\/\/ Lookup returns the codec associated with mimetype, ok is set to true or false\n\/\/ based on whether a codec was found.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (reg *Registry) Codecs() (codecs map[string]Codec) {\r\n\tcodecs = make(map[string]Codec)\r\n\treg.mutex.RLock()\r\n\tfor mimetype, codec := range reg.codecs {\r\n\t\tcodecs[mimetype] = codec\r\n\t}\r\n\treg.mutex.RUnlock()\r\n\treturn\r\n}","code-length":98,"reference":"\/\/ Codecs returns a map of all codecs registered in reg.","result":"Get the codecs from the registry.","score":[0.0839,0.0476]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Error) Type() string {\r\n\ts := e.Error()\r\n\tif i := strings.IndexByte(s, ' '); i < 0 {\r\n\t\ts = \"\"\r\n\t} else {\r\n\t\ts = s[:i]\r\n\t\tfor _, c := range s {\r\n\t\t\tif !unicode.IsUpper(c) {\r\n\t\t\t\ts = \"\"\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn s\r\n}","code-length":130,"reference":"\/\/ Type returns the RESP error type, which is represented by the leading\n\/\/ uppercase word in the error string.","result":"Generate the type of the error.","score":[0.0223,0.0806]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Install(typ reflect.Type, adapter Adapter) {\r\n\tif adapter.Encode == nil {\r\n\t\tpanic(\"objconv: the encoder function of an adapter cannot be nil\")\r\n\t}\r\n\tif adapter.Decode == nil {\r\n\t\tpanic(\"objconv: the decoder function of an adapter cannot be nil\")\r\n\t}\r\n\tadapterMutex.Lock()\r\n\tadapterStore[typ] = adapter\r\n\tadapterMutex.Unlock()\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tstructCache.clear()\r\n}","code-length":141,"reference":"\/\/ Install adds an adapter for typ.\n\/\/\n\/\/ The function panics if one of the encoder and decoder functions of the\n\/\/ adapter are nil.\n\/\/\n\/\/ A typical use case for this function is to be called during the package\n\/\/ initialization phase to extend objconv support for new types.","result":"Install the adapter.","score":[0.0,0.0212]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AdapterOf(typ reflect.Type) (a Adapter, ok bool) {\r\n\tadapterMutex.RLock()\r\n\ta, ok = adapterStore[typ]\r\n\tadapterMutex.RUnlock()\r\n\treturn\r\n}","code-length":63,"reference":"\/\/ AdapterOf returns the adapter for typ, setting ok to true if one was found,\n\/\/ false otherwise.","result":"Create a new adapter.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AppendDuration(b []byte, d time.Duration) []byte {\r\n\t\r\n\tvar buf [32]byte\r\n\tw := len(buf)\r\n\tu := uint64(d)\r\n\tneg := d < 0\r\n\tif neg {\r\n\t\tu = -u\r\n\t}\r\n\tif u < uint64(time.Second) {\r\n\t\t\r\n\t\t\r\n\t\tvar prec int\r\n\t\tw--\r\n\t\tbuf[w] = 's'\r\n\t\tw--\r\n\t\tswitch {\r\n\t\tcase u == 0:\r\n\t\t\treturn append(b, '0', 's')\r\n\t\tcase u < uint64(time.Microsecond):\r\n\t\t\t\r\n\t\t\tprec = 0\r\n\t\t\tbuf[w] = 'n'\r\n\t\tcase u < uint64(time.Millisecond):\r\n\t\t\t\r\n\t\t\tprec = 3\r\n\t\t\t\r\n\t\t\tw--\r\n\t\t\tcopy(buf[w:], \"\u00b5\")\r\n\t\tdefault:\r\n\t\t\t\r\n\t\t\tprec = 6\r\n\t\t\tbuf[w] = 'm'\r\n\t\t}\r\n\t\tw, u = fmtFrac(buf[:w], u, prec)\r\n\t\tw = fmtInt(buf[:w], u)\r\n\t} else {\r\n\t\tw--\r\n\t\tbuf[w] = 's'\r\n\t\tw, u = fmtFrac(buf[:w], u, 9)\r\n\t\t\r\n\t\tw = fmtInt(buf[:w], u%60)\r\n\t\tu \/= 60\r\n\t\t\r\n\t\tif u > 0 {\r\n\t\t\tw--\r\n\t\t\tbuf[w] = 'm'\r\n\t\t\tw = fmtInt(buf[:w], u%60)\r\n\t\t\tu \/= 60\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tif u > 0 {\r\n\t\t\t\tw--\r\n\t\t\t\tbuf[w] = 'h'\r\n\t\t\t\tw = fmtInt(buf[:w], u)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif neg {\r\n\t\tw--\r\n\t\tbuf[w] = '-'\r\n\t}\r\n\treturn append(b, buf[w:]...)\r\n}","code-length":545,"reference":"\/\/ AppendDuration appends a human-readable representation of d to b.\n\/\/\n\/\/ The function copies the implementation of time.Duration.String but prevents\n\/\/ Go from making a dynamic memory allocation on the returned value.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc fmtInt(buf []byte, v uint64) int {\r\n\tw := len(buf)\r\n\tif v == 0 {\r\n\t\tw--\r\n\t\tbuf[w] = '0'\r\n\t} else {\r\n\t\tfor v > 0 {\r\n\t\t\tw--\r\n\t\t\tbuf[w] = byte(v%10) + '0'\r\n\t\t\tv \/= 10\r\n\t\t}\r\n\t}\r\n\treturn w\r\n}","code-length":122,"reference":"\/\/ fmtInt formats v into the tail of buf.\n\/\/ It returns the index where the output begins.","result":"Format the integer.","score":[0.0028,0.0606]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDecoder(r io.Reader) *objconv.Decoder {\r\n\treturn objconv.NewDecoder(NewParser(r))\r\n}","code-length":41,"reference":"\/\/ NewDecoder returns a new JSON decoder that parses values from r.","result":"Parse json.","score":[0,0.0455]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewStreamDecoder(r io.Reader) *objconv.StreamDecoder {\r\n\treturn objconv.NewStreamDecoder(NewParser(r))\r\n}","code-length":45,"reference":"\/\/ NewStreamDecoder returns a new JSON stream decoder that parses values from r.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Unmarshal(b []byte, v interface{}) error {\r\n\tu := unmarshalerPool.Get().(*unmarshaler)\r\n\tu.reset(b)\r\n\terr := (objconv.Decoder{Parser: u}).Decode(v)\r\n\tu.reset(nil)\r\n\tunmarshalerPool.Put(u)\r\n\treturn err\r\n}","code-length":96,"reference":"\/\/ Unmarshal decodes a JSON representation of v from b.","result":"Unmarshal the bytes.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t Type) String() string {\r\n\tswitch t {\r\n\tcase Nil:\r\n\t\treturn \"nil\"\r\n\tcase Bool:\r\n\t\treturn \"bool\"\r\n\tcase Int:\r\n\t\treturn \"int\"\r\n\tcase Uint:\r\n\t\treturn \"uint\"\r\n\tcase Float:\r\n\t\treturn \"float\"\r\n\tcase String:\r\n\t\treturn \"string\"\r\n\tcase Bytes:\r\n\t\treturn \"bytes\"\r\n\tcase Time:\r\n\t\treturn \"time\"\r\n\tcase Duration:\r\n\t\treturn \"duration\"\r\n\tcase Error:\r\n\t\treturn \"error\"\r\n\tcase Array:\r\n\t\treturn \"array\"\r\n\tcase Map:\r\n\t\treturn \"map\"\r\n\tdefault:\r\n\t\treturn \"<type>\"\r\n\t}\r\n}","code-length":212,"reference":"\/\/ String returns a human readable representation of the type.","result":"Get the string representation of the type.","score":[0.3293,0.499]}
{"code":"\/*is used to<extra_id_0>\r\nfunc zeroValueOf(t reflect.Type) reflect.Value {\r\n\tzeroMutex.RLock()\r\n\tv, ok := zeroCache[t]\r\n\tzeroMutex.RUnlock()\r\n\tif !ok {\r\n\t\tv = reflect.Zero(t)\r\n\t\tzeroMutex.Lock()\r\n\t\tzeroCache[t] = v\r\n\t\tzeroMutex.Unlock()\r\n\t}\r\n\treturn v\r\n}","code-length":113,"reference":"\/\/ zeroValueOf and the related cache is used to keep the zero values so they\n\/\/ don't need to be reallocated every time they're used.","result":"Create a zero value of a type.","score":[0.0123,0.0808]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewValueParser(v interface{}) *ValueParser {\r\n\treturn &ValueParser{\r\n\t\tstack: []reflect.Value{reflect.ValueOf(v)},\r\n\t}\r\n}","code-length":57,"reference":"\/\/ NewValueParser creates a new parser that exposes the value v.","result":"Parse the value.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseTag(s string) Tag {\r\n\tvar name string\r\n\tvar omitzero bool\r\n\tvar omitempty bool\r\n\tname, s = parseNextTagToken(s)\r\n\tfor len(s) != 0 {\r\n\t\tvar token string\r\n\t\tswitch token, s = parseNextTagToken(s); token {\r\n\t\tcase \"omitempty\":\r\n\t\t\tomitempty = true\r\n\t\tcase \"omitzero\":\r\n\t\t\tomitzero = true\r\n\t\t}\r\n\t}\r\n\treturn Tag{\r\n\t\tName:      name,\r\n\t\tOmitempty: omitempty,\r\n\t\tOmitzero:  omitzero,\r\n\t}\r\n}","code-length":176,"reference":"\/\/ ParseTag parses a raw tag obtained from a struct field, returning the results\n\/\/ as a tag value.","result":"Parse tags.","score":[0,0.0289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewEncoder(w io.Writer) *objconv.Encoder {\r\n\treturn objconv.NewEncoder(NewEmitter(w))\r\n}","code-length":41,"reference":"\/\/ NewEncoder returns a new JSON encoder that writes to w.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewStreamEncoder(w io.Writer) *objconv.StreamEncoder {\r\n\treturn objconv.NewStreamEncoder(NewEmitter(w))\r\n}","code-length":45,"reference":"\/\/ NewStreamEncoder returns a new JSON stream encoder that writes to w.","result":"Create a stream encoder.","score":[0.0514,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPrettyEncoder(w io.Writer) *objconv.Encoder {\r\n\treturn objconv.NewEncoder(NewPrettyEmitter(w))\r\n}","code-length":44,"reference":"\/\/ NewPrettyEncoder returns a new JSON encoder that writes to w.","result":"Create pretty encoding.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPrettyStreamEncoder(w io.Writer) *objconv.StreamEncoder {\r\n\treturn objconv.NewStreamEncoder(NewPrettyEmitter(w))\r\n}","code-length":47,"reference":"\/\/ NewPrettyStreamEncoder returns a new JSON stream encoder that writes to w.","result":"Encode json.","score":[0,0.0455]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Marshal(v interface{}) (b []byte, err error) {\r\n\tm := marshalerPool.Get().(*marshaler)\r\n\tm.b.Truncate(0)\r\n\tif err = (objconv.Encoder{Emitter: m}).Encode(v); err == nil {\r\n\t\tb = make([]byte, m.b.Len())\r\n\t\tcopy(b, m.b.Bytes())\r\n\t}\r\n\tmarshalerPool.Put(m)\r\n\treturn\r\n}","code-length":129,"reference":"\/\/ Marshal writes the JSON representation of v to a byte slice returned in b.","result":"Marshal the given value.","score":[0.0243,0.1079]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewEncoder(e Emitter) *Encoder {\r\n\tif e == nil {\r\n\t\tpanic(\"objconv: the emitter is nil\")\r\n\t}\r\n\treturn &Encoder{Emitter: e}\r\n}","code-length":60,"reference":"\/\/ NewEncoder returns a new encoder that outputs values to e.\n\/\/\n\/\/ Encoders created by this function use the default encoder configuration,\n\/\/ which is equivalent to using a zero-value EncoderConfig with only the Emitter\n\/\/ field set.\n\/\/\n\/\/ The function panics if e is nil.","result":"Create a new encoder.","score":[0.0,0.0344]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e Encoder) EncodeArray(n int, f func(Encoder) error) (err error) {\r\n\tif e.key {\r\n\t\tif e.key, err = false, e.Emitter.EmitMapValue(); err != nil {\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n\tif err = e.Emitter.EmitArrayBegin(n); err != nil {\r\n\t\treturn\r\n\t}\r\nencodeArray:\r\n\tfor i := 0; n < 0 || i < n; i++ {\r\n\t\tif i != 0 {\r\n\t\t\tif e.Emitter.EmitArrayNext(); err != nil {\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t}\r\n\t\tswitch err = f(e); err {\r\n\t\tcase nil:\r\n\t\tcase End:\r\n\t\t\tbreak encodeArray\r\n\t\tdefault:\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n\treturn e.Emitter.EmitArrayEnd()\r\n}","code-length":242,"reference":"\/\/ EncodeArray provides the implementation of the array encoding algorithm,\n\/\/ where n is the number of elements in the array, and f a function called to\n\/\/ encode each element.\n\/\/\n\/\/ The n argument can be set to a negative value to indicate that the program\n\/\/ doesn't know how many elements it will output to the array. Be mindful that\n\/\/ not all emitters support encoding arrays of unknown lengths.\n\/\/\n\/\/ The f function is called to encode each element of the array.","result":"Encode arrays in the map.","score":[0.0,0.0254]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e Encoder) EncodeMap(n int, f func(Encoder, Encoder) error) (err error) {\r\n\tif e.key {\r\n\t\tif e.key, err = false, e.Emitter.EmitMapValue(); err != nil {\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n\tif err = e.Emitter.EmitMapBegin(n); err != nil {\r\n\t\treturn\r\n\t}\r\nencodeMap:\r\n\tfor i := 0; n < 0 || i < n; i++ {\r\n\t\tif i != 0 {\r\n\t\t\tif err = e.Emitter.EmitMapNext(); err != nil {\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t}\r\n\t\te.key = true\r\n\t\terr = f(\r\n\t\t\tEncoder{Emitter: e.Emitter, SortMapKeys: e.SortMapKeys},\r\n\t\t\tEncoder{Emitter: e.Emitter, SortMapKeys: e.SortMapKeys, key: true},\r\n\t\t)\r\n\t\t\r\n\t\t\r\n\t\te.key = false\r\n\t\tswitch err {\r\n\t\tcase nil:\r\n\t\tcase End:\r\n\t\t\tbreak encodeMap\r\n\t\tdefault:\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n\treturn e.Emitter.EmitMapEnd()\r\n}","code-length":325,"reference":"\/\/ EncodeMap provides the implementation of the map encoding algorithm, where n\n\/\/ is the number of elements in the map, and f a function called to encode each\n\/\/ element.\n\/\/\n\/\/ The n argument can be set to a negative value to indicate that the program\n\/\/ doesn't know how many elements it will output to the map. Be mindful that not\n\/\/ all emitters support encoding maps of unknown length.\n\/\/\n\/\/ The f function is called to encode each element of the map, it is expected to\n\/\/ encode two values, the first one being the key, follow by the associated value.\n\/\/ The first encoder must be used to encode the key, the second for the value.","result":"Encode maps in Go.","score":[0.0,0.0136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewStreamEncoder(e Emitter) *StreamEncoder {\r\n\tif e == nil {\r\n\t\tpanic(\"objconv.NewStreamEncoder: the emitter is nil\")\r\n\t}\r\n\treturn &StreamEncoder{Emitter: e}\r\n}","code-length":68,"reference":"\/\/ NewStreamEncoder returns a new stream encoder that outputs to e.\n\/\/\n\/\/ The function panics if e is nil.","result":"Create a new stream encoder.","score":[0.0246,0.1592]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *StreamEncoder) Open(n int) error {\r\n\tif err := e.err; err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif e.closed {\r\n\t\treturn io.ErrClosedPipe\r\n\t}\r\n\tif !e.opened {\r\n\t\te.max = n\r\n\t\te.opened = true\r\n\t\tif !e.oneshot {\r\n\t\t\te.err = e.Emitter.EmitArrayBegin(n)\r\n\t\t}\r\n\t}\r\n\treturn e.err\r\n}","code-length":145,"reference":"\/\/ Open explicitly tells the encoder to start the stream, setting the number\n\/\/ of values to n.\n\/\/\n\/\/ Depending on the actual format that the stream is encoding to, n may or\n\/\/ may not have to be accurate, some formats also support passing a negative\n\/\/ value to indicate that the number of elements is unknown.","result":"Encode arrays.","score":[0,0.0094]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *StreamEncoder) Close() error {\r\n\tif !e.closed {\r\n\t\tif err := e.Open(-1); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\te.closed = true\r\n\t\tif !e.oneshot {\r\n\t\t\te.err = e.Emitter.EmitArrayEnd()\r\n\t\t}\r\n\t}\r\n\treturn e.err\r\n}","code-length":113,"reference":"\/\/ Close terminates the stream encoder.","result":"Close the stream encoder.","score":[0.4289,0.6466]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *StreamEncoder) Encode(v interface{}) error {\r\n\tif err := e.Open(-1); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif e.max >= 0 && e.cnt >= e.max {\r\n\t\treturn fmt.Errorf(\"objconv: too many values sent to a stream encoder exceed the configured limit of %d\", e.max)\r\n\t}\r\n\tif !e.oneshot && e.cnt != 0 {\r\n\t\te.err = e.Emitter.EmitArrayNext()\r\n\t}\r\n\tif e.err == nil {\r\n\t\te.err = (Encoder{\r\n\t\t\tEmitter:     e.Emitter,\r\n\t\t\tSortMapKeys: e.SortMapKeys,\r\n\t\t}).Encode(v)\r\n\t\tif e.cnt++; e.max >= 0 && e.cnt >= e.max {\r\n\t\t\te.Close()\r\n\t\t}\r\n\t}\r\n\treturn e.err\r\n}","code-length":248,"reference":"\/\/ Encode writes v to the stream, encoding it based on the emitter configured\n\/\/ on e.","result":"Encode a map[string]interface.","score":[0.0038,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newStructType(t reflect.Type, c map[reflect.Type]*structType) *structType {\r\n\tif s := c[t]; s != nil {\r\n\t\treturn s\r\n\t}\r\n\tn := t.NumField()\r\n\ts := &structType{\r\n\t\tfields:       make([]structField, 0, n),\r\n\t\tfieldsByName: make(map[string]*structField),\r\n\t}\r\n\tc[t] = s\r\n\tfor i := 0; i != n; i++ {\r\n\t\tft := t.Field(i)\r\n\t\tif ft.Anonymous || len(ft.PkgPath) != 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tsf := makeStructField(ft, c)\r\n\t\tif sf.name == \"-\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\ts.fields = append(s.fields, sf)\r\n\t\ts.fieldsByName[sf.name] = &s.fields[len(s.fields)-1]\r\n\t}\r\n\treturn s\r\n}","code-length":269,"reference":"\/\/ newStructType takes a Go type as argument and extract information to make a\n\/\/ new structType value.\n\/\/ The type has to be a struct type or a panic will be raised.","result":"Create a new struct type.","score":[0.0012,0.0497]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cache *structTypeCache) lookup(t reflect.Type) (s *structType) {\r\n\tcache.mutex.RLock()\r\n\ts = cache.store[t]\r\n\tcache.mutex.RUnlock()\r\n\tif s == nil {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\ts = newStructType(t, map[reflect.Type]*structType{})\r\n\t\tcache.mutex.Lock()\r\n\t\tcache.store[t] = s\r\n\t\tcache.mutex.Unlock()\r\n\t}\r\n\treturn\r\n}","code-length":154,"reference":"\/\/ lookup takes a Go type as argument and returns the matching structType value,\n\/\/ potentially creating it if it didn't already exist.\n\/\/ This method is safe to call from multiple goroutines.","result":"Cache the result of the lookup function .","score":[0.0073,0.0492]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cache *structTypeCache) clear() {\r\n\tcache.mutex.Lock()\r\n\tfor typ := range cache.store {\r\n\t\tdelete(cache.store, typ)\r\n\t}\r\n\tcache.mutex.Unlock()\r\n}","code-length":68,"reference":"\/\/ clear empties the cache.","result":"Clear the cache.","score":[0.2964,0.5324]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CheckUint64Bounds(v uint64, max uint64, t reflect.Type) (err error) {\r\n\tif v > max {\r\n\t\terr = fmt.Errorf(\"objconv: %d overflows the maximum value of %d for %s\", v, max, t)\r\n\t}\r\n\treturn\r\n}","code-length":85,"reference":"\/\/ CheckUint64Bounds verifies that v is smaller than max, t represents the\n\/\/ original type of v.","result":"Check uint.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CheckInt64Bounds(v int64, min int64, max uint64, t reflect.Type) (err error) {\r\n\tif v < min {\r\n\t\terr = fmt.Errorf(\"objconv: %d overflows the minimum value of %d for %s\", v, min, t)\r\n\t}\r\n\tif v > 0 && uint64(v) > max {\r\n\t\terr = fmt.Errorf(\"objconv: %d overflows the maximum value of %d for %s\", v, max, t)\r\n\t}\r\n\treturn\r\n}","code-length":142,"reference":"\/\/ CheckInt64Bounds verifies that v is within min and max, t represents the\n\/\/ original type of v.","result":"Check the bounds of an int.","score":[0.0311,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDecoder(p Parser) *Decoder {\r\n\tif p == nil {\r\n\t\tpanic(\"objconv: the parser is nil\")\r\n\t}\r\n\treturn &Decoder{Parser: p}\r\n}","code-length":59,"reference":"\/\/ NewDecoder returns a decoder object that uses p, will panic if p is nil.","result":"Decode json.","score":[0,0.0365]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d Decoder) Decode(v interface{}) error {\r\n\tto := reflect.ValueOf(v)\r\n\tif d.off != 0 {\r\n\t\tvar err error\r\n\t\tif d.off, err = 0, d.Parser.ParseMapValue(d.off-1); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tif !to.IsValid() {\r\n\t\t\r\n\t\t\r\n\t\t_, err := d.decodeInterface(to)\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t\r\n\tswitch x := v.(type) {\r\n\tcase ValueDecoder:\r\n\t\treturn x.DecodeValue(d)\r\n\t}\r\n\tif to.Kind() == reflect.Ptr {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tto = to.Elem()\r\n\t}\r\n\t_, err := d.decode(to)\r\n\treturn err\r\n}","code-length":242,"reference":"\/\/ Decode expects v to be a pointer to a value in which the decoder will load\n\/\/ the next parsed data.\n\/\/\n\/\/ The method panics if v is neither a pointer type nor implements the\n\/\/ ValueDecoder interface, or if v is a nil pointer.","result":"Decode a map value.","score":[0.0,0.0234]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d Decoder) DecodeArray(f func(Decoder) error) (err error) {\r\n\tvar typ Type\r\n\tif d.off != 0 {\r\n\t\tif d.off, err = 0, d.Parser.ParseMapValue(d.off-1); err != nil {\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n\tif typ, err = d.Parser.ParseType(); err != nil {\r\n\t\treturn\r\n\t}\r\n\terr = d.decodeArrayImpl(typ, f)\r\n\treturn\r\n}","code-length":140,"reference":"\/\/ DecodeArray provides the implementation of the algorithm for decoding arrays,\n\/\/ where f is called to decode each element of the array.","result":"Decode array in map values.","score":[0,0.0236]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d Decoder) DecodeMap(f func(Decoder, Decoder) error) (err error) {\r\n\tvar typ Type\r\n\tif d.off != 0 {\r\n\t\tif d.off, err = 0, d.Parser.ParseMapValue(d.off-1); err != nil {\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n\tif typ, err = d.Parser.ParseType(); err != nil {\r\n\t\treturn\r\n\t}\r\n\terr = d.decodeMapImpl(typ, f)\r\n\treturn\r\n}","code-length":142,"reference":"\/\/ DecodeMap provides the implementation of the algorithm for decoding maps,\n\/\/ where f is called to decode each pair of key and value.\n\/\/\n\/\/ The function f is expected to decode two values from the map, the first one\n\/\/ being the key and the second the associated value. The first decoder must be\n\/\/ used to decode the key, the second one for the value.","result":"Avoid recursive call to decodeMap.","score":[0.0,0.0162]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewStreamDecoder(p Parser) *StreamDecoder {\r\n\tif p == nil {\r\n\t\tpanic(\"objconv: the parser is nil\")\r\n\t}\r\n\treturn &StreamDecoder{Parser: p}\r\n}","code-length":63,"reference":"\/\/ NewStreamDecoder returns a new stream decoder that takes input from p.\n\/\/\n\/\/ The function panics if p is nil.","result":"Create a new stream decoder.","score":[0.0202,0.1518]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *StreamDecoder) Len() int {\r\n\tif d.err != nil {\r\n\t\treturn 0\r\n\t}\r\n\tif d.typ == Unknown {\r\n\t\tif d.init() != nil {\r\n\t\t\treturn 0\r\n\t\t}\r\n\t}\r\n\treturn d.max - d.cnt\r\n}","code-length":91,"reference":"\/\/ Len returns the number of values remaining to be read from the stream, which\n\/\/ may be -1 if the underlying format doesn't provide this information. If an\n\/\/ error occurred while decoding the stream the method returns zero because no\n\/\/ more values can be read.","result":"Get the length of the stream decoder.","score":[0.0008,0.0456]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *StreamDecoder) Err() error {\r\n\tif d.err == End {\r\n\t\treturn nil\r\n\t}\r\n\treturn d.err\r\n}","code-length":50,"reference":"\/\/ Err returns the last error returned by the Decode method.\n\/\/\n\/\/ The method returns nil if the stream reached its natural end.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *StreamDecoder) Decode(v interface{}) error {\r\n\tif d.err != nil {\r\n\t\treturn d.err\r\n\t}\r\n\terr := error(nil)\r\n\tcnt := d.cnt\r\n\tmax := d.max\r\n\tdec := Decoder{\r\n\t\tParser:  d.Parser,\r\n\t\tMapType: d.MapType,\r\n\t}\r\n\tswitch d.typ {\r\n\tcase Unknown:\r\n\t\terr = d.init()\r\n\t\tmax = d.max\r\n\tcase Array:\r\n\t\tif cnt == max {\r\n\t\t\terr = dec.Parser.ParseArrayEnd(cnt)\r\n\t\t} else if cnt != 0 {\r\n\t\t\terr = dec.Parser.ParseArrayNext(cnt)\r\n\t\t}\r\n\t}\r\n\tif err == nil {\r\n\t\tif cnt == max {\r\n\t\t\terr = End\r\n\t\t} else {\r\n\t\t\tswitch err = dec.Decode(v); err {\r\n\t\t\tcase nil:\r\n\t\t\t\tcnt++\r\n\t\t\tcase End:\r\n\t\t\t\tcnt++\r\n\t\t\t\tmax = cnt\r\n\t\t\tdefault:\r\n\t\t\t\tif max < 0 && dec.Parser.ParseArrayEnd(cnt) == nil {\r\n\t\t\t\t\terr = End\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\td.err = err\r\n\td.cnt = cnt\r\n\td.max = max\r\n\treturn err\r\n}","code-length":370,"reference":"\/\/ Decodes the next value from the stream into v.","result":"Decode the stream.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *StreamDecoder) Encoder(e Emitter) (enc *StreamEncoder, err error) {\r\n\tvar typ Type\r\n\tif typ, err = d.Parser.ParseType(); err == nil {\r\n\t\tenc = NewStreamEncoder(e)\r\n\t\tenc.oneshot = typ != Array\r\n\t}\r\n\treturn\r\n}","code-length":93,"reference":"\/\/ Encoder returns a new StreamEncoder which can be used to re-encode the stream\n\/\/ decoded by d into e.\n\/\/\n\/\/ The method panics if e is nil.","result":"Encode the stream.","score":[0.0001,0.0379]}
{"code":"\/*is used to<extra_id_0>\r\nfunc init() {\r\n\tfor _, f := range strings.Split(os.Getenv(\"LOGFLAGS\"), \",\") {\r\n\t\tswitch f {\r\n\t\tcase \"longfile\":\r\n\t\t\tdefaultFlags |= Llongfile\r\n\t\tcase \"shortfile\":\r\n\t\t\tdefaultFlags |= Lshortfile\r\n\t\t}\r\n\t}\r\n}","code-length":95,"reference":"\/\/ Read logger flags from the LOGFLAGS environment variable.  Multiple flags can\n\/\/ be set at once, separated by commas.","result":"Initialize the logger.","score":[0.0014,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LevelFromString(s string) (l Level, ok bool) {\r\n\tswitch strings.ToLower(s) {\r\n\tcase \"trace\", \"trc\":\r\n\t\treturn LevelTrace, true\r\n\tcase \"debug\", \"dbg\":\r\n\t\treturn LevelDebug, true\r\n\tcase \"info\", \"inf\":\r\n\t\treturn LevelInfo, true\r\n\tcase \"warn\", \"wrn\":\r\n\t\treturn LevelWarn, true\r\n\tcase \"error\", \"err\":\r\n\t\treturn LevelError, true\r\n\tcase \"critical\", \"crt\":\r\n\t\treturn LevelCritical, true\r\n\tcase \"off\":\r\n\t\treturn LevelOff, true\r\n\tdefault:\r\n\t\treturn LevelInfo, false\r\n\t}\r\n}","code-length":191,"reference":"\/\/ LevelFromString returns a level based on the input string s.  If the input\n\/\/ can't be interpreted as a valid log level, the info level and false is\n\/\/ returned.","result":"Convert string to string.","score":[0.0004,0.0177]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewBackend(w io.Writer, opts ...BackendOption) *Backend {\r\n\tb := &Backend{w: w, flag: defaultFlags}\r\n\tfor _, o := range opts {\r\n\t\to(b)\r\n\t}\r\n\treturn b\r\n}","code-length":74,"reference":"\/\/ NewBackend creates a logger backend from a Writer.","result":"Create a new backend.","score":[0.0915,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc callsite(flag uint32) (string, int) {\r\n\t_, file, line, ok := runtime.Caller(calldepth)\r\n\tif !ok {\r\n\t\treturn \"???\", 0\r\n\t}\r\n\tif flag&Lshortfile != 0 {\r\n\t\tshort := file\r\n\t\tfor i := len(file) - 1; i > 0; i-- {\r\n\t\t\tif os.IsPathSeparator(file[i]) {\r\n\t\t\t\tshort = file[i+1:]\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tfile = short\r\n\t}\r\n\treturn file, line\r\n}","code-length":166,"reference":"\/\/ callsite returns the file name and line number of the callsite to the\n\/\/ subsystem logger.","result":"Call the caller function.","score":[0.0124,0.0637]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Backend) print(lvl, tag string, args ...interface{}) {\r\n\tt := time.Now()\r\n\tbytebuf := buffer()\r\n\tvar file string\r\n\tvar line int\r\n\tif b.flag&(Lshortfile|Llongfile) != 0 {\r\n\t\tfile, line = callsite(b.flag)\r\n\t}\r\n\tformatHeader(bytebuf, t, lvl, tag, file, line)\r\n\tbuf := bytes.NewBuffer(*bytebuf)\r\n\tfmt.Fprintln(buf, args...)\r\n\t*bytebuf = buf.Bytes()\r\n\tb.mu.Lock()\r\n\tb.w.Write(*bytebuf)\r\n\tb.mu.Unlock()\r\n\trecycleBuffer(bytebuf)\r\n}","code-length":194,"reference":"\/\/ print outputs a log message to the writer associated with the backend after\n\/\/ creating a prefix for the given level and tag according to the formatHeader\n\/\/ function and formatting the provided arguments using the default formatting\n\/\/ rules.","result":"Print to the backend.","score":[0.0,0.0402]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Backend) Logger(subsystemTag string) Logger {\r\n\treturn &slog{LevelInfo, subsystemTag, b}\r\n}","code-length":43,"reference":"\/\/ Logger returns a new logger for a particular subsystem that writes to the\n\/\/ Backend b.  A tag describes the subsystem and is included in all log\n\/\/ messages.  The logger uses the info verbosity level by default.","result":"Generate the generated code.","score":[0.0001,0.0141]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *slog) Trace(args ...interface{}) {\r\n\tlvl := l.Level()\r\n\tif lvl <= LevelTrace {\r\n\t\tl.b.print(\"TRC\", l.tag, args...)\r\n\t}\r\n}","code-length":68,"reference":"\/\/ Trace formats message using the default formats for its operands, prepends\n\/\/ the prefix as necessary, and writes to log with LevelTrace.\n\/\/\n\/\/ This is part of the Logger interface implementation.","result":"Call Trace in a context of a logger.","score":[0.0073,0.0328]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *slog) Tracef(format string, args ...interface{}) {\r\n\tlvl := l.Level()\r\n\tif lvl <= LevelTrace {\r\n\t\tl.b.printf(\"TRC\", l.tag, format, args...)\r\n\t}\r\n}","code-length":73,"reference":"\/\/ Tracef formats message according to format specifier, prepends the prefix as\n\/\/ necessary, and writes to log with LevelTrace.\n\/\/\n\/\/ This is part of the Logger interface implementation.","result":"Print trace statements.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *slog) Debug(args ...interface{}) {\r\n\tlvl := l.Level()\r\n\tif lvl <= LevelDebug {\r\n\t\tl.b.print(\"DBG\", l.tag, args...)\r\n\t}\r\n}","code-length":68,"reference":"\/\/ Debug formats message using the default formats for its operands, prepends\n\/\/ the prefix as necessary, and writes to log with LevelDebug.\n\/\/\n\/\/ This is part of the Logger interface implementation.","result":"Debug debug messages.","score":[0.0,0.0167]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *slog) Debugf(format string, args ...interface{}) {\r\n\tlvl := l.Level()\r\n\tif lvl <= LevelDebug {\r\n\t\tl.b.printf(\"DBG\", l.tag, format, args...)\r\n\t}\r\n}","code-length":73,"reference":"\/\/ Debugf formats message according to format specifier, prepends the prefix as\n\/\/ necessary, and writes to log with LevelDebug.\n\/\/\n\/\/ This is part of the Logger interface implementation.","result":"Debug debug messages.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *slog) Info(args ...interface{}) {\r\n\tlvl := l.Level()\r\n\tif lvl <= LevelInfo {\r\n\t\tl.b.print(\"INF\", l.tag, args...)\r\n\t}\r\n}","code-length":67,"reference":"\/\/ Info formats message using the default formats for its operands, prepends\n\/\/ the prefix as necessary, and writes to log with LevelInfo.\n\/\/\n\/\/ This is part of the Logger interface implementation.","result":"Print info to the console.","score":[0.0011,0.0497]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *slog) Infof(format string, args ...interface{}) {\r\n\tlvl := l.Level()\r\n\tif lvl <= LevelInfo {\r\n\t\tl.b.printf(\"INF\", l.tag, format, args...)\r\n\t}\r\n}","code-length":72,"reference":"\/\/ Infof formats message according to format specifier, prepends the prefix as\n\/\/ necessary, and writes to log with LevelInfo.\n\/\/\n\/\/ This is part of the Logger interface implementation.","result":"Print debug messages.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *slog) Warn(args ...interface{}) {\r\n\tlvl := l.Level()\r\n\tif lvl <= LevelWarn {\r\n\t\tl.b.print(\"WRN\", l.tag, args...)\r\n\t}\r\n}","code-length":68,"reference":"\/\/ Warn formats message using the default formats for its operands, prepends\n\/\/ the prefix as necessary, and writes to log with LevelWarn.\n\/\/\n\/\/ This is part of the Logger interface implementation.","result":"Avoid recursion.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *slog) Warnf(format string, args ...interface{}) {\r\n\tlvl := l.Level()\r\n\tif lvl <= LevelWarn {\r\n\t\tl.b.printf(\"WRN\", l.tag, format, args...)\r\n\t}\r\n}","code-length":73,"reference":"\/\/ Warnf formats message according to format specifier, prepends the prefix as\n\/\/ necessary, and writes to log with LevelWarn.\n\/\/\n\/\/ This is part of the Logger interface implementation.","result":"Set the logger on the fly.","score":[0.0042,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *slog) Error(args ...interface{}) {\r\n\tlvl := l.Level()\r\n\tif lvl <= LevelError {\r\n\t\tl.b.print(\"ERR\", l.tag, args...)\r\n\t}\r\n}","code-length":67,"reference":"\/\/ Error formats message using the default formats for its operands, prepends\n\/\/ the prefix as necessary, and writes to log with LevelError.\n\/\/\n\/\/ This is part of the Logger interface implementation.","result":"Avoid recursion.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *slog) Errorf(format string, args ...interface{}) {\r\n\tlvl := l.Level()\r\n\tif lvl <= LevelError {\r\n\t\tl.b.printf(\"ERR\", l.tag, format, args...)\r\n\t}\r\n}","code-length":72,"reference":"\/\/ Errorf formats message according to format specifier, prepends the prefix as\n\/\/ necessary, and writes to log with LevelError.\n\/\/\n\/\/ This is part of the Logger interface implementation.","result":"Set the error message.","score":[0.0005,0.0182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *slog) Critical(args ...interface{}) {\r\n\tlvl := l.Level()\r\n\tif lvl <= LevelCritical {\r\n\t\tl.b.print(\"CRT\", l.tag, args...)\r\n\t}\r\n}","code-length":69,"reference":"\/\/ Critical formats message using the default formats for its operands, prepends\n\/\/ the prefix as necessary, and writes to log with LevelCritical.\n\/\/\n\/\/ This is part of the Logger interface implementation.","result":"Call the function from within a function.","score":[0.0039,0.0329]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *slog) Criticalf(format string, args ...interface{}) {\r\n\tlvl := l.Level()\r\n\tif lvl <= LevelCritical {\r\n\t\tl.b.printf(\"CRT\", l.tag, format, args...)\r\n\t}\r\n}","code-length":75,"reference":"\/\/ Criticalf formats message according to format specifier, prepends the prefix\n\/\/ as necessary, and writes to log with LevelCritical.\n\/\/\n\/\/ This is part of the Logger interface implementation.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *slog) Level() Level {\r\n\treturn Level(atomic.LoadUint32((*uint32)(&l.lvl)))\r\n}","code-length":44,"reference":"\/\/ Level returns the current logging level\n\/\/\n\/\/ This is part of the Logger interface implementation.","result":"Get the level of the log.","score":[0.0519,0.1985]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *slog) SetLevel(level Level) {\r\n\tatomic.StoreUint32((*uint32)(&l.lvl), uint32(level))\r\n}","code-length":49,"reference":"\/\/ SetLevel changes the logging level to the passed level.\n\/\/\n\/\/ This is part of the Logger interface implementation.","result":"Set the level of the log.","score":[0.0315,0.1697]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (permission *Permission) Concat(newPermission *Permission) *Permission {\r\n\tvar result = Permission{\r\n\t\tRole:         Global,\r\n\t\tAllowedRoles: map[PermissionMode][]string{},\r\n\t\tDeniedRoles:  map[PermissionMode][]string{},\r\n\t}\r\n\tvar appendRoles = func(p *Permission) {\r\n\t\tif p != nil {\r\n\t\t\tresult.Role = p.Role\r\n\t\t\tfor mode, roles := range p.DeniedRoles {\r\n\t\t\t\tresult.DeniedRoles[mode] = append(result.DeniedRoles[mode], roles...)\r\n\t\t\t}\r\n\t\t\tfor mode, roles := range p.AllowedRoles {\r\n\t\t\t\tresult.AllowedRoles[mode] = append(result.AllowedRoles[mode], roles...)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tappendRoles(newPermission)\r\n\tappendRoles(permission)\r\n\treturn &result\r\n}","code-length":234,"reference":"\/\/ Concat concat two permissions into a new one","result":"Concatenate permission to newPermission.","score":[0,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (permission Permission) HasPermission(mode PermissionMode, roles ...interface{}) bool {\r\n\tvar roleNames []string\r\n\tfor _, role := range roles {\r\n\t\tif r, ok := role.(string); ok {\r\n\t\t\troleNames = append(roleNames, r)\r\n\t\t} else if roler, ok := role.(Roler); ok {\r\n\t\t\troleNames = append(roleNames, roler.GetRoles()...)\r\n\t\t} else {\r\n\t\t\tfmt.Printf(\"invalid role %#v\\n\", role)\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\tif len(permission.DeniedRoles) != 0 {\r\n\t\tif DeniedRoles := permission.DeniedRoles[mode]; DeniedRoles != nil {\r\n\t\t\tif includeRoles(DeniedRoles, roleNames) {\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\tif len(permission.AllowedRoles) == 0 {\r\n\t\treturn true\r\n\t}\r\n\tif AllowedRoles := permission.AllowedRoles[mode]; AllowedRoles != nil {\r\n\t\tif includeRoles(AllowedRoles, roleNames) {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":311,"reference":"\/\/ HasPermission check roles has permission for mode or not","result":"Check if a permission has been granted.","score":[0.1251,0.1546]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ConcatPermissioner(ps ...Permissioner) Permissioner {\r\n\tvar newPS []Permissioner\r\n\tfor _, p := range ps {\r\n\t\tif p != nil {\r\n\t\t\tnewPS = append(newPS, p)\r\n\t\t}\r\n\t}\r\n\treturn permissioners(newPS)\r\n}","code-length":87,"reference":"\/\/ ConcatPermissioner concat permissioner","result":"Concatenate permissioners.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ps permissioners) HasPermission(mode PermissionMode, roles ...interface{}) bool {\r\n\tfor _, p := range ps {\r\n\t\tif p != nil && !p.HasPermission(mode, roles) {\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":83,"reference":"\/\/ HasPermission check has permission for permissioners or not","result":"Check permission.","score":[0,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (role *Role) Register(name string, fc Checker) {\r\n\tif role.definitions == nil {\r\n\t\trole.definitions = map[string]Checker{}\r\n\t}\r\n\tdefinition := role.definitions[name]\r\n\tif definition != nil {\r\n\t\tfmt.Printf(\"Role `%v` already defined, overwrited it!\\n\", name)\r\n\t}\r\n\trole.definitions[name] = fc\r\n}","code-length":113,"reference":"\/\/ Register register role with conditions","result":"Register a new role.","score":[0.1938,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (role *Role) NewPermission() *Permission {\r\n\treturn &Permission{\r\n\t\tRole:         role,\r\n\t\tAllowedRoles: map[PermissionMode][]string{},\r\n\t\tDeniedRoles:  map[PermissionMode][]string{},\r\n\t}\r\n}","code-length":77,"reference":"\/\/ NewPermission initialize permission","result":"Create a new permission.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (role *Role) Get(name string) (Checker, bool) {\r\n\tfc, ok := role.definitions[name]\r\n\treturn fc, ok\r\n}","code-length":49,"reference":"\/\/ Get role defination","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) isPtrFromHeap(a core.Address) bool {\r\n\treturn p.findHeapInfo(a).IsPtr(a, p.proc.PtrSize())\r\n}","code-length":54,"reference":"\/\/ isPtrFromHeap reports whether the inferior at address a contains a pointer.\n\/\/ a must be somewhere in the heap.","result":"Check ptr address.","score":[0,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) IsPtr(a core.Address) bool {\r\n\th := p.findHeapInfo(a)\r\n\tif h != nil {\r\n\t\treturn h.IsPtr(a, p.proc.PtrSize())\r\n\t}\r\n\tfor _, m := range p.modules {\r\n\t\tfor _, s := range [2]string{\"data\", \"bss\"} {\r\n\t\t\tmin := core.Address(m.r.Field(s).Uintptr())\r\n\t\t\tmax := core.Address(m.r.Field(\"e\" + s).Uintptr())\r\n\t\t\tif a < min || a >= max {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tgc := m.r.Field(\"gc\" + s + \"mask\").Field(\"bytedata\").Address()\r\n\t\t\ti := a.Sub(min)\r\n\t\t\treturn p.proc.ReadUint8(gc.Add(i\/8))>>uint(i%8) != 0\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\treturn false\r\n}","code-length":269,"reference":"\/\/ IsPtr reports whether the inferior at address a contains a pointer.","result":"Detect if a pointer is a pointer to a pointer to a pointer to a pointer.","score":[0.1028,0.2061]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) FindObject(a core.Address) (Object, int64) {\r\n\t\r\n\th := p.findHeapInfo(a)\r\n\tif h == nil {\r\n\t\t\r\n\t\t\r\n\t\treturn 0, 0\r\n\t}\r\n\tx := h.base.Add(a.Sub(h.base) \/ h.size * h.size)\r\n\t\r\n\th = p.findHeapInfo(x)\r\n\tif h.mark>>(uint64(x)%heapInfoSize\/8)&1 == 0 {\r\n\t\treturn 0, 0\r\n\t}\r\n\treturn Object(x), a.Sub(x)\r\n}","code-length":171,"reference":"\/\/ FindObject finds the object containing a.  Returns that object and the offset within\n\/\/ that object to which a points.\n\/\/ Returns 0,0 if a doesn't point to a live heap object.","result":"Find the object in the heap.","score":[0.0034,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) ForEachObject(fn func(x Object) bool) {\r\n\tfor _, k := range p.pages {\r\n\t\tpt := p.pageTable[k]\r\n\t\tfor i := range pt {\r\n\t\t\th := &pt[i]\r\n\t\t\tm := h.mark\r\n\t\t\tfor m != 0 {\r\n\t\t\t\tj := bits.TrailingZeros64(m)\r\n\t\t\t\tm &= m - 1\r\n\t\t\t\tx := Object(k)*pageTableSize*heapInfoSize + Object(i)*heapInfoSize + Object(j)*8\r\n\t\t\t\tif !fn(x) {\r\n\t\t\t\t\treturn\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":185,"reference":"\/\/ ForEachObject calls fn with each object in the Go heap.\n\/\/ If fn returns false, ForEachObject returns immediately.","result":"Generate code for the generated code.","score":[0.0221,0.0282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) ForEachRoot(fn func(r *Root) bool) {\r\n\tfor _, r := range p.globals {\r\n\t\tif !fn(r) {\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n\tfor _, g := range p.goroutines {\r\n\t\tfor _, f := range g.frames {\r\n\t\t\tfor _, r := range f.roots {\r\n\t\t\t\tif !fn(r) {\r\n\t\t\t\t\treturn\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":147,"reference":"\/\/ ForEachRoot calls fn with each garbage collection root.\n\/\/ If fn returns false, ForEachRoot returns immediately.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) Addr(x Object) core.Address {\r\n\treturn core.Address(x)\r\n}","code-length":37,"reference":"\/\/ Addr returns the starting address of x.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) Size(x Object) int64 {\r\n\treturn p.findHeapInfo(core.Address(x)).size\r\n}","code-length":44,"reference":"\/\/ Size returns the size of x in bytes.","result":"Avoid panic.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) Type(x Object) (*Type, int64) {\r\n\tp.typeHeap()\r\n\ti, _ := p.findObjectIndex(core.Address(x))\r\n\treturn p.types[i].t, p.types[i].r\r\n}","code-length":77,"reference":"\/\/ Type returns the type and repeat count for the object x.\n\/\/ x contains at least repeat copies of the returned type.","result":"Type the object.","score":[0.0006,0.0476]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) ForEachRootPtr(r *Root, fn func(int64, Object, int64) bool) {\r\n\tedges1(p, r, 0, r.Type, fn)\r\n}","code-length":59,"reference":"\/\/ ForEachRootPtr behaves like ForEachPtr but it starts with a Root instead of an Object.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc edges1(p *Process, r *Root, off int64, t *Type, fn func(int64, Object, int64) bool) bool {\r\n\tswitch t.Kind {\r\n\tcase KindBool, KindInt, KindUint, KindFloat, KindComplex:\r\n\t\t\r\n\tcase KindIface, KindEface:\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\ta := r.Addr.Add(off)\r\n\t\tif r.Frame == nil || r.Frame.Live[a] {\r\n\t\t\tdst, off2 := p.FindObject(p.proc.ReadPtr(a))\r\n\t\t\tif dst != 0 {\r\n\t\t\t\tif !fn(off, dst, off2) {\r\n\t\t\t\t\treturn false\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\toff += p.proc.PtrSize()\r\n\t\tfallthrough\r\n\tcase KindPtr, KindString, KindSlice, KindFunc:\r\n\t\ta := r.Addr.Add(off)\r\n\t\tif r.Frame == nil || r.Frame.Live[a] {\r\n\t\t\tdst, off2 := p.FindObject(p.proc.ReadPtr(a))\r\n\t\t\tif dst != 0 {\r\n\t\t\t\tif !fn(off, dst, off2) {\r\n\t\t\t\t\treturn false\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\tcase KindArray:\r\n\t\ts := t.Elem.Size\r\n\t\tfor i := int64(0); i < t.Count; i++ {\r\n\t\t\tif !edges1(p, r, off+i*s, t.Elem, fn) {\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\t}\r\n\tcase KindStruct:\r\n\t\tfor _, f := range t.Fields {\r\n\t\t\tif !edges1(p, r, off+f.Off, f.Type, fn) {\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":495,"reference":"\/\/ edges1 calls fn for the edges found in an object of type t living at offset off in the root r.\n\/\/ If fn returns false, return immediately with false.","result":"Detect circular references .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) setHeapPtr(a core.Address) {\r\n\th := p.allocHeapInfo(a)\r\n\tif p.proc.PtrSize() == 8 {\r\n\t\ti := uint(a%heapInfoSize) \/ 8\r\n\t\th.ptr[0] |= uint64(1) << i\r\n\t\treturn\r\n\t}\r\n\ti := a % heapInfoSize \/ 4\r\n\th.ptr[i\/64] |= uint64(1) << (i % 64)\r\n}","code-length":133,"reference":"\/\/ setHeapPtr records that the memory at heap address a contains a pointer.","result":"Set the ptr of the heap ptr.","score":[0.0815,0.0806]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) findHeapInfo(a core.Address) *heapInfo {\r\n\tk := a \/ heapInfoSize \/ pageTableSize\r\n\ti := a \/ heapInfoSize % pageTableSize\r\n\tt := p.pageTable[k]\r\n\tif t == nil {\r\n\t\treturn nil\r\n\t}\r\n\th := &t[i]\r\n\tif h.base == 0 {\r\n\t\treturn nil\r\n\t}\r\n\treturn h\r\n}","code-length":124,"reference":"\/\/ findHeapInfo finds the heapInfo structure for a.\n\/\/ Returns nil if a is not a heap address.","result":"Find heap info in the process.","score":[0.0311,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) allocHeapInfo(a core.Address) *heapInfo {\r\n\tk := a \/ heapInfoSize \/ pageTableSize\r\n\ti := a \/ heapInfoSize % pageTableSize\r\n\tt := p.pageTable[k]\r\n\tif t == nil {\r\n\t\tt = new(pageTableEntry)\r\n\t\tfor j := 0; j < pageTableSize; j++ {\r\n\t\t\tt[j].firstIdx = -1\r\n\t\t}\r\n\t\tp.pageTable[k] = t\r\n\t\tp.pages = append(p.pages, k)\r\n\t}\r\n\treturn &t[i]\r\n}","code-length":169,"reference":"\/\/ Same as findHeapInfo, but allocates the heapInfo if it\n\/\/ hasn't been allocated yet.","result":"Allocate heap info.","score":[0,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc runtimeName(dt dwarf.Type) string {\r\n\tswitch x := dt.(type) {\r\n\tcase *dwarf.PtrType:\r\n\t\tif _, ok := x.Type.(*dwarf.VoidType); ok {\r\n\t\t\treturn \"unsafe.Pointer\"\r\n\t\t}\r\n\t\treturn \"*\" + runtimeName(x.Type)\r\n\tcase *dwarf.ArrayType:\r\n\t\treturn fmt.Sprintf(\"[%d]%s\", x.Count, runtimeName(x.Type))\r\n\tcase *dwarf.StructType:\r\n\t\tif !strings.HasPrefix(x.StructName, \"struct {\") {\r\n\t\t\t\r\n\t\t\treturn stripPackagePath(x.StructName)\r\n\t\t}\r\n\t\t\r\n\t\tvar anon []bool\r\n\t\tfor _, f := range strings.Split(x.StructName[8:len(x.StructName)-1], \";\") {\r\n\t\t\tf = strings.TrimSpace(f)\r\n\t\t\tanon = append(anon, !strings.Contains(f, \" \"))\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t}\r\n\t\t\r\n\t\tfor len(anon) < len(x.Field) {\r\n\t\t\tanon = append(anon, false)\r\n\t\t}\r\n\t\t\r\n\t\ts := \"struct {\"\r\n\t\tfirst := true\r\n\t\tfor _, f := range x.Field {\r\n\t\t\tif !first {\r\n\t\t\t\ts += \";\"\r\n\t\t\t}\r\n\t\t\tname := f.Name\r\n\t\t\tif i := strings.Index(name, \".\"); i >= 0 {\r\n\t\t\t\tname = name[i+1:]\r\n\t\t\t}\r\n\t\t\tif anon[0] {\r\n\t\t\t\ts += fmt.Sprintf(\" %s\", runtimeName(f.Type))\r\n\t\t\t} else {\r\n\t\t\t\ts += fmt.Sprintf(\" %s %s\", name, runtimeName(f.Type))\r\n\t\t\t}\r\n\t\t\tfirst = false\r\n\t\t\tanon = anon[1:]\r\n\t\t}\r\n\t\ts += \" }\"\r\n\t\treturn s\r\n\tdefault:\r\n\t\treturn stripPackagePath(dt.String())\r\n\t}\r\n}","code-length":553,"reference":"\/\/ Generate the name the runtime uses for a dwarf type. The DWARF generator\n\/\/ and the runtime use slightly different names for the same underlying type.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) readRuntimeConstants() {\r\n\tp.rtConstants = map[string]int64{}\r\n\t\r\n\t\r\n\tm := p.rtConstants\r\n\tm[\"_MSpanDead\"] = 0\r\n\tm[\"_MSpanInUse\"] = 1\r\n\tm[\"_MSpanManual\"] = 2\r\n\tm[\"_MSpanFree\"] = 3\r\n\tm[\"_Gidle\"] = 0\r\n\tm[\"_Grunnable\"] = 1\r\n\tm[\"_Grunning\"] = 2\r\n\tm[\"_Gsyscall\"] = 3\r\n\tm[\"_Gwaiting\"] = 4\r\n\tm[\"_Gdead\"] = 6\r\n\tm[\"_Gscan\"] = 0x1000\r\n\tm[\"_PCDATA_StackMapIndex\"] = 0\r\n\tm[\"_FUNCDATA_LocalsPointerMaps\"] = 1\r\n\tm[\"_FUNCDATA_ArgsPointerMaps\"] = 0\r\n\tm[\"tflagExtraStar\"] = 1 << 1\r\n\tm[\"kindGCProg\"] = 1 << 6\r\n\tm[\"kindDirectIface\"] = 1 << 5\r\n\tm[\"_PageSize\"] = 1 << 13\r\n\tm[\"_KindSpecialFinalizer\"] = 1\r\n\t\r\n\td, _ := p.proc.DWARF()\r\n\tr := d.Reader()\r\n\tfor e, err := r.Next(); e != nil && err == nil; e, err = r.Next() {\r\n\t\tif e.Tag != dwarf.TagConstant {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tf := e.AttrField(dwarf.AttrName)\r\n\t\tif f == nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tname := f.Val.(string)\r\n\t\tif !strings.HasPrefix(name, \"runtime.\") {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tname = name[8:]\r\n\t\tc := e.AttrField(dwarf.AttrConstValue)\r\n\t\tif c == nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tp.rtConstants[name] = c.Val.(int64)\r\n\t}\r\n}","code-length":528,"reference":"\/\/ readRuntimeConstants populates the p.rtConstants map.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *funcTab) add(min, max core.Address, f *Func) {\r\n\tt.entries = append(t.entries, funcTabEntry{min: min, max: max, f: f})\r\n}","code-length":62,"reference":"\/\/ add records that PCs in the range [min,max) map to function f.","result":"Create a new funcTab.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *funcTab) sort() {\r\n\tsort.Slice(t.entries, func(i, j int) bool {\r\n\t\treturn t.entries[i].min < t.entries[j].min\r\n\t})\r\n}","code-length":66,"reference":"\/\/ sort must be called after all the adds, but before any find.","result":"Sort the functions in the function tab.","score":[0.0685,0.0806]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *funcTab) find(pc core.Address) *Func {\r\n\tn := sort.Search(len(t.entries), func(i int) bool {\r\n\t\treturn t.entries[i].max > pc\r\n\t})\r\n\tif n == len(t.entries) || pc < t.entries[n].min || pc >= t.entries[n].max {\r\n\t\treturn nil\r\n\t}\r\n\treturn t.entries[n].f\r\n}","code-length":123,"reference":"\/\/ Finds a Func for the given address.  Sort must have been called already.","result":"Find the function in the function tab.","score":[0.0594,0.0752]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *pcTab) read(core *core.Process, data core.Address) {\r\n\tvar pcQuantum int64\r\n\tswitch core.Arch() {\r\n\tcase \"386\", \"amd64\", \"amd64p32\":\r\n\t\tpcQuantum = 1\r\n\tcase \"s390x\":\r\n\t\tpcQuantum = 2\r\n\tcase \"arm\", \"arm64\", \"mips\", \"mipsle\", \"mips64\", \"mips64le\", \"ppc64\", \"ppc64le\":\r\n\t\tpcQuantum = 4\r\n\tdefault:\r\n\t\tpanic(\"unknown architecture \" + core.Arch())\r\n\t}\r\n\tval := int64(-1)\r\n\tfirst := true\r\n\tfor {\r\n\t\t\r\n\t\tv, n := readVarint(core, data)\r\n\t\tif v == 0 && !first {\r\n\t\t\treturn\r\n\t\t}\r\n\t\tdata = data.Add(n)\r\n\t\tif v&1 != 0 {\r\n\t\t\tval += ^(v >> 1)\r\n\t\t} else {\r\n\t\t\tval += v >> 1\r\n\t\t}\r\n\t\t\r\n\t\tv, n = readVarint(core, data)\r\n\t\tdata = data.Add(n)\r\n\t\tt.entries = append(t.entries, pcTabEntry{bytes: v * pcQuantum, val: val})\r\n\t\tfirst = false\r\n\t}\r\n}","code-length":361,"reference":"\/\/ read parses a pctab from the core file at address data.","result":"Read the pc tab .","score":[0.0593,0.0885]}
{"code":"\/*is used to<extra_id_0>\r\nfunc readVarint(core *core.Process, a core.Address) (val, n int64) {\r\n\tfor {\r\n\t\tb := core.ReadUint8(a)\r\n\t\tval |= int64(b&0x7f) << uint(n*7)\r\n\t\tn++\r\n\t\ta++\r\n\t\tif b&0x80 == 0 {\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":116,"reference":"\/\/ readVarint reads a varint from the core file.\n\/\/ val is the value, n is the number of bytes consumed.","result":"Read varint .","score":[0.001,0.0521]}
{"code":"\/*is used to<extra_id_0>\r\nfunc useLine(c *cobra.Command) string {\r\n\tvar useline string\r\n\tif c.HasParent() {\r\n\t\tuseline = commandPath(c.Parent()) + \" \" + c.Use\r\n\t} else {\r\n\t\tuseline = c.Use\r\n\t}\r\n\tif c.DisableFlagsInUseLine {\r\n\t\treturn useline\r\n\t}\r\n\tif c.HasAvailableFlags() && !strings.Contains(useline, \"[flags]\") {\r\n\t\tuseline += \" [flags]\"\r\n\t}\r\n\treturn useline\r\n}","code-length":151,"reference":"\/\/ useLine is like cobra.Command.UseLine but tweaked to use commandPath.","result":"Generate the useLine function.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc commandPath(c *cobra.Command) string {\r\n\tif c.HasParent() {\r\n\t\treturn commandPath(c) + \" \" + c.Name()\r\n\t}\r\n\treturn c.Use\r\n}","code-length":65,"reference":"\/\/ commandPath is like cobra.Command.CommandPath but tweaked to\n\/\/ use c.Use instead of c.Name for the root command so it works\n\/\/ with viewcore's unusual command structure.","result":"Generate the command path.","score":[0.0012,0.0405]}
{"code":"\/*is used to<extra_id_0>\r\nfunc readCore() (*core.Process, *gocore.Process, error) {\r\n\tcc := coreCache\r\n\tif cc.cfg == cfg {\r\n\t\treturn cc.coreP, cc.gocoreP, cc.err\r\n\t}\r\n\tc, err := core.Core(cfg.corefile, cfg.base, cfg.exePath)\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\tp, err := gocore.Core(c)\r\n\tif os.IsNotExist(err) && cfg.exePath == \"\" {\r\n\t\treturn nil, nil, fmt.Errorf(\"%v; consider specifying the --exe flag\", err)\r\n\t}\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\tfor _, w := range c.Warnings() {\r\n\t\tfmt.Fprintf(os.Stderr, \"WARNING: %s\\n\", w)\r\n\t}\r\n\tcc.cfg = cfg\r\n\tcc.coreP = c\r\n\tcc.gocoreP = p\r\n\tcc.err = nil\r\n\treturn c, p, nil\r\n}","code-length":289,"reference":"\/\/ readCore reads corefile and returns core and gocore process states.","result":"Read the core file.","score":[0.0555,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc typeName(c *gocore.Process, x gocore.Object) string {\r\n\tsize := c.Size(x)\r\n\ttyp, repeat := c.Type(x)\r\n\tif typ == nil {\r\n\t\treturn fmt.Sprintf(\"unk%d\", size)\r\n\t}\r\n\tname := typ.String()\r\n\tn := size \/ typ.Size\r\n\tif n > 1 {\r\n\t\tif repeat < n {\r\n\t\t\tname = fmt.Sprintf(\"[%d+%d?]%s\", repeat, n-repeat, name)\r\n\t\t} else {\r\n\t\t\tname = fmt.Sprintf(\"[%d]%s\", repeat, name)\r\n\t\t}\r\n\t}\r\n\treturn name\r\n}","code-length":190,"reference":"\/\/ typeName returns a string representing the type of this object.","result":"Generate the name of the type .","score":[0.1427,0.2411]}
{"code":"\/*is used to<extra_id_0>\r\nfunc fieldName(c *gocore.Process, x gocore.Object, off int64) string {\r\n\tsize := c.Size(x)\r\n\ttyp, repeat := c.Type(x)\r\n\tif typ == nil {\r\n\t\treturn fmt.Sprintf(\"f%d\", off)\r\n\t}\r\n\tn := size \/ typ.Size\r\n\ti := off \/ typ.Size\r\n\tif i == 0 && repeat == 1 {\r\n\t\t\r\n\t\treturn typeFieldName(typ, off)\r\n\t}\r\n\tif i >= n {\r\n\t\t\r\n\t\treturn fmt.Sprintf(\"f%d\", off)\r\n\t}\r\n\tq := \"\"\r\n\tif i >= repeat {\r\n\t\t\r\n\t\tq = \"?\"\r\n\t}\r\n\treturn fmt.Sprintf(\"[%d]%s%s\", i, typeFieldName(typ, off-i*typ.Size), q)\r\n}","code-length":231,"reference":"\/\/ fieldName returns the name of the field at offset off in x.","result":"Generate the field name.","score":[0.0476,0.155]}
{"code":"\/*is used to<extra_id_0>\r\nfunc typeFieldName(t *gocore.Type, off int64) string {\r\n\tswitch t.Kind {\r\n\tcase gocore.KindBool, gocore.KindInt, gocore.KindUint, gocore.KindFloat:\r\n\t\treturn \"\"\r\n\tcase gocore.KindComplex:\r\n\t\tif off == 0 {\r\n\t\t\treturn \".real\"\r\n\t\t}\r\n\t\treturn \".imag\"\r\n\tcase gocore.KindIface, gocore.KindEface:\r\n\t\tif off == 0 {\r\n\t\t\treturn \".type\"\r\n\t\t}\r\n\t\treturn \".data\"\r\n\tcase gocore.KindPtr, gocore.KindFunc:\r\n\t\treturn \"\"\r\n\tcase gocore.KindString:\r\n\t\tif off == 0 {\r\n\t\t\treturn \".ptr\"\r\n\t\t}\r\n\t\treturn \".len\"\r\n\tcase gocore.KindSlice:\r\n\t\tif off == 0 {\r\n\t\t\treturn \".ptr\"\r\n\t\t}\r\n\t\tif off <= t.Size\/2 {\r\n\t\t\treturn \".len\"\r\n\t\t}\r\n\t\treturn \".cap\"\r\n\tcase gocore.KindArray:\r\n\t\ts := t.Elem.Size\r\n\t\ti := off \/ s\r\n\t\treturn fmt.Sprintf(\"[%d]%s\", i, typeFieldName(t.Elem, off-i*s))\r\n\tcase gocore.KindStruct:\r\n\t\tfor _, f := range t.Fields {\r\n\t\t\tif f.Off <= off && off < f.Off+f.Type.Size {\r\n\t\t\t\treturn \".\" + f.Name + typeFieldName(f.Type, off-f.Off)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn \".???\"\r\n}","code-length":441,"reference":"\/\/ typeFieldName returns the name of the field at offset off in t.","result":"Generate the type field name .","score":[0.0791,0.122]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) FindFunc(pc core.Address) *Func {\r\n\treturn p.funcTab.find(pc)\r\n}","code-length":42,"reference":"\/\/ FindFunc returns the function which contains the code at address pc, if any.","result":"Find functions in the code.","score":[0.0397,0.0763]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Core(proc *core.Process) (p *Process, err error) {\r\n\t\r\n\tif _, err := proc.DWARF(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\t\r\n\tp = &Process{\r\n\t\tproc:       proc,\r\n\t\truntimeMap: map[core.Address]*Type{},\r\n\t\tdwarfMap:   map[dwarf.Type]*Type{},\r\n\t}\r\n\t\r\n\tp.readDWARFTypes()\r\n\tp.readRuntimeConstants()\r\n\tp.readGlobals()\r\n\t\r\n\tp.rtGlobals = map[string]region{}\r\n\tfor _, g := range p.globals {\r\n\t\tif strings.HasPrefix(g.Name, \"runtime.\") {\r\n\t\t\tp.rtGlobals[g.Name[8:]] = region{p: p, a: g.Addr, typ: g.Type}\r\n\t\t}\r\n\t}\r\n\t\r\n\tp.buildVersion = p.rtGlobals[\"buildVersion\"].String()\r\n\tp.readModules()\r\n\tp.readHeap()\r\n\tp.readGs()\r\n\tp.readStackVars()\r\n\tp.markObjects()\r\n\treturn p, nil\r\n}","code-length":322,"reference":"\/\/ Core takes a loaded core file and extracts Go information from it.","result":"Initialize the core .","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r region) Address() core.Address {\r\n\tif r.typ.Kind != KindPtr {\r\n\t\tpanic(\"can't ask for the Address of a non-pointer \" + r.typ.Name)\r\n\t}\r\n\treturn r.p.proc.ReadPtr(r.a)\r\n}","code-length":83,"reference":"\/\/ Address returns the address that a region of pointer type points to.","result":"Generate the address of the region.","score":[0.0941,0.122]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r region) Int() int64 {\r\n\tif r.typ.Kind != KindInt || r.typ.Size != r.p.proc.PtrSize() {\r\n\t\tpanic(\"not an int: \" + r.typ.Name)\r\n\t}\r\n\treturn r.p.proc.ReadInt(r.a)\r\n}","code-length":91,"reference":"\/\/ Int returns the int value stored in r.","result":"Get the region.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r region) Uintptr() uint64 {\r\n\tif r.typ.Kind != KindUint || r.typ.Size != r.p.proc.PtrSize() {\r\n\t\tpanic(\"not a uintptr: \" + r.typ.Name)\r\n\t}\r\n\treturn r.p.proc.ReadUintptr(r.a)\r\n}","code-length":93,"reference":"\/\/ Uintptr returns the uintptr value stored in r.","result":"Get the ptr of a region.","score":[0.1171,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r region) Cast(typ string) region {\r\n\treturn region{p: r.p, a: r.a, typ: r.p.findType(typ)}\r\n}","code-length":53,"reference":"\/\/ Cast the region to the given type.","result":"Cast the region.","score":[0.109,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r region) Deref() region {\r\n\tif r.typ.Kind != KindPtr {\r\n\t\tpanic(\"can't deref on non-pointer: \" + r.typ.Name)\r\n\t}\r\n\tif r.typ.Elem == nil {\r\n\t\tpanic(\"can't deref unsafe.Pointer\")\r\n\t}\r\n\tp := r.p.proc.ReadPtr(r.a)\r\n\treturn region{p: r.p, a: p, typ: r.typ.Elem}\r\n}","code-length":137,"reference":"\/\/ Deref loads from a pointer. r must contain a pointer.","result":"Dereference pointers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r region) Uint64() uint64 {\r\n\tif r.typ.Kind != KindUint || r.typ.Size != 8 {\r\n\t\tpanic(\"bad uint64 type \" + r.typ.Name)\r\n\t}\r\n\treturn r.p.proc.ReadUint64(r.a)\r\n}","code-length":85,"reference":"\/\/ Uint64 returns the uint64 value stored in r.\n\/\/ r must have type uint64.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r region) Uint32() uint32 {\r\n\tif r.typ.Kind != KindUint || r.typ.Size != 4 {\r\n\t\tpanic(\"bad uint32 type \" + r.typ.Name)\r\n\t}\r\n\treturn r.p.proc.ReadUint32(r.a)\r\n}","code-length":85,"reference":"\/\/ Uint32 returns the uint32 value stored in r.\n\/\/ r must have type uint32.","result":"Values from the region.","score":[0.0204,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r region) Int32() int32 {\r\n\tif r.typ.Kind != KindInt || r.typ.Size != 4 {\r\n\t\tpanic(\"bad int32 type \" + r.typ.Name)\r\n\t}\r\n\treturn r.p.proc.ReadInt32(r.a)\r\n}","code-length":85,"reference":"\/\/ Int32 returns the int32 value stored in r.\n\/\/ r must have type int32.","result":"Create a new region.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r region) Uint16() uint16 {\r\n\tif r.typ.Kind != KindUint || r.typ.Size != 2 {\r\n\t\tpanic(\"bad uint16 type \" + r.typ.Name)\r\n\t}\r\n\treturn r.p.proc.ReadUint16(r.a)\r\n}","code-length":85,"reference":"\/\/ Uint16 returns the uint16 value stored in r.\n\/\/ r must have type uint16.","result":"Value of a region.","score":[0,0.036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r region) Uint8() uint8 {\r\n\tif r.typ.Kind != KindUint || r.typ.Size != 1 {\r\n\t\tpanic(\"bad uint8 type \" + r.typ.Name)\r\n\t}\r\n\treturn r.p.proc.ReadUint8(r.a)\r\n}","code-length":85,"reference":"\/\/ Uint8 returns the uint8 value stored in r.\n\/\/ r must have type uint8.","result":"Generated by gen.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r region) String() string {\r\n\tif r.typ.Kind != KindString {\r\n\t\tpanic(\"bad string type \" + r.typ.Name)\r\n\t}\r\n\tp := r.p.proc.ReadPtr(r.a)\r\n\tn := r.p.proc.ReadUintptr(r.a.Add(r.p.proc.PtrSize()))\r\n\tb := make([]byte, n)\r\n\tr.p.proc.ReadAt(b, p)\r\n\treturn string(b)\r\n}","code-length":141,"reference":"\/\/ String returns the value of the string stored in r.","result":"Construct a string region.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r region) SlicePtr() region {\r\n\tif r.typ.Kind != KindSlice {\r\n\t\tpanic(\"can't Ptr a non-slice\")\r\n\t}\r\n\treturn region{p: r.p, a: r.a, typ: &Type{Name: \"*\" + r.typ.Name[2:], Size: r.p.proc.PtrSize(), Kind: KindPtr, Elem: r.typ.Elem}}\r\n}","code-length":114,"reference":"\/\/ SlicePtr returns the pointer inside a slice. r must contain a slice.","result":"Create a slice pointer.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r region) SliceLen() int64 {\r\n\tif r.typ.Kind != KindSlice {\r\n\t\tpanic(\"can't len a non-slice\")\r\n\t}\r\n\treturn r.p.proc.ReadInt(r.a.Add(r.p.proc.PtrSize()))\r\n}","code-length":84,"reference":"\/\/ SliceLen returns the length of a slice. r must contain a slice.","result":"Generate the slice length .","score":[0.0577,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r region) Field(f string) region {\r\n\tfinfo := r.typ.field(f)\r\n\tif finfo == nil {\r\n\t\tpanic(\"can't find field \" + r.typ.Name + \".\" + f)\r\n\t}\r\n\treturn region{p: r.p, a: r.a.Add(finfo.Off), typ: finfo.Type}\r\n}","code-length":104,"reference":"\/\/ Field returns the part of r which contains the field f.\n\/\/ r must contain a struct, and f must be one of its fields.","result":"Construct field regions.","score":[0.0002,0.0211]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) ReadUint8(a Address) uint8 {\r\n\tm := p.findMapping(a)\r\n\tif m == nil {\r\n\t\tpanic(fmt.Errorf(\"address %x is not mapped in the core file\", a))\r\n\t}\r\n\treturn m.contents[a.Sub(m.min)]\r\n}","code-length":92,"reference":"\/\/ ReadUint8 returns a uint8 read from address a of the inferior.","result":"From core file.","score":[0,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) ReadUint16(a Address) uint16 {\r\n\tm := p.findMapping(a)\r\n\tif m == nil {\r\n\t\tpanic(fmt.Errorf(\"address %x is not mapped in the core file\", a))\r\n\t}\r\n\tb := m.contents[a.Sub(m.min):]\r\n\tif len(b) < 2 {\r\n\t\tvar buf [2]byte\r\n\t\tb = buf[:]\r\n\t\tp.ReadAt(b, a)\r\n\t}\r\n\tif p.littleEndian {\r\n\t\treturn binary.LittleEndian.Uint16(b)\r\n\t}\r\n\treturn binary.BigEndian.Uint16(b)\r\n}","code-length":183,"reference":"\/\/ ReadUint16 returns a uint16 read from address a of the inferior.","result":"From the core file.","score":[0.0432,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) ReadUint32(a Address) uint32 {\r\n\tm := p.findMapping(a)\r\n\tif m == nil {\r\n\t\tpanic(fmt.Errorf(\"address %x is not mapped in the core file\", a))\r\n\t}\r\n\tb := m.contents[a.Sub(m.min):]\r\n\tif len(b) < 4 {\r\n\t\tvar buf [4]byte\r\n\t\tb = buf[:]\r\n\t\tp.ReadAt(b, a)\r\n\t}\r\n\tif p.littleEndian {\r\n\t\treturn binary.LittleEndian.Uint32(b)\r\n\t}\r\n\treturn binary.BigEndian.Uint32(b)\r\n}","code-length":183,"reference":"\/\/ ReadUint32 returns a uint32 read from address a of the inferior.","result":"From the core file.","score":[0.0432,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) ReadUint64(a Address) uint64 {\r\n\tm := p.findMapping(a)\r\n\tif m == nil {\r\n\t\tpanic(fmt.Errorf(\"address %x is not mapped in the core file\", a))\r\n\t}\r\n\tb := m.contents[a.Sub(m.min):]\r\n\tif len(b) < 8 {\r\n\t\tvar buf [8]byte\r\n\t\tb = buf[:]\r\n\t\tp.ReadAt(b, a)\r\n\t}\r\n\tif p.littleEndian {\r\n\t\treturn binary.LittleEndian.Uint64(b)\r\n\t}\r\n\treturn binary.BigEndian.Uint64(b)\r\n}","code-length":183,"reference":"\/\/ ReadUint64 returns a uint64 read from address a of the inferior.","result":"From the core file.","score":[0.0432,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) ReadInt8(a Address) int8 {\r\n\treturn int8(p.ReadUint8(a))\r\n}","code-length":43,"reference":"\/\/ ReadInt8 returns an int8 read from address a of the inferior.","result":"From address.","score":[0,0.0455]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) ReadInt16(a Address) int16 {\r\n\treturn int16(p.ReadUint16(a))\r\n}","code-length":43,"reference":"\/\/ ReadInt16 returns an int16 read from address a of the inferior.","result":"From a address.","score":[0.0203,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) ReadInt32(a Address) int32 {\r\n\treturn int32(p.ReadUint32(a))\r\n}","code-length":43,"reference":"\/\/ ReadInt32 returns an int32 read from address a of the inferior.","result":"Read uint.","score":[0,0.0455]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) ReadInt64(a Address) int64 {\r\n\treturn int64(p.ReadUint64(a))\r\n}","code-length":43,"reference":"\/\/ ReadInt64 returns an int64 read from address a of the inferior.","result":"Generate the code.","score":[0.0203,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) ReadUintptr(a Address) uint64 {\r\n\tif p.ptrSize == 4 {\r\n\t\treturn uint64(p.ReadUint32(a))\r\n\t}\r\n\treturn p.ReadUint64(a)\r\n}","code-length":71,"reference":"\/\/ ReadUintptr returns a uint of pointer size read from address a of the inferior.","result":"Read uintptr from a address.","score":[0.0387,0.1071]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) ReadPtr(a Address) Address {\r\n\treturn Address(p.ReadUintptr(a))\r\n}","code-length":40,"reference":"\/\/ ReadPtr returns a pointer loaded from address a of the inferior.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) ReadCString(a Address) string {\r\n\tfor n := int64(0); ; n++ {\r\n\t\tif p.ReadUint8(a.Add(n)) == 0 {\r\n\t\t\tb := make([]byte, n)\r\n\t\t\tp.ReadAt(b, a)\r\n\t\t\treturn string(b)\r\n\t\t}\r\n\t}\r\n}","code-length":106,"reference":"\/\/ ReadCString reads a null-terminated string starting at address a.","result":"String from a address.","score":[0.0713,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Mapping) Source() (string, int64) {\r\n\tif m.f == nil {\r\n\t\treturn \"\", 0\r\n\t}\r\n\treturn m.f.Name(), m.off\r\n}","code-length":61,"reference":"\/\/ Source returns the backing file and offset for the mapping, or \"\", 0 if none.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) findMapping(a Address) *Mapping {\r\n\tt3 := p.pageTable[a>>52]\r\n\tif t3 == nil {\r\n\t\treturn nil\r\n\t}\r\n\tt2 := t3[a>>42%(1<<10)]\r\n\tif t2 == nil {\r\n\t\treturn nil\r\n\t}\r\n\tt1 := t2[a>>32%(1<<10)]\r\n\tif t1 == nil {\r\n\t\treturn nil\r\n\t}\r\n\tt0 := t1[a>>22%(1<<10)]\r\n\tif t0 == nil {\r\n\t\treturn nil\r\n\t}\r\n\treturn t0[a>>12%(1<<10)]\r\n}","code-length":184,"reference":"\/\/ findMapping is simple enough that it inlines.","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a Address) Max(b Address) Address {\r\n\tif a > b {\r\n\t\treturn a\r\n\t}\r\n\treturn b\r\n}","code-length":47,"reference":"\/\/ Max returns the larger of a and b.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a Address) Min(b Address) Address {\r\n\tif a < b {\r\n\t\treturn a\r\n\t}\r\n\treturn b\r\n}","code-length":47,"reference":"\/\/ Min returns the smaller of a and b.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a Address) Align(x int64) Address {\r\n\treturn (a + Address(x) - 1) & ^(Address(x) - 1)\r\n}","code-length":48,"reference":"\/\/ Align rounds a up to a multiple of x.\n\/\/ x must be a power of 2.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *ltDom) initialize() {\r\n\ttype workItem struct {\r\n\t\tname       vName\r\n\t\tparentName vName\r\n\t}\r\n\t\r\n\ti := 0\r\n\td.p.ForEachObject(func(x Object) bool {\r\n\t\td.objs[i] = x\r\n\t\ti++\r\n\t\treturn true\r\n\t})\r\n\t\r\n\t\r\n\td.semis[pseudoRoot] = 0\r\n\td.parents[pseudoRoot] = -1\r\n\td.vertices[0] = pseudoRoot\r\n\tvar work []workItem\r\n\tfor i := 1; i < 1+d.nRoots; i++ {\r\n\t\twork = append(work, workItem{name: vName(i), parentName: 0})\r\n\t}\r\n\tn := vNumber(1)\r\n\t\r\n\t\r\n\tfor len(work) != 0 {\r\n\t\titem := work[len(work)-1]\r\n\t\twork = work[:len(work)-1]\r\n\t\tif d.semis[item.name] != -1 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\td.semis[item.name] = n\r\n\t\td.parents[item.name] = item.parentName\r\n\t\td.vertices[n] = item.name\r\n\t\tn++\r\n\t\tvisitChild := func(_ int64, child Object, _ int64) bool {\r\n\t\t\tchildIdx, _ := d.p.findObjectIndex(d.p.Addr(child))\r\n\t\t\twork = append(work, workItem{name: vName(childIdx + d.nRoots + 1), parentName: item.name})\r\n\t\t\treturn true\r\n\t\t}\r\n\t\troot, object := d.findVertexByName(item.name)\r\n\t\tif root != nil {\r\n\t\t\td.p.ForEachRootPtr(root, visitChild)\r\n\t\t} else {\r\n\t\t\td.p.ForEachPtr(object, visitChild)\r\n\t\t}\r\n\t}\r\n}","code-length":509,"reference":"\/\/ initialize implements step 1 of LT.","result":"Initialize the ltDom .","score":[0,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *ltDom) calculate() {\r\n\t\r\n\tbuckets := make([]vName, d.nVertices)\r\n\tfor i := range buckets {\r\n\t\tbuckets[i] = vName(i)\r\n\t}\r\n\tfor i := vNumber(len(d.vertices)) - 1; i > 0; i-- {\r\n\t\tw := d.vertices[i]\r\n\t\t\r\n\t\tfor v := buckets[w]; v != w; v = buckets[v] {\r\n\t\t\tu := d.eval(v)\r\n\t\t\tif d.semis[u] < d.semis[v] {\r\n\t\t\t\td.idom[v] = u\r\n\t\t\t} else {\r\n\t\t\t\td.idom[v] = w\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\troot, obj := d.findVertexByName(w)\r\n\t\t\r\n\t\tif root != nil {\r\n\t\t\tu := d.eval(pseudoRoot)\r\n\t\t\tif d.semis[u] < d.semis[w] {\r\n\t\t\t\td.semis[w] = d.semis[u]\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\td.p.ForEachReversePtr(obj, func(x Object, r *Root, _, _ int64) bool {\r\n\t\t\t\tvar v int\r\n\t\t\t\tif r != nil {\r\n\t\t\t\t\tv = d.p.findRootIndex(r) + 1\r\n\t\t\t\t} else {\r\n\t\t\t\t\tv, _ = d.p.findObjectIndex(d.p.Addr(x))\r\n\t\t\t\t\tv += d.nRoots + 1\r\n\t\t\t\t}\r\n\t\t\t\tu := d.eval(vName(v))\r\n\t\t\t\tif d.semis[u] < d.semis[w] {\r\n\t\t\t\t\td.semis[w] = d.semis[u]\r\n\t\t\t\t}\r\n\t\t\t\treturn true\r\n\t\t\t})\r\n\t\t}\r\n\t\td.link(d.parents[w], w)\r\n\t\tif d.parents[w] == d.vertices[d.semis[w]] {\r\n\t\t\td.idom[w] = d.parents[w]\r\n\t\t} else {\r\n\t\t\tbuckets[w] = buckets[d.vertices[d.semis[w]]]\r\n\t\t\tbuckets[d.vertices[d.semis[w]]] = w\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor v := buckets[pseudoRoot]; v != pseudoRoot; v = buckets[v] {\r\n\t\td.idom[v] = pseudoRoot\r\n\t}\r\n\t\r\n\t\r\n\tfor _, w := range d.vertices[1:] {\r\n\t\tif d.idom[w] != d.vertices[d.semis[w]] {\r\n\t\t\td.idom[w] = d.idom[d.idom[w]]\r\n\t\t}\r\n\t}\r\n}","code-length":733,"reference":"\/\/ calculate runs the main part of LT.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *ltDom) eval(v vName) vName {\r\n\tif d.ancestor[v] == -1 {\r\n\t\treturn v\r\n\t}\r\n\td.compress(v)\r\n\treturn d.labels[v]\r\n}","code-length":71,"reference":"\/\/ eval is EVAL from the papers.","result":"Evaluate the expression.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *ltDom) compress(v vName) {\r\n\tvar stackBuf [20]vName\r\n\tstack := stackBuf[:0]\r\n\tfor d.ancestor[d.ancestor[v]] != -1 {\r\n\t\tstack = append(stack, v)\r\n\t\tv = d.ancestor[v]\r\n\t}\r\n\tfor len(stack) != 0 {\r\n\t\tv := stack[len(stack)-1]\r\n\t\tstack = stack[:len(stack)-1]\r\n\t\tif d.semis[d.labels[d.ancestor[v]]] < d.semis[d.labels[v]] {\r\n\t\t\td.labels[v] = d.labels[d.ancestor[v]]\r\n\t\t}\r\n\t\td.ancestor[v] = d.ancestor[d.ancestor[v]]\r\n\t}\r\n}","code-length":217,"reference":"\/\/ compress is COMPRESS from the papers.","result":"Compress the tree.","score":[0.1076,0.1515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *ltDom) link(v, w vName) {\r\n\td.ancestor[w] = v\r\n}","code-length":39,"reference":"\/\/ link is LINK from the papers.","result":"Generate the code.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *dominators) reverse() {\r\n\t\r\n\t\r\n\t\r\n\tcnt := make([]int, len(d.idom)+2)\r\n\t\r\n\ttmp := cnt[2:]\r\n\tfor _, idom := range d.idom {\r\n\t\ttmp[idom]++\r\n\t}\r\n\t\r\n\t\r\n\tvar n int\r\n\tfor idx, c := range tmp {\r\n\t\tn += c\r\n\t\ttmp[idx] = n\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tredge := make([]vName, len(d.idom))\r\n\ttmp = cnt[1:]\r\n\tfor i, idom := range d.idom {\r\n\t\tredge[tmp[idom]] = vName(i)\r\n\t\ttmp[idom]++\r\n\t}\r\n\td.redge, d.ridx = redge, cnt[:len(cnt)-1]\r\n}","code-length":243,"reference":"\/\/ reverse computes and stores reverse edges for each vertex.","result":"Reverse the dominators .","score":[0,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *dominators) calcSize(p *Process) {\r\n\td.size = make([]int64, len(d.idom))\r\n\ttype workItem struct {\r\n\t\tv    vName\r\n\t\tmode dfsMode\r\n\t}\r\n\twork := []workItem{{pseudoRoot, down}}\r\n\tfor len(work) > 0 {\r\n\t\titem := &work[len(work)-1]\r\n\t\tkids := d.redge[d.ridx[item.v]:d.ridx[item.v+1]]\r\n\t\tif item.mode == down && len(kids) != 0 {\r\n\t\t\titem.mode = up\r\n\t\t\tfor _, w := range kids {\r\n\t\t\t\tif w == 0 {\r\n\t\t\t\t\t\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\twork = append(work, workItem{w, down})\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\twork = work[:len(work)-1]\r\n\t\troot, obj := d.findVertexByName(item.v)\r\n\t\tvar size int64\r\n\t\tswitch {\r\n\t\tcase item.v == pseudoRoot:\r\n\t\t\tbreak\r\n\t\tcase root != nil:\r\n\t\t\tsize += root.Type.Size\r\n\t\tdefault:\r\n\t\t\tsize += p.Size(obj)\r\n\t\t}\r\n\t\tfor _, w := range kids {\r\n\t\t\tsize += d.size[w]\r\n\t\t}\r\n\t\td.size[item.v] = size\r\n\t}\r\n}","code-length":395,"reference":"\/\/ calcSize calculates the total retained size for each vertex.","result":"Calculate the size of the dominators.","score":[0.1179,0.1562]}
{"code":"\/*is used to<extra_id_0>\r\nfunc objField(c *gocore.Process, x gocore.Object, off int64) string {\r\n\tt, r := c.Type(x)\r\n\tif t == nil {\r\n\t\treturn fmt.Sprintf(\"f%d\", off)\r\n\t}\r\n\ts := \"\"\r\n\tif r > 1 {\r\n\t\ts = fmt.Sprintf(\"[%d]\", off\/t.Size)\r\n\t\toff %= t.Size\r\n\t}\r\n\treturn s + typeFieldName(t, off)\r\n}","code-length":138,"reference":"\/\/ Returns the name of the field at offset off in x.","result":"Generate the field name.","score":[0.0611,0.1674]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) Readable(a Address) bool {\r\n\treturn p.findMapping(a) != nil\r\n}","code-length":38,"reference":"\/\/ Readable reports whether the address a is readable.","result":"Detect the error.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) ReadableN(a Address, n int64) bool {\r\n\tfor {\r\n\t\tm := p.findMapping(a)\r\n\t\tif m == nil || m.perm&Read == 0 {\r\n\t\t\treturn false\r\n\t\t}\r\n\t\tc := m.max.Sub(a)\r\n\t\tif n <= c {\r\n\t\t\treturn true\r\n\t\t}\r\n\t\tn -= c\r\n\t\ta = a.Add(c)\r\n\t}\r\n}","code-length":133,"reference":"\/\/ ReadableN reports whether the n bytes starting at address a are readable.","result":"Avoid the need for the function .","score":[0.0685,0.0403]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) splitMappingsAt(a Address) {\r\n\tfor _, m := range p.memory.mappings {\r\n\t\tif a < m.min || a > m.max {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif a == m.min || a == m.max {\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\tm2 := new(Mapping)\r\n\t\t*m2 = *m\r\n\t\tm.max = a\r\n\t\tm2.min = a\r\n\t\tif m2.f != nil {\r\n\t\t\tm2.off += m.Size()\r\n\t\t}\r\n\t\tif m2.origF != nil {\r\n\t\t\tm2.origOff += m.Size()\r\n\t\t}\r\n\t\tp.memory.mappings = append(p.memory.mappings, m2)\r\n\t\treturn\r\n\t}\r\n}","code-length":230,"reference":"\/\/ splitMappingsAt ensures that a is not in the middle of any mapping.\n\/\/ Splits mappings as necessary.","result":"Split the mappings in a single file.","score":[0.0474,0.1479]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Process) DynamicType(t *Type, a core.Address) *Type {\r\n\tswitch t.Kind {\r\n\tdefault:\r\n\t\tpanic(\"asking for the dynamic type of a non-interface\")\r\n\tcase KindEface:\r\n\t\tx := p.proc.ReadPtr(a)\r\n\t\tif x == 0 {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\treturn p.runtimeType2Type(x)\r\n\tcase KindIface:\r\n\t\tx := p.proc.ReadPtr(a)\r\n\t\tif x == 0 {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\t\r\n\t\tx = p.proc.ReadPtr(x.Add(p.proc.PtrSize()))\r\n\t\treturn p.runtimeType2Type(x)\r\n\t}\r\n}","code-length":211,"reference":"\/\/ DynamicType returns the concrete type stored in the interface type t at address a.\n\/\/ If the interface is nil, returns nil.","result":"Generate the dynamic type .","score":[0.0078,0.0472]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (fs *BtrfsFilesystem) Create(bytes uint64) error {\r\n\t\r\n\tidempotent := exec.Command(\"bash\", \"-e\", \"-x\", \"-c\", `\r\n\t\tif [ ! -e $IMAGE_PATH ] || [ \"$(stat --printf=\"%s\" $IMAGE_PATH)\" != \"$SIZE_IN_BYTES\" ]; then\r\n\t\t\ttouch $IMAGE_PATH\r\n\t\t\ttruncate -s ${SIZE_IN_BYTES} $IMAGE_PATH\r\n\t\tfi\r\n\t\tlo=\"$(losetup -j $IMAGE_PATH | cut -d':' -f1)\"\r\n\t\tif [ -z \"$lo\" ]; then\r\n\t\t\tlo=\"$(losetup -f --show $IMAGE_PATH)\"\r\n\t\tfi\r\n\t\tif ! file $IMAGE_PATH | grep BTRFS; then\r\n\t\t\t`+fs.mkfsBin+` --nodiscard $IMAGE_PATH\r\n\t\tfi\r\n\t\tmkdir -p $MOUNT_PATH\r\n\t\tif ! mountpoint -q $MOUNT_PATH; then\r\n\t\t\tmount -t btrfs $lo $MOUNT_PATH\r\n\t\tfi\r\n\t`)\r\n\tidempotent.Env = []string{\r\n\t\t\"PATH=\" + os.Getenv(\"PATH\"),\r\n\t\t\"MOUNT_PATH=\" + fs.mountPath,\r\n\t\t\"IMAGE_PATH=\" + fs.imagePath,\r\n\t\tfmt.Sprintf(\"SIZE_IN_BYTES=%d\", bytes),\r\n\t}\r\n\t_, err := fs.run(idempotent)\r\n\treturn err\r\n}","code-length":391,"reference":"\/\/ lower your expectations","result":"Create a new Btrfs filesystem.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Resolve(u *url.URL) (*net.IPAddr, error) {\r\n\thost, _, err := SplitHostPort(u)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\taddr, err := net.ResolveIPAddr(\"ip\", host)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn addr, nil\r\n}","code-length":108,"reference":"\/\/ Resolve resolves the URL host to its IP address.","result":"Resolve URLs.","score":[0.0092,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Token) Equal(b *Token) bool {\r\n\tif a == nil || b == nil {\r\n\t\treturn false\r\n\t}\r\n\tif a.tokenType != b.tokenType {\r\n\t\treturn false\r\n\t}\r\n\treturn a.value == b.value\r\n}","code-length":83,"reference":"\/\/ Equal reports whether tokens a, and b, are equal.\n\/\/ Two tokens are equal if both their types and values are equal. A nil token can\n\/\/ never be equal to another token.","result":"Compare tokens .","score":[0.0,0.0162]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newDefaultClassifier() tokenClassifier {\r\n\tt := tokenClassifier{}\r\n\tt.addRuneClass(spaceRunes, spaceRuneClass)\r\n\tt.addRuneClass(escapingQuoteRunes, escapingQuoteRuneClass)\r\n\tt.addRuneClass(nonEscapingQuoteRunes, nonEscapingQuoteRuneClass)\r\n\tt.addRuneClass(escapeRunes, escapeRuneClass)\r\n\tt.addRuneClass(commentRunes, commentRuneClass)\r\n\treturn t\r\n}","code-length":127,"reference":"\/\/ newDefaultClassifier creates a new classifier for ASCII characters.","result":"Create a default classifier.","score":[0.0915,0.2206]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *Lexer) Next() (string, error) {\r\n\tfor {\r\n\t\ttoken, err := (*Tokenizer)(l).Next()\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", err\r\n\t\t}\r\n\t\tswitch token.tokenType {\r\n\t\tcase WordToken:\r\n\t\t\treturn token.value, nil\r\n\t\tcase CommentToken:\r\n\t\t\t\r\n\t\tdefault:\r\n\t\t\treturn \"\", fmt.Errorf(\"Unknown token type: %v\", token.tokenType)\r\n\t\t}\r\n\t}\r\n}","code-length":144,"reference":"\/\/ Next returns the next word, or an error. If there are no more words,\n\/\/ the error will be io.EOF.","result":"Parse the next token.","score":[0.0064,0.0518]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTokenizer(r io.Reader) *Tokenizer {\r\n\tinput := bufio.NewReader(r)\r\n\tclassifier := newDefaultClassifier()\r\n\treturn &Tokenizer{\r\n\t\tinput:      *input,\r\n\t\tclassifier: classifier}\r\n}","code-length":72,"reference":"\/\/ NewTokenizer creates a new tokenizer from an input stream.","result":"Create a new tokenizer.","score":[0.1008,0.3132]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Split(s string) ([]string, error) {\r\n\tl := NewLexer(strings.NewReader(s))\r\n\tsubStrings := make([]string, 0)\r\n\tfor {\r\n\t\tword, err := l.Next()\r\n\t\tif err != nil {\r\n\t\t\tif err == io.EOF {\r\n\t\t\t\treturn subStrings, nil\r\n\t\t\t}\r\n\t\t\treturn subStrings, err\r\n\t\t}\r\n\t\tsubStrings = append(subStrings, word)\r\n\t}\r\n}","code-length":136,"reference":"\/\/ Split partitions a string into a slice of strings.","result":"Split a string into multiple words.","score":[0.2194,0.3288]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Between(s, left, right string) string {\r\n\tl := len(left)\r\n\tstartPos := strings.Index(s, left)\r\n\tif startPos < 0 {\r\n\t\treturn \"\"\r\n\t}\r\n\tendPos := IndexOf(s, right, startPos+l)\r\n\t\r\n\tif endPos < 0 {\r\n\t\treturn \"\"\r\n\t} else if right == \"\" {\r\n\t\treturn s[endPos:]\r\n\t} else {\r\n\t\treturn s[startPos+l : endPos]\r\n\t}\r\n}","code-length":144,"reference":"\/\/ Between extracts a string between left and right strings.","result":"Find the substring between.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc BetweenF(left, right string) func(string) string {\r\n\treturn func(s string) string {\r\n\t\treturn Between(s, left, right)\r\n\t}\r\n}","code-length":57,"reference":"\/\/ BetweenF is the filter form for Between.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Camelize(s string) string {\r\n\treturn camelizeRe.ReplaceAllStringFunc(s, func(val string) string {\r\n\t\tval = strings.ToUpper(val)\r\n\t\tval = camelizeRe2.ReplaceAllString(val, \"\")\r\n\t\treturn val\r\n\t})\r\n}","code-length":81,"reference":"\/\/ Camelize return new string which removes any underscores or dashes and convert a string into camel casing.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Capitalize(s string) string {\r\n\treturn strings.ToUpper(s[0:1]) + strings.ToLower(s[1:])\r\n}","code-length":48,"reference":"\/\/ Capitalize uppercases the first char of s and lowercases the rest.","result":"Generate the code.","score":[0.0203,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CharAt(s string, index int) string {\r\n\tl := len(s)\r\n\tshortcut := index < 0 || index > l-1 || l == 0\r\n\tif shortcut {\r\n\t\treturn \"\"\r\n\t}\r\n\treturn s[index : index+1]\r\n}","code-length":79,"reference":"\/\/ CharAt returns a string from the character at the specified position.","result":"Generate the code.","score":[0.0203,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CharAtF(index int) func(string) string {\r\n\treturn func(s string) string {\r\n\t\treturn CharAt(s, index)\r\n\t}\r\n}","code-length":53,"reference":"\/\/ CharAtF is the filter form of CharAt.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ChompLeft(s, prefix string) string {\r\n\tif strings.HasPrefix(s, prefix) {\r\n\t\treturn s[len(prefix):]\r\n\t}\r\n\treturn s\r\n}","code-length":59,"reference":"\/\/ ChompLeft removes prefix at the start of a string.","result":"Generate the code.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ChompLeftF(prefix string) func(string) string {\r\n\treturn func(s string) string {\r\n\t\treturn ChompLeft(s, prefix)\r\n\t}\r\n}","code-length":55,"reference":"\/\/ ChompLeftF is the filter form of ChompLeft.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ChompRight(s, suffix string) string {\r\n\tif strings.HasSuffix(s, suffix) {\r\n\t\treturn s[:len(s)-len(suffix)]\r\n\t}\r\n\treturn s\r\n}","code-length":62,"reference":"\/\/ ChompRight removes suffix from end of s.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ChompRightF(suffix string) func(string) string {\r\n\treturn func(s string) string {\r\n\t\treturn ChompRight(s, suffix)\r\n\t}\r\n}","code-length":55,"reference":"\/\/ ChompRightF is the filter form of ChompRight.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ClassifyF(s string) func(string) string {\r\n\treturn func(s string) string {\r\n\t\treturn Classify(s)\r\n\t}\r\n}","code-length":51,"reference":"\/\/ ClassifyF is the filter form of Classify.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Clean(s string) string {\r\n\ts = spacesRe.ReplaceAllString(s, \" \")\r\n\ts = beginEndSpacesRe.ReplaceAllString(s, \"\")\r\n\treturn s\r\n}","code-length":57,"reference":"\/\/ Clean compresses all adjacent whitespace to a single space and trims s.","result":"Clean strings.","score":[0.002,0.042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Dasherize(s string) string {\r\n\ts = strings.TrimSpace(s)\r\n\ts = spaceUnderscoreRe.ReplaceAllString(s, \"-\")\r\n\ts = capitalsRe.ReplaceAllString(s, \"-$1\")\r\n\ts = dashesRe.ReplaceAllString(s, \"-\")\r\n\ts = strings.ToLower(s)\r\n\treturn s\r\n}","code-length":102,"reference":"\/\/ Dasherize  converts a camel cased string into a string delimited by dashes.","result":"Generate a dasherized version of the string.","score":[0.0685,0.0806]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EscapeHTML(s string) string {\r\n\tif Verbose {\r\n\t\tfmt.Println(\"Use html.EscapeString instead of EscapeHTML\")\r\n\t}\r\n\treturn html.EscapeString(s)\r\n}","code-length":61,"reference":"\/\/ EscapeHTML is alias for html.EscapeString.","result":"Escape html.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DecodeHTMLEntities(s string) string {\r\n\tif Verbose {\r\n\t\tfmt.Println(\"Use html.UnescapeString instead of DecodeHTMLEntities\")\r\n\t}\r\n\treturn html.UnescapeString(s)\r\n}","code-length":67,"reference":"\/\/ DecodeHTMLEntities decodes HTML entities into their proper string representation.\n\/\/ DecodeHTMLEntities is an alias for html.UnescapeString","result":"UnescapeString.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EnsurePrefixF(prefix string) func(string) string {\r\n\treturn func(s string) string {\r\n\t\treturn EnsurePrefix(s, prefix)\r\n\t}\r\n}","code-length":53,"reference":"\/\/ EnsurePrefixF is the filter form of EnsurePrefix.","result":"Ensure the prefix is valid.","score":[0.1568,0.1299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EnsureSuffixF(suffix string) func(string) string {\r\n\treturn func(s string) string {\r\n\t\treturn EnsureSuffix(s, suffix)\r\n\t}\r\n}","code-length":53,"reference":"\/\/ EnsureSuffixF is the filter form of EnsureSuffix.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Humanize(s string) string {\r\n\tif s == \"\" {\r\n\t\treturn s\r\n\t}\r\n\ts = Underscore(s)\r\n\tvar humanizeRe = regexp.MustCompile(`_id$`)\r\n\ts = humanizeRe.ReplaceAllString(s, \"\")\r\n\ts = strings.Replace(s, \"_\", \" \", -1)\r\n\ts = strings.TrimSpace(s)\r\n\ts = Capitalize(s)\r\n\treturn s\r\n}","code-length":128,"reference":"\/\/ Humanize transforms s into a human friendly form.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Iif(condition bool, truthy string, falsey string) string {\r\n\tif condition {\r\n\t\treturn truthy\r\n\t}\r\n\treturn falsey\r\n}","code-length":52,"reference":"\/\/ Iif is short for immediate if. If condition is true return truthy else falsey.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IndexOf(s string, needle string, start int) int {\r\n\tl := len(s)\r\n\tif needle == \"\" {\r\n\t\tif start < 0 {\r\n\t\t\treturn 0\r\n\t\t} else if start < l {\r\n\t\t\treturn start\r\n\t\t} else {\r\n\t\t\treturn l\r\n\t\t}\r\n\t}\r\n\tif start < 0 || start > l-1 {\r\n\t\treturn -1\r\n\t}\r\n\tpos := strings.Index(s[start:], needle)\r\n\tif pos == -1 {\r\n\t\treturn -1\r\n\t}\r\n\treturn start + pos\r\n}","code-length":166,"reference":"\/\/ IndexOf finds the index of needle in s starting from start.","result":"Index the string in a slice.","score":[0.0845,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsLower(s string) bool {\r\n\treturn IsAlpha(s) && s == strings.ToLower(s)\r\n}","code-length":40,"reference":"\/\/ IsLower returns true if s comprised of all lower case characters.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsUpper(s string) bool {\r\n\treturn IsAlpha(s) && s == strings.ToUpper(s)\r\n}","code-length":40,"reference":"\/\/ IsUpper returns true if s contains all upper case chracters.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Left(s string, n int) string {\r\n\tif n < 0 {\r\n\t\treturn Right(s, -n)\r\n\t}\r\n\treturn Substr(s, 0, n)\r\n}","code-length":60,"reference":"\/\/ Left returns the left substring of length n.","result":"Generate the code.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LeftF(n int) func(string) string {\r\n\treturn func(s string) string {\r\n\t\treturn Left(s, n)\r\n\t}\r\n}","code-length":51,"reference":"\/\/ LeftF is the filter form of Left.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Letters(s string) []string {\r\n\tresult := []string{}\r\n\tfor _, r := range s {\r\n\t\tresult = append(result, string(r))\r\n\t}\r\n\treturn result\r\n}","code-length":64,"reference":"\/\/ Letters returns an array of runes as strings so it can be indexed into.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Lines(s string) []string {\r\n\ts = strings.Replace(s, \"\\r\\n\", \"\\n\", -1)\r\n\treturn strings.Split(s, \"\\n\")\r\n}","code-length":56,"reference":"\/\/ Lines convert windows newlines to unix newlines then convert to an Array of lines.","result":"Parse the input.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Map(arr []string, iterator func(string) string) []string {\r\n\tr := []string{}\r\n\tfor _, item := range arr {\r\n\t\tr = append(r, iterator(item))\r\n\t}\r\n\treturn r\r\n}","code-length":71,"reference":"\/\/ Map maps an array's iitem through an iterator.","result":"Avoid the need for the map function.","score":[0,0.0568]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Match(s, pattern string) bool {\r\n\tr := regexp.MustCompile(pattern)\r\n\treturn r.MatchString(s)\r\n}","code-length":45,"reference":"\/\/ Match returns true if patterns matches the string","result":"Match .","score":[0.0151,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc tasks(p *do.Project) {\r\n\tp.Task(\"default\", do.S{\"readme\"}, nil)\r\n\tp.Task(\"install\", nil, func(c *do.Context) {\r\n\t\tc.Run(\"go get github.com\/robertkrimen\/godocdown\/godocdown\")\r\n\t})\r\n\tp.Task(\"lint\", nil, func(c *do.Context) {\r\n\t\tc.Run(\"golint .\")\r\n\t\tc.Run(\"gofmt -w -s .\")\r\n\t\tc.Run(\"go vet .\")\r\n\t\tc.Run(\"go test\")\r\n\t})\r\n\tp.Task(\"readme\", nil, func(c *do.Context) {\r\n\t\tc.Run(\"godocdown -output README.md\")\r\n\t\tpackageName, _ := util.PackageName(\"doc.go\")\r\n\t\t\r\n\t\tgoa.Pipe(\r\n\t\t\tf.Load(\".\/README.md\"),\r\n\t\t\tf.Str(str.ReplaceF(\"--\", \"\\n[godoc](https:\r\n\t\t\tf.Write(),\r\n\t\t)\r\n\t}).Src(\"**\/*.go\")\r\n\tp.Task(\"test\", nil, func(c *do.Context) {\r\n\t\tc.Run(\"go test\")\r\n\t})\r\n}","code-length":341,"reference":"\/\/ Project is local project.","result":"Generate the docs.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Pad(s, c string, n int) string {\r\n\tL := len(s)\r\n\tif L >= n {\r\n\t\treturn s\r\n\t}\r\n\tn -= L\r\n\tleft := strings.Repeat(c, int(math.Ceil(float64(n)\/2)))\r\n\tright := strings.Repeat(c, int(math.Floor(float64(n)\/2)))\r\n\treturn left + s + right\r\n}","code-length":118,"reference":"\/\/ Pad pads string s on both sides with c until it has length of n.","result":"Pad strings.","score":[0.0005,0.0342]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PadF(c string, n int) func(string) string {\r\n\treturn func(s string) string {\r\n\t\treturn Pad(s, c, n)\r\n\t}\r\n}","code-length":56,"reference":"\/\/ PadF is the filter form of Pad.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PadLeft(s, c string, n int) string {\r\n\tL := len(s)\r\n\tif L > n {\r\n\t\treturn s\r\n\t}\r\n\treturn strings.Repeat(c, (n-L)) + s\r\n}","code-length":70,"reference":"\/\/ PadLeft pads s on left side with c until it has length of n.","result":"Pad right.","score":[0,0.0365]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PadLeftF(c string, n int) func(string) string {\r\n\treturn func(s string) string {\r\n\t\treturn PadLeft(s, c, n)\r\n\t}\r\n}","code-length":58,"reference":"\/\/ PadLeftF is the filter form of PadLeft.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PadRightF(c string, n int) func(string) string {\r\n\treturn func(s string) string {\r\n\t\treturn PadRight(s, c, n)\r\n\t}\r\n}","code-length":58,"reference":"\/\/ PadRightF is the filter form of Padright","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Pipe(s string, funcs ...func(string) string) string {\r\n\tfor _, fn := range funcs {\r\n\t\ts = fn(s)\r\n\t}\r\n\treturn s\r\n}","code-length":58,"reference":"\/\/ Pipe pipes s through one or more string filters.","result":"Pipe a string into a string.","score":[0.1179,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc QuoteItems(arr []string) []string {\r\n\treturn Map(arr, func(s string) string {\r\n\t\treturn strconv.Quote(s)\r\n\t})\r\n}","code-length":53,"reference":"\/\/ QuoteItems quotes all items in array, mostly for debugging.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReplaceF(old, new string, n int) func(string) string {\r\n\treturn func(s string) string {\r\n\t\treturn strings.Replace(s, old, new, n)\r\n\t}\r\n}","code-length":62,"reference":"\/\/ ReplaceF is the filter form of strings.Replace.","result":"Replace the string in the file.","score":[0.1383,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReplacePatternF(pattern, repl string) func(string) string {\r\n\treturn func(s string) string {\r\n\t\treturn ReplacePattern(s, pattern, repl)\r\n\t}\r\n}","code-length":57,"reference":"\/\/ ReplacePatternF is the filter form of ReplaceRegexp.","result":"Replace the pattern.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Reverse(s string) string {\r\n\tcs := make([]rune, utf8.RuneCountInString(s))\r\n\ti := len(cs)\r\n\tfor _, c := range s {\r\n\t\ti--\r\n\t\tcs[i] = c\r\n\t}\r\n\treturn string(cs)\r\n}","code-length":88,"reference":"\/\/ Reverse a string","result":"Reverse the string.","score":[0.2925,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RightF(n int) func(string) string {\r\n\treturn func(s string) string {\r\n\t\treturn Right(s, n)\r\n\t}\r\n}","code-length":51,"reference":"\/\/ RightF is the Filter version of Right.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Slice(s string, start, end int) string {\r\n\tif end > -1 {\r\n\t\treturn s[start:end]\r\n\t}\r\n\tL := len(s)\r\n\tif L+end > 0 {\r\n\t\treturn s[start : L-end]\r\n\t}\r\n\treturn s[start:]\r\n}","code-length":93,"reference":"\/\/ Slice slices a string. If end is negative then it is the from the end\n\/\/ of the string.","result":"Avoid recursion.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SliceF(start, end int) func(string) string {\r\n\treturn func(s string) string {\r\n\t\treturn Slice(s, start, end)\r\n\t}\r\n}","code-length":55,"reference":"\/\/ SliceF is the filter for Slice.","result":"Generate the function for slice operations.","score":[0.1943,0.1449]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SliceContains(slice []string, val string) bool {\r\n\tif slice == nil {\r\n\t\treturn false\r\n\t}\r\n\tfor _, it := range slice {\r\n\t\tif it == val {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":83,"reference":"\/\/ SliceContains determines whether val is an element in slice.","result":"Test the slice contains function.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SliceIndexOf(slice []string, val string) int {\r\n\tif slice == nil {\r\n\t\treturn -1\r\n\t}\r\n\tfor i, it := range slice {\r\n\t\tif it == val {\r\n\t\t\treturn i\r\n\t\t}\r\n\t}\r\n\treturn -1\r\n}","code-length":85,"reference":"\/\/ SliceIndexOf gets the indx of val in slice. Returns -1 if not found.","result":"Call the sliceIndexOf function.","score":[0.0262,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Slugify(s string) string {\r\n\tsl := slugifyRe.ReplaceAllString(s, \"\")\r\n\tsl = strings.ToLower(sl)\r\n\tsl = Dasherize(sl)\r\n\treturn sl\r\n}","code-length":66,"reference":"\/\/ Slugify converts s into a dasherized string suitable for URL segment.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StripPunctuation(s string) string {\r\n\ts = stripPuncRe.ReplaceAllString(s, \"\")\r\n\ts = nWhitespaceRe.ReplaceAllString(s, \" \")\r\n\treturn s\r\n}","code-length":60,"reference":"\/\/ StripPunctuation strips puncation from string.","result":"Strip punctuation from strings.","score":[0.1938,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StripTags(s string, tags ...string) string {\r\n\tif len(tags) == 0 {\r\n\t\ttags = append(tags, \"\")\r\n\t}\r\n\tfor _, tag := range tags {\r\n\t\tstripTagsRe := regexp.MustCompile(`(?i)<\\\/?` + tag + `[^<>]*>`)\r\n\t\ts = stripTagsRe.ReplaceAllString(s, \"\")\r\n\t}\r\n\treturn s\r\n}","code-length":118,"reference":"\/\/ StripTags strips all of the html tags or tags specified by the parameters","result":"Strip HTML tags.","score":[0,0.0775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Substr(s string, index int, n int) string {\r\n\tL := len(s)\r\n\tif index < 0 || index >= L || s == \"\" {\r\n\t\treturn \"\"\r\n\t}\r\n\tend := index + n\r\n\tif end >= L {\r\n\t\tend = L\r\n\t}\r\n\tif end <= index {\r\n\t\treturn \"\"\r\n\t}\r\n\treturn s[index:end]\r\n}","code-length":117,"reference":"\/\/ Substr returns a substring of s starting at index of length n.","result":"Call substring functions.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SubstrF(index, n int) func(string) string {\r\n\treturn func(s string) string {\r\n\t\treturn Substr(s, index, n)\r\n\t}\r\n}","code-length":57,"reference":"\/\/ SubstrF is the filter form of Substr.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc TemplateWithDelimiters(s string, values map[string]interface{}, opening, closing string) string {\r\n\tescapeDelimiter := func(delim string) string {\r\n\t\tresult := templateRe.ReplaceAllString(delim, \"\\\\$1\")\r\n\t\treturn templateRe2.ReplaceAllString(result, \"\\\\$\")\r\n\t}\r\n\topeningDelim := escapeDelimiter(opening)\r\n\tclosingDelim := escapeDelimiter(closing)\r\n\tr := regexp.MustCompile(openingDelim + `(.+?)` + closingDelim)\r\n\tmatches := r.FindAllStringSubmatch(s, -1)\r\n\tfor _, submatches := range matches {\r\n\t\tmatch := submatches[0]\r\n\t\tkey := submatches[1]\r\n\t\t\r\n\t\tif values[key] != nil {\r\n\t\t\tv := fmt.Sprintf(\"%v\", values[key])\r\n\t\t\ts = strings.Replace(s, match, v, -1)\r\n\t\t}\r\n\t}\r\n\treturn s\r\n}","code-length":249,"reference":"\/\/ TemplateWithDelimiters is string template with user-defineable opening and closing delimiters.","result":"Replace the delimiters in the template.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ToArgv(s string) []string {\r\n\tconst (\r\n\t\tInArg = iota\r\n\t\tInArgQuote\r\n\t\tOutOfArg\r\n\t)\r\n\tcurrentState := OutOfArg\r\n\tcurrentQuoteChar := \"\\x00\"\r\n\t\r\n\tcurrentArg := \"\"\r\n\targv := []string{}\r\n\tisQuote := func(c string) bool {\r\n\t\treturn c == `\"` || c == `'`\r\n\t}\r\n\tisEscape := func(c string) bool {\r\n\t\treturn c == `\\`\r\n\t}\r\n\tisWhitespace := func(c string) bool {\r\n\t\treturn c == \" \" || c == \"\\t\"\r\n\t}\r\n\tL := len(s)\r\n\tfor i := 0; i < L; i++ {\r\n\t\tc := s[i : i+1]\r\n\t\t\r\n\t\tif isQuote(c) {\r\n\t\t\tswitch currentState {\r\n\t\t\tcase OutOfArg:\r\n\t\t\t\tcurrentArg = \"\"\r\n\t\t\t\tfallthrough\r\n\t\t\tcase InArg:\r\n\t\t\t\tcurrentState = InArgQuote\r\n\t\t\t\tcurrentQuoteChar = c\r\n\t\t\tcase InArgQuote:\r\n\t\t\t\tif c == currentQuoteChar {\r\n\t\t\t\t\tcurrentState = InArg\r\n\t\t\t\t} else {\r\n\t\t\t\t\tcurrentArg += c\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t} else if isWhitespace(c) {\r\n\t\t\tswitch currentState {\r\n\t\t\tcase InArg:\r\n\t\t\t\targv = append(argv, currentArg)\r\n\t\t\t\tcurrentState = OutOfArg\r\n\t\t\tcase InArgQuote:\r\n\t\t\t\tcurrentArg += c\r\n\t\t\tcase OutOfArg:\r\n\t\t\t\t\r\n\t\t\t}\r\n\t\t} else if isEscape(c) {\r\n\t\t\tswitch currentState {\r\n\t\t\tcase OutOfArg:\r\n\t\t\t\tcurrentArg = \"\"\r\n\t\t\t\tcurrentState = InArg\r\n\t\t\t\tfallthrough\r\n\t\t\tcase InArg:\r\n\t\t\t\tfallthrough\r\n\t\t\tcase InArgQuote:\r\n\t\t\t\tif i == L-1 {\r\n\t\t\t\t\tif runtime.GOOS == \"windows\" {\r\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tcurrentArg += c\r\n\t\t\t\t\t} else {\r\n\t\t\t\t\t\tpanic(\"Escape character at end string\")\r\n\t\t\t\t\t}\r\n\t\t\t\t} else {\r\n\t\t\t\t\tif runtime.GOOS == \"windows\" {\r\n\t\t\t\t\t\tpeek := s[i+1 : i+2]\r\n\t\t\t\t\t\tif peek != `\"` {\r\n\t\t\t\t\t\t\tcurrentArg += c\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t} else {\r\n\t\t\t\t\t\ti++\r\n\t\t\t\t\t\tc = s[i : i+1]\r\n\t\t\t\t\t\tcurrentArg += c\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\tswitch currentState {\r\n\t\t\tcase InArg, InArgQuote:\r\n\t\t\t\tcurrentArg += c\r\n\t\t\tcase OutOfArg:\r\n\t\t\t\tcurrentArg = \"\"\r\n\t\t\t\tcurrentArg += c\r\n\t\t\t\tcurrentState = InArg\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif currentState == InArg {\r\n\t\targv = append(argv, currentArg)\r\n\t} else if currentState == InArgQuote {\r\n\t\tpanic(\"Starting quote has no ending quote.\")\r\n\t}\r\n\treturn argv\r\n}","code-length":812,"reference":"\/\/ ToArgv converts string s into an argv for exec.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ToBool(s string) bool {\r\n\ts = strings.ToLower(s)\r\n\treturn s == \"true\" || s == \"yes\" || s == \"on\" || s == \"1\"\r\n}","code-length":60,"reference":"\/\/ ToBool fuzzily converts truthy values.","result":"Convert string to bool.","score":[0,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ToBoolOr(s string, defaultValue bool) bool {\r\n\tb, err := strconv.ParseBool(s)\r\n\tif err != nil {\r\n\t\treturn defaultValue\r\n\t}\r\n\treturn b\r\n}","code-length":62,"reference":"\/\/ ToBoolOr parses s as a bool or returns defaultValue.","result":"Convert string to bool.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ToIntOr(s string, defaultValue int) int {\r\n\tn, err := strconv.Atoi(s)\r\n\tif err != nil {\r\n\t\treturn defaultValue\r\n\t}\r\n\treturn n\r\n}","code-length":62,"reference":"\/\/ ToIntOr parses s as an int or returns defaultValue.","result":"Convert strings to integers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ToFloat32Or(s string, defaultValue float32) float32 {\r\n\tf, err := strconv.ParseFloat(s, 32)\r\n\tif err != nil {\r\n\t\treturn defaultValue\r\n\t}\r\n\treturn float32(f)\r\n}","code-length":71,"reference":"\/\/ ToFloat32Or parses as a float32 or returns defaultValue on error.","result":"Convert string to float.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ToFloat64Or(s string, defaultValue float64) float64 {\r\n\tf, err := strconv.ParseFloat(s, 64)\r\n\tif err != nil {\r\n\t\treturn defaultValue\r\n\t}\r\n\treturn f\r\n}","code-length":67,"reference":"\/\/ ToFloat64Or parses s as a float64 or returns defaultValue.","result":"Convert string to float.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UnescapeHTML(s string) string {\r\n\tif Verbose {\r\n\t\tfmt.Println(\"Use html.UnescapeString instead of UnescapeHTML\")\r\n\t}\r\n\treturn html.UnescapeString(s)\r\n}","code-length":65,"reference":"\/\/ UnescapeHTML is an alias for html.UnescapeString.","result":"Unescape html.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WrapHTML(s string, tag string, attrs map[string]string) string {\r\n\tescapeHTMLAttributeQuotes := func(v string) string {\r\n\t\tv = strings.Replace(v, \"<\", \"&lt;\", -1)\r\n\t\tv = strings.Replace(v, \"&\", \"&amp;\", -1)\r\n\t\tv = strings.Replace(v, \"\\\"\", \"&quot;\", -1)\r\n\t\treturn v\r\n\t}\r\n\tif tag == \"\" {\r\n\t\ttag = \"div\"\r\n\t}\r\n\tel := \"<\" + tag\r\n\tfor name, val := range attrs {\r\n\t\tel += \" \" + name + \"=\\\"\" + escapeHTMLAttributeQuotes(val) + \"\\\"\"\r\n\t}\r\n\tel += \">\" + s + \"<\/\" + tag + \">\"\r\n\treturn el\r\n}","code-length":206,"reference":"\/\/ WrapHTML wraps s within HTML tag having attributes attrs. Note,\n\/\/ WrapHTML does not escape s value.","result":"Wrap html strings.","score":[0,0.0606]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WrapHTMLF(tag string, attrs map[string]string) func(string) string {\r\n\treturn func(s string) string {\r\n\t\treturn WrapHTML(s, tag, attrs)\r\n\t}\r\n}","code-length":62,"reference":"\/\/ WrapHTMLF is the filter form of WrapHTML.","result":"Wrap html in f.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReapChildren(pids PidCh, errors ErrorCh, done chan struct{}, reapLock *sync.RWMutex) {\r\n\tc := make(chan os.Signal, 1)\r\n\tsignal.Notify(c, unix.SIGCHLD)\r\n\tfor {\r\n\t\t\r\n\t\tselect {\r\n\t\tcase <-c:\r\n\t\t\t\r\n\t\tcase <-done:\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tfunc() {\r\n\t\t\tif reapLock != nil {\r\n\t\t\t\treapLock.Lock()\r\n\t\t\t\tdefer reapLock.Unlock()\r\n\t\t\t}\r\n\t\tPOLL:\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tvar status unix.WaitStatus\r\n\t\t\tpid, err := unix.Wait4(-1, &status, unix.WNOHANG, nil)\r\n\t\t\tswitch err {\r\n\t\t\tcase nil:\r\n\t\t\t\t\r\n\t\t\t\tif pid > 0 {\r\n\t\t\t\t\tif pids != nil {\r\n\t\t\t\t\t\tpids <- pid\r\n\t\t\t\t\t}\r\n\t\t\t\t\tgoto POLL\r\n\t\t\t\t}\r\n\t\t\t\treturn\r\n\t\t\tcase unix.ECHILD:\r\n\t\t\t\t\r\n\t\t\t\treturn\r\n\t\t\tcase unix.EINTR:\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tgoto POLL\r\n\t\t\tdefault:\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tif errors != nil {\r\n\t\t\t\t\terrors <- err\r\n\t\t\t\t}\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t}()\r\n\t}\r\n}","code-length":405,"reference":"\/\/ ReapChildren is a long-running routine that blocks waiting for child\n\/\/ processes to exit and reaps them, reporting reaped process IDs to the\n\/\/ optional pids channel and any errors to the optional errors channel.\n\/\/\n\/\/ The optional reapLock will be used to prevent reaping during periods\n\/\/ when you know your application is waiting for subprocesses to return.\n\/\/ You need to use care in order to prevent the reaper from stealing your\n\/\/ return values from uses of packages like Go's exec. We use an RWMutex\n\/\/ so that we don't serialize all of the application's execution of sub\n\/\/ processes with each other, but we do serialize them with reaping. The\n\/\/ application should get a read lock when it wants to do a wait.","result":"Reap children .","score":[0,0.0085]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SdNotify(state string) error {\r\n\tname := os.Getenv(\"NOTIFY_SOCKET\")\r\n\tif name == \"\" {\r\n\t\treturn ErrSdNotifyNoSocket\r\n\t}\r\n\tconn, err := net.DialUnix(\"unixgram\", nil, &net.UnixAddr{Name: name, Net: \"unixgram\"})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer conn.Close()\r\n\t_, err = conn.Write([]byte(state))\r\n\treturn err\r\n}","code-length":141,"reference":"\/\/ SdNotify sends a specified string to the systemd notification socket.","result":"Send state to the SdNotify socket.","score":[0.1411,0.3543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewAuthenticator(store *coal.Store, policy *Policy) *Authenticator {\r\n\t\r\n\tcoal.Init(policy.Token)\r\n\t\r\n\tfor _, model := range policy.Clients {\r\n\t\tcoal.Init(model)\r\n\t}\r\n\treturn &Authenticator{\r\n\t\tstore:  store,\r\n\t\tpolicy: policy,\r\n\t}\r\n}","code-length":104,"reference":"\/\/ NewAuthenticator constructs a new Authenticator from a store and policy.","result":"Create the authenticator.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Authenticator) Endpoint(prefix string) http.Handler {\r\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\r\n\t\t\r\n\t\ttracer := fire.NewTracerFromRequest(r, \"flame\/Authenticator.Endpoint\")\r\n\t\ttracer.Tag(\"prefix\", prefix)\r\n\t\tdefer tracer.Finish(true)\r\n\t\t\r\n\t\tdefer stack.Resume(func(err error) {\r\n\t\t\t\r\n\t\t\tif oauth2Error, ok := err.(*oauth2.Error); ok {\r\n\t\t\t\t_ = oauth2.WriteError(w, oauth2Error)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\ttracer.Tag(\"error\", true)\r\n\t\t\ttracer.Log(\"error\", err.Error())\r\n\t\t\ttracer.Log(\"stack\", stack.Trace())\r\n\t\t\t\r\n\t\t\tif a.Reporter != nil {\r\n\t\t\t\ta.Reporter(err)\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\t_ = oauth2.WriteError(w, oauth2.ServerError(\"\"))\r\n\t\t})\r\n\t\t\r\n\t\ts := strings.Split(strings.Trim(strings.TrimPrefix(r.URL.Path, prefix), \"\/\"), \"\/\")\r\n\t\tif len(s) != 1 || (s[0] != \"authorize\" && s[0] != \"token\" && s[0] != \"revoke\") {\r\n\t\t\tw.WriteHeader(http.StatusNotFound)\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\tstore := a.store.Copy()\r\n\t\tdefer store.Close()\r\n\t\t\r\n\t\tstate := &state{\r\n\t\t\trequest: r,\r\n\t\t\twriter:  w,\r\n\t\t\tstore:   store,\r\n\t\t\ttracer:  tracer,\r\n\t\t}\r\n\t\t\r\n\t\tswitch s[0] {\r\n\t\tcase \"authorize\":\r\n\t\t\ta.authorizationEndpoint(state)\r\n\t\tcase \"token\":\r\n\t\t\ta.tokenEndpoint(state)\r\n\t\tcase \"revoke\":\r\n\t\t\ta.revocationEndpoint(state)\r\n\t\t}\r\n\t})\r\n}","code-length":532,"reference":"\/\/ Endpoint returns a handler for the common token and authorize endpoint.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Unique(ids []bson.ObjectId) []bson.ObjectId {\r\n\t\r\n\tm := make(map[bson.ObjectId]bool)\r\n\tl := make([]bson.ObjectId, 0, len(ids))\r\n\tfor _, id := range ids {\r\n\t\tif _, ok := m[id]; !ok {\r\n\t\t\tm[id] = true\r\n\t\t\tl = append(l, id)\r\n\t\t}\r\n\t}\r\n\treturn l\r\n}","code-length":129,"reference":"\/\/ Unique is a helper to get a unique list of object ids.","result":"Generate unique ids.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Contains(list []bson.ObjectId, id bson.ObjectId) bool {\r\n\tfor _, item := range list {\r\n\t\tif item == id {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":69,"reference":"\/\/ Contains returns true if a list of object ids contains the specified id.","result":"Test the contains function.","score":[0.0312,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Includes(all, subset []bson.ObjectId) bool {\r\n\tfor _, item := range subset {\r\n\t\tif !Contains(all, item) {\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":71,"reference":"\/\/ Includes returns true if a list of object ids includes another list of object\n\/\/ ids.","result":"Test the includes function.","score":[0.0124,0.0318]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Require(m Model, flags ...string) {\r\n\t\r\n\tfor _, f := range flags {\r\n\t\tL(m, f, true)\r\n\t}\r\n}","code-length":53,"reference":"\/\/ Require will check if the specified flags are set on the specified model and\n\/\/ panic if one is missing.","result":"Require a model.","score":[0.001,0.026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Enqueue(store *coal.SubStore, name string, data Model, delay time.Duration) (*Job, error) {\r\n\t\r\n\tif data == nil {\r\n\t\tdata = bson.M{}\r\n\t}\r\n\t\r\n\tnow := time.Now()\r\n\t\r\n\tjob := coal.Init(&Job{\r\n\t\tName:      name,\r\n\t\tStatus:    StatusEnqueued,\r\n\t\tCreated:   now,\r\n\t\tAvailable: now.Add(delay),\r\n\t}).(*Job)\r\n\t\r\n\traw, err := bson.Marshal(data)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\terr = bson.Unmarshal(raw, &job.Data)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\terr = store.C(job).Insert(job)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn job, nil\r\n}","code-length":264,"reference":"\/\/ Enqueue will enqueue a job using the specified name and data. If a delay\n\/\/ is specified the job will not be dequeued until the specified time has passed.","result":"Store the job in the store.","score":[0.0055,0.0926]}
{"code":"\/*is used to<extra_id_0>\r\nfunc A(name string, m fire.Matcher, h Handler) *Authorizer {\r\n\t\r\n\tif m == nil || h == nil {\r\n\t\tpanic(\"ash: missing matcher or handler\")\r\n\t}\r\n\t\r\n\treturn &Authorizer{\r\n\t\tMatcher: m,\r\n\t\tHandler: func(ctx *fire.Context) ([]*Enforcer, error) {\r\n\t\t\t\r\n\t\t\tctx.Tracer.Push(name)\r\n\t\t\t\r\n\t\t\tenforcers, err := h(ctx)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tctx.Tracer.Pop()\r\n\t\t\treturn enforcers, nil\r\n\t\t},\r\n\t}\r\n}","code-length":187,"reference":"\/\/ A is a short-hand function to construct an authorizer. It will also add tracing\n\/\/ code around the execution of the authorizer.","result":"Create an authorizer.","score":[0.0007,0.0476]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Run(enforcers ...*Enforcer) *Authorizer {\r\n\treturn A(\"ash\/Run\", fire.All(), func(ctx *fire.Context) ([]*Enforcer, error) {\r\n\t\treturn enforcers, nil\r\n\t})\r\n}","code-length":68,"reference":"\/\/ Run will authorize immediately and return the provided list of enforcers.","result":"Run a new authorizer.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc And(a, b *Authorizer) *Authorizer {\r\n\treturn A(\"ash\/And\", func(ctx *fire.Context) bool {\r\n\t\treturn a.Matcher(ctx) && b.Matcher(ctx)\r\n\t}, func(ctx *fire.Context) ([]*Enforcer, error) {\r\n\t\t\r\n\t\tenforcers1, err := a.Handler(ctx)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t} else if enforcers1 == nil {\r\n\t\t\treturn nil, nil\r\n\t\t}\r\n\t\t\r\n\t\tenforcers2, err := b.Handler(ctx)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t} else if enforcers2 == nil {\r\n\t\t\treturn nil, nil\r\n\t\t}\r\n\t\t\r\n\t\tenforcers := append(S{}, enforcers1...)\r\n\t\tenforcers = append(enforcers, enforcers2...)\r\n\t\treturn enforcers, nil\r\n\t})\r\n}","code-length":263,"reference":"\/\/ And will match and run both authorizers and return immediately if one does not\n\/\/ return a set of enforcers. The two successfully returned enforcer sets are\n\/\/ merged into one and returned.","result":"Create an authorizer for the .","score":[0,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Or(a, b *Authorizer) *Authorizer {\r\n\treturn A(\"ash\/Or\", func(ctx *fire.Context) bool {\r\n\t\treturn a.Matcher(ctx) || b.Matcher(ctx)\r\n\t}, func(ctx *fire.Context) ([]*Enforcer, error) {\r\n\t\t\r\n\t\tif a.Matcher(ctx) {\r\n\t\t\t\r\n\t\t\tenforcers, err := a.Handler(ctx)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif enforcers != nil {\r\n\t\t\t\treturn enforcers, nil\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tif b.Matcher(ctx) {\r\n\t\t\t\r\n\t\t\tenforcers, err := b.Handler(ctx)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif enforcers != nil {\r\n\t\t\t\treturn enforcers, nil\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil, nil\r\n\t})\r\n}","code-length":273,"reference":"\/\/ Or will match and run the first authorizer and return its enforcers on success.\n\/\/ If no enforcers are returned it will match and run the second authorizer and\n\/\/ return its enforcers.","result":"Create an OR function.","score":[0,0.0161]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *Queue) Enqueue(name string, data Model, delay time.Duration) (*Job, error) {\r\n\t\r\n\tstore := q.store.Copy()\r\n\tdefer store.Close()\r\n\t\r\n\tjob, err := Enqueue(store, name, data, delay)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn job, nil\r\n}","code-length":109,"reference":"\/\/ Enqueue will enqueue a job using the specified name and data. If a delay\n\/\/ is specified the job will not dequeued until the specified time has passed.","result":"Store the job in the queue.","score":[0.0065,0.0957]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *Queue) Callback(name string, delay time.Duration, matcher fire.Matcher, cb func(ctx *fire.Context) Model) *fire.Callback {\r\n\treturn fire.C(\"axe\/Queue.Callback\", matcher, func(ctx *fire.Context) error {\r\n\t\t\r\n\t\tctx.Tracer.Tag(\"task\", name)\r\n\t\t\r\n\t\tvar data Model\r\n\t\tif cb != nil {\r\n\t\t\tdata = cb(ctx)\r\n\t\t}\r\n\t\t\r\n\t\tif q.store == ctx.Controller.Store {\r\n\t\t\t\r\n\t\t\t_, err := Enqueue(ctx.Store, name, data, delay)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\t\r\n\t\t\t_, err := q.Enqueue(name, data, delay)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tif ctx.Operation.Action() {\r\n\t\t\terr := ctx.Respond(fire.Map{})\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n}","code-length":307,"reference":"\/\/ Callback is a factory to create callbacks that can be used to enqueue jobs\n\/\/ during request processing.","result":"Create a callback function.","score":[0.0075,0.0857]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewWatcher() *Watcher {\r\n\t\r\n\tw := &Watcher{\r\n\t\tstreams: make(map[string]*Stream),\r\n\t}\r\n\t\r\n\tw.manager = newManager(w)\r\n\treturn w\r\n}","code-length":68,"reference":"\/\/ NewWatcher creates and returns a new watcher.","result":"Create a new watcher.","score":[0.2421,0.4934]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *Watcher) Add(stream *Stream) {\r\n\t\r\n\tcoal.Init(stream.Model)\r\n\t\r\n\tif w.streams[stream.Name()] != nil {\r\n\t\tpanic(fmt.Sprintf(`spark: stream with name \"%s\" already exists`, stream.Name()))\r\n\t}\r\n\t\r\n\tw.streams[stream.Name()] = stream\r\n\t\r\n\tcoal.OpenStream(stream.Store, stream.Model, nil, func(e coal.Event, id bson.ObjectId, m coal.Model, token []byte) {\r\n\t\t\r\n\t\tif stream.SoftDelete && e == coal.Deleted {\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\tif stream.SoftDelete && e == coal.Updated {\r\n\t\t\t\r\n\t\t\tsoftDeleteField := coal.L(stream.Model, \"fire-soft-delete\", true)\r\n\t\t\t\r\n\t\t\tt := m.MustGet(softDeleteField).(*time.Time)\r\n\t\t\t\r\n\t\t\tif t != nil && !t.IsZero() {\r\n\t\t\t\te = coal.Deleted\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tevt := &Event{\r\n\t\t\tType:   e,\r\n\t\t\tID:     id,\r\n\t\t\tModel:  m,\r\n\t\t\tStream: stream,\r\n\t\t}\r\n\t\t\r\n\t\tw.manager.broadcast(evt)\r\n\t}, nil, func(err error) bool {\r\n\t\t\r\n\t\tw.Reporter(err)\r\n\t\treturn true\r\n\t})\r\n}","code-length":401,"reference":"\/\/ Add will add a stream to the watcher.","result":"Add a new stream to the watcher.","score":[0.4204,0.6692]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *Watcher) Action() *fire.Action {\r\n\treturn &fire.Action{\r\n\t\tMethods: []string{\"GET\"},\r\n\t\tCallback: fire.C(\"spark\/Watcher.Action\", fire.All(), func(ctx *fire.Context) error {\r\n\t\t\t\r\n\t\t\tw.manager.handle(ctx)\r\n\t\t\treturn nil\r\n\t\t}),\r\n\t}\r\n}","code-length":107,"reference":"\/\/ Action returns an action that should be registered in the group under\n\/\/ the \"watch\" name.","result":"Get the action from the watcher.","score":[0.0406,0.0943]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Operation) Write() bool {\r\n\treturn o == Create || o == Update || o == Delete\r\n}","code-length":36,"reference":"\/\/ Write will return true when this operation does write data.","result":"Check if the operation is Write.","score":[0.0839,0.0476]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Operation) String() string {\r\n\tswitch o {\r\n\tcase List:\r\n\t\treturn \"List\"\r\n\tcase Find:\r\n\t\treturn \"Find\"\r\n\tcase Create:\r\n\t\treturn \"Create\"\r\n\tcase Update:\r\n\t\treturn \"Update\"\r\n\tcase Delete:\r\n\t\treturn \"Delete\"\r\n\tcase CollectionAction:\r\n\t\treturn \"CollectionAction\"\r\n\tcase ResourceAction:\r\n\t\treturn \"ResourceAction\"\r\n\t}\r\n\treturn \"\"\r\n}","code-length":138,"reference":"\/\/ String returns the name of the operation.","result":"Generate the string representation of the operation.","score":[0.3099,0.5646]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Context) Query() bson.M {\r\n\treturn bson.M{\"$and\": append([]bson.M{c.Selector}, c.Filters...)}\r\n}","code-length":52,"reference":"\/\/ Query returns the composite query of Selector and Filter.","result":"Query the context.","score":[0.0471,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Context) Respond(value interface{}) error {\r\n\t\r\n\tbytes, err := json.Marshal(value)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t_, err = c.ResponseWriter.Write(bytes)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":102,"reference":"\/\/ Respond will encode the provided value as JSON and write it to the client.","result":"Set the response body.","score":[0.0204,0.036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EnsureApplication(store *coal.Store, name, key, secret string) (string, error) {\r\n\t\r\n\ts := store.Copy()\r\n\tdefer s.Close()\r\n\t\r\n\tvar apps []Application\r\n\terr := s.C(&Application{}).Find(bson.M{\r\n\t\tcoal.F(&Application{}, \"Name\"): name,\r\n\t}).All(&apps)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\t\r\n\tif len(apps) > 1 {\r\n\t\treturn \"\", errors.New(\"to many applications with that name\")\r\n\t} else if len(apps) == 1 {\r\n\t\treturn apps[0].Key, nil\r\n\t}\r\n\t\r\n\t\r\n\tapp := coal.Init(&Application{}).(*Application)\r\n\tapp.Key = key\r\n\tapp.Name = name\r\n\tapp.Secret = secret\r\n\t\r\n\terr = app.Validate()\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\t\r\n\terr = s.C(app).Insert(app)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn app.Key, nil\r\n}","code-length":318,"reference":"\/\/ EnsureApplication will ensure that an application with the provided name\n\/\/ exists and returns its key.","result":"Ensure that the application is created.","score":[0.0406,0.234]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EnsureFirstUser(store *coal.Store, name, email, password string) error {\r\n\t\r\n\ts := store.Copy()\r\n\tdefer s.Close()\r\n\t\r\n\tn, err := s.C(&User{}).Count()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t} else if n > 0 {\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\t\r\n\tuser := coal.Init(&User{}).(*User)\r\n\tuser.Name = name\r\n\tuser.Email = email\r\n\tuser.Password = password\r\n\t\r\n\terr = user.Validate()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\terr = s.C(user).Insert(user)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":225,"reference":"\/\/ EnsureFirstUser ensures the existence of a first user if no other has been\n\/\/ created.","result":"Ensure that the first user is created.","score":[0.0751,0.2824]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Strategy) Callback() *fire.Callback {\r\n\t\r\n\tif s.CollectionAction == nil {\r\n\t\ts.CollectionAction = make(map[string][]*Authorizer)\r\n\t}\r\n\tif s.ResourceAction == nil {\r\n\t\ts.ResourceAction = make(map[string][]*Authorizer)\r\n\t}\r\n\t\r\n\treturn fire.C(\"ash\/Strategy.Callback\", fire.All(), func(ctx *fire.Context) (err error) {\r\n\t\tswitch ctx.Operation {\r\n\t\tcase fire.List:\r\n\t\t\terr = s.call(ctx, s.List, s.Read, s.All)\r\n\t\tcase fire.Find:\r\n\t\t\terr = s.call(ctx, s.Find, s.Read, s.All)\r\n\t\tcase fire.Create:\r\n\t\t\terr = s.call(ctx, s.Create, s.Write, s.All)\r\n\t\tcase fire.Update:\r\n\t\t\terr = s.call(ctx, s.Update, s.Write, s.All)\r\n\t\tcase fire.Delete:\r\n\t\t\terr = s.call(ctx, s.Delete, s.Write, s.All)\r\n\t\tcase fire.CollectionAction:\r\n\t\t\terr = s.call(ctx, s.CollectionAction[ctx.JSONAPIRequest.CollectionAction], s.CollectionActions, s.Actions, s.All)\r\n\t\tcase fire.ResourceAction:\r\n\t\t\terr = s.call(ctx, s.ResourceAction[ctx.JSONAPIRequest.ResourceAction], s.ResourceActions, s.Actions, s.All)\r\n\t\t}\r\n\t\treturn err\r\n\t})\r\n}","code-length":415,"reference":"\/\/ Callback will return a callback that authorizes operations using the strategy.","result":"Create a callback function for the strategy.","score":[0.1471,0.3878]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OpenStream(store *Store, model Model, token []byte, receiver Receiver, opened func(), manager func(error) bool) *Stream {\r\n\t\r\n\tvar resumeToken *bson.Raw\r\n\t\r\n\tif token != nil {\r\n\t\tresumeToken = &bson.Raw{\r\n\t\t\tKind: bson.ElementDocument,\r\n\t\t\tData: token,\r\n\t\t}\r\n\t}\r\n\t\r\n\ts := &Stream{\r\n\t\tstore:    store,\r\n\t\tmodel:    model,\r\n\t\ttoken:    resumeToken,\r\n\t\treceiver: receiver,\r\n\t\topened:   opened,\r\n\t\tmanager:  manager,\r\n\t}\r\n\t\r\n\tgo s.open()\r\n\treturn s\r\n}","code-length":194,"reference":"\/\/ OpenStream will open a stream and continuously forward events to the specified\n\/\/ receiver until the stream is closed. If a token is present it will be used to\n\/\/ resume the stream. The provided opened function is called when the stream has\n\/\/ been opened the first time. The passed manager is called with errors returned\n\/\/ by the underlying change stream. The managers result is used to determine if\n\/\/ the stream should be opened again.\n\/\/\n\/\/ The stream automatically resumes on errors using an internally stored resume\n\/\/ token. Applications that need more control should store the token externally\n\/\/ and reopen the stream manually to resume from a specific position.","result":"Open a stream.","score":[2.127e-17,0.0143]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Stream) Close() {\r\n\t\r\n\ts.mutex.Lock()\r\n\tdefer s.mutex.Unlock()\r\n\t\r\n\ts.closed = true\r\n\t\r\n\tif s.current != nil {\r\n\t\t_ = s.current.Close()\r\n\t}\r\n}","code-length":83,"reference":"\/\/ Close will close the stream.","result":"Close the stream.","score":[0.2351,0.5166]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AddTokenIndexes(i *coal.Indexer, autoExpire bool) {\r\n\ti.Add(&Token{}, false, 0, \"Type\")\r\n\ti.Add(&Token{}, false, 0, \"Application\")\r\n\ti.Add(&Token{}, false, 0, \"User\")\r\n\tif autoExpire {\r\n\t\ti.Add(&Token{}, false, time.Minute, \"ExpiresAt\")\r\n\t}\r\n}","code-length":116,"reference":"\/\/ AddTokenIndexes will add access token indexes to the specified indexer.","result":"Index all token indexes.","score":[0.0555,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Token) GetTokenData() (TokenType, []string, time.Time, bson.ObjectId, *bson.ObjectId) {\r\n\treturn t.Type, t.Scope, t.ExpiresAt, t.Application, t.User\r\n}","code-length":67,"reference":"\/\/ GetTokenData implements the flame.GenericToken interface.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Token) SetTokenData(typ TokenType, scope []string, expiresAt time.Time, client Client, resourceOwner ResourceOwner) {\r\n\tt.Type = typ\r\n\tt.Scope = scope\r\n\tt.ExpiresAt = expiresAt\r\n\tt.Application = client.ID()\r\n\tif resourceOwner != nil {\r\n\t\tt.User = coal.P(resourceOwner.ID())\r\n\t}\r\n}","code-length":112,"reference":"\/\/ SetTokenData implements the flame.GenericToken interface.","result":"Set token data in the token.","score":[0.193,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Application) ValidSecret(secret string) bool {\r\n\treturn bcrypt.CompareHashAndPassword(a.SecretHash, []byte(secret)) == nil\r\n}","code-length":50,"reference":"\/\/ ValidSecret implements the flame.Client interface.","result":"Validate secret.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Application) HashSecret() error {\r\n\t\r\n\tif len(a.Secret) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\thash, err := bcrypt.GenerateFromPassword([]byte(a.Secret), bcrypt.DefaultCost)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\ta.SecretHash = hash\r\n\t\r\n\ta.Secret = \"\"\r\n\treturn nil\r\n}","code-length":125,"reference":"\/\/ HashSecret will hash Secret and set SecretHash.","result":"Generate the hash of the secret.","score":[0.1383,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *User) ValidPassword(password string) bool {\r\n\treturn bcrypt.CompareHashAndPassword(u.PasswordHash, []byte(password)) == nil\r\n}","code-length":50,"reference":"\/\/ ValidPassword implements the flame.ResourceOwner interface.","result":"Validate the password.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *User) HashPassword() error {\r\n\t\r\n\tif len(u.Password) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\thash, err := bcrypt.GenerateFromPassword([]byte(u.Password), bcrypt.DefaultCost)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tu.PasswordHash = hash\r\n\t\r\n\tu.Password = \"\"\r\n\treturn nil\r\n}","code-length":125,"reference":"\/\/ HashPassword will hash Password and set PasswordHash.","result":"Generate the password hash.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MustCreateStore(uri string) *Store {\r\n\tstore, err := CreateStore(uri)\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\treturn store\r\n}","code-length":61,"reference":"\/\/ MustCreateStore will dial the passed database and return a new store. It will\n\/\/ panic if the initial connection failed.","result":"Create a store.","score":[0.0012,0.0521]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CreateStore(uri string) (*Store, error) {\r\n\tsession, err := mgo.Dial(uri)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn NewStore(session), nil\r\n}","code-length":69,"reference":"\/\/ CreateStore will dial the passed database and return a new store. It will\n\/\/ return an error if the initial connection failed","result":"Create a new store.","score":[0.0057,0.1395]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *SubStore) C(model Model) *mgo.Collection {\r\n\treturn s.DB().C(C(model))\r\n}","code-length":44,"reference":"\/\/ C will return the collection associated to the passed model.","result":"Store the data.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewAssetServer(prefix, directory string) http.Handler {\r\n\t\r\n\tprefix = \"\/\" + strings.Trim(prefix, \"\/\")\r\n\t\r\n\tdir := http.Dir(directory)\r\n\t\r\n\tfs := http.FileServer(dir)\r\n\th := func(w http.ResponseWriter, r *http.Request) {\r\n\t\t\r\n\t\tf, err := dir.Open(r.URL.Path)\r\n\t\tif err != nil {\r\n\t\t\tr.URL.Path = \"\/\"\r\n\t\t} else if f != nil {\r\n\t\t\t_ = f.Close()\r\n\t\t}\r\n\t\t\r\n\t\tfs.ServeHTTP(w, r)\r\n\t}\r\n\treturn http.StripPrefix(prefix, http.HandlerFunc(h))\r\n}","code-length":198,"reference":"\/\/ NewAssetServer constructs an asset server handler that serves an asset\n\/\/ directory on a specified path and serves the index file for not found paths\n\/\/ which is needed to run single page applications like Ember.","result":"Create a new asset server.","score":[0.0005,0.0296]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DefaultGrantStrategy(scope oauth2.Scope, _ Client, _ ResourceOwner) (oauth2.Scope, error) {\r\n\t\r\n\tif !scope.Empty() {\r\n\t\treturn nil, ErrInvalidScope\r\n\t}\r\n\treturn scope, nil\r\n}","code-length":72,"reference":"\/\/ DefaultGrantStrategy grants only empty scopes.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DefaultTokenData(_ Client, ro ResourceOwner, _ GenericToken) map[string]interface{} {\r\n\tif ro != nil {\r\n\t\treturn map[string]interface{}{\r\n\t\t\t\"user\": ro.ID(),\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":79,"reference":"\/\/ DefaultTokenData adds the user's id to the token data claim.","result":"Generate the default token data.","score":[0.0861,0.0962]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Policy) GenerateToken(id bson.ObjectId, issuedAt, expiresAt time.Time, client Client, resourceOwner ResourceOwner, token GenericToken) (string, error) {\r\n\t\r\n\tclaims := &TokenClaims{}\r\n\tclaims.Id = id.Hex()\r\n\tclaims.IssuedAt = issuedAt.Unix()\r\n\tclaims.ExpiresAt = expiresAt.Unix()\r\n\t\r\n\tif p.TokenData != nil {\r\n\t\tclaims.Data = p.TokenData(client, resourceOwner, token)\r\n\t}\r\n\t\r\n\ttkn := jwt.NewWithClaims(jwt.SigningMethodHS256, claims)\r\n\t\r\n\tstr, err := tkn.SignedString(p.Secret)\r\n\tif err != nil {\r\n\t\treturn \"\", nil\r\n\t}\r\n\treturn str, nil\r\n}","code-length":211,"reference":"\/\/ GenerateToken returns a new token for the provided information.","result":"Generate the token.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Policy) ParseToken(str string) (*TokenClaims, bool, error) {\r\n\t\r\n\tvar claims TokenClaims\r\n\t_, err := jwt.ParseWithClaims(str, &claims, func(_ *jwt.Token) (interface{}, error) {\r\n\t\treturn p.Secret, nil\r\n\t})\r\n\tif valErr, ok := err.(*jwt.ValidationError); ok && valErr.Errors == jwt.ValidationErrorExpired {\r\n\t\treturn nil, true, err\r\n\t} else if err != nil {\r\n\t\treturn nil, false, err\r\n\t} else if !bson.IsObjectIdHex(claims.Id) {\r\n\t\treturn nil, false, errors.New(\"invalid id\")\r\n\t}\r\n\treturn &claims, false, nil\r\n}","code-length":197,"reference":"\/\/ ParseToken will parse the presented token and return its claims, if it is\n\/\/ expired and eventual errors.","result":"Parse the token.","score":[0.002,0.1078]}
{"code":"\/*is used to<extra_id_0>\r\nfunc E(name string, m fire.Matcher, h fire.Handler) *Enforcer {\r\n\treturn fire.C(name, m, h)\r\n}","code-length":45,"reference":"\/\/ E is a short-hand function to create an enforcer.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Base) MustGet(name string) interface{} {\r\n\t\r\n\tfield := b.meta.Fields[name]\r\n\tif field == nil {\r\n\t\tpanic(fmt.Sprintf(`coal: field \"%s\" not found on \"%s\"`, name, b.meta.Name))\r\n\t}\r\n\t\r\n\tstructField := reflect.ValueOf(b.model).Elem().Field(field.index)\r\n\treturn structField.Interface()\r\n}","code-length":125,"reference":"\/\/ MustGet returns the value of the given field. MustGet will panic if no field\n\/\/ has been found.","result":"Get the value of a field.","score":[0.0489,0.1783]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Base) MustSet(name string, value interface{}) {\r\n\t\r\n\tfield := b.meta.Fields[name]\r\n\tif field == nil {\r\n\t\tpanic(fmt.Sprintf(`coal: field \"%s\" not found on \"%s\"`, name, b.meta.Name))\r\n\t}\r\n\t\r\n\treflect.ValueOf(b.model).Elem().Field(field.index).Set(reflect.ValueOf(value))\r\n}","code-length":126,"reference":"\/\/ MustSet will set the given field to the the passed valued. MustSet will panic\n\/\/ if no field has been found.","result":"Set the field value.","score":[0.0042,0.0743]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewGroup() *Group {\r\n\treturn &Group{\r\n\t\tcontrollers: make(map[string]*Controller),\r\n\t\tactions:     make(map[string]*GroupAction),\r\n\t}\r\n}","code-length":60,"reference":"\/\/ NewGroup creates and returns a new group.","result":"Create a new group.","score":[0.2421,0.4934]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Group) Add(controllers ...*Controller) {\r\n\tfor _, controller := range controllers {\r\n\t\t\r\n\t\tcontroller.prepare()\r\n\t\t\r\n\t\tname := controller.Model.Meta().PluralName\r\n\t\t\r\n\t\tif g.controllers[name] != nil {\r\n\t\t\tpanic(fmt.Sprintf(`fire: controller with name \"%s\" already exists`, name))\r\n\t\t}\r\n\t\t\r\n\t\tg.controllers[name] = controller\r\n\t}\r\n}","code-length":132,"reference":"\/\/ Add will add a controller to the group.","result":"Add controllers to a group.","score":[0.1527,0.4326]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Group) Endpoint(prefix string) http.Handler {\r\n\t\r\n\tprefix = strings.Trim(prefix, \"\/\")\r\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\r\n\t\t\r\n\t\ttracer := NewTracerFromRequest(r, \"fire\/Group.Endpoint\")\r\n\t\tdefer tracer.Finish(true)\r\n\t\t\r\n\t\tdefer stack.Resume(func(err error) {\r\n\t\t\t\r\n\t\t\tif jsonapiError, ok := err.(*jsonapi.Error); ok {\r\n\t\t\t\t_ = jsonapi.WriteError(w, jsonapiError)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\ttracer.Tag(\"error\", true)\r\n\t\t\ttracer.Log(\"error\", err.Error())\r\n\t\t\ttracer.Log(\"stack\", stack.Trace())\r\n\t\t\t\r\n\t\t\tif g.Reporter != nil {\r\n\t\t\t\tg.Reporter(err)\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\t_ = jsonapi.WriteError(w, jsonapi.InternalServerError(\"\"))\r\n\t\t})\r\n\t\t\r\n\t\tpath := strings.Trim(r.URL.Path, \"\/\")\r\n\t\tpath = strings.TrimPrefix(path, prefix)\r\n\t\tpath = strings.Trim(path, \"\/\")\r\n\t\t\r\n\t\tif path == \"\" {\r\n\t\t\tstack.Abort(jsonapi.NotFound(\"resource not found\"))\r\n\t\t}\r\n\t\t\r\n\t\ts := strings.Split(path, \"\/\")\r\n\t\t\r\n\t\tctx := &Context{\r\n\t\t\tData:           Map{},\r\n\t\t\tHTTPRequest:    r,\r\n\t\t\tResponseWriter: w,\r\n\t\t\tGroup:          g,\r\n\t\t\tTracer:         tracer,\r\n\t\t}\r\n\t\t\r\n\t\tcontroller, ok := g.controllers[s[0]]\r\n\t\tif ok {\r\n\t\t\t\r\n\t\t\tctx.Controller = controller\r\n\t\t\t\r\n\t\t\tcontroller.generalHandler(prefix, ctx)\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\taction, ok := g.actions[s[0]]\r\n\t\tif ok {\r\n\t\t\t\r\n\t\t\tif Contains(action.Action.Methods, r.Method) {\r\n\t\t\t\t\r\n\t\t\t\tif action.Action.Callback.Matcher(ctx) {\r\n\t\t\t\t\t\r\n\t\t\t\t\tfor _, cb := range action.Authorizers {\r\n\t\t\t\t\t\t\r\n\t\t\t\t\t\tif !cb.Matcher(ctx) {\r\n\t\t\t\t\t\t\tcontinue\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\t\r\n\t\t\t\t\t\terr := cb.Handler(ctx)\r\n\t\t\t\t\t\tif IsSafe(err) {\r\n\t\t\t\t\t\t\tstack.Abort(&jsonapi.Error{\r\n\t\t\t\t\t\t\t\tStatus: http.StatusUnauthorized,\r\n\t\t\t\t\t\t\t\tDetail: err.Error(),\r\n\t\t\t\t\t\t\t})\r\n\t\t\t\t\t\t} else if err != nil {\r\n\t\t\t\t\t\t\tstack.Abort(err)\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t}\r\n\t\t\t\t\t\r\n\t\t\t\t\tLimitBody(ctx.ResponseWriter, ctx.HTTPRequest, int64(action.Action.BodyLimit))\r\n\t\t\t\t\t\r\n\t\t\t\t\tstack.AbortIf(action.Action.Callback.Handler(ctx))\r\n\t\t\t\t\treturn\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tstack.Abort(jsonapi.NotFound(\"resource not found\"))\r\n\t})\r\n}","code-length":810,"reference":"\/\/ Endpoint will return an http handler that serves requests for this group. The\n\/\/ specified prefix is used to parse the requests and generate urls for the\n\/\/ resources.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *Indexer) Add(model Model, unique bool, expireAfter time.Duration, fields ...string) {\r\n\t\r\n\tvar key []string\r\n\tfor _, f := range fields {\r\n\t\tkey = append(key, F(model, f))\r\n\t}\r\n\t\r\n\ti.AddRaw(C(model), mgo.Index{\r\n\t\tKey:         key,\r\n\t\tUnique:      unique,\r\n\t\tExpireAfter: expireAfter,\r\n\t\tBackground:  true,\r\n\t})\r\n}","code-length":138,"reference":"\/\/ Add will add an index to the internal index list. Fields that are prefixed\n\/\/ with a dash will result in an descending index. See the MongoDB documentation\n\/\/ for more details.","result":"Index the model.","score":[0.0,0.0333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *Indexer) AddRaw(coll string, idx mgo.Index) {\r\n\ti.indexes = append(i.indexes, index{\r\n\t\tcoll:  coll,\r\n\t\tindex: idx,\r\n\t})\r\n}","code-length":66,"reference":"\/\/ AddRaw will add a raw mgo.Index to the internal index list.","result":"Add raw index to the index.","score":[0.1194,0.3263]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *Indexer) Ensure(store *Store) error {\r\n\t\r\n\ts := store.Copy()\r\n\tdefer s.Close()\r\n\t\r\n\tfor _, i := range i.indexes {\r\n\t\t\r\n\t\terr := s.DB().C(i.coll).EnsureIndex(i.index)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":117,"reference":"\/\/ Ensure will ensure that the required indexes exist. It may fail early if some\n\/\/ of the indexes are already existing and do not match the supplied index.","result":"Ensure the index.","score":[0.0001,0.0568]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCatalog(models ...Model) *Catalog {\r\n\t\r\n\tc := &Catalog{\r\n\t\tmodels: make(map[string]Model),\r\n\t}\r\n\t\r\n\tc.Add(models...)\r\n\treturn c\r\n}","code-length":69,"reference":"\/\/ NewCatalog will create a new catalog.","result":"Create a new catalog.","score":[0.3108,0.5924]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Catalog) Add(models ...Model) {\r\n\tfor _, model := range models {\r\n\t\t\r\n\t\tname := Init(model).Meta().PluralName\r\n\t\t\r\n\t\tif c.models[name] != nil {\r\n\t\t\tpanic(fmt.Sprintf(`coal: model with name \"%s\" already exists in catalog`, name))\r\n\t\t}\r\n\t\t\r\n\t\tc.models[name] = model\r\n\t}\r\n}","code-length":123,"reference":"\/\/ Add will add the specified models to the catalog.","result":"Add models to the catalog.","score":[0.2926,0.5095]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Catalog) All() []Model {\r\n\t\r\n\tmodels := make([]Model, 0, len(c.models))\r\n\t\r\n\tfor _, model := range c.models {\r\n\t\tmodels = append(models, model)\r\n\t}\r\n\treturn models\r\n}","code-length":81,"reference":"\/\/ All returns a list of all registered models.","result":"Get all the models in the catalog.","score":[0.1214,0.0568]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Catalog) Visualize(title string) string {\r\n\t\r\n\tvar out bytes.Buffer\r\n\t\r\n\tout.WriteString(\"graph G {\\n\")\r\n\tout.WriteString(\"  rankdir=\\\"LR\\\";\\n\")\r\n\tout.WriteString(\"  sep=\\\"0.3\\\";\\n\")\r\n\tout.WriteString(\"  ranksep=\\\"0.5\\\";\\n\")\r\n\tout.WriteString(\"  nodesep=\\\"0.4\\\";\\n\")\r\n\tout.WriteString(\"  pad=\\\"0.4,0.4\\\";\\n\")\r\n\tout.WriteString(\"  margin=\\\"0,0\\\";\\n\")\r\n\tout.WriteString(\"  labelloc=\\\"t\\\";\\n\")\r\n\tout.WriteString(\"  fontsize=\\\"13\\\";\\n\")\r\n\tout.WriteString(\"  fontname=\\\"Arial BoldMT\\\";\\n\")\r\n\tout.WriteString(\"  splines=\\\"spline\\\";\\n\")\r\n\tout.WriteString(\"  overlap=\\\"voronoi\\\";\\n\")\r\n\tout.WriteString(\"  outputorder=\\\"edgesfirst\\\";\\n\")\r\n\tout.WriteString(\"  edge[headclip=true, tailclip=false];\\n\")\r\n\tout.WriteString(\"  label=\\\"\" + title + \"\\\";\\n\")\r\n\t\r\n\tvar names []string\r\n\tlookup := make(map[string]string)\r\n\tfor name, model := range c.models {\r\n\t\tnames = append(names, name)\r\n\t\tlookup[name] = model.Meta().Name\r\n\t}\r\n\tsort.Strings(names)\r\n\t\r\n\tfor _, name := range names {\r\n\t\t\r\n\t\tmodel := c.models[name]\r\n\t\t\r\n\t\tout.WriteString(fmt.Sprintf(`  \"%s\" [ style=filled, fillcolor=white, label=`, lookup[name]))\r\n\t\t\r\n\t\tout.WriteString(fmt.Sprintf(`<<table border=\"0\" align=\"center\" cellspacing=\"0.5\" cellpadding=\"0\" width=\"134\"><tr><td align=\"center\" valign=\"bottom\" width=\"130\"><font face=\"Arial BoldMT\" point-size=\"11\">%s<\/font><\/td><\/tr><\/table>|`, lookup[name]))\r\n\t\t\r\n\t\tout.WriteString(fmt.Sprintf(`<table border=\"0\" align=\"left\" cellspacing=\"2\" cellpadding=\"0\" width=\"134\">`))\r\n\t\t\r\n\t\tfor _, field := range model.Meta().OrderedFields {\r\n\t\t\tout.WriteString(fmt.Sprintf(`<tr><td align=\"left\" width=\"130\" port=\"%s\">%s<font face=\"Arial ItalicMT\" color=\"grey60\"> %s<\/font><\/td><\/tr>`, field.Name, field.Name, field.Type.String()))\r\n\t\t}\r\n\t\t\r\n\t\tout.WriteString(fmt.Sprintf(`<\/table>>`))\r\n\t\t\r\n\t\tout.WriteString(`, shape=Mrecord, fontsize=10, fontname=\"ArialMT\", margin=\"0.07,0.05\", penwidth=\"1.0\" ];` + \"\\n\")\r\n\t}\r\n\t\r\n\ttype rel struct {\r\n\t\tfrom, to   string\r\n\t\tsrcMany    bool\r\n\t\tdstMany    bool\r\n\t\thasInverse bool\r\n\t}\r\n\t\r\n\tlist := make(map[string]*rel)\r\n\tvar relNames []string\r\n\t\r\n\tfor _, name := range names {\r\n\t\t\r\n\t\tmodel := c.models[name]\r\n\t\t\r\n\t\tfor _, field := range model.Meta().OrderedFields {\r\n\t\t\tif field.RelName != \"\" && (field.ToOne || field.ToMany) {\r\n\t\t\t\tlist[name+\"-\"+field.RelName] = &rel{\r\n\t\t\t\t\tfrom:    name,\r\n\t\t\t\t\tto:      field.RelType,\r\n\t\t\t\t\tsrcMany: field.ToMany,\r\n\t\t\t\t}\r\n\t\t\t\trelNames = append(relNames, name+\"-\"+field.RelName)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor _, name := range names {\r\n\t\t\r\n\t\tmodel := c.models[name]\r\n\t\t\r\n\t\tfor _, field := range model.Meta().OrderedFields {\r\n\t\t\tif field.RelName != \"\" && (field.HasOne || field.HasMany) {\r\n\t\t\t\tr := list[field.RelType+\"-\"+field.RelInverse]\r\n\t\t\t\tr.dstMany = field.HasMany\r\n\t\t\t\tr.hasInverse = true\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\tsort.Strings(relNames)\r\n\t\r\n\tfor _, name := range relNames {\r\n\t\t\r\n\t\tr := list[name]\r\n\t\t\r\n\t\tstyle := \"solid\"\r\n\t\tif !r.hasInverse {\r\n\t\t\tstyle = \"dotted\"\r\n\t\t}\r\n\t\t\r\n\t\tcolor := \"black\"\r\n\t\tif r.srcMany {\r\n\t\t\tcolor = \"black:white:black\"\r\n\t\t}\r\n\t\t\r\n\t\tout.WriteString(fmt.Sprintf(`  \"%s\"--\"%s\"[ fontname=\"ArialMT\", fontsize=7, dir=both, arrowsize=\"0.9\", penwidth=\"0.9\", labelangle=32, labeldistance=\"1.8\", style=%s, color=\"%s\", arrowhead=%s, arrowtail=%s ];`, lookup[r.from], lookup[r.to], style, color, \"normal\", \"none\") + \"\\n\")\r\n\t}\r\n\t\r\n\tout.WriteString(\"}\\n\")\r\n\treturn out.String()\r\n}","code-length":1400,"reference":"\/\/ Visualize emits a string in dot format which when rendered with graphviz\n\/\/ visualizes the models and their relationships.","result":"Code too long,keep in 512.","score":[0.012,0.027]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewErrorReporter(out io.Writer) func(error) {\r\n\treturn func(err error) {\r\n\t\t_, _ = fmt.Fprintf(out, \"===> Begin Error: %s\\n\", err.Error())\r\n\t\t_, _ = out.Write(debug.Stack())\r\n\t\t_, _ = fmt.Fprintln(out, \"<=== End Error\")\r\n\t}\r\n}","code-length":106,"reference":"\/\/ NewErrorReporter returns a very basic reporter that writes errors and stack\n\/\/ traces to the specified writer.","result":"Report errors to the given output.","score":[0.0409,0.2214]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EnsureIndexes(store *coal.Store) error {\r\n\t\r\n\terr := indexer.Ensure(store)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":62,"reference":"\/\/ EnsureIndexes will ensure that the required indexes exist.","result":"Ensure the indexes.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc E(format string, a ...interface{}) error {\r\n\treturn Safe(fmt.Errorf(format, a...))\r\n}","code-length":40,"reference":"\/\/ E is a short-hand function to construct a safe error.","result":"Generate the error message.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Compose(chain ...interface{}) http.Handler {\r\n\t\r\n\tif len(chain) < 2 {\r\n\t\tpanic(\"fire: expected chain to have at least two items\")\r\n\t}\r\n\t\r\n\th, ok := chain[len(chain)-1].(http.Handler)\r\n\tif !ok {\r\n\t\tpanic(`fire: expected last chain item to be a \"http.Handler\"`)\r\n\t}\r\n\t\r\n\tfor i := len(chain) - 2; i >= 0; i-- {\r\n\t\t\r\n\t\tm, ok := chain[i].(func(http.Handler) http.Handler)\r\n\t\tif !ok {\r\n\t\t\tpanic(`fire: expected intermediary chain item to be a \"func(http.handler) http.Handler\"`)\r\n\t\t}\r\n\t\t\r\n\t\th = m(h)\r\n\t}\r\n\treturn h\r\n}","code-length":233,"reference":"\/\/ Compose is a short-hand for chaining the specified middleware and handler\n\/\/ together.","result":"Compose a chain of handlers.","score":[0.0472,0.1145]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Includes(all, subset []string) bool {\r\n\tfor _, item := range subset {\r\n\t\tif !Contains(all, item) {\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":68,"reference":"\/\/ Includes returns true if a list of strings includes another list of strings.","result":"Test the includes function.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Intersect(listA, listB []string) []string {\r\n\t\r\n\tlist := make([]string, 0, len(listA))\r\n\t\r\n\tfor _, item := range listA {\r\n\t\tif Contains(listB, item) {\r\n\t\t\tlist = append(list, item)\r\n\t\t}\r\n\t}\r\n\treturn list\r\n}","code-length":101,"reference":"\/\/ Intersect will return the intersection of both lists.","result":"Create the function to do the intersection.","score":[0.1214,0.0568]}
{"code":"\/*is used to<extra_id_0>\r\nfunc E(reason string, retry bool) *Error {\r\n\treturn &Error{\r\n\t\tReason: reason,\r\n\t\tRetry:  retry,\r\n\t}\r\n}","code-length":52,"reference":"\/\/ E is a short-hand to construct an error.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RootTracer() func(http.Handler) http.Handler {\r\n\treturn func(next http.Handler) http.Handler {\r\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\r\n\t\t\t\r\n\t\t\tsegments := strings.Split(r.URL.Path, \"\/\")\r\n\t\t\t\r\n\t\t\tfor i, s := range segments {\r\n\t\t\t\tif bson.IsObjectIdHex(s) {\r\n\t\t\t\t\tsegments[i] = \":id\"\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tpath := strings.Join(segments, \"\/\")\r\n\t\t\tname := fmt.Sprintf(\"%s %s\", r.Method, path)\r\n\t\t\t\r\n\t\t\ttracer := NewTracerFromRequest(r, name)\r\n\t\t\ttracer.Tag(\"peer.address\", r.RemoteAddr)\r\n\t\t\ttracer.Tag(\"http.proto\", r.Proto)\r\n\t\t\ttracer.Tag(\"http.method\", r.Method)\r\n\t\t\ttracer.Tag(\"http.host\", r.Host)\r\n\t\t\ttracer.Log(\"http.url\", r.URL.String())\r\n\t\t\ttracer.Log(\"http.length\", r.ContentLength)\r\n\t\t\ttracer.Log(\"http.header\", r.Header)\r\n\t\t\tr = r.WithContext(tracer.Context(r.Context()))\r\n\t\t\tdefer tracer.Finish(true)\r\n\t\t\t\r\n\t\t\tnext.ServeHTTP(w, r)\r\n\t\t})\r\n\t}\r\n}","code-length":373,"reference":"\/\/ RootTracer is a middleware that can be used to create root trace span for an\n\/\/ incoming request.","result":"Create the root tracer.","score":[0.0075,0.0571]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTracerFromRequest(r *http.Request, name string) *Tracer {\r\n\tspan, _ := opentracing.StartSpanFromContext(r.Context(), name)\r\n\treturn NewTracer(span)\r\n}","code-length":57,"reference":"\/\/ NewTracerFromRequest returns a new tracer that has a root span derived from\n\/\/ the specified request. A span previously added to the request context using\n\/\/ Context is automatically used as the parent.","result":"Create a new span.","score":[0.0002,0.0323]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTracer(root opentracing.Span) *Tracer {\r\n\treturn &Tracer{\r\n\t\troot:  root,\r\n\t\tspans: make([]opentracing.Span, 0, 32),\r\n\t}\r\n}","code-length":62,"reference":"\/\/ NewTracer returns a new tracer with the specified root span.","result":"Create a new Tracer.","score":[0.0785,0.182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Tracer) Push(name string) {\r\n\t\r\n\tvar ctx opentracing.SpanContext\r\n\tif len(t.spans) > 0 {\r\n\t\tctx = t.Last().Context()\r\n\t} else {\r\n\t\tctx = t.root.Context()\r\n\t}\r\n\t\r\n\tspan := opentracing.StartSpan(name, opentracing.ChildOf(ctx))\r\n\t\r\n\tt.spans = append(t.spans, span)\r\n}","code-length":123,"reference":"\/\/ Push will add a new span on to the stack. Successful spans must be finished by\n\/\/ calling Pop. If the code panics or an error is returned the last pushed span\n\/\/ will be flagged with the error and a leftover spans are popped.","result":"Push a span to the tracer.","score":[0.0004,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Tracer) Last() opentracing.Span {\r\n\t\r\n\tif len(t.spans) == 0 {\r\n\t\treturn t.root\r\n\t}\r\n\treturn t.spans[len(t.spans)-1]\r\n}","code-length":68,"reference":"\/\/ Last returns the last pushed span or the root span.","result":"Get the last span.","score":[0.0869,0.1456]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Tracer) Tag(key string, value interface{}) {\r\n\tt.Last().SetTag(key, value)\r\n}","code-length":42,"reference":"\/\/ Tag adds a tag to the last pushed span.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Tracer) Log(key string, value interface{}) {\r\n\tt.Last().LogKV(key, value)\r\n}","code-length":42,"reference":"\/\/ Log adds a log to the last pushed span.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Tracer) Context(ctx context.Context) context.Context {\r\n\treturn opentracing.ContextWithSpan(ctx, t.Last())\r\n}","code-length":45,"reference":"\/\/ Context returns a new context with the latest span stored as a reference for\n\/\/ handlers that will call NewTracerFromRequest or similar.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Tracer) Pop() {\r\n\t\r\n\tif len(t.spans) == 0 {\r\n\t\treturn\r\n\t}\r\n\t\r\n\tt.Last().Finish()\r\n\t\r\n\tt.spans = t.spans[:len(t.spans)-1]\r\n}","code-length":80,"reference":"\/\/ Pop finishes and removes the last pushed span.","result":"Pop the last span.","score":[0.1539,0.3713]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Tracer) Finish(root bool) {\r\n\tfor _, span := range t.spans {\r\n\t\tspan.Finish()\r\n\t}\r\n\tif root {\r\n\t\tt.root.Finish()\r\n\t}\r\n}","code-length":69,"reference":"\/\/ Finish will finish all leftover spans and the root span if requested.","result":"Call the function.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPool() *Pool {\r\n\treturn &Pool{\r\n\t\ttasks:  make(map[string]*Task),\r\n\t\tqueues: make(map[*Queue]bool),\r\n\t\tclosed: make(chan struct{}),\r\n\t}\r\n}","code-length":72,"reference":"\/\/ NewPool creates and returns a new pool.","result":"Create a new pool.","score":[0.2421,0.4934]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Pool) Add(task *Task) {\r\n\t\r\n\tif p.tasks[task.Name] != nil {\r\n\t\tpanic(fmt.Sprintf(`axe: task with name \"%s\" already exists`, task.Name))\r\n\t}\r\n\t\r\n\tp.tasks[task.Name] = task\r\n\t\r\n\ttask.Queue.tasks = append(task.Queue.tasks, task.Name)\r\n\t\r\n\tp.queues[task.Queue] = true\r\n}","code-length":132,"reference":"\/\/ Add will add the specified task and its queue to the pool.","result":"Add tasks to the pool.","score":[0.1074,0.3656]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Pool) Run() {\r\n\t\r\n\tfor queue := range p.queues {\r\n\t\tqueue.start(p)\r\n\t}\r\n\t\r\n\tfor _, task := range p.tasks {\r\n\t\ttask.start(p)\r\n\t}\r\n}","code-length":79,"reference":"\/\/ Run will launch the queue watchers and task workers in the background.","result":"Run the pool.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewBodyLimiter(w http.ResponseWriter, r *http.Request, n int64) *BodyLimiter {\r\n\treturn &BodyLimiter{\r\n\t\tOriginal:   r.Body,\r\n\t\tReadCloser: http.MaxBytesReader(w, r.Body, n),\r\n\t}\r\n}","code-length":81,"reference":"\/\/ NewBodyLimiter returns a new body limiter for the specified request.","result":"Create a new BodyLimiter.","score":[0.0785,0.182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LimitBody(w http.ResponseWriter, r *http.Request, n int64) {\r\n\t\r\n\tif bl, ok := r.Body.(*BodyLimiter); ok {\r\n\t\tr.Body = bl.Original\r\n\t}\r\n\t\r\n\tr.Body = NewBodyLimiter(w, r, n)\r\n}","code-length":89,"reference":"\/\/ LimitBody will limit reading from the body of the supplied request to the\n\/\/ specified amount of bytes. Earlier calls to LimitBody will be overwritten\n\/\/ which essentially allows callers to increase the limit from a default limit.","result":"Limit the body.","score":[0.0,0.0282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc C(name string, m Matcher, h Handler) *Callback {\r\n\t\r\n\tif m == nil || h == nil {\r\n\t\tpanic(\"fire: missing matcher or handler\")\r\n\t}\r\n\treturn &Callback{\r\n\t\tMatcher: m,\r\n\t\tHandler: func(ctx *Context) error {\r\n\t\t\t\r\n\t\t\tctx.Tracer.Push(name)\r\n\t\t\t\r\n\t\t\terr := h(ctx)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tctx.Tracer.Pop()\r\n\t\t\treturn nil\r\n\t\t},\r\n\t}\r\n}","code-length":165,"reference":"\/\/ C is a short-hand function to construct a callback. It will also add tracing\n\/\/ code around the execution of the callback.","result":"Create a callback .","score":[0.0028,0.0237]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Only(ops ...Operation) Matcher {\r\n\treturn func(ctx *Context) bool {\r\n\t\t\r\n\t\tfor _, op := range ops {\r\n\t\t\tif op == ctx.Operation {\r\n\t\t\t\treturn true\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn false\r\n\t}\r\n}","code-length":85,"reference":"\/\/ Only will match if the operation is present in the provided list.","result":"Match only operations.","score":[0,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc BasicAuthorizer(credentials map[string]string) *Callback {\r\n\treturn C(\"fire\/BasicAuthorizer\", All(), func(ctx *Context) error {\r\n\t\t\r\n\t\tuser, password, ok := ctx.HTTPRequest.BasicAuth()\r\n\t\tif !ok {\r\n\t\t\treturn ErrAccessDenied\r\n\t\t}\r\n\t\t\r\n\t\tif val, ok := credentials[user]; !ok || val != password {\r\n\t\t\treturn ErrAccessDenied\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n}","code-length":133,"reference":"\/\/ BasicAuthorizer authorizes requests based on a simple credentials list.","result":"Authorize the user.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ModelValidator() *Callback {\r\n\treturn C(\"fire\/ModelValidator\", Only(Create, Update), func(ctx *Context) error {\r\n\t\t\r\n\t\tm, ok := ctx.Model.(ValidatableModel)\r\n\t\tif !ok {\r\n\t\t\treturn fmt.Errorf(\"model is not validatable\")\r\n\t\t}\r\n\t\t\r\n\t\terr := m.Validate()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n}","code-length":135,"reference":"\/\/ ModelValidator performs a validation of the model using the Validate method.","result":"Validate the model.","score":[0.0242,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc TimestampValidator() *Callback {\r\n\treturn C(\"fire\/TimestampValidator\", Only(Create, Update), func(ctx *Context) error {\r\n\t\t\r\n\t\tnow := time.Now()\r\n\t\t\r\n\t\tctf := coal.L(ctx.Model, \"fire-created-timestamp\", false)\r\n\t\tutf := coal.L(ctx.Model, \"fire-updated-timestamp\", false)\r\n\t\t\r\n\t\t\r\n\t\tif ctf != \"\" {\r\n\t\t\tif ctx.Operation == Create {\r\n\t\t\t\tctx.Model.MustSet(ctf, now)\r\n\t\t\t} else if t := ctx.Model.MustGet(ctf).(time.Time); t.IsZero() {\r\n\t\t\t\tctx.Model.MustSet(ctf, ctx.Model.ID().Time())\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tif utf != \"\" {\r\n\t\t\tctx.Model.MustSet(utf, now)\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n}","code-length":256,"reference":"\/\/ TimestampValidator will set timestamp fields on create and update operations.\n\/\/ The fields are inferred from the model using the \"fire-created-timestamp\" and\n\/\/ \"fire-updated-timestamp\" flags. Missing created timestamps are retroactively\n\/\/ set using the timestamp encoded in the model id.","result":"Generate a timestamp validator function.","score":[0.0002,0.0134]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RelationshipValidator(model coal.Model, catalog *coal.Catalog, excludedFields ...string) *Callback {\r\n\t\r\n\tdependentResources := make(map[coal.Model]string)\r\n\treferences := make(map[string]coal.Model)\r\n\t\r\n\tfor _, field := range coal.Init(model).Meta().Relationships {\r\n\t\t\r\n\t\tif Contains(excludedFields, field.Name) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tif field.HasOne || field.HasMany {\r\n\t\t\t\r\n\t\t\trelatedModel := catalog.Find(field.RelType)\r\n\t\t\tif relatedModel == nil {\r\n\t\t\t\tpanic(fmt.Sprintf(`fire: missing model in catalog: \"%s\"`, field.RelType))\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tbsonField := \"\"\r\n\t\t\tfor _, relatedField := range relatedModel.Meta().Relationships {\r\n\t\t\t\tif relatedField.RelName == field.RelInverse {\r\n\t\t\t\t\tbsonField = relatedField.Name\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tif bsonField == \"\" {\r\n\t\t\t\tpanic(fmt.Sprintf(`fire: missing field for inverse relationship: \"%s\"`, field.RelInverse))\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tdependentResources[relatedModel] = bsonField\r\n\t\t}\r\n\t\t\r\n\t\tif field.ToOne || field.ToMany {\r\n\t\t\t\r\n\t\t\trelatedModel := catalog.Find(field.RelType)\r\n\t\t\tif relatedModel == nil {\r\n\t\t\t\tpanic(fmt.Sprintf(`fire: missing model in catalog: \"%s\"`, field.RelType))\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\treferences[field.Name] = relatedModel\r\n\t\t}\r\n\t}\r\n\t\r\n\tcb1 := DependentResourcesValidator(dependentResources)\r\n\tcb2 := VerifyReferencesValidator(references)\r\n\treturn C(\"RelationshipValidator\", func(ctx *Context) bool {\r\n\t\treturn cb1.Matcher(ctx) || cb2.Matcher(ctx)\r\n\t}, func(ctx *Context) error {\r\n\t\t\r\n\t\tif cb1.Matcher(ctx) {\r\n\t\t\terr := cb1.Handler(ctx)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tif cb2.Matcher(ctx) {\r\n\t\t\terr := cb2.Handler(ctx)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n}","code-length":639,"reference":"\/\/ RelationshipValidator makes sure all relationships of a model are correct and\n\/\/ in place. It does so by combining a DependentResourcesValidator and a\n\/\/ VerifyReferencesValidator based on the specified model and catalog.","result":"Code too long,keep in 512.","score":[0.0009,0.0166]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Seekret) Inspect(Nworkers int) {\r\n\tjobs := make(chan workerJob)\r\n\tresults := make(chan workerResult)\r\n\tfor w := 1; w <= Nworkers; w++ {\r\n\t\tgo inspect_worker(w, jobs, results)\r\n\t}\r\n\tobjectGroupMap := s.GroupObjectsByPrimaryKeyHash()\r\n\tgo func() {\r\n\t\tfor _, objectGroup := range objectGroupMap {\r\n\t\t\tjobs <- workerJob{\r\n\t\t\t\tobjectGroup:   objectGroup,\r\n\t\t\t\truleList:      s.ruleList,\r\n\t\t\t\texceptionList: s.exceptionList,\r\n\t\t\t}\r\n\t\t}\r\n\t\tclose(jobs)\r\n\t}()\r\n\tfor i := 0; i < len(objectGroupMap); i++ {\r\n\t\tresult := <-results\r\n\t\ts.secretList = append(s.secretList, result.secretList...)\r\n\t}\r\n}","code-length":240,"reference":"\/\/ Inspect executes the inspection into all loaded objects, by checking all\n\/\/ rules and exceptions loaded.","result":"Generate code for the Inspect function.","score":[0.0367,0.0629]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRule(name string, match string) (*Rule, error) {\r\n\tmatchRegexp, err := regexp.Compile(\"(?i)\" + match)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err != nil {\r\n\t\tfmt.Println(err)\r\n\t}\r\n\tr := &Rule{\r\n\t\tEnabled: false,\r\n\t\tName:    name,\r\n\t\tMatch:   matchRegexp,\r\n\t}\r\n\treturn r, nil\r\n}","code-length":136,"reference":"\/\/ NewRule creates a new rule.","result":"Create a new rule.","score":[0.3991,0.6843]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Rule) AddUnmatch(unmatch string) error {\r\n\tunmatchRegexp, err := regexp.Compile(\"(?i)\" + unmatch)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tr.Unmatch = append(r.Unmatch, unmatchRegexp)\r\n\treturn nil\r\n}","code-length":90,"reference":"\/\/ AddUnmatch adds a refular expression into the unmatch list.","result":"Add unmatched regexp to the.","score":[0,0.1053]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Rule) Run(content []byte) []RunResult {\r\n\tvar results []RunResult\r\n\tb := bufio.NewScanner(bytes.NewReader(content))\r\n\tnLine := 0\r\n\tfor b.Scan() {\r\n\t\tnLine = nLine + 1\r\n\t\tline := b.Text()\r\n\t\tif r.Match.MatchString(line) {\r\n\t\t\tunmatch := false\r\n\t\t\tfor _, Unmatch := range r.Unmatch {\r\n\t\t\t\tif Unmatch.MatchString(line) {\r\n\t\t\t\t\tunmatch = true\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tif !unmatch {\r\n\t\t\t\tresults = append(results, RunResult{\r\n\t\t\t\t\tLine:  line,\r\n\t\t\t\t\tNline: nLine,\r\n\t\t\t\t})\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn results\r\n}","code-length":226,"reference":"\/\/ Run executes the rule into a content to find all lines that matches it.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSecret(object *Object, rule *Rule, nLine int, line string) *Secret {\r\n\ts := &Secret{\r\n\t\tObject: object,\r\n\t\tRule:   rule,\r\n\t\tNline:  nLine,\r\n\t\tLine:   line,\r\n\t}\r\n\treturn s\r\n}","code-length":88,"reference":"\/\/ NewSecret creates a new secret.","result":"Create a new secret.","score":[0.3991,0.6843]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewObject(name string, t string, st string, content []byte) *Object {\r\n\tif len(content) > MaxObjectContentLen {\r\n\t\tcontent = content[:MaxObjectContentLen]\r\n\t}\r\n\to := &Object{\r\n\t\tType: t,\r\n\t\tSubType: st,\r\n\t\tName:    name,\r\n\t\tContent: content,\r\n\t\tMetadata:       make(map[string]MetadataData),\r\n\t\tPrimaryKeyHash: nil,\r\n\t}\r\n\treturn o\r\n}","code-length":138,"reference":"\/\/ NewObject creates a new object.","result":"Create a new object.","score":[0.3991,0.6843]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *Object) SetMetadata(key string, value string, attr MetadataAttributes) error {\r\n\to.Metadata[key] = MetadataData{\r\n\t\tvalue: value,\r\n\t\tattr:  attr,\r\n\t}\r\n\tif attr.PrimaryKey {\r\n\t\to.updatePrimaryKeyHash()\r\n\t}\r\n\treturn nil\r\n}","code-length":94,"reference":"\/\/ SetMetadata sets a metadata value for the object.","result":"Set the metadata in the object.","score":[0.1833,0.3628]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *Object) GetMetadata(key string) (string, error) {\r\n\tdata, ok := o.Metadata[key]\r\n\tif !ok {\r\n\t\treturn \"\", fmt.Errorf(\"%s unexistent key\", key)\r\n\t}\r\n\treturn data.value, nil\r\n}","code-length":80,"reference":"\/\/ SetMetadata gets a metadata value from the object.","result":"Get the metadata value of an object.","score":[0.2041,0.4227]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *Object) GetMetadataAll(attr bool) map[string]string {\r\n\tmetadataAll := make(map[string]string)\r\n\tfor k, v := range o.Metadata {\r\n\t\tmetadataAll[k] = v.value\r\n\t}\r\n\treturn metadataAll\r\n}","code-length":81,"reference":"\/\/ GetMetadataAll gets a map that contains all metadata of the object.","result":"Get all metadata from an object.","score":[0.1112,0.2769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (x *Exception) SetRule(rule string) error {\r\n\truleRegexp, err := regexp.Compile(\"(?i)\" + rule)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tx.Rule = ruleRegexp\r\n\treturn nil\r\n}","code-length":76,"reference":"\/\/ SetRule sets the regular expresion that should match the name of the rule.","result":"Set the rule in the exception.","score":[0.0605,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (x *Exception) SetObject(object string) error {\r\n\tobjectRegexp, err := regexp.Compile(\"(?i)\" + object)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tx.Object = objectRegexp\r\n\treturn nil\r\n}","code-length":76,"reference":"\/\/ SetObject sets the regular expresion that should match the name of the\n\/\/ object.","result":"Set the object of the exception.","score":[0.0674,0.2238]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (x *Exception) SetNline(nLine int) error {\r\n\tx.Nline = &nLine\r\n\treturn nil\r\n}","code-length":44,"reference":"\/\/ SetNline sets the number of line where secret should be found.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (x *Exception) SetContent(content string) error {\r\n\tcontentRegexp, err := regexp.Compile(\"(?i)\" + content)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tx.Content = contentRegexp\r\n\treturn nil\r\n}","code-length":76,"reference":"\/\/ SetContent sets the regular expresion that should match the content of the\n\/\/ object.","result":"Set the content of the exception.","score":[0.1348,0.3433]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (x *Exception) Run(s *Secret) bool {\r\n\tmatch := true\r\n\tif match && x.Rule != nil && !x.Rule.MatchString(s.Rule.Name) {\r\n\t\tmatch = false\r\n\t}\r\n\tif match && x.Object != nil && !x.Object.MatchString(s.Object.Name) {\r\n\t\tmatch = false\r\n\t}\r\n\tif match && x.Nline != nil && *x.Nline != s.Nline {\r\n\t\tmatch = false\r\n\t}\r\n\tif match && x.Content != nil && !x.Content.MatchString(s.Line) {\r\n\t\tmatch = false\r\n\t}\r\n\treturn match\r\n}","code-length":184,"reference":"\/\/ Run executes the exception into a secret to determine if it's an exception\n\/\/ or not.","result":"S exception handler.","score":[0.0038,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Seekret) AddRule(rule models.Rule, enabled bool) {\r\n\tif enabled {\r\n\t\trule.Enable()\r\n\t}\r\n\ts.ruleList = append(s.ruleList, rule)\r\n}","code-length":66,"reference":"\/\/ AddRule adds a new rule into the context.","result":"Add rules to the seekret.","score":[0.108,0.1744]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Seekret) LoadRulesFromFile(file string, defaulEnabled bool) error {\r\n\tvar ruleYamlMap map[string]ruleYaml\r\n\tif file == \"\" {\r\n\t\treturn nil\r\n\t}\r\n\tfilename, _ := filepath.Abs(file)\r\n\truleBase := filepath.Base(filename)\r\n\tif filepath.Ext(ruleBase) == \".rule\" {\r\n\t\truleBase = ruleBase[0 : len(ruleBase)-5]\r\n\t}\r\n\tyamlData, err := ioutil.ReadFile(filename)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = yaml.Unmarshal(yamlData, &ruleYamlMap)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfor k, v := range ruleYamlMap {\r\n\t\trule, err := models.NewRule(ruleBase+\".\"+k, v.Match)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tfor _, e := range v.Unmatch {\r\n\t\t\trule.AddUnmatch(e)\r\n\t\t}\r\n\t\ts.AddRule(*rule, defaulEnabled)\r\n\t}\r\n\treturn nil\r\n}","code-length":311,"reference":"\/\/ LoadRulesFromFile loads rules from a YAML file.","result":"Load rules from a file.","score":[0.2919,0.6286]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Seekret) LoadRulesFromDir(dir string, defaulEnabled bool) error {\r\n\tfi, err := os.Stat(dir)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif !fi.IsDir() {\r\n\t\terr := fmt.Errorf(\"%s is not a directory\", dir)\r\n\t\treturn err\r\n\t}\r\n\tfileList, err := filepath.Glob(dir + \"\/*\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfor _, file := range fileList {\r\n\t\tif strings.HasSuffix(file, \".rule\") {\r\n\t\t\terr := s.LoadRulesFromFile(file, defaulEnabled)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":220,"reference":"\/\/ LoadRulesFromFile loads rules from all YAML files inside a directory.","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DefaultRulesPath() string {\r\n\trulesPath := os.Getenv(\"SEEKRET_RULES_PATH\")\r\n\tif rulesPath == \"\" {\r\n\t\trulesPath = os.ExpandEnv(defaultRulesDir)\r\n\t}\r\n\treturn rulesPath\r\n}","code-length":74,"reference":"\/\/ DefaultRulesPath return the default PATH that contains rules.","result":"Generate the default rules path.","score":[0.1527,0.218]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Seekret) EnableRule(name string) error {\r\n\treturn setRuleEnabled(s.ruleList, name, true)\r\n}","code-length":44,"reference":"\/\/ EnableRule enables specific rule.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Seekret) DisableRule(name string) error {\r\n\treturn setRuleEnabled(s.ruleList, name, false)\r\n}","code-length":44,"reference":"\/\/ DisableRule disables specific rule.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Seekret) EnableRuleByRegexp(name string) int {\r\n\treturn setRuleEnabledByRegexp(s.ruleList, name, true)\r\n}","code-length":48,"reference":"\/\/ EnableRule enables rules that match with a regular expression.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Seekret) DisableRuleByRegexp(name string) int {\r\n\treturn setRuleEnabledByRegexp(s.ruleList, name, false)\r\n}","code-length":48,"reference":"\/\/ DisableRule disables rules that match with a regular expression.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Seekret) LoadObjects(st SourceType, source string, opt LoadOptions) error {\r\n\tobjectList, err := st.LoadObjects(source, opt)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ts.objectList = append(s.objectList, objectList...)\r\n\treturn nil\r\n}","code-length":93,"reference":"\/\/ LoadObjects loads objects form an specific source. It can load objects from\n\/\/ different source types, that are implemented following the SourceType\n\/\/ interface.","result":"Load objects in a file.","score":[0.0044,0.0815]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Seekret) GroupObjectsByMetadata(k string) map[string][]models.Object {\r\n\treturn models.GroupObjectsByMetadata(s.objectList, k)\r\n}","code-length":54,"reference":"\/\/ GroupObjectsByMetadata returns a map with all objects grouped by specific\n\/\/ metadata key.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Seekret) GroupObjectsByPrimaryKeyHash() map[string][]models.Object {\r\n\treturn models.GroupObjectsByPrimaryKeyHash(s.objectList)\r\n}","code-length":51,"reference":"\/\/ GroupObjectsByPrimaryKeyHash returns a map with all objects grouped by\n\/\/ the primary key hash, that is calculated from all metadata keys with the\n\/\/ primary attribute.\n\/\/ All returned objects could have the same content, even if are not the same.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Seekret) AddException(exception models.Exception) {\r\n\ts.exceptionList = append(s.exceptionList, exception)\r\n}","code-length":45,"reference":"\/\/ AddException adds a new exception into the context.","result":"Generate the code.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Seekret) LoadExceptionsFromFile(file string) error {\r\n\tvar exceptionYamlList []exceptionYaml\r\n\tif file == \"\" {\r\n\t\treturn nil\r\n\t}\r\n\tfilename, _ := filepath.Abs(file)\r\n\tyamlData, err := ioutil.ReadFile(filename)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = yaml.Unmarshal(yamlData, &exceptionYamlList)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfor _, v := range exceptionYamlList {\r\n\t\tx := models.NewException()\r\n\t\tif v.Rule != nil {\r\n\t\t\terr := x.SetRule(*v.Rule)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\tif v.Object != nil {\r\n\t\t\terr := x.SetObject(*v.Object)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\tif v.Line != nil {\r\n\t\t\terr := x.SetNline(*v.Line)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\tif v.Content != nil {\r\n\t\t\terr := x.SetContent(*v.Content)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\ts.AddException(*x)\r\n\t}\r\n\treturn nil\r\n}","code-length":386,"reference":"\/\/ LoadExceptionsFromFile loads exceptions from a YAML file.","result":"Load exceptions from a file.","score":[0.2919,0.6286]}
{"code":"\/*is used to<extra_id_0>\r\nfunc printPlainResults(results Results) error {\r\n\tfor _, res := range results {\r\n\t\t\r\n\t\tfmt.Printf(\"Source = %s\\n\", res.origString)\r\n\t\tfmt.Printf(\"    String = %s\\n\", res.String)\r\n\t\tif res.Error != \"\" {\r\n\t\t\tfmt.Printf(\"    Error = %s\\n\", res.Error)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\ttyp := reflect.TypeOf(*res)\r\n\t\tval := reflect.ValueOf(*res)\r\n\t\tfor i := 0; i < typ.NumField(); i++ {\r\n\t\t\tfield := typ.Field(i)\r\n\t\t\tif field.Name == \"Error\" || field.Name == \"String\" {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tif field.PkgPath != \"\" {\r\n\t\t\t\t\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tfmt.Printf(\"    %s = %v\\n\", field.Name, val.Field(i).Interface())\r\n\t\t}\r\n\t\tfmt.Print(\"\\n\")\r\n\t}\r\n\treturn nil\r\n}","code-length":286,"reference":"\/\/ printPlainResults prints plain-text output for results","result":"Print results in plain format.","score":[0.1611,0.1471]}
{"code":"\/*is used to<extra_id_0>\r\nfunc printJsonResults(results Results) error {\r\n\tdata, err := json.MarshalIndent(results, \"\", \"    \")\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"Failed to convert results to JSON: %s\", err.Error())\r\n\t}\r\n\tif _, err = io.Copy(os.Stdout, bytes.NewReader(data)); err != nil {\r\n\t\treturn fmt.Errorf(\"Failed to write json output: %s\", err.Error())\r\n\t}\r\n\tfmt.Print(\"\\n\")\r\n\treturn nil\r\n}","code-length":142,"reference":"\/\/ printJsonResults prints json-formatted output for results","result":"Print results to stdout.","score":[0.1509,0.1493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewXor64Source(seed int64) *Xor64Source {\r\n\tvar s Xor64Source\r\n\ts.Seed(seed)\r\n\treturn &s\r\n}","code-length":53,"reference":"\/\/ NewXor64Source returns a pointer to a new Xor64Source seeded with the given\n\/\/ value.","result":"Generate the file.","score":[0.0075,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc xor64(x uint64) uint64 {\r\n\tx ^= x << 13\r\n\tx ^= x >> 7\r\n\tx ^= x << 17\r\n\treturn x\r\n}","code-length":52,"reference":"\/\/ xor64 generates the next value of a pseudo-random sequence given a current\n\/\/ state x.","result":"Perform the xor.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Xor64Source) next() uint64 {\r\n\tx := xor64(uint64(*s))\r\n\t*s = Xor64Source(x)\r\n\treturn x\r\n}","code-length":57,"reference":"\/\/ next advances the generators internal state to the next value and returns\n\/\/ this value as an uint64.","result":"Generate code.","score":[0,0.0289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Xor64Source) Seed(seed int64) {\r\n\tif seed == 0 {\r\n\t\tseed = seed0\r\n\t}\r\n\t*s = Xor64Source(seed)\r\n}","code-length":61,"reference":"\/\/ Seed uses the given value to initialize the generator. If this value is 0, a\n\/\/ pre-defined seed is used instead, since the xorshift algorithm requires at\n\/\/ least one bit of the internal state to be set.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFrameSet(frange string) (*FrameSet, error) {\r\n\t\r\n\tmatches, err := frameRangeMatches(frange)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tframeSet := &FrameSet{frange, &ranges.InclusiveRanges{}}\r\n\t\r\n\tfor _, match := range matches {\r\n\t\tif err = frameSet.handleMatch(match); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\treturn frameSet, nil\r\n}","code-length":144,"reference":"\/\/ Create a new FrameSet from a given frame range string\n\/\/ Returns an error if the frame range could not be parsed.","result":"Create a new frame set.","score":[0.0145,0.0943]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *FrameSet) handleMatch(match []string) error {\r\n\tswitch len(match) {\r\n\t\r\n\tcase 1:\r\n\t\tf, err := parseInt(match[0])\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\ts.rangePtr.AppendUnique(f, f, 1)\r\n\t\r\n\tcase 2:\r\n\t\tstart, err := parseInt(match[0])\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tend, err := parseInt(match[1])\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\tvar inc int\r\n\t\tif start > end {\r\n\t\t\tinc = -1\r\n\t\t} else {\r\n\t\t\tinc = 1\r\n\t\t}\r\n\t\ts.rangePtr.AppendUnique(start, end, inc)\r\n\t\r\n\tcase 4:\r\n\t\tvar (\r\n\t\t\terr               error\r\n\t\t\tmod               string\r\n\t\t\tstart, end, chunk int\r\n\t\t)\r\n\t\tchunk, err = parseInt(match[3])\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif chunk == 0 {\r\n\t\t\treturn fmt.Errorf(\"Failed to parse part of range %v. \"+\r\n\t\t\t\t\"Encountered invalid 0 value\", match[3])\r\n\t\t}\r\n\t\tif start, err = parseInt(match[0]); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif end, err = parseInt(match[1]); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif mod = match[2]; !isModifier(mod) {\r\n\t\t\treturn fmt.Errorf(\"%q is not one of the valid modifier 'xy:'\", mod)\r\n\t\t}\r\n\t\tswitch mod {\r\n\t\tcase `x`:\r\n\t\t\ts.rangePtr.AppendUnique(start, end, chunk)\r\n\t\tcase `y`:\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tskip := start\r\n\t\t\taRange := ranges.NewInclusiveRange(start, end, 1)\r\n\t\t\tvar val int\r\n\t\t\tfor it := aRange.IterValues(); !it.IsDone(); {\r\n\t\t\t\tval = it.Next()\r\n\t\t\t\tif val == skip {\r\n\t\t\t\t\tskip += chunk\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\ts.rangePtr.AppendUnique(val, val, 1)\r\n\t\t\t}\r\n\t\tcase `:`:\r\n\t\t\tfor ; chunk > 0; chunk-- {\r\n\t\t\t\ts.rangePtr.AppendUnique(start, end, chunk)\r\n\t\t\t}\r\n\t\t}\r\n\tdefault:\r\n\t\treturn fmt.Errorf(\"Unexpected match []string size: %v\", match)\r\n\t}\r\n\treturn nil\r\n}","code-length":718,"reference":"\/\/ Process a rangePattern match group","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *FrameSet) Index(frame int) int {\r\n\treturn s.rangePtr.Index(frame)\r\n}","code-length":39,"reference":"\/\/ Index returns the index position of the frame value\n\/\/ within the frame set.\n\/\/ If the given frame does not exist, then return -1","result":"Generate the code.","score":[0.0002,0.0211]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *FrameSet) Frame(index int) (int, error) {\r\n\treturn s.rangePtr.Value(index)\r\n}","code-length":43,"reference":"\/\/ Frame returns the frame number value for a given index into\n\/\/ the frame set.\n\/\/ If the index is outside the bounds of the frame set range,\n\/\/ then an error is returned.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *FrameSet) HasFrame(frame int) bool {\r\n\treturn s.rangePtr.Contains(frame)\r\n}","code-length":40,"reference":"\/\/ HasFrame returns true if the frameset contains the given\n\/\/ frame value.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *FrameSet) FrameRangePadded(pad int) string {\r\n\treturn PadFrameRange(s.frange, pad)\r\n}","code-length":44,"reference":"\/\/ FrameRangePadded returns the range string that was used\n\/\/ to initialize the FrameSet, with each number padded out\n\/\/ with zeros to a given width","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *FrameSet) Normalize() *FrameSet {\r\n\tptr := s.rangePtr.Normalized()\r\n\treturn &FrameSet{ptr.String(), ptr}\r\n}","code-length":51,"reference":"\/\/ Normalize returns a new sorted and compacted FrameSet","result":"Normalize the frame set.","score":[0.0915,0.0588]}
