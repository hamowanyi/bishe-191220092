{"code":"\/*is used to<extra_id_0>\r\nfunc NewSTM(c *v3.Client, apply func(STM) error, so ...stmOption) (*v3.TxnResponse, error) {\r\n\topts := &stmOptions{ctx: c.Ctx()}\r\n\tfor _, f := range so {\r\n\t\tf(opts)\r\n\t}\r\n\tif len(opts.prefetch) != 0 {\r\n\t\tf := apply\r\n\t\tapply = func(s STM) error {\r\n\t\t\ts.Get(opts.prefetch...)\r\n\t\t\treturn f(s)\r\n\t\t}\r\n\t}\r\n\treturn runSTM(mkSTM(c, opts), apply)\r\n}","code-length":172,"reference":"\/\/ NewSTM initiates a new STM instance, using serializable snapshot isolation by default.","result":"Create a new STM.","score":[0.0476,0.155]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rs readSet) first() int64 {\r\n\tret := int64(math.MaxInt64 - 1)\r\n\tfor _, resp := range rs {\r\n\t\tif rev := resp.Header.Revision; rev < ret {\r\n\t\t\tret = rev\r\n\t\t}\r\n\t}\r\n\treturn ret\r\n}","code-length":88,"reference":"\/\/ first returns the store revision from the first fetch","result":"Compute the first revision in a readSet.","score":[0.1647,0.2635]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ws writeSet) cmps(rev int64) []v3.Cmp {\r\n\tcmps := make([]v3.Cmp, 0, len(ws))\r\n\tfor key := range ws {\r\n\t\tcmps = append(cmps, v3.Compare(v3.ModRevision(key), \"<\", rev))\r\n\t}\r\n\treturn cmps\r\n}","code-length":99,"reference":"\/\/ cmps returns a cmp list testing no writes have happened past rev","result":"Generate the cmps function.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSTMRepeatable(ctx context.Context, c *v3.Client, apply func(STM) error) (*v3.TxnResponse, error) {\r\n\treturn NewSTM(c, apply, WithAbortContext(ctx), WithIsolation(RepeatableReads))\r\n}","code-length":75,"reference":"\/\/ NewSTMRepeatable is deprecated.","result":"Create a new STM.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSTMSerializable(ctx context.Context, c *v3.Client, apply func(STM) error) (*v3.TxnResponse, error) {\r\n\treturn NewSTM(c, apply, WithAbortContext(ctx), WithIsolation(Serializable))\r\n}","code-length":72,"reference":"\/\/ NewSTMSerializable is deprecated.","result":"Create a new STMSerializable object.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSTMReadCommitted(ctx context.Context, c *v3.Client, apply func(STM) error) (*v3.TxnResponse, error) {\r\n\treturn NewSTM(c, apply, WithAbortContext(ctx), WithIsolation(ReadCommitted))\r\n}","code-length":74,"reference":"\/\/ NewSTMReadCommitted is deprecated.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCertPool(CAFiles []string) (*x509.CertPool, error) {\r\n\tcertPool := x509.NewCertPool()\r\n\tfor _, CAFile := range CAFiles {\r\n\t\tpemByte, err := ioutil.ReadFile(CAFile)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tfor {\r\n\t\t\tvar block *pem.Block\r\n\t\t\tblock, pemByte = pem.Decode(pemByte)\r\n\t\t\tif block == nil {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\tcert, err := x509.ParseCertificate(block.Bytes)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\tcertPool.AddCert(cert)\r\n\t\t}\r\n\t}\r\n\treturn certPool, nil\r\n}","code-length":218,"reference":"\/\/ NewCertPool creates x509 certPool with provided CA files.","result":"Create a new cert pool.","score":[0,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCert(certfile, keyfile string, parseFunc func([]byte, []byte) (tls.Certificate, error)) (*tls.Certificate, error) {\r\n\tcert, err := ioutil.ReadFile(certfile)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tkey, err := ioutil.ReadFile(keyfile)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif parseFunc == nil {\r\n\t\tparseFunc = tls.X509KeyPair\r\n\t}\r\n\ttlsCert, err := parseFunc(cert, key)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &tlsCert, nil\r\n}","code-length":187,"reference":"\/\/ NewCert generates TLS cert by using the given cert,key and parse function.","result":"Create a new certificate.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *peer) Pause() {\r\n\tp.mu.Lock()\r\n\tdefer p.mu.Unlock()\r\n\tp.paused = true\r\n\tp.msgAppReader.pause()\r\n\tp.msgAppV2Reader.pause()\r\n}","code-length":73,"reference":"\/\/ Pause pauses the peer. The peer will simply drops all incoming\n\/\/ messages without returning an error.","result":"Pause the peer.","score":[0.0043,0.0909]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *peer) Resume() {\r\n\tp.mu.Lock()\r\n\tdefer p.mu.Unlock()\r\n\tp.paused = false\r\n\tp.msgAppReader.resume()\r\n\tp.msgAppV2Reader.resume()\r\n}","code-length":74,"reference":"\/\/ Resume resumes a paused peer.","result":"Resume the peer.","score":[0.1786,0.1754]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *peer) pick(m raftpb.Message) (writec chan<- raftpb.Message, picked string) {\r\n\tvar ok bool\r\n\t\r\n\t\r\n\tif isMsgSnap(m) {\r\n\t\treturn p.pipeline.msgc, pipelineMsg\r\n\t} else if writec, ok = p.msgAppV2Writer.writec(); ok && isMsgApp(m) {\r\n\t\treturn writec, streamAppV2\r\n\t} else if writec, ok = p.writer.writec(); ok {\r\n\t\treturn writec, streamMsg\r\n\t}\r\n\treturn p.pipeline.msgc, pipelineMsg\r\n}","code-length":168,"reference":"\/\/ pick picks a chan for sending the given message. The picked chan and the picked chan\n\/\/ string name are returned.","result":"Pick a message from the cluster.","score":[0.016,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *snapshotSender) post(req *http.Request) (err error) {\r\n\tctx, cancel := context.WithCancel(context.Background())\r\n\treq = req.WithContext(ctx)\r\n\tdefer cancel()\r\n\ttype responseAndError struct {\r\n\t\tresp *http.Response\r\n\t\tbody []byte\r\n\t\terr  error\r\n\t}\r\n\tresult := make(chan responseAndError, 1)\r\n\tgo func() {\r\n\t\tresp, err := s.tr.pipelineRt.RoundTrip(req)\r\n\t\tif err != nil {\r\n\t\t\tresult <- responseAndError{resp, nil, err}\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\ttime.AfterFunc(snapResponseReadTimeout, func() { httputil.GracefulClose(resp) })\r\n\t\tbody, err := ioutil.ReadAll(resp.Body)\r\n\t\tresult <- responseAndError{resp, body, err}\r\n\t}()\r\n\tselect {\r\n\tcase <-s.stopc:\r\n\t\treturn errStopped\r\n\tcase r := <-result:\r\n\t\tif r.err != nil {\r\n\t\t\treturn r.err\r\n\t\t}\r\n\t\treturn checkPostResponse(r.resp, r.body, req, s.to)\r\n\t}\r\n}","code-length":336,"reference":"\/\/ post posts the given request.\n\/\/ It returns nil when request is sent out and processed successfully.","result":"Send snapshot requests to the snapshot sender.","score":[0.0336,0.0888]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newTxnResp(rt *pb.TxnRequest, txnPath []bool) (txnResp *pb.TxnResponse, txnCount int) {\r\n\treqs := rt.Success\r\n\tif !txnPath[0] {\r\n\t\treqs = rt.Failure\r\n\t}\r\n\tresps := make([]*pb.ResponseOp, len(reqs))\r\n\ttxnResp = &pb.TxnResponse{\r\n\t\tResponses: resps,\r\n\t\tSucceeded: txnPath[0],\r\n\t\tHeader:    &pb.ResponseHeader{},\r\n\t}\r\n\tfor i, req := range reqs {\r\n\t\tswitch tv := req.Request.(type) {\r\n\t\tcase *pb.RequestOp_RequestRange:\r\n\t\t\tresps[i] = &pb.ResponseOp{Response: &pb.ResponseOp_ResponseRange{}}\r\n\t\tcase *pb.RequestOp_RequestPut:\r\n\t\t\tresps[i] = &pb.ResponseOp{Response: &pb.ResponseOp_ResponsePut{}}\r\n\t\tcase *pb.RequestOp_RequestDeleteRange:\r\n\t\t\tresps[i] = &pb.ResponseOp{Response: &pb.ResponseOp_ResponseDeleteRange{}}\r\n\t\tcase *pb.RequestOp_RequestTxn:\r\n\t\t\tresp, txns := newTxnResp(tv.RequestTxn, txnPath[1:])\r\n\t\t\tresps[i] = &pb.ResponseOp{Response: &pb.ResponseOp_ResponseTxn{ResponseTxn: resp}}\r\n\t\t\ttxnPath = txnPath[1+txns:]\r\n\t\t\ttxnCount += txns + 1\r\n\t\tdefault:\r\n\t\t}\r\n\t}\r\n\treturn txnResp, txnCount\r\n}","code-length":417,"reference":"\/\/ newTxnResp allocates a txn response for a txn request given a path.","result":"Create a new txn response object.","score":[0.0941,0.122]}
{"code":"\/*is used to<extra_id_0>\r\nfunc applyCompare(rv mvcc.ReadView, c *pb.Compare) bool {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\trr, err := rv.Range(c.Key, mkGteRange(c.RangeEnd), mvcc.RangeOptions{})\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\tif len(rr.KVs) == 0 {\r\n\t\tif c.Target == pb.Compare_VALUE {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\treturn false\r\n\t\t}\r\n\t\treturn compareKV(c, mvccpb.KeyValue{})\r\n\t}\r\n\tfor _, kv := range rr.KVs {\r\n\t\tif !compareKV(c, kv) {\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":211,"reference":"\/\/ applyCompare applies the compare request.\n\/\/ If the comparison succeeds, it returns true. Otherwise, returns false.","result":"Apply a compare to a read view.","score":[0.0387,0.0625]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OpCompact(rev int64, opts ...CompactOption) CompactOp {\r\n\tret := CompactOp{revision: rev}\r\n\tret.applyCompactOpts(opts)\r\n\treturn ret\r\n}","code-length":56,"reference":"\/\/ OpCompact wraps slice CompactOption to create a CompactOp.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPriorityQueue(client *v3.Client, key string) *PriorityQueue {\r\n\treturn &PriorityQueue{client, context.TODO(), key + \"\/\"}\r\n}","code-length":49,"reference":"\/\/ NewPriorityQueue creates an etcd priority queue.","result":"Use the PriorityQueue interface.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *PriorityQueue) Enqueue(val string, pr uint16) error {\r\n\tprefix := fmt.Sprintf(\"%s%05d\", q.key, pr)\r\n\t_, err := newSequentialKV(q.client, prefix, val)\r\n\treturn err\r\n}","code-length":76,"reference":"\/\/ Enqueue puts a value into a queue with a given priority.","result":"Enqueue a string to the queue.","score":[0.0845,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLeaderStats(id string) *LeaderStats {\r\n\treturn &LeaderStats{\r\n\t\tleaderStats: leaderStats{\r\n\t\t\tLeader:    id,\r\n\t\t\tFollowers: make(map[string]*FollowerStats),\r\n\t\t},\r\n\t}\r\n}","code-length":77,"reference":"\/\/ NewLeaderStats generates a new LeaderStats with the given id as leader","result":"Create a new stats object.","score":[0.0838,0.1659]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (fs *FollowerStats) Succ(d time.Duration) {\r\n\tfs.Lock()\r\n\tdefer fs.Unlock()\r\n\ttotal := float64(fs.Counts.Success) * fs.Latency.Average\r\n\ttotalSquare := float64(fs.Counts.Success) * fs.Latency.averageSquare\r\n\tfs.Counts.Success++\r\n\tfs.Latency.Current = float64(d) \/ (1000000.0)\r\n\tif fs.Latency.Current > fs.Latency.Maximum {\r\n\t\tfs.Latency.Maximum = fs.Latency.Current\r\n\t}\r\n\tif fs.Latency.Current < fs.Latency.Minimum {\r\n\t\tfs.Latency.Minimum = fs.Latency.Current\r\n\t}\r\n\tfs.Latency.Average = (total + fs.Latency.Current) \/ float64(fs.Counts.Success)\r\n\tfs.Latency.averageSquare = (totalSquare + fs.Latency.Current*fs.Latency.Current) \/ float64(fs.Counts.Success)\r\n\t\r\n\tfs.Latency.StandardDeviation = math.Sqrt(fs.Latency.averageSquare - fs.Latency.Average*fs.Latency.Average)\r\n}","code-length":289,"reference":"\/\/ Succ updates the FollowerStats with a successful send","result":"Avoid locking.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (fs *FollowerStats) Fail() {\r\n\tfs.Lock()\r\n\tdefer fs.Unlock()\r\n\tfs.Counts.Fail++\r\n}","code-length":47,"reference":"\/\/ Fail updates the FollowerStats with an unsuccessful send","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wbs *watchBroadcasts) delete(w *watcher) int {\r\n\twbs.mu.Lock()\r\n\tdefer wbs.mu.Unlock()\r\n\twb, ok := wbs.watchers[w]\r\n\tif !ok {\r\n\t\tpanic(\"deleting missing watcher from broadcasts\")\r\n\t}\r\n\tdelete(wbs.watchers, w)\r\n\twb.delete(w)\r\n\tif wb.empty() {\r\n\t\tdelete(wbs.bcasts, wb)\r\n\t\twb.stop()\r\n\t}\r\n\treturn len(wbs.bcasts)\r\n}","code-length":162,"reference":"\/\/ delete removes a watcher and returns the number of remaining watchers.","result":"Delete watchers.","score":[0.0034,0.0909]}
{"code":"\/*is used to<extra_id_0>\r\nfunc startStreamWriter(lg *zap.Logger, local, id types.ID, status *peerStatus, fs *stats.FollowerStats, r Raft) *streamWriter {\r\n\tw := &streamWriter{\r\n\t\tlg: lg,\r\n\t\tlocalID: local,\r\n\t\tpeerID:  id,\r\n\t\tstatus: status,\r\n\t\tfs:     fs,\r\n\t\tr:      r,\r\n\t\tmsgc:   make(chan raftpb.Message, streamBufSize),\r\n\t\tconnc:  make(chan *outgoingConn),\r\n\t\tstopc:  make(chan struct{}),\r\n\t\tdone:   make(chan struct{}),\r\n\t}\r\n\tgo w.run()\r\n\treturn w\r\n}","code-length":191,"reference":"\/\/ startStreamWriter creates a streamWrite and starts a long running go-routine that accepts\n\/\/ messages and writes to the attached outgoing connection.","result":"Start the stream writer.","score":[0.0035,0.0495]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkStreamSupport(v *semver.Version, t streamType) bool {\r\n\tnv := &semver.Version{Major: v.Major, Minor: v.Minor}\r\n\tfor _, s := range supportedStream[nv.String()] {\r\n\t\tif s == t {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":100,"reference":"\/\/ checkStreamSupport checks whether the stream type is supported in the\n\/\/ given version.","result":"Check if the stream is supported by the server.","score":[0.1376,0.3786]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pr *Progress) maybeUpdate(n uint64) bool {\r\n\tvar updated bool\r\n\tif pr.Match < n {\r\n\t\tpr.Match = n\r\n\t\tupdated = true\r\n\t\tpr.resume()\r\n\t}\r\n\tif pr.Next < n+1 {\r\n\t\tpr.Next = n + 1\r\n\t}\r\n\treturn updated\r\n}","code-length":103,"reference":"\/\/ maybeUpdate returns false if the given n index comes from an outdated message.\n\/\/ Otherwise it updates the progress and returns true.","result":"Check if the progress is updated.","score":[0.0197,0.12]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pr *Progress) IsPaused() bool {\r\n\tswitch pr.State {\r\n\tcase ProgressStateProbe:\r\n\t\treturn pr.Paused\r\n\tcase ProgressStateReplicate:\r\n\t\treturn pr.ins.full()\r\n\tcase ProgressStateSnapshot:\r\n\t\treturn true\r\n\tdefault:\r\n\t\tpanic(\"unexpected state\")\r\n\t}\r\n}","code-length":101,"reference":"\/\/ IsPaused returns whether sending log entries to this node has been\n\/\/ paused. A node may be paused because it has rejected recent\n\/\/ MsgApps, is currently waiting for a snapshot, or has reached the\n\/\/ MaxInflightMsgs limit.","result":"Check if the progress is paused.","score":[0.001,0.042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pr *Progress) needSnapshotAbort() bool {\r\n\treturn pr.State == ProgressStateSnapshot && pr.Match >= pr.PendingSnapshot\r\n}","code-length":44,"reference":"\/\/ needSnapshotAbort returns true if snapshot progress's Match\n\/\/ is equal or higher than the pendingSnapshot.","result":"Generate the code.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *inflights) add(inflight uint64) {\r\n\tif in.full() {\r\n\t\tpanic(\"cannot add into a full inflights\")\r\n\t}\r\n\tnext := in.start + in.count\r\n\tsize := in.size\r\n\tif next >= size {\r\n\t\tnext -= size\r\n\t}\r\n\tif next >= len(in.buffer) {\r\n\t\tin.growBuf()\r\n\t}\r\n\tin.buffer[next] = inflight\r\n\tin.count++\r\n}","code-length":141,"reference":"\/\/ add adds an inflight into inflights","result":"Add to the inflights buffer.","score":[0.1611,0.1471]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *inflights) growBuf() {\r\n\tnewSize := len(in.buffer) * 2\r\n\tif newSize == 0 {\r\n\t\tnewSize = 1\r\n\t} else if newSize > in.size {\r\n\t\tnewSize = in.size\r\n\t}\r\n\tnewBuffer := make([]uint64, newSize)\r\n\tcopy(newBuffer, in.buffer)\r\n\tin.buffer = newBuffer\r\n}","code-length":115,"reference":"\/\/ grow the inflight buffer by doubling up to inflights.size. We grow on demand\n\/\/ instead of preallocating to inflights.size to handle systems which have\n\/\/ thousands of Raft groups per process.","result":"Avoid the need for the function to be executed.","score":[0.0113,0.0505]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *inflights) freeTo(to uint64) {\r\n\tif in.count == 0 || to < in.buffer[in.start] {\r\n\t\t\r\n\t\treturn\r\n\t}\r\n\tidx := in.start\r\n\tvar i int\r\n\tfor i = 0; i < in.count; i++ {\r\n\t\tif to < in.buffer[idx] {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\t\r\n\t\tsize := in.size\r\n\t\tif idx++; idx >= size {\r\n\t\t\tidx -= size\r\n\t\t}\r\n\t}\r\n\t\r\n\tin.count -= i\r\n\tin.start = idx\r\n\tif in.count == 0 {\r\n\t\t\r\n\t\t\r\n\t\tin.start = 0\r\n\t}\r\n}","code-length":204,"reference":"\/\/ freeTo frees the inflights smaller or equal to the given `to` flight.","result":"Free the inflights.","score":[0.0146,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Snapshotter) SaveDBFrom(r io.Reader, id uint64) (int64, error) {\r\n\tstart := time.Now()\r\n\tf, err := ioutil.TempFile(s.dir, \"tmp\")\r\n\tif err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\tvar n int64\r\n\tn, err = io.Copy(f, r)\r\n\tif err == nil {\r\n\t\tfsyncStart := time.Now()\r\n\t\terr = fileutil.Fsync(f)\r\n\t\tsnapDBFsyncSec.Observe(time.Since(fsyncStart).Seconds())\r\n\t}\r\n\tf.Close()\r\n\tif err != nil {\r\n\t\tos.Remove(f.Name())\r\n\t\treturn n, err\r\n\t}\r\n\tfn := s.dbFilePath(id)\r\n\tif fileutil.Exist(fn) {\r\n\t\tos.Remove(f.Name())\r\n\t\treturn n, nil\r\n\t}\r\n\terr = os.Rename(f.Name(), fn)\r\n\tif err != nil {\r\n\t\tos.Remove(f.Name())\r\n\t\treturn n, err\r\n\t}\r\n\tif s.lg != nil {\r\n\t\ts.lg.Info(\r\n\t\t\t\"saved database snapshot to disk\",\r\n\t\t\tzap.String(\"path\", fn),\r\n\t\t\tzap.Int64(\"bytes\", n),\r\n\t\t\tzap.String(\"size\", humanize.Bytes(uint64(n))),\r\n\t\t)\r\n\t} else {\r\n\t\tplog.Infof(\"saved database snapshot to disk [total bytes: %d]\", n)\r\n\t}\r\n\tsnapDBSaveSec.Observe(time.Since(start).Seconds())\r\n\treturn n, nil\r\n}","code-length":448,"reference":"\/\/ SaveDBFrom saves snapshot of the database from the given reader. It\n\/\/ guarantees the save operation is atomic.","result":"Save snapshot to disk.","score":[0.0075,0.0571]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Snapshotter) DBFilePath(id uint64) (string, error) {\r\n\tif _, err := fileutil.ReadDir(s.dir); err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tfn := s.dbFilePath(id)\r\n\tif fileutil.Exist(fn) {\r\n\t\treturn fn, nil\r\n\t}\r\n\tif s.lg != nil {\r\n\t\ts.lg.Warn(\r\n\t\t\t\"failed to find [SNAPSHOT-INDEX].snap.db\",\r\n\t\t\tzap.Uint64(\"snapshot-index\", id),\r\n\t\t\tzap.String(\"snapshot-file-path\", fn),\r\n\t\t\tzap.Error(ErrNoDBSnapshot),\r\n\t\t)\r\n\t}\r\n\treturn \"\", ErrNoDBSnapshot\r\n}","code-length":203,"reference":"\/\/ DBFilePath returns the file path for the snapshot of the database with\n\/\/ given id. If the snapshot does not exist, it returns error.","result":"Generate the generated code.","score":[0.0017,0.0218]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (us *UniqueStringsValue) Set(s string) error {\r\n\tus.Values = make(map[string]struct{})\r\n\tfor _, v := range strings.Split(s, \",\") {\r\n\t\tus.Values[v] = struct{}{}\r\n\t}\r\n\treturn nil\r\n}","code-length":84,"reference":"\/\/ Set parses a command line set of strings, separated by comma.\n\/\/ Implements \"flag.Value\" interface.\n\/\/ The values are set in order.","result":"Set the value of the unique strings value.","score":[0.0253,0.093]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewUniqueStringsValue(s string) (us *UniqueStringsValue) {\r\n\tus = &UniqueStringsValue{Values: make(map[string]struct{})}\r\n\tif s == \"\" {\r\n\t\treturn us\r\n\t}\r\n\tif err := us.Set(s); err != nil {\r\n\t\tplog.Panicf(\"new UniqueStringsValue should never fail: %v\", err)\r\n\t}\r\n\treturn us\r\n}","code-length":116,"reference":"\/\/ NewUniqueStringsValue implements string slice as \"flag.Value\" interface.\n\/\/ Given value is to be separated by comma.\n\/\/ The values are set in order.","result":"Create a new unique string value.","score":[0.0096,0.0225]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UniqueStringsFromFlag(fs *flag.FlagSet, flagName string) []string {\r\n\treturn (*fs.Lookup(flagName).Value.(*UniqueStringsValue)).stringSlice()\r\n}","code-length":56,"reference":"\/\/ UniqueStringsFromFlag returns a string slice from the flag.","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UniqueStringsMapFromFlag(fs *flag.FlagSet, flagName string) map[string]struct{} {\r\n\treturn (*fs.Lookup(flagName).Value.(*UniqueStringsValue)).Values\r\n}","code-length":59,"reference":"\/\/ UniqueStringsMapFromFlag returns a map of strings from the flag.","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Percentiles(nums []float64) (pcs []float64, data []float64) {\r\n\treturn pctls, percentiles(nums)\r\n}","code-length":46,"reference":"\/\/ Percentiles returns percentile distribution of float64 slice.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ServerConfig) VerifyBootstrap() error {\r\n\tif err := c.hasLocalMember(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := c.advertiseMatchesCluster(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif checkDuplicateURL(c.InitialPeerURLsMap) {\r\n\t\treturn fmt.Errorf(\"initial cluster %s has duplicate url\", c.InitialPeerURLsMap)\r\n\t}\r\n\tif c.InitialPeerURLsMap.String() == \"\" && c.DiscoveryURL == \"\" {\r\n\t\treturn fmt.Errorf(\"initial cluster unset and no discovery URL found\")\r\n\t}\r\n\treturn nil\r\n}","code-length":171,"reference":"\/\/ VerifyBootstrap sanity-checks the initial config for bootstrap case\n\/\/ and returns an error for things that should never happen.","result":"Generate code for generated code.","score":[0.012,0.027]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ServerConfig) VerifyJoinExisting() error {\r\n\t\r\n\t\r\n\tif err := c.hasLocalMember(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif checkDuplicateURL(c.InitialPeerURLsMap) {\r\n\t\treturn fmt.Errorf(\"initial cluster %s has duplicate url\", c.InitialPeerURLsMap)\r\n\t}\r\n\tif c.DiscoveryURL != \"\" {\r\n\t\treturn fmt.Errorf(\"discovery URL should not be set when joining existing initial cluster\")\r\n\t}\r\n\treturn nil\r\n}","code-length":142,"reference":"\/\/ VerifyJoinExisting sanity-checks the initial config for join existing cluster\n\/\/ case and returns an error for things that should never happen.","result":"Verify the join existing initial cluster.","score":[0.0226,0.1547]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ServerConfig) hasLocalMember() error {\r\n\tif urls := c.InitialPeerURLsMap[c.Name]; urls == nil {\r\n\t\treturn fmt.Errorf(\"couldn't find local name %q in the initial cluster configuration\", c.Name)\r\n\t}\r\n\treturn nil\r\n}","code-length":82,"reference":"\/\/ hasLocalMember checks that the cluster at least contains the local server.","result":"Check if local member exists.","score":[0.0593,0.0885]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ServerConfig) advertiseMatchesCluster() error {\r\n\turls, apurls := c.InitialPeerURLsMap[c.Name], c.PeerURLs.StringSlice()\r\n\turls.Sort()\r\n\tsort.Strings(apurls)\r\n\tctx, cancel := context.WithTimeout(context.TODO(), 30*time.Second)\r\n\tdefer cancel()\r\n\tok, err := netutil.URLStringsEqual(ctx, c.Logger, apurls, urls.StringSlice())\r\n\tif ok {\r\n\t\treturn nil\r\n\t}\r\n\tinitMap, apMap := make(map[string]struct{}), make(map[string]struct{})\r\n\tfor _, url := range c.PeerURLs {\r\n\t\tapMap[url.String()] = struct{}{}\r\n\t}\r\n\tfor _, url := range c.InitialPeerURLsMap[c.Name] {\r\n\t\tinitMap[url.String()] = struct{}{}\r\n\t}\r\n\tmissing := []string{}\r\n\tfor url := range initMap {\r\n\t\tif _, ok := apMap[url]; !ok {\r\n\t\t\tmissing = append(missing, url)\r\n\t\t}\r\n\t}\r\n\tif len(missing) > 0 {\r\n\t\tfor i := range missing {\r\n\t\t\tmissing[i] = c.Name + \"=\" + missing[i]\r\n\t\t}\r\n\t\tmstr := strings.Join(missing, \",\")\r\n\t\tapStr := strings.Join(apurls, \",\")\r\n\t\treturn fmt.Errorf(\"--initial-cluster has %s but missing from --initial-advertise-peer-urls=%s (%v)\", mstr, apStr, err)\r\n\t}\r\n\tfor url := range apMap {\r\n\t\tif _, ok := initMap[url]; !ok {\r\n\t\t\tmissing = append(missing, url)\r\n\t\t}\r\n\t}\r\n\tif len(missing) > 0 {\r\n\t\tmstr := strings.Join(missing, \",\")\r\n\t\tumap := types.URLsMap(map[string]types.URLs{c.Name: c.PeerURLs})\r\n\t\treturn fmt.Errorf(\"--initial-advertise-peer-urls has %s but missing from --initial-cluster=%s\", mstr, umap.String())\r\n\t}\r\n\t\r\n\tapStr := strings.Join(apurls, \",\")\r\n\tumap := types.URLsMap(map[string]types.URLs{c.Name: c.PeerURLs})\r\n\treturn fmt.Errorf(\"failed to resolve %s to match --initial-cluster=%s (%v)\", apStr, umap.String(), err)\r\n}","code-length":648,"reference":"\/\/ advertiseMatchesCluster confirms peer URLs match those in the cluster peer list.","result":"Code too long,keep in 512.","score":[0.0593,0.0442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ServerConfig) ReqTimeout() time.Duration {\r\n\t\r\n\t\r\n\treturn 5*time.Second + 2*time.Duration(c.ElectionTicks*int(c.TickMs))*time.Millisecond\r\n}","code-length":66,"reference":"\/\/ ReqTimeout returns timeout for request to finish.","result":"Set the default timeout.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getStatus(r *raft) Status {\r\n\ts := getStatusWithoutProgress(r)\r\n\tif s.RaftState == StateLeader {\r\n\t\ts.Progress = getProgressCopy(r)\r\n\t}\r\n\treturn s\r\n}","code-length":68,"reference":"\/\/ getStatus gets a copy of the current raft status.","result":"Get the status of the raft.","score":[0.1402,0.2662]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetDefaultHost() (string, error) {\r\n\trmsgs, rerr := getDefaultRoutes()\r\n\tif rerr != nil {\r\n\t\treturn \"\", rerr\r\n\t}\r\n\t\r\n\tif rmsg, ok := rmsgs[syscall.AF_INET]; ok {\r\n\t\tif host, err := chooseHost(syscall.AF_INET, rmsg); host != \"\" || err != nil {\r\n\t\t\treturn host, err\r\n\t\t}\r\n\t\tdelete(rmsgs, syscall.AF_INET)\r\n\t}\r\n\t\r\n\tvar families []int\r\n\tfor family := range rmsgs {\r\n\t\tfamilies = append(families, int(family))\r\n\t}\r\n\tsort.Ints(families)\r\n\tfor _, f := range families {\r\n\t\tfamily := uint8(f)\r\n\t\tif host, err := chooseHost(family, rmsgs[family]); host != \"\" || err != nil {\r\n\t\t\treturn host, err\r\n\t\t}\r\n\t}\r\n\treturn \"\", errNoDefaultHost\r\n}","code-length":267,"reference":"\/\/ GetDefaultHost obtains the first IP address of machine from the routing table and returns the IP address as string.\n\/\/ An IPv4 address is preferred to an IPv6 address for backward compatibility.","result":"Get the default host name.","score":[0.0009,0.0331]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getIfaceAddr(idx uint32, family uint8) (*syscall.NetlinkMessage, error) {\r\n\tdat, err := syscall.NetlinkRIB(syscall.RTM_GETADDR, int(family))\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tmsgs, msgErr := syscall.ParseNetlinkMessage(dat)\r\n\tif msgErr != nil {\r\n\t\treturn nil, msgErr\r\n\t}\r\n\tifaddrmsg := syscall.IfAddrmsg{}\r\n\tfor _, m := range msgs {\r\n\t\tif m.Header.Type != syscall.RTM_NEWADDR {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tbuf := bytes.NewBuffer(m.Data[:syscall.SizeofIfAddrmsg])\r\n\t\tif rerr := binary.Read(buf, cpuutil.ByteOrder(), &ifaddrmsg); rerr != nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif ifaddrmsg.Index == idx {\r\n\t\t\treturn &m, nil\r\n\t\t}\r\n\t}\r\n\treturn nil, fmt.Errorf(\"could not find address for interface index %v\", idx)\r\n}","code-length":293,"reference":"\/\/ Used to get an address of interface.","result":"Get the interface address of an interface.","score":[0.2355,0.4709]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getIfaceLink(idx uint32) (*syscall.NetlinkMessage, error) {\r\n\tdat, err := syscall.NetlinkRIB(syscall.RTM_GETLINK, syscall.AF_UNSPEC)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tmsgs, msgErr := syscall.ParseNetlinkMessage(dat)\r\n\tif msgErr != nil {\r\n\t\treturn nil, msgErr\r\n\t}\r\n\tifinfomsg := syscall.IfInfomsg{}\r\n\tfor _, m := range msgs {\r\n\t\tif m.Header.Type != syscall.RTM_NEWLINK {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tbuf := bytes.NewBuffer(m.Data[:syscall.SizeofIfInfomsg])\r\n\t\tif rerr := binary.Read(buf, cpuutil.ByteOrder(), &ifinfomsg); rerr != nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif ifinfomsg.Index == int32(idx) {\r\n\t\t\treturn &m, nil\r\n\t\t}\r\n\t}\r\n\treturn nil, fmt.Errorf(\"could not find link for interface index %v\", idx)\r\n}","code-length":301,"reference":"\/\/ Used to get a name of interface.","result":"Get the interface link for the given interface index.","score":[0,0.0617]}
{"code":"\/*is used to<extra_id_0>\r\nfunc lsCommandFunc(c *cli.Context, ki client.KeysAPI) {\r\n\tkey := \"\/\"\r\n\tif len(c.Args()) != 0 {\r\n\t\tkey = c.Args()[0]\r\n\t}\r\n\tsort := c.Bool(\"sort\")\r\n\trecursive := c.Bool(\"recursive\")\r\n\tquorum := c.Bool(\"quorum\")\r\n\tctx, cancel := contextWithTotalTimeout(c)\r\n\tresp, err := ki.Get(ctx, key, &client.GetOptions{Sort: sort, Recursive: recursive, Quorum: quorum})\r\n\tcancel()\r\n\tif err != nil {\r\n\t\thandleError(c, ExitServerError, err)\r\n\t}\r\n\tprintLs(c, resp)\r\n}","code-length":191,"reference":"\/\/ lsCommandFunc executes the \"ls\" command.","result":"Generate the code.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc printLs(c *cli.Context, resp *client.Response) {\r\n\tif c.GlobalString(\"output\") == \"simple\" {\r\n\t\tif !resp.Node.Dir {\r\n\t\t\tfmt.Println(resp.Node.Key)\r\n\t\t}\r\n\t\tfor _, node := range resp.Node.Nodes {\r\n\t\t\trPrint(c, node)\r\n\t\t}\r\n\t} else {\r\n\t\t\r\n\t\tprintResponseKey(resp, c.GlobalString(\"output\"))\r\n\t}\r\n}","code-length":141,"reference":"\/\/ printLs writes a response out in a manner similar to the `ls` command in unix.\n\/\/ Non-empty directories list their contents and files list their name.","result":"Print the list of objects.","score":[0.0035,0.0403]}
{"code":"\/*is used to<extra_id_0>\r\nfunc rPrint(c *cli.Context, n *client.Node) {\r\n\tif n.Dir && c.Bool(\"p\") {\r\n\t\tfmt.Println(fmt.Sprintf(\"%v\/\", n.Key))\r\n\t} else {\r\n\t\tfmt.Println(n.Key)\r\n\t}\r\n\tfor _, node := range n.Nodes {\r\n\t\trPrint(c, node)\r\n\t}\r\n}","code-length":116,"reference":"\/\/ rPrint recursively prints out the nodes in the node structure.","result":"Print the contents of the node.","score":[0.0998,0.1429]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLeaseRenewerCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"lease-renewer\",\r\n\t\tShort: \"Performs lease renew operation\",\r\n\t\tRun:   runLeaseRenewerFunc,\r\n\t}\r\n\tcmd.Flags().Int64Var(&leaseTTL, \"ttl\", 5, \"lease's ttl\")\r\n\treturn cmd\r\n}","code-length":111,"reference":"\/\/ NewLeaseRenewerCommand returns the cobra command for \"lease-renewer runner\".","result":"Create a new command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Read(lg *zap.Logger, snapname string) (*raftpb.Snapshot, error) {\r\n\tb, err := ioutil.ReadFile(snapname)\r\n\tif err != nil {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\"failed to read a snap file\", zap.String(\"path\", snapname), zap.Error(err))\r\n\t\t} else {\r\n\t\t\tplog.Errorf(\"cannot read file %v: %v\", snapname, err)\r\n\t\t}\r\n\t\treturn nil, err\r\n\t}\r\n\tif len(b) == 0 {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\"failed to read empty snapshot file\", zap.String(\"path\", snapname))\r\n\t\t} else {\r\n\t\t\tplog.Errorf(\"unexpected empty snapshot\")\r\n\t\t}\r\n\t\treturn nil, ErrEmptySnapshot\r\n\t}\r\n\tvar serializedSnap snappb.Snapshot\r\n\tif err = serializedSnap.Unmarshal(b); err != nil {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\"failed to unmarshal snappb.Snapshot\", zap.String(\"path\", snapname), zap.Error(err))\r\n\t\t} else {\r\n\t\t\tplog.Errorf(\"corrupted snapshot file %v: %v\", snapname, err)\r\n\t\t}\r\n\t\treturn nil, err\r\n\t}\r\n\tif len(serializedSnap.Data) == 0 || serializedSnap.Crc == 0 {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\"failed to read empty snapshot data\", zap.String(\"path\", snapname))\r\n\t\t} else {\r\n\t\t\tplog.Errorf(\"unexpected empty snapshot\")\r\n\t\t}\r\n\t\treturn nil, ErrEmptySnapshot\r\n\t}\r\n\tcrc := crc32.Update(0, crcTable, serializedSnap.Data)\r\n\tif crc != serializedSnap.Crc {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\"snap file is corrupt\",\r\n\t\t\t\tzap.String(\"path\", snapname),\r\n\t\t\t\tzap.Uint32(\"prev-crc\", serializedSnap.Crc),\r\n\t\t\t\tzap.Uint32(\"new-crc\", crc),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Errorf(\"corrupted snapshot file %v: crc mismatch\", snapname)\r\n\t\t}\r\n\t\treturn nil, ErrCRCMismatch\r\n\t}\r\n\tvar snap raftpb.Snapshot\r\n\tif err = snap.Unmarshal(serializedSnap.Data); err != nil {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\"failed to unmarshal raftpb.Snapshot\", zap.String(\"path\", snapname), zap.Error(err))\r\n\t\t} else {\r\n\t\t\tplog.Errorf(\"corrupted snapshot file %v: %v\", snapname, err)\r\n\t\t}\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &snap, nil\r\n}","code-length":723,"reference":"\/\/ Read reads the snapshot named by snapname and returns the snapshot.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetCipherSuite(s string) (uint16, bool) {\r\n\tv, ok := cipherSuites[s]\r\n\treturn v, ok\r\n}","code-length":46,"reference":"\/\/ GetCipherSuite returns the corresponding cipher suite,\n\/\/ and boolean value if it is supported.","result":"Generate the generated code.","score":[0.0204,0.036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *pipeline) post(data []byte) (err error) {\r\n\tu := p.picker.pick()\r\n\treq := createPostRequest(u, RaftPrefix, bytes.NewBuffer(data), \"application\/protobuf\", p.tr.URLs, p.tr.ID, p.tr.ClusterID)\r\n\tdone := make(chan struct{}, 1)\r\n\tctx, cancel := context.WithCancel(context.Background())\r\n\treq = req.WithContext(ctx)\r\n\tgo func() {\r\n\t\tselect {\r\n\t\tcase <-done:\r\n\t\tcase <-p.stopc:\r\n\t\t\twaitSchedule()\r\n\t\t\tcancel()\r\n\t\t}\r\n\t}()\r\n\tresp, err := p.tr.pipelineRt.RoundTrip(req)\r\n\tdone <- struct{}{}\r\n\tif err != nil {\r\n\t\tp.picker.unreachable(u)\r\n\t\treturn err\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\tb, err := ioutil.ReadAll(resp.Body)\r\n\tif err != nil {\r\n\t\tp.picker.unreachable(u)\r\n\t\treturn err\r\n\t}\r\n\terr = checkPostResponse(resp, b, req, p.peerID)\r\n\tif err != nil {\r\n\t\tp.picker.unreachable(u)\r\n\t\t\r\n\t\t\r\n\t\tif err == errMemberRemoved {\r\n\t\t\treportCriticalError(err, p.errorc)\r\n\t\t}\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":390,"reference":"\/\/ post POSTs a data payload to a url. Returns nil if the POST succeeds,\n\/\/ error on any failure.","result":"Post data to Raft members.","score":[0.0142,0.0811]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) send(m pb.Message) {\r\n\tm.From = r.id\r\n\tif m.Type == pb.MsgVote || m.Type == pb.MsgVoteResp || m.Type == pb.MsgPreVote || m.Type == pb.MsgPreVoteResp {\r\n\t\tif m.Term == 0 {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tpanic(fmt.Sprintf(\"term should be set when sending %s\", m.Type))\r\n\t\t}\r\n\t} else {\r\n\t\tif m.Term != 0 {\r\n\t\t\tpanic(fmt.Sprintf(\"term should not be set when sending %s (was %d)\", m.Type, m.Term))\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif m.Type != pb.MsgProp && m.Type != pb.MsgReadIndex {\r\n\t\t\tm.Term = r.Term\r\n\t\t}\r\n\t}\r\n\tr.msgs = append(r.msgs, m)\r\n}","code-length":285,"reference":"\/\/ send persists state to stable storage and then sends to its mailbox.","result":"Send messages to the raft.","score":[0.0485,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) sendHeartbeat(to uint64, ctx []byte) {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tcommit := min(r.getProgress(to).Match, r.raftLog.committed)\r\n\tm := pb.Message{\r\n\t\tTo:      to,\r\n\t\tType:    pb.MsgHeartbeat,\r\n\t\tCommit:  commit,\r\n\t\tContext: ctx,\r\n\t}\r\n\tr.send(m)\r\n}","code-length":132,"reference":"\/\/ sendHeartbeat sends a heartbeat RPC to the given peer.","result":"Send heartbeat messages.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) bcastAppend() {\r\n\tr.forEachProgress(func(id uint64, _ *Progress) {\r\n\t\tif id == r.id {\r\n\t\t\treturn\r\n\t\t}\r\n\t\tr.sendAppend(id)\r\n\t})\r\n}","code-length":79,"reference":"\/\/ bcastAppend sends RPC, with entries to all peers that are not up-to-date\n\/\/ according to the progress recorded in r.prs.","result":"Bcast the append.","score":[0.001,0.026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) bcastHeartbeat() {\r\n\tlastCtx := r.readOnly.lastPendingRequestCtx()\r\n\tif len(lastCtx) == 0 {\r\n\t\tr.bcastHeartbeatWithCtx(nil)\r\n\t} else {\r\n\t\tr.bcastHeartbeatWithCtx([]byte(lastCtx))\r\n\t}\r\n}","code-length":93,"reference":"\/\/ bcastHeartbeat sends RPC, without entries to all the peers.","result":"Bcast heartbeat.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) tickElection() {\r\n\tr.electionElapsed++\r\n\tif r.promotable() && r.pastElectionTimeout() {\r\n\t\tr.electionElapsed = 0\r\n\t\tr.Step(pb.Message{From: r.id, Type: pb.MsgHup})\r\n\t}\r\n}","code-length":91,"reference":"\/\/ tickElection is run by followers and candidates after r.electionTimeout.","result":"Tick the election.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) tickHeartbeat() {\r\n\tr.heartbeatElapsed++\r\n\tr.electionElapsed++\r\n\tif r.electionElapsed >= r.electionTimeout {\r\n\t\tr.electionElapsed = 0\r\n\t\tif r.checkQuorum {\r\n\t\t\tr.Step(pb.Message{From: r.id, Type: pb.MsgCheckQuorum})\r\n\t\t}\r\n\t\t\r\n\t\tif r.state == StateLeader && r.leadTransferee != None {\r\n\t\t\tr.abortLeaderTransfer()\r\n\t\t}\r\n\t}\r\n\tif r.state != StateLeader {\r\n\t\treturn\r\n\t}\r\n\tif r.heartbeatElapsed >= r.heartbeatTimeout {\r\n\t\tr.heartbeatElapsed = 0\r\n\t\tr.Step(pb.Message{From: r.id, Type: pb.MsgBeat})\r\n\t}\r\n}","code-length":223,"reference":"\/\/ tickHeartbeat is run by leaders to send a MsgBeat after r.heartbeatTimeout.","result":"Tick heartbeat timeout.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc stepCandidate(r *raft, m pb.Message) error {\r\n\t\r\n\t\r\n\t\r\n\tvar myVoteRespType pb.MessageType\r\n\tif r.state == StatePreCandidate {\r\n\t\tmyVoteRespType = pb.MsgPreVoteResp\r\n\t} else {\r\n\t\tmyVoteRespType = pb.MsgVoteResp\r\n\t}\r\n\tswitch m.Type {\r\n\tcase pb.MsgProp:\r\n\t\tr.logger.Infof(\"%x no leader at term %d; dropping proposal\", r.id, r.Term)\r\n\t\treturn ErrProposalDropped\r\n\tcase pb.MsgApp:\r\n\t\tr.becomeFollower(m.Term, m.From)\r\n\t\tr.handleAppendEntries(m)\r\n\tcase pb.MsgHeartbeat:\r\n\t\tr.becomeFollower(m.Term, m.From)\r\n\t\tr.handleHeartbeat(m)\r\n\tcase pb.MsgSnap:\r\n\t\tr.becomeFollower(m.Term, m.From)\r\n\t\tr.handleSnapshot(m)\r\n\tcase myVoteRespType:\r\n\t\tgr := r.poll(m.From, m.Type, !m.Reject)\r\n\t\tr.logger.Infof(\"%x [quorum:%d] has received %d %s votes and %d vote rejections\", r.id, r.quorum(), gr, m.Type, len(r.votes)-gr)\r\n\t\tswitch r.quorum() {\r\n\t\tcase gr:\r\n\t\t\tif r.state == StatePreCandidate {\r\n\t\t\t\tr.campaign(campaignElection)\r\n\t\t\t} else {\r\n\t\t\t\tr.becomeLeader()\r\n\t\t\t\tr.bcastAppend()\r\n\t\t\t}\r\n\t\tcase len(r.votes) - gr:\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tr.becomeFollower(r.Term, None)\r\n\t\t}\r\n\tcase pb.MsgTimeoutNow:\r\n\t\tr.logger.Debugf(\"%x [term %d state %v] ignored MsgTimeoutNow from %x\", r.id, r.Term, r.state, m.From)\r\n\t}\r\n\treturn nil\r\n}","code-length":543,"reference":"\/\/ stepCandidate is shared by StateCandidate and StatePreCandidate; the difference is\n\/\/ whether they respond to MsgVoteResp or MsgPreVoteResp.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) restore(s pb.Snapshot) bool {\r\n\tif s.Metadata.Index <= r.raftLog.committed {\r\n\t\treturn false\r\n\t}\r\n\tif r.raftLog.matchTerm(s.Metadata.Index, s.Metadata.Term) {\r\n\t\tr.logger.Infof(\"%x [commit: %d, lastindex: %d, lastterm: %d] fast-forwarded commit to snapshot [index: %d, term: %d]\",\r\n\t\t\tr.id, r.raftLog.committed, r.raftLog.lastIndex(), r.raftLog.lastTerm(), s.Metadata.Index, s.Metadata.Term)\r\n\t\tr.raftLog.commitTo(s.Metadata.Index)\r\n\t\treturn false\r\n\t}\r\n\t\r\n\tif !r.isLearner {\r\n\t\tfor _, id := range s.Metadata.ConfState.Learners {\r\n\t\t\tif id == r.id {\r\n\t\t\t\tr.logger.Errorf(\"%x can't become learner when restores snapshot [index: %d, term: %d]\", r.id, s.Metadata.Index, s.Metadata.Term)\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tr.logger.Infof(\"%x [commit: %d, lastindex: %d, lastterm: %d] starts to restore snapshot [index: %d, term: %d]\",\r\n\t\tr.id, r.raftLog.committed, r.raftLog.lastIndex(), r.raftLog.lastTerm(), s.Metadata.Index, s.Metadata.Term)\r\n\tr.raftLog.restore(s)\r\n\tr.prs = make(map[uint64]*Progress)\r\n\tr.learnerPrs = make(map[uint64]*Progress)\r\n\tr.restoreNode(s.Metadata.ConfState.Nodes, false)\r\n\tr.restoreNode(s.Metadata.ConfState.Learners, true)\r\n\treturn true\r\n}","code-length":497,"reference":"\/\/ restore recovers the state machine from a snapshot. It restores the log and the\n\/\/ configuration of state machine.","result":"Restore raft log.","score":[0,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) promotable() bool {\r\n\t_, ok := r.prs[r.id]\r\n\treturn ok\r\n}","code-length":45,"reference":"\/\/ promotable indicates whether state machine can be promoted to leader,\n\/\/ which is true when its own id is in progress list.","result":"Check if promotable.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) checkQuorumActive() bool {\r\n\tvar act int\r\n\tr.forEachProgress(func(id uint64, pr *Progress) {\r\n\t\tif id == r.id {\r\n\t\t\tact++\r\n\t\t\treturn\r\n\t\t}\r\n\t\tif pr.RecentActive && !pr.IsLearner {\r\n\t\t\tact++\r\n\t\t}\r\n\t\tpr.RecentActive = false\r\n\t})\r\n\treturn act >= r.quorum()\r\n}","code-length":130,"reference":"\/\/ checkQuorumActive returns true if the quorum is active from\n\/\/ the view of the local raft state machine. Otherwise, it returns\n\/\/ false.\n\/\/ checkQuorumActive also resets all RecentActive to false.","result":"Check quorum active.","score":[0.0,0.0172]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) increaseUncommittedSize(ents []pb.Entry) bool {\r\n\tvar s uint64\r\n\tfor _, e := range ents {\r\n\t\ts += uint64(PayloadSize(e))\r\n\t}\r\n\tif r.uncommittedSize > 0 && r.uncommittedSize+s > r.maxUncommittedSize {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\treturn false\r\n\t}\r\n\tr.uncommittedSize += s\r\n\treturn true\r\n}","code-length":134,"reference":"\/\/ increaseUncommittedSize computes the size of the proposed entries and\n\/\/ determines whether they would push leader over its maxUncommittedSize limit.\n\/\/ If the new entries would exceed the limit, the method returns false. If not,\n\/\/ the increase in uncommitted entry size is recorded and the method returns\n\/\/ true.","result":"Increase the uncommitted size of the.","score":[0.0002,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raft) reduceUncommittedSize(ents []pb.Entry) {\r\n\tif r.uncommittedSize == 0 {\r\n\t\t\r\n\t\treturn\r\n\t}\r\n\tvar s uint64\r\n\tfor _, e := range ents {\r\n\t\ts += uint64(PayloadSize(e))\r\n\t}\r\n\tif s > r.uncommittedSize {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tr.uncommittedSize = 0\r\n\t} else {\r\n\t\tr.uncommittedSize -= s\r\n\t}\r\n}","code-length":149,"reference":"\/\/ reduceUncommittedSize accounts for the newly committed entries by decreasing\n\/\/ the uncommitted entry size limit.","result":"Avoid the need for a function.","score":[0.0434,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newPeriodic(lg *zap.Logger, clock clockwork.Clock, h time.Duration, rg RevGetter, c Compactable) *Periodic {\r\n\tpc := &Periodic{\r\n\t\tlg:     lg,\r\n\t\tclock:  clock,\r\n\t\tperiod: h,\r\n\t\trg:     rg,\r\n\t\tc:      c,\r\n\t\trevs:   make([]int64, 0),\r\n\t}\r\n\tpc.ctx, pc.cancel = context.WithCancel(context.Background())\r\n\treturn pc\r\n}","code-length":142,"reference":"\/\/ newPeriodic creates a new instance of Periodic compactor that purges\n\/\/ the log older than h Duration.","result":"Create a new periodic.","score":[0.0136,0.1774]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pc *Periodic) Pause() {\r\n\tpc.mu.Lock()\r\n\tpc.paused = true\r\n\tpc.mu.Unlock()\r\n}","code-length":48,"reference":"\/\/ Pause pauses periodic compactor.","result":"Avoid recursive call to Pause.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pc *Periodic) Resume() {\r\n\tpc.mu.Lock()\r\n\tpc.paused = false\r\n\tpc.mu.Unlock()\r\n}","code-length":49,"reference":"\/\/ Resume resumes periodic compactor.","result":"Avoid recursive call to Resume.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Mutex) Lock(ctx context.Context) error {\r\n\ts := m.s\r\n\tclient := m.s.Client()\r\n\tm.myKey = fmt.Sprintf(\"%s%x\", m.pfx, s.Lease())\r\n\tcmp := v3.Compare(v3.CreateRevision(m.myKey), \"=\", 0)\r\n\t\r\n\tput := v3.OpPut(m.myKey, \"\", v3.WithLease(s.Lease()))\r\n\t\r\n\tget := v3.OpGet(m.myKey)\r\n\t\r\n\tgetOwner := v3.OpGet(m.pfx, v3.WithFirstCreate()...)\r\n\tresp, err := client.Txn(ctx).If(cmp).Then(put, getOwner).Else(get, getOwner).Commit()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tm.myRev = resp.Header.Revision\r\n\tif !resp.Succeeded {\r\n\t\tm.myRev = resp.Responses[0].GetResponseRange().Kvs[0].CreateRevision\r\n\t}\r\n\t\r\n\townerKey := resp.Responses[1].GetResponseRange().Kvs\r\n\tif len(ownerKey) == 0 || ownerKey[0].CreateRevision == m.myRev {\r\n\t\tm.hdr = resp.Header\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\thdr, werr := waitDeletes(ctx, client, m.pfx, m.myRev-1)\r\n\t\r\n\tif werr != nil {\r\n\t\tm.Unlock(client.Ctx())\r\n\t} else {\r\n\t\tm.hdr = hdr\r\n\t}\r\n\treturn werr\r\n}","code-length":422,"reference":"\/\/ Lock locks the mutex with a cancelable context. If the context is canceled\n\/\/ while trying to acquire the lock, the mutex tries to clean its stale lock entry.","result":"Lock the mutex.","score":[0.0001,0.0366]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLocker(s *Session, pfx string) sync.Locker {\r\n\treturn &lockerMutex{NewMutex(s, pfx)}\r\n}","code-length":45,"reference":"\/\/ NewLocker creates a sync.Locker backed by an etcd mutex.","result":"Create a new locker.","score":[0.0713,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFIFOScheduler() Scheduler {\r\n\tf := &fifo{\r\n\t\tresume: make(chan struct{}, 1),\r\n\t\tdonec:  make(chan struct{}, 1),\r\n\t}\r\n\tf.finishCond = sync.NewCond(&f.mu)\r\n\tf.ctx, f.cancel = context.WithCancel(context.Background())\r\n\tgo f.run()\r\n\treturn f\r\n}","code-length":114,"reference":"\/\/ NewFIFOScheduler returns a Scheduler that schedules jobs in FIFO\n\/\/ order sequentially","result":"Create a new scheduler.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *fifo) Schedule(j Job) {\r\n\tf.mu.Lock()\r\n\tdefer f.mu.Unlock()\r\n\tif f.cancel == nil {\r\n\t\tpanic(\"schedule: schedule to stopped scheduler\")\r\n\t}\r\n\tif len(f.pendings) == 0 {\r\n\t\tselect {\r\n\t\tcase f.resume <- struct{}{}:\r\n\t\tdefault:\r\n\t\t}\r\n\t}\r\n\tf.pendings = append(f.pendings, j)\r\n}","code-length":137,"reference":"\/\/ Schedule schedules a job that will be ran in FIFO order sequentially.","result":"Schedule jobs to stopped scheduler.","score":[0.0485,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *fifo) Stop() {\r\n\tf.mu.Lock()\r\n\tf.cancel()\r\n\tf.cancel = nil\r\n\tf.mu.Unlock()\r\n\t<-f.donec\r\n}","code-length":64,"reference":"\/\/ Stop stops the scheduler and cancels all pending jobs.","result":"Stop the fifo.","score":[0.0471,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewServer(\r\n\tlg *zap.Logger,\r\n\tnetwork string,\r\n\taddress string,\r\n) *Server {\r\n\treturn &Server{\r\n\t\tlg:                         lg,\r\n\t\tnetwork:                    network,\r\n\t\taddress:                    address,\r\n\t\tlast:                       rpcpb.Operation_NOT_STARTED,\r\n\t\tadvertiseClientPortToProxy: make(map[int]proxy.Server),\r\n\t\tadvertisePeerPortToProxy:   make(map[int]proxy.Server),\r\n\t}\r\n}","code-length":141,"reference":"\/\/ NewServer returns a new agent server.","result":"Create a new server.","score":[0.2362,0.3814]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (srv *Server) StartServe() error {\r\n\tvar err error\r\n\tsrv.ln, err = net.Listen(srv.network, srv.address)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tvar opts []grpc.ServerOption\r\n\topts = append(opts, grpc.MaxRecvMsgSize(int(maxRequestBytes+grpcOverheadBytes)))\r\n\topts = append(opts, grpc.MaxSendMsgSize(maxSendBytes))\r\n\topts = append(opts, grpc.MaxConcurrentStreams(maxStreams))\r\n\tsrv.grpcServer = grpc.NewServer(opts...)\r\n\trpcpb.RegisterTransportServer(srv.grpcServer, srv)\r\n\tsrv.lg.Info(\r\n\t\t\"gRPC server started\",\r\n\t\tzap.String(\"address\", srv.address),\r\n\t\tzap.String(\"listener-address\", srv.ln.Addr().String()),\r\n\t)\r\n\terr = srv.grpcServer.Serve(srv.ln)\r\n\tif err != nil && strings.Contains(err.Error(), \"use of closed network connection\") {\r\n\t\tsrv.lg.Info(\r\n\t\t\t\"gRPC server is shut down\",\r\n\t\t\tzap.String(\"address\", srv.address),\r\n\t\t\tzap.Error(err),\r\n\t\t)\r\n\t} else {\r\n\t\tsrv.lg.Warn(\r\n\t\t\t\"gRPC server returned with error\",\r\n\t\t\tzap.String(\"address\", srv.address),\r\n\t\t\tzap.Error(err),\r\n\t\t)\r\n\t}\r\n\treturn err\r\n}","code-length":396,"reference":"\/\/ StartServe starts serving agent server.","result":"Start the server.","score":[0.1502,0.1754]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (srv *Server) Stop() {\r\n\tsrv.lg.Info(\"gRPC server stopping\", zap.String(\"address\", srv.address))\r\n\tsrv.grpcServer.Stop()\r\n\tsrv.lg.Info(\"gRPC server stopped\", zap.String(\"address\", srv.address))\r\n}","code-length":79,"reference":"\/\/ Stop stops serving gRPC server.","result":"Stop the server.","score":[0.1786,0.1754]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (srv *Server) Transport(stream rpcpb.Transport_TransportServer) (err error) {\r\n\terrc := make(chan error)\r\n\tgo func() {\r\n\t\tfor {\r\n\t\t\tvar req *rpcpb.Request\r\n\t\t\treq, err = stream.Recv()\r\n\t\t\tif err != nil {\r\n\t\t\t\terrc <- err\r\n\t\t\t\t\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tif req.Member != nil {\r\n\t\t\t\tsrv.Member = req.Member\r\n\t\t\t}\r\n\t\t\tif req.Tester != nil {\r\n\t\t\t\tsrv.Tester = req.Tester\r\n\t\t\t}\r\n\t\t\tvar resp *rpcpb.Response\r\n\t\t\tresp, err = srv.handleTesterRequest(req)\r\n\t\t\tif err != nil {\r\n\t\t\t\terrc <- err\r\n\t\t\t\t\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tif err = stream.Send(resp); err != nil {\r\n\t\t\t\terrc <- err\r\n\t\t\t\t\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t}\r\n\t}()\r\n\tselect {\r\n\tcase err = <-errc:\r\n\tcase <-stream.Context().Done():\r\n\t\terr = stream.Context().Err()\r\n\t}\r\n\treturn err\r\n}","code-length":321,"reference":"\/\/ Transport communicates with etcd tester.","result":"Serve the transport RPCs.","score":[0,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterInterruptHandler(h InterruptHandler) {\r\n\tinterruptRegisterMu.Lock()\r\n\tdefer interruptRegisterMu.Unlock()\r\n\tinterruptHandlers = append(interruptHandlers, h)\r\n}","code-length":55,"reference":"\/\/ RegisterInterruptHandler registers a new InterruptHandler. Handlers registered\n\/\/ after interrupt handing was initiated will not be executed.","result":"Register the InterruptHandler.","score":[0.0028,0.0606]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HandleInterrupts(lg *zap.Logger) {\r\n\tnotifier := make(chan os.Signal, 1)\r\n\tsignal.Notify(notifier, syscall.SIGINT, syscall.SIGTERM)\r\n\tgo func() {\r\n\t\tsig := <-notifier\r\n\t\tinterruptRegisterMu.Lock()\r\n\t\tihs := make([]InterruptHandler, len(interruptHandlers))\r\n\t\tcopy(ihs, interruptHandlers)\r\n\t\tinterruptRegisterMu.Unlock()\r\n\t\tinterruptExitMu.Lock()\r\n\t\tif lg != nil {\r\n\t\t\tlg.Info(\"received signal; shutting down\", zap.String(\"signal\", sig.String()))\r\n\t\t} else {\r\n\t\t\tplog.Noticef(\"received %v signal, shutting down...\", sig)\r\n\t\t}\r\n\t\tfor _, h := range ihs {\r\n\t\t\th()\r\n\t\t}\r\n\t\tsignal.Stop(notifier)\r\n\t\tpid := syscall.Getpid()\r\n\t\t\r\n\t\tif pid == 1 {\r\n\t\t\tos.Exit(0)\r\n\t\t}\r\n\t\tsetDflSignal(sig.(syscall.Signal))\r\n\t\tsyscall.Kill(pid, sig.(syscall.Signal))\r\n\t}()\r\n}","code-length":318,"reference":"\/\/ HandleInterrupts calls the handler functions on receiving a SIGINT or SIGTERM.","result":"Handle interrupts.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OpGet(key string, opts ...OpOption) Op {\r\n\t\r\n\tif isWithPrefix(opts) && isWithFromKey(opts) {\r\n\t\tpanic(\"`WithPrefix` and `WithFromKey` cannot be set at the same time, choose one\")\r\n\t}\r\n\tret := Op{t: tRange, key: []byte(key)}\r\n\tret.applyOpts(opts)\r\n\treturn ret\r\n}","code-length":114,"reference":"\/\/ OpGet returns \"get\" operation based on given key and operation options.","result":"Get a range.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OpDelete(key string, opts ...OpOption) Op {\r\n\t\r\n\tif isWithPrefix(opts) && isWithFromKey(opts) {\r\n\t\tpanic(\"`WithPrefix` and `WithFromKey` cannot be set at the same time, choose one\")\r\n\t}\r\n\tret := Op{t: tDeleteRange, key: []byte(key)}\r\n\tret.applyOpts(opts)\r\n\tswitch {\r\n\tcase ret.leaseID != 0:\r\n\t\tpanic(\"unexpected lease in delete\")\r\n\tcase ret.limit != 0:\r\n\t\tpanic(\"unexpected limit in delete\")\r\n\tcase ret.rev != 0:\r\n\t\tpanic(\"unexpected revision in delete\")\r\n\tcase ret.sort != nil:\r\n\t\tpanic(\"unexpected sort in delete\")\r\n\tcase ret.serializable:\r\n\t\tpanic(\"unexpected serializable in delete\")\r\n\tcase ret.countOnly:\r\n\t\tpanic(\"unexpected countOnly in delete\")\r\n\tcase ret.minModRev != 0, ret.maxModRev != 0:\r\n\t\tpanic(\"unexpected mod revision filter in delete\")\r\n\tcase ret.minCreateRev != 0, ret.maxCreateRev != 0:\r\n\t\tpanic(\"unexpected create revision filter in delete\")\r\n\tcase ret.filterDelete, ret.filterPut:\r\n\t\tpanic(\"unexpected filter in delete\")\r\n\tcase ret.createdNotify:\r\n\t\tpanic(\"unexpected createdNotify in delete\")\r\n\t}\r\n\treturn ret\r\n}","code-length":372,"reference":"\/\/ OpDelete returns \"delete\" operation based on given key and operation options.","result":"Delete a range.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OpPut(key, val string, opts ...OpOption) Op {\r\n\tret := Op{t: tPut, key: []byte(key), val: []byte(val)}\r\n\tret.applyOpts(opts)\r\n\tswitch {\r\n\tcase ret.end != nil:\r\n\t\tpanic(\"unexpected range in put\")\r\n\tcase ret.limit != 0:\r\n\t\tpanic(\"unexpected limit in put\")\r\n\tcase ret.rev != 0:\r\n\t\tpanic(\"unexpected revision in put\")\r\n\tcase ret.sort != nil:\r\n\t\tpanic(\"unexpected sort in put\")\r\n\tcase ret.serializable:\r\n\t\tpanic(\"unexpected serializable in put\")\r\n\tcase ret.countOnly:\r\n\t\tpanic(\"unexpected countOnly in put\")\r\n\tcase ret.minModRev != 0, ret.maxModRev != 0:\r\n\t\tpanic(\"unexpected mod revision filter in put\")\r\n\tcase ret.minCreateRev != 0, ret.maxCreateRev != 0:\r\n\t\tpanic(\"unexpected create revision filter in put\")\r\n\tcase ret.filterDelete, ret.filterPut:\r\n\t\tpanic(\"unexpected filter in put\")\r\n\tcase ret.createdNotify:\r\n\t\tpanic(\"unexpected createdNotify in put\")\r\n\t}\r\n\treturn ret\r\n}","code-length":325,"reference":"\/\/ OpPut returns \"put\" operation based on given key-value and operation options.","result":"Create a new Op object.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OpTxn(cmps []Cmp, thenOps []Op, elseOps []Op) Op {\r\n\treturn Op{t: tTxn, cmps: cmps, thenOps: thenOps, elseOps: elseOps}\r\n}","code-length":62,"reference":"\/\/ OpTxn returns \"txn\" operation based on given transaction conditions.","result":"Create a transaction.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WithFromKey() OpOption {\r\n\treturn func(op *Op) {\r\n\t\tif len(op.key) == 0 {\r\n\t\t\top.key = []byte{0}\r\n\t\t}\r\n\t\top.end = []byte(\"\\x00\")\r\n\t}\r\n}","code-length":81,"reference":"\/\/ WithFromKey specifies the range of 'Get', 'Delete', 'Watch' requests\n\/\/ to be equal or greater than the key in the argument.","result":"Create a new op.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc withTop(target SortTarget, order SortOrder) []OpOption {\r\n\treturn []OpOption{WithPrefix(), WithSort(target, order), WithLimit(1)}\r\n}","code-length":51,"reference":"\/\/ withTop gets the first key over the get's prefix given a sort order","result":"Create a new function.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Exist(dir string) bool {\r\n\tnames, err := fileutil.ReadDir(dir, fileutil.WithExt(\".wal\"))\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\treturn len(names) != 0\r\n}","code-length":74,"reference":"\/\/ Exist returns true if there are any files in a given directory.","result":"Check if the directory exists.","score":[0.0485,0.041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc searchIndex(lg *zap.Logger, names []string, index uint64) (int, bool) {\r\n\tfor i := len(names) - 1; i >= 0; i-- {\r\n\t\tname := names[i]\r\n\t\t_, curIndex, err := parseWALName(name)\r\n\t\tif err != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Panic(\"failed to parse WAL file name\", zap.String(\"path\", name), zap.Error(err))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"parse correct name should never fail: %v\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t\tif index >= curIndex {\r\n\t\t\treturn i, true\r\n\t\t}\r\n\t}\r\n\treturn -1, false\r\n}","code-length":206,"reference":"\/\/ searchIndex returns the last array index of names whose raft index section is\n\/\/ equal to or smaller than the given index.\n\/\/ The given names MUST be sorted.","result":"Search the index of the WAL file .","score":[0.0149,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isValidSeq(lg *zap.Logger, names []string) bool {\r\n\tvar lastSeq uint64\r\n\tfor _, name := range names {\r\n\t\tcurSeq, _, err := parseWALName(name)\r\n\t\tif err != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Panic(\"failed to parse WAL file name\", zap.String(\"path\", name), zap.Error(err))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"parse correct name should never fail: %v\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t\tif lastSeq != 0 && lastSeq != curSeq-1 {\r\n\t\t\treturn false\r\n\t\t}\r\n\t\tlastSeq = curSeq\r\n\t}\r\n\treturn true\r\n}","code-length":199,"reference":"\/\/ names should have been sorted based on sequence number.\n\/\/ isValidSeq checks whether seq increases continuously.","result":"Check if the sequence number is valid.","score":[0.0387,0.0625]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewListener(addr, scheme string, tlsinfo *TLSInfo) (l net.Listener, err error) {\r\n\tif l, err = newListener(addr, scheme); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn wrapTLS(scheme, tlsinfo, l)\r\n}","code-length":82,"reference":"\/\/ NewListener creates a new listner.","result":"Create a new listener.","score":[0.274,0.5077]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (info TLSInfo) cafiles() []string {\r\n\tcs := make([]string, 0)\r\n\tif info.TrustedCAFile != \"\" {\r\n\t\tcs = append(cs, info.TrustedCAFile)\r\n\t}\r\n\treturn cs\r\n}","code-length":74,"reference":"\/\/ cafiles returns a list of CA file paths.","result":"Generate the cafiles.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (info TLSInfo) ServerConfig() (*tls.Config, error) {\r\n\tcfg, err := info.baseConfig()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tcfg.ClientAuth = tls.NoClientCert\r\n\tif info.TrustedCAFile != \"\" || info.ClientCertAuth {\r\n\t\tcfg.ClientAuth = tls.RequireAndVerifyClientCert\r\n\t}\r\n\tcs := info.cafiles()\r\n\tif len(cs) > 0 {\r\n\t\tcp, err := tlsutil.NewCertPool(cs)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tcfg.ClientCAs = cp\r\n\t}\r\n\t\r\n\tcfg.NextProtos = []string{\"h2\"}\r\n\treturn cfg, nil\r\n}","code-length":214,"reference":"\/\/ ServerConfig generates a tls.Config object for use by an HTTP server.","result":"Generate the server config.","score":[0,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (info TLSInfo) ClientConfig() (*tls.Config, error) {\r\n\tvar cfg *tls.Config\r\n\tvar err error\r\n\tif !info.Empty() {\r\n\t\tcfg, err = info.baseConfig()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t} else {\r\n\t\tcfg = &tls.Config{ServerName: info.ServerName}\r\n\t}\r\n\tcfg.InsecureSkipVerify = info.InsecureSkipVerify\r\n\tcs := info.cafiles()\r\n\tif len(cs) > 0 {\r\n\t\tcfg.RootCAs, err = tlsutil.NewCertPool(cs)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\tif info.selfCert {\r\n\t\tcfg.InsecureSkipVerify = true\r\n\t}\r\n\tif info.EmptyCN {\r\n\t\thasNonEmptyCN := false\r\n\t\tcn := \"\"\r\n\t\ttlsutil.NewCert(info.CertFile, info.KeyFile, func(certPEMBlock []byte, keyPEMBlock []byte) (tls.Certificate, error) {\r\n\t\t\tvar block *pem.Block\r\n\t\t\tblock, _ = pem.Decode(certPEMBlock)\r\n\t\t\tcert, err := x509.ParseCertificate(block.Bytes)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn tls.Certificate{}, err\r\n\t\t\t}\r\n\t\t\tif len(cert.Subject.CommonName) != 0 {\r\n\t\t\t\thasNonEmptyCN = true\r\n\t\t\t\tcn = cert.Subject.CommonName\r\n\t\t\t}\r\n\t\t\treturn tls.X509KeyPair(certPEMBlock, keyPEMBlock)\r\n\t\t})\r\n\t\tif hasNonEmptyCN {\r\n\t\t\treturn nil, fmt.Errorf(\"cert has non empty Common Name (%s)\", cn)\r\n\t\t}\r\n\t}\r\n\treturn cfg, nil\r\n}","code-length":472,"reference":"\/\/ ClientConfig generates a tls.Config object for use by an HTTP client.","result":"Create a client config.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newTLSKeepaliveListener(inner net.Listener, config *tls.Config) net.Listener {\r\n\tl := &tlsKeepaliveListener{}\r\n\tl.Listener = inner\r\n\tl.config = config\r\n\treturn l\r\n}","code-length":66,"reference":"\/\/ NewListener creates a Listener which accepts connections from an inner\n\/\/ Listener and wraps each connection with Server.\n\/\/ The configuration config must be non-nil and must have\n\/\/ at least one certificate.","result":"Keep the keepalive listener alive.","score":[0,0.0322]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) applyV2Request(r *RequestV2) Response {\r\n\tdefer warnOfExpensiveRequest(s.getLogger(), time.Now(), r, nil, nil)\r\n\tswitch r.Method {\r\n\tcase \"POST\":\r\n\t\treturn s.applyV2.Post(r)\r\n\tcase \"PUT\":\r\n\t\treturn s.applyV2.Put(r)\r\n\tcase \"DELETE\":\r\n\t\treturn s.applyV2.Delete(r)\r\n\tcase \"QGET\":\r\n\t\treturn s.applyV2.QGet(r)\r\n\tcase \"SYNC\":\r\n\t\treturn s.applyV2.Sync(r)\r\n\tdefault:\r\n\t\t\r\n\t\treturn Response{Err: ErrUnknownMethod}\r\n\t}\r\n}","code-length":202,"reference":"\/\/ applyV2Request interprets r as a call to v2store.X\n\/\/ and returns a Response interpreted from v2store.Event","result":"Apply a request to a cluster.","score":[0.0406,0.0943]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRoleCommand() *cobra.Command {\r\n\tac := &cobra.Command{\r\n\t\tUse:   \"role <subcommand>\",\r\n\t\tShort: \"Role related commands\",\r\n\t}\r\n\tac.AddCommand(newRoleAddCommand())\r\n\tac.AddCommand(newRoleDeleteCommand())\r\n\tac.AddCommand(newRoleGetCommand())\r\n\tac.AddCommand(newRoleListCommand())\r\n\tac.AddCommand(newRoleGrantPermissionCommand())\r\n\tac.AddCommand(newRoleRevokePermissionCommand())\r\n\treturn ac\r\n}","code-length":150,"reference":"\/\/ NewRoleCommand returns the cobra command for \"role\".","result":"Generate the role command.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc roleAddCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"role add command requires role name as its argument\"))\r\n\t}\r\n\tresp, err := mustClientFromCmd(cmd).Auth.RoleAdd(context.TODO(), args[0])\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.RoleAdd(args[0], *resp)\r\n}","code-length":138,"reference":"\/\/ roleAddCommandFunc executes the \"role add\" command.","result":"Generate the code.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc roleGetCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"role get command requires role name as its argument\"))\r\n\t}\r\n\tname := args[0]\r\n\tresp, err := mustClientFromCmd(cmd).Auth.RoleGet(context.TODO(), name)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.RoleGet(name, *resp)\r\n}","code-length":143,"reference":"\/\/ roleGetCommandFunc executes the \"role get\" command.","result":"Generate the role get command .","score":[0.1634,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc roleGrantPermissionCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) < 3 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"role grant command requires role name, permission type, and key [endkey] as its argument\"))\r\n\t}\r\n\tperm, err := clientv3.StrToPermissionType(args[1])\r\n\tif err != nil {\r\n\t\tExitWithError(ExitBadArgs, err)\r\n\t}\r\n\tkey, rangeEnd := permRange(args[2:])\r\n\tresp, err := mustClientFromCmd(cmd).Auth.RoleGrantPermission(context.TODO(), args[0], key, rangeEnd, perm)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.RoleGrantPermission(args[0], *resp)\r\n}","code-length":217,"reference":"\/\/ roleGrantPermissionCommandFunc executes the \"role grant-permission\" command.","result":"Generate the code.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc roleRevokePermissionCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) < 2 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"role revoke-permission command requires role name and key [endkey] as its argument\"))\r\n\t}\r\n\tkey, rangeEnd := permRange(args[1:])\r\n\tresp, err := mustClientFromCmd(cmd).Auth.RoleRevokePermission(context.TODO(), args[0], key, rangeEnd)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.RoleRevokePermission(args[0], args[1], rangeEnd, *resp)\r\n}","code-length":174,"reference":"\/\/ roleRevokePermissionCommandFunc executes the \"role revoke-permission\" command.","result":"Generate the code.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCluster(t testing.TB, size int) *cluster {\r\n\treturn newCluster(t, &ClusterConfig{Size: size})\r\n}","code-length":44,"reference":"\/\/ NewCluster returns an unlaunched cluster of the given size which has been\n\/\/ set to use static bootstrap.","result":"Create a new cluster.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClusterByConfig(t testing.TB, cfg *ClusterConfig) *cluster {\r\n\treturn newCluster(t, cfg)\r\n}","code-length":42,"reference":"\/\/ NewClusterByConfig returns an unlaunched cluster defined by a cluster configuration","result":"Generate the file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *cluster) HTTPMembers() []client.Member {\r\n\tms := []client.Member{}\r\n\tfor _, m := range c.Members {\r\n\t\tpScheme := schemeFromTLSInfo(m.PeerTLSInfo)\r\n\t\tcScheme := schemeFromTLSInfo(m.ClientTLSInfo)\r\n\t\tcm := client.Member{Name: m.Name}\r\n\t\tfor _, ln := range m.PeerListeners {\r\n\t\t\tcm.PeerURLs = append(cm.PeerURLs, pScheme+\":\r\n\t\t}\r\n\t\tfor _, ln := range m.ClientListeners {\r\n\t\t\tcm.ClientURLs = append(cm.ClientURLs, cScheme+\":\r\n\t\t}\r\n\t\tms = append(ms, cm)\r\n\t}\r\n\treturn ms\r\n}","code-length":202,"reference":"\/\/ HTTPMembers returns a list of all active members as client.Members","result":"Generate the cluster members .","score":[0.0724,0.0481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *cluster) waitLeader(t testing.TB, membs []*member) int {\r\n\tpossibleLead := make(map[uint64]bool)\r\n\tvar lead uint64\r\n\tfor _, m := range membs {\r\n\t\tpossibleLead[uint64(m.s.ID())] = true\r\n\t}\r\n\tcc := MustNewHTTPClient(t, getMembersURLs(membs), nil)\r\n\tkapi := client.NewKeysAPI(cc)\r\n\t\r\n\tfor {\r\n\t\tctx, cancel := context.WithTimeout(context.Background(), 10*tickDuration+time.Second)\r\n\t\t_, err := kapi.Get(ctx, \"0\", &client.GetOptions{Quorum: true})\r\n\t\tcancel()\r\n\t\tif err == nil || strings.Contains(err.Error(), \"Key not found\") {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tfor lead == 0 || !possibleLead[lead] {\r\n\t\tlead = 0\r\n\t\tfor _, m := range membs {\r\n\t\t\tselect {\r\n\t\t\tcase <-m.s.StopNotify():\r\n\t\t\t\tcontinue\r\n\t\t\tdefault:\r\n\t\t\t}\r\n\t\t\tif lead != 0 && lead != m.s.Lead() {\r\n\t\t\t\tlead = 0\r\n\t\t\t\ttime.Sleep(10 * tickDuration)\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\tlead = m.s.Lead()\r\n\t\t}\r\n\t}\r\n\tfor i, m := range membs {\r\n\t\tif uint64(m.s.ID()) == lead {\r\n\t\t\treturn i\r\n\t\t}\r\n\t}\r\n\treturn -1\r\n}","code-length":418,"reference":"\/\/ waitLeader waits until given members agree on the same leader.","result":"Test the waitLeader function.","score":[0.066,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *cluster) waitNoLeader(membs []*member) {\r\n\tnoLeader := false\r\n\tfor !noLeader {\r\n\t\tnoLeader = true\r\n\t\tfor _, m := range membs {\r\n\t\t\tselect {\r\n\t\t\tcase <-m.s.StopNotify():\r\n\t\t\t\tcontinue\r\n\t\t\tdefault:\r\n\t\t\t}\r\n\t\t\tif m.s.Lead() != 0 {\r\n\t\t\t\tnoLeader = false\r\n\t\t\t\ttime.Sleep(10 * tickDuration)\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":154,"reference":"\/\/ waitNoLeader waits until given members lose leader.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isMembersEqual(membs []client.Member, wmembs []client.Member) bool {\r\n\tsort.Sort(SortableMemberSliceByPeerURLs(membs))\r\n\tsort.Sort(SortableMemberSliceByPeerURLs(wmembs))\r\n\tfor i := range membs {\r\n\t\tmembs[i].ID = \"\"\r\n\t}\r\n\treturn reflect.DeepEqual(membs, wmembs)\r\n}","code-length":111,"reference":"\/\/ isMembersEqual checks whether two members equal except ID field.\n\/\/ The given wmembs should always set ID field to empty string.","result":"Compare members.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *member) listenGRPC() error {\r\n\t\r\n\tm.grpcAddr = \"localhost:\" + m.Name\r\n\tif m.useIP {\r\n\t\tm.grpcAddr = \"127.0.0.1:\" + m.Name\r\n\t}\r\n\tl, err := transport.NewUnixListener(m.grpcAddr)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"listen failed on grpc socket %s (%v)\", m.grpcAddr, err)\r\n\t}\r\n\tm.grpcBridge, err = newBridge(m.grpcAddr)\r\n\tif err != nil {\r\n\t\tl.Close()\r\n\t\treturn err\r\n\t}\r\n\tm.grpcAddr = schemeFromTLSInfo(m.ClientTLSInfo) + \":\r\n\tm.grpcListener = l\r\n\treturn nil\r\n}","code-length":212,"reference":"\/\/ listenGRPC starts a grpc server over a unix domain socket on the member","result":"Listen on the grpc socket.","score":[0.0622,0.1951]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClientV3(m *member) (*clientv3.Client, error) {\r\n\tif m.grpcAddr == \"\" {\r\n\t\treturn nil, fmt.Errorf(\"member not configured for grpc\")\r\n\t}\r\n\tcfg := clientv3.Config{\r\n\t\tEndpoints:          []string{m.grpcAddr},\r\n\t\tDialTimeout:        5 * time.Second,\r\n\t\tDialOptions:        []grpc.DialOption{grpc.WithBlock()},\r\n\t\tMaxCallSendMsgSize: m.clientMaxCallSendMsgSize,\r\n\t\tMaxCallRecvMsgSize: m.clientMaxCallRecvMsgSize,\r\n\t}\r\n\tif m.ClientTLSInfo != nil {\r\n\t\ttls, err := m.ClientTLSInfo.ClientConfig()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tcfg.TLS = tls\r\n\t}\r\n\tif m.DialOptions != nil {\r\n\t\tcfg.DialOptions = append(cfg.DialOptions, m.DialOptions...)\r\n\t}\r\n\treturn newClientV3(cfg)\r\n}","code-length":275,"reference":"\/\/ NewClientV3 creates a new grpc client connection to the member","result":"Create a new client v.","score":[0.1133,0.3606]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *member) Clone(t testing.TB) *member {\r\n\tmm := &member{}\r\n\tmm.ServerConfig = m.ServerConfig\r\n\tvar err error\r\n\tclientURLStrs := m.ClientURLs.StringSlice()\r\n\tmm.ClientURLs, err = types.NewURLs(clientURLStrs)\r\n\tif err != nil {\r\n\t\t\r\n\t\tpanic(err)\r\n\t}\r\n\tpeerURLStrs := m.PeerURLs.StringSlice()\r\n\tmm.PeerURLs, err = types.NewURLs(peerURLStrs)\r\n\tif err != nil {\r\n\t\t\r\n\t\tpanic(err)\r\n\t}\r\n\tclusterStr := m.InitialPeerURLsMap.String()\r\n\tmm.InitialPeerURLsMap, err = types.NewURLsMap(clusterStr)\r\n\tif err != nil {\r\n\t\t\r\n\t\tpanic(err)\r\n\t}\r\n\tmm.InitialClusterToken = m.InitialClusterToken\r\n\tmm.ElectionTicks = m.ElectionTicks\r\n\tmm.PeerTLSInfo = m.PeerTLSInfo\r\n\tmm.ClientTLSInfo = m.ClientTLSInfo\r\n\treturn mm\r\n}","code-length":289,"reference":"\/\/ Clone returns a member with the same server configuration. The returned\n\/\/ member will not set PeerListeners and ClientListeners.","result":"Clone the member.","score":[0.0017,0.0546]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *member) Close() {\r\n\tif m.grpcBridge != nil {\r\n\t\tm.grpcBridge.Close()\r\n\t\tm.grpcBridge = nil\r\n\t}\r\n\tif m.serverClient != nil {\r\n\t\tm.serverClient.Close()\r\n\t\tm.serverClient = nil\r\n\t}\r\n\tif m.grpcServer != nil {\r\n\t\tm.grpcServer.Stop()\r\n\t\tm.grpcServer.GracefulStop()\r\n\t\tm.grpcServer = nil\r\n\t\tm.grpcServerPeer.Stop()\r\n\t\tm.grpcServerPeer.GracefulStop()\r\n\t\tm.grpcServerPeer = nil\r\n\t}\r\n\tm.s.HardStop()\r\n\tfor _, f := range m.serverClosers {\r\n\t\tf()\r\n\t}\r\n}","code-length":214,"reference":"\/\/ Close stops the member's etcdserver and closes its connections","result":"Close the member.","score":[0.0471,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *member) Stop(t testing.TB) {\r\n\tlg.Info(\r\n\t\t\"stopping a member\",\r\n\t\tzap.String(\"name\", m.Name),\r\n\t\tzap.Strings(\"advertise-peer-urls\", m.PeerURLs.StringSlice()),\r\n\t\tzap.Strings(\"listen-client-urls\", m.ClientURLs.StringSlice()),\r\n\t\tzap.String(\"grpc-address\", m.grpcAddr),\r\n\t)\r\n\tm.Close()\r\n\tm.serverClosers = nil\r\n\tlg.Info(\r\n\t\t\"stopped a member\",\r\n\t\tzap.String(\"name\", m.Name),\r\n\t\tzap.Strings(\"advertise-peer-urls\", m.PeerURLs.StringSlice()),\r\n\t\tzap.Strings(\"listen-client-urls\", m.ClientURLs.StringSlice()),\r\n\t\tzap.String(\"grpc-address\", m.grpcAddr),\r\n\t)\r\n}","code-length":248,"reference":"\/\/ Stop stops the member, but the data dir of the member is preserved.","result":"Test the member stop .","score":[0.0562,0.1951]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkLeaderTransition(m *member, oldLead uint64) uint64 {\r\n\tinterval := time.Duration(m.s.Cfg.TickMs) * time.Millisecond\r\n\tfor m.s.Lead() == 0 || (m.s.Lead() == oldLead) {\r\n\t\ttime.Sleep(interval)\r\n\t}\r\n\treturn m.s.Lead()\r\n}","code-length":102,"reference":"\/\/ checkLeaderTransition waits for leader transition, returning the new leader ID.","result":"Check leader transition.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *member) Restart(t testing.TB) error {\r\n\tlg.Info(\r\n\t\t\"restarting a member\",\r\n\t\tzap.String(\"name\", m.Name),\r\n\t\tzap.Strings(\"advertise-peer-urls\", m.PeerURLs.StringSlice()),\r\n\t\tzap.Strings(\"listen-client-urls\", m.ClientURLs.StringSlice()),\r\n\t\tzap.String(\"grpc-address\", m.grpcAddr),\r\n\t)\r\n\tnewPeerListeners := make([]net.Listener, 0)\r\n\tfor _, ln := range m.PeerListeners {\r\n\t\tnewPeerListeners = append(newPeerListeners, NewListenerWithAddr(t, ln.Addr().String()))\r\n\t}\r\n\tm.PeerListeners = newPeerListeners\r\n\tnewClientListeners := make([]net.Listener, 0)\r\n\tfor _, ln := range m.ClientListeners {\r\n\t\tnewClientListeners = append(newClientListeners, NewListenerWithAddr(t, ln.Addr().String()))\r\n\t}\r\n\tm.ClientListeners = newClientListeners\r\n\tif m.grpcListener != nil {\r\n\t\tif err := m.listenGRPC(); err != nil {\r\n\t\t\tt.Fatal(err)\r\n\t\t}\r\n\t}\r\n\terr := m.Launch()\r\n\tlg.Info(\r\n\t\t\"restarted a member\",\r\n\t\tzap.String(\"name\", m.Name),\r\n\t\tzap.Strings(\"advertise-peer-urls\", m.PeerURLs.StringSlice()),\r\n\t\tzap.Strings(\"listen-client-urls\", m.ClientURLs.StringSlice()),\r\n\t\tzap.String(\"grpc-address\", m.grpcAddr),\r\n\t\tzap.Error(err),\r\n\t)\r\n\treturn err\r\n}","code-length":449,"reference":"\/\/ Restart starts the member using the preserved data dir.","result":"Restart a member.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *member) Terminate(t testing.TB) {\r\n\tlg.Info(\r\n\t\t\"terminating a member\",\r\n\t\tzap.String(\"name\", m.Name),\r\n\t\tzap.Strings(\"advertise-peer-urls\", m.PeerURLs.StringSlice()),\r\n\t\tzap.Strings(\"listen-client-urls\", m.ClientURLs.StringSlice()),\r\n\t\tzap.String(\"grpc-address\", m.grpcAddr),\r\n\t)\r\n\tm.Close()\r\n\tif !m.keepDataDirTerminate {\r\n\t\tif err := os.RemoveAll(m.ServerConfig.DataDir); err != nil {\r\n\t\t\tt.Fatal(err)\r\n\t\t}\r\n\t}\r\n\tlg.Info(\r\n\t\t\"terminated a member\",\r\n\t\tzap.String(\"name\", m.Name),\r\n\t\tzap.Strings(\"advertise-peer-urls\", m.PeerURLs.StringSlice()),\r\n\t\tzap.Strings(\"listen-client-urls\", m.ClientURLs.StringSlice()),\r\n\t\tzap.String(\"grpc-address\", m.grpcAddr),\r\n\t)\r\n}","code-length":293,"reference":"\/\/ Terminate stops the member and removes the data dir.","result":"Terminate a member.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *member) Metric(metricName string) (string, error) {\r\n\tcfgtls := transport.TLSInfo{}\r\n\ttr, err := transport.NewTimeoutTransport(cfgtls, time.Second, time.Second, time.Second)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tcli := &http.Client{Transport: tr}\r\n\tresp, err := cli.Get(m.ClientURLs[0].String() + \"\/metrics\")\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\tb, rerr := ioutil.ReadAll(resp.Body)\r\n\tif rerr != nil {\r\n\t\treturn \"\", rerr\r\n\t}\r\n\tlines := strings.Split(string(b), \"\\n\")\r\n\tfor _, l := range lines {\r\n\t\tif strings.HasPrefix(l, metricName) {\r\n\t\t\treturn strings.Split(l, \" \")[1], nil\r\n\t\t}\r\n\t}\r\n\treturn \"\", nil\r\n}","code-length":267,"reference":"\/\/ Metric gets the metric value for a member","result":"Get the value of a metric.","score":[0.1541,0.3628]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *member) InjectPartition(t testing.TB, others ...*member) {\r\n\tfor _, other := range others {\r\n\t\tm.s.CutPeer(other.s.ID())\r\n\t\tother.s.CutPeer(m.s.ID())\r\n\t}\r\n}","code-length":81,"reference":"\/\/ InjectPartition drops connections from m to others, vice versa.","result":"Inject partition.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *member) RecoverPartition(t testing.TB, others ...*member) {\r\n\tfor _, other := range others {\r\n\t\tm.s.MendPeer(other.s.ID())\r\n\t\tother.s.MendPeer(m.s.ID())\r\n\t}\r\n}","code-length":84,"reference":"\/\/ RecoverPartition recovers connections from m to others, vice versa.","result":"Test the partition recovery.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClusterV3(t testing.TB, cfg *ClusterConfig) *ClusterV3 {\r\n\tcfg.UseGRPC = true\r\n\tif os.Getenv(\"CLIENT_DEBUG\") != \"\" {\r\n\t\tclientv3.SetLogger(grpclog.NewLoggerV2WithVerbosity(os.Stderr, os.Stderr, os.Stderr, 4))\r\n\t}\r\n\tclus := &ClusterV3{\r\n\t\tcluster: NewClusterByConfig(t, cfg),\r\n\t}\r\n\tclus.Launch(t)\r\n\tif !cfg.SkipCreatingClient {\r\n\t\tfor _, m := range clus.Members {\r\n\t\t\tclient, err := NewClientV3(m)\r\n\t\t\tif err != nil {\r\n\t\t\t\tt.Fatalf(\"cannot create client: %v\", err)\r\n\t\t\t}\r\n\t\t\tclus.clients = append(clus.clients, client)\r\n\t\t}\r\n\t}\r\n\treturn clus\r\n}","code-length":242,"reference":"\/\/ NewClusterV3 returns a launched cluster with a grpc client connection\n\/\/ for each cluster member.","result":"Create a new cluster by config.","score":[0.0434,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (opts *jwtOptions) ParseWithDefaults(optMap map[string]string) error {\r\n\tif opts.TTL == 0 && optMap[optTTL] == \"\" {\r\n\t\topts.TTL = DefaultTTL\r\n\t}\r\n\treturn opts.Parse(optMap)\r\n}","code-length":77,"reference":"\/\/ ParseWithDefaults will load options from the specified map or set defaults where appropriate","result":"Parse JWT.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (opts *jwtOptions) Parse(optMap map[string]string) error {\r\n\tvar err error\r\n\tif ttl := optMap[optTTL]; ttl != \"\" {\r\n\t\topts.TTL, err = time.ParseDuration(ttl)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tif file := optMap[optPublicKey]; file != \"\" {\r\n\t\topts.PublicKey, err = ioutil.ReadFile(file)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tif file := optMap[optPrivateKey]; file != \"\" {\r\n\t\topts.PrivateKey, err = ioutil.ReadFile(file)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\t\r\n\tmethod := optMap[optSignMethod]\r\n\topts.SignMethod = jwt.GetSigningMethod(method)\r\n\tif opts.SignMethod == nil {\r\n\t\treturn ErrInvalidAuthMethod\r\n\t}\r\n\treturn nil\r\n}","code-length":267,"reference":"\/\/ Parse will load options from the specified map","result":"Parse the options.","score":[0.0657,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (opts *jwtOptions) Key() (interface{}, error) {\r\n\tswitch opts.SignMethod.(type) {\r\n\tcase *jwt.SigningMethodRSA, *jwt.SigningMethodRSAPSS:\r\n\t\treturn opts.rsaKey()\r\n\tcase *jwt.SigningMethodECDSA:\r\n\t\treturn opts.ecKey()\r\n\tcase *jwt.SigningMethodHMAC:\r\n\t\treturn opts.hmacKey()\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"unsupported signing method: %T\", opts.SignMethod)\r\n\t}\r\n}","code-length":146,"reference":"\/\/ Key will parse and return the appropriately typed key for the selected signature method","result":"Generate the key.","score":[0.0075,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *header) fill(rh *pb.ResponseHeader) {\r\n\tif rh == nil {\r\n\t\tplog.Panic(\"unexpected nil resp.Header\")\r\n\t}\r\n\trh.ClusterId = uint64(h.clusterID)\r\n\trh.MemberId = uint64(h.memberID)\r\n\trh.RaftTerm = h.sg.Term()\r\n\tif rh.Revision == 0 {\r\n\t\trh.Revision = h.rev()\r\n\t}\r\n}","code-length":128,"reference":"\/\/ fill populates pb.ResponseHeader using etcdserver information","result":"Fill the header.","score":[0,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wb *watchBroadcast) add(w *watcher) bool {\r\n\twb.mu.Lock()\r\n\tdefer wb.mu.Unlock()\r\n\tif wb.nextrev > w.nextrev || (wb.nextrev == 0 && w.nextrev != 0) {\r\n\t\t\r\n\t\t\r\n\t\treturn false\r\n\t}\r\n\tif wb.responses == 0 {\r\n\t\t\r\n\t\twb.receivers[w] = struct{}{}\r\n\t\treturn true\r\n\t}\r\n\t\r\n\tok := w.post(&pb.WatchResponse{\r\n\t\tHeader: &pb.ResponseHeader{\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tRevision: w.nextrev,\r\n\t\t\t\r\n\t\t},\r\n\t\tWatchId: w.id,\r\n\t\tCreated: true,\r\n\t})\r\n\tif !ok {\r\n\t\treturn false\r\n\t}\r\n\twb.receivers[w] = struct{}{}\r\n\twatchersCoalescing.Inc()\r\n\treturn true\r\n}","code-length":256,"reference":"\/\/ add puts a watcher into receiving a broadcast if its revision at least\n\/\/ meets the broadcast revision. Returns true if added.","result":"Broadcast watchers.","score":[0,0.0239]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ws *watchStream) Watch(id WatchID, key, end []byte, startRev int64, fcs ...FilterFunc) (WatchID, error) {\r\n\t\r\n\t\r\n\tif len(end) != 0 && bytes.Compare(key, end) != -1 {\r\n\t\treturn -1, ErrEmptyWatcherRange\r\n\t}\r\n\tws.mu.Lock()\r\n\tdefer ws.mu.Unlock()\r\n\tif ws.closed {\r\n\t\treturn -1, ErrEmptyWatcherRange\r\n\t}\r\n\tif id == AutoWatchID {\r\n\t\tfor ws.watchers[ws.nextID] != nil {\r\n\t\t\tws.nextID++\r\n\t\t}\r\n\t\tid = ws.nextID\r\n\t\tws.nextID++\r\n\t} else if _, ok := ws.watchers[id]; ok {\r\n\t\treturn -1, ErrWatcherDuplicateID\r\n\t}\r\n\tw, c := ws.watchable.watch(key, end, startRev, id, ws.ch, fcs...)\r\n\tws.cancels[id] = c\r\n\tws.watchers[id] = w\r\n\treturn id, nil\r\n}","code-length":294,"reference":"\/\/ Watch creates a new watcher in the stream and returns its WatchID.","result":"Watch a range of keys.","score":[0.0577,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newFileEncoder(f *os.File, prevCrc uint32) (*encoder, error) {\r\n\toffset, err := f.Seek(0, io.SeekCurrent)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn newEncoder(f, prevCrc, int(offset)), nil\r\n}","code-length":92,"reference":"\/\/ newFileEncoder creates a new encoder with current file offset for the page writer.","result":"Create a new file encoder.","score":[0.0622,0.2863]}
{"code":"\/*is used to<extra_id_0>\r\nfunc purgeFile(lg *zap.Logger, dirname string, suffix string, max uint, interval time.Duration, stop <-chan struct{}, purgec chan<- string) <-chan error {\r\n\terrC := make(chan error, 1)\r\n\tgo func() {\r\n\t\tfor {\r\n\t\t\tfnames, err := ReadDir(dirname)\r\n\t\t\tif err != nil {\r\n\t\t\t\terrC <- err\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tnewfnames := make([]string, 0)\r\n\t\t\tfor _, fname := range fnames {\r\n\t\t\t\tif strings.HasSuffix(fname, suffix) {\r\n\t\t\t\t\tnewfnames = append(newfnames, fname)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tsort.Strings(newfnames)\r\n\t\t\tfnames = newfnames\r\n\t\t\tfor len(newfnames) > int(max) {\r\n\t\t\t\tf := filepath.Join(dirname, newfnames[0])\r\n\t\t\t\tl, err := TryLockFile(f, os.O_WRONLY, PrivateFileMode)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t\tif err = os.Remove(f); err != nil {\r\n\t\t\t\t\terrC <- err\r\n\t\t\t\t\treturn\r\n\t\t\t\t}\r\n\t\t\t\tif err = l.Close(); err != nil {\r\n\t\t\t\t\tif lg != nil {\r\n\t\t\t\t\t\tlg.Warn(\"failed to unlock\/close\", zap.String(\"path\", l.Name()), zap.Error(err))\r\n\t\t\t\t\t} else {\r\n\t\t\t\t\t\tplog.Errorf(\"error unlocking %s when purging file (%v)\", l.Name(), err)\r\n\t\t\t\t\t}\r\n\t\t\t\t\terrC <- err\r\n\t\t\t\t\treturn\r\n\t\t\t\t}\r\n\t\t\t\tif lg != nil {\r\n\t\t\t\t\tlg.Info(\"purged\", zap.String(\"path\", f))\r\n\t\t\t\t} else {\r\n\t\t\t\t\tplog.Infof(\"purged file %s successfully\", f)\r\n\t\t\t\t}\r\n\t\t\t\tnewfnames = newfnames[1:]\r\n\t\t\t}\r\n\t\t\tif purgec != nil {\r\n\t\t\t\tfor i := 0; i < len(fnames)-len(newfnames); i++ {\r\n\t\t\t\t\tpurgec <- fnames[i]\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tselect {\r\n\t\t\tcase <-time.After(interval):\r\n\t\t\tcase <-stop:\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t}\r\n\t}()\r\n\treturn errC\r\n}","code-length":627,"reference":"\/\/ purgeFile is the internal implementation for PurgeFile which can post purged files to purgec if non-nil.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ss *StringsValue) Set(s string) error {\r\n\t*ss = strings.Split(s, \",\")\r\n\treturn nil\r\n}","code-length":45,"reference":"\/\/ Set parses a command line set of strings, separated by comma.\n\/\/ Implements \"flag.Value\" interface.","result":"Set the value of the stringsValue.","score":[0.0434,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewStringsValue(s string) (ss *StringsValue) {\r\n\tif s == \"\" {\r\n\t\treturn &StringsValue{}\r\n\t}\r\n\tss = new(StringsValue)\r\n\tif err := ss.Set(s); err != nil {\r\n\t\tplog.Panicf(\"new StringsValue should never fail: %v\", err)\r\n\t}\r\n\treturn ss\r\n}","code-length":105,"reference":"\/\/ NewStringsValue implements string slice as \"flag.Value\" interface.\n\/\/ Given value is to be separated by comma.","result":"Create a new StringsValue.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StringsFromFlag(fs *flag.FlagSet, flagName string) []string {\r\n\treturn []string(*fs.Lookup(flagName).Value.(*StringsValue))\r\n}","code-length":51,"reference":"\/\/ StringsFromFlag returns a string slice from the flag.","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Cluster(v string) string {\r\n\tvs := strings.Split(v, \".\")\r\n\tif len(vs) <= 2 {\r\n\t\treturn v\r\n\t}\r\n\treturn fmt.Sprintf(\"%s.%s\", vs[0], vs[1])\r\n}","code-length":75,"reference":"\/\/ Cluster only keeps the major.minor.","result":"Create cluster objects.","score":[0,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPageWriter(w io.Writer, pageBytes, pageOffset int) *PageWriter {\r\n\treturn &PageWriter{\r\n\t\tw:                 w,\r\n\t\tpageOffset:        pageOffset,\r\n\t\tpageBytes:         pageBytes,\r\n\t\tbuf:               make([]byte, defaultBufferBytes+pageBytes),\r\n\t\tbufWatermarkBytes: defaultBufferBytes,\r\n\t}\r\n}","code-length":107,"reference":"\/\/ NewPageWriter creates a new PageWriter. pageBytes is the number of bytes\n\/\/ to write per page. pageOffset is the starting offset of io.Writer.","result":"Create a new page writer.","score":[0.0076,0.1332]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wh *watcherHub) watch(key string, recursive, stream bool, index, storeIndex uint64) (Watcher, *v2error.Error) {\r\n\treportWatchRequest()\r\n\tevent, err := wh.EventHistory.scan(key, recursive, index)\r\n\tif err != nil {\r\n\t\terr.Index = storeIndex\r\n\t\treturn nil, err\r\n\t}\r\n\tw := &watcher{\r\n\t\teventChan:  make(chan *Event, 100),\r\n\t\trecursive:  recursive,\r\n\t\tstream:     stream,\r\n\t\tsinceIndex: index,\r\n\t\tstartIndex: storeIndex,\r\n\t\thub:        wh,\r\n\t}\r\n\twh.mutex.Lock()\r\n\tdefer wh.mutex.Unlock()\r\n\t\r\n\tif event != nil {\r\n\t\tne := event.Clone()\r\n\t\tne.EtcdIndex = storeIndex\r\n\t\tw.eventChan <- ne\r\n\t\treturn w, nil\r\n\t}\r\n\tl, ok := wh.watchers[key]\r\n\tvar elem *list.Element\r\n\tif ok {\r\n\t\telem = l.PushBack(w)\r\n\t} else {\r\n\t\tl = list.New()\r\n\t\telem = l.PushBack(w)\r\n\t\twh.watchers[key] = l\r\n\t}\r\n\tw.remove = func() {\r\n\t\tif w.removed {\r\n\t\t\treturn\r\n\t\t}\r\n\t\tw.removed = true\r\n\t\tl.Remove(elem)\r\n\t\tatomic.AddInt64(&wh.count, -1)\r\n\t\treportWatcherRemoved()\r\n\t\tif l.Len() == 0 {\r\n\t\t\tdelete(wh.watchers, key)\r\n\t\t}\r\n\t}\r\n\tatomic.AddInt64(&wh.count, 1)\r\n\treportWatcherAdded()\r\n\treturn w, nil\r\n}","code-length":477,"reference":"\/\/ Watch function returns a Watcher.\n\/\/ If recursive is true, the first change after index under key will be sent to the event channel of the watcher.\n\/\/ If recursive is false, the first change after index at key will be sent to the event channel of the watcher.\n\/\/ If index is zero, watch will start from the current index + 1.","result":"Watch a key.","score":[0.0,0.0173]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wh *watcherHub) notify(e *Event) {\r\n\te = wh.EventHistory.addEvent(e)\r\n\tsegments := strings.Split(e.Node.Key, \"\/\")\r\n\tcurrPath := \"\/\"\r\n\t\r\n\t\r\n\t\r\n\tfor _, segment := range segments {\r\n\t\tcurrPath = path.Join(currPath, segment)\r\n\t\t\r\n\t\twh.notifyWatchers(e, currPath, false)\r\n\t}\r\n}","code-length":125,"reference":"\/\/ notify function accepts an event and notify to the watchers.","result":"Notify watchers.","score":[0.0056,0.099]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wh *watcherHub) clone() *watcherHub {\r\n\tclonedHistory := wh.EventHistory.clone()\r\n\treturn &watcherHub{\r\n\t\tEventHistory: clonedHistory,\r\n\t}\r\n}","code-length":61,"reference":"\/\/ clone function clones the watcherHub and return the cloned one.\n\/\/ only clone the static content. do not clone the current watchers.","result":"Avoid cloning the event history.","score":[0.0066,0.0884]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isHidden(watchPath, keyPath string) bool {\r\n\t\r\n\t\r\n\tif len(watchPath) > len(keyPath) {\r\n\t\treturn false\r\n\t}\r\n\t\r\n\t\r\n\tafterPath := path.Clean(\"\/\" + keyPath[len(watchPath):])\r\n\treturn strings.Contains(afterPath, \"\/_\")\r\n}","code-length":95,"reference":"\/\/ isHidden checks to see if key path is considered hidden to watch path i.e. the\n\/\/ last element is hidden or it's within a hidden directory","result":"Determine if the file is hidden.","score":[0.0077,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (srv *Server) createEtcdLogFile() error {\r\n\tvar err error\r\n\tsrv.etcdLogFile, err = os.Create(srv.Member.Etcd.LogOutputs[0])\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tsrv.lg.Info(\"created etcd log file\", zap.String(\"path\", srv.Member.Etcd.LogOutputs[0]))\r\n\treturn nil\r\n}","code-length":110,"reference":"\/\/ just archive the first file","result":"Create etcd log file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (srv *Server) runEtcd() error {\r\n\terrc := make(chan error)\r\n\tgo func() {\r\n\t\ttime.Sleep(5 * time.Second)\r\n\t\t\r\n\t\t\r\n\t\terrc <- srv.startProxy()\r\n\t}()\r\n\tif srv.etcdCmd != nil {\r\n\t\tsrv.lg.Info(\r\n\t\t\t\"starting etcd command\",\r\n\t\t\tzap.String(\"command-path\", srv.etcdCmd.Path),\r\n\t\t)\r\n\t\terr := srv.etcdCmd.Start()\r\n\t\tperr := <-errc\r\n\t\tsrv.lg.Info(\r\n\t\t\t\"started etcd command\",\r\n\t\t\tzap.String(\"command-path\", srv.etcdCmd.Path),\r\n\t\t\tzap.Errors(\"errors\", []error{err, perr}),\r\n\t\t)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn perr\r\n\t}\r\n\tselect {\r\n\tcase <-srv.etcdServer.Server.ReadyNotify():\r\n\t\tsrv.lg.Info(\"embedded etcd is ready\")\r\n\tcase <-time.After(time.Minute):\r\n\t\tsrv.etcdServer.Close()\r\n\t\treturn fmt.Errorf(\"took too long to start %v\", <-srv.etcdServer.Err())\r\n\t}\r\n\treturn <-errc\r\n}","code-length":354,"reference":"\/\/ start but do not wait for it to complete","result":"Run etcd server.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (srv *Server) stopEtcd(sig os.Signal) error {\r\n\tsrv.stopProxy()\r\n\tif srv.etcdCmd != nil {\r\n\t\tsrv.lg.Info(\r\n\t\t\t\"stopping etcd command\",\r\n\t\t\tzap.String(\"command-path\", srv.etcdCmd.Path),\r\n\t\t\tzap.String(\"signal\", sig.String()),\r\n\t\t)\r\n\t\terr := srv.etcdCmd.Process.Signal(sig)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\terrc := make(chan error)\r\n\t\tgo func() {\r\n\t\t\t_, ew := srv.etcdCmd.Process.Wait()\r\n\t\t\terrc <- ew\r\n\t\t\tclose(errc)\r\n\t\t}()\r\n\t\tselect {\r\n\t\tcase <-time.After(5 * time.Second):\r\n\t\t\tsrv.etcdCmd.Process.Kill()\r\n\t\tcase e := <-errc:\r\n\t\t\treturn e\r\n\t\t}\r\n\t\terr = <-errc\r\n\t\tsrv.lg.Info(\r\n\t\t\t\"stopped etcd command\",\r\n\t\t\tzap.String(\"command-path\", srv.etcdCmd.Path),\r\n\t\t\tzap.String(\"signal\", sig.String()),\r\n\t\t\tzap.Error(err),\r\n\t\t)\r\n\t\treturn err\r\n\t}\r\n\tsrv.lg.Info(\"stopping embedded etcd\")\r\n\tsrv.etcdServer.Server.HardStop()\r\n\tsrv.etcdServer.Close()\r\n\tsrv.lg.Info(\"stopped embedded etcd\")\r\n\treturn nil\r\n}","code-length":415,"reference":"\/\/ SIGQUIT to exit with stackstrace","result":"Stop the embedded etcd server.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (srv *Server) handle_SIGQUIT_ETCD_AND_REMOVE_DATA_AND_STOP_AGENT() (*rpcpb.Response, error) {\r\n\terr := srv.stopEtcd(syscall.SIGQUIT)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif srv.etcdServer != nil {\r\n\t\tsrv.etcdServer.GetLogger().Sync()\r\n\t} else {\r\n\t\tsrv.etcdLogFile.Sync()\r\n\t\tsrv.etcdLogFile.Close()\r\n\t}\r\n\terr = os.RemoveAll(srv.Member.BaseDir)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tsrv.lg.Info(\"removed base directory\", zap.String(\"dir\", srv.Member.BaseDir))\r\n\t\r\n\tsrv.Stop()\r\n\treturn &rpcpb.Response{\r\n\t\tSuccess: true,\r\n\t\tStatus:  \"destroyed etcd and agent\",\r\n\t}, nil\r\n}","code-length":257,"reference":"\/\/ stop proxy, etcd, delete data directory","result":"Handle SIGTERM and SIGKILL.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LimitListener(l net.Listener, n int) net.Listener {\r\n\treturn &limitListener{l, make(chan struct{}, n)}\r\n}","code-length":46,"reference":"\/\/ LimitListener returns a Listener that accepts at most n simultaneous\n\/\/ connections from the provided Listener.","result":"Create a new listener.","score":[0.0124,0.0637]}
{"code":"\/*is used to<extra_id_0>\r\nfunc allowMethod(w http.ResponseWriter, m string, ms ...string) bool {\r\n\tfor _, meth := range ms {\r\n\t\tif m == meth {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\tw.Header().Set(\"Allow\", strings.Join(ms, \",\"))\r\n\thttp.Error(w, \"Method Not Allowed\", http.StatusMethodNotAllowed)\r\n\treturn false\r\n}","code-length":110,"reference":"\/\/ allowMethod verifies that the given method is one of the allowed methods,\n\/\/ and if not, it writes an error to w.  A boolean is returned indicating\n\/\/ whether or not the method is allowed.","result":"Check if the method is.","score":[0.0008,0.0777]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewWatchServer(s *etcdserver.EtcdServer) pb.WatchServer {\r\n\treturn &watchServer{\r\n\t\tlg: s.Cfg.Logger,\r\n\t\tclusterID: int64(s.Cluster().ID()),\r\n\t\tmemberID:  int64(s.ID()),\r\n\t\tmaxRequestBytes: int(s.Cfg.MaxRequestBytes + grpcOverheadBytes),\r\n\t\tsg:        s,\r\n\t\twatchable: s.Watchable(),\r\n\t\tag:        s,\r\n\t}\r\n}","code-length":141,"reference":"\/\/ NewWatchServer returns a new watch server.","result":"Create a new watch server.","score":[0.5042,0.5836]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FiltersFromRequest(creq *pb.WatchCreateRequest) []mvcc.FilterFunc {\r\n\tfilters := make([]mvcc.FilterFunc, 0, len(creq.Filters))\r\n\tfor _, ft := range creq.Filters {\r\n\t\tswitch ft {\r\n\t\tcase pb.WatchCreateRequest_NOPUT:\r\n\t\t\tfilters = append(filters, filterNoPut)\r\n\t\tcase pb.WatchCreateRequest_NODELETE:\r\n\t\t\tfilters = append(filters, filterNoDelete)\r\n\t\tdefault:\r\n\t\t}\r\n\t}\r\n\treturn filters\r\n}","code-length":152,"reference":"\/\/ FiltersFromRequest returns \"mvcc.FilterFunc\" from a given watch create request.","result":"Create a new watch request.","score":[0.1163,0.2105]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newPipelineHandler(t *Transport, r Raft, cid types.ID) http.Handler {\r\n\treturn &pipelineHandler{\r\n\t\tlg:      t.Logger,\r\n\t\tlocalID: t.ID,\r\n\t\ttr:      t,\r\n\t\tr:       r,\r\n\t\tcid:     cid,\r\n\t}\r\n}","code-length":94,"reference":"\/\/ newPipelineHandler returns a handler for handling raft messages\n\/\/ from pipeline for RaftPrefix.\n\/\/\n\/\/ The handler reads out the raft message from request body,\n\/\/ and forwards it to the given raft state machine for processing.","result":"Create a pipeline handler.","score":[0.0001,0.0289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkClusterCompatibilityFromHeader(lg *zap.Logger, localID types.ID, header http.Header, cid types.ID) error {\r\n\tremoteName := header.Get(\"X-Server-From\")\r\n\tremoteServer := serverVersion(header)\r\n\tremoteVs := \"\"\r\n\tif remoteServer != nil {\r\n\t\tremoteVs = remoteServer.String()\r\n\t}\r\n\tremoteMinClusterVer := minClusterVersion(header)\r\n\tremoteMinClusterVs := \"\"\r\n\tif remoteMinClusterVer != nil {\r\n\t\tremoteMinClusterVs = remoteMinClusterVer.String()\r\n\t}\r\n\tlocalServer, localMinCluster, err := checkVersionCompatibility(remoteName, remoteServer, remoteMinClusterVer)\r\n\tlocalVs := \"\"\r\n\tif localServer != nil {\r\n\t\tlocalVs = localServer.String()\r\n\t}\r\n\tlocalMinClusterVs := \"\"\r\n\tif localMinCluster != nil {\r\n\t\tlocalMinClusterVs = localMinCluster.String()\r\n\t}\r\n\tif err != nil {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\r\n\t\t\t\t\"failed to check version compatibility\",\r\n\t\t\t\tzap.String(\"local-member-id\", localID.String()),\r\n\t\t\t\tzap.String(\"local-member-cluster-id\", cid.String()),\r\n\t\t\t\tzap.String(\"local-member-server-version\", localVs),\r\n\t\t\t\tzap.String(\"local-member-server-minimum-cluster-version\", localMinClusterVs),\r\n\t\t\t\tzap.String(\"remote-peer-server-name\", remoteName),\r\n\t\t\t\tzap.String(\"remote-peer-server-version\", remoteVs),\r\n\t\t\t\tzap.String(\"remote-peer-server-minimum-cluster-version\", remoteMinClusterVs),\r\n\t\t\t\tzap.Error(err),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Errorf(\"request version incompatibility (%v)\", err)\r\n\t\t}\r\n\t\treturn errIncompatibleVersion\r\n\t}\r\n\tif gcid := header.Get(\"X-Etcd-Cluster-ID\"); gcid != cid.String() {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\r\n\t\t\t\t\"request cluster ID mismatch\",\r\n\t\t\t\tzap.String(\"local-member-id\", localID.String()),\r\n\t\t\t\tzap.String(\"local-member-cluster-id\", cid.String()),\r\n\t\t\t\tzap.String(\"local-member-server-version\", localVs),\r\n\t\t\t\tzap.String(\"local-member-server-minimum-cluster-version\", localMinClusterVs),\r\n\t\t\t\tzap.String(\"remote-peer-server-name\", remoteName),\r\n\t\t\t\tzap.String(\"remote-peer-server-version\", remoteVs),\r\n\t\t\t\tzap.String(\"remote-peer-server-minimum-cluster-version\", remoteMinClusterVs),\r\n\t\t\t\tzap.String(\"remote-peer-cluster-id\", gcid),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Errorf(\"request cluster ID mismatch (got %s want %s)\", gcid, cid)\r\n\t\t}\r\n\t\treturn errClusterIDMismatch\r\n\t}\r\n\treturn nil\r\n}","code-length":795,"reference":"\/\/ checkClusterCompatibilityFromHeader checks the cluster compatibility of\n\/\/ the local member from the given header.\n\/\/ It checks whether the version of local member is compatible with\n\/\/ the versions in the header, and whether the cluster ID of local member\n\/\/ matches the one in the header.","result":"Code too long,keep in 512.","score":[0.0,0.0114]}
{"code":"\/*is used to<extra_id_0>\r\nfunc KeyExists(key string) clientv3.Cmp {\r\n\treturn clientv3.Compare(clientv3.Version(key), \">\", 0)\r\n}","code-length":47,"reference":"\/\/ KeyExists returns a comparison operation that evaluates to true iff the given\n\/\/ key exists. It does this by checking if the key `Version` is greater than 0.\n\/\/ It is a useful guard in transaction delete operations.","result":"Check if a key exists.","score":[0.0005,0.1045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc KeyMissing(key string) clientv3.Cmp {\r\n\treturn clientv3.Compare(clientv3.Version(key), \"=\", 0)\r\n}","code-length":47,"reference":"\/\/ KeyMissing returns a comparison operation that evaluates to true iff the\n\/\/ given key does not exist.","result":"Detect missing keys.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ValidateSecureEndpoints(tlsInfo TLSInfo, eps []string) ([]string, error) {\r\n\tt, err := NewTransport(tlsInfo, 5*time.Second)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar errs []string\r\n\tvar endpoints []string\r\n\tfor _, ep := range eps {\r\n\t\tif !strings.HasPrefix(ep, \"https:\r\n\t\t\terrs = append(errs, fmt.Sprintf(\"%q is insecure\", ep))\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tconn, cerr := t.Dial(\"tcp\", ep[len(\"https:\r\n\t\tif cerr != nil {\r\n\t\t\terrs = append(errs, fmt.Sprintf(\"%q failed to dial (%v)\", ep, cerr))\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tconn.Close()\r\n\t\tendpoints = append(endpoints, ep)\r\n\t}\r\n\tif len(errs) != 0 {\r\n\t\terr = fmt.Errorf(\"%s\", strings.Join(errs, \",\"))\r\n\t}\r\n\treturn endpoints, err\r\n}","code-length":282,"reference":"\/\/ ValidateSecureEndpoints scans the given endpoints against tls info, returning only those\n\/\/ endpoints that could be validated as secure.","result":"Validate the endpoints of a secure endpoint.","score":[0.03,0.0802]}
{"code":"\/*is used to<extra_id_0>\r\nfunc putNewKV(kv v3.KV, key, val string, leaseID v3.LeaseID) (int64, error) {\r\n\tcmp := v3.Compare(v3.Version(key), \"=\", 0)\r\n\treq := v3.OpPut(key, val, v3.WithLease(leaseID))\r\n\ttxnresp, err := kv.Txn(context.TODO()).If(cmp).Then(req).Commit()\r\n\tif err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\tif !txnresp.Succeeded {\r\n\t\treturn 0, ErrKeyExists\r\n\t}\r\n\treturn txnresp.Header.Revision, nil\r\n}","code-length":171,"reference":"\/\/ putNewKV attempts to create the given key, only succeeding if the key did\n\/\/ not yet exist.","result":"Create a new KV object.","score":[0,0.0299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newUniqueEphemeralKey(s *concurrency.Session, prefix string) (*EphemeralKV, error) {\r\n\treturn newUniqueEphemeralKV(s, prefix, \"\")\r\n}","code-length":51,"reference":"\/\/ newUniqueEphemeralKey creates a new unique valueless key associated with a session lease","result":"Create a new unique ephemeral key.","score":[0.1238,0.2566]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewUpdateDirCommand() cli.Command {\r\n\treturn cli.Command{\r\n\t\tName:      \"updatedir\",\r\n\t\tUsage:     \"update an existing directory\",\r\n\t\tArgsUsage: \"<key> <value>\",\r\n\t\tFlags: []cli.Flag{\r\n\t\t\tcli.IntFlag{Name: \"ttl\", Value: 0, Usage: \"key time-to-live in seconds\"},\r\n\t\t},\r\n\t\tAction: func(c *cli.Context) error {\r\n\t\t\tupdatedirCommandFunc(c, mustNewKeyAPI(c))\r\n\t\t\treturn nil\r\n\t\t},\r\n\t}\r\n}","code-length":164,"reference":"\/\/ NewUpdateDirCommand returns the CLI command for \"updatedir\".","result":"Update the directory.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc updatedirCommandFunc(c *cli.Context, ki client.KeysAPI) {\r\n\tif len(c.Args()) == 0 {\r\n\t\thandleError(c, ExitBadArgs, errors.New(\"key required\"))\r\n\t}\r\n\tkey := c.Args()[0]\r\n\tttl := c.Int(\"ttl\")\r\n\tctx, cancel := contextWithTotalTimeout(c)\r\n\tresp, err := ki.Set(ctx, key, \"\", &client.SetOptions{TTL: time.Duration(ttl) * time.Second, Dir: true, PrevExist: client.PrevExist})\r\n\tcancel()\r\n\tif err != nil {\r\n\t\thandleError(c, ExitServerError, err)\r\n\t}\r\n\tif c.GlobalString(\"output\") != \"simple\" {\r\n\t\tprintResponseKey(resp, c.GlobalString(\"output\"))\r\n\t}\r\n}","code-length":222,"reference":"\/\/ updatedirCommandFunc executes the \"updatedir\" command.","result":"Update the directory in the etcd.","score":[0.193,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc handleBackup(c *cli.Context) error {\r\n\tvar srcWAL string\r\n\tvar destWAL string\r\n\twithV3 := c.Bool(\"with-v3\")\r\n\tsrcSnap := filepath.Join(c.String(\"data-dir\"), \"member\", \"snap\")\r\n\tdestSnap := filepath.Join(c.String(\"backup-dir\"), \"member\", \"snap\")\r\n\tif c.String(\"wal-dir\") != \"\" {\r\n\t\tsrcWAL = c.String(\"wal-dir\")\r\n\t} else {\r\n\t\tsrcWAL = filepath.Join(c.String(\"data-dir\"), \"member\", \"wal\")\r\n\t}\r\n\tif c.String(\"backup-wal-dir\") != \"\" {\r\n\t\tdestWAL = c.String(\"backup-wal-dir\")\r\n\t} else {\r\n\t\tdestWAL = filepath.Join(c.String(\"backup-dir\"), \"member\", \"wal\")\r\n\t}\r\n\tif err := fileutil.CreateDirAll(destSnap); err != nil {\r\n\t\tlog.Fatalf(\"failed creating backup snapshot dir %v: %v\", destSnap, err)\r\n\t}\r\n\twalsnap := saveSnap(destSnap, srcSnap)\r\n\tmetadata, state, ents := loadWAL(srcWAL, walsnap, withV3)\r\n\tsaveDB(filepath.Join(destSnap, \"db\"), filepath.Join(srcSnap, \"db\"), state.Commit, withV3)\r\n\tidgen := idutil.NewGenerator(0, time.Now())\r\n\tmetadata.NodeID = idgen.Next()\r\n\tmetadata.ClusterID = idgen.Next()\r\n\tneww, err := wal.Create(zap.NewExample(), destWAL, pbutil.MustMarshal(&metadata))\r\n\tif err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n\tdefer neww.Close()\r\n\tif err := neww.Save(state, ents); err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n\tif err := neww.SaveSnapshot(walsnap); err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n\treturn nil\r\n}","code-length":557,"reference":"\/\/ handleBackup handles a request that intends to do a backup.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc saveDB(destDB, srcDB string, idx uint64, v3 bool) {\r\n\t\r\n\tif v3 {\r\n\t\tvar src *bolt.DB\r\n\t\tch := make(chan *bolt.DB, 1)\r\n\t\tgo func() {\r\n\t\t\tdb, err := bolt.Open(srcDB, 0444, &bolt.Options{ReadOnly: true})\r\n\t\t\tif err != nil {\r\n\t\t\t\tlog.Fatal(err)\r\n\t\t\t}\r\n\t\t\tch <- db\r\n\t\t}()\r\n\t\tselect {\r\n\t\tcase src = <-ch:\r\n\t\tcase <-time.After(time.Second):\r\n\t\t\tlog.Println(\"waiting to acquire lock on\", srcDB)\r\n\t\t\tsrc = <-ch\r\n\t\t}\r\n\t\tdefer src.Close()\r\n\t\ttx, err := src.Begin(false)\r\n\t\tif err != nil {\r\n\t\t\tlog.Fatal(err)\r\n\t\t}\r\n\t\t\r\n\t\tdest, err := os.Create(destDB)\r\n\t\tif err != nil {\r\n\t\t\tlog.Fatal(err)\r\n\t\t}\r\n\t\tif _, err := tx.WriteTo(dest); err != nil {\r\n\t\t\tlog.Fatal(err)\r\n\t\t}\r\n\t\tdest.Close()\r\n\t\tif err := tx.Rollback(); err != nil {\r\n\t\t\tlog.Fatal(err)\r\n\t\t}\r\n\t}\r\n\tdb, err := bolt.Open(destDB, 0644, &bolt.Options{})\r\n\tif err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n\ttx, err := db.Begin(true)\r\n\tif err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n\t\r\n\tfor _, bucket := range []string{\"members\", \"members_removed\", \"cluster\"} {\r\n\t\ttx.DeleteBucket([]byte(bucket))\r\n\t}\r\n\t\r\n\tif !v3 {\r\n\t\tidxBytes := make([]byte, 8)\r\n\t\tbinary.BigEndian.PutUint64(idxBytes, idx)\r\n\t\tb, err := tx.CreateBucketIfNotExists([]byte(\"meta\"))\r\n\t\tif err != nil {\r\n\t\t\tlog.Fatal(err)\r\n\t\t}\r\n\t\tb.Put([]byte(\"consistent_index\"), idxBytes)\r\n\t}\r\n\tif err := tx.Commit(); err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n\tif err := db.Close(); err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n}","code-length":662,"reference":"\/\/ saveDB copies the v3 backend and strips cluster information.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewWatchCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"watcher\",\r\n\t\tShort: \"Performs watch operation\",\r\n\t\tRun:   runWatcherFunc,\r\n\t}\r\n\tcmd.Flags().DurationVar(&runningTime, \"running-time\", 60, \"number of seconds to run\")\r\n\tcmd.Flags().StringVar(&watchPrefix, \"prefix\", \"\", \"the prefix to append on all keys\")\r\n\tcmd.Flags().IntVar(&noOfPrefixes, \"total-prefixes\", 10, \"total no of prefixes to use\")\r\n\tcmd.Flags().IntVar(&watchPerPrefix, \"watch-per-prefix\", 10, \"number of watchers per prefix\")\r\n\tcmd.Flags().IntVar(&totalKeys, \"total-keys\", 1000, \"total number of keys to watch\")\r\n\treturn cmd\r\n}","code-length":222,"reference":"\/\/ NewWatchCommand returns the cobra command for \"watcher runner\".","result":"Create a new command .","score":[0.108,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewV3(lg *zap.Logger) Manager {\r\n\tif lg == nil {\r\n\t\tlg = zap.NewExample()\r\n\t}\r\n\treturn &v3Manager{lg: lg}\r\n}","code-length":62,"reference":"\/\/ NewV3 returns a new snapshot Manager for v3.x snapshot.","result":"Create a new V.","score":[0.1008,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *v3Manager) Save(ctx context.Context, cfg clientv3.Config, dbPath string) error {\r\n\tif len(cfg.Endpoints) != 1 {\r\n\t\treturn fmt.Errorf(\"snapshot must be requested to one selected node, not multiple %v\", cfg.Endpoints)\r\n\t}\r\n\tcli, err := clientv3.New(cfg)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer cli.Close()\r\n\tpartpath := dbPath + \".part\"\r\n\tdefer os.RemoveAll(partpath)\r\n\tvar f *os.File\r\n\tf, err = os.OpenFile(partpath, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, fileutil.PrivateFileMode)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"could not open %s (%v)\", partpath, err)\r\n\t}\r\n\ts.lg.Info(\r\n\t\t\"created temporary db file\",\r\n\t\tzap.String(\"path\", partpath),\r\n\t)\r\n\tnow := time.Now()\r\n\tvar rd io.ReadCloser\r\n\trd, err = cli.Snapshot(ctx)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ts.lg.Info(\r\n\t\t\"fetching snapshot\",\r\n\t\tzap.String(\"endpoint\", cfg.Endpoints[0]),\r\n\t)\r\n\tif _, err = io.Copy(f, rd); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err = fileutil.Fsync(f); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err = f.Close(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\ts.lg.Info(\r\n\t\t\"fetched snapshot\",\r\n\t\tzap.String(\"endpoint\", cfg.Endpoints[0]),\r\n\t\tzap.Duration(\"took\", time.Since(now)),\r\n\t)\r\n\tif err = os.Rename(partpath, dbPath); err != nil {\r\n\t\treturn fmt.Errorf(\"could not rename %s to %s (%v)\", partpath, dbPath, err)\r\n\t}\r\n\ts.lg.Info(\"saved\", zap.String(\"path\", dbPath))\r\n\treturn nil\r\n}","code-length":580,"reference":"\/\/ Save fetches snapshot from remote etcd server and saves data to target path.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *v3Manager) Status(dbPath string) (ds Status, err error) {\r\n\tif _, err = os.Stat(dbPath); err != nil {\r\n\t\treturn ds, err\r\n\t}\r\n\tdb, err := bolt.Open(dbPath, 0400, &bolt.Options{ReadOnly: true})\r\n\tif err != nil {\r\n\t\treturn ds, err\r\n\t}\r\n\tdefer db.Close()\r\n\th := crc32.New(crc32.MakeTable(crc32.Castagnoli))\r\n\tif err = db.View(func(tx *bolt.Tx) error {\r\n\t\t\r\n\t\tvar dbErrStrings []string\r\n\t\tfor dbErr := range tx.Check() {\r\n\t\t\tdbErrStrings = append(dbErrStrings, dbErr.Error())\r\n\t\t}\r\n\t\tif len(dbErrStrings) > 0 {\r\n\t\t\treturn fmt.Errorf(\"snapshot file integrity check failed. %d errors found.\\n\"+strings.Join(dbErrStrings, \"\\n\"), len(dbErrStrings))\r\n\t\t}\r\n\t\tds.TotalSize = tx.Size()\r\n\t\tc := tx.Cursor()\r\n\t\tfor next, _ := c.First(); next != nil; next, _ = c.Next() {\r\n\t\t\tb := tx.Bucket(next)\r\n\t\t\tif b == nil {\r\n\t\t\t\treturn fmt.Errorf(\"cannot get hash of bucket %s\", string(next))\r\n\t\t\t}\r\n\t\t\th.Write(next)\r\n\t\t\tiskeyb := (string(next) == \"key\")\r\n\t\t\tb.ForEach(func(k, v []byte) error {\r\n\t\t\t\th.Write(k)\r\n\t\t\t\th.Write(v)\r\n\t\t\t\tif iskeyb {\r\n\t\t\t\t\trev := bytesToRev(k)\r\n\t\t\t\t\tds.Revision = rev.main\r\n\t\t\t\t}\r\n\t\t\t\tds.TotalKey++\r\n\t\t\t\treturn nil\r\n\t\t\t})\r\n\t\t}\r\n\t\treturn nil\r\n\t}); err != nil {\r\n\t\treturn ds, err\r\n\t}\r\n\tds.Hash = h.Sum32()\r\n\treturn ds, nil\r\n}","code-length":546,"reference":"\/\/ Status returns the snapshot file information.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *v3Manager) Restore(cfg RestoreConfig) error {\r\n\tpURLs, err := types.NewURLs(cfg.PeerURLs)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tvar ics types.URLsMap\r\n\tics, err = types.NewURLsMap(cfg.InitialCluster)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tsrv := etcdserver.ServerConfig{\r\n\t\tLogger:              s.lg,\r\n\t\tName:                cfg.Name,\r\n\t\tPeerURLs:            pURLs,\r\n\t\tInitialPeerURLsMap:  ics,\r\n\t\tInitialClusterToken: cfg.InitialClusterToken,\r\n\t}\r\n\tif err = srv.VerifyBootstrap(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\ts.cl, err = membership.NewClusterFromURLsMap(s.lg, cfg.InitialClusterToken, ics)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdataDir := cfg.OutputDataDir\r\n\tif dataDir == \"\" {\r\n\t\tdataDir = cfg.Name + \".etcd\"\r\n\t}\r\n\tif fileutil.Exist(dataDir) {\r\n\t\treturn fmt.Errorf(\"data-dir %q exists\", dataDir)\r\n\t}\r\n\twalDir := cfg.OutputWALDir\r\n\tif walDir == \"\" {\r\n\t\twalDir = filepath.Join(dataDir, \"member\", \"wal\")\r\n\t} else if fileutil.Exist(walDir) {\r\n\t\treturn fmt.Errorf(\"wal-dir %q exists\", walDir)\r\n\t}\r\n\ts.name = cfg.Name\r\n\ts.dbPath = cfg.SnapshotPath\r\n\ts.walDir = walDir\r\n\ts.snapDir = filepath.Join(dataDir, \"member\", \"snap\")\r\n\ts.skipHashCheck = cfg.SkipHashCheck\r\n\ts.lg.Info(\r\n\t\t\"restoring snapshot\",\r\n\t\tzap.String(\"path\", s.dbPath),\r\n\t\tzap.String(\"wal-dir\", s.walDir),\r\n\t\tzap.String(\"data-dir\", dataDir),\r\n\t\tzap.String(\"snap-dir\", s.snapDir),\r\n\t)\r\n\tif err = s.saveDB(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err = s.saveWALAndSnap(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\ts.lg.Info(\r\n\t\t\"restored snapshot\",\r\n\t\tzap.String(\"path\", s.dbPath),\r\n\t\tzap.String(\"wal-dir\", s.walDir),\r\n\t\tzap.String(\"data-dir\", dataDir),\r\n\t\tzap.String(\"snap-dir\", s.snapDir),\r\n\t)\r\n\treturn nil\r\n}","code-length":723,"reference":"\/\/ Restore restores a new etcd data directory from given snapshot file.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewAuthStore(lg *zap.Logger, be backend.Backend, tp TokenProvider, bcryptCost int) *authStore {\r\n\tif bcryptCost < bcrypt.MinCost || bcryptCost > bcrypt.MaxCost {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\r\n\t\t\t\t\"use default bcrypt cost instead of the invalid given cost\",\r\n\t\t\t\tzap.Int(\"min-cost\", bcrypt.MinCost),\r\n\t\t\t\tzap.Int(\"max-cost\", bcrypt.MaxCost),\r\n\t\t\t\tzap.Int(\"default-cost\", bcrypt.DefaultCost),\r\n\t\t\t\tzap.Int(\"given-cost\", bcryptCost))\r\n\t\t} else {\r\n\t\t\tplog.Warningf(\"Use default bcrypt-cost %d instead of the invalid value %d\",\r\n\t\t\t\tbcrypt.DefaultCost, bcryptCost)\r\n\t\t}\r\n\t\tbcryptCost = bcrypt.DefaultCost\r\n\t}\r\n\ttx := be.BatchTx()\r\n\ttx.Lock()\r\n\ttx.UnsafeCreateBucket(authBucketName)\r\n\ttx.UnsafeCreateBucket(authUsersBucketName)\r\n\ttx.UnsafeCreateBucket(authRolesBucketName)\r\n\tenabled := false\r\n\t_, vs := tx.UnsafeRange(authBucketName, enableFlagKey, nil, 0)\r\n\tif len(vs) == 1 {\r\n\t\tif bytes.Equal(vs[0], authEnabled) {\r\n\t\t\tenabled = true\r\n\t\t}\r\n\t}\r\n\tas := &authStore{\r\n\t\trevision:       getRevision(tx),\r\n\t\tlg:             lg,\r\n\t\tbe:             be,\r\n\t\tenabled:        enabled,\r\n\t\trangePermCache: make(map[string]*unifiedRangePermissions),\r\n\t\ttokenProvider:  tp,\r\n\t\tbcryptCost:     bcryptCost,\r\n\t}\r\n\tif enabled {\r\n\t\tas.tokenProvider.enable()\r\n\t}\r\n\tif as.Revision() == 0 {\r\n\t\tas.commitRevision(tx)\r\n\t}\r\n\ttx.Unlock()\r\n\tbe.ForceCommit()\r\n\treturn as\r\n}","code-length":531,"reference":"\/\/ NewAuthStore creates a new AuthStore.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTokenProvider(\r\n\tlg *zap.Logger,\r\n\ttokenOpts string,\r\n\tindexWaiter func(uint64) <-chan struct{}) (TokenProvider, error) {\r\n\ttokenType, typeSpecificOpts, err := decomposeOpts(lg, tokenOpts)\r\n\tif err != nil {\r\n\t\treturn nil, ErrInvalidAuthOpts\r\n\t}\r\n\tswitch tokenType {\r\n\tcase tokenTypeSimple:\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\"simple token is not cryptographically signed\")\r\n\t\t} else {\r\n\t\t\tplog.Warningf(\"simple token is not cryptographically signed\")\r\n\t\t}\r\n\t\treturn newTokenProviderSimple(lg, indexWaiter), nil\r\n\tcase tokenTypeJWT:\r\n\t\treturn newTokenProviderJWT(lg, typeSpecificOpts)\r\n\tcase \"\":\r\n\t\treturn newTokenProviderNop()\r\n\tdefault:\r\n\t\tif lg != nil {\r\n\t\t\tlg.Warn(\r\n\t\t\t\t\"unknown token type\",\r\n\t\t\t\tzap.String(\"type\", tokenType),\r\n\t\t\t\tzap.Error(ErrInvalidAuthOpts),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Errorf(\"unknown token type: %s\", tokenType)\r\n\t\t}\r\n\t\treturn nil, ErrInvalidAuthOpts\r\n\t}\r\n}","code-length":333,"reference":"\/\/ NewTokenProvider creates a new token provider.","result":"Create a token provider.","score":[0.2362,0.5597]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Transport) MendPeer(id types.ID) {\r\n\tt.mu.RLock()\r\n\tp, pok := t.peers[id]\r\n\tg, gok := t.remotes[id]\r\n\tt.mu.RUnlock()\r\n\tif pok {\r\n\t\tp.(Pausable).Resume()\r\n\t}\r\n\tif gok {\r\n\t\tg.Resume()\r\n\t}\r\n}","code-length":119,"reference":"\/\/ MendPeer recovers the message dropping behavior of the given peer.","result":"Mend peers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Transport) removePeer(id types.ID) {\r\n\tif peer, ok := t.peers[id]; ok {\r\n\t\tpeer.stop()\r\n\t} else {\r\n\t\tif t.Logger != nil {\r\n\t\t\tt.Logger.Panic(\"unexpected removal of unknown remote peer\", zap.String(\"remote-peer-id\", id.String()))\r\n\t\t} else {\r\n\t\t\tplog.Panicf(\"unexpected removal of unknown peer '%d'\", id)\r\n\t\t}\r\n\t}\r\n\tdelete(t.peers, id)\r\n\tdelete(t.LeaderStats.Followers, id.String())\r\n\tt.pipelineProber.Remove(id.String())\r\n\tt.streamProber.Remove(id.String())\r\n\tif t.Logger != nil {\r\n\t\tt.Logger.Info(\r\n\t\t\t\"removed remote peer\",\r\n\t\t\tzap.String(\"local-member-id\", t.ID.String()),\r\n\t\t\tzap.String(\"removed-remote-peer-id\", id.String()),\r\n\t\t)\r\n\t} else {\r\n\t\tplog.Infof(\"removed peer %s\", id)\r\n\t}\r\n}","code-length":300,"reference":"\/\/ the caller of this function must have the peers mutex.","result":"Remove peer from transport.","score":[0,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Transport) ActivePeers() (cnt int) {\r\n\tt.mu.RLock()\r\n\tdefer t.mu.RUnlock()\r\n\tfor _, p := range t.peers {\r\n\t\tif !p.activeSince().IsZero() {\r\n\t\t\tcnt++\r\n\t\t}\r\n\t}\r\n\treturn cnt\r\n}","code-length":95,"reference":"\/\/ ActivePeers returns a channel that closes when an initial\n\/\/ peer connection has been established. Use this to wait until the\n\/\/ first peer connection becomes active.","result":"Get the number of active peers.","score":[0.0049,0.0194]}
{"code":"\/*is used to<extra_id_0>\r\nfunc resolveTCPAddrDefault(ctx context.Context, addr string) (*net.TCPAddr, error) {\r\n\thost, port, serr := net.SplitHostPort(addr)\r\n\tif serr != nil {\r\n\t\treturn nil, serr\r\n\t}\r\n\tportnum, perr := net.DefaultResolver.LookupPort(ctx, \"tcp\", port)\r\n\tif perr != nil {\r\n\t\treturn nil, perr\r\n\t}\r\n\tvar ips []net.IPAddr\r\n\tif ip := net.ParseIP(host); ip != nil {\r\n\t\tips = []net.IPAddr{{IP: ip}}\r\n\t} else {\r\n\t\t\r\n\t\tipss, err := net.DefaultResolver.LookupIPAddr(ctx, host)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tips = ipss\r\n\t}\r\n\t\r\n\tip := ips[0]\r\n\treturn &net.TCPAddr{IP: ip.IP, Port: portnum, Zone: ip.Zone}, nil\r\n}","code-length":269,"reference":"\/\/ taken from go's ResolveTCP code but uses configurable ctx","result":"Resolve a default address.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc resolveTCPAddrs(ctx context.Context, lg *zap.Logger, urls [][]url.URL) ([][]url.URL, error) {\r\n\tnewurls := make([][]url.URL, 0)\r\n\tfor _, us := range urls {\r\n\t\tnus := make([]url.URL, len(us))\r\n\t\tfor i, u := range us {\r\n\t\t\tnu, err := url.Parse(u.String())\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, fmt.Errorf(\"failed to parse %q (%v)\", u.String(), err)\r\n\t\t\t}\r\n\t\t\tnus[i] = *nu\r\n\t\t}\r\n\t\tfor i, u := range nus {\r\n\t\t\th, err := resolveURL(ctx, lg, u)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, fmt.Errorf(\"failed to resolve %q (%v)\", u.String(), err)\r\n\t\t\t}\r\n\t\t\tif h != \"\" {\r\n\t\t\t\tnus[i].Host = h\r\n\t\t\t}\r\n\t\t}\r\n\t\tnewurls = append(newurls, nus)\r\n\t}\r\n\treturn newurls, nil\r\n}","code-length":304,"reference":"\/\/ resolveTCPAddrs is a convenience wrapper for net.ResolveTCPAddr.\n\/\/ resolveTCPAddrs return a new set of url.URLs, in which all DNS hostnames\n\/\/ are resolved.","result":"Resolve the address of a given URL.","score":[0.0169,0.0673]}
{"code":"\/*is used to<extra_id_0>\r\nfunc urlsEqual(ctx context.Context, lg *zap.Logger, a []url.URL, b []url.URL) (bool, error) {\r\n\tif len(a) != len(b) {\r\n\t\treturn false, fmt.Errorf(\"len(%q) != len(%q)\", urlsToStrings(a), urlsToStrings(b))\r\n\t}\r\n\turls, err := resolveTCPAddrs(ctx, lg, [][]url.URL{a, b})\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\tpreva, prevb := a, b\r\n\ta, b = urls[0], urls[1]\r\n\tsort.Sort(types.URLs(a))\r\n\tsort.Sort(types.URLs(b))\r\n\tfor i := range a {\r\n\t\tif !reflect.DeepEqual(a[i], b[i]) {\r\n\t\t\treturn false, fmt.Errorf(\"%q(resolved from %q) != %q(resolved from %q)\",\r\n\t\t\t\ta[i].String(), preva[i].String(),\r\n\t\t\t\tb[i].String(), prevb[i].String(),\r\n\t\t\t)\r\n\t\t}\r\n\t}\r\n\treturn true, nil\r\n}","code-length":308,"reference":"\/\/ urlsEqual checks equality of url.URLS between two arrays.\n\/\/ This check pass even if an URL is in hostname and opposite is in IP address.","result":"Compare urls in the same order as the urls in the list.","score":[0.033,0.061]}
{"code":"\/*is used to<extra_id_0>\r\nfunc URLStringsEqual(ctx context.Context, lg *zap.Logger, a []string, b []string) (bool, error) {\r\n\tif len(a) != len(b) {\r\n\t\treturn false, fmt.Errorf(\"len(%q) != len(%q)\", a, b)\r\n\t}\r\n\turlsA := make([]url.URL, 0)\r\n\tfor _, str := range a {\r\n\t\tu, err := url.Parse(str)\r\n\t\tif err != nil {\r\n\t\t\treturn false, fmt.Errorf(\"failed to parse %q\", str)\r\n\t\t}\r\n\t\turlsA = append(urlsA, *u)\r\n\t}\r\n\turlsB := make([]url.URL, 0)\r\n\tfor _, str := range b {\r\n\t\tu, err := url.Parse(str)\r\n\t\tif err != nil {\r\n\t\t\treturn false, fmt.Errorf(\"failed to parse %q\", str)\r\n\t\t}\r\n\t\turlsB = append(urlsB, *u)\r\n\t}\r\n\tif lg == nil {\r\n\t\tlg, _ = zap.NewProduction()\r\n\t\tif lg == nil {\r\n\t\t\tlg = zap.NewExample()\r\n\t\t}\r\n\t}\r\n\treturn urlsEqual(ctx, lg, urlsA, urlsB)\r\n}","code-length":337,"reference":"\/\/ URLStringsEqual returns \"true\" if given URLs are valid\n\/\/ and resolved to same IP addresses. Otherwise, return \"false\"\n\/\/ and error, if any.","result":"Compare URLs in a string array.","score":[0.0096,0.0225]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLeaseCommand() *cobra.Command {\r\n\tlc := &cobra.Command{\r\n\t\tUse:   \"lease <subcommand>\",\r\n\t\tShort: \"Lease related commands\",\r\n\t}\r\n\tlc.AddCommand(NewLeaseGrantCommand())\r\n\tlc.AddCommand(NewLeaseRevokeCommand())\r\n\tlc.AddCommand(NewLeaseTimeToLiveCommand())\r\n\tlc.AddCommand(NewLeaseListCommand())\r\n\tlc.AddCommand(NewLeaseKeepAliveCommand())\r\n\treturn lc\r\n}","code-length":136,"reference":"\/\/ NewLeaseCommand returns the cobra command for \"lease\".","result":"Create a new lease.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLeaseGrantCommand() *cobra.Command {\r\n\tlc := &cobra.Command{\r\n\t\tUse:   \"grant <ttl>\",\r\n\t\tShort: \"Creates leases\",\r\n\t\tRun: leaseGrantCommandFunc,\r\n\t}\r\n\treturn lc\r\n}","code-length":81,"reference":"\/\/ NewLeaseGrantCommand returns the cobra command for \"lease grant\".","result":"Create leases.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc leaseGrantCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"lease grant command needs TTL argument\"))\r\n\t}\r\n\tttl, err := strconv.ParseInt(args[0], 10, 64)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"bad TTL (%v)\", err))\r\n\t}\r\n\tctx, cancel := commandCtx(cmd)\r\n\tresp, err := mustClientFromCmd(cmd).Grant(ctx, ttl)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, fmt.Errorf(\"failed to grant lease (%v)\", err))\r\n\t}\r\n\tdisplay.Grant(*resp)\r\n}","code-length":206,"reference":"\/\/ leaseGrantCommandFunc executes the \"lease grant\" command.","result":"Generate the code.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLeaseRevokeCommand() *cobra.Command {\r\n\tlc := &cobra.Command{\r\n\t\tUse:   \"revoke <leaseID>\",\r\n\t\tShort: \"Revokes leases\",\r\n\t\tRun: leaseRevokeCommandFunc,\r\n\t}\r\n\treturn lc\r\n}","code-length":85,"reference":"\/\/ NewLeaseRevokeCommand returns the cobra command for \"lease revoke\".","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc leaseRevokeCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"lease revoke command needs 1 argument\"))\r\n\t}\r\n\tid := leaseFromArgs(args[0])\r\n\tctx, cancel := commandCtx(cmd)\r\n\tresp, err := mustClientFromCmd(cmd).Revoke(ctx, id)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, fmt.Errorf(\"failed to revoke lease (%v)\", err))\r\n\t}\r\n\tdisplay.Revoke(id, *resp)\r\n}","code-length":167,"reference":"\/\/ leaseRevokeCommandFunc executes the \"lease grant\" command.","result":"Generate the code.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLeaseTimeToLiveCommand() *cobra.Command {\r\n\tlc := &cobra.Command{\r\n\t\tUse:   \"timetolive <leaseID> [options]\",\r\n\t\tShort: \"Get lease information\",\r\n\t\tRun: leaseTimeToLiveCommandFunc,\r\n\t}\r\n\tlc.Flags().BoolVar(&timeToLiveKeys, \"keys\", false, \"Get keys attached to this lease\")\r\n\treturn lc\r\n}","code-length":118,"reference":"\/\/ NewLeaseTimeToLiveCommand returns the cobra command for \"lease timetolive\".","result":"Generate the code.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc leaseTimeToLiveCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"lease timetolive command needs lease ID as argument\"))\r\n\t}\r\n\tvar opts []v3.LeaseOption\r\n\tif timeToLiveKeys {\r\n\t\topts = append(opts, v3.WithAttachedKeys())\r\n\t}\r\n\tresp, rerr := mustClientFromCmd(cmd).TimeToLive(context.TODO(), leaseFromArgs(args[0]), opts...)\r\n\tif rerr != nil {\r\n\t\tExitWithError(ExitBadConnection, rerr)\r\n\t}\r\n\tdisplay.TimeToLive(*resp, timeToLiveKeys)\r\n}","code-length":188,"reference":"\/\/ leaseTimeToLiveCommandFunc executes the \"lease timetolive\" command.","result":"Generate the code.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLeaseListCommand() *cobra.Command {\r\n\tlc := &cobra.Command{\r\n\t\tUse:   \"list\",\r\n\t\tShort: \"List all active leases\",\r\n\t\tRun:   leaseListCommandFunc,\r\n\t}\r\n\treturn lc\r\n}","code-length":81,"reference":"\/\/ NewLeaseListCommand returns the cobra command for \"lease list\".","result":"Create a new command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc leaseListCommandFunc(cmd *cobra.Command, args []string) {\r\n\tresp, rerr := mustClientFromCmd(cmd).Leases(context.TODO())\r\n\tif rerr != nil {\r\n\t\tExitWithError(ExitBadConnection, rerr)\r\n\t}\r\n\tdisplay.Leases(*resp)\r\n}","code-length":90,"reference":"\/\/ leaseListCommandFunc executes the \"lease list\" command.","result":"List leases.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLeaseKeepAliveCommand() *cobra.Command {\r\n\tlc := &cobra.Command{\r\n\t\tUse:   \"keep-alive [options] <leaseID>\",\r\n\t\tShort: \"Keeps leases alive (renew)\",\r\n\t\tRun: leaseKeepAliveCommandFunc,\r\n\t}\r\n\tlc.Flags().BoolVar(&leaseKeepAliveOnce, \"once\", false, \"Resets the keep-alive time to its original value and exits immediately\")\r\n\treturn lc\r\n}","code-length":128,"reference":"\/\/ NewLeaseKeepAliveCommand returns the cobra command for \"lease keep-alive\".","result":"Generate the code.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc leaseKeepAliveCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"lease keep-alive command needs lease ID as argument\"))\r\n\t}\r\n\tid := leaseFromArgs(args[0])\r\n\tif leaseKeepAliveOnce {\r\n\t\trespc, kerr := mustClientFromCmd(cmd).KeepAliveOnce(context.TODO(), id)\r\n\t\tif kerr != nil {\r\n\t\t\tExitWithError(ExitBadConnection, kerr)\r\n\t\t}\r\n\t\tdisplay.KeepAlive(*respc)\r\n\t\treturn\r\n\t}\r\n\trespc, kerr := mustClientFromCmd(cmd).KeepAlive(context.TODO(), id)\r\n\tif kerr != nil {\r\n\t\tExitWithError(ExitBadConnection, kerr)\r\n\t}\r\n\tfor resp := range respc {\r\n\t\tdisplay.KeepAlive(*resp)\r\n\t}\r\n\tif _, ok := (display).(*simplePrinter); ok {\r\n\t\tfmt.Printf(\"lease %016x expired or revoked.\\n\", id)\r\n\t}\r\n}","code-length":285,"reference":"\/\/ leaseKeepAliveCommandFunc executes the \"lease keep-alive\" command.","result":"Run the command .","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewAlarmCommand() *cobra.Command {\r\n\tac := &cobra.Command{\r\n\t\tUse:   \"alarm <subcommand>\",\r\n\t\tShort: \"Alarm related commands\",\r\n\t}\r\n\tac.AddCommand(NewAlarmDisarmCommand())\r\n\tac.AddCommand(NewAlarmListCommand())\r\n\treturn ac\r\n}","code-length":97,"reference":"\/\/ NewAlarmCommand returns the cobra command for \"alarm\".","result":"Create a command to manage the alarm.","score":[0.1665,0.1266]}
{"code":"\/*is used to<extra_id_0>\r\nfunc alarmDisarmCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 0 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"alarm disarm command accepts no arguments\"))\r\n\t}\r\n\tctx, cancel := commandCtx(cmd)\r\n\tresp, err := mustClientFromCmd(cmd).AlarmDisarm(ctx, &v3.AlarmMember{})\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.Alarm(*resp)\r\n}","code-length":149,"reference":"\/\/ alarmDisarmCommandFunc executes the \"alarm disarm\" command.","result":"Generate the code.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc alarmListCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 0 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"alarm list command accepts no arguments\"))\r\n\t}\r\n\tctx, cancel := commandCtx(cmd)\r\n\tresp, err := mustClientFromCmd(cmd).AlarmList(ctx)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.Alarm(*resp)\r\n}","code-length":138,"reference":"\/\/ alarmListCommandFunc executes the \"alarm list\" command.","result":"List all the alarm.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Etcd) Flags() (fs []string) {\r\n\ttp := reflect.TypeOf(*e)\r\n\tvo := reflect.ValueOf(*e)\r\n\tfor _, name := range etcdFields {\r\n\t\tfield, ok := tp.FieldByName(name)\r\n\t\tif !ok {\r\n\t\t\tpanic(fmt.Errorf(\"field %q not found\", name))\r\n\t\t}\r\n\t\tfv := reflect.Indirect(vo).FieldByName(name)\r\n\t\tvar sv string\r\n\t\tswitch fv.Type().Kind() {\r\n\t\tcase reflect.String:\r\n\t\t\tsv = fv.String()\r\n\t\tcase reflect.Slice:\r\n\t\t\tn := fv.Len()\r\n\t\t\tsl := make([]string, n)\r\n\t\t\tfor i := 0; i < n; i++ {\r\n\t\t\t\tsl[i] = fv.Index(i).String()\r\n\t\t\t}\r\n\t\t\tsv = strings.Join(sl, \",\")\r\n\t\tcase reflect.Int64:\r\n\t\t\tsv = fmt.Sprintf(\"%d\", fv.Int())\r\n\t\tcase reflect.Bool:\r\n\t\t\tsv = fmt.Sprintf(\"%v\", fv.Bool())\r\n\t\tdefault:\r\n\t\t\tpanic(fmt.Errorf(\"field %q (%v) cannot be parsed\", name, fv.Type().Kind()))\r\n\t\t}\r\n\t\tfname := field.Tag.Get(\"yaml\")\r\n\t\t\r\n\t\tif fname == \"initial-corrupt-check\" {\r\n\t\t\tfname = \"experimental-\" + fname\r\n\t\t}\r\n\t\tif sv != \"\" {\r\n\t\t\tfs = append(fs, fmt.Sprintf(\"--%s=%s\", fname, sv))\r\n\t\t}\r\n\t}\r\n\treturn fs\r\n}","code-length":440,"reference":"\/\/ Flags returns etcd flags in string slice.","result":"Parse etcd flags.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Etcd) EmbedConfig() (cfg *embed.Config, err error) {\r\n\tvar lcURLs types.URLs\r\n\tlcURLs, err = types.NewURLs(e.ListenClientURLs)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar acURLs types.URLs\r\n\tacURLs, err = types.NewURLs(e.AdvertiseClientURLs)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar lpURLs types.URLs\r\n\tlpURLs, err = types.NewURLs(e.ListenPeerURLs)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar apURLs types.URLs\r\n\tapURLs, err = types.NewURLs(e.AdvertisePeerURLs)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tcfg = embed.NewConfig()\r\n\tcfg.Name = e.Name\r\n\tcfg.Dir = e.DataDir\r\n\tcfg.WalDir = e.WALDir\r\n\tcfg.TickMs = uint(e.HeartbeatIntervalMs)\r\n\tcfg.ElectionMs = uint(e.ElectionTimeoutMs)\r\n\tcfg.LCUrls = lcURLs\r\n\tcfg.ACUrls = acURLs\r\n\tcfg.ClientAutoTLS = e.ClientAutoTLS\r\n\tcfg.ClientTLSInfo = transport.TLSInfo{\r\n\t\tClientCertAuth: e.ClientCertAuth,\r\n\t\tCertFile:       e.ClientCertFile,\r\n\t\tKeyFile:        e.ClientKeyFile,\r\n\t\tTrustedCAFile:  e.ClientTrustedCAFile,\r\n\t}\r\n\tcfg.LPUrls = lpURLs\r\n\tcfg.APUrls = apURLs\r\n\tcfg.PeerAutoTLS = e.PeerAutoTLS\r\n\tcfg.PeerTLSInfo = transport.TLSInfo{\r\n\t\tClientCertAuth: e.PeerClientCertAuth,\r\n\t\tCertFile:       e.PeerCertFile,\r\n\t\tKeyFile:        e.PeerKeyFile,\r\n\t\tTrustedCAFile:  e.PeerTrustedCAFile,\r\n\t}\r\n\tcfg.InitialCluster = e.InitialCluster\r\n\tcfg.ClusterState = e.InitialClusterState\r\n\tcfg.InitialClusterToken = e.InitialClusterToken\r\n\tcfg.SnapshotCount = uint64(e.SnapshotCount)\r\n\tcfg.QuotaBackendBytes = e.QuotaBackendBytes\r\n\tcfg.PreVote = e.PreVote\r\n\tcfg.ExperimentalInitialCorruptCheck = e.InitialCorruptCheck\r\n\tcfg.Logger = e.Logger\r\n\tcfg.LogOutputs = e.LogOutputs\r\n\tcfg.Debug = e.Debug\r\n\treturn cfg, nil\r\n}","code-length":656,"reference":"\/\/ EmbedConfig returns etcd embed.Config.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PProfHandlers() map[string]http.Handler {\r\n\t\r\n\tif runtime.SetMutexProfileFraction(-1) == 0 {\r\n\t\t\r\n\t\truntime.SetMutexProfileFraction(5)\r\n\t}\r\n\tm := make(map[string]http.Handler)\r\n\tm[HTTPPrefixPProf+\"\/\"] = http.HandlerFunc(pprof.Index)\r\n\tm[HTTPPrefixPProf+\"\/profile\"] = http.HandlerFunc(pprof.Profile)\r\n\tm[HTTPPrefixPProf+\"\/symbol\"] = http.HandlerFunc(pprof.Symbol)\r\n\tm[HTTPPrefixPProf+\"\/cmdline\"] = http.HandlerFunc(pprof.Cmdline)\r\n\tm[HTTPPrefixPProf+\"\/trace \"] = http.HandlerFunc(pprof.Trace)\r\n\tm[HTTPPrefixPProf+\"\/heap\"] = pprof.Handler(\"heap\")\r\n\tm[HTTPPrefixPProf+\"\/goroutine\"] = pprof.Handler(\"goroutine\")\r\n\tm[HTTPPrefixPProf+\"\/threadcreate\"] = pprof.Handler(\"threadcreate\")\r\n\tm[HTTPPrefixPProf+\"\/block\"] = pprof.Handler(\"block\")\r\n\tm[HTTPPrefixPProf+\"\/mutex\"] = pprof.Handler(\"mutex\")\r\n\treturn m\r\n}","code-length":314,"reference":"\/\/ PProfHandlers returns a map of pprof handlers keyed by the HTTP path.","result":"Generate the handlers for the PProf.","score":[0.0715,0.0813]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewBackendQuota(s *EtcdServer, name string) Quota {\r\n\tlg := s.getLogger()\r\n\tquotaBackendBytes.Set(float64(s.Cfg.QuotaBackendBytes))\r\n\tif s.Cfg.QuotaBackendBytes < 0 {\r\n\t\t\r\n\t\tquotaLogOnce.Do(func() {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Info(\r\n\t\t\t\t\t\"disabled backend quota\",\r\n\t\t\t\t\tzap.String(\"quota-name\", name),\r\n\t\t\t\t\tzap.Int64(\"quota-size-bytes\", s.Cfg.QuotaBackendBytes),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Warningf(\"disabling backend quota\")\r\n\t\t\t}\r\n\t\t})\r\n\t\treturn &passthroughQuota{}\r\n\t}\r\n\tif s.Cfg.QuotaBackendBytes == 0 {\r\n\t\t\r\n\t\tquotaLogOnce.Do(func() {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Info(\r\n\t\t\t\t\t\"enabled backend quota with default value\",\r\n\t\t\t\t\tzap.String(\"quota-name\", name),\r\n\t\t\t\t\tzap.Int64(\"quota-size-bytes\", DefaultQuotaBytes),\r\n\t\t\t\t\tzap.String(\"quota-size\", DefaultQuotaSize),\r\n\t\t\t\t)\r\n\t\t\t}\r\n\t\t})\r\n\t\tquotaBackendBytes.Set(float64(DefaultQuotaBytes))\r\n\t\treturn &backendQuota{s, DefaultQuotaBytes}\r\n\t}\r\n\tquotaLogOnce.Do(func() {\r\n\t\tif s.Cfg.QuotaBackendBytes > MaxQuotaBytes {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"quota exceeds the maximum value\",\r\n\t\t\t\t\tzap.String(\"quota-name\", name),\r\n\t\t\t\t\tzap.Int64(\"quota-size-bytes\", s.Cfg.QuotaBackendBytes),\r\n\t\t\t\t\tzap.String(\"quota-size\", humanize.Bytes(uint64(s.Cfg.QuotaBackendBytes))),\r\n\t\t\t\t\tzap.Int64(\"quota-maximum-size-bytes\", MaxQuotaBytes),\r\n\t\t\t\t\tzap.String(\"quota-maximum-size\", maxQuotaSize),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Warningf(\"backend quota %v exceeds maximum recommended quota %v\", s.Cfg.QuotaBackendBytes, MaxQuotaBytes)\r\n\t\t\t}\r\n\t\t}\r\n\t\tif lg != nil {\r\n\t\t\tlg.Info(\r\n\t\t\t\t\"enabled backend quota\",\r\n\t\t\t\tzap.String(\"quota-name\", name),\r\n\t\t\t\tzap.Int64(\"quota-size-bytes\", s.Cfg.QuotaBackendBytes),\r\n\t\t\t\tzap.String(\"quota-size\", humanize.Bytes(uint64(s.Cfg.QuotaBackendBytes))),\r\n\t\t\t)\r\n\t\t}\r\n\t})\r\n\treturn &backendQuota{s, s.Cfg.QuotaBackendBytes}\r\n}","code-length":714,"reference":"\/\/ NewBackendQuota creates a quota layer with the given storage limit.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClusterProxy(c *clientv3.Client, advaddr string, prefix string) (pb.ClusterServer, <-chan struct{}) {\r\n\tcp := &clusterProxy{\r\n\t\tclus: c.Cluster,\r\n\t\tctx:  c.Ctx(),\r\n\t\tgr:   &naming.GRPCResolver{Client: c},\r\n\t\tadvaddr: advaddr,\r\n\t\tprefix:  prefix,\r\n\t\tumap:    make(map[string]gnaming.Update),\r\n\t}\r\n\tdonec := make(chan struct{})\r\n\tif advaddr != \"\" && prefix != \"\" {\r\n\t\tgo func() {\r\n\t\t\tdefer close(donec)\r\n\t\t\tcp.resolve(prefix)\r\n\t\t}()\r\n\t\treturn cp, donec\r\n\t}\r\n\tclose(donec)\r\n\treturn cp, donec\r\n}","code-length":223,"reference":"\/\/ NewClusterProxy takes optional prefix to fetch grpc-proxy member endpoints.\n\/\/ The returned channel is closed when there is grpc-proxy endpoint registered\n\/\/ and the client's context is canceled so the 'register' loop returns.","result":"Create a proxy for the cluster.","score":[0.0018,0.016]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewHandler(l lease.Lessor, waitch func() <-chan struct{}) http.Handler {\r\n\treturn &leaseHandler{l, waitch}\r\n}","code-length":48,"reference":"\/\/ NewHandler returns an http Handler for lease renewals","result":"Create a new handler.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc TimeToLiveHTTP(ctx context.Context, id lease.LeaseID, keys bool, url string, rt http.RoundTripper) (*leasepb.LeaseInternalResponse, error) {\r\n\t\r\n\tlreq, err := (&leasepb.LeaseInternalRequest{\r\n\t\tLeaseTimeToLiveRequest: &pb.LeaseTimeToLiveRequest{\r\n\t\t\tID:   int64(id),\r\n\t\t\tKeys: keys,\r\n\t\t},\r\n\t}).Marshal()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treq, err := http.NewRequest(\"POST\", url, bytes.NewReader(lreq))\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treq.Header.Set(\"Content-Type\", \"application\/protobuf\")\r\n\treq = req.WithContext(ctx)\r\n\tcc := &http.Client{Transport: rt}\r\n\tvar b []byte\r\n\t\r\n\tresp, err := cc.Do(req)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tb, err = readResponse(resp)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif resp.StatusCode == http.StatusRequestTimeout {\r\n\t\treturn nil, ErrLeaseHTTPTimeout\r\n\t}\r\n\tif resp.StatusCode == http.StatusNotFound {\r\n\t\treturn nil, lease.ErrLeaseNotFound\r\n\t}\r\n\tif resp.StatusCode != http.StatusOK {\r\n\t\treturn nil, fmt.Errorf(\"lease: unknown error(%s)\", string(b))\r\n\t}\r\n\tlresp := &leasepb.LeaseInternalResponse{}\r\n\tif err := lresp.Unmarshal(b); err != nil {\r\n\t\treturn nil, fmt.Errorf(`lease: %v. data = \"%s\"`, err, string(b))\r\n\t}\r\n\tif lresp.LeaseTimeToLiveResponse.ID != int64(id) {\r\n\t\treturn nil, fmt.Errorf(\"lease: renew id mismatch\")\r\n\t}\r\n\treturn lresp, nil\r\n}","code-length":514,"reference":"\/\/ TimeToLiveHTTP retrieves lease information of the given lease ID.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newWatcherBatch(wg *watcherGroup, evs []mvccpb.Event) watcherBatch {\r\n\tif len(wg.watchers) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\twb := make(watcherBatch)\r\n\tfor _, ev := range evs {\r\n\t\tfor w := range wg.watcherSetByKey(string(ev.Kv.Key)) {\r\n\t\t\tif ev.Kv.ModRevision >= w.minRev {\r\n\t\t\t\t\r\n\t\t\t\twb.add(w, ev)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn wb\r\n}","code-length":156,"reference":"\/\/ newWatcherBatch maps watchers to their matched events. It enables quick\n\/\/ events look up by watcher.","result":"Create a new watcherBatch .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wg *watcherGroup) add(wa *watcher) {\r\n\twg.watchers.add(wa)\r\n\tif wa.end == nil {\r\n\t\twg.keyWatchers.add(wa)\r\n\t\treturn\r\n\t}\r\n\t\r\n\tivl := adt.NewStringAffineInterval(string(wa.key), string(wa.end))\r\n\tif iv := wg.ranges.Find(ivl); iv != nil {\r\n\t\tiv.Val.(watcherSet).add(wa)\r\n\t\treturn\r\n\t}\r\n\t\r\n\tws := make(watcherSet)\r\n\tws.add(wa)\r\n\twg.ranges.Insert(ivl, ws)\r\n}","code-length":188,"reference":"\/\/ add puts a watcher in the group.","result":"Add watchers to the watcherGroup.","score":[0.1319,0.1948]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wg *watcherGroup) contains(key string) bool {\r\n\t_, ok := wg.keyWatchers[key]\r\n\treturn ok || wg.ranges.Intersects(adt.NewStringAffinePoint(key))\r\n}","code-length":65,"reference":"\/\/ contains is whether the given key has a watcher in the group.","result":"Check if the watcherGroup contains a key.","score":[0.0902,0.121]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wg *watcherGroup) delete(wa *watcher) bool {\r\n\tif _, ok := wg.watchers[wa]; !ok {\r\n\t\treturn false\r\n\t}\r\n\twg.watchers.delete(wa)\r\n\tif wa.end == nil {\r\n\t\twg.keyWatchers.delete(wa)\r\n\t\treturn true\r\n\t}\r\n\tivl := adt.NewStringAffineInterval(string(wa.key), string(wa.end))\r\n\tiv := wg.ranges.Find(ivl)\r\n\tif iv == nil {\r\n\t\treturn false\r\n\t}\r\n\tws := iv.Val.(watcherSet)\r\n\tdelete(ws, wa)\r\n\tif len(ws) == 0 {\r\n\t\t\r\n\t\tif ok := wg.ranges.Delete(ivl); !ok {\r\n\t\t\tpanic(\"could not remove watcher from interval tree\")\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":250,"reference":"\/\/ delete removes a watcher from the group.","result":"Delete watchers from the watcherGroup.","score":[0.1865,0.487]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wg *watcherGroup) choose(maxWatchers int, curRev, compactRev int64) (*watcherGroup, int64) {\r\n\tif len(wg.watchers) < maxWatchers {\r\n\t\treturn wg, wg.chooseAll(curRev, compactRev)\r\n\t}\r\n\tret := newWatcherGroup()\r\n\tfor w := range wg.watchers {\r\n\t\tif maxWatchers <= 0 {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tmaxWatchers--\r\n\t\tret.add(w)\r\n\t}\r\n\treturn &ret, ret.chooseAll(curRev, compactRev)\r\n}","code-length":163,"reference":"\/\/ choose selects watchers from the watcher group to update","result":"Create a new watcherGroup.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wg *watcherGroup) watcherSetByKey(key string) watcherSet {\r\n\twkeys := wg.keyWatchers[key]\r\n\twranges := wg.ranges.Stab(adt.NewStringAffinePoint(key))\r\n\t\r\n\tswitch {\r\n\tcase len(wranges) == 0:\r\n\t\t\r\n\t\treturn wkeys\r\n\tcase len(wranges) == 0 && len(wkeys) == 0:\r\n\t\treturn nil\r\n\tcase len(wranges) == 1 && len(wkeys) == 0:\r\n\t\treturn wranges[0].Val.(watcherSet)\r\n\t}\r\n\t\r\n\tret := make(watcherSet)\r\n\tret.union(wg.keyWatchers[key])\r\n\tfor _, item := range wranges {\r\n\t\tret.union(item.Val.(watcherSet))\r\n\t}\r\n\treturn ret\r\n}","code-length":228,"reference":"\/\/ watcherSetByKey gets the set of watchers that receive events on the given key.","result":"Create a watcherSet by the watcherGroup.","score":[0.0509,0.0379]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivl *Interval) Compare(c Comparable) int {\r\n\tivl2 := c.(*Interval)\r\n\tivbCmpBegin := ivl.Begin.Compare(ivl2.Begin)\r\n\tivbCmpEnd := ivl.Begin.Compare(ivl2.End)\r\n\tiveCmpBegin := ivl.End.Compare(ivl2.Begin)\r\n\t\r\n\tif ivbCmpBegin < 0 && iveCmpBegin <= 0 {\r\n\t\treturn -1\r\n\t}\r\n\t\r\n\tif ivbCmpEnd >= 0 {\r\n\t\treturn 1\r\n\t}\r\n\treturn 0\r\n}","code-length":161,"reference":"\/\/ Compare on an interval gives == if the interval overlaps.","result":"Compare two intervals.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (x *intervalNode) successor() *intervalNode {\r\n\tif x.right != nil {\r\n\t\treturn x.right.min()\r\n\t}\r\n\ty := x.parent\r\n\tfor y != nil && x == y.right {\r\n\t\tx = y\r\n\t\ty = y.parent\r\n\t}\r\n\treturn y\r\n}","code-length":97,"reference":"\/\/ successor is the next in-order node in the tree","result":"Find the successor of an interval node.","score":[0.1251,0.1031]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (x *intervalNode) updateMax() {\r\n\tfor x != nil {\r\n\t\toldmax := x.max\r\n\t\tmax := x.iv.Ivl.End\r\n\t\tif x.left != nil && x.left.max.Compare(max) > 0 {\r\n\t\t\tmax = x.left.max\r\n\t\t}\r\n\t\tif x.right != nil && x.right.max.Compare(max) > 0 {\r\n\t\t\tmax = x.right.max\r\n\t\t}\r\n\t\tif oldmax.Compare(max) == 0 {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tx.max = max\r\n\t\tx = x.parent\r\n\t}\r\n}","code-length":182,"reference":"\/\/ updateMax updates the maximum values for a node and its ancestors","result":"Update the max value of the interval node.","score":[0.0842,0.1293]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (x *intervalNode) visit(iv *Interval, nv nodeVisitor) bool {\r\n\tif x == nil {\r\n\t\treturn true\r\n\t}\r\n\tv := iv.Compare(&x.iv.Ivl)\r\n\tswitch {\r\n\tcase v < 0:\r\n\t\tif !x.left.visit(iv, nv) {\r\n\t\t\treturn false\r\n\t\t}\r\n\tcase v > 0:\r\n\t\tmaxiv := Interval{x.iv.Ivl.Begin, x.max}\r\n\t\tif maxiv.Compare(iv) == 0 {\r\n\t\t\tif !x.left.visit(iv, nv) || !x.right.visit(iv, nv) {\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\t}\r\n\tdefault:\r\n\t\tif !x.left.visit(iv, nv) || !nv(x) || !x.right.visit(iv, nv) {\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":257,"reference":"\/\/ visit will call a node visitor on each node that overlaps the given interval","result":"Detect if the interval node is a leaf.","score":[0.0819,0.1399]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) Delete(ivl Interval) bool {\r\n\tz := ivt.find(ivl)\r\n\tif z == nil {\r\n\t\treturn false\r\n\t}\r\n\ty := z\r\n\tif z.left != nil && z.right != nil {\r\n\t\ty = z.successor()\r\n\t}\r\n\tx := y.left\r\n\tif x == nil {\r\n\t\tx = y.right\r\n\t}\r\n\tif x != nil {\r\n\t\tx.parent = y.parent\r\n\t}\r\n\tif y.parent == nil {\r\n\t\tivt.root = x\r\n\t} else {\r\n\t\tif y == y.parent.left {\r\n\t\t\ty.parent.left = x\r\n\t\t} else {\r\n\t\t\ty.parent.right = x\r\n\t\t}\r\n\t\ty.parent.updateMax()\r\n\t}\r\n\tif y != z {\r\n\t\tz.iv = y.iv\r\n\t\tz.updateMax()\r\n\t}\r\n\tif y.color() == black && x != nil {\r\n\t\tivt.deleteFixup(x)\r\n\t}\r\n\tivt.count--\r\n\treturn true\r\n}","code-length":313,"reference":"\/\/ Delete removes the node with the given interval from the tree, returning\n\/\/ true if a node is in fact removed.","result":"Delete an interval from the tree.","score":[0.0297,0.1838]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) Insert(ivl Interval, val interface{}) {\r\n\tvar y *intervalNode\r\n\tz := &intervalNode{iv: IntervalValue{ivl, val}, max: ivl.End, c: red}\r\n\tx := ivt.root\r\n\tfor x != nil {\r\n\t\ty = x\r\n\t\tif z.iv.Ivl.Begin.Compare(x.iv.Ivl.Begin) < 0 {\r\n\t\t\tx = x.left\r\n\t\t} else {\r\n\t\t\tx = x.right\r\n\t\t}\r\n\t}\r\n\tz.parent = y\r\n\tif y == nil {\r\n\t\tivt.root = z\r\n\t} else {\r\n\t\tif z.iv.Ivl.Begin.Compare(y.iv.Ivl.Begin) < 0 {\r\n\t\t\ty.left = z\r\n\t\t} else {\r\n\t\t\ty.right = z\r\n\t\t}\r\n\t\ty.updateMax()\r\n\t}\r\n\tz.c = red\r\n\tivt.insertFixup(z)\r\n\tivt.count++\r\n}","code-length":286,"reference":"\/\/ Insert adds a node with the given interval into the tree.","result":"Insert an item into the IntervalTree.","score":[0.1112,0.2242]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) rotateLeft(x *intervalNode) {\r\n\ty := x.right\r\n\tx.right = y.left\r\n\tif y.left != nil {\r\n\t\ty.left.parent = x\r\n\t}\r\n\tx.updateMax()\r\n\tivt.replaceParent(x, y)\r\n\ty.left = x\r\n\ty.updateMax()\r\n}","code-length":109,"reference":"\/\/ rotateLeft moves x so it is left of its right child","result":"Rotate left.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) replaceParent(x *intervalNode, y *intervalNode) {\r\n\ty.parent = x.parent\r\n\tif x.parent == nil {\r\n\t\tivt.root = y\r\n\t} else {\r\n\t\tif x == x.parent.left {\r\n\t\t\tx.parent.left = y\r\n\t\t} else {\r\n\t\t\tx.parent.right = y\r\n\t\t}\r\n\t\tx.parent.updateMax()\r\n\t}\r\n\tx.parent = y\r\n}","code-length":140,"reference":"\/\/ replaceParent replaces x's parent with y","result":"Replace the parent of an interval node.","score":[0.1615,0.1429]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) MaxHeight() int {\r\n\treturn int((2 * math.Log2(float64(ivt.Len()+1))) + 0.5)\r\n}","code-length":54,"reference":"\/\/ MaxHeight is the expected maximum tree height given the number of nodes","result":"Generate the generated code.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) Visit(ivl Interval, ivv IntervalVisitor) {\r\n\tivt.root.visit(&ivl, func(n *intervalNode) bool { return ivv(&n.iv) })\r\n}","code-length":66,"reference":"\/\/ Visit calls a visitor function on every tree node intersecting the given interval.\n\/\/ It will visit each interval [x, y) in ascending order sorted on x.","result":"Create the interval tree.","score":[0.0009,0.0391]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) find(ivl Interval) (ret *intervalNode) {\r\n\tf := func(n *intervalNode) bool {\r\n\t\tif n.iv.Ivl != ivl {\r\n\t\t\treturn true\r\n\t\t}\r\n\t\tret = n\r\n\t\treturn false\r\n\t}\r\n\tivt.root.visit(&ivl, f)\r\n\treturn ret\r\n}","code-length":111,"reference":"\/\/ find the exact node for a given interval","result":"Find the node in the IntervalTree.","score":[0.1392,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) Find(ivl Interval) (ret *IntervalValue) {\r\n\tn := ivt.find(ivl)\r\n\tif n == nil {\r\n\t\treturn nil\r\n\t}\r\n\treturn &n.iv\r\n}","code-length":72,"reference":"\/\/ Find gets the IntervalValue for the node matching the given interval","result":"Find the interval value in the tree.","score":[0.1118,0.1739]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) Intersects(iv Interval) bool {\r\n\tx := ivt.root\r\n\tfor x != nil && iv.Compare(&x.iv.Ivl) != 0 {\r\n\t\tif x.left != nil && x.left.max.Compare(iv.Begin) > 0 {\r\n\t\t\tx = x.left\r\n\t\t} else {\r\n\t\t\tx = x.right\r\n\t\t}\r\n\t}\r\n\treturn x != nil\r\n}","code-length":128,"reference":"\/\/ Intersects returns true if there is some tree node intersecting the given interval.","result":"Check if an interval.","score":[0.0312,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) Contains(ivl Interval) bool {\r\n\tvar maxEnd, minBegin Comparable\r\n\tisContiguous := true\r\n\tivt.Visit(ivl, func(n *IntervalValue) bool {\r\n\t\tif minBegin == nil {\r\n\t\t\tminBegin = n.Ivl.Begin\r\n\t\t\tmaxEnd = n.Ivl.End\r\n\t\t\treturn true\r\n\t\t}\r\n\t\tif maxEnd.Compare(n.Ivl.Begin) < 0 {\r\n\t\t\tisContiguous = false\r\n\t\t\treturn false\r\n\t\t}\r\n\t\tif n.Ivl.End.Compare(maxEnd) > 0 {\r\n\t\t\tmaxEnd = n.Ivl.End\r\n\t\t}\r\n\t\treturn true\r\n\t})\r\n\treturn isContiguous && minBegin != nil && maxEnd.Compare(ivl.End) >= 0 && minBegin.Compare(ivl.Begin) <= 0\r\n}","code-length":239,"reference":"\/\/ Contains returns true if the interval tree's keys cover the entire given interval.","result":"Test if the interval tree contains a given interval.","score":[0.1758,0.3158]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) Stab(iv Interval) (ivs []*IntervalValue) {\r\n\tif ivt.count == 0 {\r\n\t\treturn nil\r\n\t}\r\n\tf := func(n *IntervalValue) bool { ivs = append(ivs, n); return true }\r\n\tivt.Visit(iv, f)\r\n\treturn ivs\r\n}","code-length":101,"reference":"\/\/ Stab returns a slice with all elements in the tree intersecting the interval.","result":"Generate the stab code.","score":[0.0262,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ivt *IntervalTree) Union(inIvt IntervalTree, ivl Interval) {\r\n\tf := func(n *IntervalValue) bool {\r\n\t\tivt.Insert(n.Ivl, n.Val)\r\n\t\treturn true\r\n\t}\r\n\tinIvt.Visit(ivl, f)\r\n}","code-length":89,"reference":"\/\/ Union merges a given interval tree into the receiver.","result":"Create the union of two intervals.","score":[0.0991,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewExactReadCloser(rc io.ReadCloser, totalBytes int64) io.ReadCloser {\r\n\treturn &exactReadCloser{rc: rc, totalBytes: totalBytes}\r\n}","code-length":50,"reference":"\/\/ NewExactReadCloser returns a ReadCloser that returns errors if the underlying\n\/\/ reader does not read back exactly the requested number of bytes.","result":"Create a new file.","score":[0.0028,0.0237]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewElection(s *Session, pfx string) *Election {\r\n\treturn &Election{session: s, keyPrefix: pfx + \"\/\"}\r\n}","code-length":43,"reference":"\/\/ NewElection returns a new election on a given key prefix.","result":"Create a new election.","score":[0.0785,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ResumeElection(s *Session, pfx string, leaderKey string, leaderRev int64) *Election {\r\n\treturn &Election{\r\n\t\tkeyPrefix:     pfx,\r\n\t\tsession:       s,\r\n\t\tleaderKey:     leaderKey,\r\n\t\tleaderRev:     leaderRev,\r\n\t\tleaderSession: s,\r\n\t}\r\n}","code-length":97,"reference":"\/\/ ResumeElection initializes an election with a known leader.","result":"Resume the election.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Election) Proclaim(ctx context.Context, val string) error {\r\n\tif e.leaderSession == nil {\r\n\t\treturn ErrElectionNotLeader\r\n\t}\r\n\tclient := e.session.Client()\r\n\tcmp := v3.Compare(v3.CreateRevision(e.leaderKey), \"=\", e.leaderRev)\r\n\ttxn := client.Txn(ctx).If(cmp)\r\n\ttxn = txn.Then(v3.OpPut(e.leaderKey, val, v3.WithLease(e.leaderSession.Lease())))\r\n\ttresp, terr := txn.Commit()\r\n\tif terr != nil {\r\n\t\treturn terr\r\n\t}\r\n\tif !tresp.Succeeded {\r\n\t\te.leaderKey = \"\"\r\n\t\treturn ErrElectionNotLeader\r\n\t}\r\n\te.hdr = tresp.Header\r\n\treturn nil\r\n}","code-length":224,"reference":"\/\/ Proclaim lets the leader announce a new value without another election.","result":"Avoid the need for the function to be called.","score":[0.0873,0.0427]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Election) Resign(ctx context.Context) (err error) {\r\n\tif e.leaderSession == nil {\r\n\t\treturn nil\r\n\t}\r\n\tclient := e.session.Client()\r\n\tcmp := v3.Compare(v3.CreateRevision(e.leaderKey), \"=\", e.leaderRev)\r\n\tresp, err := client.Txn(ctx).If(cmp).Then(v3.OpDelete(e.leaderKey)).Commit()\r\n\tif err == nil {\r\n\t\te.hdr = resp.Header\r\n\t}\r\n\te.leaderKey = \"\"\r\n\te.leaderSession = nil\r\n\treturn err\r\n}","code-length":170,"reference":"\/\/ Resign lets a leader start a new election.","result":"Resign the leader session.","score":[0.1088,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Election) Leader(ctx context.Context) (*v3.GetResponse, error) {\r\n\tclient := e.session.Client()\r\n\tresp, err := client.Get(ctx, e.keyPrefix, v3.WithFirstCreate()...)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t} else if len(resp.Kvs) == 0 {\r\n\t\t\r\n\t\treturn nil, ErrElectionNoLeader\r\n\t}\r\n\treturn resp, nil\r\n}","code-length":130,"reference":"\/\/ Leader returns the leader value for the current election.","result":"Get the leader key.","score":[0.1008,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Election) Observe(ctx context.Context) <-chan v3.GetResponse {\r\n\tretc := make(chan v3.GetResponse)\r\n\tgo e.observe(ctx, retc)\r\n\treturn retc\r\n}","code-length":68,"reference":"\/\/ Observe returns a channel that reliably observes ordered leader proposals\n\/\/ as GetResponse values on every current elected leader key. It will not\n\/\/ necessarily fetch all historical leader updates, but will always post the\n\/\/ most recent leader value.\n\/\/\n\/\/ The channel closes when the context is canceled or the underlying watcher\n\/\/ is otherwise disrupted.","result":"Observe the election.","score":[0.0,0.0187]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (qa *quotaAlarmer) check(ctx context.Context, r interface{}) error {\r\n\tif qa.q.Available(r) {\r\n\t\treturn nil\r\n\t}\r\n\treq := &pb.AlarmRequest{\r\n\t\tMemberID: uint64(qa.id),\r\n\t\tAction:   pb.AlarmRequest_ACTIVATE,\r\n\t\tAlarm:    pb.AlarmType_NOSPACE,\r\n\t}\r\n\tqa.a.Alarm(ctx, req)\r\n\treturn rpctypes.ErrGRPCNoSpace\r\n}","code-length":140,"reference":"\/\/ check whether request satisfies the quota. If there is not enough space,\n\/\/ ignore request and raise the free space alarm.","result":"Check the quota.","score":[0.001,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewExecWatchCommand() cli.Command {\r\n\treturn cli.Command{\r\n\t\tName:      \"exec-watch\",\r\n\t\tUsage:     \"watch a key for changes and exec an executable\",\r\n\t\tArgsUsage: \"<key> <command> [args...]\",\r\n\t\tFlags: []cli.Flag{\r\n\t\t\tcli.IntFlag{Name: \"after-index\", Value: 0, Usage: \"watch after the given index\"},\r\n\t\t\tcli.BoolFlag{Name: \"recursive, r\", Usage: \"watch all values for key and child keys\"},\r\n\t\t},\r\n\t\tAction: func(c *cli.Context) error {\r\n\t\t\texecWatchCommandFunc(c, mustNewKeyAPI(c))\r\n\t\t\treturn nil\r\n\t\t},\r\n\t}\r\n}","code-length":202,"reference":"\/\/ NewExecWatchCommand returns the CLI command for \"exec-watch\".","result":"Watch a key for changes and exec an executable.","score":[0.1219,0.0617]}
{"code":"\/*is used to<extra_id_0>\r\nfunc execWatchCommandFunc(c *cli.Context, ki client.KeysAPI) {\r\n\targs := c.Args()\r\n\targslen := len(args)\r\n\tif argslen < 2 {\r\n\t\thandleError(c, ExitBadArgs, errors.New(\"key and command to exec required\"))\r\n\t}\r\n\tvar (\r\n\t\tkey     string\r\n\t\tcmdArgs []string\r\n\t)\r\n\tfoundSep := false\r\n\tfor i := range args {\r\n\t\tif args[i] == \"--\" && i != 0 {\r\n\t\t\tfoundSep = true\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif foundSep {\r\n\t\tkey = args[0]\r\n\t\tcmdArgs = args[2:]\r\n\t} else {\r\n\t\t\r\n\t\t\r\n\t\tkey = args[argslen-1]\r\n\t\tcmdArgs = args[:argslen-1]\r\n\t}\r\n\tindex := 0\r\n\tif c.Int(\"after-index\") != 0 {\r\n\t\tindex = c.Int(\"after-index\")\r\n\t}\r\n\trecursive := c.Bool(\"recursive\")\r\n\tsigch := make(chan os.Signal, 1)\r\n\tsignal.Notify(sigch, os.Interrupt)\r\n\tgo func() {\r\n\t\t<-sigch\r\n\t\tos.Exit(0)\r\n\t}()\r\n\tw := ki.Watcher(key, &client.WatcherOptions{AfterIndex: uint64(index), Recursive: recursive})\r\n\tfor {\r\n\t\tresp, err := w.Next(context.TODO())\r\n\t\tif err != nil {\r\n\t\t\thandleError(c, ExitServerError, err)\r\n\t\t}\r\n\t\tif resp.Node.Dir {\r\n\t\t\tfmt.Fprintf(os.Stderr, \"Ignored dir %s change\\n\", resp.Node.Key)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tcmd := exec.Command(cmdArgs[0], cmdArgs[1:]...)\r\n\t\tcmd.Env = environResponse(resp, os.Environ())\r\n\t\tcmd.Stdout = os.Stdout\r\n\t\tcmd.Stderr = os.Stderr\r\n\t\tgo func() {\r\n\t\t\terr := cmd.Start()\r\n\t\t\tif err != nil {\r\n\t\t\t\tfmt.Fprintf(os.Stderr, err.Error())\r\n\t\t\t\tos.Exit(1)\r\n\t\t\t}\r\n\t\t\tcmd.Wait()\r\n\t\t}()\r\n\t}\r\n}","code-length":610,"reference":"\/\/ execWatchCommandFunc executes the \"exec-watch\" command.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewListener(u url.URL, tlsinfo *transport.TLSInfo) (net.Listener, error) {\r\n\treturn transport.NewTimeoutListener(u.Host, u.Scheme, tlsinfo, ConnReadTimeout, ConnWriteTimeout)\r\n}","code-length":66,"reference":"\/\/ NewListener returns a listener for raft message transfer between peers.\n\/\/ It uses timeout listener to identify broken streams promptly.","result":"Create a new listener.","score":[0.0046,0.0259]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRoundTripper(tlsInfo transport.TLSInfo, dialTimeout time.Duration) (http.RoundTripper, error) {\r\n\t\r\n\t\r\n\t\r\n\treturn transport.NewTimeoutTransport(tlsInfo, dialTimeout, 0, 0)\r\n}","code-length":70,"reference":"\/\/ NewRoundTripper returns a roundTripper used to send requests\n\/\/ to rafthttp listener of remote peers.","result":"Create the round tripper.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc createPostRequest(u url.URL, path string, body io.Reader, ct string, urls types.URLs, from, cid types.ID) *http.Request {\r\n\tuu := u\r\n\tuu.Path = path\r\n\treq, err := http.NewRequest(\"POST\", uu.String(), body)\r\n\tif err != nil {\r\n\t\tplog.Panicf(\"unexpected new request error (%v)\", err)\r\n\t}\r\n\treq.Header.Set(\"Content-Type\", ct)\r\n\treq.Header.Set(\"X-Server-From\", from.String())\r\n\treq.Header.Set(\"X-Server-Version\", version.Version)\r\n\treq.Header.Set(\"X-Min-Cluster-Version\", version.MinClusterVersion)\r\n\treq.Header.Set(\"X-Etcd-Cluster-ID\", cid.String())\r\n\tsetPeerURLsHeader(req, urls)\r\n\treturn req\r\n}","code-length":231,"reference":"\/\/ createPostRequest creates a HTTP POST request that sends raft message.","result":"Create a new request.","score":[0.0555,0.182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkPostResponse(resp *http.Response, body []byte, req *http.Request, to types.ID) error {\r\n\tswitch resp.StatusCode {\r\n\tcase http.StatusPreconditionFailed:\r\n\t\tswitch strings.TrimSuffix(string(body), \"\\n\") {\r\n\t\tcase errIncompatibleVersion.Error():\r\n\t\t\tplog.Errorf(\"request sent was ignored by peer %s (server version incompatible)\", to)\r\n\t\t\treturn errIncompatibleVersion\r\n\t\tcase errClusterIDMismatch.Error():\r\n\t\t\tplog.Errorf(\"request sent was ignored (cluster ID mismatch: remote[%s]=%s, local=%s)\",\r\n\t\t\t\tto, resp.Header.Get(\"X-Etcd-Cluster-ID\"), req.Header.Get(\"X-Etcd-Cluster-ID\"))\r\n\t\t\treturn errClusterIDMismatch\r\n\t\tdefault:\r\n\t\t\treturn fmt.Errorf(\"unhandled error %q when precondition failed\", string(body))\r\n\t\t}\r\n\tcase http.StatusForbidden:\r\n\t\treturn errMemberRemoved\r\n\tcase http.StatusNoContent:\r\n\t\treturn nil\r\n\tdefault:\r\n\t\treturn fmt.Errorf(\"unexpected http status %s while posting to %q\", http.StatusText(resp.StatusCode), req.URL.String())\r\n\t}\r\n}","code-length":319,"reference":"\/\/ checkPostResponse checks the response of the HTTP POST request that sends\n\/\/ raft message.","result":"Check the response status of a request.","score":[0.0806,0.1408]}
{"code":"\/*is used to<extra_id_0>\r\nfunc serverVersion(h http.Header) *semver.Version {\r\n\tverStr := h.Get(\"X-Server-Version\")\r\n\t\r\n\tif verStr == \"\" {\r\n\t\tverStr = \"2.0.0\"\r\n\t}\r\n\treturn semver.Must(semver.NewVersion(verStr))\r\n}","code-length":90,"reference":"\/\/ serverVersion returns the server version from the given header.","result":"Determine the server version.","score":[0.1008,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkVersionCompatibility(name string, server, minCluster *semver.Version) (\r\n\tlocalServer *semver.Version,\r\n\tlocalMinCluster *semver.Version,\r\n\terr error) {\r\n\tlocalServer = semver.Must(semver.NewVersion(version.Version))\r\n\tlocalMinCluster = semver.Must(semver.NewVersion(version.MinClusterVersion))\r\n\tif compareMajorMinorVersion(server, localMinCluster) == -1 {\r\n\t\treturn localServer, localMinCluster, fmt.Errorf(\"remote version is too low: remote[%s]=%s, local=%s\", name, server, localServer)\r\n\t}\r\n\tif compareMajorMinorVersion(minCluster, localServer) == 1 {\r\n\t\treturn localServer, localMinCluster, fmt.Errorf(\"local version is too low: remote[%s]=%s, local=%s\", name, server, localServer)\r\n\t}\r\n\treturn localServer, localMinCluster, nil\r\n}","code-length":241,"reference":"\/\/ checkVersionCompatibility checks whether the given version is compatible\n\/\/ with the local version.","result":"Check the version of the cluster .","score":[0.0782,0.1504]}
{"code":"\/*is used to<extra_id_0>\r\nfunc setPeerURLsHeader(req *http.Request, urls types.URLs) {\r\n\tif urls == nil {\r\n\t\t\r\n\t\treturn\r\n\t}\r\n\tpeerURLs := make([]string, urls.Len())\r\n\tfor i := range urls {\r\n\t\tpeerURLs[i] = urls[i].String()\r\n\t}\r\n\treq.Header.Set(\"X-PeerURLs\", strings.Join(peerURLs, \",\"))\r\n}","code-length":117,"reference":"\/\/ setPeerURLsHeader reports local urls for peer discovery","result":"Set the peer URLs header.","score":[0.1319,0.1299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc addRemoteFromRequest(tr Transporter, r *http.Request) {\r\n\tif from, err := types.IDFromString(r.Header.Get(\"X-Server-From\")); err == nil {\r\n\t\tif urls := r.Header.Get(\"X-PeerURLs\"); urls != \"\" {\r\n\t\t\ttr.AddRemote(from, strings.Split(urls, \",\"))\r\n\t\t}\r\n\t}\r\n}","code-length":108,"reference":"\/\/ addRemoteFromRequest adds a remote peer according to an http request header","result":"Add remote requests from the request.","score":[0.071,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewKeysAPIWithPrefix(c Client, p string) KeysAPI {\r\n\treturn &httpKeysAPI{\r\n\t\tclient: c,\r\n\t\tprefix: p,\r\n\t}\r\n}","code-length":57,"reference":"\/\/ NewKeysAPIWithPrefix acts like NewKeysAPI, but allows the caller\n\/\/ to provide a custom base URL path. This should only be used in\n\/\/ very rare cases.","result":"Create a new KeysAPI.","score":[0.001,0.0202]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *Node) TTLDuration() time.Duration {\r\n\treturn time.Duration(n.TTL) * time.Second\r\n}","code-length":41,"reference":"\/\/ TTLDuration returns the Node's TTL as a time.Duration object","result":"Generate the code.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetPflagsFromEnv(prefix string, fs *pflag.FlagSet) error {\r\n\tvar err error\r\n\talreadySet := make(map[string]bool)\r\n\tusedEnvKey := make(map[string]bool)\r\n\tfs.VisitAll(func(f *pflag.Flag) {\r\n\t\tif f.Changed {\r\n\t\t\talreadySet[FlagToEnv(prefix, f.Name)] = true\r\n\t\t}\r\n\t\tif serr := setFlagFromEnv(fs, prefix, f.Name, usedEnvKey, alreadySet, false); serr != nil {\r\n\t\t\terr = serr\r\n\t\t}\r\n\t})\r\n\tverifyEnv(prefix, usedEnvKey, alreadySet)\r\n\treturn err\r\n}","code-length":190,"reference":"\/\/ SetPflagsFromEnv is similar to SetFlagsFromEnv. However, the accepted flagset type is pflag.FlagSet\n\/\/ and it does not do any logging.","result":"Set flags from environment variables.","score":[0,0.0258]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FlagToEnv(prefix, name string) string {\r\n\treturn prefix + \"_\" + strings.ToUpper(strings.Replace(name, \"-\", \"_\", -1))\r\n}","code-length":50,"reference":"\/\/ FlagToEnv converts flag string to upper-case environment variable key string.","result":"Set flags to environment variables.","score":[0.0861,0.1442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc excerpt(str string, pre, suf int) string {\r\n\tif pre+suf > len(str) {\r\n\t\treturn fmt.Sprintf(\"%q\", str)\r\n\t}\r\n\treturn fmt.Sprintf(\"%q...%q\", str[:pre], str[len(str)-suf:])\r\n}","code-length":86,"reference":"\/\/ excerpt replaces middle part with ellipsis and returns a double-quoted\n\/\/ string safely escaped with Go syntax.","result":"Generate the excerpt.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc passConfChange(entry raftpb.Entry) (bool, string) {\r\n\treturn entry.Type == raftpb.EntryConfChange, \"ConfigChange\"\r\n}","code-length":48,"reference":"\/\/ The 9 pass functions below takes the raftpb.Entry and return if the entry should be printed and the type of entry,\n\/\/ the type of the entry will used in the following print function","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc printInternalRaftRequest(entry raftpb.Entry) {\r\n\tvar rr etcdserverpb.InternalRaftRequest\r\n\tif err := rr.Unmarshal(entry.Data); err == nil {\r\n\t\tfmt.Printf(\"%4d\\t%10d\\tnorm\\t%s\", entry.Term, entry.Index, rr.String())\r\n\t}\r\n}","code-length":96,"reference":"\/\/ The 4 print functions below print the entry format based on there types\n\/\/ printInternalRaftRequest is used to print entry information for IRRRange, IRRPut,\n\/\/ IRRDeleteRange and IRRTxn entries","result":"Print the internal request to the console.","score":[0.0072,0.0722]}
{"code":"\/*is used to<extra_id_0>\r\nfunc listEntriesType(entrytype string, streamdecoder string, ents []raftpb.Entry) {\r\n\tentryFilters := evaluateEntrytypeFlag(entrytype)\r\n\tprinterMap := map[string]EntryPrinter{\"InternalRaftRequest\": printInternalRaftRequest,\r\n\t\t\"Request\":       printRequest,\r\n\t\t\"ConfigChange\":  printConfChange,\r\n\t\t\"UnknownNormal\": printUnknownNormal}\r\n\tvar stderr bytes.Buffer\r\n\targs := strings.Split(streamdecoder, \" \")\r\n\tcmd := exec.Command(args[0], args[1:]...)\r\n\tstdin, err := cmd.StdinPipe()\r\n\tif err != nil {\r\n\t\tlog.Panic(err)\r\n\t}\r\n\tstdout, err := cmd.StdoutPipe()\r\n\tif err != nil {\r\n\t\tlog.Panic(err)\r\n\t}\r\n\tcmd.Stderr = &stderr\r\n\tif streamdecoder != \"\" {\r\n\t\terr = cmd.Start()\r\n\t\tif err != nil {\r\n\t\t\tlog.Panic(err)\r\n\t\t}\r\n\t}\r\n\tcnt := 0\r\n\tfor _, e := range ents {\r\n\t\tpassed := false\r\n\t\tcurrtype := \"\"\r\n\t\tfor _, filter := range entryFilters {\r\n\t\t\tpassed, currtype = filter(e)\r\n\t\t\tif passed {\r\n\t\t\t\tcnt++\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif passed {\r\n\t\t\tprinter := printerMap[currtype]\r\n\t\t\tprinter(e)\r\n\t\t\tif streamdecoder == \"\" {\r\n\t\t\t\tfmt.Println()\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tio.WriteString(stdin, hex.EncodeToString(e.Data))\r\n\t\t\tio.WriteString(stdin, \"\\n\")\r\n\t\t\toutputReader := bufio.NewReader(stdout)\r\n\t\t\tdecoderoutput, currerr := outputReader.ReadString('\\n')\r\n\t\t\tif currerr != nil {\r\n\t\t\t\tfmt.Println(currerr)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tdecoder_status, decoded_data := parseDecoderOutput(decoderoutput)\r\n\t\t\tfmt.Printf(\"\\t%s\\t%s\", decoder_status, decoded_data)\r\n\t\t}\r\n\t}\r\n\tstdin.Close()\r\n\terr = cmd.Wait()\r\n\tif streamdecoder != \"\" {\r\n\t\tif err != nil {\r\n\t\t\tlog.Panic(err)\r\n\t\t}\r\n\t\tif stderr.String() != \"\" {\r\n\t\t\tos.Stderr.WriteString(\"decoder stderr: \" + stderr.String())\r\n\t\t}\r\n\t}\r\n\tfmt.Printf(\"\\nEntry types (%s) count is : %d\", entrytype, cnt)\r\n}","code-length":684,"reference":"\/\/  listEntriesType filters and prints entries based on the entry-type flag,","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newLog(storage Storage, logger Logger) *raftLog {\r\n\treturn newLogWithSize(storage, logger, noLimit)\r\n}","code-length":42,"reference":"\/\/ newLog returns log using the given storage and default options. It\n\/\/ recovers the log to the state that it just commits and applies the\n\/\/ latest snapshot.","result":"Generate the generated code.","score":[0.0006,0.0189]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newLogWithSize(storage Storage, logger Logger, maxNextEntsSize uint64) *raftLog {\r\n\tif storage == nil {\r\n\t\tlog.Panic(\"storage must not be nil\")\r\n\t}\r\n\tlog := &raftLog{\r\n\t\tstorage:         storage,\r\n\t\tlogger:          logger,\r\n\t\tmaxNextEntsSize: maxNextEntsSize,\r\n\t}\r\n\tfirstIndex, err := storage.FirstIndex()\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tlastIndex, err := storage.LastIndex()\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tlog.unstable.offset = lastIndex + 1\r\n\tlog.unstable.logger = logger\r\n\t\r\n\tlog.committed = firstIndex - 1\r\n\tlog.applied = firstIndex - 1\r\n\treturn log\r\n}","code-length":233,"reference":"\/\/ newLogWithSize returns a log using the given storage and max\n\/\/ message size.","result":"Create a new log with size.","score":[0.067,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *raftLog) findConflict(ents []pb.Entry) uint64 {\r\n\tfor _, ne := range ents {\r\n\t\tif !l.matchTerm(ne.Index, ne.Term) {\r\n\t\t\tif ne.Index <= l.lastIndex() {\r\n\t\t\t\tl.logger.Infof(\"found conflict at index %d [existing term: %d, conflicting term: %d]\",\r\n\t\t\t\t\tne.Index, l.zeroTermOnErrCompacted(l.term(ne.Index)), ne.Term)\r\n\t\t\t}\r\n\t\t\treturn ne.Index\r\n\t\t}\r\n\t}\r\n\treturn 0\r\n}","code-length":166,"reference":"\/\/ findConflict finds the index of the conflict.\n\/\/ It returns the first pair of conflicting entries between the existing\n\/\/ entries and the given entries, if there are any.\n\/\/ If there is no conflicting entries, and the existing entries contains\n\/\/ all the given entries, zero will be returned.\n\/\/ If there is no conflicting entries, but the given entries contains new\n\/\/ entries, the index of the first new entry will be returned.\n\/\/ An entry is considered to be conflicting if it has the same index but\n\/\/ a different term.\n\/\/ The first entry MUST have an index equal to the argument 'from'.\n\/\/ The index of the given entries MUST be continuously increasing.","result":"Generate the generated code.","score":[0.0,0.0047]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *raftLog) nextEnts() (ents []pb.Entry) {\r\n\toff := max(l.applied+1, l.firstIndex())\r\n\tif l.committed+1 > off {\r\n\t\tents, err := l.slice(off, l.committed+1, l.maxNextEntsSize)\r\n\t\tif err != nil {\r\n\t\t\tl.logger.Panicf(\"unexpected error when getting unapplied entries (%v)\", err)\r\n\t\t}\r\n\t\treturn ents\r\n\t}\r\n\treturn nil\r\n}","code-length":147,"reference":"\/\/ nextEnts returns all the available entries for execution.\n\/\/ If applied is smaller than the index of snapshot, it returns all committed\n\/\/ entries after the index of snapshot.","result":"Generate the code.","score":[0.0001,0.0183]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *raftLog) allEntries() []pb.Entry {\r\n\tents, err := l.entries(l.firstIndex(), noLimit)\r\n\tif err == nil {\r\n\t\treturn ents\r\n\t}\r\n\tif err == ErrCompacted {\r\n\t\treturn l.allEntries()\r\n\t}\r\n\t\r\n\tpanic(err)\r\n}","code-length":100,"reference":"\/\/ allEntries returns all entries in the log.","result":"Get all entries from the log.","score":[0.2575,0.4808]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *raftLog) slice(lo, hi, maxSize uint64) ([]pb.Entry, error) {\r\n\terr := l.mustCheckOutOfBounds(lo, hi)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif lo == hi {\r\n\t\treturn nil, nil\r\n\t}\r\n\tvar ents []pb.Entry\r\n\tif lo < l.unstable.offset {\r\n\t\tstoredEnts, err := l.storage.Entries(lo, min(hi, l.unstable.offset), maxSize)\r\n\t\tif err == ErrCompacted {\r\n\t\t\treturn nil, err\r\n\t\t} else if err == ErrUnavailable {\r\n\t\t\tl.logger.Panicf(\"entries[%d:%d) is unavailable from storage\", lo, min(hi, l.unstable.offset))\r\n\t\t} else if err != nil {\r\n\t\t\tpanic(err)\r\n\t\t}\r\n\t\t\r\n\t\tif uint64(len(storedEnts)) < min(hi, l.unstable.offset)-lo {\r\n\t\t\treturn storedEnts, nil\r\n\t\t}\r\n\t\tents = storedEnts\r\n\t}\r\n\tif hi > l.unstable.offset {\r\n\t\tunstable := l.unstable.slice(max(lo, l.unstable.offset), hi)\r\n\t\tif len(ents) > 0 {\r\n\t\t\tcombined := make([]pb.Entry, len(ents)+len(unstable))\r\n\t\t\tn := copy(combined, ents)\r\n\t\t\tcopy(combined[n:], unstable)\r\n\t\t\tents = combined\r\n\t\t} else {\r\n\t\t\tents = unstable\r\n\t\t}\r\n\t}\r\n\treturn limitSize(ents, maxSize), nil\r\n}","code-length":442,"reference":"\/\/ slice returns a slice of log entries from lo through hi-1, inclusive.","result":"Store the entries in the raft log.","score":[0.0685,0.0403]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSession(client *v3.Client, opts ...SessionOption) (*Session, error) {\r\n\tops := &sessionOptions{ttl: defaultSessionTTL, ctx: client.Ctx()}\r\n\tfor _, opt := range opts {\r\n\t\topt(ops)\r\n\t}\r\n\tid := ops.leaseID\r\n\tif id == v3.NoLease {\r\n\t\tresp, err := client.Grant(ops.ctx, int64(ops.ttl))\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tid = v3.LeaseID(resp.ID)\r\n\t}\r\n\tctx, cancel := context.WithCancel(ops.ctx)\r\n\tkeepAlive, err := client.KeepAlive(ctx, id)\r\n\tif err != nil || keepAlive == nil {\r\n\t\tcancel()\r\n\t\treturn nil, err\r\n\t}\r\n\tdonec := make(chan struct{})\r\n\ts := &Session{client: client, opts: ops, id: id, cancel: cancel, donec: donec}\r\n\t\r\n\tgo func() {\r\n\t\tdefer close(donec)\r\n\t\tfor range keepAlive {\r\n\t\t\t\r\n\t\t}\r\n\t}()\r\n\treturn s, nil\r\n}","code-length":317,"reference":"\/\/ NewSession gets the leased session for a client.","result":"Create a new session.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Session) Close() error {\r\n\ts.Orphan()\r\n\t\r\n\tctx, cancel := context.WithTimeout(s.opts.ctx, time.Duration(s.opts.ttl)*time.Second)\r\n\t_, err := s.client.Revoke(ctx, s.id)\r\n\tcancel()\r\n\treturn err\r\n}","code-length":93,"reference":"\/\/ Close orphans the session and revokes the session lease.","result":"Close the session.","score":[0.0471,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WithTTL(ttl int) SessionOption {\r\n\treturn func(so *sessionOptions) {\r\n\t\tif ttl > 0 {\r\n\t\t\tso.ttl = ttl\r\n\t\t}\r\n\t}\r\n}","code-length":61,"reference":"\/\/ WithTTL configures the session's TTL in seconds.\n\/\/ If TTL is <= 0, the default 60 seconds TTL will be used.","result":"Set the TTL.","score":[0.0007,0.0249]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WithLease(leaseID v3.LeaseID) SessionOption {\r\n\treturn func(so *sessionOptions) {\r\n\t\tso.leaseID = leaseID\r\n\t}\r\n}","code-length":54,"reference":"\/\/ WithLease specifies the existing leaseID to be used for the session.\n\/\/ This is useful in process restart scenario, for example, to reclaim\n\/\/ leadership from an election prior to restart.","result":"Generate the generated code.","score":[0.0003,0.0171]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ro *readOnly) addRequest(index uint64, m pb.Message) {\r\n\tctx := string(m.Entries[0].Data)\r\n\tif _, ok := ro.pendingReadIndex[ctx]; ok {\r\n\t\treturn\r\n\t}\r\n\tro.pendingReadIndex[ctx] = &readIndexStatus{index: index, req: m, acks: make(map[uint64]struct{})}\r\n\tro.readIndexQueue = append(ro.readIndexQueue, ctx)\r\n}","code-length":131,"reference":"\/\/ addRequest adds a read only reuqest into readonly struct.\n\/\/ `index` is the commit index of the raft state machine when it received\n\/\/ the read only request.\n\/\/ `m` is the original read only request message from the local or remote node.","result":"Add request to read only objects.","score":[0.0005,0.0785]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ro *readOnly) recvAck(m pb.Message) int {\r\n\trs, ok := ro.pendingReadIndex[string(m.Context)]\r\n\tif !ok {\r\n\t\treturn 0\r\n\t}\r\n\trs.acks[m.From] = struct{}{}\r\n\t\r\n\treturn len(rs.acks) + 1\r\n}","code-length":95,"reference":"\/\/ recvAck notifies the readonly struct that the raft state machine received\n\/\/ an acknowledgment of the heartbeat that attached with the read only request\n\/\/ context.","result":"Call recvAck in readOnly.","score":[0.001,0.0202]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ro *readOnly) advance(m pb.Message) []*readIndexStatus {\r\n\tvar (\r\n\t\ti     int\r\n\t\tfound bool\r\n\t)\r\n\tctx := string(m.Context)\r\n\trss := []*readIndexStatus{}\r\n\tfor _, okctx := range ro.readIndexQueue {\r\n\t\ti++\r\n\t\trs, ok := ro.pendingReadIndex[okctx]\r\n\t\tif !ok {\r\n\t\t\tpanic(\"cannot find corresponding read state from pending map\")\r\n\t\t}\r\n\t\trss = append(rss, rs)\r\n\t\tif okctx == ctx {\r\n\t\t\tfound = true\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif found {\r\n\t\tro.readIndexQueue = ro.readIndexQueue[i:]\r\n\t\tfor _, rs := range rss {\r\n\t\t\tdelete(ro.pendingReadIndex, string(rs.req.Entries[0].Data))\r\n\t\t}\r\n\t\treturn rss\r\n\t}\r\n\treturn nil\r\n}","code-length":267,"reference":"\/\/ advance advances the read only request queue kept by the readonly struct.\n\/\/ It dequeues the requests until it finds the read only request that has\n\/\/ the same context as the given `m`.","result":"Advance the read index queue.","score":[0.0008,0.0469]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ro *readOnly) lastPendingRequestCtx() string {\r\n\tif len(ro.readIndexQueue) == 0 {\r\n\t\treturn \"\"\r\n\t}\r\n\treturn ro.readIndexQueue[len(ro.readIndexQueue)-1]\r\n}","code-length":71,"reference":"\/\/ lastPendingRequestCtx returns the context of the last pending read only\n\/\/ request in readonly struct.","result":"Generate the last pending request context.","score":[0.0807,0.25]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) Start() {\r\n\ts.start()\r\n\ts.goAttach(func() { s.adjustTicks() })\r\n\ts.goAttach(func() { s.publish(s.Cfg.ReqTimeout()) })\r\n\ts.goAttach(s.purgeFile)\r\n\ts.goAttach(func() { monitorFileDescriptor(s.getLogger(), s.stopping) })\r\n\ts.goAttach(s.monitorVersions)\r\n\ts.goAttach(s.linearizableReadLoop)\r\n\ts.goAttach(s.monitorKVHash)\r\n}","code-length":153,"reference":"\/\/ Start performs any initialization of the Server necessary for it to\n\/\/ begin serving requests. It must be called before Do or Process.\n\/\/ Start must be non-blocking; any long-running server functionality\n\/\/ should be implemented in goroutines.","result":"Start the server.","score":[0.0,0.0282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) start() {\r\n\tlg := s.getLogger()\r\n\tif s.Cfg.SnapshotCount == 0 {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Info(\r\n\t\t\t\t\"updating snapshot-count to default\",\r\n\t\t\t\tzap.Uint64(\"given-snapshot-count\", s.Cfg.SnapshotCount),\r\n\t\t\t\tzap.Uint64(\"updated-snapshot-count\", DefaultSnapshotCount),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Infof(\"set snapshot count to default %d\", DefaultSnapshotCount)\r\n\t\t}\r\n\t\ts.Cfg.SnapshotCount = DefaultSnapshotCount\r\n\t}\r\n\tif s.Cfg.SnapshotCatchUpEntries == 0 {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Info(\r\n\t\t\t\t\"updating snapshot catch-up entries to default\",\r\n\t\t\t\tzap.Uint64(\"given-snapshot-catchup-entries\", s.Cfg.SnapshotCatchUpEntries),\r\n\t\t\t\tzap.Uint64(\"updated-snapshot-catchup-entries\", DefaultSnapshotCatchUpEntries),\r\n\t\t\t)\r\n\t\t}\r\n\t\ts.Cfg.SnapshotCatchUpEntries = DefaultSnapshotCatchUpEntries\r\n\t}\r\n\ts.w = wait.New()\r\n\ts.applyWait = wait.NewTimeList()\r\n\ts.done = make(chan struct{})\r\n\ts.stop = make(chan struct{})\r\n\ts.stopping = make(chan struct{})\r\n\ts.ctx, s.cancel = context.WithCancel(context.Background())\r\n\ts.readwaitc = make(chan struct{}, 1)\r\n\ts.readNotifier = newNotifier()\r\n\ts.leaderChanged = make(chan struct{})\r\n\tif s.ClusterVersion() != nil {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Info(\r\n\t\t\t\t\"starting etcd server\",\r\n\t\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\t\tzap.String(\"local-server-version\", version.Version),\r\n\t\t\t\tzap.String(\"cluster-id\", s.Cluster().ID().String()),\r\n\t\t\t\tzap.String(\"cluster-version\", version.Cluster(s.ClusterVersion().String())),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Infof(\"starting server... [version: %v, cluster version: %v]\", version.Version, version.Cluster(s.ClusterVersion().String()))\r\n\t\t}\r\n\t\tmembership.ClusterVersionMetrics.With(prometheus.Labels{\"cluster_version\": s.ClusterVersion().String()}).Set(1)\r\n\t} else {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Info(\r\n\t\t\t\t\"starting etcd server\",\r\n\t\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\t\tzap.String(\"local-server-version\", version.Version),\r\n\t\t\t\tzap.String(\"cluster-version\", \"to_be_decided\"),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Infof(\"starting server... [version: %v, cluster version: to_be_decided]\", version.Version)\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\tgo s.run()\r\n}","code-length":816,"reference":"\/\/ start prepares and starts server in a new goroutine. It is no longer safe to\n\/\/ modify a server's fields after it has been sent to Start.\n\/\/ This function is just used for testing.","result":"Code too long,keep in 512.","score":[0.0005,0.0152]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) Process(ctx context.Context, m raftpb.Message) error {\r\n\tif s.cluster.IsIDRemoved(types.ID(m.From)) {\r\n\t\tif lg := s.getLogger(); lg != nil {\r\n\t\t\tlg.Warn(\r\n\t\t\t\t\"rejected Raft message from removed member\",\r\n\t\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\t\tzap.String(\"removed-member-id\", types.ID(m.From).String()),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Warningf(\"reject message from removed member %s\", types.ID(m.From).String())\r\n\t\t}\r\n\t\treturn httptypes.NewHTTPError(http.StatusForbidden, \"cannot process message from removed member\")\r\n\t}\r\n\tif m.Type == raftpb.MsgApp {\r\n\t\ts.stats.RecvAppendReq(types.ID(m.From).String(), m.Size())\r\n\t}\r\n\treturn s.r.Step(ctx, m)\r\n}","code-length":273,"reference":"\/\/ Process takes a raft message and applies it to the server's raft state\n\/\/ machine, respecting any timeout of the given context.","result":"Generate the generated code.","score":[0.0028,0.0237]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) ReportSnapshot(id uint64, status raft.SnapshotStatus) {\r\n\ts.r.ReportSnapshot(id, status)\r\n}","code-length":47,"reference":"\/\/ ReportSnapshot reports snapshot sent status to the raft state machine,\n\/\/ and clears the used snapshot from the snapshot store.","result":"Generate the code.","score":[0.001,0.026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) MoveLeader(ctx context.Context, lead, transferee uint64) error {\r\n\tnow := time.Now()\r\n\tinterval := time.Duration(s.Cfg.TickMs) * time.Millisecond\r\n\tif lg := s.getLogger(); lg != nil {\r\n\t\tlg.Info(\r\n\t\t\t\"leadership transfer starting\",\r\n\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\tzap.String(\"current-leader-member-id\", types.ID(lead).String()),\r\n\t\t\tzap.String(\"transferee-member-id\", types.ID(transferee).String()),\r\n\t\t)\r\n\t} else {\r\n\t\tplog.Infof(\"%s starts leadership transfer from %s to %s\", s.ID(), types.ID(lead), types.ID(transferee))\r\n\t}\r\n\ts.r.TransferLeadership(ctx, lead, transferee)\r\n\tfor s.Lead() != transferee {\r\n\t\tselect {\r\n\t\tcase <-ctx.Done():\r\n\t\t\treturn ErrTimeoutLeaderTransfer\r\n\t\tcase <-time.After(interval):\r\n\t\t}\r\n\t}\r\n\t\r\n\tif lg := s.getLogger(); lg != nil {\r\n\t\tlg.Info(\r\n\t\t\t\"leadership transfer finished\",\r\n\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\tzap.String(\"old-leader-member-id\", types.ID(lead).String()),\r\n\t\t\tzap.String(\"new-leader-member-id\", types.ID(transferee).String()),\r\n\t\t\tzap.Duration(\"took\", time.Since(now)),\r\n\t\t)\r\n\t} else {\r\n\t\tplog.Infof(\"%s finished leadership transfer from %s to %s (took %v)\", s.ID(), types.ID(lead), types.ID(transferee), time.Since(now))\r\n\t}\r\n\treturn nil\r\n}","code-length":505,"reference":"\/\/ MoveLeader transfers the leader to the given transferee.","result":"Transfer leadership.","score":[0,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) TransferLeadership() error {\r\n\tif !s.isLeader() {\r\n\t\tif lg := s.getLogger(); lg != nil {\r\n\t\t\tlg.Info(\r\n\t\t\t\t\"skipped leadership transfer; local server is not leader\",\r\n\t\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\t\tzap.String(\"current-leader-member-id\", types.ID(s.Lead()).String()),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Printf(\"skipped leadership transfer for stopping non-leader member\")\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\tif !s.isMultiNode() {\r\n\t\tif lg := s.getLogger(); lg != nil {\r\n\t\t\tlg.Info(\r\n\t\t\t\t\"skipped leadership transfer; it's a single-node cluster\",\r\n\t\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\t\tzap.String(\"current-leader-member-id\", types.ID(s.Lead()).String()),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Printf(\"skipped leadership transfer for single member cluster\")\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\ttransferee, ok := longestConnected(s.r.transport, s.cluster.MemberIDs())\r\n\tif !ok {\r\n\t\treturn ErrUnhealthy\r\n\t}\r\n\ttm := s.Cfg.ReqTimeout()\r\n\tctx, cancel := context.WithTimeout(s.ctx, tm)\r\n\terr := s.MoveLeader(ctx, s.Lead(), uint64(transferee))\r\n\tcancel()\r\n\treturn err\r\n}","code-length":429,"reference":"\/\/ TransferLeadership transfers the leader to the chosen transferee.","result":"Transfer leadership from the leader to the member.","score":[0.3836,0.5438]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) configure(ctx context.Context, cc raftpb.ConfChange) ([]*membership.Member, error) {\r\n\tcc.ID = s.reqIDGen.Next()\r\n\tch := s.w.Register(cc.ID)\r\n\tstart := time.Now()\r\n\tif err := s.r.ProposeConfChange(ctx, cc); err != nil {\r\n\t\ts.w.Trigger(cc.ID, nil)\r\n\t\treturn nil, err\r\n\t}\r\n\tselect {\r\n\tcase x := <-ch:\r\n\t\tif x == nil {\r\n\t\t\tif lg := s.getLogger(); lg != nil {\r\n\t\t\t\tlg.Panic(\"failed to configure\")\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"configure trigger value should never be nil\")\r\n\t\t\t}\r\n\t\t}\r\n\t\tresp := x.(*confChangeResponse)\r\n\t\tif lg := s.getLogger(); lg != nil {\r\n\t\t\tlg.Info(\r\n\t\t\t\t\"applied a configuration change through raft\",\r\n\t\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\t\tzap.String(\"raft-conf-change\", cc.Type.String()),\r\n\t\t\t\tzap.String(\"raft-conf-change-node-id\", types.ID(cc.NodeID).String()),\r\n\t\t\t)\r\n\t\t}\r\n\t\treturn resp.membs, resp.err\r\n\tcase <-ctx.Done():\r\n\t\ts.w.Trigger(cc.ID, nil)\r\n\t\treturn nil, s.parseProposeCtxErr(ctx.Err(), start)\r\n\tcase <-s.stopping:\r\n\t\treturn nil, ErrStopped\r\n\t}\r\n}","code-length":434,"reference":"\/\/ configure sends a configuration change through consensus and\n\/\/ then waits for it to be applied to the server. It\n\/\/ will block until the change is performed or there is an error.","result":"Configure raft members.","score":[0,0.0162]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) sync(timeout time.Duration) {\r\n\treq := pb.Request{\r\n\t\tMethod: \"SYNC\",\r\n\t\tID:     s.reqIDGen.Next(),\r\n\t\tTime:   time.Now().UnixNano(),\r\n\t}\r\n\tdata := pbutil.MustMarshal(&req)\r\n\t\r\n\t\r\n\tctx, cancel := context.WithTimeout(s.ctx, timeout)\r\n\ts.goAttach(func() {\r\n\t\ts.r.Propose(ctx, data)\r\n\t\tcancel()\r\n\t})\r\n}","code-length":152,"reference":"\/\/ sync proposes a SYNC request and is non-blocking.\n\/\/ This makes no guarantee that the request will be proposed or performed.\n\/\/ The request will be canceled after the given timeout.","result":"Sync the etcd server.","score":[0.0003,0.0342]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) publish(timeout time.Duration) {\r\n\tb, err := json.Marshal(s.attributes)\r\n\tif err != nil {\r\n\t\tif lg := s.getLogger(); lg != nil {\r\n\t\t\tlg.Panic(\"failed to marshal JSON\", zap.Error(err))\r\n\t\t} else {\r\n\t\t\tplog.Panicf(\"json marshal error: %v\", err)\r\n\t\t}\r\n\t\treturn\r\n\t}\r\n\treq := pb.Request{\r\n\t\tMethod: \"PUT\",\r\n\t\tPath:   membership.MemberAttributesStorePath(s.id),\r\n\t\tVal:    string(b),\r\n\t}\r\n\tfor {\r\n\t\tctx, cancel := context.WithTimeout(s.ctx, timeout)\r\n\t\t_, err := s.Do(ctx, req)\r\n\t\tcancel()\r\n\t\tswitch err {\r\n\t\tcase nil:\r\n\t\t\tclose(s.readych)\r\n\t\t\tif lg := s.getLogger(); lg != nil {\r\n\t\t\t\tlg.Info(\r\n\t\t\t\t\t\"published local member to cluster through raft\",\r\n\t\t\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\t\t\tzap.String(\"local-member-attributes\", fmt.Sprintf(\"%+v\", s.attributes)),\r\n\t\t\t\t\tzap.String(\"request-path\", req.Path),\r\n\t\t\t\t\tzap.String(\"cluster-id\", s.cluster.ID().String()),\r\n\t\t\t\t\tzap.Duration(\"publish-timeout\", timeout),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Infof(\"published %+v to cluster %s\", s.attributes, s.cluster.ID())\r\n\t\t\t}\r\n\t\t\treturn\r\n\t\tcase ErrStopped:\r\n\t\t\tif lg := s.getLogger(); lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"stopped publish because server is stopped\",\r\n\t\t\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\t\t\tzap.String(\"local-member-attributes\", fmt.Sprintf(\"%+v\", s.attributes)),\r\n\t\t\t\t\tzap.Duration(\"publish-timeout\", timeout),\r\n\t\t\t\t\tzap.Error(err),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Infof(\"aborting publish because server is stopped\")\r\n\t\t\t}\r\n\t\t\treturn\r\n\t\tdefault:\r\n\t\t\tif lg := s.getLogger(); lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"failed to publish local member to cluster through raft\",\r\n\t\t\t\t\tzap.String(\"local-member-id\", s.ID().String()),\r\n\t\t\t\t\tzap.String(\"local-member-attributes\", fmt.Sprintf(\"%+v\", s.attributes)),\r\n\t\t\t\t\tzap.String(\"request-path\", req.Path),\r\n\t\t\t\t\tzap.Duration(\"publish-timeout\", timeout),\r\n\t\t\t\t\tzap.Error(err),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Errorf(\"publish error: %v\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":780,"reference":"\/\/ publish registers server information into the cluster. The information\n\/\/ is the JSON representation of this server's member struct, updated with the\n\/\/ static clientURLs of the server.\n\/\/ The function keeps attempting to register until it succeeds,\n\/\/ or its server is stopped.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) applyEntryNormal(e *raftpb.Entry) {\r\n\tshouldApplyV3 := false\r\n\tif e.Index > s.consistIndex.ConsistentIndex() {\r\n\t\t\r\n\t\ts.consistIndex.setConsistentIndex(e.Index)\r\n\t\tshouldApplyV3 = true\r\n\t}\r\n\t\r\n\t\r\n\tif len(e.Data) == 0 {\r\n\t\tselect {\r\n\t\tcase s.forceVersionC <- struct{}{}:\r\n\t\tdefault:\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tif s.isLeader() {\r\n\t\t\ts.lessor.Promote(s.Cfg.electionTimeout())\r\n\t\t}\r\n\t\treturn\r\n\t}\r\n\tvar raftReq pb.InternalRaftRequest\r\n\tif !pbutil.MaybeUnmarshal(&raftReq, e.Data) {\r\n\t\tvar r pb.Request\r\n\t\trp := &r\r\n\t\tpbutil.MustUnmarshal(rp, e.Data)\r\n\t\ts.w.Trigger(r.ID, s.applyV2Request((*RequestV2)(rp)))\r\n\t\treturn\r\n\t}\r\n\tif raftReq.V2 != nil {\r\n\t\treq := (*RequestV2)(raftReq.V2)\r\n\t\ts.w.Trigger(req.ID, s.applyV2Request(req))\r\n\t\treturn\r\n\t}\r\n\t\r\n\tif !shouldApplyV3 {\r\n\t\treturn\r\n\t}\r\n\tid := raftReq.ID\r\n\tif id == 0 {\r\n\t\tid = raftReq.Header.ID\r\n\t}\r\n\tvar ar *applyResult\r\n\tneedResult := s.w.IsRegistered(id)\r\n\tif needResult || !noSideEffect(&raftReq) {\r\n\t\tif !needResult && raftReq.Txn != nil {\r\n\t\t\tremoveNeedlessRangeReqs(raftReq.Txn)\r\n\t\t}\r\n\t\tar = s.applyV3.Apply(&raftReq)\r\n\t}\r\n\tif ar == nil {\r\n\t\treturn\r\n\t}\r\n\tif ar.err != ErrNoSpace || len(s.alarmStore.Get(pb.AlarmType_NOSPACE)) > 0 {\r\n\t\ts.w.Trigger(id, ar)\r\n\t\treturn\r\n\t}\r\n\tif lg := s.getLogger(); lg != nil {\r\n\t\tlg.Warn(\r\n\t\t\t\"message exceeded backend quota; raising alarm\",\r\n\t\t\tzap.Int64(\"quota-size-bytes\", s.Cfg.QuotaBackendBytes),\r\n\t\t\tzap.String(\"quota-size\", humanize.Bytes(uint64(s.Cfg.QuotaBackendBytes))),\r\n\t\t\tzap.Error(ar.err),\r\n\t\t)\r\n\t} else {\r\n\t\tplog.Errorf(\"applying raft message exceeded backend quota\")\r\n\t}\r\n\ts.goAttach(func() {\r\n\t\ta := &pb.AlarmRequest{\r\n\t\t\tMemberID: uint64(s.ID()),\r\n\t\t\tAction:   pb.AlarmRequest_ACTIVATE,\r\n\t\t\tAlarm:    pb.AlarmType_NOSPACE,\r\n\t\t}\r\n\t\ts.raftRequest(s.ctx, pb.InternalRaftRequest{Alarm: a})\r\n\t\ts.w.Trigger(id, ar)\r\n\t})\r\n}","code-length":833,"reference":"\/\/ applyEntryNormal apples an EntryNormal type raftpb request to the EtcdServer","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) applyConfChange(cc raftpb.ConfChange, confState *raftpb.ConfState) (bool, error) {\r\n\tif err := s.cluster.ValidateConfigurationChange(cc); err != nil {\r\n\t\tcc.NodeID = raft.None\r\n\t\ts.r.ApplyConfChange(cc)\r\n\t\treturn false, err\r\n\t}\r\n\tlg := s.getLogger()\r\n\t*confState = *s.r.ApplyConfChange(cc)\r\n\tswitch cc.Type {\r\n\tcase raftpb.ConfChangeAddNode:\r\n\t\tm := new(membership.Member)\r\n\t\tif err := json.Unmarshal(cc.Context, m); err != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Panic(\"failed to unmarshal member\", zap.Error(err))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"unmarshal member should never fail: %v\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t\tif cc.NodeID != uint64(m.ID) {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Panic(\r\n\t\t\t\t\t\"got different member ID\",\r\n\t\t\t\t\tzap.String(\"member-id-from-config-change-entry\", types.ID(cc.NodeID).String()),\r\n\t\t\t\t\tzap.String(\"member-id-from-message\", m.ID.String()),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"nodeID should always be equal to member ID\")\r\n\t\t\t}\r\n\t\t}\r\n\t\ts.cluster.AddMember(m)\r\n\t\tif m.ID != s.id {\r\n\t\t\ts.r.transport.AddPeer(m.ID, m.PeerURLs)\r\n\t\t}\r\n\tcase raftpb.ConfChangeRemoveNode:\r\n\t\tid := types.ID(cc.NodeID)\r\n\t\ts.cluster.RemoveMember(id)\r\n\t\tif id == s.id {\r\n\t\t\treturn true, nil\r\n\t\t}\r\n\t\ts.r.transport.RemovePeer(id)\r\n\tcase raftpb.ConfChangeUpdateNode:\r\n\t\tm := new(membership.Member)\r\n\t\tif err := json.Unmarshal(cc.Context, m); err != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Panic(\"failed to unmarshal member\", zap.Error(err))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"unmarshal member should never fail: %v\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t\tif cc.NodeID != uint64(m.ID) {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Panic(\r\n\t\t\t\t\t\"got different member ID\",\r\n\t\t\t\t\tzap.String(\"member-id-from-config-change-entry\", types.ID(cc.NodeID).String()),\r\n\t\t\t\t\tzap.String(\"member-id-from-message\", m.ID.String()),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"nodeID should always be equal to member ID\")\r\n\t\t\t}\r\n\t\t}\r\n\t\ts.cluster.UpdateRaftAttributes(m.ID, m.RaftAttributes)\r\n\t\tif m.ID != s.id {\r\n\t\t\ts.r.transport.UpdatePeer(m.ID, m.PeerURLs)\r\n\t\t}\r\n\t}\r\n\treturn false, nil\r\n}","code-length":851,"reference":"\/\/ applyConfChange applies a ConfChange to the server. It is only\n\/\/ invoked with a ConfChange that has already passed through Raft","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) monitorVersions() {\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase <-s.forceVersionC:\r\n\t\tcase <-time.After(monitorVersionInterval):\r\n\t\tcase <-s.stopping:\r\n\t\t\treturn\r\n\t\t}\r\n\t\tif s.Leader() != s.ID() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tv := decideClusterVersion(s.getLogger(), getVersions(s.getLogger(), s.cluster, s.id, s.peerRt))\r\n\t\tif v != nil {\r\n\t\t\t\r\n\t\t\tv = &semver.Version{\r\n\t\t\t\tMajor: v.Major,\r\n\t\t\t\tMinor: v.Minor,\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif s.cluster.Version() == nil {\r\n\t\t\tverStr := version.MinClusterVersion\r\n\t\t\tif v != nil {\r\n\t\t\t\tverStr = v.String()\r\n\t\t\t}\r\n\t\t\ts.goAttach(func() { s.updateClusterVersion(verStr) })\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tif v != nil && s.cluster.Version().LessThan(*v) {\r\n\t\t\ts.goAttach(func() { s.updateClusterVersion(v.String()) })\r\n\t\t}\r\n\t}\r\n}","code-length":349,"reference":"\/\/ monitorVersions checks the member's version every monitorVersionInterval.\n\/\/ It updates the cluster version if all members agrees on a higher one.\n\/\/ It prints out log if there is a member with a higher version than the\n\/\/ local version.","result":"Monitor the cluster version.","score":[0.0,0.0402]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) goAttach(f func()) {\r\n\ts.wgMu.RLock()\r\n\tdefer s.wgMu.RUnlock()\r\n\tselect {\r\n\tcase <-s.stopping:\r\n\t\tif lg := s.getLogger(); lg != nil {\r\n\t\t\tlg.Warn(\"server has stopped; skipping goAttach\")\r\n\t\t} else {\r\n\t\t\tplog.Warning(\"server has stopped (skipping goAttach)\")\r\n\t\t}\r\n\t\treturn\r\n\tdefault:\r\n\t}\r\n\t\r\n\ts.wg.Add(1)\r\n\tgo func() {\r\n\t\tdefer s.wg.Done()\r\n\t\tf()\r\n\t}()\r\n}","code-length":184,"reference":"\/\/ goAttach creates a goroutine on a given function and tracks it using\n\/\/ the etcdserver waitgroup.","result":"Attach to the etcd server.","score":[0.0218,0.0316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRoundrobinBalanced(\r\n\tlg *zap.Logger,\r\n\tscs []balancer.SubConn,\r\n\taddrToSc map[resolver.Address]balancer.SubConn,\r\n\tscToAddr map[balancer.SubConn]resolver.Address,\r\n) Picker {\r\n\treturn &rrBalanced{\r\n\t\tlg:       lg,\r\n\t\tscs:      scs,\r\n\t\taddrToSc: addrToSc,\r\n\t\tscToAddr: scToAddr,\r\n\t}\r\n}","code-length":138,"reference":"\/\/ NewRoundrobinBalanced returns a new roundrobin balanced picker.","result":"Create a new Picker.","score":[0.1662,0.3363]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rb *rrBalanced) Pick(ctx context.Context, opts balancer.PickOptions) (balancer.SubConn, func(balancer.DoneInfo), error) {\r\n\trb.mu.RLock()\r\n\tn := len(rb.scs)\r\n\trb.mu.RUnlock()\r\n\tif n == 0 {\r\n\t\treturn nil, nil, balancer.ErrNoSubConnAvailable\r\n\t}\r\n\trb.mu.Lock()\r\n\tcur := rb.next\r\n\tsc := rb.scs[cur]\r\n\tpicked := rb.scToAddr[sc].Addr\r\n\trb.next = (rb.next + 1) % len(rb.scs)\r\n\trb.mu.Unlock()\r\n\trb.lg.Debug(\r\n\t\t\"picked\",\r\n\t\tzap.String(\"address\", picked),\r\n\t\tzap.Int(\"subconn-index\", cur),\r\n\t\tzap.Int(\"subconn-size\", n),\r\n\t)\r\n\tdoneFunc := func(info balancer.DoneInfo) {\r\n\t\t\r\n\t\tfss := []zapcore.Field{\r\n\t\t\tzap.Error(info.Err),\r\n\t\t\tzap.String(\"address\", picked),\r\n\t\t\tzap.Bool(\"success\", info.Err == nil),\r\n\t\t\tzap.Bool(\"bytes-sent\", info.BytesSent),\r\n\t\t\tzap.Bool(\"bytes-received\", info.BytesReceived),\r\n\t\t}\r\n\t\tif info.Err == nil {\r\n\t\t\trb.lg.Debug(\"balancer done\", fss...)\r\n\t\t} else {\r\n\t\t\trb.lg.Warn(\"balancer failed\", fss...)\r\n\t\t}\r\n\t}\r\n\treturn sc, doneFunc, nil\r\n}","code-length":435,"reference":"\/\/ Pick is called for every client request.","result":"Pick a subconn from the pool.","score":[0.1383,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTLSListener(l net.Listener, tlsinfo *TLSInfo) (net.Listener, error) {\r\n\tcheck := func(context.Context, *tls.Conn) error { return nil }\r\n\treturn newTLSListener(l, tlsinfo, check)\r\n}","code-length":72,"reference":"\/\/ NewTLSListener handshakes TLS connections and performs optional CRL checking.","result":"Create a new listener.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *tlsListener) acceptLoop() {\r\n\tvar wg sync.WaitGroup\r\n\tvar pendingMu sync.Mutex\r\n\tpending := make(map[net.Conn]struct{})\r\n\tctx, cancel := context.WithCancel(context.Background())\r\n\tdefer func() {\r\n\t\tcancel()\r\n\t\tpendingMu.Lock()\r\n\t\tfor c := range pending {\r\n\t\t\tc.Close()\r\n\t\t}\r\n\t\tpendingMu.Unlock()\r\n\t\twg.Wait()\r\n\t\tclose(l.donec)\r\n\t}()\r\n\tfor {\r\n\t\tconn, err := l.Listener.Accept()\r\n\t\tif err != nil {\r\n\t\t\tl.err = err\r\n\t\t\treturn\r\n\t\t}\r\n\t\tpendingMu.Lock()\r\n\t\tpending[conn] = struct{}{}\r\n\t\tpendingMu.Unlock()\r\n\t\twg.Add(1)\r\n\t\tgo func() {\r\n\t\t\tdefer func() {\r\n\t\t\t\tif conn != nil {\r\n\t\t\t\t\tconn.Close()\r\n\t\t\t\t}\r\n\t\t\t\twg.Done()\r\n\t\t\t}()\r\n\t\t\ttlsConn := conn.(*tls.Conn)\r\n\t\t\therr := tlsConn.Handshake()\r\n\t\t\tpendingMu.Lock()\r\n\t\t\tdelete(pending, conn)\r\n\t\t\tpendingMu.Unlock()\r\n\t\t\tif herr != nil {\r\n\t\t\t\tl.handshakeFailure(tlsConn, herr)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tif err := l.check(ctx, tlsConn); err != nil {\r\n\t\t\t\tl.handshakeFailure(tlsConn, err)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tselect {\r\n\t\t\tcase l.connc <- tlsConn:\r\n\t\t\t\tconn = nil\r\n\t\t\tcase <-ctx.Done():\r\n\t\t\t}\r\n\t\t}()\r\n\t}\r\n}","code-length":476,"reference":"\/\/ acceptLoop launches each TLS handshake in a separate goroutine\n\/\/ to prevent a hanging TLS connection from blocking other connections.","result":"Avoid deadlock.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *ResolverGroup) SetEndpoints(endpoints []string) {\r\n\taddrs := epsToAddrs(endpoints...)\r\n\te.mu.Lock()\r\n\te.endpoints = endpoints\r\n\tfor _, r := range e.resolvers {\r\n\t\tr.cc.NewAddress(addrs)\r\n\t}\r\n\te.mu.Unlock()\r\n}","code-length":95,"reference":"\/\/ SetEndpoints updates the endpoints for ResolverGroup. All registered resolver are updated\n\/\/ immediately with the new endpoints.","result":"Set the endpoints of the resolver group.","score":[0.0564,0.1868]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *ResolverGroup) Target(endpoint string) string {\r\n\treturn Target(e.id, endpoint)\r\n}","code-length":38,"reference":"\/\/ Target constructs a endpoint target using the endpoint id of the ResolverGroup.","result":"Generate the code.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Target(id, endpoint string) string {\r\n\treturn fmt.Sprintf(\"%s:\r\n}","code-length":33,"reference":"\/\/ Target constructs a endpoint resolver target.","result":"Create the target .","score":[0,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *builder) Build(target resolver.Target, cc resolver.ClientConn, opts resolver.BuildOption) (resolver.Resolver, error) {\r\n\tif len(target.Authority) < 1 {\r\n\t\treturn nil, fmt.Errorf(\"'etcd' target scheme requires non-empty authority identifying etcd cluster being routed to\")\r\n\t}\r\n\tid := target.Authority\r\n\tes, err := b.getResolverGroup(id)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to build resolver: %v\", err)\r\n\t}\r\n\tr := &Resolver{\r\n\t\tendpointID: id,\r\n\t\tcc:         cc,\r\n\t}\r\n\tes.addResolver(r)\r\n\treturn r, nil\r\n}","code-length":194,"reference":"\/\/ Build creates or reuses an etcd resolver for the etcd cluster name identified by the authority part of the target.","result":"Generate code for the generated code.","score":[0.0224,0.0513]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *RequestV2) Handle(ctx context.Context, v2api RequestV2Handler) (Response, error) {\r\n\tif r.Method == \"GET\" && r.Quorum {\r\n\t\tr.Method = \"QGET\"\r\n\t}\r\n\tswitch r.Method {\r\n\tcase \"POST\":\r\n\t\treturn v2api.Post(ctx, r)\r\n\tcase \"PUT\":\r\n\t\treturn v2api.Put(ctx, r)\r\n\tcase \"DELETE\":\r\n\t\treturn v2api.Delete(ctx, r)\r\n\tcase \"QGET\":\r\n\t\treturn v2api.QGet(ctx, r)\r\n\tcase \"GET\":\r\n\t\treturn v2api.Get(ctx, r)\r\n\tcase \"HEAD\":\r\n\t\treturn v2api.Head(ctx, r)\r\n\t}\r\n\treturn Response{}, ErrUnknownMethod\r\n}","code-length":229,"reference":"\/\/ Handle interprets r and performs an operation on s.store according to r.Method\n\/\/ and other fields. If r.Method is \"POST\", \"PUT\", \"DELETE\", or a \"GET\" with\n\/\/ Quorum == true, r will be sent through consensus before performing its\n\/\/ respective operation. Do will block until an action is performed or there is\n\/\/ an error.","result":"Handle request v.","score":[0.0,0.0097]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewElectionCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"election [election name (defaults to 'elector')]\",\r\n\t\tShort: \"Performs election operation\",\r\n\t\tRun:   runElectionFunc,\r\n\t}\r\n\tcmd.Flags().IntVar(&totalClientConnections, \"total-client-connections\", 10, \"total number of client connections\")\r\n\treturn cmd\r\n}","code-length":121,"reference":"\/\/ NewElectionCommand returns the cobra command for \"election runner\".","result":"Create a new command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc nodeToMember(n *v2store.NodeExtern) (*Member, error) {\r\n\tm := &Member{ID: MustParseMemberIDFromKey(n.Key)}\r\n\tattrs := make(map[string][]byte)\r\n\traftAttrKey := path.Join(n.Key, raftAttributesSuffix)\r\n\tattrKey := path.Join(n.Key, attributesSuffix)\r\n\tfor _, nn := range n.Nodes {\r\n\t\tif nn.Key != raftAttrKey && nn.Key != attrKey {\r\n\t\t\treturn nil, fmt.Errorf(\"unknown key %q\", nn.Key)\r\n\t\t}\r\n\t\tattrs[nn.Key] = []byte(*nn.Value)\r\n\t}\r\n\tif data := attrs[raftAttrKey]; data != nil {\r\n\t\tif err := json.Unmarshal(data, &m.RaftAttributes); err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"unmarshal raftAttributes error: %v\", err)\r\n\t\t}\r\n\t} else {\r\n\t\treturn nil, fmt.Errorf(\"raftAttributes key doesn't exist\")\r\n\t}\r\n\tif data := attrs[attrKey]; data != nil {\r\n\t\tif err := json.Unmarshal(data, &m.Attributes); err != nil {\r\n\t\t\treturn m, fmt.Errorf(\"unmarshal attributes error: %v\", err)\r\n\t\t}\r\n\t}\r\n\treturn m, nil\r\n}","code-length":353,"reference":"\/\/ nodeToMember builds member from a key value node.\n\/\/ the child nodes of the given node MUST be sorted by key.","result":"Convert a node to a member .","score":[0.0249,0.0732]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTmpBackend(batchInterval time.Duration, batchLimit int) (*backend, string) {\r\n\tdir, err := ioutil.TempDir(os.TempDir(), \"etcd_backend_test\")\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\ttmpPath := filepath.Join(dir, \"database\")\r\n\tbcfg := DefaultBackendConfig()\r\n\tbcfg.Path, bcfg.BatchInterval, bcfg.BatchLimit = tmpPath, batchInterval, batchLimit\r\n\treturn newBackend(bcfg), tmpPath\r\n}","code-length":145,"reference":"\/\/ NewTmpBackend creates a backend implementation for testing.","result":"Create a temporary backend.","score":[0.1175,0.2467]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newRevision(lg *zap.Logger, clock clockwork.Clock, retention int64, rg RevGetter, c Compactable) *Revision {\r\n\trc := &Revision{\r\n\t\tlg:        lg,\r\n\t\tclock:     clock,\r\n\t\tretention: retention,\r\n\t\trg:        rg,\r\n\t\tc:         c,\r\n\t}\r\n\trc.ctx, rc.cancel = context.WithCancel(context.Background())\r\n\treturn rc\r\n}","code-length":126,"reference":"\/\/ newRevision creates a new instance of Revisonal compactor that purges\n\/\/ the log older than retention revisions from the current revision.","result":"Create a new revision.","score":[0.0056,0.1856]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rc *Revision) Run() {\r\n\tprev := int64(0)\r\n\tgo func() {\r\n\t\tfor {\r\n\t\t\tselect {\r\n\t\t\tcase <-rc.ctx.Done():\r\n\t\t\t\treturn\r\n\t\t\tcase <-rc.clock.After(revInterval):\r\n\t\t\t\trc.mu.Lock()\r\n\t\t\t\tp := rc.paused\r\n\t\t\t\trc.mu.Unlock()\r\n\t\t\t\tif p {\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\trev := rc.rg.Rev() - rc.retention\r\n\t\t\tif rev <= 0 || rev == prev {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tnow := time.Now()\r\n\t\t\tif rc.lg != nil {\r\n\t\t\t\trc.lg.Info(\r\n\t\t\t\t\t\"starting auto revision compaction\",\r\n\t\t\t\t\tzap.Int64(\"revision\", rev),\r\n\t\t\t\t\tzap.Int64(\"revision-compaction-retention\", rc.retention),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Noticef(\"Starting auto-compaction at revision %d (retention: %d revisions)\", rev, rc.retention)\r\n\t\t\t}\r\n\t\t\t_, err := rc.c.Compact(rc.ctx, &pb.CompactionRequest{Revision: rev})\r\n\t\t\tif err == nil || err == mvcc.ErrCompacted {\r\n\t\t\t\tprev = rev\r\n\t\t\t\tif rc.lg != nil {\r\n\t\t\t\t\trc.lg.Info(\r\n\t\t\t\t\t\t\"completed auto revision compaction\",\r\n\t\t\t\t\t\tzap.Int64(\"revision\", rev),\r\n\t\t\t\t\t\tzap.Int64(\"revision-compaction-retention\", rc.retention),\r\n\t\t\t\t\t\tzap.Duration(\"took\", time.Since(now)),\r\n\t\t\t\t\t)\r\n\t\t\t\t} else {\r\n\t\t\t\t\tplog.Noticef(\"Finished auto-compaction at revision %d\", rev)\r\n\t\t\t\t}\r\n\t\t\t} else {\r\n\t\t\t\tif rc.lg != nil {\r\n\t\t\t\t\trc.lg.Warn(\r\n\t\t\t\t\t\t\"failed auto revision compaction\",\r\n\t\t\t\t\t\tzap.Int64(\"revision\", rev),\r\n\t\t\t\t\t\tzap.Int64(\"revision-compaction-retention\", rc.retention),\r\n\t\t\t\t\t\tzap.Duration(\"retry-interval\", revInterval),\r\n\t\t\t\t\t\tzap.Error(err),\r\n\t\t\t\t\t)\r\n\t\t\t\t} else {\r\n\t\t\t\t\tplog.Noticef(\"Failed auto-compaction at revision %d (%v)\", rev, err)\r\n\t\t\t\t\tplog.Noticef(\"Retry after %v\", revInterval)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}()\r\n}","code-length":663,"reference":"\/\/ Run runs revision-based compactor.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rc *Revision) Pause() {\r\n\trc.mu.Lock()\r\n\trc.paused = true\r\n\trc.mu.Unlock()\r\n}","code-length":48,"reference":"\/\/ Pause pauses revision-based compactor.","result":"Pause the revision.","score":[0.2096,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rc *Revision) Resume() {\r\n\trc.mu.Lock()\r\n\trc.paused = false\r\n\trc.mu.Unlock()\r\n}","code-length":49,"reference":"\/\/ Resume resumes revision-based compactor.","result":"Avoid recursive call to Resume.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc voteRespMsgType(msgt pb.MessageType) pb.MessageType {\r\n\tswitch msgt {\r\n\tcase pb.MsgVote:\r\n\t\treturn pb.MsgVoteResp\r\n\tcase pb.MsgPreVote:\r\n\t\treturn pb.MsgPreVoteResp\r\n\tdefault:\r\n\t\tpanic(fmt.Sprintf(\"not a vote message: %s\", msgt))\r\n\t}\r\n}","code-length":107,"reference":"\/\/ voteResponseType maps vote and prevote message types to their corresponding responses.","result":"Generate the vote response message.","score":[0.0593,0.0442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DescribeMessage(m pb.Message, f EntryFormatter) string {\r\n\tvar buf bytes.Buffer\r\n\tfmt.Fprintf(&buf, \"%x->%x %v Term:%d Log:%d\/%d\", m.From, m.To, m.Type, m.Term, m.LogTerm, m.Index)\r\n\tif m.Reject {\r\n\t\tfmt.Fprintf(&buf, \" Rejected (Hint: %d)\", m.RejectHint)\r\n\t}\r\n\tif m.Commit != 0 {\r\n\t\tfmt.Fprintf(&buf, \" Commit:%d\", m.Commit)\r\n\t}\r\n\tif len(m.Entries) > 0 {\r\n\t\tfmt.Fprintf(&buf, \" Entries:[\")\r\n\t\tfor i, e := range m.Entries {\r\n\t\t\tif i != 0 {\r\n\t\t\t\tbuf.WriteString(\", \")\r\n\t\t\t}\r\n\t\t\tbuf.WriteString(DescribeEntry(e, f))\r\n\t\t}\r\n\t\tfmt.Fprintf(&buf, \"]\")\r\n\t}\r\n\tif !IsEmptySnap(m.Snapshot) {\r\n\t\tfmt.Fprintf(&buf, \" Snapshot:%v\", m.Snapshot)\r\n\t}\r\n\treturn buf.String()\r\n}","code-length":316,"reference":"\/\/ DescribeMessage returns a concise human-readable description of a\n\/\/ Message for debugging.","result":"Describe a message.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DescribeEntry(e pb.Entry, f EntryFormatter) string {\r\n\tvar formatted string\r\n\tif e.Type == pb.EntryNormal && f != nil {\r\n\t\tformatted = f(e.Data)\r\n\t} else {\r\n\t\tformatted = fmt.Sprintf(\"%q\", e.Data)\r\n\t}\r\n\treturn fmt.Sprintf(\"%d\/%d %s %s\", e.Term, e.Index, e.Type, formatted)\r\n}","code-length":120,"reference":"\/\/ DescribeEntry returns a concise human-readable description of an\n\/\/ Entry for debugging.","result":"Describe the entry.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DescribeEntries(ents []pb.Entry, f EntryFormatter) string {\r\n\tvar buf bytes.Buffer\r\n\tfor _, e := range ents {\r\n\t\t_, _ = buf.WriteString(DescribeEntry(e, f) + \"\\n\")\r\n\t}\r\n\treturn buf.String()\r\n}","code-length":84,"reference":"\/\/ DescribeEntries calls DescribeEntry for each Entry, adding a newline to\n\/\/ each.","result":"Describe entries.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetLogger(l grpclog.LoggerV2) {\r\n\tlgMu.Lock()\r\n\tlg = logutil.NewLogger(l)\r\n\t\r\n\tgrpclog.SetLoggerV2(lg)\r\n\tlgMu.Unlock()\r\n}","code-length":70,"reference":"\/\/ SetLogger sets client-side Logger.","result":"Set the logger.","score":[0,0.2083]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetLogger() logutil.Logger {\r\n\tlgMu.RLock()\r\n\tl := lg\r\n\tlgMu.RUnlock()\r\n\treturn l\r\n}","code-length":50,"reference":"\/\/ GetLogger returns the current logutil.Logger.","result":"Get the logger.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *unstable) maybeFirstIndex() (uint64, bool) {\r\n\tif u.snapshot != nil {\r\n\t\treturn u.snapshot.Metadata.Index + 1, true\r\n\t}\r\n\treturn 0, false\r\n}","code-length":67,"reference":"\/\/ maybeFirstIndex returns the index of the first possible entry in entries\n\/\/ if it has a snapshot.","result":"Determine if the index is first index of the unstable.","score":[0.1284,0.2972]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *unstable) maybeLastIndex() (uint64, bool) {\r\n\tif l := len(u.entries); l != 0 {\r\n\t\treturn u.offset + uint64(l) - 1, true\r\n\t}\r\n\tif u.snapshot != nil {\r\n\t\treturn u.snapshot.Metadata.Index, true\r\n\t}\r\n\treturn 0, false\r\n}","code-length":103,"reference":"\/\/ maybeLastIndex returns the last index if it has at least one\n\/\/ unstable entry or snapshot.","result":"Determine if the last index is stable.","score":[0.0857,0.2344]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *unstable) maybeTerm(i uint64) (uint64, bool) {\r\n\tif i < u.offset {\r\n\t\tif u.snapshot == nil {\r\n\t\t\treturn 0, false\r\n\t\t}\r\n\t\tif u.snapshot.Metadata.Index == i {\r\n\t\t\treturn u.snapshot.Metadata.Term, true\r\n\t\t}\r\n\t\treturn 0, false\r\n\t}\r\n\tlast, ok := u.maybeLastIndex()\r\n\tif !ok {\r\n\t\treturn 0, false\r\n\t}\r\n\tif i > last {\r\n\t\treturn 0, false\r\n\t}\r\n\treturn u.entries[i-u.offset].Term, true\r\n}","code-length":182,"reference":"\/\/ maybeTerm returns the term of the entry at index i, if there\n\/\/ is any.","result":"Check the term of the entry.","score":[0.1141,0.2646]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *unstable) shrinkEntriesArray() {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tconst lenMultiple = 2\r\n\tif len(u.entries) == 0 {\r\n\t\tu.entries = nil\r\n\t} else if len(u.entries)*lenMultiple < cap(u.entries) {\r\n\t\tnewEntries := make([]pb.Entry, len(u.entries))\r\n\t\tcopy(newEntries, u.entries)\r\n\t\tu.entries = newEntries\r\n\t}\r\n}","code-length":135,"reference":"\/\/ shrinkEntriesArray discards the underlying array used by the entries slice\n\/\/ if most of it isn't being used. This avoids holding references to a bunch of\n\/\/ potentially large entries that aren't needed anymore. Simply clearing the\n\/\/ entries wouldn't be safe because clients might still be using them.","result":"Shrink entries array.","score":[0.0,0.011]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (st *storage) SaveSnap(snap raftpb.Snapshot) error {\r\n\twalsnap := walpb.Snapshot{\r\n\t\tIndex: snap.Metadata.Index,\r\n\t\tTerm:  snap.Metadata.Term,\r\n\t}\r\n\terr := st.WAL.SaveSnapshot(walsnap)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = st.Snapshotter.SaveSnap(snap)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn st.WAL.ReleaseLockTo(snap.Metadata.Index)\r\n}","code-length":157,"reference":"\/\/ SaveSnap saves the snapshot to disk and release the locked\n\/\/ wal files since they will not be used.","result":"Save snapshot.","score":[0,0.0275]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(cfg Config) (*Client, error) {\r\n\tif len(cfg.Endpoints) == 0 {\r\n\t\treturn nil, ErrNoAvailableEndpoints\r\n\t}\r\n\treturn newClient(&cfg)\r\n}","code-length":61,"reference":"\/\/ New creates a new etcdv3 client from a given configuration.","result":"Create a new client.","score":[0.0785,0.1456]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCtxClient(ctx context.Context) *Client {\r\n\tcctx, cancel := context.WithCancel(ctx)\r\n\treturn &Client{ctx: cctx, cancel: cancel}\r\n}","code-length":56,"reference":"\/\/ NewCtxClient creates a client with a context but no underlying grpc\n\/\/ connection. This is useful for embedded cases that override the\n\/\/ service interface implementations and do not need connection management.","result":"Create a new client.","score":[0.0002,0.0332]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFromURL(url string) (*Client, error) {\r\n\treturn New(Config{Endpoints: []string{url}})\r\n}","code-length":43,"reference":"\/\/ NewFromURL creates a new etcdv3 client from a URL.","result":"Create a new client.","score":[0.1008,0.1596]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Close() error {\r\n\tc.cancel()\r\n\tc.Watcher.Close()\r\n\tc.Lease.Close()\r\n\tif c.resolverGroup != nil {\r\n\t\tc.resolverGroup.Close()\r\n\t}\r\n\tif c.conn != nil {\r\n\t\treturn toErr(c.ctx, c.conn.Close())\r\n\t}\r\n\treturn c.ctx.Err()\r\n}","code-length":115,"reference":"\/\/ Close shuts down the client's etcd connections.","result":"Close the client.","score":[0.0917,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Endpoints() []string {\r\n\t\r\n\tc.mu.RLock()\r\n\tdefer c.mu.RUnlock()\r\n\teps := make([]string, len(c.cfg.Endpoints))\r\n\tcopy(eps, c.cfg.Endpoints)\r\n\treturn eps\r\n}","code-length":83,"reference":"\/\/ Endpoints lists the registered endpoints for the client.","result":"Get the endpoints of the client.","score":[0.1969,0.3628]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) SetEndpoints(eps ...string) {\r\n\tc.mu.Lock()\r\n\tdefer c.mu.Unlock()\r\n\tc.cfg.Endpoints = eps\r\n\tc.resolverGroup.SetEndpoints(eps)\r\n}","code-length":68,"reference":"\/\/ SetEndpoints updates client's endpoints.","result":"Set the endpoints of the client.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Sync(ctx context.Context) error {\r\n\tmresp, err := c.MemberList(ctx)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tvar eps []string\r\n\tfor _, m := range mresp.Members {\r\n\t\teps = append(eps, m.ClientURLs...)\r\n\t}\r\n\tc.SetEndpoints(eps...)\r\n\treturn nil\r\n}","code-length":115,"reference":"\/\/ Sync synchronizes client's endpoints with the known endpoints from the etcd membership.","result":"Sync members.","score":[0.002,0.042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) dialSetupOpts(creds *credentials.TransportCredentials, dopts ...grpc.DialOption) (opts []grpc.DialOption, err error) {\r\n\tif c.cfg.DialKeepAliveTime > 0 {\r\n\t\tparams := keepalive.ClientParameters{\r\n\t\t\tTime:                c.cfg.DialKeepAliveTime,\r\n\t\t\tTimeout:             c.cfg.DialKeepAliveTimeout,\r\n\t\t\tPermitWithoutStream: c.cfg.PermitWithoutStream,\r\n\t\t}\r\n\t\topts = append(opts, grpc.WithKeepaliveParams(params))\r\n\t}\r\n\topts = append(opts, dopts...)\r\n\t\r\n\tf := func(dialEp string, t time.Duration) (net.Conn, error) {\r\n\t\tproto, host, _ := endpoint.ParseEndpoint(dialEp)\r\n\t\tselect {\r\n\t\tcase <-c.ctx.Done():\r\n\t\t\treturn nil, c.ctx.Err()\r\n\t\tdefault:\r\n\t\t}\r\n\t\tdialer := &net.Dialer{Timeout: t}\r\n\t\treturn dialer.DialContext(c.ctx, proto, host)\r\n\t}\r\n\topts = append(opts, grpc.WithDialer(f))\r\n\tif creds != nil {\r\n\t\topts = append(opts, grpc.WithTransportCredentials(*creds))\r\n\t} else {\r\n\t\topts = append(opts, grpc.WithInsecure())\r\n\t}\r\n\t\r\n\t\r\n\ttBetween, defaultBackoffJitterFraction))\r\n\topts = append(opts,\r\n\t\t\r\n\t\t\r\n\t\tgrpc.WithStreamInterceptor(c.streamClientInterceptor(c.lg, withMax(0), rrBackoff)),\r\n\t\tgrpc.WithUnaryInterceptor(c.unaryClientInterceptor(c.lg, withMax(defaultUnaryMaxRetries), rrBackoff)),\r\n\t)\r\n\treturn opts, nil\r\n}","code-length":461,"reference":"\/\/ dialSetupOpts gives the dial opts prior to any authentication.","result":"Create a new client.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Dial(ep string) (*grpc.ClientConn, error) {\r\n\tcreds := c.directDialCreds(ep)\r\n\t\r\n\t\r\n\t\r\n\t\r\n\treturn c.dial(fmt.Sprintf(\"passthrough:\r\n}","code-length":75,"reference":"\/\/ Dial connects to a single endpoint using the client's config.","result":"Connect to the endpoint.","score":[0.066,0.2481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) dialWithBalancer(ep string, dopts ...grpc.DialOption) (*grpc.ClientConn, error) {\r\n\t_, host, _ := endpoint.ParseEndpoint(ep)\r\n\ttarget := c.resolverGroup.Target(host)\r\n\tcreds := c.dialWithBalancerCreds(ep)\r\n\treturn c.dial(target, creds, dopts...)\r\n}","code-length":102,"reference":"\/\/ dialWithBalancer dials the client's current load balanced resolver group.  The scheme of the host\n\/\/ of the provided endpoint determines the scheme used for all endpoints of the client connection.","result":"Dial with balancer.","score":[0,0.0177]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) dial(target string, creds *credentials.TransportCredentials, dopts ...grpc.DialOption) (*grpc.ClientConn, error) {\r\n\topts, err := c.dialSetupOpts(creds, dopts...)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to configure dialer: %v\", err)\r\n\t}\r\n\tif c.Username != \"\" && c.Password != \"\" {\r\n\t\tc.tokenCred = &authTokenCredential{\r\n\t\t\ttokenMu: &sync.RWMutex{},\r\n\t\t}\r\n\t\tctx, cancel := c.ctx, func() {}\r\n\t\tif c.cfg.DialTimeout > 0 {\r\n\t\t\tctx, cancel = context.WithTimeout(ctx, c.cfg.DialTimeout)\r\n\t\t}\r\n\t\terr = c.getToken(ctx)\r\n\t\tif err != nil {\r\n\t\t\tif toErr(ctx, err) != rpctypes.ErrAuthNotEnabled {\r\n\t\t\t\tif err == ctx.Err() && ctx.Err() != c.ctx.Err() {\r\n\t\t\t\t\terr = context.DeadlineExceeded\r\n\t\t\t\t}\r\n\t\t\t\tcancel()\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\topts = append(opts, grpc.WithPerRPCCredentials(c.tokenCred))\r\n\t\t}\r\n\t\tcancel()\r\n\t}\r\n\topts = append(opts, c.cfg.DialOptions...)\r\n\tdctx := c.ctx\r\n\tif c.cfg.DialTimeout > 0 {\r\n\t\tvar cancel context.CancelFunc\r\n\t\tdctx, cancel = context.WithTimeout(c.ctx, c.cfg.DialTimeout)\r\n\t\tdefer cancel()\r\n\t}\r\n\tconn, err := grpc.DialContext(dctx, target, opts...)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn conn, nil\r\n}","code-length":480,"reference":"\/\/ dial configures and dials any grpc balancer target.","result":"Connect to the server.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WithRequireLeader(ctx context.Context) context.Context {\r\n\tmd := metadata.Pairs(rpctypes.MetadataRequireLeaderKey, rpctypes.MetadataHasLeader)\r\n\treturn metadata.NewOutgoingContext(ctx, md)\r\n}","code-length":66,"reference":"\/\/ WithRequireLeader requires client requests to only succeed\n\/\/ when the cluster has a leader.","result":"Disable the leader check.","score":[0.0204,0.036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) roundRobinQuorumBackoff(waitBetween time.Duration, jitterFraction float64) backoffFunc {\r\n\treturn func(attempt uint) time.Duration {\r\n\t\t\r\n\t\tn := uint(len(c.Endpoints()))\r\n\t\tquorum := (n\/2 + 1)\r\n\t\tif attempt%quorum == 0 {\r\n\t\t\tc.lg.Debug(\"backoff\", zap.Uint(\"attempt\", attempt), zap.Uint(\"quorum\", quorum), zap.Duration(\"waitBetween\", waitBetween), zap.Float64(\"jitterFraction\", jitterFraction))\r\n\t\t\treturn jitterUp(waitBetween, jitterFraction)\r\n\t\t}\r\n\t\tc.lg.Debug(\"backoff skipped\", zap.Uint(\"attempt\", attempt), zap.Uint(\"quorum\", quorum))\r\n\t\treturn 0\r\n\t}\r\n}","code-length":207,"reference":"\/\/ roundRobinQuorumBackoff retries against quorum between each backoff.\n\/\/ This is intended for use with a round robin load balancer.","result":"Avoid the need for the following code.","score":[0.0252,0.0267]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isHaltErr(ctx context.Context, err error) bool {\r\n\tif ctx != nil && ctx.Err() != nil {\r\n\t\treturn true\r\n\t}\r\n\tif err == nil {\r\n\t\treturn false\r\n\t}\r\n\tev, _ := status.FromError(err)\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\treturn ev.Code() != codes.Unavailable && ev.Code() != codes.Internal\r\n}","code-length":123,"reference":"\/\/ isHaltErr returns true if the given error and context indicate no forward\n\/\/ progress can be made, even after reconnecting.","result":"Check if the error is a halt error.","score":[0.0428,0.1602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLease(l clientv3.Lease, prefix string) clientv3.Lease {\r\n\treturn &leasePrefix{l, []byte(prefix)}\r\n}","code-length":47,"reference":"\/\/ NewLease wraps a Lease interface to filter for only keys with a prefix\n\/\/ and remove that prefix when fetching attached keys through TimeToLive.","result":"Create a new lease.","score":[0.0017,0.0218]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Event) IsCreate() bool {\r\n\treturn e.Type == EventTypePut && e.Kv.CreateRevision == e.Kv.ModRevision\r\n}","code-length":49,"reference":"\/\/ IsCreate returns true if the event tells that the key is newly created.","result":"Check if an event is created.","score":[0.072,0.1515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wr *WatchResponse) Err() error {\r\n\tswitch {\r\n\tcase wr.closeErr != nil:\r\n\t\treturn v3rpc.Error(wr.closeErr)\r\n\tcase wr.CompactRevision != 0:\r\n\t\treturn v3rpc.ErrCompacted\r\n\tcase wr.Canceled:\r\n\t\tif len(wr.cancelReason) != 0 {\r\n\t\t\treturn v3rpc.Error(status.Error(codes.FailedPrecondition, wr.cancelReason))\r\n\t\t}\r\n\t\treturn v3rpc.ErrFutureRev\r\n\t}\r\n\treturn nil\r\n}","code-length":156,"reference":"\/\/ Err is the error value if this WatchResponse holds an error.","result":"Return errors from the WatchResponse.","score":[0.0593,0.0885]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wr *WatchResponse) IsProgressNotify() bool {\r\n\treturn len(wr.Events) == 0 && !wr.Canceled && !wr.Created && wr.CompactRevision == 0 && wr.Header.Revision != 0\r\n}","code-length":66,"reference":"\/\/ IsProgressNotify returns true if the WatchResponse is progress notification.","result":"Detect progress notifications.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *watcher) RequestProgress(ctx context.Context) (err error) {\r\n\tctxKey := streamKeyFromCtx(ctx)\r\n\tw.mu.Lock()\r\n\tif w.streams == nil {\r\n\t\treturn fmt.Errorf(\"no stream found for context\")\r\n\t}\r\n\twgs := w.streams[ctxKey]\r\n\tif wgs == nil {\r\n\t\twgs = w.newWatcherGrpcStream(ctx)\r\n\t\tw.streams[ctxKey] = wgs\r\n\t}\r\n\tdonec := wgs.donec\r\n\treqc := wgs.reqc\r\n\tw.mu.Unlock()\r\n\tpr := &progressRequest{}\r\n\tselect {\r\n\tcase reqc <- pr:\r\n\t\treturn nil\r\n\tcase <-ctx.Done():\r\n\t\tif err == nil {\r\n\t\t\treturn ctx.Err()\r\n\t\t}\r\n\t\treturn err\r\n\tcase <-donec:\r\n\t\tif wgs.closeErr != nil {\r\n\t\t\treturn wgs.closeErr\r\n\t\t}\r\n\t\t\r\n\t\treturn w.RequestProgress(ctx)\r\n\t}\r\n}","code-length":292,"reference":"\/\/ RequestProgress requests a progress notify response be sent in all watch channels.","result":"Request progress on the server.","score":[0.0485,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *watchGrpcStream) nextResume() *watcherStream {\r\n\tfor len(w.resuming) != 0 {\r\n\t\tif w.resuming[0] != nil {\r\n\t\t\treturn w.resuming[0]\r\n\t\t}\r\n\t\tw.resuming = w.resuming[1:len(w.resuming)]\r\n\t}\r\n\treturn nil\r\n}","code-length":106,"reference":"\/\/ nextResume chooses the next resuming to register with the grpc stream. Abandoned\n\/\/ streams are marked as nil in the queue since the head must wait for its inflight registration.","result":"Resume the stream.","score":[0.0,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *watchGrpcStream) dispatchEvent(pbresp *pb.WatchResponse) bool {\r\n\tevents := make([]*Event, len(pbresp.Events))\r\n\tfor i, ev := range pbresp.Events {\r\n\t\tevents[i] = (*Event)(ev)\r\n\t}\r\n\t\r\n\twr := &WatchResponse{\r\n\t\tHeader:          *pbresp.Header,\r\n\t\tEvents:          events,\r\n\t\tCompactRevision: pbresp.CompactRevision,\r\n\t\tCreated:         pbresp.Created,\r\n\t\tCanceled:        pbresp.Canceled,\r\n\t\tcancelReason:    pbresp.CancelReason,\r\n\t}\r\n\t\r\n\t\r\n\tif wr.IsProgressNotify() && pbresp.WatchId == -1 {\r\n\t\treturn w.broadcastResponse(wr)\r\n\t}\r\n\treturn w.unicastResponse(wr, pbresp.WatchId)\r\n}","code-length":235,"reference":"\/\/ dispatchEvent sends a WatchResponse to the appropriate watcher stream","result":"Broadcast response to all watchers.","score":[0.0884,0.1053]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *watchGrpcStream) broadcastResponse(wr *WatchResponse) bool {\r\n\tfor _, ws := range w.substreams {\r\n\t\tselect {\r\n\t\tcase ws.recvc <- wr:\r\n\t\tcase <-ws.donec:\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":89,"reference":"\/\/ broadcastResponse send a watch response to all watch substreams.","result":"Broadcast the response to all substreams.","score":[0.2194,0.4646]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *watchGrpcStream) unicastResponse(wr *WatchResponse, watchId int64) bool {\r\n\tws, ok := w.substreams[watchId]\r\n\tif !ok {\r\n\t\treturn false\r\n\t}\r\n\tselect {\r\n\tcase ws.recvc <- wr:\r\n\tcase <-ws.donec:\r\n\t\treturn false\r\n\t}\r\n\treturn true\r\n}","code-length":111,"reference":"\/\/ unicastResponse sends a watch response to a specific watch substream.","result":"Unicast the response to the client.","score":[0.1187,0.1786]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *watchGrpcStream) joinSubstreams() {\r\n\tfor _, ws := range w.substreams {\r\n\t\t<-ws.donec\r\n\t}\r\n\tfor _, ws := range w.resuming {\r\n\t\tif ws != nil {\r\n\t\t\t<-ws.donec\r\n\t\t}\r\n\t}\r\n}","code-length":96,"reference":"\/\/ joinSubstreams waits for all substream goroutines to complete.","result":"Join substreams.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wr *watchRequest) toPB() *pb.WatchRequest {\r\n\treq := &pb.WatchCreateRequest{\r\n\t\tStartRevision:  wr.rev,\r\n\t\tKey:            []byte(wr.key),\r\n\t\tRangeEnd:       []byte(wr.end),\r\n\t\tProgressNotify: wr.progressNotify,\r\n\t\tFilters:        wr.filters,\r\n\t\tPrevKv:         wr.prevKV,\r\n\t\tFragment:       wr.fragment,\r\n\t}\r\n\tcr := &pb.WatchRequest_CreateRequest{CreateRequest: req}\r\n\treturn &pb.WatchRequest{RequestUnion: cr}\r\n}","code-length":170,"reference":"\/\/ toPB converts an internal watch request structure to its protobuf WatchRequest structure.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pr *progressRequest) toPB() *pb.WatchRequest {\r\n\treq := &pb.WatchProgressRequest{}\r\n\tcr := &pb.WatchRequest_ProgressRequest{ProgressRequest: req}\r\n\treturn &pb.WatchRequest{RequestUnion: cr}\r\n}","code-length":74,"reference":"\/\/ toPB converts an internal progress request structure to its protobuf WatchRequest structure.","result":"Convert progressRequest to pb.","score":[0.0337,0.0826]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (us *unsafeSet) Contains(value string) (exists bool) {\r\n\t_, exists = us.d[value]\r\n\treturn exists\r\n}","code-length":48,"reference":"\/\/ Contains returns whether the set contains the given value","result":"Check unsafeSet equality.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (us *unsafeSet) ContainsAll(values []string) bool {\r\n\tfor _, s := range values {\r\n\t\tif !us.Contains(s) {\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":73,"reference":"\/\/ ContainsAll returns whether the set contains all given values","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (us *unsafeSet) Equals(other Set) bool {\r\n\tv1 := sort.StringSlice(us.Values())\r\n\tv2 := sort.StringSlice(other.Values())\r\n\tv1.Sort()\r\n\tv2.Sort()\r\n\treturn reflect.DeepEqual(v1, v2)\r\n}","code-length":88,"reference":"\/\/ Equals returns whether the contents of two sets are identical","result":"Compare unsafeSets.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (us *unsafeSet) Values() (values []string) {\r\n\tvalues = make([]string, 0)\r\n\tfor val := range us.d {\r\n\t\tvalues = append(values, val)\r\n\t}\r\n\treturn values\r\n}","code-length":72,"reference":"\/\/ Values returns the values of the Set in an unspecified order.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (us *unsafeSet) Copy() Set {\r\n\tcp := NewUnsafeSet()\r\n\tfor val := range us.d {\r\n\t\tcp.Add(val)\r\n\t}\r\n\treturn cp\r\n}","code-length":63,"reference":"\/\/ Copy creates a new Set containing the values of the first","result":"Copy unsafeSet.","score":[0.0034,0.0455]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (us *unsafeSet) Sub(other Set) Set {\r\n\toValues := other.Values()\r\n\tresult := us.Copy().(*unsafeSet)\r\n\tfor _, val := range oValues {\r\n\t\tif _, ok := result.d[val]; !ok {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tdelete(result.d, val)\r\n\t}\r\n\treturn result\r\n}","code-length":112,"reference":"\/\/ Sub removes all elements in other from the set","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc v2MembersURL(ep url.URL) *url.URL {\r\n\tep.Path = path.Join(ep.Path, defaultV2MembersPrefix)\r\n\treturn &ep\r\n}","code-length":55,"reference":"\/\/ v2MembersURL add the necessary path to the provided endpoint\n\/\/ to route requests to the default v2 members API.","result":"Members URL.","score":[0,0.0275]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMigrateCommand() *cobra.Command {\r\n\tmc := &cobra.Command{\r\n\t\tUse:   \"migrate\",\r\n\t\tShort: \"Migrates keys in a v2 store to a mvcc store\",\r\n\t\tRun:   migrateCommandFunc,\r\n\t}\r\n\tmc.Flags().BoolVar(&migrateExcludeTTLKey, \"no-ttl\", false, \"Do not convert TTL keys\")\r\n\tmc.Flags().StringVar(&migrateDatadir, \"data-dir\", \"\", \"Path to the data directory\")\r\n\tmc.Flags().StringVar(&migrateWALdir, \"wal-dir\", \"\", \"Path to the WAL directory\")\r\n\tmc.Flags().StringVar(&migrateTransformer, \"transformer\", \"\", \"Path to the user-provided transformer program\")\r\n\treturn mc\r\n}","code-length":204,"reference":"\/\/ NewMigrateCommand returns the cobra command for \"migrate\".","result":"Create a new command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rc *raftNode) publishEntries(ents []raftpb.Entry) bool {\r\n\tfor i := range ents {\r\n\t\tswitch ents[i].Type {\r\n\t\tcase raftpb.EntryNormal:\r\n\t\t\tif len(ents[i].Data) == 0 {\r\n\t\t\t\t\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\ts := string(ents[i].Data)\r\n\t\t\tselect {\r\n\t\t\tcase rc.commitC <- &s:\r\n\t\t\tcase <-rc.stopc:\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\tcase raftpb.EntryConfChange:\r\n\t\t\tvar cc raftpb.ConfChange\r\n\t\t\tcc.Unmarshal(ents[i].Data)\r\n\t\t\trc.confState = *rc.node.ApplyConfChange(cc)\r\n\t\t\tswitch cc.Type {\r\n\t\t\tcase raftpb.ConfChangeAddNode:\r\n\t\t\t\tif len(cc.Context) > 0 {\r\n\t\t\t\t\trc.transport.AddPeer(types.ID(cc.NodeID), []string{string(cc.Context)})\r\n\t\t\t\t}\r\n\t\t\tcase raftpb.ConfChangeRemoveNode:\r\n\t\t\t\tif cc.NodeID == uint64(rc.id) {\r\n\t\t\t\t\tlog.Println(\"I've been removed from the cluster! Shutting down.\")\r\n\t\t\t\t\treturn false\r\n\t\t\t\t}\r\n\t\t\t\trc.transport.RemovePeer(types.ID(cc.NodeID))\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\trc.appliedIndex = ents[i].Index\r\n\t\t\r\n\t\tif ents[i].Index == rc.lastIndex {\r\n\t\t\tselect {\r\n\t\t\tcase rc.commitC <- nil:\r\n\t\t\tcase <-rc.stopc:\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":460,"reference":"\/\/ publishEntries writes committed log entries to commit channel and returns\n\/\/ whether all entries could be published.","result":"Publish entries to the raft node.","score":[0.0369,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rc *raftNode) openWAL(snapshot *raftpb.Snapshot) *wal.WAL {\r\n\tif !wal.Exist(rc.waldir) {\r\n\t\tif err := os.Mkdir(rc.waldir, 0750); err != nil {\r\n\t\t\tlog.Fatalf(\"raftexample: cannot create dir for wal (%v)\", err)\r\n\t\t}\r\n\t\tw, err := wal.Create(zap.NewExample(), rc.waldir, nil)\r\n\t\tif err != nil {\r\n\t\t\tlog.Fatalf(\"raftexample: create wal error (%v)\", err)\r\n\t\t}\r\n\t\tw.Close()\r\n\t}\r\n\twalsnap := walpb.Snapshot{}\r\n\tif snapshot != nil {\r\n\t\twalsnap.Index, walsnap.Term = snapshot.Metadata.Index, snapshot.Metadata.Term\r\n\t}\r\n\tlog.Printf(\"loading WAL at term %d and index %d\", walsnap.Term, walsnap.Index)\r\n\tw, err := wal.Open(zap.NewExample(), rc.waldir, walsnap)\r\n\tif err != nil {\r\n\t\tlog.Fatalf(\"raftexample: error loading wal (%v)\", err)\r\n\t}\r\n\treturn w\r\n}","code-length":326,"reference":"\/\/ openWAL returns a WAL ready for reading.","result":"Create a new WAL.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rc *raftNode) replayWAL() *wal.WAL {\r\n\tlog.Printf(\"replaying WAL of member %d\", rc.id)\r\n\tsnapshot := rc.loadSnapshot()\r\n\tw := rc.openWAL(snapshot)\r\n\t_, st, ents, err := w.ReadAll()\r\n\tif err != nil {\r\n\t\tlog.Fatalf(\"raftexample: failed to read WAL (%v)\", err)\r\n\t}\r\n\trc.raftStorage = raft.NewMemoryStorage()\r\n\tif snapshot != nil {\r\n\t\trc.raftStorage.ApplySnapshot(*snapshot)\r\n\t}\r\n\trc.raftStorage.SetHardState(st)\r\n\t\r\n\trc.raftStorage.Append(ents)\r\n\t\r\n\tif len(ents) > 0 {\r\n\t\trc.lastIndex = ents[len(ents)-1].Index\r\n\t} else {\r\n\t\trc.commitC <- nil\r\n\t}\r\n\treturn w\r\n}","code-length":251,"reference":"\/\/ replayWAL replays WAL entries into the raft instance.","result":"Replay member.","score":[0,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rc *raftNode) stop() {\r\n\trc.stopHTTP()\r\n\tclose(rc.commitC)\r\n\tclose(rc.errorC)\r\n\trc.node.Stop()\r\n}","code-length":59,"reference":"\/\/ stop closes http, closes all channels, and stops raft.","result":"Stop the raft node.","score":[0,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewWatchCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"watch [options] [key or prefix] [range_end] [--] [exec-command arg1 arg2 ...]\",\r\n\t\tShort: \"Watches events stream on keys or prefixes\",\r\n\t\tRun:   watchCommandFunc,\r\n\t}\r\n\tcmd.Flags().BoolVarP(&watchInteractive, \"interactive\", \"i\", false, \"Interactive mode\")\r\n\tcmd.Flags().BoolVar(&watchPrefix, \"prefix\", false, \"Watch on a prefix if prefix is set\")\r\n\tcmd.Flags().Int64Var(&watchRev, \"rev\", 0, \"Revision to start watching\")\r\n\tcmd.Flags().BoolVar(&watchPrevKey, \"prev-kv\", false, \"get the previous key-value pair before the event happens\")\r\n\treturn cmd\r\n}","code-length":225,"reference":"\/\/ NewWatchCommand returns the cobra command for \"watch\".","result":"Create a command to watch events stream on a.","score":[0.1219,0.0617]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MemoryStorage) InitialState() (pb.HardState, pb.ConfState, error) {\r\n\treturn ms.hardState, ms.snapshot.Metadata.ConfState, nil\r\n}","code-length":55,"reference":"\/\/ InitialState implements the Storage interface.","result":"Store the state in memory.","score":[0.1967,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MemoryStorage) SetHardState(st pb.HardState) error {\r\n\tms.Lock()\r\n\tdefer ms.Unlock()\r\n\tms.hardState = st\r\n\treturn nil\r\n}","code-length":60,"reference":"\/\/ SetHardState saves the current HardState.","result":"Store the generated code.","score":[0.1938,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MemoryStorage) Entries(lo, hi, maxSize uint64) ([]pb.Entry, error) {\r\n\tms.Lock()\r\n\tdefer ms.Unlock()\r\n\toffset := ms.ents[0].Index\r\n\tif lo <= offset {\r\n\t\treturn nil, ErrCompacted\r\n\t}\r\n\tif hi > ms.lastIndex()+1 {\r\n\t\traftLogger.Panicf(\"entries' hi(%d) is out of bound lastindex(%d)\", hi, ms.lastIndex())\r\n\t}\r\n\t\r\n\tif len(ms.ents) == 1 {\r\n\t\treturn nil, ErrUnavailable\r\n\t}\r\n\tents := ms.ents[lo-offset : hi-offset]\r\n\treturn limitSize(ents, maxSize), nil\r\n}","code-length":196,"reference":"\/\/ Entries implements the Storage interface.","result":"Fetch the entries from the storage.","score":[0.193,0.1667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MemoryStorage) Term(i uint64) (uint64, error) {\r\n\tms.Lock()\r\n\tdefer ms.Unlock()\r\n\toffset := ms.ents[0].Index\r\n\tif i < offset {\r\n\t\treturn 0, ErrCompacted\r\n\t}\r\n\tif int(i-offset) >= len(ms.ents) {\r\n\t\treturn 0, ErrUnavailable\r\n\t}\r\n\treturn ms.ents[i-offset].Term, nil\r\n}","code-length":127,"reference":"\/\/ Term implements the Storage interface.","result":"Store the term in the storage.","score":[0.193,0.1667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MemoryStorage) LastIndex() (uint64, error) {\r\n\tms.Lock()\r\n\tdefer ms.Unlock()\r\n\treturn ms.lastIndex(), nil\r\n}","code-length":53,"reference":"\/\/ LastIndex implements the Storage interface.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MemoryStorage) FirstIndex() (uint64, error) {\r\n\tms.Lock()\r\n\tdefer ms.Unlock()\r\n\treturn ms.firstIndex(), nil\r\n}","code-length":54,"reference":"\/\/ FirstIndex implements the Storage interface.","result":"Generate the generated code.","score":[0.1938,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MemoryStorage) Snapshot() (pb.Snapshot, error) {\r\n\tms.Lock()\r\n\tdefer ms.Unlock()\r\n\treturn ms.snapshot, nil\r\n}","code-length":53,"reference":"\/\/ Snapshot implements the Storage interface.","result":"Generate the generated code.","score":[0.1938,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MemoryStorage) ApplySnapshot(snap pb.Snapshot) error {\r\n\tms.Lock()\r\n\tdefer ms.Unlock()\r\n\t\r\n\tmsIndex := ms.snapshot.Metadata.Index\r\n\tsnapIndex := snap.Metadata.Index\r\n\tif msIndex >= snapIndex {\r\n\t\treturn ErrSnapOutOfDate\r\n\t}\r\n\tms.snapshot = snap\r\n\tms.ents = []pb.Entry{{Term: snap.Metadata.Term, Index: snap.Metadata.Index}}\r\n\treturn nil\r\n}","code-length":135,"reference":"\/\/ ApplySnapshot overwrites the contents of this Storage object with\n\/\/ those of the given snapshot.","result":"Apply snapshot to the storage.","score":[0.0266,0.0336]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MemoryStorage) Compact(compactIndex uint64) error {\r\n\tms.Lock()\r\n\tdefer ms.Unlock()\r\n\toffset := ms.ents[0].Index\r\n\tif compactIndex <= offset {\r\n\t\treturn ErrCompacted\r\n\t}\r\n\tif compactIndex > ms.lastIndex() {\r\n\t\traftLogger.Panicf(\"compact %d is out of bound lastindex(%d)\", compactIndex, ms.lastIndex())\r\n\t}\r\n\ti := compactIndex - offset\r\n\tents := make([]pb.Entry, 1, 1+uint64(len(ms.ents))-i)\r\n\tents[0].Index = ms.ents[i].Index\r\n\tents[0].Term = ms.ents[i].Term\r\n\tents = append(ents, ms.ents[i+1:]...)\r\n\tms.ents = ents\r\n\treturn nil\r\n}","code-length":225,"reference":"\/\/ Compact discards all log entries prior to compactIndex.\n\/\/ It is the application's responsibility to not attempt to compact an index\n\/\/ greater than raftLog.applied.","result":"Avoid the need for the function to be executed.","score":[0.0219,0.0412]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *urlPicker) unreachable(u url.URL) {\r\n\tp.mu.Lock()\r\n\tdefer p.mu.Unlock()\r\n\tif u == p.urls[p.picked] {\r\n\t\tp.picked = (p.picked + 1) % len(p.urls)\r\n\t}\r\n}","code-length":90,"reference":"\/\/ unreachable notices the picker that the given url is unreachable,\n\/\/ and it should use other possible urls.","result":"Avoid circular references.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewEndpointCommand() *cobra.Command {\r\n\tec := &cobra.Command{\r\n\t\tUse:   \"endpoint <subcommand>\",\r\n\t\tShort: \"Endpoint related commands\",\r\n\t}\r\n\tec.PersistentFlags().BoolVar(&epClusterEndpoints, \"cluster\", false, \"use all endpoints from the cluster member list\")\r\n\tec.AddCommand(newEpHealthCommand())\r\n\tec.AddCommand(newEpStatusCommand())\r\n\tec.AddCommand(newEpHashKVCommand())\r\n\treturn ec\r\n}","code-length":141,"reference":"\/\/ NewEndpointCommand returns the cobra command for \"endpoint\".","result":"Create a new endpoint command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc epHealthCommandFunc(cmd *cobra.Command, args []string) {\r\n\tflags.SetPflagsFromEnv(\"ETCDCTL\", cmd.InheritedFlags())\r\n\tinitDisplayFromCmd(cmd)\r\n\tsec := secureCfgFromCmd(cmd)\r\n\tdt := dialTimeoutFromCmd(cmd)\r\n\tka := keepAliveTimeFromCmd(cmd)\r\n\tkat := keepAliveTimeoutFromCmd(cmd)\r\n\tauth := authCfgFromCmd(cmd)\r\n\tcfgs := []*v3.Config{}\r\n\tfor _, ep := range endpointsFromCluster(cmd) {\r\n\t\tcfg, err := newClientCfg([]string{ep}, dt, ka, kat, sec, auth)\r\n\t\tif err != nil {\r\n\t\t\tExitWithError(ExitBadArgs, err)\r\n\t\t}\r\n\t\tcfgs = append(cfgs, cfg)\r\n\t}\r\n\tvar wg sync.WaitGroup\r\n\thch := make(chan epHealth, len(cfgs))\r\n\tfor _, cfg := range cfgs {\r\n\t\twg.Add(1)\r\n\t\tgo func(cfg *v3.Config) {\r\n\t\t\tdefer wg.Done()\r\n\t\t\tep := cfg.Endpoints[0]\r\n\t\t\tcli, err := v3.New(*cfg)\r\n\t\t\tif err != nil {\r\n\t\t\t\thch <- epHealth{Ep: ep, Health: false, Error: err.Error()}\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tst := time.Now()\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tctx, cancel := commandCtx(cmd)\r\n\t\t\t_, err = cli.Get(ctx, \"health\")\r\n\t\t\tcancel()\r\n\t\t\teh := epHealth{Ep: ep, Health: false, Took: time.Since(st).String()}\r\n\t\t\t\r\n\t\t\tif err == nil || err == rpctypes.ErrPermissionDenied {\r\n\t\t\t\teh.Health = true\r\n\t\t\t} else {\r\n\t\t\t\teh.Error = err.Error()\r\n\t\t\t}\r\n\t\t\thch <- eh\r\n\t\t}(cfg)\r\n\t}\r\n\twg.Wait()\r\n\tclose(hch)\r\n\terrs := false\r\n\thealthList := []epHealth{}\r\n\tfor h := range hch {\r\n\t\thealthList = append(healthList, h)\r\n\t\tif h.Error != \"\" {\r\n\t\t\terrs = true\r\n\t\t}\r\n\t}\r\n\tdisplay.EndpointHealth(healthList)\r\n\tif errs {\r\n\t\tExitWithError(ExitError, fmt.Errorf(\"unhealthy cluster\"))\r\n\t}\r\n}","code-length":648,"reference":"\/\/ epHealthCommandFunc executes the \"endpoint-health\" command.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewElectCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"elect <election-name> [proposal]\",\r\n\t\tShort: \"Observes and participates in leader election\",\r\n\t\tRun:   electCommandFunc,\r\n\t}\r\n\tcmd.Flags().BoolVarP(&electListen, \"listen\", \"l\", false, \"observation mode\")\r\n\treturn cmd\r\n}","code-length":119,"reference":"\/\/ NewElectCommand returns the cobra command for \"elect\".","result":"Create a command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDefragCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"defrag\",\r\n\t\tShort: \"Defragments the storage of the etcd members with given endpoints\",\r\n\t\tRun:   defragCommandFunc,\r\n\t}\r\n\tcmd.PersistentFlags().BoolVar(&epClusterEndpoints, \"cluster\", false, \"use all endpoints from the cluster member list\")\r\n\tcmd.Flags().StringVar(&defragDataDir, \"data-dir\", \"\", \"Optional. If present, defragments a data directory not in use by etcd.\")\r\n\treturn cmd\r\n}","code-length":161,"reference":"\/\/ NewDefragCommand returns the cobra command for \"Defrag\".","result":"Create a new command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterBuilder(cfg Config) {\r\n\tbb := &builder{cfg}\r\n\tbalancer.Register(bb)\r\n\tbb.cfg.Logger.Debug(\r\n\t\t\"registered balancer\",\r\n\t\tzap.String(\"policy\", bb.cfg.Policy.String()),\r\n\t\tzap.String(\"name\", bb.cfg.Name),\r\n\t)\r\n}","code-length":99,"reference":"\/\/ RegisterBuilder creates and registers a builder. Since this function calls balancer.Register, it\n\/\/ must be invoked at initialization time.","result":"Register balancer builder.","score":[0.0014,0.0546]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *builder) Build(cc balancer.ClientConn, opt balancer.BuildOptions) balancer.Balancer {\r\n\tbb := &baseBalancer{\r\n\t\tid:     strconv.FormatInt(time.Now().UnixNano(), 36),\r\n\t\tpolicy: b.cfg.Policy,\r\n\t\tname:   b.cfg.Name,\r\n\t\tlg:     b.cfg.Logger,\r\n\t\taddrToSc: make(map[resolver.Address]balancer.SubConn),\r\n\t\tscToAddr: make(map[balancer.SubConn]resolver.Address),\r\n\t\tscToSt:   make(map[balancer.SubConn]connectivity.State),\r\n\t\tcurrentConn: nil,\r\n\t\tcsEvltr:     &connectivityStateEvaluator{},\r\n\t\t\r\n\t\tPicker: picker.NewErr(balancer.ErrNoSubConnAvailable),\r\n\t}\r\n\tif bb.lg == nil {\r\n\t\tbb.lg = zap.NewNop()\r\n\t}\r\n\t\r\n\tbb.mu.Lock()\r\n\tbb.currentConn = cc\r\n\tbb.mu.Unlock()\r\n\tbb.lg.Info(\r\n\t\t\"built balancer\",\r\n\t\tzap.String(\"balancer-id\", bb.id),\r\n\t\tzap.String(\"policy\", bb.policy.String()),\r\n\t\tzap.String(\"resolver-target\", cc.Target()),\r\n\t)\r\n\treturn bb\r\n}","code-length":358,"reference":"\/\/ Build is called initially when creating \"ccBalancerWrapper\".\n\/\/ \"grpc.Dial\" is called to this client connection.\n\/\/ Then, resolved addresses will be handled via \"HandleResolvedAddrs\".","result":"Build the balancer.","score":[0.0003,0.0219]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cse *connectivityStateEvaluator) recordTransition(oldState, newState connectivity.State) connectivity.State {\r\n\t\r\n\tfor idx, state := range []connectivity.State{oldState, newState} {\r\n\t\tupdateVal := 2*uint64(idx) - 1\r\n\t\tswitch state {\r\n\t\tcase connectivity.Ready:\r\n\t\t\tcse.numReady += updateVal\r\n\t\tcase connectivity.Connecting:\r\n\t\t\tcse.numConnecting += updateVal\r\n\t\tcase connectivity.TransientFailure:\r\n\t\t\tcse.numTransientFailure += updateVal\r\n\t\t}\r\n\t}\r\n\t\r\n\tif cse.numReady > 0 {\r\n\t\treturn connectivity.Ready\r\n\t}\r\n\tif cse.numConnecting > 0 {\r\n\t\treturn connectivity.Connecting\r\n\t}\r\n\treturn connectivity.TransientFailure\r\n}","code-length":217,"reference":"\/\/ recordTransition records state change happening in every subConn and based on\n\/\/ that it evaluates what aggregated state should be.\n\/\/ It can only transition between Ready, Connecting and TransientFailure. Other states,\n\/\/ Idle and Shutdown are transitioned into by ClientConn; in the beginning of the connection\n\/\/ before any subConn is created ClientConn is in idle state. In the end when ClientConn\n\/\/ closes it is in Shutdown state.\n\/\/\n\/\/ recordTransition should only be called synchronously from the same goroutine.","result":"Record transition .","score":[0.0,0.0133]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *EtcdServer) doSerialize(ctx context.Context, chk func(*auth.AuthInfo) error, get func()) error {\r\n\tai, err := s.AuthInfoFromCtx(ctx)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif ai == nil {\r\n\t\t\r\n\t\tai = &auth.AuthInfo{}\r\n\t}\r\n\tif err = chk(ai); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tget()\r\n\t\r\n\t\r\n\tif ai.Revision != 0 && ai.Revision != s.authStore.Revision() {\r\n\t\treturn auth.ErrAuthOldRevision\r\n\t}\r\n\treturn nil\r\n}","code-length":183,"reference":"\/\/ doSerialize handles the auth logic, with permissions checked by \"chk\", for a serialized request \"get\". Returns a non-nil error on authentication failure.","result":"Serialize the auth info.","score":[0.0039,0.1211]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *watcher) send(wr clientv3.WatchResponse) {\r\n\tif wr.IsProgressNotify() && !w.progress {\r\n\t\treturn\r\n\t}\r\n\tif w.nextrev > wr.Header.Revision && len(wr.Events) > 0 {\r\n\t\treturn\r\n\t}\r\n\tif w.nextrev == 0 {\r\n\t\t\r\n\t\tw.nextrev = wr.Header.Revision + 1\r\n\t}\r\n\tevents := make([]*mvccpb.Event, 0, len(wr.Events))\r\n\tvar lastRev int64\r\n\tfor i := range wr.Events {\r\n\t\tev := (*mvccpb.Event)(wr.Events[i])\r\n\t\tif ev.Kv.ModRevision < w.nextrev {\r\n\t\t\tcontinue\r\n\t\t} else {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tlastRev = ev.Kv.ModRevision\r\n\t\t}\r\n\t\tfiltered := false\r\n\t\tfor _, filter := range w.filters {\r\n\t\t\tif filter(*ev) {\r\n\t\t\t\tfiltered = true\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif filtered {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif !w.prevKV {\r\n\t\t\tevCopy := *ev\r\n\t\t\tevCopy.PrevKv = nil\r\n\t\t\tev = &evCopy\r\n\t\t}\r\n\t\tevents = append(events, ev)\r\n\t}\r\n\tif lastRev >= w.nextrev {\r\n\t\tw.nextrev = lastRev + 1\r\n\t}\r\n\t\r\n\tif !wr.IsProgressNotify() && !wr.Created && len(events) == 0 && wr.CompactRevision == 0 {\r\n\t\treturn\r\n\t}\r\n\tw.lastHeader = wr.Header\r\n\tw.post(&pb.WatchResponse{\r\n\t\tHeader:          &wr.Header,\r\n\t\tCreated:         wr.Created,\r\n\t\tCompactRevision: wr.CompactRevision,\r\n\t\tCanceled:        wr.Canceled,\r\n\t\tWatchId:         w.id,\r\n\t\tEvents:          events,\r\n\t})\r\n}","code-length":546,"reference":"\/\/ send filters out repeated events by discarding revisions older\n\/\/ than the last one sent over the watch channel.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *watcher) post(wr *pb.WatchResponse) bool {\r\n\tselect {\r\n\tcase w.wps.watchCh <- wr:\r\n\tcase <-time.After(50 * time.Millisecond):\r\n\t\tw.wps.cancel()\r\n\t\treturn false\r\n\t}\r\n\treturn true\r\n}","code-length":92,"reference":"\/\/ post puts a watch response on the watcher's proxy stream channel","result":"Post the watch event.","score":[0.0514,0.1339]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ac *AccessController) OriginAllowed(origin string) bool {\r\n\tac.corsMu.RLock()\r\n\tdefer ac.corsMu.RUnlock()\r\n\tif len(ac.CORS) == 0 {\r\n\t\treturn true\r\n\t}\r\n\t_, ok := ac.CORS[\"*\"]\r\n\tif ok {\r\n\t\treturn true\r\n\t}\r\n\t_, ok = ac.CORS[origin]\r\n\treturn ok\r\n}","code-length":125,"reference":"\/\/ OriginAllowed determines whether the server will allow a given CORS origin.\n\/\/ If CORS is empty, allow all.","result":"Check if the origin is allowed.","score":[0.0263,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ac *AccessController) IsHostWhitelisted(host string) bool {\r\n\tac.hostWhitelistMu.RLock()\r\n\tdefer ac.hostWhitelistMu.RUnlock()\r\n\tif len(ac.HostWhitelist) == 0 {\r\n\t\treturn true\r\n\t}\r\n\t_, ok := ac.HostWhitelist[\"*\"]\r\n\tif ok {\r\n\t\treturn true\r\n\t}\r\n\t_, ok = ac.HostWhitelist[host]\r\n\treturn ok\r\n}","code-length":127,"reference":"\/\/ IsHostWhitelisted returns true if the host is whitelisted.\n\/\/ If whitelist is empty, allow all.","result":"Check if host is whitelisted.","score":[0.0589,0.1342]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ss *SelectiveStringValue) Valids() []string {\r\n\ts := make([]string, 0, len(ss.valids))\r\n\tfor k := range ss.valids {\r\n\t\ts = append(s, k)\r\n\t}\r\n\tsort.Strings(s)\r\n\treturn s\r\n}","code-length":87,"reference":"\/\/ Valids returns the list of valid strings.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSelectiveStringsValue(valids ...string) *SelectiveStringsValue {\r\n\tvm := make(map[string]struct{})\r\n\tfor _, v := range valids {\r\n\t\tvm[v] = struct{}{}\r\n\t}\r\n\treturn &SelectiveStringsValue{valids: vm, vs: []string{}}\r\n}","code-length":93,"reference":"\/\/ NewSelectiveStringsValue creates a new string slice flag\n\/\/ for which any one of the given strings is a valid value,\n\/\/ and any other value is an error.","result":"Create a new SelectiveStringsValue.","score":[0.0009,0.0566]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewKV(kv clientv3.KV, prefix string) clientv3.KV {\r\n\treturn &kvPrefix{kv, prefix}\r\n}","code-length":44,"reference":"\/\/ NewKV wraps a KV instance so that all requests\n\/\/ are prefixed with a given string.","result":"Create a new KV object.","score":[0.0259,0.0633]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewURLsValue(s string) *URLsValue {\r\n\tif s == \"\" {\r\n\t\treturn &URLsValue{}\r\n\t}\r\n\tv := &URLsValue{}\r\n\tif err := v.Set(s); err != nil {\r\n\t\tplog.Panicf(\"new URLsValue should never fail: %v\", err)\r\n\t}\r\n\treturn v\r\n}","code-length":101,"reference":"\/\/ NewURLsValue implements \"url.URL\" slice as flag.Value interface.\n\/\/ Given value is to be separated by comma.","result":"Create a new URLsValue.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc URLsFromFlag(fs *flag.FlagSet, urlsFlagName string) []url.URL {\r\n\treturn []url.URL(*fs.Lookup(urlsFlagName).Value.(*URLsValue))\r\n}","code-length":57,"reference":"\/\/ URLsFromFlag returns a slices from url got from the flag.","result":"Generate the generated code.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *Etcd) servePeers() (err error) {\r\n\tph := etcdhttp.NewPeerHandler(e.GetLogger(), e.Server)\r\n\tvar peerTLScfg *tls.Config\r\n\tif !e.cfg.PeerTLSInfo.Empty() {\r\n\t\tif peerTLScfg, err = e.cfg.PeerTLSInfo.ServerConfig(); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tfor _, p := range e.Peers {\r\n\t\tu := p.Listener.Addr().String()\r\n\t\tgs := v3rpc.Server(e.Server, peerTLScfg)\r\n\t\tm := cmux.New(p.Listener)\r\n\t\tgo gs.Serve(m.Match(cmux.HTTP2()))\r\n\t\tsrv := &http.Server{\r\n\t\t\tHandler:     grpcHandlerFunc(gs, ph),\r\n\t\t\tReadTimeout: 5 * time.Minute,\r\n\t\t\tErrorLog:    defaultLog.New(ioutil.Discard, \"\", 0),\r\n\t\t}\r\n\t\tgo srv.Serve(m.Match(cmux.Any()))\r\n\t\tp.serve = func() error { return m.Serve() }\r\n\t\tp.close = func(ctx context.Context) error {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tif e.cfg.logger != nil {\r\n\t\t\t\te.cfg.logger.Info(\r\n\t\t\t\t\t\"stopping serving peer traffic\",\r\n\t\t\t\t\tzap.String(\"address\", u),\r\n\t\t\t\t)\r\n\t\t\t}\r\n\t\t\tstopServers(ctx, &servers{secure: peerTLScfg != nil, grpc: gs, http: srv})\r\n\t\t\tif e.cfg.logger != nil {\r\n\t\t\t\te.cfg.logger.Info(\r\n\t\t\t\t\t\"stopped serving peer traffic\",\r\n\t\t\t\t\tzap.String(\"address\", u),\r\n\t\t\t\t)\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor _, pl := range e.Peers {\r\n\t\tgo func(l *peerListener) {\r\n\t\t\tu := l.Addr().String()\r\n\t\t\tif e.cfg.logger != nil {\r\n\t\t\t\te.cfg.logger.Info(\r\n\t\t\t\t\t\"serving peer traffic\",\r\n\t\t\t\t\tzap.String(\"address\", u),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Info(\"listening for peers on \", u)\r\n\t\t\t}\r\n\t\t\te.errHandler(l.serve())\r\n\t\t}(pl)\r\n\t}\r\n\treturn nil\r\n}","code-length":642,"reference":"\/\/ configure peer handlers after rafthttp.Transport started","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewStore(lg *zap.Logger, b backend.Backend, le lease.Lessor, ig ConsistentIndexGetter) *store {\r\n\ts := &store{\r\n\t\tb:       b,\r\n\t\tig:      ig,\r\n\t\tkvindex: newTreeIndex(lg),\r\n\t\tle: le,\r\n\t\tcurrentRev:     1,\r\n\t\tcompactMainRev: -1,\r\n\t\tbytesBuf8: make([]byte, 8),\r\n\t\tfifoSched: schedule.NewFIFOScheduler(),\r\n\t\tstopc: make(chan struct{}),\r\n\t\tlg: lg,\r\n\t}\r\n\ts.ReadView = &readView{s}\r\n\ts.WriteView = &writeView{s}\r\n\tif s.le != nil {\r\n\t\ts.le.SetRangeDeleter(func() lease.TxnDelete { return s.Write() })\r\n\t}\r\n\ttx := s.b.BatchTx()\r\n\ttx.Lock()\r\n\ttx.UnsafeCreateBucket(keyBucketName)\r\n\ttx.UnsafeCreateBucket(metaBucketName)\r\n\ttx.Unlock()\r\n\ts.b.ForceCommit()\r\n\ts.mu.Lock()\r\n\tdefer s.mu.Unlock()\r\n\tif err := s.restore(); err != nil {\r\n\t\t\r\n\t\tpanic(\"failed to recover store from backend\")\r\n\t}\r\n\treturn s\r\n}","code-length":356,"reference":"\/\/ NewStore returns a new store. It is useful to create a store inside\n\/\/ mvcc pkg. It should only be used for testing externally.","result":"Create a new store.","score":[0.0035,0.1638]}
{"code":"\/*is used to<extra_id_0>\r\nfunc appendMarkTombstone(lg *zap.Logger, b []byte) []byte {\r\n\tif len(b) != revBytesLen {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Panic(\r\n\t\t\t\t\"cannot append tombstone mark to non-normal revision bytes\",\r\n\t\t\t\tzap.Int(\"expected-revision-bytes-size\", revBytesLen),\r\n\t\t\t\tzap.Int(\"given-revision-bytes-size\", len(b)),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Panicf(\"cannot append mark to non normal revision bytes\")\r\n\t\t}\r\n\t}\r\n\treturn append(b, markTombstone)\r\n}","code-length":176,"reference":"\/\/ appendMarkTombstone appends tombstone mark to normal revision bytes.","result":"Append tombstones to the revision.","score":[0.108,0.2972]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsDirWriteable(dir string) error {\r\n\tf := filepath.Join(dir, \".touch\")\r\n\tif err := ioutil.WriteFile(f, []byte(\"\"), PrivateFileMode); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn os.Remove(f)\r\n}","code-length":82,"reference":"\/\/ IsDirWriteable checks if dir is writable by writing and removing a file\n\/\/ to dir. It returns nil if dir is writable.","result":"Check if a directory is writeable.","score":[0.0149,0.0939]}
{"code":"\/*is used to<extra_id_0>\r\nfunc TouchDirAll(dir string) error {\r\n\t\r\n\t\r\n\terr := os.MkdirAll(dir, PrivateDirMode)\r\n\tif err != nil {\r\n\t\t\r\n\t\t\r\n\t\treturn err\r\n\t}\r\n\treturn IsDirWriteable(dir)\r\n}","code-length":79,"reference":"\/\/ TouchDirAll is similar to os.MkdirAll. It creates directories with 0700 permission if any directory\n\/\/ does not exists. TouchDirAll also ensures the given directory is writable.","result":"Touch a directory.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CreateDirAll(dir string) error {\r\n\terr := TouchDirAll(dir)\r\n\tif err == nil {\r\n\t\tvar ns []string\r\n\t\tns, err = ReadDir(dir)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif len(ns) != 0 {\r\n\t\t\terr = fmt.Errorf(\"expected %q to be empty, got %q\", dir, ns)\r\n\t\t}\r\n\t}\r\n\treturn err\r\n}","code-length":133,"reference":"\/\/ CreateDirAll is similar to TouchDirAll but returns error\n\/\/ if the deepest directory was not empty.","result":"Create a directory.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ZeroToEnd(f *os.File) error {\r\n\t\r\n\toff, err := f.Seek(0, io.SeekCurrent)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tlenf, lerr := f.Seek(0, io.SeekEnd)\r\n\tif lerr != nil {\r\n\t\treturn lerr\r\n\t}\r\n\tif err = f.Truncate(off); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif err = Preallocate(f, lenf, true); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t_, err = f.Seek(off, io.SeekStart)\r\n\treturn err\r\n}","code-length":186,"reference":"\/\/ ZeroToEnd zeros a file starting from SEEK_CUR to its SEEK_END. May temporarily\n\/\/ shorten the length of the file.","result":"End the file.","score":[0.002,0.1025]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (fp *filePipeline) Open() (f *fileutil.LockedFile, err error) {\r\n\tselect {\r\n\tcase f = <-fp.filec:\r\n\tcase err = <-fp.errc:\r\n\t}\r\n\treturn f, err\r\n}","code-length":74,"reference":"\/\/ Open returns a fresh file for writing. Rename the file before calling\n\/\/ Open again or there will be file collisions.","result":"Open the file pipeline.","score":[0.0056,0.0743]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRaftLoggerFromZapCore(cr zapcore.Core, syncer zapcore.WriteSyncer) raft.Logger {\r\n\t\r\n\tlg := zap.New(cr, zap.AddCaller(), zap.AddCallerSkip(1), zap.ErrorOutput(syncer))\r\n\treturn &zapRaftLogger{lg: lg, sugar: lg.Sugar()}\r\n}","code-length":98,"reference":"\/\/ NewRaftLoggerFromZapCore creates \"raft.Logger\" from \"zap.Core\"\n\/\/ and \"zapcore.WriteSyncer\".","result":"Create a new raft logger from zap core.","score":[0.1226,0.1124]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewConfig(fpath string) (*clientv3.Config, error) {\r\n\tb, err := ioutil.ReadFile(fpath)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tyc := &yamlConfig{}\r\n\terr = yaml.Unmarshal(b, yc)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif yc.InsecureTransport {\r\n\t\treturn &yc.Config, nil\r\n\t}\r\n\tvar (\r\n\t\tcert *tls.Certificate\r\n\t\tcp   *x509.CertPool\r\n\t)\r\n\tif yc.Certfile != \"\" && yc.Keyfile != \"\" {\r\n\t\tcert, err = tlsutil.NewCert(yc.Certfile, yc.Keyfile, nil)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\tif yc.TrustedCAfile != \"\" {\r\n\t\tcp, err = tlsutil.NewCertPool([]string{yc.TrustedCAfile})\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\ttlscfg := &tls.Config{\r\n\t\tMinVersion:         tls.VersionTLS12,\r\n\t\tInsecureSkipVerify: yc.InsecureSkipTLSVerify,\r\n\t\tRootCAs:            cp,\r\n\t}\r\n\tif cert != nil {\r\n\t\ttlscfg.Certificates = []tls.Certificate{*cert}\r\n\t}\r\n\tyc.Config.TLS = tlscfg\r\n\treturn &yc.Config, nil\r\n}","code-length":407,"reference":"\/\/ NewConfig creates a new clientv3.Config from a yaml file.","result":"Create a clientv.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterElectionHandler(ctx context.Context, mux *runtime.ServeMux, conn *grpc.ClientConn) error {\r\n\treturn RegisterElectionHandlerClient(ctx, mux, v3electionpb.NewElectionClient(conn))\r\n}","code-length":63,"reference":"\/\/ RegisterElectionHandler registers the http handlers for service Election to \"mux\".\n\/\/ The handlers forward requests to the grpc endpoint over \"conn\".","result":"Register the election handler.","score":[0.0035,0.0743]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UpdateCapability(lg *zap.Logger, v *semver.Version) {\r\n\tif v == nil {\r\n\t\t\r\n\t\treturn\r\n\t}\r\n\tenableMapMu.Lock()\r\n\tif curVersion != nil && !curVersion.LessThan(*v) {\r\n\t\tenableMapMu.Unlock()\r\n\t\treturn\r\n\t}\r\n\tcurVersion = v\r\n\tenabledMap = capabilityMaps[curVersion.String()]\r\n\tenableMapMu.Unlock()\r\n\tif lg != nil {\r\n\t\tlg.Info(\r\n\t\t\t\"enabled capabilities for version\",\r\n\t\t\tzap.String(\"cluster-version\", version.Cluster(v.String())),\r\n\t\t)\r\n\t} else {\r\n\t\tplog.Infof(\"enabled capabilities for version %s\", version.Cluster(v.String()))\r\n\t}\r\n}","code-length":217,"reference":"\/\/ UpdateCapability updates the enabledMap when the cluster version increases.","result":"Update the capability map.","score":[0.0713,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLockCommand() *cobra.Command {\r\n\tc := &cobra.Command{\r\n\t\tUse:   \"lock <lockname> [exec-command arg1 arg2 ...]\",\r\n\t\tShort: \"Acquires a named lock\",\r\n\t\tRun:   lockCommandFunc,\r\n\t}\r\n\tc.Flags().IntVarP(&lockTTL, \"ttl\", \"\", lockTTL, \"timeout for session\")\r\n\treturn c\r\n}","code-length":120,"reference":"\/\/ NewLockCommand returns the cobra command for \"lock\".","result":"Create a new lock.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raftNode) tick() {\r\n\tr.tickMu.Lock()\r\n\tr.Tick()\r\n\tr.tickMu.Unlock()\r\n}","code-length":49,"reference":"\/\/ raft.Node does not have locks in Raft package","result":"Tick the raftNode.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raftNode) advanceTicks(ticks int) {\r\n\tfor i := 0; i < ticks; i++ {\r\n\t\tr.tick()\r\n\t}\r\n}","code-length":53,"reference":"\/\/ advanceTicks advances ticks of Raft node.\n\/\/ This can be used for fast-forwarding election\n\/\/ ticks in multi data-center deployments, thus\n\/\/ speeding up election process.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewAuthCommand() *cobra.Command {\r\n\tac := &cobra.Command{\r\n\t\tUse:   \"auth <enable or disable>\",\r\n\t\tShort: \"Enable or disable authentication\",\r\n\t}\r\n\tac.AddCommand(newAuthEnableCommand())\r\n\tac.AddCommand(newAuthDisableCommand())\r\n\treturn ac\r\n}","code-length":98,"reference":"\/\/ NewAuthCommand returns the cobra command for \"auth\".","result":"Create a new command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc authEnableCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 0 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"auth enable command does not accept any arguments\"))\r\n\t}\r\n\tctx, cancel := commandCtx(cmd)\r\n\tcli := mustClientFromCmd(cmd)\r\n\tvar err error\r\n\tfor err == nil {\r\n\t\tif _, err = cli.AuthEnable(ctx); err == nil {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif err == rpctypes.ErrRootRoleNotExist {\r\n\t\t\tif _, err = cli.RoleAdd(ctx, \"root\"); err != nil {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\tif _, err = cli.UserGrantRole(ctx, \"root\", \"root\"); err != nil {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tfmt.Println(\"Authentication Enabled\")\r\n}","code-length":274,"reference":"\/\/ authEnableCommandFunc executes the \"auth enable\" command.","result":"Disable auth.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc authDisableCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 0 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"auth disable command does not accept any arguments\"))\r\n\t}\r\n\tctx, cancel := commandCtx(cmd)\r\n\t_, err := mustClientFromCmd(cmd).Auth.AuthDisable(ctx)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tfmt.Println(\"Authentication Disabled\")\r\n}","code-length":144,"reference":"\/\/ authDisableCommandFunc executes the \"auth disable\" command.","result":"Execute the command.","score":[0.128,0.3872]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RetryKVClient(c *Client) pb.KVClient {\r\n\treturn &retryKVClient{\r\n\t\tkc: pb.NewKVClient(c.conn),\r\n\t}\r\n}","code-length":56,"reference":"\/\/ RetryKVClient implements a KVClient.","result":"Retry the RPC.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RetryLeaseClient(c *Client) pb.LeaseClient {\r\n\treturn &retryLeaseClient{\r\n\t\tlc: pb.NewLeaseClient(c.conn),\r\n\t}\r\n}","code-length":55,"reference":"\/\/ RetryLeaseClient implements a LeaseClient.","result":"Retry the request.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RetryClusterClient(c *Client) pb.ClusterClient {\r\n\treturn &retryClusterClient{\r\n\t\tcc: pb.NewClusterClient(c.conn),\r\n\t}\r\n}","code-length":55,"reference":"\/\/ RetryClusterClient implements a ClusterClient.","result":"Retry cluster operations.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RetryMaintenanceClient(c *Client, conn *grpc.ClientConn) pb.MaintenanceClient {\r\n\treturn &retryMaintenanceClient{\r\n\t\tmc: pb.NewMaintenanceClient(conn),\r\n\t}\r\n}","code-length":60,"reference":"\/\/ RetryMaintenanceClient implements a Maintenance.","result":"Retry the operation.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RetryAuthClient(c *Client) pb.AuthClient {\r\n\treturn &retryAuthClient{\r\n\t\tac: pb.NewAuthClient(c.conn),\r\n\t}\r\n}","code-length":55,"reference":"\/\/ RetryAuthClient implements a AuthClient.","result":"Retry auth.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSetDirCommand() cli.Command {\r\n\treturn cli.Command{\r\n\t\tName:      \"setdir\",\r\n\t\tUsage:     \"create a new directory or update an existing directory TTL\",\r\n\t\tArgsUsage: \"<key>\",\r\n\t\tFlags: []cli.Flag{\r\n\t\t\tcli.IntFlag{Name: \"ttl\", Value: 0, Usage: \"key time-to-live in seconds\"},\r\n\t\t},\r\n\t\tAction: func(c *cli.Context) error {\r\n\t\t\tmkdirCommandFunc(c, mustNewKeyAPI(c), client.PrevIgnore)\r\n\t\t\treturn nil\r\n\t\t},\r\n\t}\r\n}","code-length":171,"reference":"\/\/ NewSetDirCommand returns the CLI command for \"setDir\".","result":"Create a new directory.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *DoubleBarrier) Enter() error {\r\n\tclient := b.s.Client()\r\n\tek, err := newUniqueEphemeralKey(b.s, b.key+\"\/waiters\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tb.myKey = ek\r\n\tresp, err := client.Get(b.ctx, b.key+\"\/waiters\", clientv3.WithPrefix())\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif len(resp.Kvs) > b.count {\r\n\t\treturn ErrTooManyClients\r\n\t}\r\n\tif len(resp.Kvs) == b.count {\r\n\t\t\r\n\t\t_, err = client.Put(b.ctx, b.key+\"\/ready\", \"\")\r\n\t\treturn err\r\n\t}\r\n\t_, err = WaitEvents(\r\n\t\tclient,\r\n\t\tb.key+\"\/ready\",\r\n\t\tek.Revision(),\r\n\t\t[]mvccpb.Event_EventType{mvccpb.PUT})\r\n\treturn err\r\n}","code-length":276,"reference":"\/\/ Enter waits for \"count\" processes to enter the barrier then returns","result":"Detect if the barrier is already in progress.","score":[0.1191,0.1616]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *DoubleBarrier) Leave() error {\r\n\tclient := b.s.Client()\r\n\tresp, err := client.Get(b.ctx, b.key+\"\/waiters\", clientv3.WithPrefix())\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif len(resp.Kvs) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\tlowest, highest := resp.Kvs[0], resp.Kvs[0]\r\n\tfor _, k := range resp.Kvs {\r\n\t\tif k.ModRevision < lowest.ModRevision {\r\n\t\t\tlowest = k\r\n\t\t}\r\n\t\tif k.ModRevision > highest.ModRevision {\r\n\t\t\thighest = k\r\n\t\t}\r\n\t}\r\n\tisLowest := string(lowest.Key) == b.myKey.Key()\r\n\tif len(resp.Kvs) == 1 {\r\n\t\t\r\n\t\tif _, err = client.Delete(b.ctx, b.key+\"\/ready\"); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn b.myKey.Delete()\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tif isLowest {\r\n\t\t_, err = WaitEvents(\r\n\t\t\tclient,\r\n\t\t\tstring(highest.Key),\r\n\t\t\thighest.ModRevision,\r\n\t\t\t[]mvccpb.Event_EventType{mvccpb.DELETE})\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn b.Leave()\r\n\t}\r\n\t\r\n\tif err = b.myKey.Delete(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tkey := string(lowest.Key)\r\n\t_, err = WaitEvents(\r\n\t\tclient,\r\n\t\tkey,\r\n\t\tlowest.ModRevision,\r\n\t\t[]mvccpb.Event_EventType{mvccpb.DELETE})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn b.Leave()\r\n}","code-length":523,"reference":"\/\/ Leave waits for \"count\" processes to leave the barrier then returns","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HandleBasic(mux *http.ServeMux, server etcdserver.ServerPeer) {\r\n\tmux.HandleFunc(varsPath, serveVars)\r\n\t\r\n\tmux.HandleFunc(configPath+\"\/local\/log\", logHandleFunc)\r\n\tHandleMetricsHealth(mux, server)\r\n\tmux.HandleFunc(versionPath, versionHandler(server.Cluster(), serveVersion))\r\n}","code-length":105,"reference":"\/\/ HandleBasic adds handlers to a mux for serving JSON etcd client requests\n\/\/ that do not access the v2 store.","result":"Handle basic etcd server .","score":[0.0098,0.0258]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WriteError(lg *zap.Logger, w http.ResponseWriter, r *http.Request, err error) {\r\n\tif err == nil {\r\n\t\treturn\r\n\t}\r\n\tswitch e := err.(type) {\r\n\tcase *v2error.Error:\r\n\t\te.WriteTo(w)\r\n\tcase *httptypes.HTTPError:\r\n\t\tif et := e.WriteTo(w); et != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Debug(\r\n\t\t\t\t\t\"failed to write v2 HTTP error\",\r\n\t\t\t\t\tzap.String(\"remote-addr\", r.RemoteAddr),\r\n\t\t\t\t\tzap.String(\"internal-server-error\", e.Error()),\r\n\t\t\t\t\tzap.Error(et),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Debugf(\"error writing HTTPError (%v) to %s\", et, r.RemoteAddr)\r\n\t\t\t}\r\n\t\t}\r\n\tdefault:\r\n\t\tswitch err {\r\n\t\tcase etcdserver.ErrTimeoutDueToLeaderFail, etcdserver.ErrTimeoutDueToConnectionLost, etcdserver.ErrNotEnoughStartedMembers,\r\n\t\t\tetcdserver.ErrUnhealthy:\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"v2 response error\",\r\n\t\t\t\t\tzap.String(\"remote-addr\", r.RemoteAddr),\r\n\t\t\t\t\tzap.String(\"internal-server-error\", err.Error()),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tmlog.MergeError(err)\r\n\t\t\t}\r\n\t\tdefault:\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"unexpected v2 response error\",\r\n\t\t\t\t\tzap.String(\"remote-addr\", r.RemoteAddr),\r\n\t\t\t\t\tzap.String(\"internal-server-error\", err.Error()),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tmlog.MergeErrorf(\"got unexpected response error (%v)\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t\therr := httptypes.NewHTTPError(http.StatusInternalServerError, \"Internal Server Error\")\r\n\t\tif et := herr.WriteTo(w); et != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Debug(\r\n\t\t\t\t\t\"failed to write v2 HTTP error\",\r\n\t\t\t\t\tzap.String(\"remote-addr\", r.RemoteAddr),\r\n\t\t\t\t\tzap.String(\"internal-server-error\", err.Error()),\r\n\t\t\t\t\tzap.Error(et),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Debugf(\"error writing HTTPError (%v) to %s\", et, r.RemoteAddr)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":689,"reference":"\/\/ WriteError logs and writes the given Error to the ResponseWriter\n\/\/ If Error is an etcdErr, it is rendered to the ResponseWriter\n\/\/ Otherwise, it is assumed to be a StatusInternalServerError","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *RaftCluster) MemberByName(name string) *Member {\r\n\tc.Lock()\r\n\tdefer c.Unlock()\r\n\tvar memb *Member\r\n\tfor _, m := range c.members {\r\n\t\tif m.Name == name {\r\n\t\t\tif memb != nil {\r\n\t\t\t\tif c.lg != nil {\r\n\t\t\t\t\tc.lg.Panic(\"two member with same name found\", zap.String(\"name\", name))\r\n\t\t\t\t} else {\r\n\t\t\t\t\tplog.Panicf(\"two members with the given name %q exist\", name)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tmemb = m\r\n\t\t}\r\n\t}\r\n\treturn memb.Clone()\r\n}","code-length":187,"reference":"\/\/ MemberByName returns a Member with the given name if exists.\n\/\/ If more than one member has the given name, it will panic.","result":"Generate the generated code.","score":[0.0022,0.0227]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *RaftCluster) PeerURLs() []string {\r\n\tc.Lock()\r\n\tdefer c.Unlock()\r\n\turls := make([]string, 0)\r\n\tfor _, p := range c.members {\r\n\t\turls = append(urls, p.PeerURLs...)\r\n\t}\r\n\tsort.Strings(urls)\r\n\treturn urls\r\n}","code-length":99,"reference":"\/\/ PeerURLs returns a list of all peer addresses.\n\/\/ The returned list is sorted in ascending lexicographical order.","result":"Generate the code.","score":[0,0.0287]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *RaftCluster) ValidateConfigurationChange(cc raftpb.ConfChange) error {\r\n\tmembers, removed := membersFromStore(c.lg, c.v2store)\r\n\tid := types.ID(cc.NodeID)\r\n\tif removed[id] {\r\n\t\treturn ErrIDRemoved\r\n\t}\r\n\tswitch cc.Type {\r\n\tcase raftpb.ConfChangeAddNode:\r\n\t\tif members[id] != nil {\r\n\t\t\treturn ErrIDExists\r\n\t\t}\r\n\t\turls := make(map[string]bool)\r\n\t\tfor _, m := range members {\r\n\t\t\tfor _, u := range m.PeerURLs {\r\n\t\t\t\turls[u] = true\r\n\t\t\t}\r\n\t\t}\r\n\t\tm := new(Member)\r\n\t\tif err := json.Unmarshal(cc.Context, m); err != nil {\r\n\t\t\tif c.lg != nil {\r\n\t\t\t\tc.lg.Panic(\"failed to unmarshal member\", zap.Error(err))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"unmarshal member should never fail: %v\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t\tfor _, u := range m.PeerURLs {\r\n\t\t\tif urls[u] {\r\n\t\t\t\treturn ErrPeerURLexists\r\n\t\t\t}\r\n\t\t}\r\n\tcase raftpb.ConfChangeRemoveNode:\r\n\t\tif members[id] == nil {\r\n\t\t\treturn ErrIDNotFound\r\n\t\t}\r\n\tcase raftpb.ConfChangeUpdateNode:\r\n\t\tif members[id] == nil {\r\n\t\t\treturn ErrIDNotFound\r\n\t\t}\r\n\t\turls := make(map[string]bool)\r\n\t\tfor _, m := range members {\r\n\t\t\tif m.ID == id {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tfor _, u := range m.PeerURLs {\r\n\t\t\t\turls[u] = true\r\n\t\t\t}\r\n\t\t}\r\n\t\tm := new(Member)\r\n\t\tif err := json.Unmarshal(cc.Context, m); err != nil {\r\n\t\t\tif c.lg != nil {\r\n\t\t\t\tc.lg.Panic(\"failed to unmarshal member\", zap.Error(err))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"unmarshal member should never fail: %v\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t\tfor _, u := range m.PeerURLs {\r\n\t\t\tif urls[u] {\r\n\t\t\t\treturn ErrPeerURLexists\r\n\t\t\t}\r\n\t\t}\r\n\tdefault:\r\n\t\tif c.lg != nil {\r\n\t\t\tc.lg.Panic(\"unknown ConfChange type\", zap.String(\"type\", cc.Type.String()))\r\n\t\t} else {\r\n\t\t\tplog.Panicf(\"ConfChange type should be either AddNode, RemoveNode or UpdateNode\")\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":732,"reference":"\/\/ ValidateConfigurationChange takes a proposed ConfChange and\n\/\/ ensures that it is still valid.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *RaftCluster) AddMember(m *Member) {\r\n\tc.Lock()\r\n\tdefer c.Unlock()\r\n\tif c.v2store != nil {\r\n\t\tmustSaveMemberToStore(c.v2store, m)\r\n\t}\r\n\tif c.be != nil {\r\n\t\tmustSaveMemberToBackend(c.be, m)\r\n\t}\r\n\tc.members[m.ID] = m\r\n\tif c.lg != nil {\r\n\t\tc.lg.Info(\r\n\t\t\t\"added member\",\r\n\t\t\tzap.String(\"cluster-id\", c.cid.String()),\r\n\t\t\tzap.String(\"local-member-id\", c.localID.String()),\r\n\t\t\tzap.String(\"added-peer-id\", m.ID.String()),\r\n\t\t\tzap.Strings(\"added-peer-peer-urls\", m.PeerURLs),\r\n\t\t)\r\n\t} else {\r\n\t\tplog.Infof(\"added member %s %v to cluster %s\", m.ID, m.PeerURLs, c.cid)\r\n\t}\r\n}","code-length":284,"reference":"\/\/ AddMember adds a new Member into the cluster, and saves the given member's\n\/\/ raftAttributes into the store. The given member should have empty attributes.\n\/\/ A Member with a matching id must not exist.","result":"Add a member to the cluster.","score":[0.0017,0.0606]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *RaftCluster) RemoveMember(id types.ID) {\r\n\tc.Lock()\r\n\tdefer c.Unlock()\r\n\tif c.v2store != nil {\r\n\t\tmustDeleteMemberFromStore(c.v2store, id)\r\n\t}\r\n\tif c.be != nil {\r\n\t\tmustDeleteMemberFromBackend(c.be, id)\r\n\t}\r\n\tm, ok := c.members[id]\r\n\tdelete(c.members, id)\r\n\tc.removed[id] = true\r\n\tif c.lg != nil {\r\n\t\tif ok {\r\n\t\t\tc.lg.Info(\r\n\t\t\t\t\"removed member\",\r\n\t\t\t\tzap.String(\"cluster-id\", c.cid.String()),\r\n\t\t\t\tzap.String(\"local-member-id\", c.localID.String()),\r\n\t\t\t\tzap.String(\"removed-remote-peer-id\", id.String()),\r\n\t\t\t\tzap.Strings(\"removed-remote-peer-urls\", m.PeerURLs),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tc.lg.Warn(\r\n\t\t\t\t\"skipped removing already removed member\",\r\n\t\t\t\tzap.String(\"cluster-id\", c.cid.String()),\r\n\t\t\t\tzap.String(\"local-member-id\", c.localID.String()),\r\n\t\t\t\tzap.String(\"removed-remote-peer-id\", id.String()),\r\n\t\t\t)\r\n\t\t}\r\n\t} else {\r\n\t\tplog.Infof(\"removed member %s from cluster %s\", id, c.cid)\r\n\t}\r\n}","code-length":408,"reference":"\/\/ RemoveMember removes a member from the store.\n\/\/ The given id MUST exist, or the function panics.","result":"Remove member from the cluster.","score":[0.0368,0.189]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ValidateClusterAndAssignIDs(lg *zap.Logger, local *RaftCluster, existing *RaftCluster) error {\r\n\tems := existing.Members()\r\n\tlms := local.Members()\r\n\tif len(ems) != len(lms) {\r\n\t\treturn fmt.Errorf(\"member count is unequal\")\r\n\t}\r\n\tsort.Sort(MembersByPeerURLs(ems))\r\n\tsort.Sort(MembersByPeerURLs(lms))\r\n\tctx, cancel := context.WithTimeout(context.TODO(), 30*time.Second)\r\n\tdefer cancel()\r\n\tfor i := range ems {\r\n\t\tif ok, err := netutil.URLStringsEqual(ctx, lg, ems[i].PeerURLs, lms[i].PeerURLs); !ok {\r\n\t\t\treturn fmt.Errorf(\"unmatched member while checking PeerURLs (%v)\", err)\r\n\t\t}\r\n\t\tlms[i].ID = ems[i].ID\r\n\t}\r\n\tlocal.members = make(map[types.ID]*Member)\r\n\tfor _, m := range lms {\r\n\t\tlocal.members[m.ID] = m\r\n\t}\r\n\treturn nil\r\n}","code-length":299,"reference":"\/\/ ValidateClusterAndAssignIDs validates the local cluster by matching the PeerURLs\n\/\/ with the existing cluster. If the validation succeeds, it assigns the IDs\n\/\/ from the existing cluster to the local cluster.\n\/\/ If the validation fails, an error will be returned.","result":"Validate cluster members and assign IDs.","score":[0.0005,0.0391]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ti *treeIndex) Keep(rev int64) map[revision]struct{} {\r\n\tavailable := make(map[revision]struct{})\r\n\tti.RLock()\r\n\tdefer ti.RUnlock()\r\n\tti.tree.Ascend(func(i btree.Item) bool {\r\n\t\tkeyi := i.(*keyIndex)\r\n\t\tkeyi.keep(rev, available)\r\n\t\treturn true\r\n\t})\r\n\treturn available\r\n}","code-length":124,"reference":"\/\/ Keep finds all revisions to be kept for a Compaction at the given rev.","result":"Keep the given revision.","score":[0.032,0.1839]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *lessor) closeRequireLeader() {\r\n\tl.mu.Lock()\r\n\tdefer l.mu.Unlock()\r\n\tfor _, ka := range l.keepAlives {\r\n\t\treqIdxs := 0\r\n\t\t\r\n\t\tfor i, ctx := range ka.ctxs {\r\n\t\t\tmd, ok := metadata.FromOutgoingContext(ctx)\r\n\t\t\tif !ok {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tks := md[rpctypes.MetadataRequireLeaderKey]\r\n\t\t\tif len(ks) < 1 || ks[0] != rpctypes.MetadataHasLeader {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tclose(ka.chs[i])\r\n\t\t\tka.chs[i] = nil\r\n\t\t\treqIdxs++\r\n\t\t}\r\n\t\tif reqIdxs == 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tnewChs := make([]chan<- *LeaseKeepAliveResponse, len(ka.chs)-reqIdxs)\r\n\t\tnewCtxs := make([]context.Context, len(newChs))\r\n\t\tnewIdx := 0\r\n\t\tfor i := range ka.chs {\r\n\t\t\tif ka.chs[i] == nil {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tnewChs[newIdx], newCtxs[newIdx] = ka.chs[i], ka.ctxs[newIdx]\r\n\t\t\tnewIdx++\r\n\t\t}\r\n\t\tka.chs, ka.ctxs = newChs, newCtxs\r\n\t}\r\n}","code-length":402,"reference":"\/\/ closeRequireLeader scans keepAlives for ctxs that have require leader\n\/\/ and closes the associated channels.","result":"Close the leader channel.","score":[0.0189,0.1727]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *lessor) resetRecv() (pb.Lease_LeaseKeepAliveClient, error) {\r\n\tsctx, cancel := context.WithCancel(l.stopCtx)\r\n\tstream, err := l.remote.LeaseKeepAlive(sctx, append(l.callOpts, withMax(0))...)\r\n\tif err != nil {\r\n\t\tcancel()\r\n\t\treturn nil, err\r\n\t}\r\n\tl.mu.Lock()\r\n\tdefer l.mu.Unlock()\r\n\tif l.stream != nil && l.streamCancel != nil {\r\n\t\tl.streamCancel()\r\n\t}\r\n\tl.streamCancel = cancel\r\n\tl.stream = stream\r\n\tgo l.sendKeepAliveLoop(stream)\r\n\treturn stream, nil\r\n}","code-length":193,"reference":"\/\/ resetRecv opens a new lease stream and starts sending keep alive requests.","result":"Reset the recv loop.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *lessor) recvKeepAlive(resp *pb.LeaseKeepAliveResponse) {\r\n\tkaresp := &LeaseKeepAliveResponse{\r\n\t\tResponseHeader: resp.GetHeader(),\r\n\t\tID:             LeaseID(resp.ID),\r\n\t\tTTL:            resp.TTL,\r\n\t}\r\n\tl.mu.Lock()\r\n\tdefer l.mu.Unlock()\r\n\tka, ok := l.keepAlives[karesp.ID]\r\n\tif !ok {\r\n\t\treturn\r\n\t}\r\n\tif karesp.TTL <= 0 {\r\n\t\t\r\n\t\tdelete(l.keepAlives, karesp.ID)\r\n\t\tka.close()\r\n\t\treturn\r\n\t}\r\n\t\r\n\tnextKeepAlive := time.Now().Add((time.Duration(karesp.TTL) * time.Second) \/ 3.0)\r\n\tka.deadline = time.Now().Add(time.Duration(karesp.TTL) * time.Second)\r\n\tfor _, ch := range ka.chs {\r\n\t\tselect {\r\n\t\tcase ch <- karesp:\r\n\t\tdefault:\r\n\t\t\tif l.lg != nil {\r\n\t\t\t\tl.lg.Warn(\"lease keepalive response queue is full; dropping response send\",\r\n\t\t\t\t\tzap.Int(\"queue-size\", len(ch)),\r\n\t\t\t\t\tzap.Int(\"queue-capacity\", cap(ch)),\r\n\t\t\t\t)\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tka.nextKeepAlive = nextKeepAlive\r\n\t}\r\n}","code-length":391,"reference":"\/\/ recvKeepAlive updates a lease based on its LeaseKeepAliveResponse","result":"Alive responses to the leader.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *lessor) deadlineLoop() {\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase <-time.After(time.Second):\r\n\t\tcase <-l.donec:\r\n\t\t\treturn\r\n\t\t}\r\n\t\tnow := time.Now()\r\n\t\tl.mu.Lock()\r\n\t\tfor id, ka := range l.keepAlives {\r\n\t\t\tif ka.deadline.Before(now) {\r\n\t\t\t\t\r\n\t\t\t\tka.close()\r\n\t\t\t\tdelete(l.keepAlives, id)\r\n\t\t\t}\r\n\t\t}\r\n\t\tl.mu.Unlock()\r\n\t}\r\n}","code-length":169,"reference":"\/\/ deadlineLoop reaps any keep alive channels that have not received a response\n\/\/ within the lease TTL","result":"Loop until the deadline.","score":[0.0096,0.0301]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *lessor) sendKeepAliveLoop(stream pb.Lease_LeaseKeepAliveClient) {\r\n\tfor {\r\n\t\tvar tosend []LeaseID\r\n\t\tnow := time.Now()\r\n\t\tl.mu.Lock()\r\n\t\tfor id, ka := range l.keepAlives {\r\n\t\t\tif ka.nextKeepAlive.Before(now) {\r\n\t\t\t\ttosend = append(tosend, id)\r\n\t\t\t}\r\n\t\t}\r\n\t\tl.mu.Unlock()\r\n\t\tfor _, id := range tosend {\r\n\t\t\tr := &pb.LeaseKeepAliveRequest{ID: int64(id)}\r\n\t\t\tif err := stream.Send(r); err != nil {\r\n\t\t\t\t\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t}\r\n\t\tselect {\r\n\t\tcase <-time.After(retryConnWait):\r\n\t\tcase <-stream.Context().Done():\r\n\t\t\treturn\r\n\t\tcase <-l.donec:\r\n\t\t\treturn\r\n\t\tcase <-l.stopCtx.Done():\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":281,"reference":"\/\/ sendKeepAliveLoop sends keep alive requests for the lifetime of the given stream.","result":"Send keep alive requests to the leader.","score":[0.1517,0.3903]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewKV(cl *v3.Client, pfx string, opts ...concurrency.SessionOption) (v3.KV, func(), error) {\r\n\tcctx, cancel := context.WithCancel(cl.Ctx())\r\n\tlkv := &leasingKV{\r\n\t\tcl:          cl,\r\n\t\tkv:          cl.KV,\r\n\t\tpfx:         pfx,\r\n\t\tleases:      leaseCache{revokes: make(map[string]time.Time)},\r\n\t\tctx:         cctx,\r\n\t\tcancel:      cancel,\r\n\t\tsessionOpts: opts,\r\n\t\tsessionc:    make(chan struct{}),\r\n\t}\r\n\tlkv.wg.Add(2)\r\n\tgo func() {\r\n\t\tdefer lkv.wg.Done()\r\n\t\tlkv.monitorSession()\r\n\t}()\r\n\tgo func() {\r\n\t\tdefer lkv.wg.Done()\r\n\t\tlkv.leases.clearOldRevokes(cctx)\r\n\t}()\r\n\treturn lkv, lkv.Close, lkv.waitSession(cctx)\r\n}","code-length":285,"reference":"\/\/ NewKV wraps a KV instance so that all requests are wired through a leasing protocol.","result":"Create a new kv object.","score":[0.0266,0.0671]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lkv *leasingKV) rescind(ctx context.Context, key string, rev int64) {\r\n\tif lkv.leases.Evict(key) > rev {\r\n\t\treturn\r\n\t}\r\n\tcmp := v3.Compare(v3.CreateRevision(lkv.pfx+key), \"<\", rev)\r\n\top := v3.OpDelete(lkv.pfx + key)\r\n\tfor ctx.Err() == nil {\r\n\t\tif _, err := lkv.kv.Txn(ctx).If(cmp).Then(op).Commit(); err == nil {\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":168,"reference":"\/\/ rescind releases a lease from this client.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LeaseValue(key string) Cmp {\r\n\treturn Cmp{Key: []byte(key), Target: pb.Compare_LEASE}\r\n}","code-length":42,"reference":"\/\/ LeaseValue compares a key's LeaseID to a value of your choosing. The empty\n\/\/ LeaseID is 0, otherwise known as `NoLease`.","result":"Generate the code.","score":[0,0.0249]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cmp *Cmp) ValueBytes() []byte {\r\n\tif tu, ok := cmp.TargetUnion.(*pb.Compare_Value); ok {\r\n\t\treturn tu.Value\r\n\t}\r\n\treturn nil\r\n}","code-length":63,"reference":"\/\/ ValueBytes returns the byte slice holding the comparison value, if any.","result":"Generate the value bytes .","score":[0.0593,0.0885]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cmp Cmp) WithRange(end string) Cmp {\r\n\tcmp.RangeEnd = []byte(end)\r\n\treturn cmp\r\n}","code-length":43,"reference":"\/\/ WithRange sets the comparison to scan the range [key, end).","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cmp Cmp) WithPrefix() Cmp {\r\n\tcmp.RangeEnd = getPrefix(cmp.Key)\r\n\treturn cmp\r\n}","code-length":41,"reference":"\/\/ WithPrefix sets the comparison to scan all keys prefixed by the key.","result":"Create a new function.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc mustInt64(val interface{}) int64 {\r\n\tif v, ok := val.(int64); ok {\r\n\t\treturn v\r\n\t}\r\n\tif v, ok := val.(int); ok {\r\n\t\treturn int64(v)\r\n\t}\r\n\tpanic(\"bad value\")\r\n}","code-length":88,"reference":"\/\/ mustInt64 panics if val isn't an int or int64. It returns an int64 otherwise.","result":"Check if val is int.","score":[0.046,0.1339]}
{"code":"\/*is used to<extra_id_0>\r\nfunc mustInt64orLeaseID(val interface{}) int64 {\r\n\tif v, ok := val.(LeaseID); ok {\r\n\t\treturn int64(v)\r\n\t}\r\n\treturn mustInt64(val)\r\n}","code-length":67,"reference":"\/\/ mustInt64orLeaseID panics if val isn't a LeaseID, int or int64. It returns an\n\/\/ int64 otherwise.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gw *gRPCWatcher) Next() ([]*naming.Update, error) {\r\n\tif gw.wch == nil {\r\n\t\t\r\n\t\treturn gw.firstNext()\r\n\t}\r\n\tif gw.err != nil {\r\n\t\treturn nil, gw.err\r\n\t}\r\n\t\r\n\twr, ok := <-gw.wch\r\n\tif !ok {\r\n\t\tgw.err = status.Error(codes.Unavailable, ErrWatcherClosed.Error())\r\n\t\treturn nil, gw.err\r\n\t}\r\n\tif gw.err = wr.Err(); gw.err != nil {\r\n\t\treturn nil, gw.err\r\n\t}\r\n\tupdates := make([]*naming.Update, 0, len(wr.Events))\r\n\tfor _, e := range wr.Events {\r\n\t\tvar jupdate naming.Update\r\n\t\tvar err error\r\n\t\tswitch e.Type {\r\n\t\tcase etcd.EventTypePut:\r\n\t\t\terr = json.Unmarshal(e.Kv.Value, &jupdate)\r\n\t\t\tjupdate.Op = naming.Add\r\n\t\tcase etcd.EventTypeDelete:\r\n\t\t\terr = json.Unmarshal(e.PrevKv.Value, &jupdate)\r\n\t\t\tjupdate.Op = naming.Delete\r\n\t\tdefault:\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif err == nil {\r\n\t\t\tupdates = append(updates, &jupdate)\r\n\t\t}\r\n\t}\r\n\treturn updates, nil\r\n}","code-length":378,"reference":"\/\/ Next gets the next set of updates from the etcd resolver.\n\/\/ Calls to Next should be serialized; concurrent calls are not safe since\n\/\/ there is no way to reconcile the update ordering.","result":"Get the next event from the watcher.","score":[0.0055,0.0776]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getJournalWriteSyncer() (zapcore.WriteSyncer, error) {\r\n\tjw, err := logutil.NewJournalWriter(os.Stderr)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"can't find journal (%v)\", err)\r\n\t}\r\n\treturn zapcore.AddSync(jw), nil\r\n}","code-length":97,"reference":"\/\/ use stderr as fallback","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newKV(store *store, nodePath string, value string, createdIndex uint64, parent *node, expireTime time.Time) *node {\r\n\treturn &node{\r\n\t\tPath:          nodePath,\r\n\t\tCreatedIndex:  createdIndex,\r\n\t\tModifiedIndex: createdIndex,\r\n\t\tParent:        parent,\r\n\t\tstore:         store,\r\n\t\tExpireTime:    expireTime,\r\n\t\tValue:         value,\r\n\t}\r\n}","code-length":123,"reference":"\/\/ newKV creates a Key-Value pair","result":"Create a new KV node.","score":[0.1967,0.3178]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newDir(store *store, nodePath string, createdIndex uint64, parent *node, expireTime time.Time) *node {\r\n\treturn &node{\r\n\t\tPath:          nodePath,\r\n\t\tCreatedIndex:  createdIndex,\r\n\t\tModifiedIndex: createdIndex,\r\n\t\tParent:        parent,\r\n\t\tExpireTime:    expireTime,\r\n\t\tChildren:      make(map[string]*node),\r\n\t\tstore:         store,\r\n\t}\r\n}","code-length":126,"reference":"\/\/ newDir creates a directory","result":"Create a new directory.","score":[0.2488,0.3827]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *node) Read() (string, *v2error.Error) {\r\n\tif n.IsDir() {\r\n\t\treturn \"\", v2error.NewError(v2error.EcodeNotFile, \"\", n.store.CurrentIndex)\r\n\t}\r\n\treturn n.Value, nil\r\n}","code-length":84,"reference":"\/\/ Read function gets the value of the node.\n\/\/ If the receiver node is not a key-value pair, a \"Not A File\" error will be returned.","result":"Read the file.","score":[0.0002,0.0407]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *node) Write(value string, index uint64) *v2error.Error {\r\n\tif n.IsDir() {\r\n\t\treturn v2error.NewError(v2error.EcodeNotFile, \"\", n.store.CurrentIndex)\r\n\t}\r\n\tn.Value = value\r\n\tn.ModifiedIndex = index\r\n\treturn nil\r\n}","code-length":99,"reference":"\/\/ Write function set the value of the node to the given value.\n\/\/ If the receiver node is a directory, a \"Not A File\" error will be returned.","result":"Write to the store.","score":[0.001,0.0566]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *node) List() ([]*node, *v2error.Error) {\r\n\tif !n.IsDir() {\r\n\t\treturn nil, v2error.NewError(v2error.EcodeNotDir, \"\", n.store.CurrentIndex)\r\n\t}\r\n\tnodes := make([]*node, len(n.Children))\r\n\ti := 0\r\n\tfor _, node := range n.Children {\r\n\t\tnodes[i] = node\r\n\t\ti++\r\n\t}\r\n\treturn nodes, nil\r\n}","code-length":140,"reference":"\/\/ List function return a slice of nodes under the receiver node.\n\/\/ If the receiver node is not a directory, a \"Not A Directory\" error will be returned.","result":"List the contents of the node.","score":[0.0062,0.0936]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *node) GetChild(name string) (*node, *v2error.Error) {\r\n\tif !n.IsDir() {\r\n\t\treturn nil, v2error.NewError(v2error.EcodeNotDir, n.Path, n.store.CurrentIndex)\r\n\t}\r\n\tchild, ok := n.Children[name]\r\n\tif ok {\r\n\t\treturn child, nil\r\n\t}\r\n\treturn nil, nil\r\n}","code-length":123,"reference":"\/\/ GetChild function returns the child node under the directory node.\n\/\/ On success, it returns the file node","result":"Get the child node.","score":[0.0118,0.0857]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *node) Add(child *node) *v2error.Error {\r\n\tif !n.IsDir() {\r\n\t\treturn v2error.NewError(v2error.EcodeNotDir, \"\", n.store.CurrentIndex)\r\n\t}\r\n\t_, name := path.Split(child.Path)\r\n\tif _, ok := n.Children[name]; ok {\r\n\t\treturn v2error.NewError(v2error.EcodeNodeExist, \"\", n.store.CurrentIndex)\r\n\t}\r\n\tn.Children[name] = child\r\n\treturn nil\r\n}","code-length":155,"reference":"\/\/ Add function adds a node to the receiver node.\n\/\/ If the receiver is not a directory, a \"Not A Directory\" error will be returned.\n\/\/ If there is an existing node with the same name under the directory, a \"Already Exist\"\n\/\/ error will be returned","result":"Add a child node to the node.","score":[0.0011,0.0683]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *node) Remove(dir, recursive bool, callback func(path string)) *v2error.Error {\r\n\tif !n.IsDir() {\r\n\t\t_, name := path.Split(n.Path)\r\n\t\t\r\n\t\tif n.Parent != nil && n.Parent.Children[name] == n {\r\n\t\t\tdelete(n.Parent.Children, name)\r\n\t\t}\r\n\t\tif callback != nil {\r\n\t\t\tcallback(n.Path)\r\n\t\t}\r\n\t\tif !n.IsPermanent() {\r\n\t\t\tn.store.ttlKeyHeap.remove(n)\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\tif !dir {\r\n\t\t\r\n\t\treturn v2error.NewError(v2error.EcodeNotFile, n.Path, n.store.CurrentIndex)\r\n\t}\r\n\tif len(n.Children) != 0 && !recursive {\r\n\t\t\r\n\t\t\r\n\t\treturn v2error.NewError(v2error.EcodeDirNotEmpty, n.Path, n.store.CurrentIndex)\r\n\t}\r\n\tfor _, child := range n.Children {\r\n\t\tchild.Remove(true, true, callback)\r\n\t}\r\n\t\r\n\t_, name := path.Split(n.Path)\r\n\tif n.Parent != nil && n.Parent.Children[name] == n {\r\n\t\tdelete(n.Parent.Children, name)\r\n\t\tif callback != nil {\r\n\t\t\tcallback(n.Path)\r\n\t\t}\r\n\t\tif !n.IsPermanent() {\r\n\t\t\tn.store.ttlKeyHeap.remove(n)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":430,"reference":"\/\/ Remove function remove the node.","result":"Remove a node.","score":[0.1786,0.1754]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *node) Compare(prevValue string, prevIndex uint64) (ok bool, which int) {\r\n\tindexMatch := prevIndex == 0 || n.ModifiedIndex == prevIndex\r\n\tvalueMatch := prevValue == \"\" || n.Value == prevValue\r\n\tok = valueMatch && indexMatch\r\n\tswitch {\r\n\tcase valueMatch && indexMatch:\r\n\t\twhich = CompareMatch\r\n\tcase indexMatch && !valueMatch:\r\n\t\twhich = CompareValueNotMatch\r\n\tcase valueMatch && !indexMatch:\r\n\t\twhich = CompareIndexNotMatch\r\n\tdefault:\r\n\t\twhich = CompareNotMatch\r\n\t}\r\n\treturn ok, which\r\n}","code-length":172,"reference":"\/\/ Compare function compares node index and value with provided ones.\n\/\/ second result value explains result and equals to one of Compare.. constants","result":"Compare the value of a node.","score":[0.0126,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *node) Clone() *node {\r\n\tif !n.IsDir() {\r\n\t\tnewkv := newKV(n.store, n.Path, n.Value, n.CreatedIndex, n.Parent, n.ExpireTime)\r\n\t\tnewkv.ModifiedIndex = n.ModifiedIndex\r\n\t\treturn newkv\r\n\t}\r\n\tclone := newDir(n.store, n.Path, n.CreatedIndex, n.Parent, n.ExpireTime)\r\n\tclone.ModifiedIndex = n.ModifiedIndex\r\n\tfor key, child := range n.Children {\r\n\t\tclone.Children[key] = child.Clone()\r\n\t}\r\n\treturn clone\r\n}","code-length":174,"reference":"\/\/ Clone function clone the node recursively and return the new node.\n\/\/ If the node is a directory, it will clone all the content under this directory.\n\/\/ If the node is a key-value pair, it will clone the pair.","result":"Clone a node.","score":[0.0,0.0403]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isConnectedToQuorumSince(transport rafthttp.Transporter, since time.Time, self types.ID, members []*membership.Member) bool {\r\n\treturn numConnectedSince(transport, since, self, members) >= (len(members)\/2)+1\r\n}","code-length":70,"reference":"\/\/ isConnectedToQuorumSince checks whether the local member is connected to the\n\/\/ quorum of the cluster since the given time.","result":"Check if the member is in the middle of a quorum.","score":[0.0768,0.2232]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isConnectedSince(transport rafthttp.Transporter, since time.Time, remote types.ID) bool {\r\n\tt := transport.ActiveSince(remote)\r\n\treturn !t.IsZero() && t.Before(since)\r\n}","code-length":65,"reference":"\/\/ isConnectedSince checks whether the local member is connected to the\n\/\/ remote member since the given time.","result":"Check if the remote is connected to a remote server.","score":[0.1142,0.2972]}
{"code":"\/*is used to<extra_id_0>\r\nfunc numConnectedSince(transport rafthttp.Transporter, since time.Time, self types.ID, members []*membership.Member) int {\r\n\tconnectedNum := 0\r\n\tfor _, m := range members {\r\n\t\tif m.ID == self || isConnectedSince(transport, since, m.ID) {\r\n\t\t\tconnectedNum++\r\n\t\t}\r\n\t}\r\n\treturn connectedNum\r\n}","code-length":107,"reference":"\/\/ numConnectedSince counts how many members are connected to the local member\n\/\/ since the given time.","result":"Determine the number of members connected to the current member.","score":[0.1262,0.2616]}
{"code":"\/*is used to<extra_id_0>\r\nfunc longestConnected(tp rafthttp.Transporter, membs []types.ID) (types.ID, bool) {\r\n\tvar longest types.ID\r\n\tvar oldest time.Time\r\n\tfor _, id := range membs {\r\n\t\ttm := tp.ActiveSince(id)\r\n\t\tif tm.IsZero() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif oldest.IsZero() {\r\n\t\t\toldest = tm\r\n\t\t\tlongest = id\r\n\t\t}\r\n\t\tif tm.Before(oldest) {\r\n\t\t\toldest = tm\r\n\t\t\tlongest = id\r\n\t\t}\r\n\t}\r\n\tif uint64(longest) == 0 {\r\n\t\treturn longest, false\r\n\t}\r\n\treturn longest, true\r\n}","code-length":203,"reference":"\/\/ longestConnected chooses the member with longest active-since-time.\n\/\/ It returns false, if nothing is active.","result":"Determine the longest connected ID.","score":[0.0317,0.0671]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *decoder) isTornEntry(data []byte) bool {\r\n\tif len(d.brs) != 1 {\r\n\t\treturn false\r\n\t}\r\n\tfileOff := d.lastValidOff + frameSizeBytes\r\n\tcurOff := 0\r\n\tchunks := [][]byte{}\r\n\t\r\n\tfor curOff < len(data) {\r\n\t\tchunkLen := int(minSectorSize - (fileOff % minSectorSize))\r\n\t\tif chunkLen > len(data)-curOff {\r\n\t\t\tchunkLen = len(data) - curOff\r\n\t\t}\r\n\t\tchunks = append(chunks, data[curOff:curOff+chunkLen])\r\n\t\tfileOff += int64(chunkLen)\r\n\t\tcurOff += chunkLen\r\n\t}\r\n\t\r\n\tfor _, sect := range chunks {\r\n\t\tisZero := true\r\n\t\tfor _, v := range sect {\r\n\t\t\tif v != 0 {\r\n\t\t\t\tisZero = false\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif isZero {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":297,"reference":"\/\/ isTornEntry determines whether the last entry of the WAL was partially written\n\/\/ and corrupted because of a torn write.","result":"Detect if a frame is to be torn.","score":[0.0273,0.0254]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StartMockServersOnNetwork(count int, network string) (ms *MockServers, err error) {\r\n\tswitch network {\r\n\tcase \"tcp\":\r\n\t\treturn startMockServersTcp(count)\r\n\tcase \"unix\":\r\n\t\treturn startMockServersUnix(count)\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"unsupported network type: %s\", network)\r\n\t}\r\n}","code-length":108,"reference":"\/\/ StartMockServersOnNetwork creates mock servers on either 'tcp' or 'unix' sockets.","result":"Start the mock servers on a specific network.","score":[0.1966,0.2752]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MockServers) StartAt(idx int) (err error) {\r\n\tms.mu.Lock()\r\n\tdefer ms.mu.Unlock()\r\n\tif ms.Servers[idx].ln == nil {\r\n\t\tms.Servers[idx].ln, err = net.Listen(ms.Servers[idx].Network, ms.Servers[idx].Address)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to listen %v\", err)\r\n\t\t}\r\n\t}\r\n\tsvr := grpc.NewServer()\r\n\tpb.RegisterKVServer(svr, &mockKVServer{})\r\n\tms.Servers[idx].GrpcServer = svr\r\n\tms.wg.Add(1)\r\n\tgo func(svr *grpc.Server, l net.Listener) {\r\n\t\tsvr.Serve(l)\r\n\t}(ms.Servers[idx].GrpcServer, ms.Servers[idx].ln)\r\n\treturn nil\r\n}","code-length":245,"reference":"\/\/ StartAt restarts mock server at given index.","result":"Start the server at the specified index.","score":[0.2191,0.3235]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MockServers) StopAt(idx int) {\r\n\tms.mu.Lock()\r\n\tdefer ms.mu.Unlock()\r\n\tif ms.Servers[idx].ln == nil {\r\n\t\treturn\r\n\t}\r\n\tms.Servers[idx].GrpcServer.Stop()\r\n\tms.Servers[idx].GrpcServer = nil\r\n\tms.Servers[idx].ln = nil\r\n\tms.wg.Done()\r\n}","code-length":118,"reference":"\/\/ StopAt stops mock server at given index.","result":"Stop the server at the given index.","score":[0.2606,0.5646]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MockServers) Stop() {\r\n\tfor idx := range ms.Servers {\r\n\t\tms.StopAt(idx)\r\n\t}\r\n\tms.wg.Wait()\r\n}","code-length":57,"reference":"\/\/ Stop stops the mock server, immediately closing all open connections and listeners.","result":"Stop the servers.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCheckCommand() *cobra.Command {\r\n\tcc := &cobra.Command{\r\n\t\tUse:   \"check <subcommand>\",\r\n\t\tShort: \"commands for checking properties of the etcd cluster\",\r\n\t}\r\n\tcc.AddCommand(NewCheckPerfCommand())\r\n\tcc.AddCommand(NewCheckDatascaleCommand())\r\n\treturn cc\r\n}","code-length":102,"reference":"\/\/ NewCheckCommand returns the cobra command for \"check\".","result":"Create the check command.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCheckPerfCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"perf [options]\",\r\n\t\tShort: \"Check the performance of the etcd cluster\",\r\n\t\tRun:   newCheckPerfCommand,\r\n\t}\r\n\t\r\n\tcmd.Flags().StringVar(&checkPerfLoad, \"load\", \"s\", \"The performance check's workload model. Accepted workloads: s(small), m(medium), l(large), xl(xLarge)\")\r\n\tcmd.Flags().StringVar(&checkPerfPrefix, \"prefix\", \"\/etcdctl-check-perf\/\", \"The prefix for writing the performance check's keys.\")\r\n\tcmd.Flags().BoolVar(&autoCompact, \"auto-compact\", false, \"Compact storage with last revision after test is finished.\")\r\n\tcmd.Flags().BoolVar(&autoDefrag, \"auto-defrag\", false, \"Defragment storage after test is finished.\")\r\n\treturn cmd\r\n}","code-length":248,"reference":"\/\/ NewCheckPerfCommand returns the cobra command for \"check perf\".","result":"Generate the test code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCheckDatascaleCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"datascale [options]\",\r\n\t\tShort: \"Check the memory usage of holding data for different workloads on a given server endpoint.\",\r\n\t\tLong:  \"If no endpoint is provided, localhost will be used. If multiple endpoints are provided, first endpoint will be used.\",\r\n\t\tRun:   newCheckDatascaleCommand,\r\n\t}\r\n\tcmd.Flags().StringVar(&checkDatascaleLoad, \"load\", \"s\", \"The datascale check's workload model. Accepted workloads: s(small), m(medium), l(large), xl(xLarge)\")\r\n\tcmd.Flags().StringVar(&checkDatascalePrefix, \"prefix\", \"\/etcdctl-check-datascale\/\", \"The prefix for writing the datascale check's keys.\")\r\n\tcmd.Flags().BoolVar(&autoCompact, \"auto-compact\", false, \"Compact storage with last revision after test is finished.\")\r\n\tcmd.Flags().BoolVar(&autoDefrag, \"auto-defrag\", false, \"Defragment storage after test is finished.\")\r\n\treturn cmd\r\n}","code-length":295,"reference":"\/\/ NewCheckDatascaleCommand returns the cobra command for \"check datascale\".","result":"Check the memory usage of the etcd server.","score":[0.1226,0.0562]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewGetCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"get [options] <key> [range_end]\",\r\n\t\tShort: \"Gets the key or a range of keys\",\r\n\t\tRun:   getCommandFunc,\r\n\t}\r\n\tcmd.Flags().StringVar(&getConsistency, \"consistency\", \"l\", \"Linearizable(l) or Serializable(s)\")\r\n\tcmd.Flags().StringVar(&getSortOrder, \"order\", \"\", \"Order of results; ASCEND or DESCEND (ASCEND by default)\")\r\n\tcmd.Flags().StringVar(&getSortTarget, \"sort-by\", \"\", \"Sort target; CREATE, KEY, MODIFY, VALUE, or VERSION\")\r\n\tcmd.Flags().Int64Var(&getLimit, \"limit\", 0, \"Maximum number of results\")\r\n\tcmd.Flags().BoolVar(&getPrefix, \"prefix\", false, \"Get keys with matching prefix\")\r\n\tcmd.Flags().BoolVar(&getFromKey, \"from-key\", false, \"Get keys that are greater than or equal to the given key using byte compare\")\r\n\tcmd.Flags().Int64Var(&getRev, \"rev\", 0, \"Specify the kv revision\")\r\n\tcmd.Flags().BoolVar(&getKeysOnly, \"keys-only\", false, \"Get only the keys\")\r\n\tcmd.Flags().BoolVar(&printValueOnly, \"print-value-only\", false, `Only write values when using the \"simple\" output format`)\r\n\treturn cmd\r\n}","code-length":377,"reference":"\/\/ NewGetCommand returns the cobra command for \"get\".","result":"Generate the command .","score":[0.1398,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewGetCommand() cli.Command {\r\n\treturn cli.Command{\r\n\t\tName:      \"get\",\r\n\t\tUsage:     \"retrieve the value of a key\",\r\n\t\tArgsUsage: \"<key>\",\r\n\t\tFlags: []cli.Flag{\r\n\t\t\tcli.BoolFlag{Name: \"sort\", Usage: \"returns result in sorted order\"},\r\n\t\t\tcli.BoolFlag{Name: \"quorum, q\", Usage: \"require quorum for get request\"},\r\n\t\t},\r\n\t\tAction: func(c *cli.Context) error {\r\n\t\t\tgetCommandFunc(c, mustNewKeyAPI(c))\r\n\t\t\treturn nil\r\n\t\t},\r\n\t}\r\n}","code-length":179,"reference":"\/\/ NewGetCommand returns the CLI command for \"get\".","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) PickPeerURL() string {\r\n\tif len(m.PeerURLs) == 0 {\r\n\t\tpanic(\"member should always have some peer url\")\r\n\t}\r\n\treturn m.PeerURLs[rand.Intn(len(m.PeerURLs))]\r\n}","code-length":79,"reference":"\/\/ PickPeerURL chooses a random address from a given Member's PeerURLs.\n\/\/ It will panic if there is no PeerURLs available in Member.","result":"Pick a random peer.","score":[0.0039,0.0474]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HandleMetricsHealth(mux *http.ServeMux, srv etcdserver.ServerV2) {\r\n\tmux.Handle(PathMetrics, promhttp.Handler())\r\n\tmux.Handle(PathHealth, NewHealthHandler(func() Health { return checkHealth(srv) }))\r\n}","code-length":77,"reference":"\/\/ HandleMetricsHealth registers metrics and health handlers.","result":"Handle metrics and health.","score":[0.2134,0.2799]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRemoveCommand() cli.Command {\r\n\treturn cli.Command{\r\n\t\tName:      \"rm\",\r\n\t\tUsage:     \"remove a key or a directory\",\r\n\t\tArgsUsage: \"<key>\",\r\n\t\tFlags: []cli.Flag{\r\n\t\t\tcli.BoolFlag{Name: \"dir\", Usage: \"removes the key if it is an empty directory or a key-value pair\"},\r\n\t\t\tcli.BoolFlag{Name: \"recursive, r\", Usage: \"removes the key and all child keys(if it is a directory)\"},\r\n\t\t\tcli.StringFlag{Name: \"with-value\", Value: \"\", Usage: \"previous value\"},\r\n\t\t\tcli.IntFlag{Name: \"with-index\", Value: 0, Usage: \"previous index\"},\r\n\t\t},\r\n\t\tAction: func(c *cli.Context) error {\r\n\t\t\trmCommandFunc(c, mustNewKeyAPI(c))\r\n\t\t\treturn nil\r\n\t\t},\r\n\t}\r\n}","code-length":252,"reference":"\/\/ NewRemoveCommand returns the CLI command for \"rm\".","result":"Create a new key .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc rmCommandFunc(c *cli.Context, ki client.KeysAPI) {\r\n\tif len(c.Args()) == 0 {\r\n\t\thandleError(c, ExitBadArgs, errors.New(\"key required\"))\r\n\t}\r\n\tkey := c.Args()[0]\r\n\trecursive := c.Bool(\"recursive\")\r\n\tdir := c.Bool(\"dir\")\r\n\tprevValue := c.String(\"with-value\")\r\n\tprevIndex := c.Int(\"with-index\")\r\n\tctx, cancel := contextWithTotalTimeout(c)\r\n\tresp, err := ki.Delete(ctx, key, &client.DeleteOptions{PrevIndex: uint64(prevIndex), PrevValue: prevValue, Dir: dir, Recursive: recursive})\r\n\tcancel()\r\n\tif err != nil {\r\n\t\thandleError(c, ExitServerError, err)\r\n\t}\r\n\tif !resp.Node.Dir || c.GlobalString(\"output\") != \"simple\" {\r\n\t\tprintResponseKey(resp, c.GlobalString(\"output\"))\r\n\t}\r\n}","code-length":264,"reference":"\/\/ rmCommandFunc executes the \"rm\" command.","result":"Execute a command like.","score":[0,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkIntervals(reqs []*pb.RequestOp) (map[string]struct{}, adt.IntervalTree, error) {\r\n\tvar dels adt.IntervalTree\r\n\t\r\n\tfor _, req := range reqs {\r\n\t\ttv, ok := req.Request.(*pb.RequestOp_RequestDeleteRange)\r\n\t\tif !ok {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tdreq := tv.RequestDeleteRange\r\n\t\tif dreq == nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvar iv adt.Interval\r\n\t\tif len(dreq.RangeEnd) != 0 {\r\n\t\t\tiv = adt.NewStringAffineInterval(string(dreq.Key), string(dreq.RangeEnd))\r\n\t\t} else {\r\n\t\t\tiv = adt.NewStringAffinePoint(string(dreq.Key))\r\n\t\t}\r\n\t\tdels.Insert(iv, struct{}{})\r\n\t}\r\n\t\r\n\tputs := make(map[string]struct{})\r\n\tfor _, req := range reqs {\r\n\t\ttv, ok := req.Request.(*pb.RequestOp_RequestTxn)\r\n\t\tif !ok {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tputsThen, delsThen, err := checkIntervals(tv.RequestTxn.Success)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, dels, err\r\n\t\t}\r\n\t\tputsElse, delsElse, err := checkIntervals(tv.RequestTxn.Failure)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, dels, err\r\n\t\t}\r\n\t\tfor k := range putsThen {\r\n\t\t\tif _, ok := puts[k]; ok {\r\n\t\t\t\treturn nil, dels, rpctypes.ErrGRPCDuplicateKey\r\n\t\t\t}\r\n\t\t\tif dels.Intersects(adt.NewStringAffinePoint(k)) {\r\n\t\t\t\treturn nil, dels, rpctypes.ErrGRPCDuplicateKey\r\n\t\t\t}\r\n\t\t\tputs[k] = struct{}{}\r\n\t\t}\r\n\t\tfor k := range putsElse {\r\n\t\t\tif _, ok := puts[k]; ok {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tif _, isSafe := putsThen[k]; !isSafe {\r\n\t\t\t\t\treturn nil, dels, rpctypes.ErrGRPCDuplicateKey\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tif dels.Intersects(adt.NewStringAffinePoint(k)) {\r\n\t\t\t\treturn nil, dels, rpctypes.ErrGRPCDuplicateKey\r\n\t\t\t}\r\n\t\t\tputs[k] = struct{}{}\r\n\t\t}\r\n\t\tdels.Union(delsThen, adt.NewStringAffineInterval(\"\\x00\", \"\"))\r\n\t\tdels.Union(delsElse, adt.NewStringAffineInterval(\"\\x00\", \"\"))\r\n\t}\r\n\t\r\n\tfor _, req := range reqs {\r\n\t\ttv, ok := req.Request.(*pb.RequestOp_RequestPut)\r\n\t\tif !ok || tv.RequestPut == nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tk := string(tv.RequestPut.Key)\r\n\t\tif _, ok := puts[k]; ok {\r\n\t\t\treturn nil, dels, rpctypes.ErrGRPCDuplicateKey\r\n\t\t}\r\n\t\tif dels.Intersects(adt.NewStringAffinePoint(k)) {\r\n\t\t\treturn nil, dels, rpctypes.ErrGRPCDuplicateKey\r\n\t\t}\r\n\t\tputs[k] = struct{}{}\r\n\t}\r\n\treturn puts, dels, nil\r\n}","code-length":907,"reference":"\/\/ checkIntervals tests whether puts and deletes overlap for a list of ops. If\n\/\/ there is an overlap, returns an error. If no overlap, return put and delete\n\/\/ sets for recursive evaluation.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReportEventReceived(n int) {\r\n\tpendingEventsGauge.Sub(float64(n))\r\n\ttotalEventsCounter.Add(float64(n))\r\n}","code-length":49,"reference":"\/\/ ReportEventReceived reports that an event is received.\n\/\/ This function should be called when the external systems received an\n\/\/ event from mvcc.Watcher.","result":"Report event received.","score":[0.0004,0.0685]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterKVHandler(ctx context.Context, mux *runtime.ServeMux, conn *grpc.ClientConn) error {\r\n\treturn RegisterKVHandlerClient(ctx, mux, etcdserverpb.NewKVClient(conn))\r\n}","code-length":61,"reference":"\/\/ RegisterKVHandler registers the http handlers for service KV to \"mux\".\n\/\/ The handlers forward requests to the grpc endpoint over \"conn\".","result":"Register the handler.","score":[0.0007,0.0498]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterWatchHandler(ctx context.Context, mux *runtime.ServeMux, conn *grpc.ClientConn) error {\r\n\treturn RegisterWatchHandlerClient(ctx, mux, etcdserverpb.NewWatchClient(conn))\r\n}","code-length":61,"reference":"\/\/ RegisterWatchHandler registers the http handlers for service Watch to \"mux\".\n\/\/ The handlers forward requests to the grpc endpoint over \"conn\".","result":"Register the watch handler.","score":[0.0035,0.0743]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterLeaseHandler(ctx context.Context, mux *runtime.ServeMux, conn *grpc.ClientConn) error {\r\n\treturn RegisterLeaseHandlerClient(ctx, mux, etcdserverpb.NewLeaseClient(conn))\r\n}","code-length":61,"reference":"\/\/ RegisterLeaseHandler registers the http handlers for service Lease to \"mux\".\n\/\/ The handlers forward requests to the grpc endpoint over \"conn\".","result":"Register the lease handler.","score":[0.0035,0.0743]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterClusterHandler(ctx context.Context, mux *runtime.ServeMux, conn *grpc.ClientConn) error {\r\n\treturn RegisterClusterHandlerClient(ctx, mux, etcdserverpb.NewClusterClient(conn))\r\n}","code-length":61,"reference":"\/\/ RegisterClusterHandler registers the http handlers for service Cluster to \"mux\".\n\/\/ The handlers forward requests to the grpc endpoint over \"conn\".","result":"Register the cluster handler.","score":[0.0035,0.0743]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterMaintenanceHandler(ctx context.Context, mux *runtime.ServeMux, conn *grpc.ClientConn) error {\r\n\treturn RegisterMaintenanceHandlerClient(ctx, mux, etcdserverpb.NewMaintenanceClient(conn))\r\n}","code-length":61,"reference":"\/\/ RegisterMaintenanceHandler registers the http handlers for service Maintenance to \"mux\".\n\/\/ The handlers forward requests to the grpc endpoint over \"conn\".","result":"Register the maintenance handler.","score":[0.0035,0.0743]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterAuthHandler(ctx context.Context, mux *runtime.ServeMux, conn *grpc.ClientConn) error {\r\n\treturn RegisterAuthHandlerClient(ctx, mux, etcdserverpb.NewAuthClient(conn))\r\n}","code-length":61,"reference":"\/\/ RegisterAuthHandler registers the http handlers for service Auth to \"mux\".\n\/\/ The handlers forward requests to the grpc endpoint over \"conn\".","result":"Register the auth handler.","score":[0.0035,0.0743]}
{"code":"\/*is used to<extra_id_0>\r\nfunc startEtcd(cfg *embed.Config) (<-chan struct{}, <-chan error, error) {\r\n\te, err := embed.StartEtcd(cfg)\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\tosutil.RegisterInterruptHandler(e.Close)\r\n\tselect {\r\n\tcase <-e.Server.ReadyNotify():\r\n\tcase <-e.Server.StopNotify():\r\n\t}\r\n\treturn e.Server.StopNotify(), e.Err(), nil\r\n}","code-length":135,"reference":"\/\/ startEtcd runs StartEtcd in addition to hooks needed for standalone etcd.","result":"Start etcd server.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc identifyDataDirOrDie(lg *zap.Logger, dir string) dirType {\r\n\tnames, err := fileutil.ReadDir(dir)\r\n\tif err != nil {\r\n\t\tif os.IsNotExist(err) {\r\n\t\t\treturn dirEmpty\r\n\t\t}\r\n\t\tif lg != nil {\r\n\t\t\tlg.Fatal(\"failed to list data directory\", zap.String(\"dir\", dir), zap.Error(err))\r\n\t\t} else {\r\n\t\t\tplog.Fatalf(\"error listing data dir: %s\", dir)\r\n\t\t}\r\n\t}\r\n\tvar m, p bool\r\n\tfor _, name := range names {\r\n\t\tswitch dirType(name) {\r\n\t\tcase dirMember:\r\n\t\t\tm = true\r\n\t\tcase dirProxy:\r\n\t\t\tp = true\r\n\t\tdefault:\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"found invalid file under data directory\",\r\n\t\t\t\t\tzap.String(\"filename\", name),\r\n\t\t\t\t\tzap.String(\"data-dir\", dir),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Warningf(\"found invalid file\/dir %s under data dir %s (Ignore this if you are upgrading etcd)\", name, dir)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif m && p {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Fatal(\"invalid datadir; both member and proxy directories exist\")\r\n\t\t} else {\r\n\t\t\tplog.Fatal(\"invalid datadir. Both member and proxy directories exist.\")\r\n\t\t}\r\n\t}\r\n\tif m {\r\n\t\treturn dirMember\r\n\t}\r\n\tif p {\r\n\t\treturn dirProxy\r\n\t}\r\n\treturn dirEmpty\r\n}","code-length":451,"reference":"\/\/ identifyDataDirOrDie returns the type of the data dir.\n\/\/ Dies if the datadir is invalid.","result":"Identify the data directory.","score":[0.0225,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc openLast(lg *zap.Logger, dirpath string) (*fileutil.LockedFile, error) {\r\n\tnames, err := readWALNames(lg, dirpath)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tlast := filepath.Join(dirpath, names[len(names)-1])\r\n\treturn fileutil.LockFile(last, os.O_RDWR, fileutil.PrivateFileMode)\r\n}","code-length":119,"reference":"\/\/ openLast opens the last wal file for read and write.","result":"Open the last WAL file.","score":[0.1023,0.3816]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *leader) gotLeader() {\r\n\tl.mu.Lock()\r\n\tdefer l.mu.Unlock()\r\n\tselect {\r\n\tcase <-l.leaderc:\r\n\t\tl.leaderc = make(chan struct{})\r\n\tdefault:\r\n\t}\r\n}","code-length":80,"reference":"\/\/ gotLeader will force update the leadership status to having a leader.","result":"Detect when the leader is lost.","score":[0.071,0.0439]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *leader) lostNotify() <-chan struct{} {\r\n\tl.mu.RLock()\r\n\tdefer l.mu.RUnlock()\r\n\treturn l.leaderc\r\n}","code-length":55,"reference":"\/\/ lostNotify returns a channel that is closed if there has been\n\/\/ a leader loss not yet followed by a leader reacquire.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newGRPCProxyCommand() *cobra.Command {\r\n\tlpc := &cobra.Command{\r\n\t\tUse:   \"grpc-proxy <subcommand>\",\r\n\t\tShort: \"grpc-proxy related command\",\r\n\t}\r\n\tlpc.AddCommand(newGRPCProxyStartCommand())\r\n\treturn lpc\r\n}","code-length":92,"reference":"\/\/ newGRPCProxyCommand returns the cobra command for \"grpc-proxy\".","result":"Create a new command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMemberCommand() *cobra.Command {\r\n\tmc := &cobra.Command{\r\n\t\tUse:   \"member <subcommand>\",\r\n\t\tShort: \"Membership related commands\",\r\n\t}\r\n\tmc.AddCommand(NewMemberAddCommand())\r\n\tmc.AddCommand(NewMemberRemoveCommand())\r\n\tmc.AddCommand(NewMemberUpdateCommand())\r\n\tmc.AddCommand(NewMemberListCommand())\r\n\treturn mc\r\n}","code-length":122,"reference":"\/\/ NewMemberCommand returns the cobra command for \"member\".","result":"Create a member command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMemberAddCommand() *cobra.Command {\r\n\tcc := &cobra.Command{\r\n\t\tUse:   \"add <memberName> [options]\",\r\n\t\tShort: \"Adds a member into the cluster\",\r\n\t\tRun: memberAddCommandFunc,\r\n\t}\r\n\tcc.Flags().StringVar(&memberPeerURLs, \"peer-urls\", \"\", \"comma separated peer URLs for the new member.\")\r\n\treturn cc\r\n}","code-length":120,"reference":"\/\/ NewMemberAddCommand returns the cobra command for \"member add\".","result":"Create a new member.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMemberRemoveCommand() *cobra.Command {\r\n\tcc := &cobra.Command{\r\n\t\tUse:   \"remove <memberID>\",\r\n\t\tShort: \"Removes a member from the cluster\",\r\n\t\tRun: memberRemoveCommandFunc,\r\n\t}\r\n\treturn cc\r\n}","code-length":85,"reference":"\/\/ NewMemberRemoveCommand returns the cobra command for \"member remove\".","result":"Create a new member remove command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMemberUpdateCommand() *cobra.Command {\r\n\tcc := &cobra.Command{\r\n\t\tUse:   \"update <memberID> [options]\",\r\n\t\tShort: \"Updates a member in the cluster\",\r\n\t\tRun: memberUpdateCommandFunc,\r\n\t}\r\n\tcc.Flags().StringVar(&memberPeerURLs, \"peer-urls\", \"\", \"comma separated peer URLs for the updated member.\")\r\n\treturn cc\r\n}","code-length":120,"reference":"\/\/ NewMemberUpdateCommand returns the cobra command for \"member update\".","result":"Create a new member in the cluster.","score":[0.1214,0.0568]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMemberListCommand() *cobra.Command {\r\n\tcc := &cobra.Command{\r\n\t\tUse:   \"list\",\r\n\t\tShort: \"Lists all members in the cluster\",\r\n\t\tLong: `When --write-out is set to simple, this command prints out comma-separated member lists for each endpoint.\r\nThe items in the lists are ID, Status, Name, Peer Addrs, Client Addrs.\r\n`,\r\n\t\tRun: memberListCommandFunc,\r\n\t}\r\n\treturn cc\r\n}","code-length":136,"reference":"\/\/ NewMemberListCommand returns the cobra command for \"member list\".","result":"Create a new member list command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc memberAddCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) < 1 {\r\n\t\tExitWithError(ExitBadArgs, errors.New(\"member name not provided\"))\r\n\t}\r\n\tif len(args) > 1 {\r\n\t\tev := \"too many arguments\"\r\n\t\tfor _, s := range args {\r\n\t\t\tif strings.HasPrefix(strings.ToLower(s), \"http\") {\r\n\t\t\t\tev += fmt.Sprintf(`, did you mean --peer-urls=%s`, s)\r\n\t\t\t}\r\n\t\t}\r\n\t\tExitWithError(ExitBadArgs, errors.New(ev))\r\n\t}\r\n\tnewMemberName := args[0]\r\n\tif len(memberPeerURLs) == 0 {\r\n\t\tExitWithError(ExitBadArgs, errors.New(\"member peer urls not provided\"))\r\n\t}\r\n\turls := strings.Split(memberPeerURLs, \",\")\r\n\tctx, cancel := commandCtx(cmd)\r\n\tcli := mustClientFromCmd(cmd)\r\n\tresp, err := cli.MemberAdd(ctx, urls)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tnewID := resp.Member.ID\r\n\tdisplay.MemberAdd(*resp)\r\n\tif _, ok := (display).(*simplePrinter); ok {\r\n\t\tctx, cancel = commandCtx(cmd)\r\n\t\tlistResp, err := cli.MemberList(ctx)\r\n\t\t\r\n\t\tfor {\r\n\t\t\tif err != nil {\r\n\t\t\t\tExitWithError(ExitError, err)\r\n\t\t\t}\r\n\t\t\tif listResp.Header.MemberId == resp.Header.MemberId {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tgresp, gerr := cli.Get(ctx, \"_\")\r\n\t\t\tif gerr != nil {\r\n\t\t\t\tExitWithError(ExitError, err)\r\n\t\t\t}\r\n\t\t\tresp.Header.MemberId = gresp.Header.MemberId\r\n\t\t\tlistResp, err = cli.MemberList(ctx)\r\n\t\t}\r\n\t\tcancel()\r\n\t\tconf := []string{}\r\n\t\tfor _, memb := range listResp.Members {\r\n\t\t\tfor _, u := range memb.PeerURLs {\r\n\t\t\t\tn := memb.Name\r\n\t\t\t\tif memb.ID == newID {\r\n\t\t\t\t\tn = newMemberName\r\n\t\t\t\t}\r\n\t\t\t\tconf = append(conf, fmt.Sprintf(\"%s=%s\", n, u))\r\n\t\t\t}\r\n\t\t}\r\n\t\tfmt.Print(\"\\n\")\r\n\t\tfmt.Printf(\"ETCD_NAME=%q\\n\", newMemberName)\r\n\t\tfmt.Printf(\"ETCD_INITIAL_CLUSTER=%q\\n\", strings.Join(conf, \",\"))\r\n\t\tfmt.Printf(\"ETCD_INITIAL_ADVERTISE_PEER_URLS=%q\\n\", memberPeerURLs)\r\n\t\tfmt.Printf(\"ETCD_INITIAL_CLUSTER_STATE=\\\"existing\\\"\\n\")\r\n\t}\r\n}","code-length":764,"reference":"\/\/ memberAddCommandFunc executes the \"member add\" command.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc memberRemoveCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"member ID is not provided\"))\r\n\t}\r\n\tid, err := strconv.ParseUint(args[0], 16, 64)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"bad member ID arg (%v), expecting ID in Hex\", err))\r\n\t}\r\n\tctx, cancel := commandCtx(cmd)\r\n\tresp, err := mustClientFromCmd(cmd).MemberRemove(ctx, id)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.MemberRemove(id, *resp)\r\n}","code-length":204,"reference":"\/\/ memberRemoveCommandFunc executes the \"member remove\" command.","result":"Remove members from the cluster.","score":[0.1611,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc memberUpdateCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"member ID is not provided\"))\r\n\t}\r\n\tid, err := strconv.ParseUint(args[0], 16, 64)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"bad member ID arg (%v), expecting ID in Hex\", err))\r\n\t}\r\n\tif len(memberPeerURLs) == 0 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"member peer urls not provided\"))\r\n\t}\r\n\turls := strings.Split(memberPeerURLs, \",\")\r\n\tctx, cancel := commandCtx(cmd)\r\n\tresp, err := mustClientFromCmd(cmd).MemberUpdate(ctx, id, urls)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.MemberUpdate(id, *resp)\r\n}","code-length":260,"reference":"\/\/ memberUpdateCommandFunc executes the \"member update\" command.","result":"Update members.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc memberListCommandFunc(cmd *cobra.Command, args []string) {\r\n\tctx, cancel := commandCtx(cmd)\r\n\tresp, err := mustClientFromCmd(cmd).MemberList(ctx)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.MemberList(*resp)\r\n}","code-length":101,"reference":"\/\/ memberListCommandFunc executes the \"member list\" command.","result":"Generate the member list command.","score":[0.1915,0.1471]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Open(lg *zap.Logger, dirpath string, snap walpb.Snapshot) (*WAL, error) {\r\n\tw, err := openAtIndex(lg, dirpath, snap, true)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif w.dirFile, err = fileutil.OpenDir(w.dir); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn w, nil\r\n}","code-length":121,"reference":"\/\/ Open opens the WAL at the given snap.\n\/\/ The snap SHOULD have been previously saved to the WAL, or the following\n\/\/ ReadAll will fail.\n\/\/ The returned WAL is ready to read and the first record will be the one after\n\/\/ the given snap. The WAL cannot be appended to before reading out all of its\n\/\/ previous records.","result":"Open the WAL.","score":[0.0,0.0175]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OpenForRead(lg *zap.Logger, dirpath string, snap walpb.Snapshot) (*WAL, error) {\r\n\treturn openAtIndex(lg, dirpath, snap, false)\r\n}","code-length":56,"reference":"\/\/ OpenForRead only opens the wal files for read.\n\/\/ Write on a read only wal panics.","result":"Open directory for read.","score":[0.0175,0.1628]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Verify(lg *zap.Logger, walDir string, snap walpb.Snapshot) error {\r\n\tvar metadata []byte\r\n\tvar err error\r\n\tvar match bool\r\n\trec := &walpb.Record{}\r\n\tnames, nameIndex, err := selectWALFiles(lg, walDir, snap)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t\r\n\trs, _, closer, err := openWALFiles(lg, walDir, names, nameIndex, false)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tdecoder := newDecoder(rs...)\r\n\tfor err = decoder.decode(rec); err == nil; err = decoder.decode(rec) {\r\n\t\tswitch rec.Type {\r\n\t\tcase metadataType:\r\n\t\t\tif metadata != nil && !bytes.Equal(metadata, rec.Data) {\r\n\t\t\t\treturn ErrMetadataConflict\r\n\t\t\t}\r\n\t\t\tmetadata = rec.Data\r\n\t\tcase crcType:\r\n\t\t\tcrc := decoder.crc.Sum32()\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tif crc != 0 && rec.Validate(crc) != nil {\r\n\t\t\t\treturn ErrCRCMismatch\r\n\t\t\t}\r\n\t\t\tdecoder.updateCRC(rec.Crc)\r\n\t\tcase snapshotType:\r\n\t\t\tvar loadedSnap walpb.Snapshot\r\n\t\t\tpbutil.MustUnmarshal(&loadedSnap, rec.Data)\r\n\t\t\tif loadedSnap.Index == snap.Index {\r\n\t\t\t\tif loadedSnap.Term != snap.Term {\r\n\t\t\t\t\treturn ErrSnapshotMismatch\r\n\t\t\t\t}\r\n\t\t\t\tmatch = true\r\n\t\t\t}\r\n\t\t\r\n\t\t\r\n\t\tcase entryType:\r\n\t\tcase stateType:\r\n\t\tdefault:\r\n\t\t\treturn fmt.Errorf(\"unexpected block type %d\", rec.Type)\r\n\t\t}\r\n\t}\r\n\tif closer != nil {\r\n\t\tcloser()\r\n\t}\r\n\t\r\n\t\r\n\tif err != io.EOF && err != io.ErrUnexpectedEOF {\r\n\t\treturn err\r\n\t}\r\n\tif !match {\r\n\t\treturn ErrSnapshotNotFound\r\n\t}\r\n\treturn nil\r\n}","code-length":551,"reference":"\/\/ Verify reads through the given WAL and verifies that it is not corrupted.\n\/\/ It creates a new decoder to read through the records of the given WAL.\n\/\/ It does not conflict with any open WAL, but it is recommended not to\n\/\/ call this function after opening the WAL for writing.\n\/\/ If it cannot read out the expected snap, it will return ErrSnapshotNotFound.\n\/\/ If the loaded snap doesn't match with the expected one, it will\n\/\/ return error ErrSnapshotMismatch.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WAL) Close() error {\r\n\tw.mu.Lock()\r\n\tdefer w.mu.Unlock()\r\n\tif w.fp != nil {\r\n\t\tw.fp.Close()\r\n\t\tw.fp = nil\r\n\t}\r\n\tif w.tail() != nil {\r\n\t\tif err := w.sync(); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tfor _, l := range w.locks {\r\n\t\tif l == nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif err := l.Close(); err != nil {\r\n\t\t\tif w.lg != nil {\r\n\t\t\t\tw.lg.Warn(\"failed to close WAL\", zap.Error(err))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Errorf(\"failed to unlock during closing wal: %s\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn w.dirFile.Close()\r\n}","code-length":248,"reference":"\/\/ Close closes the current WAL file and directory.","result":"Close the WAL file.","score":[0.1205,0.1765]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *watcher) notify(e *Event, originalPath bool, deleted bool) bool {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif (w.recursive || originalPath || deleted) && e.Index() >= w.sinceIndex {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tselect {\r\n\t\tcase w.eventChan <- e:\r\n\t\tdefault:\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tw.remove()\r\n\t\t}\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":164,"reference":"\/\/ notify function notifies the watcher. If the watcher interests in the given path,\n\/\/ the function will return true.","result":"Notify watchers.","score":[0,0.0275]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *watcher) Remove() {\r\n\tw.hub.mutex.Lock()\r\n\tdefer w.hub.mutex.Unlock()\r\n\tclose(w.eventChan)\r\n\tif w.remove != nil {\r\n\t\tw.remove()\r\n\t}\r\n}","code-length":76,"reference":"\/\/ Remove removes the watcher from watcherHub\n\/\/ The actual remove function is guaranteed to only be executed once","result":"Remove the watcher.","score":[0.0023,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *v2v3Store) mkPathDepth(nodePath string, depth int) string {\r\n\tnormalForm := path.Clean(path.Join(\"\/\", nodePath))\r\n\tn := strings.Count(normalForm, \"\/\") + depth\r\n\treturn fmt.Sprintf(\"%s\/%03d\/k\/%s\", s.pfx, n, normalForm)\r\n}","code-length":97,"reference":"\/\/ mkPathDepth makes a path to a key that encodes its directory depth\n\/\/ for fast directory listing. If a depth is provided, it is added\n\/\/ to the computed depth.","result":"Create a new path.","score":[0.0004,0.0177]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *v2v3Store) mkV2Node(kv *mvccpb.KeyValue) *v2store.NodeExtern {\r\n\tif kv == nil {\r\n\t\treturn nil\r\n\t}\r\n\tn := &v2store.NodeExtern{\r\n\t\tKey:           s.mkNodePath(string(kv.Key)),\r\n\t\tDir:           kv.Key[len(kv.Key)-1] == '\/',\r\n\t\tCreatedIndex:  mkV2Rev(kv.CreateRevision),\r\n\t\tModifiedIndex: mkV2Rev(kv.ModRevision),\r\n\t}\r\n\tif !n.Dir {\r\n\t\tv := string(kv.Value)\r\n\t\tn.Value = &v\r\n\t}\r\n\treturn n\r\n}","code-length":195,"reference":"\/\/ mkV2Node creates a V2 NodeExtern from a V3 KeyValue","result":"Create a new node.","score":[0.0713,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc prevKeyFromPuts(resp *clientv3.TxnResponse) *mvccpb.KeyValue {\r\n\tfor _, r := range resp.Responses {\r\n\t\tpkv := r.GetResponsePut().PrevKv\r\n\t\tif pkv != nil && pkv.CreateRevision > 0 {\r\n\t\t\treturn pkv\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":102,"reference":"\/\/ prevKeyFromPuts gets the prev key that is being put; ignores\n\/\/ the put action response.","result":"Generate the code.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewWeightedReport(r Report, precision string) Report {\r\n\treturn &weightedReport{\r\n\t\tbaseReport: r,\r\n\t\treport:     newReport(precision),\r\n\t\tresults:    make(chan Result, 16),\r\n\t}\r\n}","code-length":73,"reference":"\/\/ NewWeightedReport returns a report that includes\n\/\/ both weighted and unweighted statistics.","result":"Create a new weighted report.","score":[0.0577,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewURLsMapFromStringMap(m map[string]string, sep string) (URLsMap, error) {\r\n\tvar err error\r\n\tum := URLsMap{}\r\n\tfor k, v := range m {\r\n\t\tum[k], err = NewURLs(strings.Split(v, sep))\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\treturn um, nil\r\n}","code-length":115,"reference":"\/\/ NewURLsMapFromStringMap takes a map of strings and returns a URLsMap. The\n\/\/ string values in the map can be multiple values separated by the sep string.","result":"Create a new URLSMap.","score":[0.001,0.0405]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c URLsMap) String() string {\r\n\tvar pairs []string\r\n\tfor name, urls := range c {\r\n\t\tfor _, url := range urls {\r\n\t\t\tpairs = append(pairs, fmt.Sprintf(\"%s=%s\", name, url.String()))\r\n\t\t}\r\n\t}\r\n\tsort.Strings(pairs)\r\n\treturn strings.Join(pairs, \",\")\r\n}","code-length":108,"reference":"\/\/ String turns URLsMap into discovery-formatted name-to-URLs sorted by name.","result":"Sort the URLsMap.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c URLsMap) URLs() []string {\r\n\tvar urls []string\r\n\tfor _, us := range c {\r\n\t\tfor _, u := range us {\r\n\t\t\turls = append(urls, u.String())\r\n\t\t}\r\n\t}\r\n\tsort.Strings(urls)\r\n\treturn urls\r\n}","code-length":90,"reference":"\/\/ URLs returns a list of all URLs.\n\/\/ The returned list is sorted in ascending lexicographical order.","result":"Generate the generated code.","score":[0,0.0301]}
{"code":"\/*is used to<extra_id_0>\r\nfunc parse(s string) map[string][]string {\r\n\tm := make(map[string][]string)\r\n\tfor s != \"\" {\r\n\t\tkey := s\r\n\t\tif i := strings.IndexAny(key, \",\"); i >= 0 {\r\n\t\t\tkey, s = key[:i], key[i+1:]\r\n\t\t} else {\r\n\t\t\ts = \"\"\r\n\t\t}\r\n\t\tif key == \"\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvalue := \"\"\r\n\t\tif i := strings.Index(key, \"=\"); i >= 0 {\r\n\t\t\tkey, value = key[:i], key[i+1:]\r\n\t\t}\r\n\t\tm[key] = append(m[key], value)\r\n\t}\r\n\treturn m\r\n}","code-length":205,"reference":"\/\/ parse parses the given string and returns a map listing the values specified for each key.","result":"Parse a string into a map of key.","score":[0.0758,0.2311]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClientHandler(lg *zap.Logger, server etcdserver.ServerPeer, timeout time.Duration) http.Handler {\r\n\tmux := http.NewServeMux()\r\n\tetcdhttp.HandleBasic(mux, server)\r\n\thandleV2(lg, mux, server, timeout)\r\n\treturn requestLogger(lg, mux)\r\n}","code-length":92,"reference":"\/\/ NewClientHandler generates a muxed http.Handler with the given parameters to serve etcd client requests.","result":"Create a new client handler.","score":[0.0387,0.0714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc writeKeyEvent(w http.ResponseWriter, resp etcdserver.Response, noValueOnSuccess bool) error {\r\n\tev := resp.Event\r\n\tif ev == nil {\r\n\t\treturn errors.New(\"cannot write empty Event\")\r\n\t}\r\n\tw.Header().Set(\"Content-Type\", \"application\/json\")\r\n\tw.Header().Set(\"X-Etcd-Index\", fmt.Sprint(ev.EtcdIndex))\r\n\tw.Header().Set(\"X-Raft-Index\", fmt.Sprint(resp.Index))\r\n\tw.Header().Set(\"X-Raft-Term\", fmt.Sprint(resp.Term))\r\n\tif ev.IsCreated() {\r\n\t\tw.WriteHeader(http.StatusCreated)\r\n\t}\r\n\tev = trimEventPrefix(ev, etcdserver.StoreKeysPrefix)\r\n\tif noValueOnSuccess &&\r\n\t\t(ev.Action == v2store.Set || ev.Action == v2store.CompareAndSwap ||\r\n\t\t\tev.Action == v2store.Create || ev.Action == v2store.Update) {\r\n\t\tev.Node = nil\r\n\t\tev.PrevNode = nil\r\n\t}\r\n\treturn json.NewEncoder(w).Encode(ev)\r\n}","code-length":309,"reference":"\/\/ writeKeyEvent trims the prefix of key path in a single Event under\n\/\/ StoreKeysPrefix, serializes it and writes the resulting JSON to the given\n\/\/ ResponseWriter, along with the appropriate headers.","result":"Write key events to the response.","score":[0.004,0.085]}
{"code":"\/*is used to<extra_id_0>\r\nfunc writeKeyError(lg *zap.Logger, w http.ResponseWriter, err error) {\r\n\tif err == nil {\r\n\t\treturn\r\n\t}\r\n\tswitch e := err.(type) {\r\n\tcase *v2error.Error:\r\n\t\te.WriteTo(w)\r\n\tdefault:\r\n\t\tswitch err {\r\n\t\tcase etcdserver.ErrTimeoutDueToLeaderFail, etcdserver.ErrTimeoutDueToConnectionLost:\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"v2 response error\",\r\n\t\t\t\t\tzap.String(\"internal-server-error\", err.Error()),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tmlog.MergeError(err)\r\n\t\t\t}\r\n\t\tdefault:\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"unexpected v2 response error\",\r\n\t\t\t\t\tzap.String(\"internal-server-error\", err.Error()),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tmlog.MergeErrorf(\"got unexpected response error (%v)\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t\tee := v2error.NewError(v2error.EcodeRaftInternal, err.Error(), 0)\r\n\t\tee.WriteTo(w)\r\n\t}\r\n}","code-length":338,"reference":"\/\/ writeKeyError logs and writes the given Error to the ResponseWriter.\n\/\/ If Error is not an etcdErr, the error will be converted to an etcd error.","result":"Write key errors to the response.","score":[0.0082,0.0803]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getUint64(form url.Values, key string) (i uint64, err error) {\r\n\tif vals, ok := form[key]; ok {\r\n\t\ti, err = strconv.ParseUint(vals[0], 10, 64)\r\n\t}\r\n\treturn\r\n}","code-length":77,"reference":"\/\/ getUint64 extracts a uint64 by the given key from a Form. If the key does\n\/\/ not exist in the form, 0 is returned. If the key exists but the value is\n\/\/ badly formed, an error is returned. If multiple values are present only the\n\/\/ first is considered.","result":"Parse the form values.","score":[0.0,0.0108]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getBool(form url.Values, key string) (b bool, err error) {\r\n\tif vals, ok := form[key]; ok {\r\n\t\tb, err = strconv.ParseBool(vals[0])\r\n\t}\r\n\treturn\r\n}","code-length":71,"reference":"\/\/ getBool extracts a bool by the given key from a Form. If the key does not\n\/\/ exist in the form, false is returned. If the key exists but the value is\n\/\/ badly formed, an error is returned. If multiple values are present only the\n\/\/ first is considered.","result":"Parse the form values.","score":[0.0,0.0108]}
{"code":"\/*is used to<extra_id_0>\r\nfunc waitDeletes(ctx context.Context, client *v3.Client, pfx string, maxCreateRev int64) (*pb.ResponseHeader, error) {\r\n\tgetOpts := append(v3.WithLastCreate(), v3.WithMaxCreateRev(maxCreateRev))\r\n\tfor {\r\n\t\tresp, err := client.Get(ctx, pfx, getOpts...)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tif len(resp.Kvs) == 0 {\r\n\t\t\treturn resp.Header, nil\r\n\t\t}\r\n\t\tlastKey := string(resp.Kvs[0].Key)\r\n\t\tif err = waitDelete(ctx, client, lastKey, resp.Header.Revision); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n}","code-length":211,"reference":"\/\/ waitDeletes efficiently waits until all keys matching the prefix and no greater\n\/\/ than the create revision.","result":"Wait for deletes to be deleted.","score":[0,0.0298]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AddOutputPaths(cfg zap.Config, outputPaths, errorOutputPaths []string) zap.Config {\r\n\toutputs := make(map[string]struct{})\r\n\tfor _, v := range cfg.OutputPaths {\r\n\t\toutputs[v] = struct{}{}\r\n\t}\r\n\tfor _, v := range outputPaths {\r\n\t\toutputs[v] = struct{}{}\r\n\t}\r\n\toutputSlice := make([]string, 0)\r\n\tif _, ok := outputs[\"\/dev\/null\"]; ok {\r\n\t\t\r\n\t\toutputSlice = []string{\"\/dev\/null\"}\r\n\t} else {\r\n\t\tfor k := range outputs {\r\n\t\t\toutputSlice = append(outputSlice, k)\r\n\t\t}\r\n\t}\r\n\tcfg.OutputPaths = outputSlice\r\n\tsort.Strings(cfg.OutputPaths)\r\n\terrOutputs := make(map[string]struct{})\r\n\tfor _, v := range cfg.ErrorOutputPaths {\r\n\t\terrOutputs[v] = struct{}{}\r\n\t}\r\n\tfor _, v := range errorOutputPaths {\r\n\t\terrOutputs[v] = struct{}{}\r\n\t}\r\n\terrOutputSlice := make([]string, 0)\r\n\tif _, ok := errOutputs[\"\/dev\/null\"]; ok {\r\n\t\t\r\n\t\terrOutputSlice = []string{\"\/dev\/null\"}\r\n\t} else {\r\n\t\tfor k := range errOutputs {\r\n\t\t\terrOutputSlice = append(errOutputSlice, k)\r\n\t\t}\r\n\t}\r\n\tcfg.ErrorOutputPaths = errOutputSlice\r\n\tsort.Strings(cfg.ErrorOutputPaths)\r\n\treturn cfg\r\n}","code-length":420,"reference":"\/\/ AddOutputPaths adds output paths to the existing output paths, resolving conflicts.","result":"Add output paths to the config.","score":[0.2223,0.3912]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewConfig() *Config {\r\n\tlpurl, _ := url.Parse(DefaultListenPeerURLs)\r\n\tapurl, _ := url.Parse(DefaultInitialAdvertisePeerURLs)\r\n\tlcurl, _ := url.Parse(DefaultListenClientURLs)\r\n\tacurl, _ := url.Parse(DefaultAdvertiseClientURLs)\r\n\tcfg := &Config{\r\n\t\tMaxSnapFiles: DefaultMaxSnapshots,\r\n\t\tMaxWalFiles:  DefaultMaxWALs,\r\n\t\tName: DefaultName,\r\n\t\tSnapshotCount:          etcdserver.DefaultSnapshotCount,\r\n\t\tSnapshotCatchUpEntries: etcdserver.DefaultSnapshotCatchUpEntries,\r\n\t\tMaxTxnOps:       DefaultMaxTxnOps,\r\n\t\tMaxRequestBytes: DefaultMaxRequestBytes,\r\n\t\tGRPCKeepAliveMinTime:  DefaultGRPCKeepAliveMinTime,\r\n\t\tGRPCKeepAliveInterval: DefaultGRPCKeepAliveInterval,\r\n\t\tGRPCKeepAliveTimeout:  DefaultGRPCKeepAliveTimeout,\r\n\t\tTickMs:                     100,\r\n\t\tElectionMs:                 1000,\r\n\t\tInitialElectionTickAdvance: true,\r\n\t\tLPUrls: []url.URL{*lpurl},\r\n\t\tLCUrls: []url.URL{*lcurl},\r\n\t\tAPUrls: []url.URL{*apurl},\r\n\t\tACUrls: []url.URL{*acurl},\r\n\t\tClusterState:        ClusterStateFlagNew,\r\n\t\tInitialClusterToken: \"etcd-cluster\",\r\n\t\tStrictReconfigCheck: DefaultStrictReconfigCheck,\r\n\t\tMetrics:             \"basic\",\r\n\t\tEnableV2:            DefaultEnableV2,\r\n\t\tCORS:          map[string]struct{}{\"*\": {}},\r\n\t\tHostWhitelist: map[string]struct{}{\"*\": {}},\r\n\t\tAuthToken:  \"simple\",\r\n\t\tBcryptCost: uint(bcrypt.DefaultCost),\r\n\t\tPreVote: false,\r\n\t\tloggerMu:            new(sync.RWMutex),\r\n\t\tlogger:              nil,\r\n\t\tLogger:              \"capnslog\",\r\n\t\tDeprecatedLogOutput: []string{DefaultLogOutput},\r\n\t\tLogOutputs:          []string{DefaultLogOutput},\r\n\t\tDebug:               false,\r\n\t\tLogPkgLevels:        \"\",\r\n\t}\r\n\tcfg.InitialCluster = cfg.InitialClusterFromName(cfg.Name)\r\n\treturn cfg\r\n}","code-length":602,"reference":"\/\/ NewConfig creates a new Config populated with default values.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cfg *Config) PeerURLsMapAndToken(which string) (urlsmap types.URLsMap, token string, err error) {\r\n\ttoken = cfg.InitialClusterToken\r\n\tswitch {\r\n\tcase cfg.Durl != \"\":\r\n\t\turlsmap = types.URLsMap{}\r\n\t\t\r\n\t\t\r\n\t\turlsmap[cfg.Name] = cfg.APUrls\r\n\t\ttoken = cfg.Durl\r\n\tcase cfg.DNSCluster != \"\":\r\n\t\tclusterStrs, cerr := cfg.GetDNSClusterNames()\r\n\t\tlg := cfg.logger\r\n\t\tif cerr != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\"failed to resolve during SRV discovery\", zap.Error(cerr))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Errorf(\"couldn't resolve during SRV discovery (%v)\", cerr)\r\n\t\t\t}\r\n\t\t\treturn nil, \"\", cerr\r\n\t\t}\r\n\t\tfor _, s := range clusterStrs {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Info(\"got bootstrap from DNS for etcd-server\", zap.String(\"node\", s))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Noticef(\"got bootstrap from DNS for etcd-server at %s\", s)\r\n\t\t\t}\r\n\t\t}\r\n\t\tclusterStr := strings.Join(clusterStrs, \",\")\r\n\t\tif strings.Contains(clusterStr, \"https:\r\n\t\t\tcfg.PeerTLSInfo.ServerName = cfg.DNSCluster\r\n\t\t}\r\n\t\turlsmap, err = types.NewURLsMap(clusterStr)\r\n\t\t\r\n\t\t\r\n\t\tif which == \"etcd\" {\r\n\t\t\tif _, ok := urlsmap[cfg.Name]; !ok {\r\n\t\t\t\treturn nil, \"\", fmt.Errorf(\"cannot find local etcd member %q in SRV records\", cfg.Name)\r\n\t\t\t}\r\n\t\t}\r\n\tdefault:\r\n\t\t\r\n\t\turlsmap, err = types.NewURLsMap(cfg.InitialCluster)\r\n\t}\r\n\treturn urlsmap, token, err\r\n}","code-length":513,"reference":"\/\/ PeerURLsMapAndToken sets up an initial peer URLsMap and cluster token for bootstrap or discovery.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cfg *Config) GetDNSClusterNames() ([]string, error) {\r\n\tvar (\r\n\t\tclusterStrs       []string\r\n\t\tcerr              error\r\n\t\tserviceNameSuffix string\r\n\t)\r\n\tif cfg.DNSClusterServiceName != \"\" {\r\n\t\tserviceNameSuffix = \"-\" + cfg.DNSClusterServiceName\r\n\t}\r\n\tlg := cfg.GetLogger()\r\n\t\r\n\t\r\n\tclusterStrs, cerr = srv.GetCluster(\"https\", \"etcd-server-ssl\"+serviceNameSuffix, cfg.Name, cfg.DNSCluster, cfg.APUrls)\r\n\tif cerr != nil {\r\n\t\tclusterStrs = make([]string, 0)\r\n\t}\r\n\tif lg != nil {\r\n\t\tlg.Info(\r\n\t\t\t\"get cluster for etcd-server-ssl SRV\",\r\n\t\t\tzap.String(\"service-scheme\", \"https\"),\r\n\t\t\tzap.String(\"service-name\", \"etcd-server-ssl\"+serviceNameSuffix),\r\n\t\t\tzap.String(\"server-name\", cfg.Name),\r\n\t\t\tzap.String(\"discovery-srv\", cfg.DNSCluster),\r\n\t\t\tzap.Strings(\"advertise-peer-urls\", cfg.getAPURLs()),\r\n\t\t\tzap.Strings(\"found-cluster\", clusterStrs),\r\n\t\t\tzap.Error(cerr),\r\n\t\t)\r\n\t}\r\n\tdefaultHTTPClusterStrs, httpCerr := srv.GetCluster(\"http\", \"etcd-server\"+serviceNameSuffix, cfg.Name, cfg.DNSCluster, cfg.APUrls)\r\n\tif httpCerr != nil {\r\n\t\tclusterStrs = append(clusterStrs, defaultHTTPClusterStrs...)\r\n\t}\r\n\tif lg != nil {\r\n\t\tlg.Info(\r\n\t\t\t\"get cluster for etcd-server SRV\",\r\n\t\t\tzap.String(\"service-scheme\", \"http\"),\r\n\t\t\tzap.String(\"service-name\", \"etcd-server\"+serviceNameSuffix),\r\n\t\t\tzap.String(\"server-name\", cfg.Name),\r\n\t\t\tzap.String(\"discovery-srv\", cfg.DNSCluster),\r\n\t\t\tzap.Strings(\"advertise-peer-urls\", cfg.getAPURLs()),\r\n\t\t\tzap.Strings(\"found-cluster\", clusterStrs),\r\n\t\t\tzap.Error(httpCerr),\r\n\t\t)\r\n\t}\r\n\treturn clusterStrs, cerr\r\n}","code-length":593,"reference":"\/\/ GetDNSClusterNames uses DNS SRV records to get a list of initial nodes for cluster bootstrapping.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkBindURLs(urls []url.URL) error {\r\n\tfor _, url := range urls {\r\n\t\tif url.Scheme == \"unix\" || url.Scheme == \"unixs\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\thost, _, err := net.SplitHostPort(url.Host)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif host == \"localhost\" {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif net.ParseIP(host) == nil {\r\n\t\t\treturn fmt.Errorf(\"expected IP in URL for binding (%s)\", url.String())\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":186,"reference":"\/\/ checkBindURLs returns an error if any URL uses a domain name.","result":"Check bind URLs.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetCluster(serviceScheme, service, name, dns string, apurls types.URLs) ([]string, error) {\r\n\ttempName := int(0)\r\n\ttcp2ap := make(map[string]url.URL)\r\n\t\r\n\tfor _, url := range apurls {\r\n\t\ttcpAddr, err := resolveTCPAddr(\"tcp\", url.Host)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\ttcp2ap[tcpAddr.String()] = url\r\n\t}\r\n\tstringParts := []string{}\r\n\tupdateNodeMap := func(service, scheme string) error {\r\n\t\t_, addrs, err := lookupSRV(service, \"tcp\", dns)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tfor _, srv := range addrs {\r\n\t\t\tport := fmt.Sprintf(\"%d\", srv.Port)\r\n\t\t\thost := net.JoinHostPort(srv.Target, port)\r\n\t\t\ttcpAddr, terr := resolveTCPAddr(\"tcp\", host)\r\n\t\t\tif terr != nil {\r\n\t\t\t\terr = terr\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tn := \"\"\r\n\t\t\turl, ok := tcp2ap[tcpAddr.String()]\r\n\t\t\tif ok {\r\n\t\t\t\tn = name\r\n\t\t\t}\r\n\t\t\tif n == \"\" {\r\n\t\t\t\tn = fmt.Sprintf(\"%d\", tempName)\r\n\t\t\t\ttempName++\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tshortHost := strings.TrimSuffix(srv.Target, \".\")\r\n\t\t\turlHost := net.JoinHostPort(shortHost, port)\r\n\t\t\tif ok && url.Scheme != scheme {\r\n\t\t\t\terr = fmt.Errorf(\"bootstrap at %s from DNS for %s has scheme mismatch with expected peer %s\", scheme+\":\r\n\t\t\t} else {\r\n\t\t\t\tstringParts = append(stringParts, fmt.Sprintf(\"%s=%s:\r\n\t\t\t}\r\n\t\t}\r\n\t\tif len(stringParts) == 0 {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\terr := updateNodeMap(service, serviceScheme)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error querying DNS SRV records for _%s %s\", service, err)\r\n\t}\r\n\treturn stringParts, nil\r\n}","code-length":594,"reference":"\/\/ GetCluster gets the cluster information via DNS discovery.\n\/\/ Also sees each entry as a separate instance.","result":"Code too long,keep in 512.","score":[0,0.0299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetClient(service, domain string, serviceName string) (*SRVClients, error) {\r\n\tvar urls []*url.URL\r\n\tvar srvs []*net.SRV\r\n\tupdateURLs := func(service, scheme string) error {\r\n\t\t_, addrs, err := lookupSRV(service, \"tcp\", domain)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tfor _, srv := range addrs {\r\n\t\t\turls = append(urls, &url.URL{\r\n\t\t\t\tScheme: scheme,\r\n\t\t\t\tHost:   net.JoinHostPort(srv.Target, fmt.Sprintf(\"%d\", srv.Port)),\r\n\t\t\t})\r\n\t\t}\r\n\t\tsrvs = append(srvs, addrs...)\r\n\t\treturn nil\r\n\t}\r\n\terrHTTPS := updateURLs(GetSRVService(service, serviceName, \"https\"), \"https\")\r\n\terrHTTP := updateURLs(GetSRVService(service, serviceName, \"http\"), \"http\")\r\n\tif errHTTPS != nil && errHTTP != nil {\r\n\t\treturn nil, fmt.Errorf(\"dns lookup errors: %s and %s\", errHTTPS, errHTTP)\r\n\t}\r\n\tendpoints := make([]string, len(urls))\r\n\tfor i := range urls {\r\n\t\tendpoints[i] = urls[i].String()\r\n\t}\r\n\treturn &SRVClients{Endpoints: endpoints, SRVs: srvs}, nil\r\n}","code-length":365,"reference":"\/\/ GetClient looks up the client endpoints for a service and domain.","result":"Get the client from the DNS server.","score":[0.1118,0.087]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetSRVService(service, serviceName string, scheme string) (SRVService string) {\r\n\tif scheme == \"https\" {\r\n\t\tservice = fmt.Sprintf(\"%s-ssl\", service)\r\n\t}\r\n\tif serviceName != \"\" {\r\n\t\treturn fmt.Sprintf(\"%s-%s\", service, serviceName)\r\n\t}\r\n\treturn service\r\n}","code-length":99,"reference":"\/\/ GetSRVService generates a SRV service including an optional suffix.","result":"Get the SRV service.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReadDir(d string, opts ...ReadDirOption) ([]string, error) {\r\n\top := &ReadDirOp{}\r\n\top.applyOpts(opts)\r\n\tdir, err := os.Open(d)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer dir.Close()\r\n\tnames, err := dir.Readdirnames(-1)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tsort.Strings(names)\r\n\tif op.ext != \"\" {\r\n\t\ttss := make([]string, 0)\r\n\t\tfor _, v := range names {\r\n\t\t\tif filepath.Ext(v) == op.ext {\r\n\t\t\t\ttss = append(tss, v)\r\n\t\t\t}\r\n\t\t}\r\n\t\tnames = tss\r\n\t}\r\n\treturn names, nil\r\n}","code-length":232,"reference":"\/\/ ReadDir returns the filenames in the given directory in sorted order.","result":"Read a directory.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc compact(c *v3.Client, rev int64) {\r\n\tfmt.Printf(\"Compacting with revision %d\\n\", rev)\r\n\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\r\n\t_, err := c.Compact(ctx, rev, v3.WithCompactPhysical())\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tfmt.Printf(\"Compacted with revision %d\\n\", rev)\r\n}","code-length":136,"reference":"\/\/ compact keyspace history to a provided revision","result":"Compact the revision.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc defrag(c *v3.Client, ep string) {\r\n\tfmt.Printf(\"Defragmenting %q\\n\", ep)\r\n\tctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)\r\n\t_, err := c.Defragment(ctx, ep)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tfmt.Printf(\"Defragmented %q\\n\", ep)\r\n}","code-length":128,"reference":"\/\/ defrag a given endpoint","result":"Avoid the need for v.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewUserCommand() *cobra.Command {\r\n\tac := &cobra.Command{\r\n\t\tUse:   \"user <subcommand>\",\r\n\t\tShort: \"User related commands\",\r\n\t}\r\n\tac.AddCommand(newUserAddCommand())\r\n\tac.AddCommand(newUserDeleteCommand())\r\n\tac.AddCommand(newUserGetCommand())\r\n\tac.AddCommand(newUserListCommand())\r\n\tac.AddCommand(newUserChangePasswordCommand())\r\n\tac.AddCommand(newUserGrantRoleCommand())\r\n\tac.AddCommand(newUserRevokeRoleCommand())\r\n\treturn ac\r\n}","code-length":164,"reference":"\/\/ NewUserCommand returns the cobra command for \"user\".","result":"Generate the user command.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc userAddCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"user add command requires user name as its argument\"))\r\n\t}\r\n\tvar password string\r\n\tvar user string\r\n\tif passwordFromFlag != \"\" {\r\n\t\tuser = args[0]\r\n\t\tpassword = passwordFromFlag\r\n\t} else {\r\n\t\tsplitted := strings.SplitN(args[0], \":\", 2)\r\n\t\tif len(splitted) < 2 {\r\n\t\t\tuser = args[0]\r\n\t\t\tif !passwordInteractive {\r\n\t\t\t\tfmt.Scanf(\"%s\", &password)\r\n\t\t\t} else {\r\n\t\t\t\tpassword = readPasswordInteractive(args[0])\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\tuser = splitted[0]\r\n\t\t\tpassword = splitted[1]\r\n\t\t\tif len(user) == 0 {\r\n\t\t\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"empty user name is not allowed\"))\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tresp, err := mustClientFromCmd(cmd).Auth.UserAdd(context.TODO(), user, password)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.UserAdd(user, *resp)\r\n}","code-length":351,"reference":"\/\/ userAddCommandFunc executes the \"user add\" command.","result":"Var userAddCommandFunc userAddCommandFunc.","score":[0.1076,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc userGetCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"user get command requires user name as its argument\"))\r\n\t}\r\n\tname := args[0]\r\n\tclient := mustClientFromCmd(cmd)\r\n\tresp, err := client.Auth.UserGet(context.TODO(), name)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tif userShowDetail {\r\n\t\tfmt.Printf(\"User: %s\\n\", name)\r\n\t\tfor _, role := range resp.Roles {\r\n\t\t\tfmt.Printf(\"\\n\")\r\n\t\t\troleResp, err := client.Auth.RoleGet(context.TODO(), role)\r\n\t\t\tif err != nil {\r\n\t\t\t\tExitWithError(ExitError, err)\r\n\t\t\t}\r\n\t\t\tdisplay.RoleGet(role, *roleResp)\r\n\t\t}\r\n\t} else {\r\n\t\tdisplay.UserGet(name, *resp)\r\n\t}\r\n}","code-length":278,"reference":"\/\/ userGetCommandFunc executes the \"user get\" command.","result":"Generate the user get command.","score":[0.1915,0.1471]}
{"code":"\/*is used to<extra_id_0>\r\nfunc userChangePasswordCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"user passwd command requires user name as its argument\"))\r\n\t}\r\n\tvar password string\r\n\tif !passwordInteractive {\r\n\t\tfmt.Scanf(\"%s\", &password)\r\n\t} else {\r\n\t\tpassword = readPasswordInteractive(args[0])\r\n\t}\r\n\tresp, err := mustClientFromCmd(cmd).Auth.UserChangePassword(context.TODO(), args[0], password)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.UserChangePassword(*resp)\r\n}","code-length":190,"reference":"\/\/ userChangePasswordCommandFunc executes the \"user passwd\" command.","result":"Change password.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (eh *EventHistory) addEvent(e *Event) *Event {\r\n\teh.rwl.Lock()\r\n\tdefer eh.rwl.Unlock()\r\n\teh.Queue.insert(e)\r\n\teh.LastIndex = e.Index()\r\n\teh.StartIndex = eh.Queue.Events[eh.Queue.Front].Index()\r\n\treturn e\r\n}","code-length":104,"reference":"\/\/ addEvent function adds event into the eventHistory","result":"Add events to the event history.","score":[0.1645,0.1923]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (eh *EventHistory) scan(key string, recursive bool, index uint64) (*Event, *v2error.Error) {\r\n\teh.rwl.RLock()\r\n\tdefer eh.rwl.RUnlock()\r\n\t\r\n\tif index < eh.StartIndex {\r\n\t\treturn nil,\r\n\t\t\tv2error.NewError(v2error.EcodeEventIndexCleared,\r\n\t\t\t\tfmt.Sprintf(\"the requested history has been cleared [%v\/%v]\",\r\n\t\t\t\t\teh.StartIndex, index), 0)\r\n\t}\r\n\t\r\n\tif index > eh.LastIndex {\r\n\t\treturn nil, nil\r\n\t}\r\n\toffset := index - eh.StartIndex\r\n\ti := (eh.Queue.Front + int(offset)) % eh.Queue.Capacity\r\n\tfor {\r\n\t\te := eh.Queue.Events[i]\r\n\t\tif !e.Refresh {\r\n\t\t\tok := e.Node.Key == key\r\n\t\t\tif recursive {\r\n\t\t\t\t\r\n\t\t\t\tnkey := path.Clean(key)\r\n\t\t\t\tif nkey[len(nkey)-1] != '\/' {\r\n\t\t\t\t\tnkey = nkey + \"\/\"\r\n\t\t\t\t}\r\n\t\t\t\tok = ok || strings.HasPrefix(e.Node.Key, nkey)\r\n\t\t\t}\r\n\t\t\tif (e.Action == Delete || e.Action == Expire) && e.PrevNode != nil && e.PrevNode.Dir {\r\n\t\t\t\tok = ok || strings.HasPrefix(key, e.PrevNode.Key)\r\n\t\t\t}\r\n\t\t\tif ok {\r\n\t\t\t\treturn e, nil\r\n\t\t\t}\r\n\t\t}\r\n\t\ti = (i + 1) % eh.Queue.Capacity\r\n\t\tif i == eh.Queue.Back {\r\n\t\t\treturn nil, nil\r\n\t\t}\r\n\t}\r\n}","code-length":466,"reference":"\/\/ scan enumerates events from the index history and stops at the first point\n\/\/ where the key matches.","result":"Scan the event history .","score":[0.0174,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (eh *EventHistory) clone() *EventHistory {\r\n\tclonedQueue := eventQueue{\r\n\t\tCapacity: eh.Queue.Capacity,\r\n\t\tEvents:   make([]*Event, eh.Queue.Capacity),\r\n\t\tSize:     eh.Queue.Size,\r\n\t\tFront:    eh.Queue.Front,\r\n\t\tBack:     eh.Queue.Back,\r\n\t}\r\n\tcopy(clonedQueue.Events, eh.Queue.Events)\r\n\treturn &EventHistory{\r\n\t\tStartIndex: eh.StartIndex,\r\n\t\tQueue:      clonedQueue,\r\n\t\tLastIndex:  eh.LastIndex,\r\n\t}\r\n}","code-length":171,"reference":"\/\/ clone will be protected by a stop-world lock\n\/\/ do not need to obtain internal lock","result":"Clone the event history.","score":[0,0.0318]}
{"code":"\/*is used to<extra_id_0>\r\nfunc openSnapshotBackend(cfg ServerConfig, ss *snap.Snapshotter, snapshot raftpb.Snapshot) (backend.Backend, error) {\r\n\tsnapPath, err := ss.DBFilePath(snapshot.Metadata.Index)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to find database snapshot file (%v)\", err)\r\n\t}\r\n\tif err := os.Rename(snapPath, cfg.backendPath()); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to rename database snapshot file (%v)\", err)\r\n\t}\r\n\treturn openBackend(cfg), nil\r\n}","code-length":155,"reference":"\/\/ openSnapshotBackend renames a snapshot db to the current etcd db and opens it.","result":"Open a snapshot backend.","score":[0.0371,0.1966]}
{"code":"\/*is used to<extra_id_0>\r\nfunc openBackend(cfg ServerConfig) backend.Backend {\r\n\tfn := cfg.backendPath()\r\n\tnow, beOpened := time.Now(), make(chan backend.Backend)\r\n\tgo func() {\r\n\t\tbeOpened <- newBackend(cfg)\r\n\t}()\r\n\tselect {\r\n\tcase be := <-beOpened:\r\n\t\tif cfg.Logger != nil {\r\n\t\t\tcfg.Logger.Info(\"opened backend db\", zap.String(\"path\", fn), zap.Duration(\"took\", time.Since(now)))\r\n\t\t}\r\n\t\treturn be\r\n\tcase <-time.After(10 * time.Second):\r\n\t\tif cfg.Logger != nil {\r\n\t\t\tcfg.Logger.Info(\r\n\t\t\t\t\"db file is flocked by another process, or taking too long\",\r\n\t\t\t\tzap.String(\"path\", fn),\r\n\t\t\t\tzap.Duration(\"took\", time.Since(now)),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Warningf(\"another etcd process is using %q and holds the file lock, or loading backend file is taking >10 seconds\", fn)\r\n\t\t\tplog.Warningf(\"waiting for it to exit before starting...\")\r\n\t\t}\r\n\t}\r\n\treturn <-beOpened\r\n}","code-length":319,"reference":"\/\/ openBackend returns a backend using the current etcd db.","result":"Open backend db file.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc recoverSnapshotBackend(cfg ServerConfig, oldbe backend.Backend, snapshot raftpb.Snapshot) (backend.Backend, error) {\r\n\tvar cIndex consistentIndex\r\n\tkv := mvcc.New(cfg.Logger, oldbe, &lease.FakeLessor{}, &cIndex)\r\n\tdefer kv.Close()\r\n\tif snapshot.Metadata.Index <= kv.ConsistentIndex() {\r\n\t\treturn oldbe, nil\r\n\t}\r\n\toldbe.Close()\r\n\treturn openSnapshotBackend(cfg, snap.New(cfg.Logger, cfg.SnapDir()), snapshot)\r\n}","code-length":150,"reference":"\/\/ recoverBackendSnapshot recovers the DB from a snapshot in case etcd crashes\n\/\/ before updating the backend db after persisting raft snapshot to disk,\n\/\/ violating the invariant snapshot.Metadata.Index < db.consistentIndex. In this\n\/\/ case, replace the db with the snapshot db sent by the leader.","result":"Recover the backend from a snapshot.","score":[0.0005,0.0886]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewUpdateCommand() cli.Command {\r\n\treturn cli.Command{\r\n\t\tName:      \"update\",\r\n\t\tUsage:     \"update an existing key with a given value\",\r\n\t\tArgsUsage: \"<key> <value>\",\r\n\t\tFlags: []cli.Flag{\r\n\t\t\tcli.IntFlag{Name: \"ttl\", Value: 0, Usage: \"key time-to-live in seconds\"},\r\n\t\t},\r\n\t\tAction: func(c *cli.Context) error {\r\n\t\t\tupdateCommandFunc(c, mustNewKeyAPI(c))\r\n\t\t\treturn nil\r\n\t\t},\r\n\t}\r\n}","code-length":165,"reference":"\/\/ NewUpdateCommand returns the CLI command for \"update\".","result":"Update the value of a key.","score":[0.1383,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc updateCommandFunc(c *cli.Context, ki client.KeysAPI) {\r\n\tif len(c.Args()) == 0 {\r\n\t\thandleError(c, ExitBadArgs, errors.New(\"key required\"))\r\n\t}\r\n\tkey := c.Args()[0]\r\n\tvalue, err := argOrStdin(c.Args(), os.Stdin, 1)\r\n\tif err != nil {\r\n\t\thandleError(c, ExitBadArgs, errors.New(\"value required\"))\r\n\t}\r\n\tttl := c.Int(\"ttl\")\r\n\tctx, cancel := contextWithTotalTimeout(c)\r\n\tresp, err := ki.Set(ctx, key, value, &client.SetOptions{TTL: time.Duration(ttl) * time.Second, PrevExist: client.PrevExist})\r\n\tcancel()\r\n\tif err != nil {\r\n\t\thandleError(c, ExitServerError, err)\r\n\t}\r\n\tprintResponseKey(resp, c.GlobalString(\"output\"))\r\n}","code-length":253,"reference":"\/\/ updateCommandFunc executes the \"update\" command.","result":"Update a key.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *statsQueue) frontAndBack() (*RequestStats, *RequestStats) {\r\n\tq.rwl.RLock()\r\n\tdefer q.rwl.RUnlock()\r\n\tif q.size != 0 {\r\n\t\treturn q.items[q.front], q.items[q.back]\r\n\t}\r\n\treturn nil, nil\r\n}","code-length":98,"reference":"\/\/ FrontAndBack gets the front and back elements in the queue\n\/\/ We must grab front and back together with the protection of the lock","result":"Get the front and back stats from the queue.","score":[0.0682,0.2184]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *statsQueue) Insert(p *RequestStats) {\r\n\tq.rwl.Lock()\r\n\tdefer q.rwl.Unlock()\r\n\tq.back = (q.back + 1) % queueCapacity\r\n\tif q.size == queueCapacity {\r\n\t\tq.totalReqSize -= q.items[q.front].Size\r\n\t\tq.front = (q.back + 1) % queueCapacity\r\n\t} else {\r\n\t\tq.size++\r\n\t}\r\n\tq.items[q.back] = p\r\n\tq.totalReqSize += q.items[q.back].Size\r\n}","code-length":162,"reference":"\/\/ Insert function insert a RequestStats into the queue and update the records","result":"Insert a new request stats into the queue.","score":[0.125,0.2525]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *statsQueue) Rate() (float64, float64) {\r\n\tfront, back := q.frontAndBack()\r\n\tif front == nil || back == nil {\r\n\t\treturn 0, 0\r\n\t}\r\n\tif time.Since(back.SendingTime) > time.Second {\r\n\t\tq.Clear()\r\n\t\treturn 0, 0\r\n\t}\r\n\tsampleDuration := back.SendingTime.Sub(front.SendingTime)\r\n\tpr := float64(q.Len()) \/ float64(sampleDuration) * float64(time.Second)\r\n\tbr := float64(q.ReqSize()) \/ float64(sampleDuration) * float64(time.Second)\r\n\treturn pr, br\r\n}","code-length":184,"reference":"\/\/ Rate function returns the package rate and byte rate","result":"Calculate the rate of the queue.","score":[0.1179,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (q *statsQueue) Clear() {\r\n\tq.rwl.Lock()\r\n\tdefer q.rwl.Unlock()\r\n\tq.back = -1\r\n\tq.front = 0\r\n\tq.size = 0\r\n\tq.totalReqSize = 0\r\n}","code-length":78,"reference":"\/\/ Clear function clear up the statsQueue","result":"Clear the queue.","score":[0.128,0.1515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UniqueStrings(slen uint, n int) (ss []string) {\r\n\texist := make(map[string]struct{})\r\n\tss = make([]string, 0, n)\r\n\tfor len(ss) < n {\r\n\t\ts := randString(slen)\r\n\t\tif _, ok := exist[s]; !ok {\r\n\t\t\tss = append(ss, s)\r\n\t\t\texist[s] = struct{}{}\r\n\t\t}\r\n\t}\r\n\treturn ss\r\n}","code-length":134,"reference":"\/\/ UniqueStrings returns a slice of randomly generated unique strings.","result":"Generate unique strings.","score":[0.056,0.3166]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RandomStrings(slen uint, n int) (ss []string) {\r\n\tss = make([]string, 0, n)\r\n\tfor i := 0; i < n; i++ {\r\n\t\tss = append(ss, randString(slen))\r\n\t}\r\n\treturn ss\r\n}","code-length":83,"reference":"\/\/ RandomStrings returns a slice of randomly generated strings.","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsKeyNotFound(err error) bool {\r\n\tif cErr, ok := err.(Error); ok {\r\n\t\treturn cErr.Code == ErrorCodeKeyNotFound\r\n\t}\r\n\treturn false\r\n}","code-length":60,"reference":"\/\/ IsKeyNotFound returns true if the error code is ErrorCodeKeyNotFound.","result":"Test the error .","score":[0.1008,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsRoleNotFound(err error) bool {\r\n\tif ae, ok := err.(authError); ok {\r\n\t\treturn roleNotFoundRegExp.MatchString(ae.Message)\r\n\t}\r\n\treturn false\r\n}","code-length":63,"reference":"\/\/ IsRoleNotFound returns true if the error means role not found of v2 API.","result":"Match the regex.","score":[0.0104,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsUserNotFound(err error) bool {\r\n\tif ae, ok := err.(authError); ok {\r\n\t\treturn userNotFoundRegExp.MatchString(ae.Message)\r\n\t}\r\n\treturn false\r\n}","code-length":63,"reference":"\/\/ IsUserNotFound returns true if the error means user not found of v2 API.","result":"Detect user not found error.","score":[0.0818,0.2248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc JoinCluster(lg *zap.Logger, durl, dproxyurl string, id types.ID, config string) (string, error) {\r\n\td, err := newDiscovery(lg, durl, dproxyurl, id)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn d.joinCluster(config)\r\n}","code-length":96,"reference":"\/\/ JoinCluster will connect to the discovery service at the given url, and\n\/\/ register the server represented by the given id and config to the cluster","result":"Config string.","score":[0,0.0204]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetCluster(lg *zap.Logger, durl, dproxyurl string) (string, error) {\r\n\td, err := newDiscovery(lg, durl, dproxyurl, 0)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn d.getCluster()\r\n}","code-length":86,"reference":"\/\/ GetCluster will connect to the discovery service at the given url and\n\/\/ retrieve a string describing the cluster","result":"Get the cluster name.","score":[0.0083,0.1019]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newProxyFunc(lg *zap.Logger, proxy string) (func(*http.Request) (*url.URL, error), error) {\r\n\tif proxy == \"\" {\r\n\t\treturn nil, nil\r\n\t}\r\n\t\r\n\t\r\n\tproxyURL, err := url.Parse(proxy)\r\n\tif err != nil || !strings.HasPrefix(proxyURL.Scheme, \"http\") {\r\n\t\terr2 error\r\n\t\tproxyURL, err2 = url.Parse(\"http:\r\n\t\tif err2 == nil {\r\n\t\t\terr = nil\r\n\t\t}\r\n\t}\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"invalid proxy address %q: %v\", proxy, err)\r\n\t}\r\n\tif lg != nil {\r\n\t\tlg.Info(\"running proxy with discovery\", zap.String(\"proxy-url\", proxyURL.String()))\r\n\t} else {\r\n\t\tplog.Infof(\"using proxy %q\", proxyURL.String())\r\n\t}\r\n\treturn http.ProxyURL(proxyURL), nil\r\n}","code-length":271,"reference":"\/\/ newProxyFunc builds a proxy function from the given string, which should\n\/\/ represent a URL that can be used as a proxy. It performs basic\n\/\/ sanitization of the URL and returns any error encountered.","result":"Create a proxy function .","score":[0.001,0.0777]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isSafeRetry(lg *zap.Logger, err error, callOpts *options) bool {\r\n\tif isContextError(err) {\r\n\t\treturn false\r\n\t}\r\n\tswitch callOpts.retryPolicy {\r\n\tcase repeatable:\r\n\t\treturn isSafeRetryImmutableRPC(err)\r\n\tcase nonRepeatable:\r\n\t\treturn isSafeRetryMutableRPC(err)\r\n\tdefault:\r\n\t\tlg.Warn(\"unrecognized retry policy\", zap.String(\"retryPolicy\", callOpts.retryPolicy.String()))\r\n\t\treturn false\r\n\t}\r\n}","code-length":150,"reference":"\/\/ isSafeRetry returns \"true\", if request is safe for retry with the given error.","result":"Check if the error is safe to retry.","score":[0.1103,0.2355]}
{"code":"\/*is used to<extra_id_0>\r\nfunc withRetryPolicy(rp retryPolicy) retryOption {\r\n\treturn retryOption{applyFunc: func(o *options) {\r\n\t\to.retryPolicy = rp\r\n\t}}\r\n}","code-length":55,"reference":"\/\/ withRetryPolicy sets the retry policy of this call.","result":"Generate the file.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc withAuthRetry(retryAuth bool) retryOption {\r\n\treturn retryOption{applyFunc: func(o *options) {\r\n\t\to.retryAuth = retryAuth\r\n\t}}\r\n}","code-length":56,"reference":"\/\/ withAuthRetry sets enables authentication retries.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc withMax(maxRetries uint) retryOption {\r\n\treturn retryOption{applyFunc: func(o *options) {\r\n\t\to.max = maxRetries\r\n\t}}\r\n}","code-length":53,"reference":"\/\/ withMax sets the maximum number of retries on this call, or this interceptor.","result":"Generate the generated code.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc withBackoff(bf backoffFunc) retryOption {\r\n\treturn retryOption{applyFunc: func(o *options) {\r\n\t\to.backoffFunc = bf\r\n\t}}\r\n}","code-length":55,"reference":"\/\/ WithBackoff sets the `BackoffFunc `used to control time between retries.","result":"Generate the code.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ss *ServerStats) RecvAppendReq(leader string, reqSize int) {\r\n\tss.Lock()\r\n\tdefer ss.Unlock()\r\n\tnow := time.Now()\r\n\tss.State = raft.StateFollower\r\n\tif leader != ss.LeaderInfo.Name {\r\n\t\tss.LeaderInfo.Name = leader\r\n\t\tss.LeaderInfo.StartTime = now\r\n\t}\r\n\tss.recvRateQueue.Insert(\r\n\t\t&RequestStats{\r\n\t\t\tSendingTime: now,\r\n\t\t\tSize:        reqSize,\r\n\t\t},\r\n\t)\r\n\tss.RecvAppendRequestCnt++\r\n}","code-length":165,"reference":"\/\/ RecvAppendReq updates the ServerStats in response to an AppendRequest\n\/\/ from the given leader being received","result":"Send a request to the leader.","score":[0.0367,0.0629]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ss *ServerStats) SendAppendReq(reqSize int) {\r\n\tss.Lock()\r\n\tdefer ss.Unlock()\r\n\tss.becomeLeader()\r\n\tss.sendRateQueue.Insert(\r\n\t\t&RequestStats{\r\n\t\t\tSendingTime: time.Now(),\r\n\t\t\tSize:        reqSize,\r\n\t\t},\r\n\t)\r\n\tss.SendAppendRequestCnt++\r\n}","code-length":112,"reference":"\/\/ SendAppendReq updates the ServerStats in response to an AppendRequest\n\/\/ being sent by this server","result":"Send append requests to the leader.","score":[0.0434,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (bb *bucketBuffer) merge(bbsrc *bucketBuffer) {\r\n\tfor i := 0; i < bbsrc.used; i++ {\r\n\t\tbb.add(bbsrc.buf[i].key, bbsrc.buf[i].val)\r\n\t}\r\n\tif bb.used == bbsrc.used {\r\n\t\treturn\r\n\t}\r\n\tif bytes.Compare(bb.buf[(bb.used-bbsrc.used)-1].key, bbsrc.buf[0].key) < 0 {\r\n\t\treturn\r\n\t}\r\n\tsort.Stable(bb)\r\n\t\r\n\twidx := 0\r\n\tfor ridx := 1; ridx < bb.used; ridx++ {\r\n\t\tif !bytes.Equal(bb.buf[ridx].key, bb.buf[widx].key) {\r\n\t\t\twidx++\r\n\t\t}\r\n\t\tbb.buf[widx] = bb.buf[ridx]\r\n\t}\r\n\tbb.used = widx + 1\r\n}","code-length":266,"reference":"\/\/ merge merges data from bb into bbsrc.","result":"Merge the two buffers.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc deleteRevKey(kv v3.KV, key string, rev int64) (bool, error) {\r\n\tcmp := v3.Compare(v3.ModRevision(key), \"=\", rev)\r\n\treq := v3.OpDelete(key)\r\n\ttxnresp, err := kv.Txn(context.TODO()).If(cmp).Then(req).Commit()\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t} else if !txnresp.Succeeded {\r\n\t\treturn false, nil\r\n\t}\r\n\treturn true, nil\r\n}","code-length":145,"reference":"\/\/ deleteRevKey deletes a key by revision, returning false if key is missing","result":"Delete rev key.","score":[0,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isMemberBootstrapped(lg *zap.Logger, cl *membership.RaftCluster, member string, rt http.RoundTripper, timeout time.Duration) bool {\r\n\trcl, err := getClusterFromRemotePeers(lg, getRemotePeerURLs(cl, member), timeout, false, rt)\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\tid := cl.MemberByName(member).ID\r\n\tm := rcl.Member(id)\r\n\tif m == nil {\r\n\t\treturn false\r\n\t}\r\n\tif len(m.ClientURLs) > 0 {\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":169,"reference":"\/\/ isMemberBootstrapped tries to check if the given member has been bootstrapped\n\/\/ in the given cluster.","result":"Check if the member is bootstrapped.","score":[0.0483,0.1985]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetClusterFromRemotePeers(lg *zap.Logger, urls []string, rt http.RoundTripper) (*membership.RaftCluster, error) {\r\n\treturn getClusterFromRemotePeers(lg, urls, 10*time.Second, true, rt)\r\n}","code-length":71,"reference":"\/\/ GetClusterFromRemotePeers takes a set of URLs representing etcd peers, and\n\/\/ attempts to construct a Cluster by accessing the members endpoint on one of\n\/\/ these URLs. The first URL to provide a response is used. If no URLs provide\n\/\/ a response, or a Cluster cannot be successfully created from a received\n\/\/ response, an error is returned.\n\/\/ Each request has a 10-second timeout. Because the upper limit of TTL is 5s,\n\/\/ 10 second is enough for building connection and finishing request.","result":"Get cluster from remote peers.","score":[0.0,0.0193]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getClusterFromRemotePeers(lg *zap.Logger, urls []string, timeout time.Duration, logerr bool, rt http.RoundTripper) (*membership.RaftCluster, error) {\r\n\tcc := &http.Client{\r\n\t\tTransport: rt,\r\n\t\tTimeout:   timeout,\r\n\t}\r\n\tfor _, u := range urls {\r\n\t\taddr := u + \"\/members\"\r\n\t\tresp, err := cc.Get(addr)\r\n\t\tif err != nil {\r\n\t\t\tif logerr {\r\n\t\t\t\tif lg != nil {\r\n\t\t\t\t\tlg.Warn(\"failed to get cluster response\", zap.String(\"address\", addr), zap.Error(err))\r\n\t\t\t\t} else {\r\n\t\t\t\t\tplog.Warningf(\"could not get cluster response from %s: %v\", u, err)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tb, err := ioutil.ReadAll(resp.Body)\r\n\t\tresp.Body.Close()\r\n\t\tif err != nil {\r\n\t\t\tif logerr {\r\n\t\t\t\tif lg != nil {\r\n\t\t\t\t\tlg.Warn(\"failed to read body of cluster response\", zap.String(\"address\", addr), zap.Error(err))\r\n\t\t\t\t} else {\r\n\t\t\t\t\tplog.Warningf(\"could not read the body of cluster response: %v\", err)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvar membs []*membership.Member\r\n\t\tif err = json.Unmarshal(b, &membs); err != nil {\r\n\t\t\tif logerr {\r\n\t\t\t\tif lg != nil {\r\n\t\t\t\t\tlg.Warn(\"failed to unmarshal cluster response\", zap.String(\"address\", addr), zap.Error(err))\r\n\t\t\t\t} else {\r\n\t\t\t\t\tplog.Warningf(\"could not unmarshal cluster response: %v\", err)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tid, err := types.IDFromString(resp.Header.Get(\"X-Etcd-Cluster-ID\"))\r\n\t\tif err != nil {\r\n\t\t\tif logerr {\r\n\t\t\t\tif lg != nil {\r\n\t\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\t\"failed to parse cluster ID\",\r\n\t\t\t\t\t\tzap.String(\"address\", addr),\r\n\t\t\t\t\t\tzap.String(\"header\", resp.Header.Get(\"X-Etcd-Cluster-ID\")),\r\n\t\t\t\t\t\tzap.Error(err),\r\n\t\t\t\t\t)\r\n\t\t\t\t} else {\r\n\t\t\t\t\tplog.Warningf(\"could not parse the cluster ID from cluster res: %v\", err)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif len(membs) > 0 {\r\n\t\t\treturn membership.NewClusterFromMembers(lg, \"\", id, membs), nil\r\n\t\t}\r\n\t\treturn nil, fmt.Errorf(\"failed to get raft cluster member(s) from the given URLs\")\r\n\t}\r\n\treturn nil, fmt.Errorf(\"could not retrieve cluster information from the given URLs\")\r\n}","code-length":770,"reference":"\/\/ If logerr is true, it prints out more error messages.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getRemotePeerURLs(cl *membership.RaftCluster, local string) []string {\r\n\tus := make([]string, 0)\r\n\tfor _, m := range cl.Members() {\r\n\t\tif m.Name == local {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tus = append(us, m.PeerURLs...)\r\n\t}\r\n\tsort.Strings(us)\r\n\treturn us\r\n}","code-length":111,"reference":"\/\/ getRemotePeerURLs returns peer urls of remote members in the cluster. The\n\/\/ returned list is sorted in ascending lexicographical order.","result":"Get remote peer URLs.","score":[0.0054,0.0518]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getVersions(lg *zap.Logger, cl *membership.RaftCluster, local types.ID, rt http.RoundTripper) map[string]*version.Versions {\r\n\tmembers := cl.Members()\r\n\tvers := make(map[string]*version.Versions)\r\n\tfor _, m := range members {\r\n\t\tif m.ID == local {\r\n\t\t\tcv := \"not_decided\"\r\n\t\t\tif cl.Version() != nil {\r\n\t\t\t\tcv = cl.Version().String()\r\n\t\t\t}\r\n\t\t\tvers[m.ID.String()] = &version.Versions{Server: version.Version, Cluster: cv}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tver, err := getVersion(lg, m, rt)\r\n\t\tif err != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\"failed to get version\", zap.String(\"remote-member-id\", m.ID.String()), zap.Error(err))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Warningf(\"cannot get the version of member %s (%v)\", m.ID, err)\r\n\t\t\t}\r\n\t\t\tvers[m.ID.String()] = nil\r\n\t\t} else {\r\n\t\t\tvers[m.ID.String()] = ver\r\n\t\t}\r\n\t}\r\n\treturn vers\r\n}","code-length":338,"reference":"\/\/ getVersions returns the versions of the members in the given cluster.\n\/\/ The key of the returned map is the member's ID. The value of the returned map\n\/\/ is the semver versions string, including server and cluster.\n\/\/ If it fails to get the version of a member, the key will be nil.","result":"Get the versions of all members in the cluster.","score":[0.0024,0.1252]}
{"code":"\/*is used to<extra_id_0>\r\nfunc decideClusterVersion(lg *zap.Logger, vers map[string]*version.Versions) *semver.Version {\r\n\tvar cv *semver.Version\r\n\tlv := semver.Must(semver.NewVersion(version.Version))\r\n\tfor mid, ver := range vers {\r\n\t\tif ver == nil {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tv, err := semver.NewVersion(ver.Server)\r\n\t\tif err != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"failed to parse server version of remote member\",\r\n\t\t\t\t\tzap.String(\"remote-member-id\", mid),\r\n\t\t\t\t\tzap.String(\"remote-member-version\", ver.Server),\r\n\t\t\t\t\tzap.Error(err),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Errorf(\"cannot understand the version of member %s (%v)\", mid, err)\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tif lv.LessThan(*v) {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"leader found higher-versioned member\",\r\n\t\t\t\t\tzap.String(\"local-member-version\", lv.String()),\r\n\t\t\t\t\tzap.String(\"remote-member-id\", mid),\r\n\t\t\t\t\tzap.String(\"remote-member-version\", ver.Server),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Warningf(\"the local etcd version %s is not up-to-date\", lv.String())\r\n\t\t\t\tplog.Warningf(\"member %s has a higher version %s\", mid, ver.Server)\r\n\t\t\t}\r\n\t\t}\r\n\t\tif cv == nil {\r\n\t\t\tcv = v\r\n\t\t} else if v.LessThan(*cv) {\r\n\t\t\tcv = v\r\n\t\t}\r\n\t}\r\n\treturn cv\r\n}","code-length":480,"reference":"\/\/ decideClusterVersion decides the cluster version based on the versions map.\n\/\/ The returned version is the min server version in the map, or nil if the min\n\/\/ version in unknown.","result":"Decide the cluster version.","score":[0.0004,0.0514]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getVersion(lg *zap.Logger, m *membership.Member, rt http.RoundTripper) (*version.Versions, error) {\r\n\tcc := &http.Client{\r\n\t\tTransport: rt,\r\n\t}\r\n\tvar (\r\n\t\terr  error\r\n\t\tresp *http.Response\r\n\t)\r\n\tfor _, u := range m.PeerURLs {\r\n\t\taddr := u + \"\/version\"\r\n\t\tresp, err = cc.Get(addr)\r\n\t\tif err != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"failed to reach the peer URL\",\r\n\t\t\t\t\tzap.String(\"address\", addr),\r\n\t\t\t\t\tzap.String(\"remote-member-id\", m.ID.String()),\r\n\t\t\t\t\tzap.Error(err),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Warningf(\"failed to reach the peerURL(%s) of member %s (%v)\", u, m.ID, err)\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvar b []byte\r\n\t\tb, err = ioutil.ReadAll(resp.Body)\r\n\t\tresp.Body.Close()\r\n\t\tif err != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"failed to read body of response\",\r\n\t\t\t\t\tzap.String(\"address\", addr),\r\n\t\t\t\t\tzap.String(\"remote-member-id\", m.ID.String()),\r\n\t\t\t\t\tzap.Error(err),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Warningf(\"failed to read out the response body from the peerURL(%s) of member %s (%v)\", u, m.ID, err)\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvar vers version.Versions\r\n\t\tif err = json.Unmarshal(b, &vers); err != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Warn(\r\n\t\t\t\t\t\"failed to unmarshal response\",\r\n\t\t\t\t\tzap.String(\"address\", addr),\r\n\t\t\t\t\tzap.String(\"remote-member-id\", m.ID.String()),\r\n\t\t\t\t\tzap.Error(err),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Warningf(\"failed to unmarshal the response body got from the peerURL(%s) of member %s (%v)\", u, m.ID, err)\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\treturn &vers, nil\r\n\t}\r\n\treturn nil, err\r\n}","code-length":651,"reference":"\/\/ getVersion returns the Versions of the given member via its\n\/\/ peerURLs. Returns the last error if it fails to get the version.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTimeoutDetector(maxDuration time.Duration) *TimeoutDetector {\r\n\treturn &TimeoutDetector{\r\n\t\tmaxDuration: maxDuration,\r\n\t\trecords:     make(map[uint64]time.Time),\r\n\t}\r\n}","code-length":67,"reference":"\/\/ NewTimeoutDetector creates the TimeoutDetector.","result":"Create a new timeout detector.","score":[0,0.1]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (td *TimeoutDetector) Reset() {\r\n\ttd.mu.Lock()\r\n\tdefer td.mu.Unlock()\r\n\ttd.records = make(map[uint64]time.Time)\r\n}","code-length":59,"reference":"\/\/ Reset resets the NewTimeoutDetector.","result":"Reset the timeout detector.","score":[0.2959,0.2041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (td *TimeoutDetector) Observe(which uint64) (bool, time.Duration) {\r\n\ttd.mu.Lock()\r\n\tdefer td.mu.Unlock()\r\n\tok := true\r\n\tnow := time.Now()\r\n\texceed := time.Duration(0)\r\n\tif pt, found := td.records[which]; found {\r\n\t\texceed = now.Sub(pt) - td.maxDuration\r\n\t\tif exceed > 0 {\r\n\t\t\tok = false\r\n\t\t}\r\n\t}\r\n\ttd.records[which] = now\r\n\treturn ok, exceed\r\n}","code-length":156,"reference":"\/\/ Observe observes an event for given id. It returns false and exceeded duration\n\/\/ if the interval is longer than the expectation.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPeerHandler(lg *zap.Logger, s etcdserver.ServerPeer) http.Handler {\r\n\treturn newPeerHandler(lg, s.Cluster(), s.RaftHandler(), s.LeaseHandler())\r\n}","code-length":60,"reference":"\/\/ NewPeerHandler generates an http.Handler to handle etcd peer requests.","result":"Create a new peer handler.","score":[0.0884,0.0526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ki *keyIndex) put(lg *zap.Logger, main int64, sub int64) {\r\n\trev := revision{main: main, sub: sub}\r\n\tif !rev.GreaterThan(ki.modified) {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Panic(\r\n\t\t\t\t\"'put' with an unexpected smaller revision\",\r\n\t\t\t\tzap.Int64(\"given-revision-main\", rev.main),\r\n\t\t\t\tzap.Int64(\"given-revision-sub\", rev.sub),\r\n\t\t\t\tzap.Int64(\"modified-revision-main\", ki.modified.main),\r\n\t\t\t\tzap.Int64(\"modified-revision-sub\", ki.modified.sub),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Panicf(\"store.keyindex: put with unexpected smaller revision [%v \/ %v]\", rev, ki.modified)\r\n\t\t}\r\n\t}\r\n\tif len(ki.generations) == 0 {\r\n\t\tki.generations = append(ki.generations, generation{})\r\n\t}\r\n\tg := &ki.generations[len(ki.generations)-1]\r\n\tif len(g.revs) == 0 {\r\n\t\tkeysGauge.Inc()\r\n\t\tg.created = rev\r\n\t}\r\n\tg.revs = append(g.revs, rev)\r\n\tg.ver++\r\n\tki.modified = rev\r\n}","code-length":359,"reference":"\/\/ put puts a revision to the keyIndex.","result":"Store the keyIndex.","score":[0.109,0.25]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ki *keyIndex) tombstone(lg *zap.Logger, main int64, sub int64) error {\r\n\tif ki.isEmpty() {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Panic(\r\n\t\t\t\t\"'tombstone' got an unexpected empty keyIndex\",\r\n\t\t\t\tzap.String(\"key\", string(ki.key)),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Panicf(\"store.keyindex: unexpected tombstone on empty keyIndex %s\", string(ki.key))\r\n\t\t}\r\n\t}\r\n\tif ki.generations[len(ki.generations)-1].isEmpty() {\r\n\t\treturn ErrRevisionNotFound\r\n\t}\r\n\tki.put(lg, main, sub)\r\n\tki.generations = append(ki.generations, generation{})\r\n\tkeysGauge.Dec()\r\n\treturn nil\r\n}","code-length":230,"reference":"\/\/ tombstone puts a revision, pointing to a tombstone, to the keyIndex.\n\/\/ It also creates a new empty generation in the keyIndex.\n\/\/ It returns ErrRevisionNotFound when tombstone on an empty generation.","result":"Store tombstones in the store.","score":[0.0013,0.0846]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ki *keyIndex) get(lg *zap.Logger, atRev int64) (modified, created revision, ver int64, err error) {\r\n\tif ki.isEmpty() {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Panic(\r\n\t\t\t\t\"'get' got an unexpected empty keyIndex\",\r\n\t\t\t\tzap.String(\"key\", string(ki.key)),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Panicf(\"store.keyindex: unexpected get on empty keyIndex %s\", string(ki.key))\r\n\t\t}\r\n\t}\r\n\tg := ki.findGeneration(atRev)\r\n\tif g.isEmpty() {\r\n\t\treturn revision{}, revision{}, 0, ErrRevisionNotFound\r\n\t}\r\n\tn := g.walk(func(rev revision) bool { return rev.main > atRev })\r\n\tif n != -1 {\r\n\t\treturn g.revs[n], g.created, g.ver - int64(len(g.revs)-n-1), nil\r\n\t}\r\n\treturn revision{}, revision{}, 0, ErrRevisionNotFound\r\n}","code-length":288,"reference":"\/\/ get gets the modified, created revision and version of the key that satisfies the given atRev.\n\/\/ Rev must be higher than or equal to the given atRev.","result":"Get the revision of a key.","score":[0.0055,0.0749]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ki *keyIndex) since(lg *zap.Logger, rev int64) []revision {\r\n\tif ki.isEmpty() {\r\n\t\tif lg != nil {\r\n\t\t\tlg.Panic(\r\n\t\t\t\t\"'since' got an unexpected empty keyIndex\",\r\n\t\t\t\tzap.String(\"key\", string(ki.key)),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Panicf(\"store.keyindex: unexpected get on empty keyIndex %s\", string(ki.key))\r\n\t\t}\r\n\t}\r\n\tsince := revision{rev, 0}\r\n\tvar gi int\r\n\t\r\n\tfor gi = len(ki.generations) - 1; gi > 0; gi-- {\r\n\t\tg := ki.generations[gi]\r\n\t\tif g.isEmpty() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif since.GreaterThan(g.created) {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tvar revs []revision\r\n\tvar last int64\r\n\tfor ; gi < len(ki.generations); gi++ {\r\n\t\tfor _, r := range ki.generations[gi].revs {\r\n\t\t\tif since.GreaterThan(r) {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tif r.main == last {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\trevs[len(revs)-1] = r\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\trevs = append(revs, r)\r\n\t\t\tlast = r.main\r\n\t\t}\r\n\t}\r\n\treturn revs\r\n}","code-length":405,"reference":"\/\/ since returns revisions since the given rev. Only the revision with the\n\/\/ largest sub revision will be returned if multiple revisions have the same\n\/\/ main revision.","result":"Get the latest revision of a key.","score":[0.0083,0.0954]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ki *keyIndex) keep(atRev int64, available map[revision]struct{}) {\r\n\tif ki.isEmpty() {\r\n\t\treturn\r\n\t}\r\n\tgenIdx, revIndex := ki.doCompact(atRev, available)\r\n\tg := &ki.generations[genIdx]\r\n\tif !g.isEmpty() {\r\n\t\t\r\n\t\tif revIndex == len(g.revs)-1 && genIdx != len(ki.generations)-1 {\r\n\t\t\tdelete(available, g.revs[revIndex])\r\n\t\t}\r\n\t}\r\n}","code-length":155,"reference":"\/\/ keep finds the revision to be kept if compact is called at given atRev.","result":"Keep the index.","score":[0.0075,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ki *keyIndex) findGeneration(rev int64) *generation {\r\n\tlastg := len(ki.generations) - 1\r\n\tcg := lastg\r\n\tfor cg >= 0 {\r\n\t\tif len(ki.generations[cg].revs) == 0 {\r\n\t\t\tcg--\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tg := ki.generations[cg]\r\n\t\tif cg != lastg {\r\n\t\t\tif tomb := g.revs[len(g.revs)-1].main; tomb <= rev {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t}\r\n\t\tif g.revs[0].main <= rev {\r\n\t\t\treturn &ki.generations[cg]\r\n\t\t}\r\n\t\tcg--\r\n\t}\r\n\treturn nil\r\n}","code-length":210,"reference":"\/\/ findGeneration finds out the generation of the keyIndex that the\n\/\/ given rev belongs to. If the given rev is at the gap of two generations,\n\/\/ which means that the key does not exist at the given rev, it returns nil.","result":"Find the generation of a key.","score":[0.0008,0.0509]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *watchableStore) cancelWatcher(wa *watcher) {\r\n\tfor {\r\n\t\ts.mu.Lock()\r\n\t\tif s.unsynced.delete(wa) {\r\n\t\t\tslowWatcherGauge.Dec()\r\n\t\t\tbreak\r\n\t\t} else if s.synced.delete(wa) {\r\n\t\t\tbreak\r\n\t\t} else if wa.compacted {\r\n\t\t\tbreak\r\n\t\t} else if wa.ch == nil {\r\n\t\t\t\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif !wa.victim {\r\n\t\t\tpanic(\"watcher not victim but not in watch groups\")\r\n\t\t}\r\n\t\tvar victimBatch watcherBatch\r\n\t\tfor _, wb := range s.victims {\r\n\t\t\tif wb[wa] != nil {\r\n\t\t\t\tvictimBatch = wb\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif victimBatch != nil {\r\n\t\t\tslowWatcherGauge.Dec()\r\n\t\t\tdelete(victimBatch, wa)\r\n\t\t\tbreak\r\n\t\t}\r\n\t\t\r\n\t\ts.mu.Unlock()\r\n\t\ttime.Sleep(time.Millisecond)\r\n\t}\r\n\twatcherGauge.Dec()\r\n\twa.ch = nil\r\n\ts.mu.Unlock()\r\n}","code-length":340,"reference":"\/\/ cancelWatcher removes references of the watcher from the watchableStore","result":"Cancel watchers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *watchableStore) syncWatchersLoop() {\r\n\tdefer s.wg.Done()\r\n\tfor {\r\n\t\ts.mu.RLock()\r\n\t\tst := time.Now()\r\n\t\tlastUnsyncedWatchers := s.unsynced.size()\r\n\t\ts.mu.RUnlock()\r\n\t\tunsyncedWatchers := 0\r\n\t\tif lastUnsyncedWatchers > 0 {\r\n\t\t\tunsyncedWatchers = s.syncWatchers()\r\n\t\t}\r\n\t\tsyncDuration := time.Since(st)\r\n\t\twaitDuration := 100 * time.Millisecond\r\n\t\t\r\n\t\tif unsyncedWatchers != 0 && lastUnsyncedWatchers > unsyncedWatchers {\r\n\t\t\t\r\n\t\t\twaitDuration = syncDuration\r\n\t\t}\r\n\t\tselect {\r\n\t\tcase <-time.After(waitDuration):\r\n\t\tcase <-s.stopc:\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":255,"reference":"\/\/ syncWatchersLoop syncs the watcher in the unsynced map every 100ms.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *watchableStore) syncVictimsLoop() {\r\n\tdefer s.wg.Done()\r\n\tfor {\r\n\t\tfor s.moveVictims() != 0 {\r\n\t\t\t\r\n\t\t}\r\n\t\ts.mu.RLock()\r\n\t\tisEmpty := len(s.victims) == 0\r\n\t\ts.mu.RUnlock()\r\n\t\tvar tickc <-chan time.Time\r\n\t\tif !isEmpty {\r\n\t\t\ttickc = time.After(10 * time.Millisecond)\r\n\t\t}\r\n\t\tselect {\r\n\t\tcase <-tickc:\r\n\t\tcase <-s.victimc:\r\n\t\tcase <-s.stopc:\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":200,"reference":"\/\/ syncVictimsLoop tries to write precomputed watcher responses to\n\/\/ watchers that had a blocked watcher channel","result":"Sync victims.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *watchableStore) moveVictims() (moved int) {\r\n\ts.mu.Lock()\r\n\tvictims := s.victims\r\n\ts.victims = nil\r\n\ts.mu.Unlock()\r\n\tvar newVictim watcherBatch\r\n\tfor _, wb := range victims {\r\n\t\t\r\n\t\tfor w, eb := range wb {\r\n\t\t\t\r\n\t\t\trev := w.minRev - 1\r\n\t\t\tif w.send(WatchResponse{WatchID: w.id, Events: eb.evs, Revision: rev}) {\r\n\t\t\t\tpendingEventsGauge.Add(float64(len(eb.evs)))\r\n\t\t\t} else {\r\n\t\t\t\tif newVictim == nil {\r\n\t\t\t\t\tnewVictim = make(watcherBatch)\r\n\t\t\t\t}\r\n\t\t\t\tnewVictim[w] = eb\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tmoved++\r\n\t\t}\r\n\t\t\r\n\t\ts.mu.Lock()\r\n\t\ts.store.revMu.RLock()\r\n\t\tcurRev := s.store.currentRev\r\n\t\tfor w, eb := range wb {\r\n\t\t\tif newVictim != nil && newVictim[w] != nil {\r\n\t\t\t\t\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tw.victim = false\r\n\t\t\tif eb.moreRev != 0 {\r\n\t\t\t\tw.minRev = eb.moreRev\r\n\t\t\t}\r\n\t\t\tif w.minRev <= curRev {\r\n\t\t\t\ts.unsynced.add(w)\r\n\t\t\t} else {\r\n\t\t\t\tslowWatcherGauge.Dec()\r\n\t\t\t\ts.synced.add(w)\r\n\t\t\t}\r\n\t\t}\r\n\t\ts.store.revMu.RUnlock()\r\n\t\ts.mu.Unlock()\r\n\t}\r\n\tif len(newVictim) > 0 {\r\n\t\ts.mu.Lock()\r\n\t\ts.victims = append(s.victims, newVictim)\r\n\t\ts.mu.Unlock()\r\n\t}\r\n\treturn moved\r\n}","code-length":531,"reference":"\/\/ moveVictims tries to update watches with already pending event data","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc kvsToEvents(lg *zap.Logger, wg *watcherGroup, revs, vals [][]byte) (evs []mvccpb.Event) {\r\n\tfor i, v := range vals {\r\n\t\tvar kv mvccpb.KeyValue\r\n\t\tif err := kv.Unmarshal(v); err != nil {\r\n\t\t\tif lg != nil {\r\n\t\t\t\tlg.Panic(\"failed to unmarshal mvccpb.KeyValue\", zap.Error(err))\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"cannot unmarshal event: %v\", err)\r\n\t\t\t}\r\n\t\t}\r\n\t\tif !wg.contains(string(kv.Key)) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tty := mvccpb.PUT\r\n\t\tif isTombstone(revs[i]) {\r\n\t\t\tty = mvccpb.DELETE\r\n\t\t\t\r\n\t\t\tkv.ModRevision = bytesToRev(revs[i]).main\r\n\t\t}\r\n\t\tevs = append(evs, mvccpb.Event{Kv: &kv, Type: ty})\r\n\t}\r\n\treturn evs\r\n}","code-length":286,"reference":"\/\/ kvsToEvents gets all events for the watchers from all key-value pairs","result":"Convert kvs to events.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *watchableStore) notify(rev int64, evs []mvccpb.Event) {\r\n\tvar victim watcherBatch\r\n\tfor w, eb := range newWatcherBatch(&s.synced, evs) {\r\n\t\tif eb.revs != 1 {\r\n\t\t\tif s.store != nil && s.store.lg != nil {\r\n\t\t\t\ts.store.lg.Panic(\r\n\t\t\t\t\t\"unexpected multiple revisions in watch notification\",\r\n\t\t\t\t\tzap.Int(\"number-of-revisions\", eb.revs),\r\n\t\t\t\t)\r\n\t\t\t} else {\r\n\t\t\t\tplog.Panicf(\"unexpected multiple revisions in notification\")\r\n\t\t\t}\r\n\t\t}\r\n\t\tif w.send(WatchResponse{WatchID: w.id, Events: eb.evs, Revision: rev}) {\r\n\t\t\tpendingEventsGauge.Add(float64(len(eb.evs)))\r\n\t\t} else {\r\n\t\t\t\r\n\t\t\tw.minRev = rev + 1\r\n\t\t\tif victim == nil {\r\n\t\t\t\tvictim = make(watcherBatch)\r\n\t\t\t}\r\n\t\t\tw.victim = true\r\n\t\t\tvictim[w] = eb\r\n\t\t\ts.synced.delete(w)\r\n\t\t\tslowWatcherGauge.Inc()\r\n\t\t}\r\n\t}\r\n\ts.addVictim(victim)\r\n}","code-length":347,"reference":"\/\/ notify notifies the fact that given event at the given rev just happened to\n\/\/ watchers that watch on the key of the event.","result":"Notify watchers.","score":[0,0.022]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isOpFuncCalled(op string, opts []OpOption) bool {\r\n\tfor _, opt := range opts {\r\n\t\tv := reflect.ValueOf(opt)\r\n\t\tif v.Kind() == reflect.Func {\r\n\t\t\tif opFunc := runtime.FuncForPC(v.Pointer()); opFunc != nil {\r\n\t\t\t\tif strings.Contains(opFunc.Name(), op) {\r\n\t\t\t\t\treturn true\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":136,"reference":"\/\/ Check if the provided function is being called in the op options.","result":"Check if the op is a function call.","score":[0.1957,0.4089]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *batchTx) UnsafePut(bucketName []byte, key []byte, value []byte) {\r\n\tt.unsafePut(bucketName, key, value, false)\r\n}","code-length":54,"reference":"\/\/ UnsafePut must be called holding the lock on the tx.","result":"Store the state of the transaction.","score":[0.0998,0.0952]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *batchTx) UnsafeSeqPut(bucketName []byte, key []byte, value []byte) {\r\n\tt.unsafePut(bucketName, key, value, true)\r\n}","code-length":55,"reference":"\/\/ UnsafeSeqPut must be called holding the lock on the tx.","result":"Store the transaction context.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *batchTx) UnsafeRange(bucketName, key, endKey []byte, limit int64) ([][]byte, [][]byte) {\r\n\tbucket := t.tx.Bucket(bucketName)\r\n\tif bucket == nil {\r\n\t\tif t.backend.lg != nil {\r\n\t\t\tt.backend.lg.Fatal(\r\n\t\t\t\t\"failed to find a bucket\",\r\n\t\t\t\tzap.String(\"bucket-name\", string(bucketName)),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Fatalf(\"bucket %s does not exist\", bucketName)\r\n\t\t}\r\n\t}\r\n\treturn unsafeRange(bucket.Cursor(), key, endKey, limit)\r\n}","code-length":181,"reference":"\/\/ UnsafeRange must be called holding the lock on the tx.","result":"Fetch the range of keys in.","score":[0.0839,0.0952]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *batchTx) UnsafeDelete(bucketName []byte, key []byte) {\r\n\tbucket := t.tx.Bucket(bucketName)\r\n\tif bucket == nil {\r\n\t\tif t.backend.lg != nil {\r\n\t\t\tt.backend.lg.Fatal(\r\n\t\t\t\t\"failed to find a bucket\",\r\n\t\t\t\tzap.String(\"bucket-name\", string(bucketName)),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Fatalf(\"bucket %s does not exist\", bucketName)\r\n\t\t}\r\n\t}\r\n\terr := bucket.Delete(key)\r\n\tif err != nil {\r\n\t\tif t.backend.lg != nil {\r\n\t\t\tt.backend.lg.Fatal(\r\n\t\t\t\t\"failed to delete a key\",\r\n\t\t\t\tzap.String(\"bucket-name\", string(bucketName)),\r\n\t\t\t\tzap.Error(err),\r\n\t\t\t)\r\n\t\t} else {\r\n\t\t\tplog.Fatalf(\"cannot delete key from bucket (%v)\", err)\r\n\t\t}\r\n\t}\r\n\tt.pending++\r\n}","code-length":283,"reference":"\/\/ UnsafeDelete must be called holding the lock on the tx.","result":"Delete a key from a bucket.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *batchTx) UnsafeForEach(bucketName []byte, visitor func(k, v []byte) error) error {\r\n\treturn unsafeForEach(t.tx, bucketName, visitor)\r\n}","code-length":57,"reference":"\/\/ UnsafeForEach must be called holding the lock on the tx.","result":"Generate the generated code.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *batchTx) Commit() {\r\n\tt.Lock()\r\n\tt.commit(false)\r\n\tt.Unlock()\r\n}","code-length":45,"reference":"\/\/ Commit commits a previous tx and begins a new writable one.","result":"Commit the transaction.","score":[0.0203,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *batchTx) CommitAndStop() {\r\n\tt.Lock()\r\n\tt.commit(true)\r\n\tt.Unlock()\r\n}","code-length":47,"reference":"\/\/ CommitAndStop commits the previous tx and does not create a new one.","result":"Commit and stop the transaction.","score":[0.0577,0.123]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (le *lessor) Renew(id LeaseID) (int64, error) {\r\n\tle.mu.RLock()\r\n\tif !le.isPrimary() {\r\n\t\t\r\n\t\tle.mu.RUnlock()\r\n\t\treturn -1, ErrNotPrimary\r\n\t}\r\n\tdemotec := le.demotec\r\n\tl := le.leaseMap[id]\r\n\tif l == nil {\r\n\t\tle.mu.RUnlock()\r\n\t\treturn -1, ErrLeaseNotFound\r\n\t}\r\n\t\r\n\tclearRemainingTTL := le.cp != nil && l.remainingTTL > 0\r\n\tle.mu.RUnlock()\r\n\tif l.expired() {\r\n\t\tselect {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tcase <-l.revokec:\r\n\t\t\treturn -1, ErrLeaseNotFound\r\n\t\t\r\n\t\t\r\n\t\tcase <-demotec:\r\n\t\t\treturn -1, ErrNotPrimary\r\n\t\tcase <-le.stopC:\r\n\t\t\treturn -1, ErrNotPrimary\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tif clearRemainingTTL {\r\n\t\tle.cp(context.Background(), &pb.LeaseCheckpointRequest{Checkpoints: []*pb.LeaseCheckpoint{{ID: int64(l.ID), Remaining_TTL: 0}}})\r\n\t}\r\n\tle.mu.Lock()\r\n\tl.refresh(0)\r\n\titem := &LeaseWithTime{id: l.ID, time: l.expiry.UnixNano()}\r\n\theap.Push(&le.leaseHeap, item)\r\n\tle.mu.Unlock()\r\n\tleaseRenewed.Inc()\r\n\treturn l.ttl, nil\r\n}","code-length":427,"reference":"\/\/ Renew renews an existing lease. If the given lease does not exist or\n\/\/ has expired, an error will be returned.","result":"Renew a lease in the lessor.","score":[0.0177,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (le *lessor) Attach(id LeaseID, items []LeaseItem) error {\r\n\tle.mu.Lock()\r\n\tdefer le.mu.Unlock()\r\n\tl := le.leaseMap[id]\r\n\tif l == nil {\r\n\t\treturn ErrLeaseNotFound\r\n\t}\r\n\tl.mu.Lock()\r\n\tfor _, it := range items {\r\n\t\tl.itemSet[it] = struct{}{}\r\n\t\tle.itemMap[it] = id\r\n\t}\r\n\tl.mu.Unlock()\r\n\treturn nil\r\n}","code-length":149,"reference":"\/\/ Attach attaches items to the lease with given ID. When the lease\n\/\/ expires, the attached items will be automatically removed.\n\/\/ If the given lease does not exist, an error will be returned.","result":"Create a new lessor.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (le *lessor) revokeExpiredLeases() {\r\n\tvar ls []*Lease\r\n\t\r\n\trevokeLimit := leaseRevokeRate \/ 2\r\n\tle.mu.RLock()\r\n\tif le.isPrimary() {\r\n\t\tls = le.findExpiredLeases(revokeLimit)\r\n\t}\r\n\tle.mu.RUnlock()\r\n\tif len(ls) != 0 {\r\n\t\tselect {\r\n\t\tcase <-le.stopC:\r\n\t\t\treturn\r\n\t\tcase le.expiredC <- ls:\r\n\t\tdefault:\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t}\r\n\t}\r\n}","code-length":168,"reference":"\/\/ revokeExpiredLeases finds all leases past their expiry and sends them to epxired channel for\n\/\/ to be revoked.","result":"Revoke expired leases.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (le *lessor) checkpointScheduledLeases() {\r\n\tvar cps []*pb.LeaseCheckpoint\r\n\t\r\n\tfor i := 0; i < leaseCheckpointRate\/2; i++ {\r\n\t\tle.mu.Lock()\r\n\t\tif le.isPrimary() {\r\n\t\t\tcps = le.findDueScheduledCheckpoints(maxLeaseCheckpointBatchSize)\r\n\t\t}\r\n\t\tle.mu.Unlock()\r\n\t\tif len(cps) != 0 {\r\n\t\t\tle.cp(context.Background(), &pb.LeaseCheckpointRequest{Checkpoints: cps})\r\n\t\t}\r\n\t\tif len(cps) < maxLeaseCheckpointBatchSize {\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":188,"reference":"\/\/ checkpointScheduledLeases finds all scheduled lease checkpoints that are due and\n\/\/ submits them to the checkpointer to persist them to the consensus log.","result":"Checkpoint scheduled leases.","score":[0.0004,0.0457]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (le *lessor) expireExists() (l *Lease, ok bool, next bool) {\r\n\tif le.leaseHeap.Len() == 0 {\r\n\t\treturn nil, false, false\r\n\t}\r\n\titem := le.leaseHeap[0]\r\n\tl = le.leaseMap[item.id]\r\n\tif l == nil {\r\n\t\t\r\n\t\t\r\n\t\theap.Pop(&le.leaseHeap)\r\n\t\treturn nil, false, true\r\n\t}\r\n\tif time.Now().UnixNano() < item.time  {\r\n\t\t\r\n\t\t\r\n\t\treturn l, false, false\r\n\t}\r\n\t\r\n\theap.Pop(&le.leaseHeap)\r\n\treturn l, true, false\r\n}","code-length":192,"reference":"\/\/ expireExists returns true if expiry items exist.\n\/\/ It pops only when expiry item exists.\n\/\/ \"next\" is true, to indicate that it may exist in next attempt.","result":"Check if the lease is expired.","score":[0.005,0.0375]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (le *lessor) findExpiredLeases(limit int) []*Lease {\r\n\tleases := make([]*Lease, 0, 16)\r\n\tfor {\r\n\t\tl, ok, next := le.expireExists()\r\n\t\tif !ok && !next {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif !ok {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif next {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif l.expired() {\r\n\t\t\tleases = append(leases, l)\r\n\t\t\t\r\n\t\t\tif len(leases) == limit {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn leases\r\n}","code-length":187,"reference":"\/\/ findExpiredLeases loops leases in the leaseMap until reaching expired limit\n\/\/ and returns the expired leases that needed to be revoked.","result":"Find expired leases.","score":[0.0007,0.0249]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *Lease) refresh(extend time.Duration) {\r\n\tnewExpiry := time.Now().Add(extend + time.Duration(l.RemainingTTL())*time.Second)\r\n\tl.expiryMu.Lock()\r\n\tdefer l.expiryMu.Unlock()\r\n\tl.expiry = newExpiry\r\n}","code-length":84,"reference":"\/\/ refresh refreshes the expiry of the lease.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *Lease) forever() {\r\n\tl.expiryMu.Lock()\r\n\tdefer l.expiryMu.Unlock()\r\n\tl.expiry = forever\r\n}","code-length":50,"reference":"\/\/ forever sets the expiry of lease to be forever.","result":"Create a new file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *Lease) Keys() []string {\r\n\tl.mu.RLock()\r\n\tkeys := make([]string, 0, len(l.itemSet))\r\n\tfor k := range l.itemSet {\r\n\t\tkeys = append(keys, k.Key)\r\n\t}\r\n\tl.mu.RUnlock()\r\n\treturn keys\r\n}","code-length":97,"reference":"\/\/ Keys returns all the keys attached to the lease.","result":"Generate the keys for the itemSet.","score":[0.1551,0.2662]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *Lease) Remaining() time.Duration {\r\n\tl.expiryMu.RLock()\r\n\tdefer l.expiryMu.RUnlock()\r\n\tif l.expiry.IsZero() {\r\n\t\treturn time.Duration(math.MaxInt64)\r\n\t}\r\n\treturn time.Until(l.expiry)\r\n}","code-length":91,"reference":"\/\/ Remaining returns the remaining time of the lease.","result":"Calculate the remaining time of the lease.","score":[0.6287,0.6802]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCompactionCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"compaction [options] <revision>\",\r\n\t\tShort: \"Compacts the event history in etcd\",\r\n\t\tRun:   compactionCommandFunc,\r\n\t}\r\n\tcmd.Flags().BoolVar(&compactPhysical, \"physical\", false, \"'true' to wait for compaction to physically remove all old revisions\")\r\n\treturn cmd\r\n}","code-length":123,"reference":"\/\/ NewCompactionCommand returns the cobra command for \"compaction\".","result":"Create a new compaction command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc compactionCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"compaction command needs 1 argument\"))\r\n\t}\r\n\trev, err := strconv.ParseInt(args[0], 10, 64)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tvar opts []clientv3.CompactOption\r\n\tif compactPhysical {\r\n\t\topts = append(opts, clientv3.WithCompactPhysical())\r\n\t}\r\n\tc := mustClientFromCmd(cmd)\r\n\tctx, cancel := commandCtx(cmd)\r\n\t_, cerr := c.Compact(ctx, rev, opts...)\r\n\tcancel()\r\n\tif cerr != nil {\r\n\t\tExitWithError(ExitError, cerr)\r\n\t}\r\n\tfmt.Println(\"compacted revision\", rev)\r\n}","code-length":237,"reference":"\/\/ compactionCommandFunc executes the \"compaction\" command.","result":"Run the compaction command.","score":[0.2304,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPutCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"put [options] <key> <value> (<value> can also be given from stdin)\",\r\n\t\tShort: \"Puts the given key into the store\",\r\n\t\tLong: `\r\nPuts the given key into the store.\r\nWhen <value> begins with '-', <value> is interpreted as a flag.\r\nInsert '--' for workaround:\r\n$ put <key> -- <value>\r\n$ put -- <key> <value>\r\nIf <value> isn't given as a command line argument and '--ignore-value' is not specified,\r\nthis command tries to read the value from standard input.\r\nIf <lease> isn't given as a command line argument and '--ignore-lease' is not specified,\r\nthis command tries to read the value from standard input.\r\nFor example,\r\n$ cat file | put <key>\r\nwill store the content of the file to <key>.\r\n`,\r\n\t\tRun: putCommandFunc,\r\n\t}\r\n\tcmd.Flags().StringVar(&leaseStr, \"lease\", \"0\", \"lease ID (in hexadecimal) to attach to the key\")\r\n\tcmd.Flags().BoolVar(&putPrevKV, \"prev-kv\", false, \"return the previous key-value pair before modification\")\r\n\tcmd.Flags().BoolVar(&putIgnoreVal, \"ignore-value\", false, \"updates the key using its current value\")\r\n\tcmd.Flags().BoolVar(&putIgnoreLease, \"ignore-lease\", false, \"updates the key using its current lease\")\r\n\treturn cmd\r\n}","code-length":398,"reference":"\/\/ NewPutCommand returns the cobra command for \"put\".","result":"Generate the command .","score":[0.1398,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc putCommandFunc(cmd *cobra.Command, args []string) {\r\n\tkey, value, opts := getPutOp(args)\r\n\tctx, cancel := commandCtx(cmd)\r\n\tresp, err := mustClientFromCmd(cmd).Put(ctx, key, value, opts...)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.Put(*resp)\r\n}","code-length":119,"reference":"\/\/ putCommandFunc executes the \"put\" command.","result":"Replace the default command function.","score":[0.1967,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewHandler(t *http.Transport, urlsFunc GetProxyURLs, failureWait time.Duration, refreshInterval time.Duration) http.Handler {\r\n\tif t.TLSClientConfig != nil {\r\n\t\t\r\n\t\terr := http2.ConfigureTransport(t)\r\n\t\tif err != nil {\r\n\t\t\tplog.Infof(\"Error enabling Transport HTTP\/2 support: %v\", err)\r\n\t\t}\r\n\t}\r\n\tp := &reverseProxy{\r\n\t\tdirector:  newDirector(urlsFunc, failureWait, refreshInterval),\r\n\t\ttransport: t,\r\n\t}\r\n\tmux := http.NewServeMux()\r\n\tmux.Handle(\"\/\", p)\r\n\tmux.HandleFunc(\"\/v2\/config\/local\/proxy\", p.configHandler)\r\n\treturn mux\r\n}","code-length":208,"reference":"\/\/ NewHandler creates a new HTTP handler, listening on the given transport,\n\/\/ which will proxy requests to an etcd cluster.\n\/\/ The handler will periodically update its view of the cluster.","result":"Create a reverse proxy handler.","score":[0.0013,0.0872]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewReadonlyHandler(hdlr http.Handler) http.Handler {\r\n\treadonly := readonlyHandlerFunc(hdlr)\r\n\treturn http.HandlerFunc(readonly)\r\n}","code-length":53,"reference":"\/\/ NewReadonlyHandler wraps the given HTTP handler to allow only GET requests","result":"Create a readonly handler.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSetCommand() cli.Command {\r\n\treturn cli.Command{\r\n\t\tName:      \"set\",\r\n\t\tUsage:     \"set the value of a key\",\r\n\t\tArgsUsage: \"<key> <value>\",\r\n\t\tDescription: `Set sets the value of a key.\r\n   When <value> begins with '-', <value> is interpreted as a flag.\r\n   Insert '--' for workaround:\r\n   $ set -- <key> <value>`,\r\n\t\tFlags: []cli.Flag{\r\n\t\t\tcli.IntFlag{Name: \"ttl\", Value: 0, Usage: \"key time-to-live in seconds\"},\r\n\t\t\tcli.StringFlag{Name: \"swap-with-value\", Value: \"\", Usage: \"previous value\"},\r\n\t\t\tcli.IntFlag{Name: \"swap-with-index\", Value: 0, Usage: \"previous index\"},\r\n\t\t},\r\n\t\tAction: func(c *cli.Context) error {\r\n\t\t\tsetCommandFunc(c, mustNewKeyAPI(c))\r\n\t\t\treturn nil\r\n\t\t},\r\n\t}\r\n}","code-length":276,"reference":"\/\/ NewSetCommand returns the CLI command for \"set\".","result":"Set the value of a key.","score":[0.1383,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc setCommandFunc(c *cli.Context, ki client.KeysAPI) {\r\n\tif len(c.Args()) == 0 {\r\n\t\thandleError(c, ExitBadArgs, errors.New(\"key required\"))\r\n\t}\r\n\tkey := c.Args()[0]\r\n\tvalue, err := argOrStdin(c.Args(), os.Stdin, 1)\r\n\tif err != nil {\r\n\t\thandleError(c, ExitBadArgs, errors.New(\"value required\"))\r\n\t}\r\n\tttl := c.Int(\"ttl\")\r\n\tprevValue := c.String(\"swap-with-value\")\r\n\tprevIndex := c.Int(\"swap-with-index\")\r\n\tctx, cancel := contextWithTotalTimeout(c)\r\n\tresp, err := ki.Set(ctx, key, value, &client.SetOptions{TTL: time.Duration(ttl) * time.Second, PrevIndex: uint64(prevIndex), PrevValue: prevValue})\r\n\tcancel()\r\n\tif err != nil {\r\n\t\thandleError(c, ExitServerError, err)\r\n\t}\r\n\tprintResponseKey(resp, c.GlobalString(\"output\"))\r\n}","code-length":292,"reference":"\/\/ setCommandFunc executes the \"set\" command.","result":"Set a value.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rwm *RWMutex) waitOnLastRev(pfx string) (bool, error) {\r\n\tclient := rwm.s.Client()\r\n\t\r\n\topts := append(v3.WithLastRev(), v3.WithMaxModRev(rwm.myKey.Revision()-1))\r\n\tlastKey, err := client.Get(rwm.ctx, pfx, opts...)\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\tif len(lastKey.Kvs) == 0 {\r\n\t\treturn true, nil\r\n\t}\r\n\t\r\n\t_, err = WaitEvents(\r\n\t\tclient,\r\n\t\tstring(lastKey.Kvs[0].Key),\r\n\t\trwm.myKey.Revision(),\r\n\t\t[]mvccpb.Event_EventType{mvccpb.DELETE})\r\n\treturn false, err\r\n}","code-length":224,"reference":"\/\/ waitOnLowest will wait on the last key with a revision < rwm.myKey.Revision with a\n\/\/ given prefix. If there are no keys left to wait on, return true.","result":"Wait on last rev.","score":[0.0007,0.0566]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetDefaultInterfaces() (map[string]uint8, error) {\r\n\treturn nil, fmt.Errorf(\"default host not supported on %s_%s\", runtime.GOOS, runtime.GOARCH)\r\n}","code-length":58,"reference":"\/\/ GetDefaultInterfaces fetches the device name of default routable interface.","result":"Get default interfaces.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSnapshotCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"snapshot <subcommand>\",\r\n\t\tShort: \"Manages etcd node snapshots\",\r\n\t}\r\n\tcmd.AddCommand(NewSnapshotSaveCommand())\r\n\tcmd.AddCommand(NewSnapshotRestoreCommand())\r\n\tcmd.AddCommand(newSnapshotStatusCommand())\r\n\treturn cmd\r\n}","code-length":112,"reference":"\/\/ NewSnapshotCommand returns the cobra command for \"snapshot\".","result":"Create a snapshot command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMoveLeaderCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"move-leader <transferee-member-id>\",\r\n\t\tShort: \"Transfers leadership to another etcd cluster member.\",\r\n\t\tRun:   transferLeadershipCommandFunc,\r\n\t}\r\n\treturn cmd\r\n}","code-length":97,"reference":"\/\/ NewMoveLeaderCommand returns the cobra command for \"move-leader\".","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc transferLeadershipCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 1 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"move-leader command needs 1 argument\"))\r\n\t}\r\n\ttarget, err := strconv.ParseUint(args[0], 16, 64)\r\n\tif err != nil {\r\n\t\tExitWithError(ExitBadArgs, err)\r\n\t}\r\n\tc := mustClientFromCmd(cmd)\r\n\teps := c.Endpoints()\r\n\tc.Close()\r\n\tctx, cancel := commandCtx(cmd)\r\n\t\r\n\tvar leaderCli *clientv3.Client\r\n\tvar leaderID uint64\r\n\tfor _, ep := range eps {\r\n\t\tcfg := clientConfigFromCmd(cmd)\r\n\t\tcfg.endpoints = []string{ep}\r\n\t\tcli := cfg.mustClient()\r\n\t\tresp, serr := cli.Status(ctx, ep)\r\n\t\tif serr != nil {\r\n\t\t\tExitWithError(ExitError, serr)\r\n\t\t}\r\n\t\tif resp.Header.GetMemberId() == resp.Leader {\r\n\t\t\tleaderCli = cli\r\n\t\t\tleaderID = resp.Leader\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tcli.Close()\r\n\t}\r\n\tif leaderCli == nil {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"no leader endpoint given at %v\", eps))\r\n\t}\r\n\tvar resp *clientv3.MoveLeaderResponse\r\n\tresp, err = leaderCli.MoveLeader(ctx, target)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.MoveLeader(leaderID, target, *resp)\r\n}","code-length":442,"reference":"\/\/ transferLeadershipCommandFunc executes the \"compaction\" command.","result":"Transfer leadership to other members.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OpenDir(path string) (*os.File, error) {\r\n\tfd, err := openDir(path)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn os.NewFile(uintptr(fd), path), nil\r\n}","code-length":77,"reference":"\/\/ OpenDir opens a directory in windows with write access for syncing.","result":"Open a directory.","score":[0.0203,0.1689]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRemoveDirCommand() cli.Command {\r\n\treturn cli.Command{\r\n\t\tName:      \"rmdir\",\r\n\t\tUsage:     \"removes the key if it is an empty directory or a key-value pair\",\r\n\t\tArgsUsage: \"<key>\",\r\n\t\tAction: func(c *cli.Context) error {\r\n\t\t\trmdirCommandFunc(c, mustNewKeyAPI(c))\r\n\t\t\treturn nil\r\n\t\t},\r\n\t}\r\n}","code-length":126,"reference":"\/\/ NewRemoveDirCommand returns the CLI command for \"rmdir\".","result":"Remove a directory.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc rmdirCommandFunc(c *cli.Context, ki client.KeysAPI) {\r\n\tif len(c.Args()) == 0 {\r\n\t\thandleError(c, ExitBadArgs, errors.New(\"key required\"))\r\n\t}\r\n\tkey := c.Args()[0]\r\n\tctx, cancel := contextWithTotalTimeout(c)\r\n\tresp, err := ki.Delete(ctx, key, &client.DeleteOptions{Dir: true})\r\n\tcancel()\r\n\tif err != nil {\r\n\t\thandleError(c, ExitServerError, err)\r\n\t}\r\n\tif !resp.Node.Dir || c.GlobalString(\"output\") != \"simple\" {\r\n\t\tprintResponseKey(resp, c.GlobalString(\"output\"))\r\n\t}\r\n}","code-length":195,"reference":"\/\/ rmdirCommandFunc executes the \"rmdir\" command.","result":"Remove a directory.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDelCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"del [options] <key> [range_end]\",\r\n\t\tShort: \"Removes the specified key or range of keys [key, range_end)\",\r\n\t\tRun:   delCommandFunc,\r\n\t}\r\n\tcmd.Flags().BoolVar(&delPrefix, \"prefix\", false, \"delete keys with matching prefix\")\r\n\tcmd.Flags().BoolVar(&delPrevKV, \"prev-kv\", false, \"return deleted key-value pairs\")\r\n\tcmd.Flags().BoolVar(&delFromKey, \"from-key\", false, \"delete keys that are greater than or equal to the given key using byte compare\")\r\n\treturn cmd\r\n}","code-length":195,"reference":"\/\/ NewDelCommand returns the cobra command for \"del\".","result":"Create a new DelCommand.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc delCommandFunc(cmd *cobra.Command, args []string) {\r\n\tkey, opts := getDelOp(args)\r\n\tctx, cancel := commandCtx(cmd)\r\n\tresp, err := mustClientFromCmd(cmd).Delete(ctx, key, opts...)\r\n\tcancel()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.Del(*resp)\r\n}","code-length":114,"reference":"\/\/ delCommandFunc executes the \"del\" command.","result":"Delete a key.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewExpect(name string, arg ...string) (ep *ExpectProcess, err error) {\r\n\t\r\n\treturn NewExpectWithEnv(name, arg, nil)\r\n}","code-length":51,"reference":"\/\/ NewExpect creates a new process for expect testing.","result":"Create a new expect process.","score":[0.169,0.436]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewExpectWithEnv(name string, args []string, env []string) (ep *ExpectProcess, err error) {\r\n\tcmd := exec.Command(name, args...)\r\n\tcmd.Env = env\r\n\tep = &ExpectProcess{\r\n\t\tcmd:        cmd,\r\n\t\tStopSignal: syscall.SIGKILL,\r\n\t}\r\n\tep.cond = sync.NewCond(&ep.mu)\r\n\tep.cmd.Stderr = ep.cmd.Stdout\r\n\tep.cmd.Stdin = nil\r\n\tif ep.fpty, err = pty.Start(ep.cmd); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tep.wg.Add(1)\r\n\tgo ep.read()\r\n\treturn ep, nil\r\n}","code-length":199,"reference":"\/\/ NewExpectWithEnv creates a new process with user defined env variables for expect testing.","result":"Create a new expect process.","score":[0.0622,0.2863]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ep *ExpectProcess) ExpectFunc(f func(string) bool) (string, error) {\r\n\tep.mu.Lock()\r\n\tfor {\r\n\t\tfor len(ep.lines) == 0 && ep.err == nil {\r\n\t\t\tep.cond.Wait()\r\n\t\t}\r\n\t\tif len(ep.lines) == 0 {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tl := ep.lines[0]\r\n\t\tep.lines = ep.lines[1:]\r\n\t\tif f(l) {\r\n\t\t\tep.mu.Unlock()\r\n\t\t\treturn l, nil\r\n\t\t}\r\n\t}\r\n\tep.mu.Unlock()\r\n\treturn \"\", ep.err\r\n}","code-length":188,"reference":"\/\/ ExpectFunc returns the first line satisfying the function f.","result":"Test the code.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ep *ExpectProcess) Expect(s string) (string, error) {\r\n\treturn ep.ExpectFunc(func(txt string) bool { return strings.Contains(txt, s) })\r\n}","code-length":57,"reference":"\/\/ Expect returns the first line containing the given string.","result":"Test the ExpectProcess interface .","score":[0.0884,0.0526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ep *ExpectProcess) LineCount() int {\r\n\tep.mu.Lock()\r\n\tdefer ep.mu.Unlock()\r\n\treturn ep.count\r\n}","code-length":50,"reference":"\/\/ LineCount returns the number of recorded lines since\n\/\/ the beginning of the process.","result":"Test the tests.","score":[0.0075,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ep *ExpectProcess) Signal(sig os.Signal) error {\r\n\treturn ep.cmd.Process.Signal(sig)\r\n}","code-length":42,"reference":"\/\/ Signal sends a signal to the expect process","result":"Test the tests.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc keyFunc(req *pb.RangeRequest) string {\r\n\t\r\n\tb, err := req.Marshal()\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\treturn string(b)\r\n}","code-length":68,"reference":"\/\/ keyFunc returns the key of a request, which is used to look up its caching response in the cache.","result":"Generate the keyFunc.","score":[0.0014,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *cache) Add(req *pb.RangeRequest, resp *pb.RangeResponse) {\r\n\tkey := keyFunc(req)\r\n\tc.mu.Lock()\r\n\tdefer c.mu.Unlock()\r\n\tif req.Revision > c.compactedRev {\r\n\t\tc.lru.Add(key, resp)\r\n\t}\r\n\t\r\n\t\r\n\tif req.Revision != 0 {\r\n\t\treturn\r\n\t}\r\n\tvar (\r\n\t\tiv  *adt.IntervalValue\r\n\t\tivl adt.Interval\r\n\t)\r\n\tif len(req.RangeEnd) != 0 {\r\n\t\tivl = adt.NewStringAffineInterval(string(req.Key), string(req.RangeEnd))\r\n\t} else {\r\n\t\tivl = adt.NewStringAffinePoint(string(req.Key))\r\n\t}\r\n\tiv = c.cachedRanges.Find(ivl)\r\n\tif iv == nil {\r\n\t\tval := map[string]struct{}{key: {}}\r\n\t\tc.cachedRanges.Insert(ivl, val)\r\n\t} else {\r\n\t\tval := iv.Val.(map[string]struct{})\r\n\t\tval[key] = struct{}{}\r\n\t\tiv.Val = val\r\n\t}\r\n}","code-length":333,"reference":"\/\/ Add adds the response of a request to the cache if its revision is larger than the compacted revision of the cache.","result":"Add range requests to the cache.","score":[0.0211,0.2094]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *cache) Get(req *pb.RangeRequest) (*pb.RangeResponse, error) {\r\n\tkey := keyFunc(req)\r\n\tc.mu.Lock()\r\n\tdefer c.mu.Unlock()\r\n\tif req.Revision > 0 && req.Revision < c.compactedRev {\r\n\t\tc.lru.Remove(key)\r\n\t\treturn nil, ErrCompacted\r\n\t}\r\n\tif resp, ok := c.lru.Get(key); ok {\r\n\t\treturn resp.(*pb.RangeResponse), nil\r\n\t}\r\n\treturn nil, errors.New(\"not exist\")\r\n}","code-length":163,"reference":"\/\/ Get looks up the caching response for a given request.\n\/\/ Get is also responsible for lazy eviction when accessing compacted entries.","result":"Get the range from the cache.","score":[0.0135,0.0469]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *cache) Invalidate(key, endkey []byte) {\r\n\tc.mu.Lock()\r\n\tdefer c.mu.Unlock()\r\n\tvar (\r\n\t\tivs []*adt.IntervalValue\r\n\t\tivl adt.Interval\r\n\t)\r\n\tif len(endkey) == 0 {\r\n\t\tivl = adt.NewStringAffinePoint(string(key))\r\n\t} else {\r\n\t\tivl = adt.NewStringAffineInterval(string(key), string(endkey))\r\n\t}\r\n\tivs = c.cachedRanges.Stab(ivl)\r\n\tfor _, iv := range ivs {\r\n\t\tkeys := iv.Val.(map[string]struct{})\r\n\t\tfor key := range keys {\r\n\t\t\tc.lru.Remove(key)\r\n\t\t}\r\n\t}\r\n\t\r\n\tc.cachedRanges.Delete(ivl)\r\n}","code-length":242,"reference":"\/\/ Invalidate invalidates the cache entries that intersecting with the given range from key to endkey.","result":"Invalidate the cache.","score":[0.0064,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *cache) Compact(revision int64) {\r\n\tc.mu.Lock()\r\n\tdefer c.mu.Unlock()\r\n\tif revision > c.compactedRev {\r\n\t\tc.compactedRev = revision\r\n\t}\r\n}","code-length":71,"reference":"\/\/ Compact invalidate all caching response before the given rev.\n\/\/ Replace with the invalidation is lazy. The actual removal happens when the entries is accessed.","result":"Compact the cache.","score":[0.0002,0.0422]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewUniqueURLsWithExceptions(s string, exceptions ...string) *UniqueURLs {\r\n\tus := &UniqueURLs{Values: make(map[string]struct{}), Allowed: make(map[string]struct{})}\r\n\tfor _, v := range exceptions {\r\n\t\tus.Allowed[v] = struct{}{}\r\n\t}\r\n\tif s == \"\" {\r\n\t\treturn us\r\n\t}\r\n\tif err := us.Set(s); err != nil {\r\n\t\tplog.Panicf(\"new UniqueURLs should never fail: %v\", err)\r\n\t}\r\n\treturn us\r\n}","code-length":155,"reference":"\/\/ NewUniqueURLsWithExceptions implements \"url.URL\" slice as flag.Value interface.\n\/\/ Given value is to be separated by comma.","result":"Create a new unique URL .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UniqueURLsFromFlag(fs *flag.FlagSet, urlsFlagName string) []url.URL {\r\n\treturn (*fs.Lookup(urlsFlagName).Value.(*UniqueURLs)).uss\r\n}","code-length":57,"reference":"\/\/ UniqueURLsFromFlag returns a slice from urls got from the flag.","result":"Generate the generated code.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UniqueURLsMapFromFlag(fs *flag.FlagSet, urlsFlagName string) map[string]struct{} {\r\n\treturn (*fs.Lookup(urlsFlagName).Value.(*UniqueURLs)).Values\r\n}","code-length":60,"reference":"\/\/ UniqueURLsMapFromFlag returns a map from url strings got from the flag.","result":"Generate the generated code.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Barrier) Hold() error {\r\n\t_, err := newKey(b.client, b.key, v3.NoLease)\r\n\treturn err\r\n}","code-length":52,"reference":"\/\/ Hold creates the barrier key causing processes to block on Wait.","result":"Hold the barrier.","score":[0.0242,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Barrier) Release() error {\r\n\t_, err := b.client.Delete(b.ctx, b.key)\r\n\treturn err\r\n}","code-length":49,"reference":"\/\/ Release deletes the barrier key to unblock all waiting processes.","result":"Release the barrier.","score":[0.0337,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Barrier) Wait() error {\r\n\tresp, err := b.client.Get(b.ctx, b.key, v3.WithFirstKey()...)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif len(resp.Kvs) == 0 {\r\n\t\t\r\n\t\treturn nil\r\n\t}\r\n\t_, err = WaitEvents(\r\n\t\tb.client,\r\n\t\tb.key,\r\n\t\tresp.Header.Revision,\r\n\t\t[]mvccpb.Event_EventType{mvccpb.PUT, mvccpb.DELETE})\r\n\treturn err\r\n}","code-length":163,"reference":"\/\/ Wait blocks on the barrier key until it is deleted. If there is no key, Wait\n\/\/ assumes Release has already been called and returns immediately.","result":"Wait for the barrier.","score":[0.0012,0.0405]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLockRacerCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"lock-racer [name of lock (defaults to 'racers')]\",\r\n\t\tShort: \"Performs lock race operation\",\r\n\t\tRun:   runRacerFunc,\r\n\t}\r\n\tcmd.Flags().IntVar(&totalClientConnections, \"total-client-connections\", 10, \"total number of client connections\")\r\n\treturn cmd\r\n}","code-length":127,"reference":"\/\/ NewLockRacerCommand returns the cobra command for \"lock-racer runner\".","result":"Create a new command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) ElectionTimeout() time.Duration {\r\n\treturn time.Duration(m.Etcd.ElectionTimeoutMs) * time.Millisecond\r\n}","code-length":48,"reference":"\/\/ ElectionTimeout returns an election timeout duration.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) DialEtcdGRPCServer(opts ...grpc.DialOption) (*grpc.ClientConn, error) {\r\n\tdialOpts := []grpc.DialOption{\r\n\t\tgrpc.WithTimeout(5 * time.Second),\r\n\t\tgrpc.WithBlock(),\r\n\t}\r\n\tsecure := false\r\n\tfor _, cu := range m.Etcd.AdvertiseClientURLs {\r\n\t\tu, err := url.Parse(cu)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tif u.Scheme == \"https\" {\r\n\t\t\tsecure = true\r\n\t\t}\r\n\t}\r\n\tif secure {\r\n\t\t\r\n\t\ttlsInfo := transport.TLSInfo{\r\n\t\t\tCertFile:      m.ClientCertPath,\r\n\t\t\tKeyFile:       m.ClientKeyPath,\r\n\t\t\tTrustedCAFile: m.ClientTrustedCAPath,\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tInsecureSkipVerify: true,\r\n\t\t}\r\n\t\ttlsConfig, err := tlsInfo.ClientConfig()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tcreds := credentials.NewTLS(tlsConfig)\r\n\t\tdialOpts = append(dialOpts, grpc.WithTransportCredentials(creds))\r\n\t} else {\r\n\t\tdialOpts = append(dialOpts, grpc.WithInsecure())\r\n\t}\r\n\tdialOpts = append(dialOpts, opts...)\r\n\treturn grpc.Dial(m.EtcdClientEndpoint, dialOpts...)\r\n}","code-length":381,"reference":"\/\/ DialEtcdGRPCServer creates a raw gRPC connection to an etcd member.","result":"Connect to etcd server.","score":[0.066,0.2481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) CreateEtcdClientConfig(opts ...grpc.DialOption) (cfg *clientv3.Config, err error) {\r\n\tsecure := false\r\n\tfor _, cu := range m.Etcd.AdvertiseClientURLs {\r\n\t\tvar u *url.URL\r\n\t\tu, err = url.Parse(cu)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tif u.Scheme == \"https\" {\r\n\t\t\tsecure = true\r\n\t\t}\r\n\t}\r\n\tcfg = &clientv3.Config{\r\n\t\tEndpoints:   []string{m.EtcdClientEndpoint},\r\n\t\tDialTimeout: 10 * time.Second,\r\n\t\tDialOptions: opts,\r\n\t}\r\n\tif secure {\r\n\t\t\r\n\t\ttlsInfo := transport.TLSInfo{\r\n\t\t\tCertFile:      m.ClientCertPath,\r\n\t\t\tKeyFile:       m.ClientKeyPath,\r\n\t\t\tTrustedCAFile: m.ClientTrustedCAPath,\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tInsecureSkipVerify: true,\r\n\t\t}\r\n\t\tvar tlsConfig *tls.Config\r\n\t\ttlsConfig, err = tlsInfo.ClientConfig()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tcfg.TLS = tlsConfig\r\n\t}\r\n\treturn cfg, err\r\n}","code-length":345,"reference":"\/\/ CreateEtcdClientConfig creates a client configuration from member.","result":"Create a new member .","score":[0.1319,0.2435]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) CreateEtcdClient(opts ...grpc.DialOption) (*clientv3.Client, error) {\r\n\tcfg, err := m.CreateEtcdClientConfig(opts...)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn clientv3.New(*cfg)\r\n}","code-length":87,"reference":"\/\/ CreateEtcdClient creates a client from member.","result":"Create the client.","score":[0,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) CheckCompact(rev int64) error {\r\n\tcli, err := m.CreateEtcdClient()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"%v (%q)\", err, m.EtcdClientEndpoint)\r\n\t}\r\n\tdefer cli.Close()\r\n\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\r\n\twch := cli.Watch(ctx, \"\\x00\", clientv3.WithFromKey(), clientv3.WithRev(rev-1))\r\n\twr, ok := <-wch\r\n\tcancel()\r\n\tif !ok {\r\n\t\treturn fmt.Errorf(\"watch channel terminated (endpoint %q)\", m.EtcdClientEndpoint)\r\n\t}\r\n\tif wr.CompactRevision != rev {\r\n\t\treturn fmt.Errorf(\"got compact revision %v, wanted %v (endpoint %q)\", wr.CompactRevision, rev, m.EtcdClientEndpoint)\r\n\t}\r\n\treturn nil\r\n}","code-length":247,"reference":"\/\/ CheckCompact ensures that historical data before given revision has been compacted.","result":"Check the compact revision.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) Defrag() error {\r\n\tcli, err := m.CreateEtcdClient()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"%v (%q)\", err, m.EtcdClientEndpoint)\r\n\t}\r\n\tdefer cli.Close()\r\n\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)\r\n\t_, err = cli.Defragment(ctx, m.EtcdClientEndpoint)\r\n\tcancel()\r\n\treturn err\r\n}","code-length":130,"reference":"\/\/ Defrag runs defragmentation on this member.","result":"Defragment a member.","score":[0.1076,0.1515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) RevHash() (int64, int64, error) {\r\n\tconn, err := m.DialEtcdGRPCServer()\r\n\tif err != nil {\r\n\t\treturn 0, 0, err\r\n\t}\r\n\tdefer conn.Close()\r\n\tmt := pb.NewMaintenanceClient(conn)\r\n\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\r\n\tresp, err := mt.Hash(ctx, &pb.HashRequest{}, grpc.FailFast(false))\r\n\tcancel()\r\n\tif err != nil {\r\n\t\treturn 0, 0, err\r\n\t}\r\n\treturn resp.Header.Revision, int64(resp.Hash), nil\r\n}","code-length":182,"reference":"\/\/ RevHash fetches current revision and hash on this member.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) Rev(ctx context.Context) (int64, error) {\r\n\tcli, err := m.CreateEtcdClient()\r\n\tif err != nil {\r\n\t\treturn 0, fmt.Errorf(\"%v (%q)\", err, m.EtcdClientEndpoint)\r\n\t}\r\n\tdefer cli.Close()\r\n\tresp, err := cli.Status(ctx, m.EtcdClientEndpoint)\r\n\tif err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\treturn resp.Header.Revision, nil\r\n}","code-length":139,"reference":"\/\/ Rev fetches current revision on this member.","result":"Get the member.","score":[0.0771,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) Compact(rev int64, timeout time.Duration) error {\r\n\tcli, err := m.CreateEtcdClient()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"%v (%q)\", err, m.EtcdClientEndpoint)\r\n\t}\r\n\tdefer cli.Close()\r\n\tctx, cancel := context.WithTimeout(context.Background(), timeout)\r\n\t_, err = cli.Compact(ctx, rev, clientv3.WithCompactPhysical())\r\n\tcancel()\r\n\treturn err\r\n}","code-length":137,"reference":"\/\/ Compact compacts member storage with given revision.\n\/\/ It blocks until it's physically done.","result":"Compact the cluster member.","score":[0.0204,0.036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) IsLeader() (bool, error) {\r\n\tcli, err := m.CreateEtcdClient()\r\n\tif err != nil {\r\n\t\treturn false, fmt.Errorf(\"%v (%q)\", err, m.EtcdClientEndpoint)\r\n\t}\r\n\tdefer cli.Close()\r\n\tresp, err := cli.Status(context.Background(), m.EtcdClientEndpoint)\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\treturn resp.Header.MemberId == resp.Leader, nil\r\n}","code-length":141,"reference":"\/\/ IsLeader returns true if this member is the current cluster leader.","result":"Check if the member is the leader.","score":[0.185,0.3878]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) WriteHealthKey() error {\r\n\tcli, err := m.CreateEtcdClient()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"%v (%q)\", err, m.EtcdClientEndpoint)\r\n\t}\r\n\tdefer cli.Close()\r\n\t\r\n\tctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\r\n\t_, err = cli.Put(ctx, \"health\", \"good\")\r\n\tcancel()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"%v (%q)\", err, m.EtcdClientEndpoint)\r\n\t}\r\n\treturn nil\r\n}","code-length":167,"reference":"\/\/ WriteHealthKey writes a health key to this member.","result":"Write the health key to the etcd cluster.","score":[0.2524,0.4213]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) SaveSnapshot(lg *zap.Logger) (err error) {\r\n\t\r\n\tif err = os.RemoveAll(m.SnapshotPath); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tvar ccfg *clientv3.Config\r\n\tccfg, err = m.CreateEtcdClientConfig()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"%v (%q)\", err, m.EtcdClientEndpoint)\r\n\t}\r\n\tlg.Info(\r\n\t\t\"snapshot save START\",\r\n\t\tzap.String(\"member-name\", m.Etcd.Name),\r\n\t\tzap.Strings(\"member-client-urls\", m.Etcd.AdvertiseClientURLs),\r\n\t\tzap.String(\"snapshot-path\", m.SnapshotPath),\r\n\t)\r\n\tnow := time.Now()\r\n\tmgr := snapshot.NewV3(lg)\r\n\tif err = mgr.Save(context.Background(), *ccfg, m.SnapshotPath); err != nil {\r\n\t\treturn err\r\n\t}\r\n\ttook := time.Since(now)\r\n\tvar fi os.FileInfo\r\n\tfi, err = os.Stat(m.SnapshotPath)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tvar st snapshot.Status\r\n\tst, err = mgr.Status(m.SnapshotPath)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tm.SnapshotInfo = &SnapshotInfo{\r\n\t\tMemberName:        m.Etcd.Name,\r\n\t\tMemberClientURLs:  m.Etcd.AdvertiseClientURLs,\r\n\t\tSnapshotPath:      m.SnapshotPath,\r\n\t\tSnapshotFileSize:  humanize.Bytes(uint64(fi.Size())),\r\n\t\tSnapshotTotalSize: humanize.Bytes(uint64(st.TotalSize)),\r\n\t\tSnapshotTotalKey:  int64(st.TotalKey),\r\n\t\tSnapshotHash:      int64(st.Hash),\r\n\t\tSnapshotRevision:  st.Revision,\r\n\t\tTook:              fmt.Sprintf(\"%v\", took),\r\n\t}\r\n\tlg.Info(\r\n\t\t\"snapshot save END\",\r\n\t\tzap.String(\"member-name\", m.SnapshotInfo.MemberName),\r\n\t\tzap.Strings(\"member-client-urls\", m.SnapshotInfo.MemberClientURLs),\r\n\t\tzap.String(\"snapshot-path\", m.SnapshotPath),\r\n\t\tzap.String(\"snapshot-file-size\", m.SnapshotInfo.SnapshotFileSize),\r\n\t\tzap.String(\"snapshot-total-size\", m.SnapshotInfo.SnapshotTotalSize),\r\n\t\tzap.Int64(\"snapshot-total-key\", m.SnapshotInfo.SnapshotTotalKey),\r\n\t\tzap.Int64(\"snapshot-hash\", m.SnapshotInfo.SnapshotHash),\r\n\t\tzap.Int64(\"snapshot-revision\", m.SnapshotInfo.SnapshotRevision),\r\n\t\tzap.String(\"took\", m.SnapshotInfo.Took),\r\n\t)\r\n\treturn nil\r\n}","code-length":749,"reference":"\/\/ SaveSnapshot downloads a snapshot file from this member, locally.\n\/\/ It's meant to requested remotely, so that local member can store\n\/\/ snapshot file on local disk.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Member) RestoreSnapshot(lg *zap.Logger) (err error) {\r\n\tif err = os.RemoveAll(m.EtcdOnSnapshotRestore.DataDir); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err = os.RemoveAll(m.EtcdOnSnapshotRestore.WALDir); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tlg.Info(\r\n\t\t\"snapshot restore START\",\r\n\t\tzap.String(\"member-name\", m.Etcd.Name),\r\n\t\tzap.Strings(\"member-client-urls\", m.Etcd.AdvertiseClientURLs),\r\n\t\tzap.String(\"snapshot-path\", m.SnapshotPath),\r\n\t)\r\n\tnow := time.Now()\r\n\tmgr := snapshot.NewV3(lg)\r\n\terr = mgr.Restore(snapshot.RestoreConfig{\r\n\t\tSnapshotPath:        m.SnapshotInfo.SnapshotPath,\r\n\t\tName:                m.EtcdOnSnapshotRestore.Name,\r\n\t\tOutputDataDir:       m.EtcdOnSnapshotRestore.DataDir,\r\n\t\tOutputWALDir:        m.EtcdOnSnapshotRestore.WALDir,\r\n\t\tPeerURLs:            m.EtcdOnSnapshotRestore.AdvertisePeerURLs,\r\n\t\tInitialCluster:      m.EtcdOnSnapshotRestore.InitialCluster,\r\n\t\tInitialClusterToken: m.EtcdOnSnapshotRestore.InitialClusterToken,\r\n\t\tSkipHashCheck:       false,\r\n\t\t\r\n\t})\r\n\ttook := time.Since(now)\r\n\tlg.Info(\r\n\t\t\"snapshot restore END\",\r\n\t\tzap.String(\"member-name\", m.SnapshotInfo.MemberName),\r\n\t\tzap.Strings(\"member-client-urls\", m.SnapshotInfo.MemberClientURLs),\r\n\t\tzap.String(\"snapshot-path\", m.SnapshotPath),\r\n\t\tzap.String(\"snapshot-file-size\", m.SnapshotInfo.SnapshotFileSize),\r\n\t\tzap.String(\"snapshot-total-size\", m.SnapshotInfo.SnapshotTotalSize),\r\n\t\tzap.Int64(\"snapshot-total-key\", m.SnapshotInfo.SnapshotTotalKey),\r\n\t\tzap.Int64(\"snapshot-hash\", m.SnapshotInfo.SnapshotHash),\r\n\t\tzap.Int64(\"snapshot-revision\", m.SnapshotInfo.SnapshotRevision),\r\n\t\tzap.String(\"took\", took.String()),\r\n\t\tzap.Error(err),\r\n\t)\r\n\treturn err\r\n}","code-length":612,"reference":"\/\/ RestoreSnapshot restores a cluster from a given snapshot file on disk.\n\/\/ It's meant to requested remotely, so that local member can load the\n\/\/ snapshot file from local disk.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewWatcher(w clientv3.Watcher, prefix string) clientv3.Watcher {\r\n\treturn &watcherPrefix{Watcher: w, pfx: prefix, stopc: make(chan struct{})}\r\n}","code-length":57,"reference":"\/\/ NewWatcher wraps a Watcher instance so that all Watch requests\n\/\/ are prefixed with a given string and all Watch responses have\n\/\/ the prefix removed.","result":"Create a new watcher.","score":[0.001,0.0202]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewRawNode(config *Config, peers []Peer) (*RawNode, error) {\r\n\tif config.ID == 0 {\r\n\t\tpanic(\"config.ID must not be zero\")\r\n\t}\r\n\tr := newRaft(config)\r\n\trn := &RawNode{\r\n\t\traft: r,\r\n\t}\r\n\tlastIndex, err := config.Storage.LastIndex()\r\n\tif err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif lastIndex == 0 {\r\n\t\tr.becomeFollower(1, None)\r\n\t\tents := make([]pb.Entry, len(peers))\r\n\t\tfor i, peer := range peers {\r\n\t\t\tcc := pb.ConfChange{Type: pb.ConfChangeAddNode, NodeID: peer.ID, Context: peer.Context}\r\n\t\t\tdata, err := cc.Marshal()\r\n\t\t\tif err != nil {\r\n\t\t\t\tpanic(\"unexpected marshal error\")\r\n\t\t\t}\r\n\t\t\tents[i] = pb.Entry{Type: pb.EntryConfChange, Term: 1, Index: uint64(i + 1), Data: data}\r\n\t\t}\r\n\t\tr.raftLog.append(ents...)\r\n\t\tr.raftLog.committed = uint64(len(ents))\r\n\t\tfor _, peer := range peers {\r\n\t\t\tr.addNode(peer.ID)\r\n\t\t}\r\n\t}\r\n\t\r\n\trn.prevSoftSt = r.softState()\r\n\tif lastIndex == 0 {\r\n\t\trn.prevHardSt = emptyState\r\n\t} else {\r\n\t\trn.prevHardSt = r.hardState()\r\n\t}\r\n\treturn rn, nil\r\n}","code-length":442,"reference":"\/\/ NewRawNode returns a new RawNode given configuration and a list of raft peers.","result":"Create a raw node.","score":[0.0262,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) Campaign() error {\r\n\treturn rn.raft.Step(pb.Message{\r\n\t\tType: pb.MsgHup,\r\n\t})\r\n}","code-length":53,"reference":"\/\/ Campaign causes this RawNode to transition to candidate state.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) Propose(data []byte) error {\r\n\treturn rn.raft.Step(pb.Message{\r\n\t\tType: pb.MsgProp,\r\n\t\tFrom: rn.raft.id,\r\n\t\tEntries: []pb.Entry{\r\n\t\t\t{Data: data},\r\n\t\t}})\r\n}","code-length":91,"reference":"\/\/ Propose proposes data be appended to the raft log.","result":"Create a new node.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) ProposeConfChange(cc pb.ConfChange) error {\r\n\tdata, err := cc.Marshal()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn rn.raft.Step(pb.Message{\r\n\t\tType: pb.MsgProp,\r\n\t\tEntries: []pb.Entry{\r\n\t\t\t{Type: pb.EntryConfChange, Data: data},\r\n\t\t},\r\n\t})\r\n}","code-length":123,"reference":"\/\/ ProposeConfChange proposes a config change.","result":"Propose a conf change.","score":[0.2304,0.4406]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) ApplyConfChange(cc pb.ConfChange) *pb.ConfState {\r\n\tif cc.NodeID == None {\r\n\t\treturn &pb.ConfState{Nodes: rn.raft.nodes(), Learners: rn.raft.learnerNodes()}\r\n\t}\r\n\tswitch cc.Type {\r\n\tcase pb.ConfChangeAddNode:\r\n\t\trn.raft.addNode(cc.NodeID)\r\n\tcase pb.ConfChangeAddLearnerNode:\r\n\t\trn.raft.addLearner(cc.NodeID)\r\n\tcase pb.ConfChangeRemoveNode:\r\n\t\trn.raft.removeNode(cc.NodeID)\r\n\tcase pb.ConfChangeUpdateNode:\r\n\tdefault:\r\n\t\tpanic(\"unexpected conf type\")\r\n\t}\r\n\treturn &pb.ConfState{Nodes: rn.raft.nodes(), Learners: rn.raft.learnerNodes()}\r\n}","code-length":230,"reference":"\/\/ ApplyConfChange applies a config change to the local node.","result":"Apply a configuration change.","score":[0.0713,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) Step(m pb.Message) error {\r\n\t\r\n\tif IsLocalMsg(m.Type) {\r\n\t\treturn ErrStepLocalMsg\r\n\t}\r\n\tif pr := rn.raft.getProgress(m.From); pr != nil || !IsResponseMsg(m.Type) {\r\n\t\treturn rn.raft.Step(m)\r\n\t}\r\n\treturn ErrStepPeerNotFound\r\n}","code-length":113,"reference":"\/\/ Step advances the state machine using the given message.","result":"Step a node.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) Ready() Ready {\r\n\trd := rn.newReady()\r\n\trn.raft.msgs = nil\r\n\trn.raft.reduceUncommittedSize(rd.CommittedEntries)\r\n\treturn rd\r\n}","code-length":66,"reference":"\/\/ Ready returns the current point-in-time state of this RawNode.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) WithProgress(visitor func(id uint64, typ ProgressType, pr Progress)) {\r\n\tfor id, pr := range rn.raft.prs {\r\n\t\tpr := *pr\r\n\t\tpr.ins = nil\r\n\t\tvisitor(id, ProgressTypePeer, pr)\r\n\t}\r\n\tfor id, pr := range rn.raft.learnerPrs {\r\n\t\tpr := *pr\r\n\t\tpr.ins = nil\r\n\t\tvisitor(id, ProgressTypeLearner, pr)\r\n\t}\r\n}","code-length":145,"reference":"\/\/ WithProgress is a helper to introspect the Progress for this node and its\n\/\/ peers.","result":"Set the node.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) ReportUnreachable(id uint64) {\r\n\t_ = rn.raft.Step(pb.Message{Type: pb.MsgUnreachable, From: id})\r\n}","code-length":55,"reference":"\/\/ ReportUnreachable reports the given node is not reachable for the last send.","result":"Report unreachable nodes.","score":[0,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) ReportSnapshot(id uint64, status SnapshotStatus) {\r\n\trej := status == SnapshotFailure\r\n\t_ = rn.raft.Step(pb.Message{Type: pb.MsgSnapStatus, From: id, Reject: rej})\r\n}","code-length":73,"reference":"\/\/ ReportSnapshot reports the status of the sent snapshot.","result":"Report snapshot.","score":[0.0151,0.1205]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) TransferLeader(transferee uint64) {\r\n\t_ = rn.raft.Step(pb.Message{Type: pb.MsgTransferLeader, From: transferee})\r\n}","code-length":56,"reference":"\/\/ TransferLeader tries to transfer leadership to the given transferee.","result":"Store the raw data in a file.","score":[0.1052,0.0515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rn *RawNode) ReadIndex(rctx []byte) {\r\n\t_ = rn.raft.Step(pb.Message{Type: pb.MsgReadIndex, Entries: []pb.Entry{{Data: rctx}}})\r\n}","code-length":63,"reference":"\/\/ ReadIndex requests a read state. The read state will be set in ready.\n\/\/ Read State has a read index. Once the application advances further than the read\n\/\/ index, any linearizable read requests issued before the read request can be\n\/\/ processed safely. The read state will have the same rctx attached.","result":"Read index.","score":[0.0,0.0205]}
{"code":"\/*is used to<extra_id_0>\r\nfunc printcURL(req *http.Request) error {\r\n\tif !cURLDebug {\r\n\t\treturn nil\r\n\t}\r\n\tvar (\r\n\t\tcommand string\r\n\t\tb       []byte\r\n\t\terr     error\r\n\t)\r\n\tif req.URL != nil {\r\n\t\tcommand = fmt.Sprintf(\"curl -X %s %s\", req.Method, req.URL.String())\r\n\t}\r\n\tif req.Body != nil {\r\n\t\tb, err = ioutil.ReadAll(req.Body)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tcommand += fmt.Sprintf(\" -d %q\", string(b))\r\n\t}\r\n\tfmt.Fprintf(os.Stderr, \"cURL Command: %s\\n\", command)\r\n\t\r\n\tbody := bytes.NewBuffer(b)\r\n\treq.Body = ioutil.NopCloser(body)\r\n\treturn nil\r\n}","code-length":247,"reference":"\/\/ printcURL prints the cURL equivalent request to stderr.\n\/\/ It returns an error if the body of the request cannot\n\/\/ be read.\n\/\/ The caller MUST cancel the request if there is an error.","result":"Print the cURL command.","score":[0.0002,0.0457]}
{"code":"\/*is used to<extra_id_0>\r\nfunc StartNode(c *Config, peers []Peer) Node {\r\n\tr := newRaft(c)\r\n\t\r\n\t\r\n\tr.becomeFollower(1, None)\r\n\tfor _, peer := range peers {\r\n\t\tcc := pb.ConfChange{Type: pb.ConfChangeAddNode, NodeID: peer.ID, Context: peer.Context}\r\n\t\td, err := cc.Marshal()\r\n\t\tif err != nil {\r\n\t\t\tpanic(\"unexpected marshal error\")\r\n\t\t}\r\n\t\te := pb.Entry{Type: pb.EntryConfChange, Term: 1, Index: r.raftLog.lastIndex() + 1, Data: d}\r\n\t\tr.raftLog.append(e)\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tr.raftLog.committed = r.raftLog.lastIndex()\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tfor _, peer := range peers {\r\n\t\tr.addNode(peer.ID)\r\n\t}\r\n\tn := newNode()\r\n\tn.logger = c.Logger\r\n\tgo n.run(r)\r\n\treturn &n\r\n}","code-length":310,"reference":"\/\/ StartNode returns a new Node given configuration and a list of raft peers.\n\/\/ It appends a ConfChangeAddNode entry for each given peer to the initial log.","result":"Start a new node.","score":[0.0011,0.0391]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RestartNode(c *Config) Node {\r\n\tr := newRaft(c)\r\n\tn := newNode()\r\n\tn.logger = c.Logger\r\n\tgo n.run(r)\r\n\treturn &n\r\n}","code-length":66,"reference":"\/\/ RestartNode is similar to StartNode but does not take a list of peers.\n\/\/ The current membership of the cluster will be restored from the Storage.\n\/\/ If the caller has an existing state machine, pass in the last log index that\n\/\/ has been applied to it; otherwise use zero.","result":"Restart raft.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *node) Tick() {\r\n\tselect {\r\n\tcase n.tickc <- struct{}{}:\r\n\tcase <-n.done:\r\n\tdefault:\r\n\t\tn.logger.Warningf(\"A tick missed to fire. Node blocks too long!\")\r\n\t}\r\n}","code-length":80,"reference":"\/\/ Tick increments the internal logical clock for this Node. Election timeouts\n\/\/ and heartbeat timeouts are in units of ticks.","result":"Fire a tick on the node.","score":[0.0158,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MustSync(st, prevst pb.HardState, entsnum int) bool {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\treturn entsnum != 0 || st.Vote != prevst.Vote || st.Term != prevst.Term\r\n}","code-length":74,"reference":"\/\/ MustSync returns true if the hard state and count of Raft entries indicate\n\/\/ that a synchronous write to persistent storage is required.","result":"Sync the state.","score":[0.0004,0.0228]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewGRPC17Health(\r\n\teps []string,\r\n\ttimeout time.Duration,\r\n\tdialFunc DialFunc,\r\n) *GRPC17Health {\r\n\tnotifyCh := make(chan []grpc.Address)\r\n\taddrs := eps2addrs(eps)\r\n\thb := &GRPC17Health{\r\n\t\taddrs:              addrs,\r\n\t\teps:                eps,\r\n\t\tnotifyCh:           notifyCh,\r\n\t\treadyc:             make(chan struct{}),\r\n\t\thealthCheck:        func(ep string) (bool, error) { return grpcHealthCheck(ep, dialFunc) },\r\n\t\tunhealthyHostPorts: make(map[string]time.Time),\r\n\t\tupc:                make(chan struct{}),\r\n\t\tstopc:              make(chan struct{}),\r\n\t\tdownc:              make(chan struct{}),\r\n\t\tdonec:              make(chan struct{}),\r\n\t\tupdateAddrsC:       make(chan NotifyMsg),\r\n\t\thostPort2ep:        getHostPort2ep(eps),\r\n\t}\r\n\tif timeout < minHealthRetryDuration {\r\n\t\ttimeout = minHealthRetryDuration\r\n\t}\r\n\thb.healthCheckTimeout = timeout\r\n\tclose(hb.downc)\r\n\tgo hb.updateNotifyLoop()\r\n\thb.wg.Add(1)\r\n\tgo func() {\r\n\t\tdefer hb.wg.Done()\r\n\t\thb.updateUnhealthy()\r\n\t}()\r\n\treturn hb\r\n}","code-length":376,"reference":"\/\/ NewGRPC17Health returns a new health balancer with gRPC v1.7.","result":"Create a new health check .","score":[0.2042,0.3067]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *GRPC17Health) NeedUpdate() bool {\r\n\t\r\n\t\r\n\t\r\n\tb.mu.RLock()\r\n\tupdate := !hasAddr(b.addrs, b.pinAddr)\r\n\tb.mu.RUnlock()\r\n\treturn update\r\n}","code-length":77,"reference":"\/\/ NeedUpdate returns true if all connections are down or\n\/\/ addresses do not include current pinned address.","result":"Check if the health is up.","score":[0.0261,0.0298]}
{"code":"\/*is used to<extra_id_0>\r\nfunc dflSignal(sig syscall.Signal) {\r\n\t\r\n\tvar sigactBuf [32]uint64\r\n\tptr := unsafe.Pointer(&sigactBuf)\r\n\tsyscall.Syscall6(uintptr(syscall.SYS_RT_SIGACTION), uintptr(sig), uintptr(ptr), 0, 8, 0, 0)\r\n}","code-length":91,"reference":"\/\/ dflSignal sets the given signal to SIG_DFL","result":"Signal the DFL driver.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(namespaces ...string) Store {\r\n\ts := newStore(namespaces...)\r\n\ts.clock = clockwork.NewRealClock()\r\n\treturn s\r\n}","code-length":50,"reference":"\/\/ New creates a store where the given namespaces will be created as initial directories.","result":"Create a new store.","score":[0.0204,0.1079]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) Index() uint64 {\r\n\ts.worldLock.RLock()\r\n\tdefer s.worldLock.RUnlock()\r\n\treturn s.CurrentIndex\r\n}","code-length":54,"reference":"\/\/ Index retrieves the current index of the store.","result":"Generate the index code.","score":[0.1088,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) Get(nodePath string, recursive, sorted bool) (*Event, error) {\r\n\tvar err *v2error.Error\r\n\ts.worldLock.RLock()\r\n\tdefer s.worldLock.RUnlock()\r\n\tdefer func() {\r\n\t\tif err == nil {\r\n\t\t\ts.Stats.Inc(GetSuccess)\r\n\t\t\tif recursive {\r\n\t\t\t\treportReadSuccess(GetRecursive)\r\n\t\t\t} else {\r\n\t\t\t\treportReadSuccess(Get)\r\n\t\t\t}\r\n\t\t\treturn\r\n\t\t}\r\n\t\ts.Stats.Inc(GetFail)\r\n\t\tif recursive {\r\n\t\t\treportReadFailure(GetRecursive)\r\n\t\t} else {\r\n\t\t\treportReadFailure(Get)\r\n\t\t}\r\n\t}()\r\n\tn, err := s.internalGet(nodePath)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\te := newEvent(Get, nodePath, n.ModifiedIndex, n.CreatedIndex)\r\n\te.EtcdIndex = s.CurrentIndex\r\n\te.Node.loadInternalNode(n, recursive, sorted, s.clock)\r\n\treturn e, nil\r\n}","code-length":304,"reference":"\/\/ Get returns a get event.\n\/\/ If recursive is true, it will return all the content under the node path.\n\/\/ If sorted is true, it will sort the content by keys.","result":"Get the node at the given path.","score":[0.007,0.1403]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) Create(nodePath string, dir bool, value string, unique bool, expireOpts TTLOptionSet) (*Event, error) {\r\n\tvar err *v2error.Error\r\n\ts.worldLock.Lock()\r\n\tdefer s.worldLock.Unlock()\r\n\tdefer func() {\r\n\t\tif err == nil {\r\n\t\t\ts.Stats.Inc(CreateSuccess)\r\n\t\t\treportWriteSuccess(Create)\r\n\t\t\treturn\r\n\t\t}\r\n\t\ts.Stats.Inc(CreateFail)\r\n\t\treportWriteFailure(Create)\r\n\t}()\r\n\te, err := s.internalCreate(nodePath, dir, value, unique, false, expireOpts.ExpireTime, Create)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\te.EtcdIndex = s.CurrentIndex\r\n\ts.WatcherHub.notify(e)\r\n\treturn e, nil\r\n}","code-length":238,"reference":"\/\/ Create creates the node at nodePath. Create will help to create intermediate directories with no ttl.\n\/\/ If the node has already existed, create will fail.\n\/\/ If any node on the path is a file, create will fail.","result":"Create a node in etcd.","score":[0.0003,0.0411]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) Set(nodePath string, dir bool, value string, expireOpts TTLOptionSet) (*Event, error) {\r\n\tvar err *v2error.Error\r\n\ts.worldLock.Lock()\r\n\tdefer s.worldLock.Unlock()\r\n\tdefer func() {\r\n\t\tif err == nil {\r\n\t\t\ts.Stats.Inc(SetSuccess)\r\n\t\t\treportWriteSuccess(Set)\r\n\t\t\treturn\r\n\t\t}\r\n\t\ts.Stats.Inc(SetFail)\r\n\t\treportWriteFailure(Set)\r\n\t}()\r\n\t\r\n\tn, getErr := s.internalGet(nodePath)\r\n\tif getErr != nil && getErr.ErrorCode != v2error.EcodeKeyNotFound {\r\n\t\terr = getErr\r\n\t\treturn nil, err\r\n\t}\r\n\tif expireOpts.Refresh {\r\n\t\tif getErr != nil {\r\n\t\t\terr = getErr\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tvalue = n.Value\r\n\t}\r\n\t\r\n\te, err := s.internalCreate(nodePath, dir, value, false, true, expireOpts.ExpireTime, Set)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\te.EtcdIndex = s.CurrentIndex\r\n\t\r\n\tif getErr == nil {\r\n\t\tprev := newEvent(Get, nodePath, n.ModifiedIndex, n.CreatedIndex)\r\n\t\tprev.Node.loadInternalNode(n, false, false, s.clock)\r\n\t\te.PrevNode = prev.Node\r\n\t}\r\n\tif !expireOpts.Refresh {\r\n\t\ts.WatcherHub.notify(e)\r\n\t} else {\r\n\t\te.SetRefresh()\r\n\t\ts.WatcherHub.add(e)\r\n\t}\r\n\treturn e, nil\r\n}","code-length":469,"reference":"\/\/ Set creates or replace the node at nodePath.","result":"Set the value of a node in etcd.","score":[0.1613,0.1685]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getCompareFailCause(n *node, which int, prevValue string, prevIndex uint64) string {\r\n\tswitch which {\r\n\tcase CompareIndexNotMatch:\r\n\t\treturn fmt.Sprintf(\"[%v != %v]\", prevIndex, n.ModifiedIndex)\r\n\tcase CompareValueNotMatch:\r\n\t\treturn fmt.Sprintf(\"[%v != %v]\", prevValue, n.Value)\r\n\tdefault:\r\n\t\treturn fmt.Sprintf(\"[%v != %v] [%v != %v]\", prevValue, n.Value, prevIndex, n.ModifiedIndex)\r\n\t}\r\n}","code-length":156,"reference":"\/\/ returns user-readable cause of failed comparison","result":"Get the compare fail cause.","score":[0,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) Delete(nodePath string, dir, recursive bool) (*Event, error) {\r\n\tvar err *v2error.Error\r\n\ts.worldLock.Lock()\r\n\tdefer s.worldLock.Unlock()\r\n\tdefer func() {\r\n\t\tif err == nil {\r\n\t\t\ts.Stats.Inc(DeleteSuccess)\r\n\t\t\treportWriteSuccess(Delete)\r\n\t\t\treturn\r\n\t\t}\r\n\t\ts.Stats.Inc(DeleteFail)\r\n\t\treportWriteFailure(Delete)\r\n\t}()\r\n\tnodePath = path.Clean(path.Join(\"\/\", nodePath))\r\n\t\r\n\tif s.readonlySet.Contains(nodePath) {\r\n\t\treturn nil, v2error.NewError(v2error.EcodeRootROnly, \"\/\", s.CurrentIndex)\r\n\t}\r\n\t\r\n\tif recursive {\r\n\t\tdir = true\r\n\t}\r\n\tn, err := s.internalGet(nodePath)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tnextIndex := s.CurrentIndex + 1\r\n\te := newEvent(Delete, nodePath, nextIndex, n.CreatedIndex)\r\n\te.EtcdIndex = nextIndex\r\n\te.PrevNode = n.Repr(false, false, s.clock)\r\n\teNode := e.Node\r\n\tif n.IsDir() {\r\n\t\teNode.Dir = true\r\n\t}\r\n\tcallback := func(path string) {\r\n\t\t\r\n\t\ts.WatcherHub.notifyWatchers(e, path, true)\r\n\t}\r\n\terr = n.Remove(dir, recursive, callback)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\ts.CurrentIndex++\r\n\ts.WatcherHub.notify(e)\r\n\treturn e, nil\r\n}","code-length":467,"reference":"\/\/ Delete deletes the node at the given path.\n\/\/ If the node is a directory, recursive must be true to delete it.","result":"Delete a node.","score":[0.0006,0.0476]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) walk(nodePath string, walkFunc func(prev *node, component string) (*node, *v2error.Error)) (*node, *v2error.Error) {\r\n\tcomponents := strings.Split(nodePath, \"\/\")\r\n\tcurr := s.Root\r\n\tvar err *v2error.Error\r\n\tfor i := 1; i < len(components); i++ {\r\n\t\tif len(components[i]) == 0 {\r\n\t\t\treturn curr, nil\r\n\t\t}\r\n\t\tcurr, err = walkFunc(curr, components[i])\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\treturn curr, nil\r\n}","code-length":185,"reference":"\/\/ walk walks all the nodePath and apply the walkFunc on each directory","result":"Generate the code.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) internalGet(nodePath string) (*node, *v2error.Error) {\r\n\tnodePath = path.Clean(path.Join(\"\/\", nodePath))\r\n\twalkFunc := func(parent *node, name string) (*node, *v2error.Error) {\r\n\t\tif !parent.IsDir() {\r\n\t\t\terr := v2error.NewError(v2error.EcodeNotDir, parent.Path, s.CurrentIndex)\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tchild, ok := parent.Children[name]\r\n\t\tif ok {\r\n\t\t\treturn child, nil\r\n\t\t}\r\n\t\treturn nil, v2error.NewError(v2error.EcodeKeyNotFound, path.Join(parent.Path, name), s.CurrentIndex)\r\n\t}\r\n\tf, err := s.walk(nodePath, walkFunc)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn f, nil\r\n}","code-length":258,"reference":"\/\/ InternalGet gets the node of the given nodePath.","result":"Get the value of a node.","score":[0.1392,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) DeleteExpiredKeys(cutoff time.Time) {\r\n\ts.worldLock.Lock()\r\n\tdefer s.worldLock.Unlock()\r\n\tfor {\r\n\t\tnode := s.ttlKeyHeap.top()\r\n\t\tif node == nil || node.ExpireTime.After(cutoff) {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\ts.CurrentIndex++\r\n\t\te := newEvent(Expire, node.Path, s.CurrentIndex, node.CreatedIndex)\r\n\t\te.EtcdIndex = s.CurrentIndex\r\n\t\te.PrevNode = node.Repr(false, false, s.clock)\r\n\t\tif node.IsDir() {\r\n\t\t\te.Node.Dir = true\r\n\t\t}\r\n\t\tcallback := func(path string) {\r\n\t\t\t\r\n\t\t\ts.WatcherHub.notifyWatchers(e, path, true)\r\n\t\t}\r\n\t\ts.ttlKeyHeap.pop()\r\n\t\tnode.Remove(true, true, callback)\r\n\t\treportExpiredKey()\r\n\t\ts.Stats.Inc(ExpireCount)\r\n\t\ts.WatcherHub.notify(e)\r\n\t}\r\n}","code-length":296,"reference":"\/\/ DeleteExpiredKeys will delete all expired keys","result":"Delete expired keys.","score":[0.1076,0.1515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) checkDir(parent *node, dirName string) (*node, *v2error.Error) {\r\n\tnode, ok := parent.Children[dirName]\r\n\tif ok {\r\n\t\tif node.IsDir() {\r\n\t\t\treturn node, nil\r\n\t\t}\r\n\t\treturn nil, v2error.NewError(v2error.EcodeNotDir, node.Path, s.CurrentIndex)\r\n\t}\r\n\tn := newDir(s, path.Join(parent.Path, dirName), s.CurrentIndex+1, parent, Permanent)\r\n\tparent.Children[dirName] = n\r\n\treturn n, nil\r\n}","code-length":171,"reference":"\/\/ checkDir will check whether the component is a directory under parent node.\n\/\/ If it is a directory, this function will return the pointer to that node.\n\/\/ If it does not exist, this function will create a new directory and return the pointer to that node.\n\/\/ If it is a file, this function will return error.","result":"Check if a directory exists in a file.","score":[0.0004,0.0464]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) Save() ([]byte, error) {\r\n\tb, err := json.Marshal(s.Clone())\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn b, nil\r\n}","code-length":69,"reference":"\/\/ Save saves the static state of the store system.\n\/\/ It will not be able to save the state of watchers.\n\/\/ It will not save the parent field of the node. Or there will\n\/\/ be cyclic dependencies issue for the json package.","result":"Save the store.","score":[0.0,0.0245]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *store) Recovery(state []byte) error {\r\n\ts.worldLock.Lock()\r\n\tdefer s.worldLock.Unlock()\r\n\terr := json.Unmarshal(state, s)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ts.ttlKeyHeap = newTtlKeyHeap()\r\n\ts.Root.recoverAndclean()\r\n\treturn nil\r\n}","code-length":109,"reference":"\/\/ Recovery recovers the store system from a static state\n\/\/ It needs to recover the parent field of the nodes.\n\/\/ It needs to delete the expired nodes since the saved time and also\n\/\/ needs to create monitoring go routines.","result":"Recover the state.","score":[0.0,0.0262]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Generator) Next() uint64 {\r\n\tsuffix := atomic.AddUint64(&g.suffix, 1)\r\n\tid := g.prefix | lowbit(suffix, suffixLen)\r\n\treturn id\r\n}","code-length":63,"reference":"\/\/ Next generates a id that is unique.","result":"Generate the next value.","score":[0,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMakeMirrorCommand() *cobra.Command {\r\n\tc := &cobra.Command{\r\n\t\tUse:   \"make-mirror [options] <destination>\",\r\n\t\tShort: \"Makes a mirror at the destination etcd cluster\",\r\n\t\tRun:   makeMirrorCommandFunc,\r\n\t}\r\n\tc.Flags().StringVar(&mmprefix, \"prefix\", \"\", \"Key-value prefix to mirror\")\r\n\tc.Flags().StringVar(&mmdestprefix, \"dest-prefix\", \"\", \"destination prefix to mirror a prefix to a different prefix in the destination cluster\")\r\n\tc.Flags().BoolVar(&mmnodestprefix, \"no-dest-prefix\", false, \"mirror key-values to the root of the destination cluster\")\r\n\tc.Flags().StringVar(&mmcert, \"dest-cert\", \"\", \"Identify secure client using this TLS certificate file for the destination cluster\")\r\n\tc.Flags().StringVar(&mmkey, \"dest-key\", \"\", \"Identify secure client using this TLS key file\")\r\n\tc.Flags().StringVar(&mmcacert, \"dest-cacert\", \"\", \"Verify certificates of TLS enabled secure servers using this CA bundle\")\r\n\t\r\n\tc.Flags().BoolVar(&mminsecureTr, \"dest-insecure-transport\", true, \"Disable transport security for client connections\")\r\n\treturn c\r\n}","code-length":334,"reference":"\/\/ NewMakeMirrorCommand returns the cobra command for \"makeMirror\".","result":"Create a new etcd cluster.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewZapCoreLoggerBuilder(lg *zap.Logger, cr zapcore.Core, syncer zapcore.WriteSyncer) func(*Config) error {\r\n\treturn func(cfg *Config) error {\r\n\t\tcfg.loggerMu.Lock()\r\n\t\tdefer cfg.loggerMu.Unlock()\r\n\t\tcfg.logger = lg\r\n\t\tcfg.loggerConfig = nil\r\n\t\tcfg.loggerCore = cr\r\n\t\tcfg.loggerWriteSyncer = syncer\r\n\t\tgrpcLogOnce.Do(func() {\r\n\t\t\tgrpclog.SetLoggerV2(logutil.NewGRPCLoggerV2FromZapCore(cr, syncer))\r\n\t\t})\r\n\t\treturn nil\r\n\t}\r\n}","code-length":183,"reference":"\/\/ NewZapCoreLoggerBuilder generates a zap core logger builder.","result":"Build the zap core logger builder.","score":[0.433,0.5088]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSyncer(c *clientv3.Client, prefix string, rev int64) Syncer {\r\n\treturn &syncer{c: c, prefix: prefix, rev: rev}\r\n}","code-length":55,"reference":"\/\/ NewSyncer creates a Syncer.","result":"Create a new syncer.","score":[0.2488,0.5215]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DropPort(port int) error {\r\n\tcmdStr := fmt.Sprintf(\"sudo iptables -A OUTPUT -p tcp --destination-port %d -j DROP\", port)\r\n\tif _, err := exec.Command(\"\/bin\/sh\", \"-c\", cmdStr).Output(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tcmdStr = fmt.Sprintf(\"sudo iptables -A INPUT -p tcp --destination-port %d -j DROP\", port)\r\n\t_, err := exec.Command(\"\/bin\/sh\", \"-c\", cmdStr).Output()\r\n\treturn err\r\n}","code-length":151,"reference":"\/\/ DropPort drops all tcp packets that are received from the given port and sent to the given port.","result":"Drop a port.","score":[0.002,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetLatency(ms, rv int) error {\r\n\tifces, err := GetDefaultInterfaces()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif rv > ms {\r\n\t\trv = 1\r\n\t}\r\n\tfor ifce := range ifces {\r\n\t\tcmdStr := fmt.Sprintf(\"sudo tc qdisc add dev %s root netem delay %dms %dms distribution normal\", ifce, ms, rv)\r\n\t\t_, err = exec.Command(\"\/bin\/sh\", \"-c\", cmdStr).Output()\r\n\t\tif err != nil {\r\n\t\t\t\r\n\t\t\tcmdStr = fmt.Sprintf(\"sudo tc qdisc change dev %s root netem delay %dms %dms distribution normal\", ifce, ms, rv)\r\n\t\t\t_, err = exec.Command(\"\/bin\/sh\", \"-c\", cmdStr).Output()\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":261,"reference":"\/\/ SetLatency adds latency in millisecond scale with random variations.","result":"Set the latency of the network interface.","score":[0.1052,0.0515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RemoveLatency() error {\r\n\tifces, err := GetDefaultInterfaces()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfor ifce := range ifces {\r\n\t\t_, err = exec.Command(\"\/bin\/sh\", \"-c\", fmt.Sprintf(\"sudo tc qdisc del dev %s root netem\", ifce)).Output()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":132,"reference":"\/\/ RemoveLatency resets latency configurations.","result":"Remove latency from the network interface.","score":[0.193,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTxnCommand() *cobra.Command {\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"txn [options]\",\r\n\t\tShort: \"Txn processes all the requests in one transaction\",\r\n\t\tRun:   txnCommandFunc,\r\n\t}\r\n\tcmd.Flags().BoolVarP(&txnInteractive, \"interactive\", \"i\", false, \"Input transaction in interactive mode\")\r\n\treturn cmd\r\n}","code-length":115,"reference":"\/\/ NewTxnCommand returns the cobra command for \"txn\".","result":"Create a transaction.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc txnCommandFunc(cmd *cobra.Command, args []string) {\r\n\tif len(args) != 0 {\r\n\t\tExitWithError(ExitBadArgs, fmt.Errorf(\"txn command does not accept argument\"))\r\n\t}\r\n\treader := bufio.NewReader(os.Stdin)\r\n\ttxn := mustClientFromCmd(cmd).Txn(context.Background())\r\n\tpromptInteractive(\"compares:\")\r\n\ttxn.If(readCompares(reader)...)\r\n\tpromptInteractive(\"success requests (get, put, del):\")\r\n\ttxn.Then(readOps(reader)...)\r\n\tpromptInteractive(\"failure requests (get, put, del):\")\r\n\ttxn.Else(readOps(reader)...)\r\n\tresp, err := txn.Commit()\r\n\tif err != nil {\r\n\t\tExitWithError(ExitError, err)\r\n\t}\r\n\tdisplay.Txn(*resp)\r\n}","code-length":228,"reference":"\/\/ txnCommandFunc executes the \"txn\" command.","result":"Run the command .","score":[0.1938,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(\r\n\tlg *zap.Logger,\r\n\tmode string,\r\n\tretention time.Duration,\r\n\trg RevGetter,\r\n\tc Compactable,\r\n) (Compactor, error) {\r\n\tswitch mode {\r\n\tcase ModePeriodic:\r\n\t\treturn newPeriodic(lg, clockwork.NewRealClock(), retention, rg, c), nil\r\n\tcase ModeRevision:\r\n\t\treturn newRevision(lg, clockwork.NewRealClock(), int64(retention), rg, c), nil\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"unsupported compaction mode %s\", mode)\r\n\t}\r\n}","code-length":164,"reference":"\/\/ New returns a new Compactor based on given \"mode\".","result":"Create a new compactor.","score":[0.1008,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc printResponseKey(resp *client.Response, format string) {\r\n\t\r\n\tswitch format {\r\n\tcase \"simple\":\r\n\t\tif resp.Action != \"delete\" {\r\n\t\t\tfmt.Println(resp.Node.Value)\r\n\t\t} else {\r\n\t\t\tfmt.Println(\"PrevNode.Value:\", resp.PrevNode.Value)\r\n\t\t}\r\n\tcase \"extended\":\r\n\t\t\r\n\t\tfmt.Println(\"Key:\", resp.Node.Key)\r\n\t\tfmt.Println(\"Created-Index:\", resp.Node.CreatedIndex)\r\n\t\tfmt.Println(\"Modified-Index:\", resp.Node.ModifiedIndex)\r\n\t\tif resp.PrevNode != nil {\r\n\t\t\tfmt.Println(\"PrevNode.Value:\", resp.PrevNode.Value)\r\n\t\t}\r\n\t\tfmt.Println(\"TTL:\", resp.Node.TTL)\r\n\t\tfmt.Println(\"Index:\", resp.Index)\r\n\t\tif resp.Action != \"delete\" {\r\n\t\t\tfmt.Println(\"\")\r\n\t\t\tfmt.Println(resp.Node.Value)\r\n\t\t}\r\n\tcase \"json\":\r\n\t\tb, err := json.Marshal(resp)\r\n\t\tif err != nil {\r\n\t\t\tpanic(err)\r\n\t\t}\r\n\t\tfmt.Println(string(b))\r\n\tdefault:\r\n\t\tfmt.Fprintln(os.Stderr, \"Unsupported output format:\", format)\r\n\t}\r\n}","code-length":378,"reference":"\/\/ printResponseKey only supports to print key correctly.","result":"Print the response key.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterLockHandler(ctx context.Context, mux *runtime.ServeMux, conn *grpc.ClientConn) error {\r\n\treturn RegisterLockHandlerClient(ctx, mux, v3lockpb.NewLockClient(conn))\r\n}","code-length":62,"reference":"\/\/ RegisterLockHandler registers the http handlers for service Lock to \"mux\".\n\/\/ The handlers forward requests to the grpc endpoint over \"conn\".","result":"Register the handler for the v.","score":[0.0177,0.1824]}
{"code":"\/*is used to<extra_id_0>\r\nfunc grpcHandlerFunc(grpcServer *grpc.Server, otherHandler http.Handler) http.Handler {\r\n\tif otherHandler == nil {\r\n\t\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\r\n\t\t\tgrpcServer.ServeHTTP(w, r)\r\n\t\t})\r\n\t}\r\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\r\n\t\tif r.ProtoMajor == 2 && strings.Contains(r.Header.Get(\"Content-Type\"), \"application\/grpc\") {\r\n\t\t\tgrpcServer.ServeHTTP(w, r)\r\n\t\t} else {\r\n\t\t\totherHandler.ServeHTTP(w, r)\r\n\t\t}\r\n\t})\r\n}","code-length":192,"reference":"\/\/ grpcHandlerFunc returns an http.Handler that delegates to grpcServer on incoming gRPC\n\/\/ connections or otherHandler otherwise. Given in gRPC docs.","result":"Handle grpc requests.","score":[0,0.026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc addCORSHeader(w http.ResponseWriter, origin string) {\r\n\tw.Header().Add(\"Access-Control-Allow-Methods\", \"POST, GET, OPTIONS, PUT, DELETE\")\r\n\tw.Header().Add(\"Access-Control-Allow-Origin\", origin)\r\n\tw.Header().Add(\"Access-Control-Allow-Headers\", \"accept, content-type, authorization\")\r\n}","code-length":101,"reference":"\/\/ addCORSHeader adds the correct cors headers given an origin","result":"Add CORS headers.","score":[0,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (txn *txnLeasing) fallback(ops []v3.Op) (fbOps []v3.Op) {\r\n\tfor _, op := range ops {\r\n\t\tif op.IsGet() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tlkey, lend := txn.lkv.pfx+string(op.KeyBytes()), \"\"\r\n\t\tif len(op.RangeBytes()) > 0 {\r\n\t\t\tlend = txn.lkv.pfx + string(op.RangeBytes())\r\n\t\t}\r\n\t\tfbOps = append(fbOps, v3.OpGet(lkey, v3.WithRange(lend)))\r\n\t}\r\n\treturn fbOps\r\n}","code-length":180,"reference":"\/\/ fallback computes the ops to fetch all possible conflicting\n\/\/ leasing keys for a list of ops.","result":"Fallback to leasing transaction.","score":[0.0115,0.0904]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IDFromString(s string) (ID, error) {\r\n\ti, err := strconv.ParseUint(s, 16, 64)\r\n\treturn ID(i), err\r\n}","code-length":52,"reference":"\/\/ IDFromString attempts to create an ID from a base-16 string.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (guard *directoryLockGuard) release() error {\r\n\tvar err error\r\n\tif !guard.readOnly {\r\n\t\t\r\n\t\terr = os.Remove(guard.path)\r\n\t}\r\n\tif closeErr := guard.f.Close(); err == nil {\r\n\t\terr = closeErr\r\n\t}\r\n\tguard.path = \"\"\r\n\tguard.f = nil\r\n\treturn err\r\n}","code-length":111,"reference":"\/\/ Release deletes the pid file and releases our lock on the directory.","result":"Release the lock.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v *ValueStruct) EncodedSize() uint16 {\r\n\tsz := len(v.Value) + 2\r\n\tif v.ExpiresAt == 0 {\r\n\t\treturn uint16(sz + 1)\r\n\t}\r\n\tenc := sizeVarint(v.ExpiresAt)\r\n\treturn uint16(sz + enc)\r\n}","code-length":89,"reference":"\/\/ EncodedSize is the size of the ValueStruct when encoded","result":"Encode the value.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v *ValueStruct) Decode(b []byte) {\r\n\tv.Meta = b[0]\r\n\tv.UserMeta = b[1]\r\n\tvar sz int\r\n\tv.ExpiresAt, sz = binary.Uvarint(b[2:])\r\n\tv.Value = b[2+sz:]\r\n}","code-length":88,"reference":"\/\/ Decode uses the length of the slice to infer the length of the Value field.","result":"Decode the value.","score":[0.0064,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMergeIterator(iters []Iterator, reversed bool) *MergeIterator {\r\n\tm := &MergeIterator{all: iters, reversed: reversed}\r\n\tm.h = make(elemHeap, 0, len(iters))\r\n\tm.initHeap()\r\n\treturn m\r\n}","code-length":77,"reference":"\/\/ NewMergeIterator returns a new MergeIterator from a list of Iterators.","result":"Create a new iterator.","score":[0.0785,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MergeIterator) initHeap() {\r\n\ts.h = s.h[:0]\r\n\tfor idx, itr := range s.all {\r\n\t\tif !itr.Valid() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\te := &elem{itr: itr, nice: idx, reversed: s.reversed}\r\n\t\ts.h = append(s.h, e)\r\n\t}\r\n\theap.Init(&s.h)\r\n\tfor len(s.h) > 0 {\r\n\t\tit := s.h[0].itr\r\n\t\tif it == nil || !it.Valid() {\r\n\t\t\theap.Pop(&s.h)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\ts.storeKey(s.h[0].itr)\r\n\t\tbreak\r\n\t}\r\n}","code-length":220,"reference":"\/\/ initHeap checks all iterators and initializes our heap and array of keys.\n\/\/ Whenever we reverse direction, we need to run this.","result":"Initialize the heap.","score":[0,0.0238]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MergeIterator) Valid() bool {\r\n\tif s == nil {\r\n\t\treturn false\r\n\t}\r\n\tif len(s.h) == 0 {\r\n\t\treturn false\r\n\t}\r\n\treturn s.h[0].itr.Valid()\r\n}","code-length":79,"reference":"\/\/ Valid returns whether the MergeIterator is at a valid element.","result":"Validate the merge iterator.","score":[0.0555,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MergeIterator) Key() []byte {\r\n\tif len(s.h) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\treturn s.h[0].itr.Key()\r\n}","code-length":62,"reference":"\/\/ Key returns the key associated with the current iterator","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MergeIterator) Value() ValueStruct {\r\n\tif len(s.h) == 0 {\r\n\t\treturn ValueStruct{}\r\n\t}\r\n\treturn s.h[0].itr.Value()\r\n}","code-length":64,"reference":"\/\/ Value returns the value associated with the iterator.","result":"Avoid recursive call.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MergeIterator) Next() {\r\n\tif len(s.h) == 0 {\r\n\t\treturn\r\n\t}\r\n\tsmallest := s.h[0].itr\r\n\tsmallest.Next()\r\n\tfor len(s.h) > 0 {\r\n\t\tsmallest = s.h[0].itr\r\n\t\tif !smallest.Valid() {\r\n\t\t\theap.Pop(&s.h)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\theap.Fix(&s.h, 0)\r\n\t\tsmallest = s.h[0].itr\r\n\t\tif smallest.Valid() {\r\n\t\t\tif !bytes.Equal(smallest.Key(), s.curKey) {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\tsmallest.Next()\r\n\t\t}\r\n\t}\r\n\tif !smallest.Valid() {\r\n\t\treturn\r\n\t}\r\n\ts.storeKey(smallest)\r\n}","code-length":249,"reference":"\/\/ Next returns the next element. If it is the same as the current key, ignore it.","result":"Avoid recursive call to Next.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MergeIterator) Seek(key []byte) {\r\n\tfor _, itr := range s.all {\r\n\t\titr.Seek(key)\r\n\t}\r\n\ts.initHeap()\r\n}","code-length":62,"reference":"\/\/ Seek brings us to element with key >= given key.","result":"Test the merge iterator.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *MergeIterator) Close() error {\r\n\tfor _, itr := range s.all {\r\n\t\tif err := itr.Close(); err != nil {\r\n\t\t\treturn errors.Wrap(err, \"MergeIterator\")\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":80,"reference":"\/\/ Close implements y.Iterator","result":"Close the iterator.","score":[0.2925,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p valuePointer) Encode(b []byte) []byte {\r\n\tbinary.BigEndian.PutUint32(b[:4], p.Fid)\r\n\tbinary.BigEndian.PutUint32(b[4:8], p.Len)\r\n\tbinary.BigEndian.PutUint32(b[8:12], p.Offset)\r\n\treturn b[:vptrSize]\r\n}","code-length":102,"reference":"\/\/ Encode encodes Pointer into byte buffer.","result":"Encode the pointer to a value.","score":[0.1634,0.1449]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *header) Decode(buf []byte) {\r\n\th.klen = binary.BigEndian.Uint32(buf[0:4])\r\n\th.vlen = binary.BigEndian.Uint32(buf[4:8])\r\n\th.expiresAt = binary.BigEndian.Uint64(buf[8:16])\r\n\th.meta = buf[16]\r\n\th.userMeta = buf[17]\r\n}","code-length":114,"reference":"\/\/ Decodes h from buf.","result":"Decode the header.","score":[0,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc encodeEntry(e *Entry, buf *bytes.Buffer) (int, error) {\r\n\th := header{\r\n\t\tklen:      uint32(len(e.Key)),\r\n\t\tvlen:      uint32(len(e.Value)),\r\n\t\texpiresAt: e.ExpiresAt,\r\n\t\tmeta:      e.meta,\r\n\t\tuserMeta:  e.UserMeta,\r\n\t}\r\n\tvar headerEnc [headerBufSize]byte\r\n\th.Encode(headerEnc[:])\r\n\thash := crc32.New(y.CastagnoliCrcTable)\r\n\tbuf.Write(headerEnc[:])\r\n\thash.Write(headerEnc[:])\r\n\tbuf.Write(e.Key)\r\n\thash.Write(e.Key)\r\n\tbuf.Write(e.Value)\r\n\thash.Write(e.Value)\r\n\tvar crcBuf [crc32.Size]byte\r\n\tbinary.BigEndian.PutUint32(crcBuf[:], hash.Sum32())\r\n\tbuf.Write(crcBuf[:])\r\n\treturn len(headerEnc) + len(e.Key) + len(e.Value) + len(crcBuf), nil\r\n}","code-length":300,"reference":"\/\/ Encodes e to buf. Returns number of bytes written.","result":"Encode the entry.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wb *WriteBatch) SetEntry(e *Entry) error {\r\n\twb.Lock()\r\n\tdefer wb.Unlock()\r\n\tif err := wb.txn.SetEntry(e); err != ErrTxnTooBig {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif cerr := wb.commit(); cerr != nil {\r\n\t\treturn cerr\r\n\t}\r\n\t\r\n\t\r\n\tif err := wb.txn.SetEntry(e); err != nil {\r\n\t\twb.err = err\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":151,"reference":"\/\/ SetEntry is the equivalent of Txn.SetEntry.","result":"Set the entry in the batch.","score":[0.1634,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wb *WriteBatch) Set(k, v []byte, meta byte) error {\r\n\te := &Entry{Key: k, Value: v, UserMeta: meta}\r\n\treturn wb.SetEntry(e)\r\n}","code-length":64,"reference":"\/\/ Set is equivalent of Txn.SetWithMeta.","result":"Set the value of a key in a write batch.","score":[0.1291,0.1562]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wb *WriteBatch) SetWithTTL(key, val []byte, dur time.Duration) error {\r\n\texpire := time.Now().Add(dur).Unix()\r\n\te := &Entry{Key: key, Value: val, ExpiresAt: uint64(expire)}\r\n\treturn wb.SetEntry(e)\r\n}","code-length":86,"reference":"\/\/ SetWithTTL is equivalent of Txn.SetWithTTL.","result":"Set the value of a key in a write batch.","score":[0.1086,0.0781]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wb *WriteBatch) Delete(k []byte) error {\r\n\twb.Lock()\r\n\tdefer wb.Unlock()\r\n\tif err := wb.txn.Delete(k); err != ErrTxnTooBig {\r\n\t\treturn err\r\n\t}\r\n\tif err := wb.commit(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := wb.txn.Delete(k); err != nil {\r\n\t\twb.err = err\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":139,"reference":"\/\/ Delete is equivalent of Txn.Delete.","result":"Delete a key.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wb *WriteBatch) commit() error {\r\n\tif wb.err != nil {\r\n\t\treturn wb.err\r\n\t}\r\n\t\r\n\t\r\n\twb.wg.Add(1)\r\n\twb.txn.CommitWith(wb.callback)\r\n\twb.txn = wb.db.newTransaction(true, true)\r\n\t\r\n\twb.txn.readTs = wb.db.orc.readMark.DoneUntil()\r\n\treturn wb.err\r\n}","code-length":127,"reference":"\/\/ Caller to commit must hold a write lock.","result":"Commit the batch.","score":[0,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wb *WriteBatch) Flush() error {\r\n\twb.Lock()\r\n\t_ = wb.commit()\r\n\twb.txn.Discard()\r\n\twb.Unlock()\r\n\twb.wg.Wait()\r\n\t\r\n\treturn wb.err\r\n}","code-length":74,"reference":"\/\/ Flush must be called at the end to ensure that any pending writes get committed to Badger. Flush\n\/\/ returns any error stored by WriteBatch.","result":"Flush the batch.","score":[0.0002,0.0422]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (wb *WriteBatch) Error() error {\r\n\twb.Lock()\r\n\tdefer wb.Unlock()\r\n\treturn wb.err\r\n}","code-length":45,"reference":"\/\/ Error returns any errors encountered so far. No commits would be run once an error is detected.","result":"Generate the error message.","score":[0.0096,0.0301]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) getMemTables() ([]*skl.Skiplist, func()) {\r\n\tdb.RLock()\r\n\tdefer db.RUnlock()\r\n\ttables := make([]*skl.Skiplist, len(db.imm)+1)\r\n\t\r\n\ttables[0] = db.mt\r\n\ttables[0].IncrRef()\r\n\t\r\n\tlast := len(db.imm) - 1\r\n\tfor i := range db.imm {\r\n\t\ttables[i+1] = db.imm[last-i]\r\n\t\ttables[i+1].IncrRef()\r\n\t}\r\n\treturn tables, func() {\r\n\t\tfor _, tbl := range tables {\r\n\t\t\ttbl.DecrRef()\r\n\t\t}\r\n\t}\r\n}","code-length":206,"reference":"\/\/ getMemtables returns the current memtables and get references.","result":"Avoid the need for the function .","score":[0.1214,0.0568]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) writeRequests(reqs []*request) error {\r\n\tif len(reqs) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\tdone := func(err error) {\r\n\t\tfor _, r := range reqs {\r\n\t\t\tr.Err = err\r\n\t\t\tr.Wg.Done()\r\n\t\t}\r\n\t}\r\n\tdb.elog.Printf(\"writeRequests called. Writing to value log\")\r\n\terr := db.vlog.write(reqs)\r\n\tif err != nil {\r\n\t\tdone(err)\r\n\t\treturn err\r\n\t}\r\n\tdb.elog.Printf(\"Writing to memtable\")\r\n\tvar count int\r\n\tfor _, b := range reqs {\r\n\t\tif len(b.Entries) == 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tcount += len(b.Entries)\r\n\t\tvar i uint64\r\n\t\tfor err = db.ensureRoomForWrite(); err == errNoRoom; err = db.ensureRoomForWrite() {\r\n\t\t\ti++\r\n\t\t\tif i%100 == 0 {\r\n\t\t\t\tdb.elog.Printf(\"Making room for writes\")\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\ttime.Sleep(10 * time.Millisecond)\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\tdone(err)\r\n\t\t\treturn errors.Wrap(err, \"writeRequests\")\r\n\t\t}\r\n\t\tif err := db.writeToLSM(b); err != nil {\r\n\t\t\tdone(err)\r\n\t\t\treturn errors.Wrap(err, \"writeRequests\")\r\n\t\t}\r\n\t\tdb.updateHead(b.Ptrs)\r\n\t}\r\n\tdone(nil)\r\n\tdb.elog.Printf(\"%d entries written\", count)\r\n\treturn nil\r\n}","code-length":463,"reference":"\/\/ writeRequests is called serially by only one goroutine.","result":"Var errNoRoom error.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) ensureRoomForWrite() error {\r\n\tvar err error\r\n\tdb.Lock()\r\n\tdefer db.Unlock()\r\n\tif db.mt.MemSize() < db.opt.MaxTableSize {\r\n\t\treturn nil\r\n\t}\r\n\ty.AssertTrue(db.mt != nil)\r\n\tselect {\r\n\tcase db.flushChan <- flushTask{mt: db.mt, vptr: db.vhead}:\r\n\t\tdb.elog.Printf(\"Flushing value log to disk if async mode.\")\r\n\t\t\r\n\t\terr = db.vlog.sync(db.vhead.Fid)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdb.elog.Printf(\"Flushing memtable, mt.size=%d size of flushChan: %d\\n\",\r\n\t\t\tdb.mt.MemSize(), len(db.flushChan))\r\n\t\t\r\n\t\tdb.imm = append(db.imm, db.mt)\r\n\t\tdb.mt = skl.NewSkiplist(arenaSize(db.opt))\r\n\t\t\r\n\t\treturn nil\r\n\tdefault:\r\n\t\t\r\n\t\treturn errNoRoom\r\n\t}\r\n}","code-length":310,"reference":"\/\/ ensureRoomForWrite is always called serially.","result":"Ensure room for write.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc writeLevel0Table(ft flushTask, f io.Writer) error {\r\n\titer := ft.mt.NewIterator()\r\n\tdefer iter.Close()\r\n\tb := table.NewTableBuilder()\r\n\tdefer b.Close()\r\n\tfor iter.SeekToFirst(); iter.Valid(); iter.Next() {\r\n\t\tif len(ft.dropPrefix) > 0 && bytes.HasPrefix(iter.Key(), ft.dropPrefix) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif err := b.Add(iter.Key(), iter.Value()); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\t_, err := f.Write(b.Finish())\r\n\treturn err\r\n}","code-length":185,"reference":"\/\/ WriteLevel0Table flushes memtable.","result":"Write the level.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) handleFlushTask(ft flushTask) error {\r\n\tif !ft.mt.Empty() {\r\n\t\t\r\n\t\tdb.opt.Debugf(\"Storing value log head: %+v\\n\", ft.vptr)\r\n\t\tdb.elog.Printf(\"Storing offset: %+v\\n\", ft.vptr)\r\n\t\toffset := make([]byte, vptrSize)\r\n\t\tft.vptr.Encode(offset)\r\n\t\t\r\n\t\t\r\n\t\theadTs := y.KeyWithTs(head, db.orc.nextTs())\r\n\t\tft.mt.Put(headTs, y.ValueStruct{Value: offset})\r\n\t\t\r\n\t\tdiscardStatsKey := y.KeyWithTs(lfDiscardStatsKey, 1)\r\n\t\tft.mt.Put(discardStatsKey, y.ValueStruct{Value: db.vlog.encodedDiscardStats()})\r\n\t}\r\n\tfileID := db.lc.reserveFileID()\r\n\tfd, err := y.CreateSyncedFile(table.NewFilename(fileID, db.opt.Dir), true)\r\n\tif err != nil {\r\n\t\treturn y.Wrap(err)\r\n\t}\r\n\t\r\n\tdirSyncCh := make(chan error)\r\n\tgo func() { dirSyncCh <- syncDir(db.opt.Dir) }()\r\n\terr = writeLevel0Table(ft, fd)\r\n\tdirSyncErr := <-dirSyncCh\r\n\tif err != nil {\r\n\t\tdb.elog.Errorf(\"ERROR while writing to level 0: %v\", err)\r\n\t\treturn err\r\n\t}\r\n\tif dirSyncErr != nil {\r\n\t\t\r\n\t\tdb.elog.Errorf(\"ERROR while syncing level directory: %v\", dirSyncErr)\r\n\t}\r\n\ttbl, err := table.OpenTable(fd, db.opt.TableLoadingMode, nil)\r\n\tif err != nil {\r\n\t\tdb.elog.Printf(\"ERROR while opening table: %v\", err)\r\n\t\treturn err\r\n\t}\r\n\t\r\n\terr = db.lc.addLevel0Table(tbl)\r\n\ttbl.DecrRef()\r\n\treturn err\r\n}","code-length":538,"reference":"\/\/ handleFlushTask must be run serially.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) flushMemtable(lc *y.Closer) error {\r\n\tdefer lc.Done()\r\n\tfor ft := range db.flushChan {\r\n\t\tif ft.mt == nil {\r\n\t\t\t\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tfor {\r\n\t\t\terr := db.handleFlushTask(ft)\r\n\t\t\tif err == nil {\r\n\t\t\t\t\r\n\t\t\t\tdb.Lock()\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\ty.AssertTrue(ft.mt == db.imm[0])\r\n\t\t\t\tdb.imm = db.imm[1:]\r\n\t\t\t\tft.mt.DecrRef()\r\n\t\t\t\tdb.Unlock()\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tdb.opt.Errorf(\"Failure while flushing memtable to disk: %v. Retrying...\\n\", err)\r\n\t\t\ttime.Sleep(time.Second)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":253,"reference":"\/\/ flushMemtable must keep running until we send it an empty flushTask. If there\n\/\/ are errors during handling the flush task, we'll retry indefinitely.","result":"Flush memtable to disk.","score":[0,0.0218]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) calculateSize() {\r\n\tnewInt := func(val int64) *expvar.Int {\r\n\t\tv := new(expvar.Int)\r\n\t\tv.Add(val)\r\n\t\treturn v\r\n\t}\r\n\ttotalSize := func(dir string) (int64, int64) {\r\n\t\tvar lsmSize, vlogSize int64\r\n\t\terr := filepath.Walk(dir, func(path string, info os.FileInfo, err error) error {\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\text := filepath.Ext(path)\r\n\t\t\tif ext == \".sst\" {\r\n\t\t\t\tlsmSize += info.Size()\r\n\t\t\t} else if ext == \".vlog\" {\r\n\t\t\t\tvlogSize += info.Size()\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t})\r\n\t\tif err != nil {\r\n\t\t\tdb.elog.Printf(\"Got error while calculating total size of directory: %s\", dir)\r\n\t\t}\r\n\t\treturn lsmSize, vlogSize\r\n\t}\r\n\tlsmSize, vlogSize := totalSize(db.opt.Dir)\r\n\ty.LSMSize.Set(db.opt.Dir, newInt(lsmSize))\r\n\t\r\n\tif db.opt.ValueDir != db.opt.Dir {\r\n\t\t_, vlogSize = totalSize(db.opt.ValueDir)\r\n\t}\r\n\ty.VlogSize.Set(db.opt.Dir, newInt(vlogSize))\r\n}","code-length":395,"reference":"\/\/ This function does a filewalk, calculates the size of vlog and sst files and stores it in\n\/\/ y.LSMSize and y.VlogSize.","result":"Calculate the size of the database.","score":[0.0276,0.1547]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) Size() (lsm, vlog int64) {\r\n\tif y.LSMSize.Get(db.opt.Dir) == nil {\r\n\t\tlsm, vlog = 0, 0\r\n\t\treturn\r\n\t}\r\n\tlsm = y.LSMSize.Get(db.opt.Dir).(*expvar.Int).Value()\r\n\tvlog = y.VlogSize.Get(db.opt.Dir).(*expvar.Int).Value()\r\n\treturn\r\n}","code-length":133,"reference":"\/\/ Size returns the size of lsm and value log files in bytes. It can be used to decide how often to\n\/\/ call RunValueLogGC.","result":"Compute the size of the database.","score":[0.0168,0.1106]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (seq *Sequence) Next() (uint64, error) {\r\n\tseq.Lock()\r\n\tdefer seq.Unlock()\r\n\tif seq.next >= seq.leased {\r\n\t\tif err := seq.updateLease(); err != nil {\r\n\t\t\treturn 0, err\r\n\t\t}\r\n\t}\r\n\tval := seq.next\r\n\tseq.next++\r\n\treturn val, nil\r\n}","code-length":110,"reference":"\/\/ Next would return the next integer in the sequence, updating the lease by running a transaction\n\/\/ if needed.","result":"Generate the code.","score":[0.0014,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (seq *Sequence) Release() error {\r\n\tseq.Lock()\r\n\tdefer seq.Unlock()\r\n\terr := seq.db.Update(func(txn *Txn) error {\r\n\t\tvar buf [8]byte\r\n\t\tbinary.BigEndian.PutUint64(buf[:], seq.next)\r\n\t\treturn txn.Set(seq.key, buf[:])\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tseq.leased = seq.next\r\n\treturn nil\r\n}","code-length":140,"reference":"\/\/ Release the leased sequence to avoid wasted integers. This should be done right\n\/\/ before closing the associated DB. However it is valid to use the sequence after\n\/\/ it was released, causing a new lease with full bandwidth.","result":"Release the sequence.","score":[0.0,0.0275]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) KeySplits(prefix []byte) []string {\r\n\tvar splits []string\r\n\tfor _, ti := range db.Tables() {\r\n\t\t\r\n\t\t\r\n\t\tif bytes.HasPrefix(ti.Right, prefix) {\r\n\t\t\tsplits = append(splits, string(ti.Right))\r\n\t\t}\r\n\t}\r\n\tsort.Strings(splits)\r\n\treturn splits\r\n}","code-length":111,"reference":"\/\/ KeySplits can be used to get rough key ranges to divide up iteration over\n\/\/ the DB.","result":"Split keys.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) Flatten(workers int) error {\r\n\tdb.stopCompactions()\r\n\tdefer db.startCompactions()\r\n\tcompactAway := func(cp compactionPriority) error {\r\n\t\tdb.opt.Infof(\"Attempting to compact with %+v\\n\", cp)\r\n\t\terrCh := make(chan error, 1)\r\n\t\tfor i := 0; i < workers; i++ {\r\n\t\t\tgo func() {\r\n\t\t\t\terrCh <- db.lc.doCompact(cp)\r\n\t\t\t}()\r\n\t\t}\r\n\t\tvar success int\r\n\t\tvar rerr error\r\n\t\tfor i := 0; i < workers; i++ {\r\n\t\t\terr := <-errCh\r\n\t\t\tif err != nil {\r\n\t\t\t\trerr = err\r\n\t\t\t\tdb.opt.Warningf(\"While running doCompact with %+v. Error: %v\\n\", cp, err)\r\n\t\t\t} else {\r\n\t\t\t\tsuccess++\r\n\t\t\t}\r\n\t\t}\r\n\t\tif success == 0 {\r\n\t\t\treturn rerr\r\n\t\t}\r\n\t\t\r\n\t\tdb.opt.Infof(\"%d compactor(s) succeeded. One or more tables from level %d compacted.\\n\",\r\n\t\t\tsuccess, cp.level)\r\n\t\treturn nil\r\n\t}\r\n\thbytes := func(sz int64) string {\r\n\t\treturn humanize.Bytes(uint64(sz))\r\n\t}\r\n\tfor {\r\n\t\tdb.opt.Infof(\"\\n\")\r\n\t\tvar levels []int\r\n\t\tfor i, l := range db.lc.levels {\r\n\t\t\tsz := l.getTotalSize()\r\n\t\t\tdb.opt.Infof(\"Level: %d. %8s Size. %8s Max.\\n\",\r\n\t\t\t\ti, hbytes(l.getTotalSize()), hbytes(l.maxTotalSize))\r\n\t\t\tif sz > 0 {\r\n\t\t\t\tlevels = append(levels, i)\r\n\t\t\t}\r\n\t\t}\r\n\t\tif len(levels) <= 1 {\r\n\t\t\tprios := db.lc.pickCompactLevels()\r\n\t\t\tif len(prios) == 0 || prios[0].score <= 1.0 {\r\n\t\t\t\tdb.opt.Infof(\"All tables consolidated into one level. Flattening done.\\n\")\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\tif err := compactAway(prios[0]); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tcp := compactionPriority{level: levels[0], score: 1.71}\r\n\t\tif err := compactAway(cp); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n}","code-length":688,"reference":"\/\/ Flatten can be used to force compactions on the LSM tree so all the tables fall on the same\n\/\/ level. This ensures that all the versions of keys are colocated and not split across multiple\n\/\/ levels, which is necessary after a restore from backup. During Flatten, live compactions are\n\/\/ stopped. Ideally, no writes are going on during Flatten. Otherwise, it would create competition\n\/\/ between flattening the tree and new tables being created at level zero.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Mmap(fd *os.File, writable bool, size int64) ([]byte, error) {\r\n\tmtype := unix.PROT_READ\r\n\tif writable {\r\n\t\tmtype |= unix.PROT_WRITE\r\n\t}\r\n\treturn unix.Mmap(int(fd.Fd()), 0, int(size), mtype, unix.MAP_SHARED)\r\n}","code-length":102,"reference":"\/\/ Mmap uses the mmap system call to memory-map a file. If writable is true,\n\/\/ memory protection of the pages is set so that they may be written to as well.","result":"Create a file map.","score":[0.0003,0.0171]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Madvise(b []byte, readahead bool) error {\r\n\tflags := unix.MADV_NORMAL\r\n\tif !readahead {\r\n\t\tflags = unix.MADV_RANDOM\r\n\t}\r\n\treturn madvise(b, flags)\r\n}","code-length":77,"reference":"\/\/ Madvise uses the madvise system call to give advise about the use of memory\n\/\/ when using a slice that is memory-mapped to a file. Set the readahead flag to\n\/\/ false if page references are expected in random order.","result":"Avoid the need for the madvise function.","score":[0.002,0.0399]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *oracle) setDiscardTs(ts uint64) {\r\n\to.Lock()\r\n\tdefer o.Unlock()\r\n\to.discardTs = ts\r\n}","code-length":52,"reference":"\/\/ Any deleted or invalid versions at or below ts would be discarded during\n\/\/ compaction to reclaim disk space in LSM tree and thence value log.","result":"Discard the current timestamp.","score":[0,0.0202]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *oracle) hasConflict(txn *Txn) bool {\r\n\tif len(txn.reads) == 0 {\r\n\t\treturn false\r\n\t}\r\n\tfor _, ro := range txn.reads {\r\n\t\t\r\n\t\t\r\n\t\tif ts, has := o.commits[ro]; has && ts > txn.readTs {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":114,"reference":"\/\/ hasConflict must be called while having a lock.","result":"Check for conflicts in the transaction.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (txn *Txn) Set(key, val []byte) error {\r\n\te := &Entry{\r\n\t\tKey:   key,\r\n\t\tValue: val,\r\n\t}\r\n\treturn txn.SetEntry(e)\r\n}","code-length":68,"reference":"\/\/ Set adds a key-value pair to the database.\n\/\/\n\/\/ It will return ErrReadOnlyTxn if update flag was set to false when creating the\n\/\/ transaction.\n\/\/\n\/\/ The current transaction keeps a reference to the key and val byte slice\n\/\/ arguments. Users must not modify key and val until the end of the transaction.","result":"Set the value of a key in a transaction.","score":[0.001,0.067]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (txn *Txn) SetWithMeta(key, val []byte, meta byte) error {\r\n\te := &Entry{Key: key, Value: val, UserMeta: meta}\r\n\treturn txn.SetEntry(e)\r\n}","code-length":65,"reference":"\/\/ SetWithMeta adds a key-value pair to the database, along with a metadata\n\/\/ byte.\n\/\/\n\/\/ This byte is stored alongside the key, and can be used as an aid to\n\/\/ interpret the value or store other contextual bits corresponding to the\n\/\/ key-value pair.\n\/\/\n\/\/ The current transaction keeps a reference to the key and val byte slice\n\/\/ arguments. Users must not modify key and val until the end of the transaction.","result":"Set the value of a key.","score":[0.0,0.0286]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (txn *Txn) Delete(key []byte) error {\r\n\te := &Entry{\r\n\t\tKey:  key,\r\n\t\tmeta: bitDelete,\r\n\t}\r\n\treturn txn.modify(e)\r\n}","code-length":66,"reference":"\/\/ Delete deletes a key.\n\/\/\n\/\/ This is done by adding a delete marker for the key at commit timestamp.  Any\n\/\/ reads happening before this timestamp would be unaffected. Any reads after\n\/\/ this commit would see the deletion.\n\/\/\n\/\/ The current transaction keeps a reference to the key byte slice argument.\n\/\/ Users must not modify the key until the end of the transaction.","result":"Delete a key.","score":[0.0,0.0244]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (txn *Txn) Get(key []byte) (item *Item, rerr error) {\r\n\tif len(key) == 0 {\r\n\t\treturn nil, ErrEmptyKey\r\n\t} else if txn.discarded {\r\n\t\treturn nil, ErrDiscardedTxn\r\n\t}\r\n\titem = new(Item)\r\n\tif txn.update {\r\n\t\tif e, has := txn.pendingWrites[string(key)]; has && bytes.Equal(key, e.Key) {\r\n\t\t\tif isDeletedOrExpired(e.meta, e.ExpiresAt) {\r\n\t\t\t\treturn nil, ErrKeyNotFound\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\titem.meta = e.meta\r\n\t\t\titem.val = e.Value\r\n\t\t\titem.userMeta = e.UserMeta\r\n\t\t\titem.key = key\r\n\t\t\titem.status = prefetched\r\n\t\t\titem.version = txn.readTs\r\n\t\t\titem.expiresAt = e.ExpiresAt\r\n\t\t\t\r\n\t\t\treturn item, nil\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\ttxn.addReadKey(key)\r\n\t}\r\n\tseek := y.KeyWithTs(key, txn.readTs)\r\n\tvs, err := txn.db.get(seek)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrapf(err, \"DB::Get key: %q\", key)\r\n\t}\r\n\tif vs.Value == nil && vs.Meta == 0 {\r\n\t\treturn nil, ErrKeyNotFound\r\n\t}\r\n\tif isDeletedOrExpired(vs.Meta, vs.ExpiresAt) {\r\n\t\treturn nil, ErrKeyNotFound\r\n\t}\r\n\titem.key = key\r\n\titem.version = vs.Version\r\n\titem.meta = vs.Meta\r\n\titem.userMeta = vs.UserMeta\r\n\titem.db = txn.db\r\n\titem.vptr = vs.Value\r\n\titem.txn = txn\r\n\titem.expiresAt = vs.ExpiresAt\r\n\treturn item, nil\r\n}","code-length":504,"reference":"\/\/ Get looks for key and returns corresponding Item.\n\/\/ If key is not found, ErrKeyNotFound is returned.","result":"Get the value of a key in a transaction.","score":[0.0533,0.0585]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (txn *Txn) CommitWith(cb func(error)) {\r\n\ttxn.commitPrecheck()\r\n\tdefer txn.Discard()\r\n\tif cb == nil {\r\n\t\tpanic(\"Nil callback provided to CommitWith\")\r\n\t}\r\n\tif len(txn.writes) == 0 {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tgo runTxnCallback(&txnCb{user: cb, err: nil})\r\n\t\treturn\r\n\t}\r\n\tcommitCb, err := txn.commitAndSend()\r\n\tif err != nil {\r\n\t\tgo runTxnCallback(&txnCb{user: cb, err: err})\r\n\t\treturn\r\n\t}\r\n\tgo runTxnCallback(&txnCb{user: cb, commit: commitCb})\r\n}","code-length":195,"reference":"\/\/ CommitWith acts like Commit, but takes a callback, which gets run via a\n\/\/ goroutine to avoid blocking this function. The callback is guaranteed to run,\n\/\/ so it is safe to increment sync.WaitGroup before calling CommitWith, and\n\/\/ decrementing it in the callback; to block until all callbacks are run.","result":"Avoid the need for the following code.","score":[0.0003,0.0421]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) View(fn func(txn *Txn) error) error {\r\n\tvar txn *Txn\r\n\tif db.opt.managedTxns {\r\n\t\ttxn = db.NewTransactionAt(math.MaxUint64, false)\r\n\t} else {\r\n\t\ttxn = db.NewTransaction(false)\r\n\t}\r\n\tdefer txn.Discard()\r\n\treturn fn(txn)\r\n}","code-length":108,"reference":"\/\/ View executes a function creating and managing a read-only transaction for the user. Error\n\/\/ returned by the function is relayed by the View method.\n\/\/ If View is used with managed transactions, it would assume a read timestamp of MaxUint64.","result":"Generate the code for the view function.","score":[0.0017,0.0519]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) Update(fn func(txn *Txn) error) error {\r\n\tif db.opt.managedTxns {\r\n\t\tpanic(\"Update can only be used with managedDB=false.\")\r\n\t}\r\n\ttxn := db.NewTransaction(true)\r\n\tdefer txn.Discard()\r\n\tif err := fn(txn); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn txn.Commit()\r\n}","code-length":117,"reference":"\/\/ Update executes a function, creating and managing a read-write transaction\n\/\/ for the user. Error returned by the function is relayed by the Update method.\n\/\/ Update cannot be used with managed transactions.","result":"Generate code for the generated code.","score":[0.0026,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (itr *blockIterator) Seek(key []byte, whence int) {\r\n\titr.err = nil\r\n\tswitch whence {\r\n\tcase origin:\r\n\t\titr.Reset()\r\n\tcase current:\r\n\t}\r\n\tvar done bool\r\n\tfor itr.Init(); itr.Valid(); itr.Next() {\r\n\t\tk := itr.Key()\r\n\t\tif y.CompareKeys(k, key) >= 0 {\r\n\t\t\t\r\n\t\t\tdone = true\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif !done {\r\n\t\titr.err = io.EOF\r\n\t}\r\n}","code-length":167,"reference":"\/\/ Seek brings us to the first block element that is >= input key.","result":"Seek the iterator.","score":[0.0124,0.0775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (itr *blockIterator) SeekToLast() {\r\n\titr.err = nil\r\n\tfor itr.Init(); itr.Valid(); itr.Next() {\r\n\t}\r\n\titr.Prev()\r\n}","code-length":63,"reference":"\/\/ SeekToLast brings us to the last element. Valid should return true.","result":"Seek to the last block in the iterator.","score":[0.1735,0.1293]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (itr *blockIterator) parseKV(h header) {\r\n\tif cap(itr.key) < int(h.plen+h.klen) {\r\n\t\tsz := int(h.plen) + int(h.klen)\r\n\t\titr.key = make([]byte, 2*sz)\r\n\t}\r\n\titr.key = itr.key[:h.plen+h.klen]\r\n\tcopy(itr.key, itr.baseKey[:h.plen])\r\n\tcopy(itr.key[h.plen:], itr.data[itr.pos:itr.pos+uint32(h.klen)])\r\n\titr.pos += uint32(h.klen)\r\n\tif itr.pos+uint32(h.vlen) > uint32(len(itr.data)) {\r\n\t\titr.err = errors.Errorf(\"Value exceeded size of block: %d %d %d %d %v\",\r\n\t\t\titr.pos, h.klen, h.vlen, len(itr.data), h)\r\n\t\treturn\r\n\t}\r\n\titr.val = y.SafeCopy(itr.val, itr.data[itr.pos:itr.pos+uint32(h.vlen)])\r\n\titr.pos += uint32(h.vlen)\r\n}","code-length":339,"reference":"\/\/ parseKV would allocate a new byte slice for key and for value.","result":"Parse the block header.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Table) NewIterator(reversed bool) *Iterator {\r\n\tt.IncrRef()\r\n\tti := &Iterator{t: t, reversed: reversed}\r\n\tti.next()\r\n\treturn ti\r\n}","code-length":65,"reference":"\/\/ NewIterator returns a new iterator of the Table","result":"Create a new iterator.","score":[0.1294,0.2206]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (itr *Iterator) seekFrom(key []byte, whence int) {\r\n\titr.err = nil\r\n\tswitch whence {\r\n\tcase origin:\r\n\t\titr.reset()\r\n\tcase current:\r\n\t}\r\n\tidx := sort.Search(len(itr.t.blockIndex), func(idx int) bool {\r\n\t\tko := itr.t.blockIndex[idx]\r\n\t\treturn y.CompareKeys(ko.key, key) > 0\r\n\t})\r\n\tif idx == 0 {\r\n\t\t\r\n\t\t\r\n\t\titr.seekHelper(0, key)\r\n\t\treturn\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\titr.seekHelper(idx-1, key)\r\n\tif itr.err == io.EOF {\r\n\t\t\r\n\t\tif idx == len(itr.t.blockIndex) {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\titr.seekHelper(idx, key)\r\n\t}\r\n\t\r\n}","code-length":276,"reference":"\/\/ seekFrom brings us to a key that is >= input key.","result":"Avoid recursion.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (itr *Iterator) seekForPrev(key []byte) {\r\n\t\r\n\titr.seekFrom(key, origin)\r\n\tif !bytes.Equal(itr.Key(), key) {\r\n\t\titr.prev()\r\n\t}\r\n}","code-length":74,"reference":"\/\/ seekForPrev will reset iterator and seek to <= key.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (itr *Iterator) Value() (ret y.ValueStruct) {\r\n\tret.Decode(itr.bi.Value())\r\n\treturn\r\n}","code-length":47,"reference":"\/\/ Value follows the y.Iterator interface","result":"Return the value of the value of the iterator.","score":[0.1219,0.1587]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (itr *Iterator) Seek(key []byte) {\r\n\tif !itr.reversed {\r\n\t\titr.seek(key)\r\n\t} else {\r\n\t\titr.seekForPrev(key)\r\n\t}\r\n}","code-length":71,"reference":"\/\/ Seek follows the y.Iterator interface","result":"Set the iterator.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewConcatIterator(tbls []*Table, reversed bool) *ConcatIterator {\r\n\titers := make([]*Iterator, len(tbls))\r\n\tfor i := 0; i < len(tbls); i++ {\r\n\t\titers[i] = tbls[i].NewIterator(reversed)\r\n\t}\r\n\treturn &ConcatIterator{\r\n\t\treversed: reversed,\r\n\t\titers:    iters,\r\n\t\ttables:   tbls,\r\n\t\tidx:      -1,\r\n\t}\r\n}","code-length":138,"reference":"\/\/ NewConcatIterator creates a new concatenated iterator","result":"Create a new iterator for the concatenation.","score":[0.2528,0.5357]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *ConcatIterator) Valid() bool {\r\n\treturn s.cur != nil && s.cur.Valid()\r\n}","code-length":39,"reference":"\/\/ Valid implements y.Interface","result":"Validate the current value of the current iterator.","score":[0,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *ConcatIterator) Next() {\r\n\ts.cur.Next()\r\n\tif s.cur.Valid() {\r\n\t\t\r\n\t\treturn\r\n\t}\r\n\tfor {\r\n\t\tif !s.reversed {\r\n\t\t\ts.setIdx(s.idx + 1)\r\n\t\t} else {\r\n\t\t\ts.setIdx(s.idx - 1)\r\n\t\t}\r\n\t\tif s.cur == nil {\r\n\t\t\t\r\n\t\t\treturn\r\n\t\t}\r\n\t\ts.cur.Rewind()\r\n\t\tif s.cur.Valid() {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n}","code-length":173,"reference":"\/\/ Next advances our concat iterator.","result":"Iterate through the iterator.","score":[0.1938,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *ConcatIterator) Close() error {\r\n\tfor _, it := range s.iters {\r\n\t\tif err := it.Close(); err != nil {\r\n\t\t\treturn errors.Wrap(err, \"ConcatIterator\")\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":80,"reference":"\/\/ Close implements y.Interface.","result":"Close the iterator.","score":[0.2925,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc OpenExistingFile(filename string, flags uint32) (*os.File, error) {\r\n\topenFlags := os.O_RDWR\r\n\tif flags&ReadOnly != 0 {\r\n\t\topenFlags = os.O_RDONLY\r\n\t}\r\n\tif flags&Sync != 0 {\r\n\t\topenFlags |= datasyncFileFlag\r\n\t}\r\n\treturn os.OpenFile(filename, openFlags, 0)\r\n}","code-length":113,"reference":"\/\/ OpenExistingFile opens an existing file, errors if it doesn't exist.","result":"Open a file.","score":[0,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Copy(a []byte) []byte {\r\n\tb := make([]byte, len(a))\r\n\tcopy(b, a)\r\n\treturn b\r\n}","code-length":50,"reference":"\/\/ Copy copies a byte slice and returns the copied slice.","result":"Copy a byte array.","score":[0.0869,0.2481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc KeyWithTs(key []byte, ts uint64) []byte {\r\n\tout := make([]byte, len(key)+8)\r\n\tcopy(out, key)\r\n\tbinary.BigEndian.PutUint64(out[len(key):], math.MaxUint64-ts)\r\n\treturn out\r\n}","code-length":85,"reference":"\/\/ KeyWithTs generates a new key by appending ts to key.","result":"Generate the key with ts.","score":[0.0724,0.0962]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseTs(key []byte) uint64 {\r\n\tif len(key) <= 8 {\r\n\t\treturn 0\r\n\t}\r\n\treturn math.MaxUint64 - binary.BigEndian.Uint64(key[len(key)-8:])\r\n}","code-length":71,"reference":"\/\/ ParseTs parses the timestamp from the key bytes.","result":"Parse timestamp keys.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseKey(key []byte) []byte {\r\n\tif key == nil {\r\n\t\treturn nil\r\n\t}\r\n\tAssertTrue(len(key) > 8)\r\n\treturn key[:len(key)-8]\r\n}","code-length":66,"reference":"\/\/ ParseKey parses the actual key from the key bytes.","result":"Parse the key.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SameKey(src, dst []byte) bool {\r\n\tif len(src) != len(dst) {\r\n\t\treturn false\r\n\t}\r\n\treturn bytes.Equal(ParseKey(src), ParseKey(dst))\r\n}","code-length":66,"reference":"\/\/ SameKey checks for key equality ignoring the version timestamp suffix.","result":"Compare two keys.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FixedDuration(d time.Duration) string {\r\n\tstr := fmt.Sprintf(\"%02ds\", int(d.Seconds())%60)\r\n\tif d >= time.Minute {\r\n\t\tstr = fmt.Sprintf(\"%02dm\", int(d.Minutes())%60) + str\r\n\t}\r\n\tif d >= time.Hour {\r\n\t\tstr = fmt.Sprintf(\"%02dh\", int(d.Hours())) + str\r\n\t}\r\n\treturn str\r\n}","code-length":126,"reference":"\/\/ FixedDuration returns a string representation of the given duration with the\n\/\/ hours, minutes, and seconds.","result":"Generate the string representation of the time.","score":[0.1281,0.2788]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCloser(initial int) *Closer {\r\n\tret := &Closer{closed: make(chan struct{})}\r\n\tret.waiting.Add(initial)\r\n\treturn ret\r\n}","code-length":54,"reference":"\/\/ NewCloser constructs a new Closer, with an initial count on the WaitGroup.","result":"Create a new closer.","score":[0.0476,0.155]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewThrottle(max int) *Throttle {\r\n\treturn &Throttle{\r\n\t\tch:    make(chan struct{}, max),\r\n\t\terrCh: make(chan error, max),\r\n\t}\r\n}","code-length":62,"reference":"\/\/ NewThrottle creates a new throttle with a max number of workers.","result":"Create a new throttle.","score":[0.0611,0.1339]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Throttle) Do() error {\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase t.ch <- struct{}{}:\r\n\t\t\tt.wg.Add(1)\r\n\t\t\treturn nil\r\n\t\tcase err := <-t.errCh:\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":106,"reference":"\/\/ Do should be called by workers before they start working. It blocks if there\n\/\/ are already maximum number of workers working. If it detects an error from\n\/\/ previously Done workers, it would return it.","result":"Avoid the need for the function.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Throttle) Done(err error) {\r\n\tif err != nil {\r\n\t\tt.errCh <- err\r\n\t}\r\n\tselect {\r\n\tcase <-t.ch:\r\n\tdefault:\r\n\t\tpanic(\"Throttle Do Done mismatch\")\r\n\t}\r\n\tt.wg.Done()\r\n}","code-length":90,"reference":"\/\/ Done should be called by workers when they finish working. They can also\n\/\/ pass the error status of work done.","result":"Call the done function.","score":[0.0035,0.0743]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Throttle) Finish() error {\r\n\tt.wg.Wait()\r\n\tclose(t.ch)\r\n\tclose(t.errCh)\r\n\tfor err := range t.errCh {\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":91,"reference":"\/\/ Finish waits until all workers have finished working. It would return any\n\/\/ error passed by Done.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) SetDiscardTs(ts uint64) {\r\n\tif !db.opt.managedTxns {\r\n\t\tpanic(\"Cannot use SetDiscardTs with managedDB=false.\")\r\n\t}\r\n\tdb.orc.setDiscardTs(ts)\r\n}","code-length":76,"reference":"\/\/ SetDiscardTs sets a timestamp at or below which, any invalid or deleted\n\/\/ versions can be discarded from the LSM tree, and thence from the value log to\n\/\/ reclaim disk space. Can only be used with managed transactions.","result":"Set the discard timestamp.","score":[0.0,0.0412]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lf *logFile) openReadOnly() error {\r\n\tvar err error\r\n\tlf.fd, err = os.OpenFile(lf.path, os.O_RDONLY, 0666)\r\n\tif err != nil {\r\n\t\treturn errors.Wrapf(err, \"Unable to open %q as RDONLY.\", lf.path)\r\n\t}\r\n\tfi, err := lf.fd.Stat()\r\n\tif err != nil {\r\n\t\treturn errors.Wrapf(err, \"Unable to check stat for %q\", lf.path)\r\n\t}\r\n\ty.AssertTrue(fi.Size() <= math.MaxUint32)\r\n\tlf.size = uint32(fi.Size())\r\n\tif err = lf.mmap(fi.Size()); err != nil {\r\n\t\t_ = lf.fd.Close()\r\n\t\treturn y.Wrapf(err, \"Unable to map file\")\r\n\t}\r\n\treturn nil\r\n}","code-length":239,"reference":"\/\/ openReadOnly assumes that we have a write lock on logFile.","result":"Create a new file.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (vlog *valueLog) iterate(lf *logFile, offset uint32, fn logEntry) (uint32, error) {\r\n\tfi, err := lf.fd.Stat()\r\n\tif err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\tif int64(offset) == fi.Size() {\r\n\t\t\r\n\t\treturn offset, nil\r\n\t}\r\n\tif vlog.opt.ReadOnly {\r\n\t\t\r\n\t\t\r\n\t\treturn 0, ErrReplayNeeded\r\n\t}\r\n\t\r\n\tif _, err := lf.fd.Seek(int64(offset), io.SeekStart); err != nil {\r\n\t\treturn 0, errFile(err, lf.path, \"Unable to seek\")\r\n\t}\r\n\treader := bufio.NewReader(lf.fd)\r\n\tread := &safeRead{\r\n\t\tk:            make([]byte, 10),\r\n\t\tv:            make([]byte, 10),\r\n\t\trecordOffset: offset,\r\n\t}\r\n\tvar lastCommit uint64\r\n\tvar validEndOffset uint32\r\n\tfor {\r\n\t\te, err := read.Entry(reader)\r\n\t\tif err == io.EOF {\r\n\t\t\tbreak\r\n\t\t} else if err == io.ErrUnexpectedEOF || err == errTruncate {\r\n\t\t\tbreak\r\n\t\t} else if err != nil {\r\n\t\t\treturn 0, err\r\n\t\t} else if e == nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvar vp valuePointer\r\n\t\tvp.Len = uint32(headerBufSize + len(e.Key) + len(e.Value) + crc32.Size)\r\n\t\tread.recordOffset += vp.Len\r\n\t\tvp.Offset = e.offset\r\n\t\tvp.Fid = lf.fid\r\n\t\tif e.meta&bitTxn > 0 {\r\n\t\t\ttxnTs := y.ParseTs(e.Key)\r\n\t\t\tif lastCommit == 0 {\r\n\t\t\t\tlastCommit = txnTs\r\n\t\t\t}\r\n\t\t\tif lastCommit != txnTs {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t} else if e.meta&bitFinTxn > 0 {\r\n\t\t\ttxnTs, err := strconv.ParseUint(string(e.Value), 10, 64)\r\n\t\t\tif err != nil || lastCommit != txnTs {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tlastCommit = 0\r\n\t\t\tvalidEndOffset = read.recordOffset\r\n\t\t} else {\r\n\t\t\tif lastCommit != 0 {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\tvalidEndOffset = read.recordOffset\r\n\t\t}\r\n\t\tif err := fn(*e, vp); err != nil {\r\n\t\t\tif err == errStop {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\treturn 0, errFile(err, lf.path, \"Iteration function\")\r\n\t\t}\r\n\t}\r\n\treturn validEndOffset, nil\r\n}","code-length":739,"reference":"\/\/ iterate iterates over log file. It doesn't not allocate new memory for every kv pair.\n\/\/ Therefore, the kv pair is only valid for the duration of fn call.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (vlog *valueLog) sortedFids() []uint32 {\r\n\ttoBeDeleted := make(map[uint32]struct{})\r\n\tfor _, fid := range vlog.filesToBeDeleted {\r\n\t\ttoBeDeleted[fid] = struct{}{}\r\n\t}\r\n\tret := make([]uint32, 0, len(vlog.filesMap))\r\n\tfor fid := range vlog.filesMap {\r\n\t\tif _, ok := toBeDeleted[fid]; !ok {\r\n\t\t\tret = append(ret, fid)\r\n\t\t}\r\n\t}\r\n\tsort.Slice(ret, func(i, j int) bool {\r\n\t\treturn ret[i] < ret[j]\r\n\t})\r\n\treturn ret\r\n}","code-length":192,"reference":"\/\/ sortedFids returns the file id's not pending deletion, sorted.  Assumes we have shared access to\n\/\/ filesMap.","result":"Sort the files in the log.","score":[0.0261,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (vlog *valueLog) write(reqs []*request) error {\r\n\tvlog.filesLock.RLock()\r\n\tmaxFid := atomic.LoadUint32(&vlog.maxFid)\r\n\tcurlf := vlog.filesMap[maxFid]\r\n\tvlog.filesLock.RUnlock()\r\n\tvar buf bytes.Buffer\r\n\ttoDisk := func() error {\r\n\t\tif buf.Len() == 0 {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tvlog.elog.Printf(\"Flushing %d blocks of total size: %d\", len(reqs), buf.Len())\r\n\t\tn, err := curlf.fd.Write(buf.Bytes())\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"Unable to write to value log file: %q\", curlf.path)\r\n\t\t}\r\n\t\tbuf.Reset()\r\n\t\ty.NumWrites.Add(1)\r\n\t\ty.NumBytesWritten.Add(int64(n))\r\n\t\tvlog.elog.Printf(\"Done\")\r\n\t\tatomic.AddUint32(&vlog.writableLogOffset, uint32(n))\r\n\t\tif vlog.woffset() > uint32(vlog.opt.ValueLogFileSize) ||\r\n\t\t\tvlog.numEntriesWritten > vlog.opt.ValueLogMaxEntries {\r\n\t\t\tvar err error\r\n\t\t\tif err = curlf.doneWriting(vlog.woffset()); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tnewid := atomic.AddUint32(&vlog.maxFid, 1)\r\n\t\t\ty.AssertTruef(newid > 0, \"newid has overflown uint32: %v\", newid)\r\n\t\t\tnewlf, err := vlog.createVlogFile(newid)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tcurlf = newlf\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\tfor i := range reqs {\r\n\t\tb := reqs[i]\r\n\t\tb.Ptrs = b.Ptrs[:0]\r\n\t\tfor j := range b.Entries {\r\n\t\t\te := b.Entries[j]\r\n\t\t\tvar p valuePointer\r\n\t\t\tp.Fid = curlf.fid\r\n\t\t\t\r\n\t\t\tp.Offset = vlog.woffset() + uint32(buf.Len())\r\n\t\t\tplen, err := encodeEntry(e, &buf)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tp.Len = uint32(plen)\r\n\t\t\tb.Ptrs = append(b.Ptrs, p)\r\n\t\t}\r\n\t\tvlog.numEntriesWritten += uint32(len(b.Entries))\r\n\t\t\r\n\t\t\r\n\t\twriteNow :=\r\n\t\t\tvlog.woffset()+uint32(buf.Len()) > uint32(vlog.opt.ValueLogFileSize) ||\r\n\t\t\t\tvlog.numEntriesWritten > uint32(vlog.opt.ValueLogMaxEntries)\r\n\t\tif writeNow {\r\n\t\t\tif err := toDisk(); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn toDisk()\r\n}","code-length":817,"reference":"\/\/ write is thread-unsafe by design and should not be called concurrently.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (vlog *valueLog) populateDiscardStats() error {\r\n\tdiscardStatsKey := y.KeyWithTs(lfDiscardStatsKey, math.MaxUint64)\r\n\tvs, err := vlog.db.get(discardStatsKey)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif vs.Value == nil || len(vs.Value) == 0 {\r\n\t\tvlog.lfDiscardStats = &lfDiscardStats{m: make(map[uint32]int64)}\r\n\t\treturn nil\r\n\t}\r\n\tvar statsMap map[uint32]int64\r\n\tif err := json.Unmarshal(vs.Value, &statsMap); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tvlog.opt.Debugf(\"Value Log Discard stats: %v\", statsMap)\r\n\tvlog.lfDiscardStats = &lfDiscardStats{m: statsMap}\r\n\treturn nil\r\n}","code-length":237,"reference":"\/\/ populateDiscardStats populates vlog.lfDiscardStats\n\/\/ This function will be called while initializing valueLog","result":"Populate the discard stats in the value log.","score":[0,0.04]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) Backup(w io.Writer, since uint64) (uint64, error) {\r\n\tstream := db.NewStream()\r\n\tstream.LogPrefix = \"DB.Backup\"\r\n\treturn stream.Backup(w, since)\r\n}","code-length":71,"reference":"\/\/ Backup is a wrapper function over Stream.Backup to generate full and incremental backups of the\n\/\/ DB. For more control over how many goroutines are used to generate the backup, or if you wish to\n\/\/ backup only a certain range of keys, use Stream.Backup directly.","result":"Create a backup.","score":[0.0,0.0117]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (st *Stream) ToList(key []byte, itr *Iterator) (*pb.KVList, error) {\r\n\tlist := &pb.KVList{}\r\n\tfor ; itr.Valid(); itr.Next() {\r\n\t\titem := itr.Item()\r\n\t\tif item.IsDeletedOrExpired() {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif !bytes.Equal(key, item.Key()) {\r\n\t\t\t\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tvalCopy, err := item.ValueCopy(nil)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tkv := &pb.KV{\r\n\t\t\tKey:       item.KeyCopy(nil),\r\n\t\t\tValue:     valCopy,\r\n\t\t\tUserMeta:  []byte{item.UserMeta()},\r\n\t\t\tVersion:   item.Version(),\r\n\t\t\tExpiresAt: item.ExpiresAt(),\r\n\t\t}\r\n\t\tlist.Kv = append(list.Kv, kv)\r\n\t\tif st.db.opt.NumVersionsToKeep == 1 {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif item.DiscardEarlierVersions() {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\treturn list, nil\r\n}","code-length":326,"reference":"\/\/ ToList is a default implementation of KeyToList. It picks up all valid versions of the key,\n\/\/ skipping over deleted or expired keys.","result":"Generate the generated code.","score":[0.0022,0.0227]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (st *Stream) produceRanges(ctx context.Context) {\r\n\tsplits := st.db.KeySplits(st.Prefix)\r\n\tstart := y.SafeCopy(nil, st.Prefix)\r\n\tfor _, key := range splits {\r\n\t\tst.rangeCh <- keyRange{left: start, right: y.SafeCopy(nil, []byte(key))}\r\n\t\tstart = y.SafeCopy(nil, []byte(key))\r\n\t}\r\n\t\r\n\t\r\n\tst.rangeCh <- keyRange{left: start}\r\n\tclose(st.rangeCh)\r\n}","code-length":154,"reference":"\/\/ keyRange is [start, end), including start, excluding end. Do ensure that the start,\n\/\/ end byte slices are owned by keyRange struct.","result":"Produce ranges.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (st *Stream) produceKVs(ctx context.Context) error {\r\n\tvar size int\r\n\tvar txn *Txn\r\n\tif st.readTs > 0 {\r\n\t\ttxn = st.db.NewTransactionAt(st.readTs, false)\r\n\t} else {\r\n\t\ttxn = st.db.NewTransaction(false)\r\n\t}\r\n\tdefer txn.Discard()\r\n\titerate := func(kr keyRange) error {\r\n\t\titerOpts := DefaultIteratorOptions\r\n\t\titerOpts.AllVersions = true\r\n\t\titerOpts.Prefix = st.Prefix\r\n\t\titerOpts.PrefetchValues = false\r\n\t\titr := txn.NewIterator(iterOpts)\r\n\t\tdefer itr.Close()\r\n\t\toutList := new(pb.KVList)\r\n\t\tvar prevKey []byte\r\n\t\tfor itr.Seek(kr.left); itr.Valid(); {\r\n\t\t\t\r\n\t\t\titem := itr.Item()\r\n\t\t\tif bytes.Equal(item.Key(), prevKey) {\r\n\t\t\t\titr.Next()\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tprevKey = append(prevKey[:0], item.Key()...)\r\n\t\t\t\r\n\t\t\tif len(kr.right) > 0 && bytes.Compare(item.Key(), kr.right) >= 0 {\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif st.ChooseKey != nil && !st.ChooseKey(item) {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tlist, err := st.KeyToList(item.KeyCopy(nil), itr)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif list == nil || len(list.Kv) == 0 {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\toutList.Kv = append(outList.Kv, list.Kv...)\r\n\t\t\tsize += list.Size()\r\n\t\t\tif size >= pageSize {\r\n\t\t\t\tst.kvChan <- outList\r\n\t\t\t\toutList = new(pb.KVList)\r\n\t\t\t\tsize = 0\r\n\t\t\t}\r\n\t\t}\r\n\t\tif len(outList.Kv) > 0 {\r\n\t\t\tst.kvChan <- outList\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase kr, ok := <-st.rangeCh:\r\n\t\t\tif !ok {\r\n\t\t\t\t\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\tif err := iterate(kr); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\tcase <-ctx.Done():\r\n\t\t\treturn ctx.Err()\r\n\t\t}\r\n\t}\r\n}","code-length":679,"reference":"\/\/ produceKVs picks up ranges from rangeCh, generates KV lists and sends them to kvChan.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (st *Stream) Orchestrate(ctx context.Context) error {\r\n\tst.rangeCh = make(chan keyRange, 3)\r\n\t\r\n\t\r\n\t\r\n\tst.kvChan = make(chan *pb.KVList, 16)\r\n\tif st.KeyToList == nil {\r\n\t\tst.KeyToList = st.ToList\r\n\t}\r\n\t\r\n\tgo st.produceRanges(ctx)\r\n\terrCh := make(chan error, 1)\r\n\tvar wg sync.WaitGroup\r\n\tfor i := 0; i < st.NumGo; i++ {\r\n\t\twg.Add(1)\r\n\t\tgo func() {\r\n\t\t\tdefer wg.Done()\r\n\t\t\t\r\n\t\t\tif err := st.produceKVs(ctx); err != nil {\r\n\t\t\t\tselect {\r\n\t\t\t\tcase errCh <- err:\r\n\t\t\t\tdefault:\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}()\r\n\t}\r\n\t\r\n\tkvErr := make(chan error, 1)\r\n\tgo func() {\r\n\t\t\r\n\t\tkvErr <- st.streamKVs(ctx)\r\n\t}()\r\n\twg.Wait()\r\n\tclose(st.kvChan)\r\n\tselect {\r\n\tcase err := <-errCh:\r\n\t\treturn err\r\n\tdefault:\r\n\t}\r\n\t\r\n\terr := <-kvErr\r\n\treturn err\r\n}","code-length":355,"reference":"\/\/ Orchestrate runs Stream. It picks up ranges from the SSTables, then runs NumGo number of\n\/\/ goroutines to iterate over these ranges and batch up KVs in lists. It concurrently runs a single\n\/\/ goroutine to pick these lists, batch them up further and send to Output.Send. Orchestrate also\n\/\/ spits logs out to Infof, using provided LogPrefix. Note that all calls to Output.Send\n\/\/ are serial. In case any of these steps encounter an error, Orchestrate would stop execution and\n\/\/ return that error. Orchestrate can be called multiple times, but in serial order.","result":"Create a stream .","score":[0.0,0.0058]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) NewStream() *Stream {\r\n\tif db.opt.managedTxns {\r\n\t\tpanic(\"This API can not be called in managed mode.\")\r\n\t}\r\n\treturn db.newStream()\r\n}","code-length":66,"reference":"\/\/ NewStream creates a new Stream.","result":"Create a new stream.","score":[0.274,0.6843]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) NewStreamAt(readTs uint64) *Stream {\r\n\tif !db.opt.managedTxns {\r\n\t\tpanic(\"This API can only be called in managed mode.\")\r\n\t}\r\n\tstream := db.newStream()\r\n\tstream.readTs = readTs\r\n\treturn stream\r\n}","code-length":89,"reference":"\/\/ NewStreamAt creates a new Stream at a particular timestamp. Should only be used with managed DB.","result":"Create a new stream.","score":[0.0175,0.0955]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Table) DecrRef() error {\r\n\tnewRef := atomic.AddInt32(&t.ref, -1)\r\n\tif newRef == 0 {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif t.loadingMode == options.MemoryMap {\r\n\t\t\ty.Munmap(t.mmap)\r\n\t\t}\r\n\t\tif err := t.fd.Truncate(0); err != nil {\r\n\t\t\t\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tfilename := t.fd.Name()\r\n\t\tif err := t.fd.Close(); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif err := os.Remove(filename); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":207,"reference":"\/\/ DecrRef decrements the refcount and possibly deletes the table","result":"Avoid recursive call to the function .","score":[0.1052,0.0515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseFileID(name string) (uint64, bool) {\r\n\tname = path.Base(name)\r\n\tif !strings.HasSuffix(name, fileSuffix) {\r\n\t\treturn 0, false\r\n\t}\r\n\t\r\n\tname = strings.TrimSuffix(name, fileSuffix)\r\n\tid, err := strconv.Atoi(name)\r\n\tif err != nil {\r\n\t\treturn 0, false\r\n\t}\r\n\ty.AssertTrue(id >= 0)\r\n\treturn uint64(id), true\r\n}","code-length":140,"reference":"\/\/ ParseFileID reads the file id out of a filename.","result":"Parse file IDs.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) PrintHistogram(keyPrefix []byte) {\r\n\tif db == nil {\r\n\t\tfmt.Println(\"\\nCannot build histogram: DB is nil.\")\r\n\t\treturn\r\n\t}\r\n\thistogram := db.buildHistogram(keyPrefix)\r\n\tfmt.Printf(\"Histogram of key sizes (in bytes)\\n\")\r\n\thistogram.keySizeHistogram.printHistogram()\r\n\tfmt.Printf(\"Histogram of value sizes (in bytes)\\n\")\r\n\thistogram.valueSizeHistogram.printHistogram()\r\n}","code-length":134,"reference":"\/\/ PrintHistogram builds and displays the key-value size histogram.\n\/\/ When keyPrefix is set, only the keys that have prefix \"keyPrefix\" are\n\/\/ considered for creating the histogram","result":"Print the histogram of key sizes and value sizes.","score":[0.0231,0.1425]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newSizeHistogram() *sizeHistogram {\r\n\t\r\n\tkeyBins := createHistogramBins(1, 16)\r\n\tvalueBins := createHistogramBins(1, 30)\r\n\treturn &sizeHistogram{\r\n\t\tkeySizeHistogram: histogramData{\r\n\t\t\tbins:        keyBins,\r\n\t\t\tcountPerBin: make([]int64, len(keyBins)+1),\r\n\t\t\tmax:         math.MinInt64,\r\n\t\t\tmin:         math.MaxInt64,\r\n\t\t\tsum:         0,\r\n\t\t},\r\n\t\tvalueSizeHistogram: histogramData{\r\n\t\t\tbins:        valueBins,\r\n\t\t\tcountPerBin: make([]int64, len(valueBins)+1),\r\n\t\t\tmax:         math.MinInt64,\r\n\t\t\tmin:         math.MaxInt64,\r\n\t\t\tsum:         0,\r\n\t\t},\r\n\t}\r\n}","code-length":235,"reference":"\/\/ newSizeHistogram returns a new instance of keyValueSizeHistogram with\n\/\/ properly initialized fields.","result":"Create a new size histogram.","score":[0.0686,0.1537]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) buildHistogram(keyPrefix []byte) *sizeHistogram {\r\n\ttxn := db.NewTransaction(false)\r\n\tdefer txn.Discard()\r\n\titr := txn.NewIterator(DefaultIteratorOptions)\r\n\tdefer itr.Close()\r\n\tbadgerHistogram := newSizeHistogram()\r\n\t\r\n\tfor itr.Seek(keyPrefix); itr.ValidForPrefix(keyPrefix); itr.Next() {\r\n\t\titem := itr.Item()\r\n\t\tbadgerHistogram.keySizeHistogram.Update(item.KeySize())\r\n\t\tbadgerHistogram.valueSizeHistogram.Update(item.ValueSize())\r\n\t}\r\n\treturn badgerHistogram\r\n}","code-length":170,"reference":"\/\/ buildHistogram builds the key-value size histogram.\n\/\/ When keyPrefix is set, only the keys that have prefix \"keyPrefix\" are\n\/\/ considered for creating the histogram","result":"Build the size histogram.","score":[0.002,0.1326]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (histogram histogramData) printHistogram() {\r\n\tfmt.Printf(\"Total count: %d\\n\", histogram.totalCount)\r\n\tfmt.Printf(\"Min value: %d\\n\", histogram.min)\r\n\tfmt.Printf(\"Max value: %d\\n\", histogram.max)\r\n\tfmt.Printf(\"Mean: %.2f\\n\", float64(histogram.sum)\/float64(histogram.totalCount))\r\n\tfmt.Printf(\"%24s %9s\\n\", \"Range\", \"Count\")\r\n\tnumBins := len(histogram.bins)\r\n\tfor index, count := range histogram.countPerBin {\r\n\t\tif count == 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif index == len(histogram.countPerBin)-1 {\r\n\t\t\tlowerBound := int(histogram.bins[numBins-1])\r\n\t\t\tfmt.Printf(\"[%10d, %10s) %9d\\n\", lowerBound, \"infinity\", count)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tupperBound := int(histogram.bins[index])\r\n\t\tlowerBound := 0\r\n\t\tif index > 0 {\r\n\t\t\tlowerBound = int(histogram.bins[index-1])\r\n\t\t}\r\n\t\tfmt.Printf(\"[%10d, %10d) %9d\\n\", lowerBound, upperBound, count)\r\n\t}\r\n\tfmt.Println()\r\n}","code-length":357,"reference":"\/\/ printHistogram prints the histogram data in a human-readable format.","result":"Print the histogram data.","score":[0.1008,0.3132]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WaterMark) Init(closer *Closer) {\r\n\tw.markCh = make(chan mark, 100)\r\n\tw.elog = trace.NewEventLog(\"Watermark\", w.Name)\r\n\tgo w.process(closer)\r\n}","code-length":70,"reference":"\/\/ Init initializes a WaterMark struct. MUST be called before using it.","result":"Initialize the water mark.","score":[0,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WaterMark) Begin(index uint64) {\r\n\tatomic.StoreUint64(&w.lastIndex, index)\r\n\tw.markCh <- mark{index: index, done: false}\r\n}","code-length":61,"reference":"\/\/ Begin sets the last index to the given value.","result":"Create the function .","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WaterMark) BeginMany(indices []uint64) {\r\n\tatomic.StoreUint64(&w.lastIndex, indices[len(indices)-1])\r\n\tw.markCh <- mark{index: 0, indices: indices, done: false}\r\n}","code-length":73,"reference":"\/\/ BeginMany works like Begin but accepts multiple indices.","result":"Create the water mark.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WaterMark) Done(index uint64) {\r\n\tw.markCh <- mark{index: index, done: true}\r\n}","code-length":44,"reference":"\/\/ Done sets a single index as done.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WaterMark) DoneMany(indices []uint64) {\r\n\tw.markCh <- mark{index: 0, indices: indices, done: true}\r\n}","code-length":50,"reference":"\/\/ DoneMany works like Done but accepts multiple indices.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WaterMark) SetDoneUntil(val uint64) {\r\n\tatomic.StoreUint64(&w.doneUntil, val)\r\n}","code-length":45,"reference":"\/\/ SetDoneUntil sets the maximum index that has the property that all indices\n\/\/ less than or equal to it are done.","result":"Generate the code.","score":[0.0007,0.0249]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *WaterMark) WaitForMark(ctx context.Context, index uint64) error {\r\n\tif w.DoneUntil() >= index {\r\n\t\treturn nil\r\n\t}\r\n\twaitCh := make(chan struct{})\r\n\tw.markCh <- mark{index: index, waiter: waitCh}\r\n\tselect {\r\n\tcase <-ctx.Done():\r\n\t\treturn ctx.Err()\r\n\tcase <-waitCh:\r\n\t\treturn nil\r\n\t}\r\n}","code-length":127,"reference":"\/\/ WaitForMark waits until the given index is marked as done.","result":"Create a new function to create a new object.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h header) Encode(b []byte) {\r\n\tbinary.BigEndian.PutUint16(b[0:2], h.plen)\r\n\tbinary.BigEndian.PutUint16(b[2:4], h.klen)\r\n\tbinary.BigEndian.PutUint16(b[4:6], h.vlen)\r\n\tbinary.BigEndian.PutUint32(b[6:10], h.prev)\r\n}","code-length":114,"reference":"\/\/ Encode encodes the header.","result":"Encode the header.","score":[0.328,0.5324]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *header) Decode(buf []byte) int {\r\n\th.plen = binary.BigEndian.Uint16(buf[0:2])\r\n\th.klen = binary.BigEndian.Uint16(buf[2:4])\r\n\th.vlen = binary.BigEndian.Uint16(buf[4:6])\r\n\th.prev = binary.BigEndian.Uint32(buf[6:10])\r\n\treturn h.Size()\r\n}","code-length":120,"reference":"\/\/ Decode decodes the header.","result":"Decode the header.","score":[0.328,0.5324]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTableBuilder() *Builder {\r\n\treturn &Builder{\r\n\t\tkeyBuf:     newBuffer(1 << 20),\r\n\t\tbuf:        newBuffer(1 << 20),\r\n\t\tprevOffset: math.MaxUint32,\r\n\t}\r\n}","code-length":73,"reference":"\/\/ NewTableBuilder makes a new TableBuilder.","result":"Create a table builder.","score":[0.1938,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b Builder) keyDiff(newKey []byte) []byte {\r\n\tvar i int\r\n\tfor i = 0; i < len(newKey) && i < len(b.baseKey); i++ {\r\n\t\tif newKey[i] != b.baseKey[i] {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\treturn newKey[i:]\r\n}","code-length":102,"reference":"\/\/ keyDiff returns a suffix of newKey that is different from b.baseKey.","result":"Generate the keyDiff function.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Builder) Add(key []byte, value y.ValueStruct) error {\r\n\tif b.counter >= restartInterval {\r\n\t\tb.finishBlock()\r\n\t\t\r\n\t\tb.restarts = append(b.restarts, uint32(b.buf.Len()))\r\n\t\tb.counter = 0\r\n\t\tb.baseKey = []byte{}\r\n\t\tb.baseOffset = uint32(b.buf.Len())\r\n\t\tb.prevOffset = math.MaxUint32\r\n\t}\r\n\tb.addHelper(key, value)\r\n\treturn nil\r\n}","code-length":155,"reference":"\/\/ Add adds a key-value pair to the block.\n\/\/ If doNotRestart is true, we will not restart even if b.counter >= restartInterval.","result":"Build the builder.","score":[0.0005,0.0238]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Builder) blockIndex() []byte {\r\n\t\r\n\tb.restarts = append(b.restarts, uint32(b.buf.Len()))\r\n\t\r\n\tsz := 4*len(b.restarts) + 4\r\n\tout := make([]byte, sz)\r\n\tbuf := out\r\n\tfor _, r := range b.restarts {\r\n\t\tbinary.BigEndian.PutUint32(buf[:4], r)\r\n\t\tbuf = buf[4:]\r\n\t}\r\n\tbinary.BigEndian.PutUint32(buf[:4], uint32(len(b.restarts)))\r\n\treturn out\r\n}","code-length":167,"reference":"\/\/ blockIndex generates the block index for the table.\n\/\/ It is mainly a list of all the block base offsets.","result":"Build the block index.","score":[0.0064,0.0972]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Builder) Finish() []byte {\r\n\tbf := bbloom.New(float64(b.keyCount), 0.01)\r\n\tvar klen [2]byte\r\n\tkey := make([]byte, 1024)\r\n\tfor {\r\n\t\tif _, err := b.keyBuf.Read(klen[:]); err == io.EOF {\r\n\t\t\tbreak\r\n\t\t} else if err != nil {\r\n\t\t\ty.Check(err)\r\n\t\t}\r\n\t\tkl := int(binary.BigEndian.Uint16(klen[:]))\r\n\t\tif cap(key) < kl {\r\n\t\t\tkey = make([]byte, 2*int(kl))\r\n\t\t}\r\n\t\tkey = key[:kl]\r\n\t\ty.Check2(b.keyBuf.Read(key))\r\n\t\tbf.Add(key)\r\n\t}\r\n\tb.finishBlock()\r\n\tindex := b.blockIndex()\r\n\tb.buf.Write(index)\r\n\t\r\n\tbdata := bf.JSONMarshal()\r\n\tn, err := b.buf.Write(bdata)\r\n\ty.Check(err)\r\n\tvar buf [4]byte\r\n\tbinary.BigEndian.PutUint32(buf[:], uint32(n))\r\n\tb.buf.Write(buf[:])\r\n\treturn b.buf.Bytes()\r\n}","code-length":344,"reference":"\/\/ Finish finishes the table by appending the index.","result":"Build the builder.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (opt *Options) Errorf(format string, v ...interface{}) {\r\n\tif opt.Logger == nil {\r\n\t\treturn\r\n\t}\r\n\topt.Logger.Errorf(format, v...)\r\n}","code-length":61,"reference":"\/\/ Errorf logs an ERROR log message to the logger specified in opts or to the\n\/\/ global logger if no logger is specified in opts.","result":"Print errors to stdout.","score":[0.0013,0.042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (opt *Options) Infof(format string, v ...interface{}) {\r\n\tif opt.Logger == nil {\r\n\t\treturn\r\n\t}\r\n\topt.Logger.Infof(format, v...)\r\n}","code-length":62,"reference":"\/\/ Infof logs an INFO message to the logger specified in opts.","result":"Print the log message.","score":[0.0432,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Skiplist) DecrRef() {\r\n\tnewRef := atomic.AddInt32(&s.ref, -1)\r\n\tif newRef > 0 {\r\n\t\treturn\r\n\t}\r\n\ts.arena.reset()\r\n\t\r\n\t\r\n\ts.arena = nil\r\n}","code-length":88,"reference":"\/\/ DecrRef decrements the refcount, deallocating the Skiplist when done using it","result":"Avoid recursion.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSkiplist(arenaSize int64) *Skiplist {\r\n\tarena := newArena(arenaSize)\r\n\thead := newNode(arena, nil, y.ValueStruct{}, maxHeight)\r\n\treturn &Skiplist{\r\n\t\theight: 1,\r\n\t\thead:   head,\r\n\t\tarena:  arena,\r\n\t\tref:    1,\r\n\t}\r\n}","code-length":114,"reference":"\/\/ NewSkiplist makes a new empty skiplist, with a given arena size","result":"Create a new Skiplist.","score":[0.0611,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Skiplist) Put(key []byte, v y.ValueStruct) {\r\n\t\r\n\t\r\n\tlistHeight := s.getHeight()\r\n\tvar prev [maxHeight + 1]*node\r\n\tvar next [maxHeight + 1]*node\r\n\tprev[listHeight] = s.head\r\n\tnext[listHeight] = nil\r\n\tfor i := int(listHeight) - 1; i >= 0; i-- {\r\n\t\t\r\n\t\tprev[i], next[i] = s.findSpliceForLevel(key, prev[i+1], i)\r\n\t\tif prev[i] == next[i] {\r\n\t\t\tprev[i].setValue(s.arena, v)\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n\t\r\n\theight := randomHeight()\r\n\tx := newNode(s.arena, key, v, height)\r\n\t\r\n\tlistHeight = s.getHeight()\r\n\tfor height > int(listHeight) {\r\n\t\tif atomic.CompareAndSwapInt32(&s.height, listHeight, int32(height)) {\r\n\t\t\t\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tlistHeight = s.getHeight()\r\n\t}\r\n\t\r\n\t\r\n\tfor i := 0; i < height; i++ {\r\n\t\tfor {\r\n\t\t\tif prev[i] == nil {\r\n\t\t\t\ty.AssertTrue(i > 1)\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tprev[i], next[i] = s.findSpliceForLevel(key, s.head, i)\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\ty.AssertTrue(prev[i] != next[i])\r\n\t\t\t}\r\n\t\t\tnextOffset := s.arena.getNodeOffset(next[i])\r\n\t\t\tx.tower[i] = nextOffset\r\n\t\t\tif prev[i].casNextOffset(i, nextOffset, s.arena.getNodeOffset(x)) {\r\n\t\t\t\t\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tprev[i], next[i] = s.findSpliceForLevel(key, prev[i], i)\r\n\t\t\tif prev[i] == next[i] {\r\n\t\t\t\ty.AssertTruef(i == 0, \"Equality can happen only on base level: %d\", i)\r\n\t\t\t\tprev[i].setValue(s.arena, v)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":620,"reference":"\/\/ Put inserts the key-value pair.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Skiplist) Get(key []byte) y.ValueStruct {\r\n\tn, _ := s.findNear(key, false, true)\r\n\tif n == nil {\r\n\t\treturn y.ValueStruct{}\r\n\t}\r\n\tnextKey := s.arena.getKey(n.keyOffset, n.keySize)\r\n\tif !y.SameKey(key, nextKey) {\r\n\t\treturn y.ValueStruct{}\r\n\t}\r\n\tvalOffset, valSize := n.getValueOffset()\r\n\tvs := s.arena.getVal(valOffset, valSize)\r\n\tvs.Version = y.ParseTs(nextKey)\r\n\treturn vs\r\n}","code-length":178,"reference":"\/\/ Get gets the value associated with the key. It returns a valid value if it finds equal or earlier\n\/\/ version of the same key.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Iterator) Key() []byte {\r\n\treturn s.list.arena.getKey(s.n.keyOffset, s.n.keySize)\r\n}","code-length":51,"reference":"\/\/ Key returns the key at the current position.","result":"Get the key of the iterator.","score":[0.1833,0.2937]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Iterator) Value() y.ValueStruct {\r\n\tvalOffset, valSize := s.n.getValueOffset()\r\n\treturn s.list.arena.getVal(valOffset, valSize)\r\n}","code-length":61,"reference":"\/\/ Value returns value.","result":"Get the value of the iterator.","score":[0,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Iterator) Next() {\r\n\ty.AssertTrue(s.Valid())\r\n\ts.n = s.list.getNext(s.n, 0)\r\n}","code-length":53,"reference":"\/\/ Next advances to the next position.","result":"Iterate over the iterator.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Iterator) Prev() {\r\n\ty.AssertTrue(s.Valid())\r\n\ts.n, _ = s.list.findNear(s.Key(), true, false)\r\n}","code-length":57,"reference":"\/\/ Prev advances to the previous position.","result":"Iterate backwards.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Iterator) Seek(target []byte) {\r\n\ts.n, _ = s.list.findNear(target, false, true)\r\n}","code-length":47,"reference":"\/\/ Seek advances to the first entry with a key >= target.","result":"Create a new iterator.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Iterator) SeekForPrev(target []byte) {\r\n\ts.n, _ = s.list.findNear(target, true, true)\r\n}","code-length":49,"reference":"\/\/ SeekForPrev finds an entry with key <= target.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Skiplist) NewUniIterator(reversed bool) *UniIterator {\r\n\treturn &UniIterator{\r\n\t\titer:     s.NewIterator(),\r\n\t\treversed: reversed,\r\n\t}\r\n}","code-length":68,"reference":"\/\/ NewUniIterator returns a UniIterator.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *UniIterator) Next() {\r\n\tif !s.reversed {\r\n\t\ts.iter.Next()\r\n\t} else {\r\n\t\ts.iter.Prev()\r\n\t}\r\n}","code-length":63,"reference":"\/\/ Next implements y.Interface","result":"Avoid recursion.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *UniIterator) Seek(key []byte) {\r\n\tif !s.reversed {\r\n\t\ts.iter.Seek(key)\r\n\t} else {\r\n\t\ts.iter.SeekForPrev(key)\r\n\t}\r\n}","code-length":73,"reference":"\/\/ Seek implements y.Interface","result":"Store the iterator in a map.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Manifest) asChanges() []*pb.ManifestChange {\r\n\tchanges := make([]*pb.ManifestChange, 0, len(m.Tables))\r\n\tfor id, tm := range m.Tables {\r\n\t\tchanges = append(changes, newCreateChange(id, int(tm.Level), tm.Checksum))\r\n\t}\r\n\treturn changes\r\n}","code-length":97,"reference":"\/\/ asChanges returns a sequence of changes that could be used to recreate the Manifest in its\n\/\/ present state.","result":"Create a manifest.","score":[0.0014,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (mf *manifestFile) rewrite() error {\r\n\t\r\n\tif err := mf.fp.Close(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfp, netCreations, err := helpRewrite(mf.directory, &mf.manifest)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tmf.fp = fp\r\n\tmf.manifest.Creations = netCreations\r\n\tmf.manifest.Deletions = 0\r\n\treturn nil\r\n}","code-length":130,"reference":"\/\/ Must be called while appendLock is held.","result":"Rewrite the manifest file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelHandler) validate() error {\r\n\tif s.level == 0 {\r\n\t\treturn nil\r\n\t}\r\n\ts.RLock()\r\n\tdefer s.RUnlock()\r\n\tnumTables := len(s.tables)\r\n\tfor j := 1; j < numTables; j++ {\r\n\t\tif j >= len(s.tables) {\r\n\t\t\treturn errors.Errorf(\"Level %d, j=%d numTables=%d\", s.level, j, numTables)\r\n\t\t}\r\n\t\tif y.CompareKeys(s.tables[j-1].Biggest(), s.tables[j].Smallest()) >= 0 {\r\n\t\t\treturn errors.Errorf(\r\n\t\t\t\t\"Inter: Biggest(j-1) \\n%s\\n vs Smallest(j): \\n%s\\n: level=%d j=%d numTables=%d\",\r\n\t\t\t\thex.Dump(s.tables[j-1].Biggest()), hex.Dump(s.tables[j].Smallest()),\r\n\t\t\t\ts.level, j, numTables)\r\n\t\t}\r\n\t\tif y.CompareKeys(s.tables[j].Smallest(), s.tables[j].Biggest()) > 0 {\r\n\t\t\treturn errors.Errorf(\r\n\t\t\t\t\"Intra: %q vs %q: level=%d j=%d numTables=%d\",\r\n\t\t\t\ts.tables[j].Smallest(), s.tables[j].Biggest(), s.level, j, numTables)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":386,"reference":"\/\/ Check does some sanity check on one level of data or in-memory index.","result":"Validate the tables in the table handler.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc acquireDirectoryLock(dirPath string, pidFileName string, readOnly bool) (*directoryLockGuard, error) {\r\n\tif readOnly {\r\n\t\treturn nil, ErrWindowsNotSupported\r\n\t}\r\n\t\r\n\t\r\n\tabsLockFilePath, err := filepath.Abs(filepath.Join(dirPath, pidFileName))\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Cannot get absolute path for pid lock file\")\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\th, err := syscall.CreateFile(\r\n\t\tsyscall.StringToUTF16Ptr(absLockFilePath), 0, 0, nil,\r\n\t\tsyscall.OPEN_ALWAYS,\r\n\t\tuint32(FILE_ATTRIBUTE_TEMPORARY|FILE_FLAG_DELETE_ON_CLOSE),\r\n\t\t0)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrapf(err,\r\n\t\t\t\"Cannot create lock file %q.  Another process is using this Badger database\",\r\n\t\t\tabsLockFilePath)\r\n\t}\r\n\treturn &directoryLockGuard{h: h, path: absLockFilePath}, nil\r\n}","code-length":293,"reference":"\/\/ AcquireDirectoryLock acquires exclusive access to a directory.","result":"Acquire a directory lock.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *directoryLockGuard) release() error {\r\n\tg.path = \"\"\r\n\treturn syscall.CloseHandle(g.h)\r\n}","code-length":45,"reference":"\/\/ Release removes the directory lock.","result":"Release the lock.","score":[0.1977,0.2632]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AssertTruef(b bool, format string, args ...interface{}) {\r\n\tif !b {\r\n\t\tlog.Fatalf(\"%+v\", errors.Errorf(format, args...))\r\n\t}\r\n}","code-length":61,"reference":"\/\/ AssertTruef is AssertTrue with extra info.","result":"Assert a true value.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Wrapf(err error, format string, args ...interface{}) error {\r\n\tif !debugMode {\r\n\t\tif err == nil {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\treturn fmt.Errorf(format+\" error: %+v\", append(args, err)...)\r\n\t}\r\n\treturn errors.Wrapf(err, format, args...)\r\n}","code-length":99,"reference":"\/\/ Wrapf is Wrap with extra info.","result":"Wrap errors.","score":[0.041,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelHandler) initTables(tables []*table.Table) {\r\n\ts.Lock()\r\n\tdefer s.Unlock()\r\n\ts.tables = tables\r\n\ts.totalSize = 0\r\n\tfor _, t := range tables {\r\n\t\ts.totalSize += t.Size()\r\n\t}\r\n\tif s.level == 0 {\r\n\t\t\r\n\t\t\r\n\t\tsort.Slice(s.tables, func(i, j int) bool {\r\n\t\t\treturn s.tables[i].ID() < s.tables[j].ID()\r\n\t\t})\r\n\t} else {\r\n\t\t\r\n\t\tsort.Slice(s.tables, func(i, j int) bool {\r\n\t\t\treturn y.CompareKeys(s.tables[i].Smallest(), s.tables[j].Smallest()) < 0\r\n\t\t})\r\n\t}\r\n}","code-length":223,"reference":"\/\/ initTables replaces s.tables with given tables. This is done during loading.","result":"Initialize the tables .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelHandler) deleteTables(toDel []*table.Table) error {\r\n\ts.Lock()\r\n\ttoDelMap := make(map[uint64]struct{})\r\n\tfor _, t := range toDel {\r\n\t\ttoDelMap[t.ID()] = struct{}{}\r\n\t}\r\n\t\r\n\tvar newTables []*table.Table\r\n\tfor _, t := range s.tables {\r\n\t\t_, found := toDelMap[t.ID()]\r\n\t\tif !found {\r\n\t\t\tnewTables = append(newTables, t)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\ts.totalSize -= t.Size()\r\n\t}\r\n\ts.tables = newTables\r\n\ts.Unlock()\r\n\treturn decrRefs(toDel)\r\n}","code-length":209,"reference":"\/\/ deleteTables remove tables idx0, ..., idx1-1.","result":"Delete tables.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelHandler) tryAddLevel0Table(t *table.Table) bool {\r\n\ty.AssertTrue(s.level == 0)\r\n\t\r\n\ts.Lock()\r\n\tdefer s.Unlock()\r\n\tif len(s.tables) >= s.db.opt.NumLevelZeroTablesStall {\r\n\t\treturn false\r\n\t}\r\n\ts.tables = append(s.tables, t)\r\n\tt.IncrRef()\r\n\ts.totalSize += t.Size()\r\n\treturn true\r\n}","code-length":140,"reference":"\/\/ tryAddLevel0Table returns true if ok and no stalling.","result":"Add a table to the level .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelHandler) getTableForKey(key []byte) ([]*table.Table, func() error) {\r\n\ts.RLock()\r\n\tdefer s.RUnlock()\r\n\tif s.level == 0 {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tout := make([]*table.Table, 0, len(s.tables))\r\n\t\tfor i := len(s.tables) - 1; i >= 0; i-- {\r\n\t\t\tout = append(out, s.tables[i])\r\n\t\t\ts.tables[i].IncrRef()\r\n\t\t}\r\n\t\treturn out, func() error {\r\n\t\t\tfor _, t := range out {\r\n\t\t\t\tif err := t.DecrRef(); err != nil {\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t}\r\n\t}\r\n\t\r\n\tidx := sort.Search(len(s.tables), func(i int) bool {\r\n\t\treturn y.CompareKeys(s.tables[i].Biggest(), key) >= 0\r\n\t})\r\n\tif idx >= len(s.tables) {\r\n\t\t\r\n\t\treturn nil, func() error { return nil }\r\n\t}\r\n\ttbl := s.tables[idx]\r\n\ttbl.IncrRef()\r\n\treturn []*table.Table{tbl}, tbl.DecrRef\r\n}","code-length":346,"reference":"\/\/ getTableForKey acquires a read-lock to access s.tables. It returns a list of tableHandlers.","result":"Get the table for a given key.","score":[0.0594,0.0752]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelHandler) get(key []byte) (y.ValueStruct, error) {\r\n\ttables, decr := s.getTableForKey(key)\r\n\tkeyNoTs := y.ParseKey(key)\r\n\tvar maxVs y.ValueStruct\r\n\tfor _, th := range tables {\r\n\t\tif th.DoesNotHave(keyNoTs) {\r\n\t\t\ty.NumLSMBloomHits.Add(s.strLevel, 1)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tit := th.NewIterator(false)\r\n\t\tdefer it.Close()\r\n\t\ty.NumLSMGets.Add(s.strLevel, 1)\r\n\t\tit.Seek(key)\r\n\t\tif !it.Valid() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif y.SameKey(key, it.Key()) {\r\n\t\t\tif version := y.ParseTs(it.Key()); maxVs.Version < version {\r\n\t\t\t\tmaxVs = it.Value()\r\n\t\t\t\tmaxVs.Version = version\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn maxVs, decr()\r\n}","code-length":290,"reference":"\/\/ get returns value for a given key or the key after that. If not found, return nil.","result":"Get the value of a key in the table.","score":[0.0634,0.1462]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelHandler) overlappingTables(_ levelHandlerRLocked, kr keyRange) (int, int) {\r\n\tif len(kr.left) == 0 || len(kr.right) == 0 {\r\n\t\treturn 0, 0\r\n\t}\r\n\tleft := sort.Search(len(s.tables), func(i int) bool {\r\n\t\treturn y.CompareKeys(kr.left, s.tables[i].Biggest()) <= 0\r\n\t})\r\n\tright := sort.Search(len(s.tables), func(i int) bool {\r\n\t\treturn y.CompareKeys(kr.right, s.tables[i].Smallest()) < 0\r\n\t})\r\n\treturn left, right\r\n}","code-length":184,"reference":"\/\/ overlappingTables returns the tables that intersect with key range. Returns a half-interval.\n\/\/ This function should already have acquired a read lock, and this is so important the caller must\n\/\/ pass an empty parameter declaring such.","result":"Check if overlapping tables are present in the table tableCache.","score":[0.0079,0.0284]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (item *Item) String() string {\r\n\treturn fmt.Sprintf(\"key=%q, version=%d, meta=%x\", item.Key(), item.Version(), item.meta)\r\n}","code-length":55,"reference":"\/\/ String returns a string representation of Item","result":"Generate the string representation of the item.","score":[0.2884,0.3727]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (item *Item) KeyCopy(dst []byte) []byte {\r\n\treturn y.SafeCopy(dst, item.key)\r\n}","code-length":43,"reference":"\/\/ KeyCopy returns a copy of the key of the item, writing it to dst slice.\n\/\/ If nil is passed, or capacity of dst isn't sufficient, a new slice would be allocated and\n\/\/ returned.","result":"Copy the key.","score":[0.0,0.0306]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (item *Item) ValueSize() int64 {\r\n\tif !item.hasValue() {\r\n\t\treturn 0\r\n\t}\r\n\tif (item.meta & bitValuePointer) == 0 {\r\n\t\treturn int64(len(item.vptr))\r\n\t}\r\n\tvar vp valuePointer\r\n\tvp.Decode(item.vptr)\r\n\tklen := int64(len(item.key) + 8)\r\n\treturn int64(vp.Len) - klen - headerBufSize - crc32.Size\r\n}","code-length":140,"reference":"\/\/ ValueSize returns the exact size of the value.\n\/\/\n\/\/ This can be called to quickly estimate the size of a value without fetching\n\/\/ it.","result":"Calculate the value size.","score":[0.0012,0.0405]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (txn *Txn) NewKeyIterator(key []byte, opt IteratorOptions) *Iterator {\r\n\tif len(opt.Prefix) > 0 {\r\n\t\tpanic(\"opt.Prefix should be nil for NewKeyIterator.\")\r\n\t}\r\n\topt.Prefix = key\r\n\topt.prefixIsKey = true\r\n\treturn txn.NewIterator(opt)\r\n}","code-length":98,"reference":"\/\/ NewKeyIterator is just like NewIterator, but allows the user to iterate over all versions of a\n\/\/ single key. Internally, it sets the Prefix option in provided opt, and uses that prefix to\n\/\/ additionally run bloom filter lookups before picking tables from the LSM tree.","result":"Create a new iterator for the given key.","score":[0.0014,0.0464]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (it *Iterator) Valid() bool {\r\n\tif it.item == nil {\r\n\t\treturn false\r\n\t}\r\n\treturn bytes.HasPrefix(it.item.key, it.opt.Prefix)\r\n}","code-length":63,"reference":"\/\/ Valid returns false when iteration is done.","result":"Validate the iterator.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (it *Iterator) ValidForPrefix(prefix []byte) bool {\r\n\treturn it.Valid() && bytes.HasPrefix(it.item.key, prefix)\r\n}","code-length":50,"reference":"\/\/ ValidForPrefix returns false when iteration is done\n\/\/ or when the current key is not prefixed by the specified prefix.","result":"Validate the iterator.","score":[0.001,0.026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (it *Iterator) Close() {\r\n\tif it.closed {\r\n\t\treturn\r\n\t}\r\n\tit.closed = true\r\n\tit.iitr.Close()\r\n\t\r\n\t\r\n\twaitFor := func(l list) {\r\n\t\titem := l.pop()\r\n\t\tfor item != nil {\r\n\t\t\titem.wg.Wait()\r\n\t\t\titem = l.pop()\r\n\t\t}\r\n\t}\r\n\twaitFor(it.waste)\r\n\twaitFor(it.data)\r\n\t\r\n\t_ = it.txn.db.vlog.decrIteratorCount()\r\n\tatomic.AddInt32(&it.txn.numIterators, -1)\r\n}","code-length":187,"reference":"\/\/ Close would close the iterator. It is important to call this when you're done with iteration.","result":"Close the iterator.","score":[0.006,0.1887]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (it *Iterator) parseItem() bool {\r\n\tmi := it.iitr\r\n\tkey := mi.Key()\r\n\tsetItem := func(item *Item) {\r\n\t\tif it.item == nil {\r\n\t\t\tit.item = item\r\n\t\t} else {\r\n\t\t\tit.data.push(item)\r\n\t\t}\r\n\t}\r\n\t\r\n\tif !it.opt.internalAccess && bytes.HasPrefix(key, badgerPrefix) {\r\n\t\tmi.Next()\r\n\t\treturn false\r\n\t}\r\n\t\r\n\tversion := y.ParseTs(key)\r\n\tif version > it.readTs {\r\n\t\tmi.Next()\r\n\t\treturn false\r\n\t}\r\n\tif it.opt.AllVersions {\r\n\t\t\r\n\t\t\r\n\t\titem := it.newItem()\r\n\t\tit.fill(item)\r\n\t\tsetItem(item)\r\n\t\tmi.Next()\r\n\t\treturn true\r\n\t}\r\n\t\r\n\t\r\n\tif !it.opt.Reverse {\r\n\t\tif y.SameKey(it.lastKey, key) {\r\n\t\t\tmi.Next()\r\n\t\t\treturn false\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tit.lastKey = y.SafeCopy(it.lastKey, mi.Key())\r\n\t}\r\nFILL:\r\n\t\r\n\tvs := mi.Value()\r\n\tif isDeletedOrExpired(vs.Meta, vs.ExpiresAt) {\r\n\t\tmi.Next()\r\n\t\treturn false\r\n\t}\r\n\titem := it.newItem()\r\n\tit.fill(item)\r\n\t\r\n\t\r\n\tmi.Next()\r\n\tif !it.opt.Reverse || !mi.Valid() {\r\n\t\tsetItem(item)\r\n\t\treturn true\r\n\t}\r\n\t\r\n\tnextTs := y.ParseTs(mi.Key())\r\n\tmik := y.ParseKey(mi.Key())\r\n\tif nextTs <= it.readTs && bytes.Equal(mik, item.key) {\r\n\t\t\r\n\t\tgoto FILL\r\n\t}\r\n\t\r\n\tsetItem(item)\r\n\treturn true\r\n}","code-length":561,"reference":"\/\/ parseItem is a complex function because it needs to handle both forward and reverse iteration\n\/\/ implementation. We store keys such that their versions are sorted in descending order. This makes\n\/\/ forward iteration efficient, but revese iteration complicated. This tradeoff is better because\n\/\/ forward iteration is more common than reverse.\n\/\/\n\/\/ This function advances the iterator.","result":"Code too long,keep in 512.","score":[0.0,0.0092]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (it *Iterator) Seek(key []byte) {\r\n\tfor i := it.data.pop(); i != nil; i = it.data.pop() {\r\n\t\ti.wg.Wait()\r\n\t\tit.waste.push(i)\r\n\t}\r\n\tit.lastKey = it.lastKey[:0]\r\n\tif len(key) == 0 {\r\n\t\tkey = it.opt.Prefix\r\n\t}\r\n\tif len(key) == 0 {\r\n\t\tit.iitr.Rewind()\r\n\t\tit.prefetch()\r\n\t\treturn\r\n\t}\r\n\tif !it.opt.Reverse {\r\n\t\tkey = y.KeyWithTs(key, it.txn.readTs)\r\n\t} else {\r\n\t\tkey = y.KeyWithTs(key, 0)\r\n\t}\r\n\tit.iitr.Seek(key)\r\n\tit.prefetch()\r\n}","code-length":239,"reference":"\/\/ Seek would seek to the provided key if present. If absent, it would seek to the next smallest key\n\/\/ greater than the provided key if iterating in the forward direction. Behavior would be reversed if\n\/\/ iterating backwards.","result":"Seek the iterator.","score":[0.0,0.0275]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (db *DB) GetMergeOperator(key []byte,\r\n\tf MergeFunc, dur time.Duration) *MergeOperator {\r\n\top := &MergeOperator{\r\n\t\tf:      f,\r\n\t\tdb:     db,\r\n\t\tkey:    key,\r\n\t\tcloser: y.NewCloser(1),\r\n\t}\r\n\tgo op.runCompactions(dur)\r\n\treturn op\r\n}","code-length":112,"reference":"\/\/ GetMergeOperator creates a new MergeOperator for a given key and returns a\n\/\/ pointer to it. It also fires off a goroutine that performs a compaction using\n\/\/ the merge function that runs periodically, as specified by dur.","result":"Get the merge operator.","score":[0.0001,0.0528]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (op *MergeOperator) Get() ([]byte, error) {\r\n\top.RLock()\r\n\tdefer op.RUnlock()\r\n\tvar existing []byte\r\n\terr := op.db.View(func(txn *Txn) (err error) {\r\n\t\texisting, err = op.iterateAndMerge(txn)\r\n\t\treturn err\r\n\t})\r\n\tif err == errNoMerge {\r\n\t\treturn existing, nil\r\n\t}\r\n\treturn existing, err\r\n}","code-length":129,"reference":"\/\/ Get returns the latest value for the merge operator, which is derived by\n\/\/ applying the merge function to all the values added so far.\n\/\/\n\/\/ If Add has not been called even once, Get will return ErrKeyNotFound.","result":"Get the current value of the current value of the current value.","score":[0.0129,0.0806]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cs *compactStatus) compareAndAdd(_ thisAndNextLevelRLocked, cd compactDef) bool {\r\n\tcs.Lock()\r\n\tdefer cs.Unlock()\r\n\tlevel := cd.thisLevel.level\r\n\ty.AssertTruef(level < len(cs.levels)-1, \"Got level %d. Max levels: %d\", level, len(cs.levels))\r\n\tthisLevel := cs.levels[level]\r\n\tnextLevel := cs.levels[level+1]\r\n\tif thisLevel.overlapsWith(cd.thisRange) {\r\n\t\treturn false\r\n\t}\r\n\tif nextLevel.overlapsWith(cd.nextRange) {\r\n\t\treturn false\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tthisLevel.ranges = append(thisLevel.ranges, cd.thisRange)\r\n\tnextLevel.ranges = append(nextLevel.ranges, cd.nextRange)\r\n\tthisLevel.delSize += cd.thisSize\r\n\treturn true\r\n}","code-length":250,"reference":"\/\/ compareAndAdd will check whether we can run this compactDef. That it doesn't overlap with any\n\/\/ other running compaction. If it can be run, it would store this run in the compactStatus state.","result":"Compare and add compactDef to compactStatus.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newArena(n int64) *Arena {\r\n\t\r\n\t\r\n\tout := &Arena{\r\n\t\tn:   1,\r\n\t\tbuf: make([]byte, n),\r\n\t}\r\n\treturn out\r\n}","code-length":74,"reference":"\/\/ newArena returns a new arena.","result":"Create a new Arena.","score":[0.274,0.5077]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Arena) putNode(height int) uint32 {\r\n\t\r\n\t\r\n\tunusedSize := (maxHeight - height) * offsetSize\r\n\t\r\n\tl := uint32(MaxNodeSize - unusedSize + nodeAlign)\r\n\tn := atomic.AddUint32(&s.n, l)\r\n\ty.AssertTruef(int(n) <= len(s.buf),\r\n\t\t\"Arena too small, toWrite:%d newTotal:%d limit:%d\",\r\n\t\tl, n, len(s.buf))\r\n\t\r\n\tm := (n - l + uint32(nodeAlign)) & ^uint32(nodeAlign)\r\n\treturn m\r\n}","code-length":178,"reference":"\/\/ putNode allocates a node in the arena. The node is aligned on a pointer-sized\n\/\/ boundary. The arena offset of the node is returned.","result":"Store the node in the buffer.","score":[0.0194,0.0866]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Arena) getNode(offset uint32) *node {\r\n\tif offset == 0 {\r\n\t\treturn nil\r\n\t}\r\n\treturn (*node)(unsafe.Pointer(&s.buf[offset]))\r\n}","code-length":67,"reference":"\/\/ getNode returns a pointer to the node located at offset. If the offset is\n\/\/ zero, then the nil node pointer is returned.","result":"Generate the code.","score":[0.0004,0.0228]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Arena) getKey(offset uint32, size uint16) []byte {\r\n\treturn s.buf[offset : offset+uint32(size)]\r\n}","code-length":50,"reference":"\/\/ getKey returns byte slice at offset.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Arena) getVal(offset uint32, size uint16) (ret y.ValueStruct) {\r\n\tret.Decode(s.buf[offset : offset+uint32(size)])\r\n\treturn\r\n}","code-length":64,"reference":"\/\/ getVal returns byte slice at offset. The given size should be just the value\n\/\/ size and should NOT include the meta bytes.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Arena) getNodeOffset(nd *node) uint32 {\r\n\tif nd == nil {\r\n\t\treturn 0\r\n\t}\r\n\treturn uint32(uintptr(unsafe.Pointer(nd)) - uintptr(unsafe.Pointer(&s.buf[0])))\r\n}","code-length":81,"reference":"\/\/ getNodeOffset returns the offset of node in the arena. If the node pointer is\n\/\/ nil, then the zero offset is returned.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc init() {\r\n\tNumReads = expvar.NewInt(\"badger_disk_reads_total\")\r\n\tNumWrites = expvar.NewInt(\"badger_disk_writes_total\")\r\n\tNumBytesRead = expvar.NewInt(\"badger_read_bytes\")\r\n\tNumBytesWritten = expvar.NewInt(\"badger_written_bytes\")\r\n\tNumLSMGets = expvar.NewMap(\"badger_lsm_level_gets_total\")\r\n\tNumLSMBloomHits = expvar.NewMap(\"badger_lsm_bloom_hits_total\")\r\n\tNumGets = expvar.NewInt(\"badger_gets_total\")\r\n\tNumPuts = expvar.NewInt(\"badger_puts_total\")\r\n\tNumBlockedPuts = expvar.NewInt(\"badger_blocked_puts_total\")\r\n\tNumMemtableGets = expvar.NewInt(\"badger_memtable_gets_total\")\r\n\tLSMSize = expvar.NewMap(\"badger_lsm_size_bytes\")\r\n\tVlogSize = expvar.NewMap(\"badger_vlog_size_bytes\")\r\n\tPendingWrites = expvar.NewMap(\"badger_pending_writes_total\")\r\n}","code-length":303,"reference":"\/\/ These variables are global and have cumulative values for all kv stores.","result":"Initialize the module.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc revertToManifest(kv *DB, mf *Manifest, idMap map[uint64]struct{}) error {\r\n\t\r\n\tfor id := range mf.Tables {\r\n\t\tif _, ok := idMap[id]; !ok {\r\n\t\t\treturn fmt.Errorf(\"file does not exist for table %d\", id)\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor id := range idMap {\r\n\t\tif _, ok := mf.Tables[id]; !ok {\r\n\t\t\tkv.elog.Printf(\"Table file %d not referenced in MANIFEST\\n\", id)\r\n\t\t\tfilename := table.NewFilename(id, kv.opt.Dir)\r\n\t\t\tif err := os.Remove(filename); err != nil {\r\n\t\t\t\treturn y.Wrapf(err, \"While removing table %d\", id)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":228,"reference":"\/\/ revertToManifest checks that all necessary table files exist and removes all table files not\n\/\/ referenced by the manifest.  idMap is a set of table file id's that were read from the directory\n\/\/ listing.","result":"Revert the manifest to the database.","score":[0.0015,0.0303]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelsController) dropTree() (int, error) {\r\n\t\r\n\tvar all []*table.Table\r\n\tfor _, l := range s.levels {\r\n\t\tl.RLock()\r\n\t\tall = append(all, l.tables...)\r\n\t\tl.RUnlock()\r\n\t}\r\n\tif len(all) == 0 {\r\n\t\treturn 0, nil\r\n\t}\r\n\t\r\n\tchanges := []*pb.ManifestChange{}\r\n\tfor _, table := range all {\r\n\t\tchanges = append(changes, newDeleteChange(table.ID()))\r\n\t}\r\n\tchangeSet := pb.ManifestChangeSet{Changes: changes}\r\n\tif err := s.kv.manifest.addChanges(changeSet.Changes); err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\t\r\n\tfor _, l := range s.levels {\r\n\t\tl.Lock()\r\n\t\tl.totalSize = 0\r\n\t\tl.tables = l.tables[:0]\r\n\t\tl.Unlock()\r\n\t}\r\n\tfor _, table := range all {\r\n\t\tif err := table.DecrRef(); err != nil {\r\n\t\t\treturn 0, err\r\n\t\t}\r\n\t}\r\n\treturn len(all), nil\r\n}","code-length":327,"reference":"\/\/ dropTree picks all tables from all levels, creates a manifest changeset,\n\/\/ applies it, and then decrements the refs of these tables, which would result\n\/\/ in their deletion.","result":"Drop the tree.","score":[0.0001,0.0183]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelsController) dropPrefix(prefix []byte) error {\r\n\topt := s.kv.opt\r\n\tfor _, l := range s.levels {\r\n\t\tl.RLock()\r\n\t\tif l.level == 0 {\r\n\t\t\tsize := len(l.tables)\r\n\t\t\tl.RUnlock()\r\n\t\t\tif size > 0 {\r\n\t\t\t\tcp := compactionPriority{\r\n\t\t\t\t\tlevel: 0,\r\n\t\t\t\t\tscore: 1.74,\r\n\t\t\t\t\t\r\n\t\t\t\t\t\r\n\t\t\t\t\tdropPrefix: prefix,\r\n\t\t\t\t}\r\n\t\t\t\tif err := s.doCompact(cp); err != nil {\r\n\t\t\t\t\topt.Warningf(\"While compacting level 0: %v\", err)\r\n\t\t\t\t\treturn nil\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvar tables []*table.Table\r\n\t\tfor _, table := range l.tables {\r\n\t\t\tvar absent bool\r\n\t\t\tswitch {\r\n\t\t\tcase bytes.HasPrefix(table.Smallest(), prefix):\r\n\t\t\tcase bytes.HasPrefix(table.Biggest(), prefix):\r\n\t\t\tcase bytes.Compare(prefix, table.Smallest()) > 0 &&\r\n\t\t\t\tbytes.Compare(prefix, table.Biggest()) < 0:\r\n\t\t\tdefault:\r\n\t\t\t\tabsent = true\r\n\t\t\t}\r\n\t\t\tif !absent {\r\n\t\t\t\ttables = append(tables, table)\r\n\t\t\t}\r\n\t\t}\r\n\t\tl.RUnlock()\r\n\t\tif len(tables) == 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tcd := compactDef{\r\n\t\t\telog:       trace.New(fmt.Sprintf(\"Badger.L%d\", l.level), \"Compact\"),\r\n\t\t\tthisLevel:  l,\r\n\t\t\tnextLevel:  l,\r\n\t\t\ttop:        []*table.Table{},\r\n\t\t\tbot:        tables,\r\n\t\t\tdropPrefix: prefix,\r\n\t\t}\r\n\t\tif err := s.runCompactDef(l.level, cd); err != nil {\r\n\t\t\topt.Warningf(\"While running compact def: %+v. Error: %v\", cd, err)\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":569,"reference":"\/\/ dropPrefix runs a L0->L1 compaction, and then runs same level compaction on the rest of the\n\/\/ levels. For L0->L1 compaction, it runs compactions normally, but skips over all the keys with the\n\/\/ provided prefix. For Li->Li compactions, it picks up the tables which would have the prefix. The\n\/\/ tables who only have keys with this prefix are quickly dropped. The ones which have other keys\n\/\/ are run through MergeIterator and compacted to create new tables. All the mechanisms of\n\/\/ compactions apply, i.e. level sizes and MANIFEST are updated as in the normal flow.","result":"Code too long,keep in 512.","score":[0.0,0.0056]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelsController) isLevel0Compactable() bool {\r\n\treturn s.levels[0].numTables() >= s.kv.opt.NumLevelZeroTables\r\n}","code-length":51,"reference":"\/\/ Returns true if level zero may be compacted, without accounting for compactions that already\n\/\/ might be happening.","result":"Check if level .","score":[0.0106,0.1071]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelsController) doCompact(p compactionPriority) error {\r\n\tl := p.level\r\n\ty.AssertTrue(l+1 < s.kv.opt.MaxLevels)\r\n\tcd := compactDef{\r\n\t\telog:       trace.New(fmt.Sprintf(\"Badger.L%d\", l), \"Compact\"),\r\n\t\tthisLevel:  s.levels[l],\r\n\t\tnextLevel:  s.levels[l+1],\r\n\t\tdropPrefix: p.dropPrefix,\r\n\t}\r\n\tcd.elog.SetMaxEvents(100)\r\n\tdefer cd.elog.Finish()\r\n\ts.kv.opt.Infof(\"Got compaction priority: %+v\", p)\r\n\t\r\n\t\r\n\tif l == 0 {\r\n\t\tif !s.fillTablesL0(&cd) {\r\n\t\t\treturn errFillTables\r\n\t\t}\r\n\t} else {\r\n\t\tif !s.fillTables(&cd) {\r\n\t\t\treturn errFillTables\r\n\t\t}\r\n\t}\r\n\tdefer s.cstatus.delete(cd)\r\n\ts.kv.opt.Infof(\"Running for level: %d\\n\", cd.thisLevel.level)\r\n\ts.cstatus.toLog(cd.elog)\r\n\tif err := s.runCompactDef(l, cd); err != nil {\r\n\t\t\r\n\t\ts.kv.opt.Warningf(\"LOG Compact FAILED with error: %+v: %+v\", err, cd)\r\n\t\treturn err\r\n\t}\r\n\ts.cstatus.toLog(cd.elog)\r\n\ts.kv.opt.Infof(\"Compaction for level: %d DONE\", cd.thisLevel.level)\r\n\treturn nil\r\n}","code-length":434,"reference":"\/\/ doCompact picks some table on level l and compacts it away to the next level.","result":"Run compact on the level.","score":[0.035,0.1342]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *levelsController) get(key []byte, maxVs *y.ValueStruct) (y.ValueStruct, error) {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tversion := y.ParseTs(key)\r\n\tfor _, h := range s.levels {\r\n\t\tvs, err := h.get(key)\r\n\t\tif err != nil {\r\n\t\t\treturn y.ValueStruct{}, errors.Wrapf(err, \"get key: %q\", key)\r\n\t\t}\r\n\t\tif vs.Value == nil && vs.Meta == 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif maxVs == nil || vs.Version == version {\r\n\t\t\treturn vs, nil\r\n\t\t}\r\n\t\tif maxVs.Version < vs.Version {\r\n\t\t\t*maxVs = vs\r\n\t\t}\r\n\t}\r\n\tif maxVs != nil {\r\n\t\treturn *maxVs, nil\r\n\t}\r\n\treturn y.ValueStruct{}, nil\r\n}","code-length":259,"reference":"\/\/ get returns the found value if any. If not found, we return nil.","result":"Get the value of a key.","score":[0.0605,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc seekTotal(txn *badger.Txn) ([]account, error) {\r\n\texpected := uint64(numAccounts) * uint64(initialBal)\r\n\tvar accounts []account\r\n\tvar total uint64\r\n\tfor i := 0; i < numAccounts; i++ {\r\n\t\titem, err := txn.Get(key(i))\r\n\t\tif err != nil {\r\n\t\t\tlog.Printf(\"Error for account: %d. err=%v. key=%q\\n\", i, err, key(i))\r\n\t\t\treturn accounts, err\r\n\t\t}\r\n\t\tval, err := item.ValueCopy(nil)\r\n\t\tif err != nil {\r\n\t\t\treturn accounts, err\r\n\t\t}\r\n\t\tacc := account{\r\n\t\t\tId:  i,\r\n\t\t\tBal: toUint64(val),\r\n\t\t}\r\n\t\taccounts = append(accounts, acc)\r\n\t\ttotal += acc.Bal\r\n\t}\r\n\tif total != expected {\r\n\t\tlog.Printf(\"Balance did NOT match up. Expected: %d. Received: %d\",\r\n\t\t\texpected, total)\r\n\t\tatomic.AddInt32(&stopAll, 1)\r\n\t\treturn accounts, errFailure\r\n\t}\r\n\treturn accounts, nil\r\n}","code-length":324,"reference":"\/\/ seekTotal retrives the total of all accounts by seeking for each account key.","result":"Determine the total balance of all accounts.","score":[0.1106,0.282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc findFirstInvalidTxn(db *badger.DB, lowTs, highTs uint64) uint64 {\r\n\tcheckAt := func(ts uint64) error {\r\n\t\ttxn := db.NewTransactionAt(ts, false)\r\n\t\t_, err := seekTotal(txn)\r\n\t\ttxn.Discard()\r\n\t\treturn err\r\n\t}\r\n\tif highTs-lowTs < 1 {\r\n\t\tlog.Printf(\"Checking at lowTs: %d\\n\", lowTs)\r\n\t\terr := checkAt(lowTs)\r\n\t\tif err == errFailure {\r\n\t\t\tfmt.Printf(\"Violation at ts: %d\\n\", lowTs)\r\n\t\t\treturn lowTs\r\n\t\t} else if err != nil {\r\n\t\t\tlog.Printf(\"Error at lowTs: %d. Err=%v\\n\", lowTs, err)\r\n\t\t\treturn 0\r\n\t\t}\r\n\t\tfmt.Printf(\"No violation found at ts: %d\\n\", lowTs)\r\n\t\treturn 0\r\n\t}\r\n\tmidTs := (lowTs + highTs) \/ 2\r\n\tlog.Println()\r\n\tlog.Printf(\"Checking. low=%d. high=%d. mid=%d\\n\", lowTs, highTs, midTs)\r\n\terr := checkAt(midTs)\r\n\tif err == badger.ErrKeyNotFound || err == nil {\r\n\t\t\r\n\t\treturn findFirstInvalidTxn(db, midTs+1, highTs)\r\n\t}\r\n\t\r\n\treturn findFirstInvalidTxn(db, lowTs, midTs)\r\n}","code-length":387,"reference":"\/\/ Range is [lowTs, highTs).","result":"Find the first invalid txn.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *InmemSnapshotStore) Create(version SnapshotVersion, index, term uint64,\r\n\tconfiguration Configuration, configurationIndex uint64, trans Transport) (SnapshotSink, error) {\r\n\t\r\n\tif version != 1 {\r\n\t\treturn nil, fmt.Errorf(\"unsupported snapshot version %d\", version)\r\n\t}\r\n\tname := snapshotName(term, index)\r\n\tm.Lock()\r\n\tdefer m.Unlock()\r\n\tsink := &InmemSnapshotSink{\r\n\t\tmeta: SnapshotMeta{\r\n\t\t\tVersion:            version,\r\n\t\t\tID:                 name,\r\n\t\t\tIndex:              index,\r\n\t\t\tTerm:               term,\r\n\t\t\tPeers:              encodePeers(configuration, trans),\r\n\t\t\tConfiguration:      configuration,\r\n\t\t\tConfigurationIndex: configurationIndex,\r\n\t\t},\r\n\t\tcontents: &bytes.Buffer{},\r\n\t}\r\n\tm.hasSnapshot = true\r\n\tm.latest = sink\r\n\treturn sink, nil\r\n}","code-length":249,"reference":"\/\/ Create replaces the stored snapshot with a new one using the given args","result":"Create a new snapshot.","score":[0.041,0.1966]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *InmemSnapshotStore) List() ([]*SnapshotMeta, error) {\r\n\tm.RLock()\r\n\tdefer m.RUnlock()\r\n\tif !m.hasSnapshot {\r\n\t\treturn []*SnapshotMeta{}, nil\r\n\t}\r\n\treturn []*SnapshotMeta{&m.latest.meta}, nil\r\n}","code-length":91,"reference":"\/\/ List returns the latest snapshot taken","result":"List all snapshots in the store.","score":[0.1943,0.2174]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *InmemSnapshotStore) Open(id string) (*SnapshotMeta, io.ReadCloser, error) {\r\n\tm.RLock()\r\n\tdefer m.RUnlock()\r\n\tif m.latest.meta.ID != id {\r\n\t\treturn nil, nil, fmt.Errorf(\"[ERR] snapshot: failed to open snapshot id: %s\", id)\r\n\t}\r\n\treturn &m.latest.meta, ioutil.NopCloser(m.latest.contents), nil\r\n}","code-length":127,"reference":"\/\/ Open wraps an io.ReadCloser around the snapshot contents","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *InmemSnapshotSink) Write(p []byte) (n int, err error) {\r\n\twritten, err := io.Copy(s.contents, bytes.NewReader(p))\r\n\ts.meta.Size += written\r\n\treturn int(written), err\r\n}","code-length":76,"reference":"\/\/ Write appends the given bytes to the snapshot contents","result":"Write to the snapshot sink.","score":[0.1956,0.3947]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFileSnapshotStoreWithLogger(base string, retain int, logger *log.Logger) (*FileSnapshotStore, error) {\r\n\tif retain < 1 {\r\n\t\treturn nil, fmt.Errorf(\"must retain at least one snapshot\")\r\n\t}\r\n\tif logger == nil {\r\n\t\tlogger = log.New(os.Stderr, \"\", log.LstdFlags)\r\n\t}\r\n\t\r\n\tpath := filepath.Join(base, snapPath)\r\n\tif err := os.MkdirAll(path, 0755); err != nil && !os.IsExist(err) {\r\n\t\treturn nil, fmt.Errorf(\"snapshot path not accessible: %v\", err)\r\n\t}\r\n\t\r\n\tstore := &FileSnapshotStore{\r\n\t\tpath:   path,\r\n\t\tretain: retain,\r\n\t\tlogger: logger,\r\n\t}\r\n\t\r\n\tif err := store.testPermissions(); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"permissions test failed: %v\", err)\r\n\t}\r\n\treturn store, nil\r\n}","code-length":266,"reference":"\/\/ NewFileSnapshotStoreWithLogger creates a new FileSnapshotStore based\n\/\/ on a base directory. The `retain` parameter controls how many\n\/\/ snapshots are retained. Must be at least 1.","result":"Create a new snapshot store with a logger.","score":[0.0202,0.1777]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFileSnapshotStore(base string, retain int, logOutput io.Writer) (*FileSnapshotStore, error) {\r\n\tif logOutput == nil {\r\n\t\tlogOutput = os.Stderr\r\n\t}\r\n\treturn NewFileSnapshotStoreWithLogger(base, retain, log.New(logOutput, \"\", log.LstdFlags))\r\n}","code-length":89,"reference":"\/\/ NewFileSnapshotStore creates a new FileSnapshotStore based\n\/\/ on a base directory. The `retain` parameter controls how many\n\/\/ snapshots are retained. Must be at least 1.","result":"Create a new file snapshot store.","score":[0.0082,0.0803]}
{"code":"\/*is used to<extra_id_0>\r\nfunc snapshotName(term, index uint64) string {\r\n\tnow := time.Now()\r\n\tmsec := now.UnixNano() \/ int64(time.Millisecond)\r\n\treturn fmt.Sprintf(\"%d-%d-%d\", term, index, msec)\r\n}","code-length":76,"reference":"\/\/ snapshotName generates a name for the snapshot.","result":"Generate snapshot names.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FileSnapshotStore) Create(version SnapshotVersion, index, term uint64,\r\n\tconfiguration Configuration, configurationIndex uint64, trans Transport) (SnapshotSink, error) {\r\n\t\r\n\tif version != 1 {\r\n\t\treturn nil, fmt.Errorf(\"unsupported snapshot version %d\", version)\r\n\t}\r\n\t\r\n\tname := snapshotName(term, index)\r\n\tpath := filepath.Join(f.path, name+tmpSuffix)\r\n\tf.logger.Printf(\"[INFO] snapshot: Creating new snapshot at %s\", path)\r\n\t\r\n\tif err := os.MkdirAll(path, 0755); err != nil {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: Failed to make snapshot directory: %v\", err)\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tsink := &FileSnapshotSink{\r\n\t\tstore:     f,\r\n\t\tlogger:    f.logger,\r\n\t\tdir:       path,\r\n\t\tparentDir: f.path,\r\n\t\tmeta: fileSnapshotMeta{\r\n\t\t\tSnapshotMeta: SnapshotMeta{\r\n\t\t\t\tVersion:            version,\r\n\t\t\t\tID:                 name,\r\n\t\t\t\tIndex:              index,\r\n\t\t\t\tTerm:               term,\r\n\t\t\t\tPeers:              encodePeers(configuration, trans),\r\n\t\t\t\tConfiguration:      configuration,\r\n\t\t\t\tConfigurationIndex: configurationIndex,\r\n\t\t\t},\r\n\t\t\tCRC: nil,\r\n\t\t},\r\n\t}\r\n\t\r\n\tif err := sink.writeMeta(); err != nil {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: Failed to write metadata: %v\", err)\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tstatePath := filepath.Join(path, stateFilePath)\r\n\tfh, err := os.Create(statePath)\r\n\tif err != nil {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: Failed to create state file: %v\", err)\r\n\t\treturn nil, err\r\n\t}\r\n\tsink.stateFile = fh\r\n\t\r\n\tsink.stateHash = crc64.New(crc64.MakeTable(crc64.ECMA))\r\n\t\r\n\tmulti := io.MultiWriter(sink.stateFile, sink.stateHash)\r\n\tsink.buffered = bufio.NewWriter(multi)\r\n\t\r\n\treturn sink, nil\r\n}","code-length":585,"reference":"\/\/ Create is used to start a new snapshot","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FileSnapshotStore) List() ([]*SnapshotMeta, error) {\r\n\t\r\n\tsnapshots, err := f.getSnapshots()\r\n\tif err != nil {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: Failed to get snapshots: %v\", err)\r\n\t\treturn nil, err\r\n\t}\r\n\tvar snapMeta []*SnapshotMeta\r\n\tfor _, meta := range snapshots {\r\n\t\tsnapMeta = append(snapMeta, &meta.SnapshotMeta)\r\n\t\tif len(snapMeta) == f.retain {\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\treturn snapMeta, nil\r\n}","code-length":167,"reference":"\/\/ List returns available snapshots in the store.","result":"List all snapshots in a file.","score":[0.2165,0.3276]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FileSnapshotStore) getSnapshots() ([]*fileSnapshotMeta, error) {\r\n\t\r\n\tsnapshots, err := ioutil.ReadDir(f.path)\r\n\tif err != nil {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: Failed to scan snapshot dir: %v\", err)\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tvar snapMeta []*fileSnapshotMeta\r\n\tfor _, snap := range snapshots {\r\n\t\t\r\n\t\tif !snap.IsDir() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tdirName := snap.Name()\r\n\t\tif strings.HasSuffix(dirName, tmpSuffix) {\r\n\t\t\tf.logger.Printf(\"[WARN] snapshot: Found temporary snapshot: %v\", dirName)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tmeta, err := f.readMeta(dirName)\r\n\t\tif err != nil {\r\n\t\t\tf.logger.Printf(\"[WARN] snapshot: Failed to read metadata for %v: %v\", dirName, err)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tif meta.Version < SnapshotVersionMin || meta.Version > SnapshotVersionMax {\r\n\t\t\tf.logger.Printf(\"[WARN] snapshot: Snapshot version for %v not supported: %d\", dirName, meta.Version)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tsnapMeta = append(snapMeta, meta)\r\n\t}\r\n\t\r\n\tsort.Sort(sort.Reverse(snapMetaSlice(snapMeta)))\r\n\treturn snapMeta, nil\r\n}","code-length":397,"reference":"\/\/ getSnapshots returns all the known snapshots.","result":"Store snapshot metadata.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FileSnapshotStore) readMeta(name string) (*fileSnapshotMeta, error) {\r\n\t\r\n\tmetaPath := filepath.Join(f.path, name, metaFilePath)\r\n\tfh, err := os.Open(metaPath)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer fh.Close()\r\n\t\r\n\tbuffered := bufio.NewReader(fh)\r\n\t\r\n\tmeta := &fileSnapshotMeta{}\r\n\tdec := json.NewDecoder(buffered)\r\n\tif err := dec.Decode(meta); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn meta, nil\r\n}","code-length":174,"reference":"\/\/ readMeta is used to read the meta data for a given named backup","result":"Read the meta file.","score":[0.0371,0.2265]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FileSnapshotStore) Open(id string) (*SnapshotMeta, io.ReadCloser, error) {\r\n\t\r\n\tmeta, err := f.readMeta(id)\r\n\tif err != nil {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: Failed to get meta data to open snapshot: %v\", err)\r\n\t\treturn nil, nil, err\r\n\t}\r\n\t\r\n\tstatePath := filepath.Join(f.path, id, stateFilePath)\r\n\tfh, err := os.Open(statePath)\r\n\tif err != nil {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: Failed to open state file: %v\", err)\r\n\t\treturn nil, nil, err\r\n\t}\r\n\t\r\n\tstateHash := crc64.New(crc64.MakeTable(crc64.ECMA))\r\n\t\r\n\t_, err = io.Copy(stateHash, fh)\r\n\tif err != nil {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: Failed to read state file: %v\", err)\r\n\t\tfh.Close()\r\n\t\treturn nil, nil, err\r\n\t}\r\n\t\r\n\tcomputed := stateHash.Sum(nil)\r\n\tif bytes.Compare(meta.CRC, computed) != 0 {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: CRC checksum failed (stored: %v computed: %v)\",\r\n\t\t\tmeta.CRC, computed)\r\n\t\tfh.Close()\r\n\t\treturn nil, nil, fmt.Errorf(\"CRC mismatch\")\r\n\t}\r\n\t\r\n\tif _, err := fh.Seek(0, 0); err != nil {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: State file seek failed: %v\", err)\r\n\t\tfh.Close()\r\n\t\treturn nil, nil, err\r\n\t}\r\n\t\r\n\tbuffered := &bufferedFile{\r\n\t\tbh: bufio.NewReader(fh),\r\n\t\tfh: fh,\r\n\t}\r\n\treturn &meta.SnapshotMeta, buffered, nil\r\n}","code-length":511,"reference":"\/\/ Open takes a snapshot ID and returns a ReadCloser for that snapshot.","result":"Open the file.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FileSnapshotStore) ReapSnapshots() error {\r\n\tsnapshots, err := f.getSnapshots()\r\n\tif err != nil {\r\n\t\tf.logger.Printf(\"[ERR] snapshot: Failed to get snapshots: %v\", err)\r\n\t\treturn err\r\n\t}\r\n\tfor i := f.retain; i < len(snapshots); i++ {\r\n\t\tpath := filepath.Join(f.path, snapshots[i].ID)\r\n\t\tf.logger.Printf(\"[INFO] snapshot: reaping snapshot %v\", path)\r\n\t\tif err := os.RemoveAll(path); err != nil {\r\n\t\t\tf.logger.Printf(\"[ERR] snapshot: Failed to reap snapshot %v: %v\", path, err)\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":212,"reference":"\/\/ ReapSnapshots reaps any snapshots beyond the retain count.","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *FileSnapshotSink) Write(b []byte) (int, error) {\r\n\treturn s.buffered.Write(b)\r\n}","code-length":44,"reference":"\/\/ Write is used to append to the state file. We write to the\n\/\/ buffered IO object to reduce the amount of context switches.","result":"Generate the generated code.","score":[0.0017,0.0218]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *FileSnapshotSink) Close() error {\r\n\t\r\n\tif s.closed {\r\n\t\treturn nil\r\n\t}\r\n\ts.closed = true\r\n\t\r\n\tif err := s.finalize(); err != nil {\r\n\t\ts.logger.Printf(\"[ERR] snapshot: Failed to finalize snapshot: %v\", err)\r\n\t\tif delErr := os.RemoveAll(s.dir); delErr != nil {\r\n\t\t\ts.logger.Printf(\"[ERR] snapshot: Failed to delete temporary snapshot directory at path %v: %v\", s.dir, delErr)\r\n\t\t\treturn delErr\r\n\t\t}\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif err := s.writeMeta(); err != nil {\r\n\t\ts.logger.Printf(\"[ERR] snapshot: Failed to write metadata: %v\", err)\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tnewPath := strings.TrimSuffix(s.dir, tmpSuffix)\r\n\tif err := os.Rename(s.dir, newPath); err != nil {\r\n\t\ts.logger.Printf(\"[ERR] snapshot: Failed to move snapshot into place: %v\", err)\r\n\t\treturn err\r\n\t}\r\n\tif runtime.GOOS != \"windows\" {\r\n\t\tparentFH, err := os.Open(s.parentDir)\r\n\t\tdefer parentFH.Close()\r\n\t\tif err != nil {\r\n\t\t\ts.logger.Printf(\"[ERR] snapshot: Failed to open snapshot parent directory %v, error: %v\", s.parentDir, err)\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif err = parentFH.Sync(); err != nil {\r\n\t\t\ts.logger.Printf(\"[ERR] snapshot: Failed syncing parent directory %v, error: %v\", s.parentDir, err)\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\t\r\n\tif err := s.store.ReapSnapshots(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":508,"reference":"\/\/ Close is used to indicate a successful end.","result":"Close the sink.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *FileSnapshotSink) Cancel() error {\r\n\t\r\n\tif s.closed {\r\n\t\treturn nil\r\n\t}\r\n\ts.closed = true\r\n\t\r\n\tif err := s.finalize(); err != nil {\r\n\t\ts.logger.Printf(\"[ERR] snapshot: Failed to finalize snapshot: %v\", err)\r\n\t\treturn err\r\n\t}\r\n\t\r\n\treturn os.RemoveAll(s.dir)\r\n}","code-length":121,"reference":"\/\/ Cancel is used to indicate an unsuccessful end.","result":"Cancel the snapshot.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *FileSnapshotSink) finalize() error {\r\n\t\r\n\tif err := s.buffered.Flush(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif err := s.stateFile.Sync(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tstat, statErr := s.stateFile.Stat()\r\n\t\r\n\tif err := s.stateFile.Close(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif statErr != nil {\r\n\t\treturn statErr\r\n\t}\r\n\ts.meta.Size = stat.Size()\r\n\t\r\n\ts.meta.CRC = s.stateHash.Sum(nil)\r\n\treturn nil\r\n}","code-length":193,"reference":"\/\/ finalize is used to close all of our resources.","result":"Finalize the snapshot sink.","score":[0,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *FileSnapshotSink) writeMeta() error {\r\n\t\r\n\tmetaPath := filepath.Join(s.dir, metaFilePath)\r\n\tfh, err := os.Create(metaPath)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer fh.Close()\r\n\t\r\n\tbuffered := bufio.NewWriter(fh)\r\n\t\r\n\tenc := json.NewEncoder(buffered)\r\n\tif err := enc.Encode(&s.meta); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err = buffered.Flush(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err = fh.Sync(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":197,"reference":"\/\/ writeMeta is used to write out the metadata we have.","result":"Generate the generated code.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewNetworkTransportWithConfig(\r\n\tconfig *NetworkTransportConfig,\r\n) *NetworkTransport {\r\n\tif config.Logger == nil {\r\n\t\tconfig.Logger = log.New(os.Stderr, \"\", log.LstdFlags)\r\n\t}\r\n\ttrans := &NetworkTransport{\r\n\t\tconnPool:              make(map[ServerAddress][]*netConn),\r\n\t\tconsumeCh:             make(chan RPC),\r\n\t\tlogger:                config.Logger,\r\n\t\tmaxPool:               config.MaxPool,\r\n\t\tshutdownCh:            make(chan struct{}),\r\n\t\tstream:                config.Stream,\r\n\t\ttimeout:               config.Timeout,\r\n\t\tTimeoutScale:          DefaultTimeoutScale,\r\n\t\tserverAddressProvider: config.ServerAddressProvider,\r\n\t}\r\n\t\r\n\ttrans.setupStreamContext()\r\n\tgo trans.listen()\r\n\treturn trans\r\n}","code-length":228,"reference":"\/\/ NewNetworkTransportWithConfig creates a new network transport with the given config struct","result":"Create a new network transport.","score":[0.122,0.3512]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) setupStreamContext() {\r\n\tctx, cancel := context.WithCancel(context.Background())\r\n\tn.streamCtx = ctx\r\n\tn.streamCancel = cancel\r\n}","code-length":58,"reference":"\/\/ setupStreamContext is used to create a new stream context. This should be\n\/\/ called with the stream lock held.","result":"Setup the stream context.","score":[0.0101,0.1389]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) getStreamContext() context.Context {\r\n\tn.streamCtxLock.RLock()\r\n\tdefer n.streamCtxLock.RUnlock()\r\n\treturn n.streamCtx\r\n}","code-length":59,"reference":"\/\/ getStreamContext is used retrieve the current stream context.","result":"Create the stream context.","score":[0.1433,0.3007]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) SetHeartbeatHandler(cb func(rpc RPC)) {\r\n\tn.heartbeatFnLock.Lock()\r\n\tdefer n.heartbeatFnLock.Unlock()\r\n\tn.heartbeatFn = cb\r\n}","code-length":62,"reference":"\/\/ SetHeartbeatHandler is used to setup a heartbeat handler\n\/\/ as a fast-pass. This is to avoid head-of-line blocking from\n\/\/ disk IO.","result":"Set the heartbeat handler.","score":[0.0028,0.0237]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) CloseStreams() {\r\n\tn.connPoolLock.Lock()\r\n\tdefer n.connPoolLock.Unlock()\r\n\t\r\n\t\r\n\tfor k, e := range n.connPool {\r\n\t\tfor _, conn := range e {\r\n\t\t\tconn.Release()\r\n\t\t}\r\n\t\tdelete(n.connPool, k)\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tn.streamCtxLock.Lock()\r\n\tn.streamCancel()\r\n\tn.setupStreamContext()\r\n\tn.streamCtxLock.Unlock()\r\n}","code-length":159,"reference":"\/\/ CloseStreams closes the current streams.","result":"Close all streams in the network transport.","score":[0.1615,0.2459]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) Close() error {\r\n\tn.shutdownLock.Lock()\r\n\tdefer n.shutdownLock.Unlock()\r\n\tif !n.shutdown {\r\n\t\tclose(n.shutdownCh)\r\n\t\tn.stream.Close()\r\n\t\tn.shutdown = true\r\n\t}\r\n\treturn nil\r\n}","code-length":92,"reference":"\/\/ Close is used to stop the network transport.","result":"Close the transport.","score":[0.0727,0.1786]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) getPooledConn(target ServerAddress) *netConn {\r\n\tn.connPoolLock.Lock()\r\n\tdefer n.connPoolLock.Unlock()\r\n\tconns, ok := n.connPool[target]\r\n\tif !ok || len(conns) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\tvar conn *netConn\r\n\tnum := len(conns)\r\n\tconn, conns[num-1] = conns[num-1], nil\r\n\tn.connPool[target] = conns[:num-1]\r\n\treturn conn\r\n}","code-length":153,"reference":"\/\/ getExistingConn is used to grab a pooled connection.","result":"Get a connection from the pool.","score":[0.1171,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) getConnFromAddressProvider(id ServerID, target ServerAddress) (*netConn, error) {\r\n\taddress := n.getProviderAddressOrFallback(id, target)\r\n\treturn n.getConn(address)\r\n}","code-length":69,"reference":"\/\/ getConnFromAddressProvider returns a connection from the server address provider if available, or defaults to a connection using the target server address","result":"Generate code for the generated code.","score":[0.0134,0.0245]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) getConn(target ServerAddress) (*netConn, error) {\r\n\t\r\n\tif conn := n.getPooledConn(target); conn != nil {\r\n\t\treturn conn, nil\r\n\t}\r\n\t\r\n\tconn, err := n.stream.Dial(target, n.timeout)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tnetConn := &netConn{\r\n\t\ttarget: target,\r\n\t\tconn:   conn,\r\n\t\tr:      bufio.NewReader(conn),\r\n\t\tw:      bufio.NewWriter(conn),\r\n\t}\r\n\t\r\n\tnetConn.dec = codec.NewDecoder(netConn.r, &codec.MsgpackHandle{})\r\n\tnetConn.enc = codec.NewEncoder(netConn.w, &codec.MsgpackHandle{})\r\n\t\r\n\treturn netConn, nil\r\n}","code-length":238,"reference":"\/\/ getConn is used to get a connection from the pool.","result":"Get a connection from the pool.","score":[0.3492,0.5701]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) returnConn(conn *netConn) {\r\n\tn.connPoolLock.Lock()\r\n\tdefer n.connPoolLock.Unlock()\r\n\tkey := conn.target\r\n\tconns, _ := n.connPool[key]\r\n\tif !n.IsShutdown() && len(conns) < n.maxPool {\r\n\t\tn.connPool[key] = append(conns, conn)\r\n\t} else {\r\n\t\tconn.Release()\r\n\t}\r\n}","code-length":133,"reference":"\/\/ returnConn returns a connection back to the pool.","result":"Return the connection to the pool.","score":[0.2592,0.5126]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) listen() {\r\n\tconst baseDelay = 5 * time.Millisecond\r\n\tconst maxDelay = 1 * time.Second\r\n\tvar loopDelay time.Duration\r\n\tfor {\r\n\t\t\r\n\t\tconn, err := n.stream.Accept()\r\n\t\tif err != nil {\r\n\t\t\tif loopDelay == 0 {\r\n\t\t\t\tloopDelay = baseDelay\r\n\t\t\t} else {\r\n\t\t\t\tloopDelay *= 2\r\n\t\t\t}\r\n\t\t\tif loopDelay > maxDelay {\r\n\t\t\t\tloopDelay = maxDelay\r\n\t\t\t}\r\n\t\t\tif !n.IsShutdown() {\r\n\t\t\t\tn.logger.Printf(\"[ERR] raft-net: Failed to accept connection: %v\", err)\r\n\t\t\t}\r\n\t\t\tselect {\r\n\t\t\tcase <-n.shutdownCh:\r\n\t\t\t\treturn\r\n\t\t\tcase <-time.After(loopDelay):\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tloopDelay = 0\r\n\t\tn.logger.Printf(\"[DEBUG] raft-net: %v accepted connection from: %v\", n.LocalAddr(), conn.RemoteAddr())\r\n\t\t\r\n\t\tgo n.handleConn(n.getStreamContext(), conn)\r\n\t}\r\n}","code-length":318,"reference":"\/\/ listen is used to handling incoming connections.","result":"Listen for incoming connections.","score":[0.1662,0.3363]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) handleConn(connCtx context.Context, conn net.Conn) {\r\n\tdefer conn.Close()\r\n\tr := bufio.NewReader(conn)\r\n\tw := bufio.NewWriter(conn)\r\n\tdec := codec.NewDecoder(r, &codec.MsgpackHandle{})\r\n\tenc := codec.NewEncoder(w, &codec.MsgpackHandle{})\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase <-connCtx.Done():\r\n\t\t\tn.logger.Println(\"[DEBUG] raft-net: stream layer is closed\")\r\n\t\t\treturn\r\n\t\tdefault:\r\n\t\t}\r\n\t\tif err := n.handleCommand(r, dec, enc); err != nil {\r\n\t\t\tif err != io.EOF {\r\n\t\t\t\tn.logger.Printf(\"[ERR] raft-net: Failed to decode incoming command: %v\", err)\r\n\t\t\t}\r\n\t\t\treturn\r\n\t\t}\r\n\t\tif err := w.Flush(); err != nil {\r\n\t\t\tn.logger.Printf(\"[ERR] raft-net: Failed to flush response: %v\", err)\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":299,"reference":"\/\/ handleConn is used to handle an inbound connection for its lifespan. The\n\/\/ handler will exit when the passed context is cancelled or the connection is\n\/\/ closed.","result":"Handle the connection.","score":[0.0001,0.0379]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *NetworkTransport) handleCommand(r *bufio.Reader, dec *codec.Decoder, enc *codec.Encoder) error {\r\n\t\r\n\trpcType, err := r.ReadByte()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\trespCh := make(chan RPCResponse, 1)\r\n\trpc := RPC{\r\n\t\tRespChan: respCh,\r\n\t}\r\n\t\r\n\tisHeartbeat := false\r\n\tswitch rpcType {\r\n\tcase rpcAppendEntries:\r\n\t\tvar req AppendEntriesRequest\r\n\t\tif err := dec.Decode(&req); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\trpc.Command = &req\r\n\t\t\r\n\t\tif req.Term != 0 && req.Leader != nil &&\r\n\t\t\treq.PrevLogEntry == 0 && req.PrevLogTerm == 0 &&\r\n\t\t\tlen(req.Entries) == 0 && req.LeaderCommitIndex == 0 {\r\n\t\t\tisHeartbeat = true\r\n\t\t}\r\n\tcase rpcRequestVote:\r\n\t\tvar req RequestVoteRequest\r\n\t\tif err := dec.Decode(&req); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\trpc.Command = &req\r\n\tcase rpcInstallSnapshot:\r\n\t\tvar req InstallSnapshotRequest\r\n\t\tif err := dec.Decode(&req); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\trpc.Command = &req\r\n\t\trpc.Reader = io.LimitReader(r, req.Size)\r\n\tdefault:\r\n\t\treturn fmt.Errorf(\"unknown rpc type %d\", rpcType)\r\n\t}\r\n\t\r\n\tif isHeartbeat {\r\n\t\tn.heartbeatFnLock.Lock()\r\n\t\tfn := n.heartbeatFn\r\n\t\tn.heartbeatFnLock.Unlock()\r\n\t\tif fn != nil {\r\n\t\t\tfn(rpc)\r\n\t\t\tgoto RESP\r\n\t\t}\r\n\t}\r\n\t\r\n\tselect {\r\n\tcase n.consumeCh <- rpc:\r\n\tcase <-n.shutdownCh:\r\n\t\treturn ErrTransportShutdown\r\n\t}\r\n\t\r\nRESP:\r\n\tselect {\r\n\tcase resp := <-respCh:\r\n\t\t\r\n\t\trespErr := \"\"\r\n\t\tif resp.Error != nil {\r\n\t\t\trespErr = resp.Error.Error()\r\n\t\t}\r\n\t\tif err := enc.Encode(respErr); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\tif err := enc.Encode(resp.Response); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\tcase <-n.shutdownCh:\r\n\t\treturn ErrTransportShutdown\r\n\t}\r\n\treturn nil\r\n}","code-length":689,"reference":"\/\/ handleCommand is used to decode and dispatch a single command.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc decodeResponse(conn *netConn, resp interface{}) (bool, error) {\r\n\t\r\n\tvar rpcError string\r\n\tif err := conn.dec.Decode(&rpcError); err != nil {\r\n\t\tconn.Release()\r\n\t\treturn false, err\r\n\t}\r\n\t\r\n\tif err := conn.dec.Decode(resp); err != nil {\r\n\t\tconn.Release()\r\n\t\treturn false, err\r\n\t}\r\n\t\r\n\tif rpcError != \"\" {\r\n\t\treturn true, fmt.Errorf(rpcError)\r\n\t}\r\n\treturn true, nil\r\n}","code-length":159,"reference":"\/\/ decodeResponse is used to decode an RPC response and reports whether\n\/\/ the connection can be reused.","result":"Decode response from RPC server.","score":[0.0212,0.0898]}
{"code":"\/*is used to<extra_id_0>\r\nfunc sendRPC(conn *netConn, rpcType uint8, args interface{}) error {\r\n\t\r\n\tif err := conn.w.WriteByte(rpcType); err != nil {\r\n\t\tconn.Release()\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif err := conn.enc.Encode(args); err != nil {\r\n\t\tconn.Release()\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif err := conn.w.Flush(); err != nil {\r\n\t\tconn.Release()\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":154,"reference":"\/\/ sendRPC is used to encode and send the RPC.","result":"Send RPCs to the network.","score":[0.1051,0.1579]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newNetPipeline(trans *NetworkTransport, conn *netConn) *netPipeline {\r\n\tn := &netPipeline{\r\n\t\tconn:         conn,\r\n\t\ttrans:        trans,\r\n\t\tdoneCh:       make(chan AppendFuture, rpcMaxPipeline),\r\n\t\tinprogressCh: make(chan *appendFuture, rpcMaxPipeline),\r\n\t\tshutdownCh:   make(chan struct{}),\r\n\t}\r\n\tgo n.decodeResponses()\r\n\treturn n\r\n}","code-length":127,"reference":"\/\/ newNetPipeline is used to construct a netPipeline from a given\n\/\/ transport and connection.","result":"Create a new NetPipeline .","score":[0.0325,0.0714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *netPipeline) decodeResponses() {\r\n\ttimeout := n.trans.timeout\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase future := <-n.inprogressCh:\r\n\t\t\tif timeout > 0 {\r\n\t\t\t\tn.conn.conn.SetReadDeadline(time.Now().Add(timeout))\r\n\t\t\t}\r\n\t\t\t_, err := decodeResponse(n.conn, future.resp)\r\n\t\t\tfuture.respond(err)\r\n\t\t\tselect {\r\n\t\t\tcase n.doneCh <- future:\r\n\t\t\tcase <-n.shutdownCh:\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\tcase <-n.shutdownCh:\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":187,"reference":"\/\/ decodeResponses is a long running routine that decodes the responses\n\/\/ sent on the connection.","result":"Decode responses.","score":[0,0.0342]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *netPipeline) AppendEntries(args *AppendEntriesRequest, resp *AppendEntriesResponse) (AppendFuture, error) {\r\n\t\r\n\tfuture := &appendFuture{\r\n\t\tstart: time.Now(),\r\n\t\targs:  args,\r\n\t\tresp:  resp,\r\n\t}\r\n\tfuture.init()\r\n\t\r\n\tif timeout := n.trans.timeout; timeout > 0 {\r\n\t\tn.conn.conn.SetWriteDeadline(time.Now().Add(timeout))\r\n\t}\r\n\t\r\n\tif err := sendRPC(n.conn, rpcAppendEntries, future.args); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\t\r\n\tselect {\r\n\tcase n.inprogressCh <- future:\r\n\t\treturn future, nil\r\n\tcase <-n.shutdownCh:\r\n\t\treturn nil, ErrPipelineShutdown\r\n\t}\r\n}","code-length":232,"reference":"\/\/ AppendEntries is used to pipeline a new append entries request.","result":"Avoid the need for the following code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *netPipeline) Close() error {\r\n\tn.shutdownLock.Lock()\r\n\tdefer n.shutdownLock.Unlock()\r\n\tif n.shutdown {\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\tn.conn.Release()\r\n\tn.shutdown = true\r\n\tclose(n.shutdownCh)\r\n\treturn nil\r\n}","code-length":97,"reference":"\/\/ Closed is used to shutdown the pipeline connection.","result":"Close the netPipeline.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewObserver(channel chan Observation, blocking bool, filter FilterFn) *Observer {\r\n\treturn &Observer{\r\n\t\tchannel:  channel,\r\n\t\tblocking: blocking,\r\n\t\tfilter:   filter,\r\n\t\tid:       atomic.AddUint64(&nextObserverID, 1),\r\n\t}\r\n}","code-length":88,"reference":"\/\/ NewObserver creates a new observer that can be registered\n\/\/ to make observations on a Raft instance. Observations\n\/\/ will be sent on the given channel if they satisfy the\n\/\/ given filter.\n\/\/\n\/\/ If blocking is true, the observer will block when it can't\n\/\/ send on the channel, otherwise it may discard events.","result":"Create a new observer.","score":[0.0,0.029]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) RegisterObserver(or *Observer) {\r\n\tr.observersLock.Lock()\r\n\tdefer r.observersLock.Unlock()\r\n\tr.observers[or.id] = or\r\n}","code-length":64,"reference":"\/\/ RegisterObserver registers a new observer.","result":"Register the observer.","score":[0.1502,0.1754]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) DeregisterObserver(or *Observer) {\r\n\tr.observersLock.Lock()\r\n\tdefer r.observersLock.Unlock()\r\n\tdelete(r.observers, or.id)\r\n}","code-length":64,"reference":"\/\/ DeregisterObserver deregisters an observer.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) observe(o interface{}) {\r\n\t\r\n\t\r\n\t\r\n\tr.observersLock.RLock()\r\n\tdefer r.observersLock.RUnlock()\r\n\tfor _, or := range r.observers {\r\n\t\t\r\n\t\t\r\n\t\tob := Observation{Raft: r, Data: o}\r\n\t\tif or.filter != nil && !or.filter(&ob) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif or.channel == nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif or.blocking {\r\n\t\t\tor.channel <- ob\r\n\t\t\tatomic.AddUint64(&or.numObserved, 1)\r\n\t\t} else {\r\n\t\t\tselect {\r\n\t\t\tcase or.channel <- ob:\r\n\t\t\t\tatomic.AddUint64(&or.numObserved, 1)\r\n\t\t\tdefault:\r\n\t\t\t\tatomic.AddUint64(&or.numDropped, 1)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":267,"reference":"\/\/ observe sends an observation to every observer.","result":"Observe a single object.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewInmemStore() *InmemStore {\r\n\ti := &InmemStore{\r\n\t\tlogs:  make(map[uint64]*Log),\r\n\t\tkv:    make(map[string][]byte),\r\n\t\tkvInt: make(map[string]uint64),\r\n\t}\r\n\treturn i\r\n}","code-length":90,"reference":"\/\/ NewInmemStore returns a new in-memory backend. Do not ever\n\/\/ use for production. Only for testing.","result":"Create a new InmemStore.","score":[0.0175,0.1194]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemStore) FirstIndex() (uint64, error) {\r\n\ti.l.RLock()\r\n\tdefer i.l.RUnlock()\r\n\treturn i.lowIndex, nil\r\n}","code-length":61,"reference":"\/\/ FirstIndex implements the LogStore interface.","result":"Generate the code.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemStore) LastIndex() (uint64, error) {\r\n\ti.l.RLock()\r\n\tdefer i.l.RUnlock()\r\n\treturn i.highIndex, nil\r\n}","code-length":60,"reference":"\/\/ LastIndex implements the LogStore interface.","result":"Store the index in the store.","score":[0.193,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemStore) GetLog(index uint64, log *Log) error {\r\n\ti.l.RLock()\r\n\tdefer i.l.RUnlock()\r\n\tl, ok := i.logs[index]\r\n\tif !ok {\r\n\t\treturn ErrLogNotFound\r\n\t}\r\n\t*log = *l\r\n\treturn nil\r\n}","code-length":99,"reference":"\/\/ GetLog implements the LogStore interface.","result":"Store the log in the inmem store.","score":[0.1615,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemStore) StoreLog(log *Log) error {\r\n\treturn i.StoreLogs([]*Log{log})\r\n}","code-length":43,"reference":"\/\/ StoreLog implements the LogStore interface.","result":"Generate the code.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemStore) StoreLogs(logs []*Log) error {\r\n\ti.l.Lock()\r\n\tdefer i.l.Unlock()\r\n\tfor _, l := range logs {\r\n\t\ti.logs[l.Index] = l\r\n\t\tif i.lowIndex == 0 {\r\n\t\t\ti.lowIndex = l.Index\r\n\t\t}\r\n\t\tif l.Index > i.highIndex {\r\n\t\t\ti.highIndex = l.Index\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":143,"reference":"\/\/ StoreLogs implements the LogStore interface.","result":"Store logs in memory.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemStore) DeleteRange(min, max uint64) error {\r\n\ti.l.Lock()\r\n\tdefer i.l.Unlock()\r\n\tfor j := min; j <= max; j++ {\r\n\t\tdelete(i.logs, j)\r\n\t}\r\n\tif min <= i.lowIndex {\r\n\t\ti.lowIndex = max + 1\r\n\t}\r\n\tif max >= i.highIndex {\r\n\t\ti.highIndex = min - 1\r\n\t}\r\n\tif i.lowIndex > i.highIndex {\r\n\t\ti.lowIndex = 0\r\n\t\ti.highIndex = 0\r\n\t}\r\n\treturn nil\r\n}","code-length":178,"reference":"\/\/ DeleteRange implements the LogStore interface.","result":"Delete log entries.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemStore) Set(key []byte, val []byte) error {\r\n\ti.l.Lock()\r\n\tdefer i.l.Unlock()\r\n\ti.kv[string(key)] = val\r\n\treturn nil\r\n}","code-length":69,"reference":"\/\/ Set implements the StableStore interface.","result":"Set the value of a key in the store.","score":[0.1449,0.1587]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemStore) Get(key []byte) ([]byte, error) {\r\n\ti.l.RLock()\r\n\tdefer i.l.RUnlock()\r\n\tval := i.kv[string(key)]\r\n\tif val == nil {\r\n\t\treturn nil, errors.New(\"not found\")\r\n\t}\r\n\treturn val, nil\r\n}","code-length":100,"reference":"\/\/ Get implements the StableStore interface.","result":"Store the value in the store.","score":[0.193,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemStore) SetUint64(key []byte, val uint64) error {\r\n\ti.l.Lock()\r\n\tdefer i.l.Unlock()\r\n\ti.kvInt[string(key)] = val\r\n\treturn nil\r\n}","code-length":72,"reference":"\/\/ SetUint64 implements the StableStore interface.","result":"Store the data in memory.","score":[0.1967,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemStore) GetUint64(key []byte) (uint64, error) {\r\n\ti.l.RLock()\r\n\tdefer i.l.RUnlock()\r\n\treturn i.kvInt[string(key)], nil\r\n}","code-length":71,"reference":"\/\/ GetUint64 implements the StableStore interface.","result":"Store the data in memory.","score":[0.1967,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewLogCache(capacity int, store LogStore) (*LogCache, error) {\r\n\tif capacity <= 0 {\r\n\t\treturn nil, fmt.Errorf(\"capacity must be positive\")\r\n\t}\r\n\tc := &LogCache{\r\n\t\tstore: store,\r\n\t\tcache: make([]*Log, capacity),\r\n\t}\r\n\treturn c, nil\r\n}","code-length":101,"reference":"\/\/ NewLogCache is used to create a new LogCache with the\n\/\/ given capacity and backend store.","result":"Create a new log cache.","score":[0.0308,0.1864]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemTransport) Connect(peer ServerAddress, t Transport) {\r\n\ttrans := t.(*InmemTransport)\r\n\ti.Lock()\r\n\tdefer i.Unlock()\r\n\ti.peers[peer] = trans\r\n}","code-length":68,"reference":"\/\/ Connect is used to connect this transport to another transport for\n\/\/ a given peer name. This allows for local routing.","result":"Connect to peers.","score":[0.0009,0.0498]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemTransport) Disconnect(peer ServerAddress) {\r\n\ti.Lock()\r\n\tdefer i.Unlock()\r\n\tdelete(i.peers, peer)\r\n\t\r\n\tn := len(i.pipelines)\r\n\tfor idx := 0; idx < n; idx++ {\r\n\t\tif i.pipelines[idx].peerAddr == peer {\r\n\t\t\ti.pipelines[idx].Close()\r\n\t\t\ti.pipelines[idx], i.pipelines[n-1] = i.pipelines[n-1], nil\r\n\t\t\tidx--\r\n\t\t\tn--\r\n\t\t}\r\n\t}\r\n\ti.pipelines = i.pipelines[:n]\r\n}","code-length":180,"reference":"\/\/ Disconnect is used to remove the ability to route to a given peer.","result":"Disconnect from a peer.","score":[0.0345,0.1154]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InmemTransport) DisconnectAll() {\r\n\ti.Lock()\r\n\tdefer i.Unlock()\r\n\ti.peers = make(map[ServerAddress]*InmemTransport)\r\n\t\r\n\tfor _, pipeline := range i.pipelines {\r\n\t\tpipeline.Close()\r\n\t}\r\n\ti.pipelines = nil\r\n}","code-length":95,"reference":"\/\/ DisconnectAll is used to remove all routes to peers.","result":"Disconnect all peers.","score":[0.0471,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *RPC) Respond(resp interface{}, err error) {\r\n\tr.RespChan <- RPCResponse{resp, err}\r\n}","code-length":43,"reference":"\/\/ Respond is used to respond with a response, error or both","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *userSnapshotFuture) Open() (*SnapshotMeta, io.ReadCloser, error) {\r\n\tif u.opener == nil {\r\n\t\treturn nil, nil, fmt.Errorf(\"no snapshot available\")\r\n\t} else {\r\n\t\t\r\n\t\t\r\n\t\tdefer func() {\r\n\t\t\tu.opener = nil\r\n\t\t}()\r\n\t\treturn u.opener()\r\n\t}\r\n}","code-length":110,"reference":"\/\/ Open is a function you can call to access the underlying snapshot and its\n\/\/ metadata.","result":"Open the snapshot.","score":[0.0046,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v *verifyFuture) vote(leader bool) {\r\n\tv.voteLock.Lock()\r\n\tdefer v.voteLock.Unlock()\r\n\t\r\n\tif v.notifyCh == nil {\r\n\t\treturn\r\n\t}\r\n\tif leader {\r\n\t\tv.votes++\r\n\t\tif v.votes >= v.quorumSize {\r\n\t\t\tv.notifyCh <- v\r\n\t\t\tv.notifyCh = nil\r\n\t\t}\r\n\t} else {\r\n\t\tv.notifyCh <- v\r\n\t\tv.notifyCh = nil\r\n\t}\r\n}","code-length":153,"reference":"\/\/ vote is used to respond to a verifyFuture.\n\/\/ This may block when responding on the notifyCh.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *followerReplication) notifyAll(leader bool) {\r\n\t\r\n\ts.notifyLock.Lock()\r\n\tn := s.notify\r\n\ts.notify = make(map[*verifyFuture]struct{})\r\n\ts.notifyLock.Unlock()\r\n\t\r\n\tfor v, _ := range n {\r\n\t\tv.vote(leader)\r\n\t}\r\n}","code-length":104,"reference":"\/\/ notifyAll is used to notify all the waiting verify futures\n\/\/ if the follower believes we are still the leader.","result":"Notify all the followers.","score":[0.0064,0.1324]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *followerReplication) cleanNotify(v *verifyFuture) {\r\n\ts.notifyLock.Lock()\r\n\tdelete(s.notify, v)\r\n\ts.notifyLock.Unlock()\r\n}","code-length":60,"reference":"\/\/ cleanNotify is used to delete notify, .","result":"Clean up the following code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *followerReplication) LastContact() time.Time {\r\n\ts.lastContactLock.RLock()\r\n\tlast := s.lastContact\r\n\ts.lastContactLock.RUnlock()\r\n\treturn last\r\n}","code-length":65,"reference":"\/\/ LastContact returns the time of last contact.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *followerReplication) setLastContact() {\r\n\ts.lastContactLock.Lock()\r\n\ts.lastContact = time.Now()\r\n\ts.lastContactLock.Unlock()\r\n}","code-length":58,"reference":"\/\/ setLastContact sets the last contact to the current time.","result":"Set the lastContact time.","score":[0.0848,0.1596]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) replicate(s *followerReplication) {\r\n\t\r\n\tstopHeartbeat := make(chan struct{})\r\n\tdefer close(stopHeartbeat)\r\n\tr.goFunc(func() { r.heartbeat(s, stopHeartbeat) })\r\nRPC:\r\n\tshouldStop := false\r\n\tfor !shouldStop {\r\n\t\tselect {\r\n\t\tcase maxIndex := <-s.stopCh:\r\n\t\t\t\r\n\t\t\tif maxIndex > 0 {\r\n\t\t\t\tr.replicateTo(s, maxIndex)\r\n\t\t\t}\r\n\t\t\treturn\r\n\t\tcase <-s.triggerCh:\r\n\t\t\tlastLogIdx, _ := r.getLastLog()\r\n\t\t\tshouldStop = r.replicateTo(s, lastLogIdx)\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tmeout):\r\n\t\t\tlastLogIdx, _ := r.getLastLog()\r\n\t\t\tshouldStop = r.replicateTo(s, lastLogIdx)\r\n\t\t}\r\n\t\t\r\n\t\tif !shouldStop && s.allowPipeline {\r\n\t\t\tgoto PIPELINE\r\n\t\t}\r\n\t}\r\n\treturn\r\nPIPELINE:\r\n\t\r\n\ts.allowPipeline = false\r\n\t\r\n\t\r\n\t\r\n\tif err := r.pipelineReplicate(s); err != nil {\r\n\t\tif err != ErrPipelineReplicationNotSupported {\r\n\t\t\tr.logger.Error(fmt.Sprintf(\"Failed to start pipeline replication to %s: %s\", s.peer, err))\r\n\t\t}\r\n\t}\r\n\tgoto RPC\r\n}","code-length":399,"reference":"\/\/ replicate is a long running routine that replicates log entries to a single\n\/\/ follower.","result":"Replicate to a follower.","score":[0.0249,0.2133]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) pipelineReplicate(s *followerReplication) error {\r\n\t\r\n\tpipeline, err := r.trans.AppendEntriesPipeline(s.peer.ID, s.peer.Address)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer pipeline.Close()\r\n\t\r\n\tr.logger.Info(fmt.Sprintf(\"pipelining replication to peer %v\", s.peer))\r\n\tdefer r.logger.Info(fmt.Sprintf(\"aborting pipeline replication to peer %v\", s.peer))\r\n\t\r\n\tstopCh := make(chan struct{})\r\n\tfinishCh := make(chan struct{})\r\n\t\r\n\tr.goFunc(func() { r.pipelineDecode(s, pipeline, stopCh, finishCh) })\r\n\t\r\n\tnextIndex := s.nextIndex\r\n\tshouldStop := false\r\nSEND:\r\n\tfor !shouldStop {\r\n\t\tselect {\r\n\t\tcase <-finishCh:\r\n\t\t\tbreak SEND\r\n\t\tcase maxIndex := <-s.stopCh:\r\n\t\t\t\r\n\t\t\tif maxIndex > 0 {\r\n\t\t\t\tr.pipelineSend(s, pipeline, &nextIndex, maxIndex)\r\n\t\t\t}\r\n\t\t\tbreak SEND\r\n\t\tcase <-s.triggerCh:\r\n\t\t\tlastLogIdx, _ := r.getLastLog()\r\n\t\t\tshouldStop = r.pipelineSend(s, pipeline, &nextIndex, lastLogIdx)\r\n\t\tcase <-randomTimeout(r.conf.CommitTimeout):\r\n\t\t\tlastLogIdx, _ := r.getLastLog()\r\n\t\t\tshouldStop = r.pipelineSend(s, pipeline, &nextIndex, lastLogIdx)\r\n\t\t}\r\n\t}\r\n\t\r\n\tclose(stopCh)\r\n\tselect {\r\n\tcase <-finishCh:\r\n\tcase <-r.shutdownCh:\r\n\t}\r\n\treturn nil\r\n}","code-length":470,"reference":"\/\/ pipelineReplicate is used when we have synchronized our state with the follower,\n\/\/ and want to switch to a higher performance pipeline mode of replication.\n\/\/ We only pipeline AppendEntries commands, and if we ever hit an error, we fall\n\/\/ back to the standard replication which can handle more complex situations.","result":"Replicate the follower replication.","score":[0.0,0.0312]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) pipelineSend(s *followerReplication, p AppendPipeline, nextIdx *uint64, lastIndex uint64) (shouldStop bool) {\r\n\t\r\n\treq := new(AppendEntriesRequest)\r\n\tif err := r.setupAppendEntries(s, req, *nextIdx, lastIndex); err != nil {\r\n\t\treturn true\r\n\t}\r\n\t\r\n\tif _, err := p.AppendEntries(req, new(AppendEntriesResponse)); err != nil {\r\n\t\tr.logger.Error(fmt.Sprintf(\"Failed to pipeline AppendEntries to %v: %v\", s.peer, err))\r\n\t\treturn true\r\n\t}\r\n\t\r\n\tif n := len(req.Entries); n > 0 {\r\n\t\tlast := req.Entries[n-1]\r\n\t\t*nextIdx = last.Index + 1\r\n\t}\r\n\treturn false\r\n}","code-length":224,"reference":"\/\/ pipelineSend is used to send data over a pipeline. It is a helper to\n\/\/ pipelineReplicate.","result":"Send the request to the Raft server.","score":[0.0387,0.0625]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) pipelineDecode(s *followerReplication, p AppendPipeline, stopCh, finishCh chan struct{}) {\r\n\tdefer close(finishCh)\r\n\trespCh := p.Consumer()\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase ready := <-respCh:\r\n\t\t\treq, resp := ready.Request(), ready.Response()\r\n\t\t\tappendStats(string(s.peer.ID), ready.Start(), float32(len(req.Entries)))\r\n\t\t\t\r\n\t\t\tif resp.Term > req.Term {\r\n\t\t\t\tr.handleStaleTerm(s)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\ts.setLastContact()\r\n\t\t\t\r\n\t\t\tif !resp.Success {\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tupdateLastAppended(s, req)\r\n\t\tcase <-stopCh:\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":239,"reference":"\/\/ pipelineDecode is used to decode the responses of pipelined requests.","result":"Detect if the file contains a comment.","score":[0.0912,0.0472]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) setupAppendEntries(s *followerReplication, req *AppendEntriesRequest, nextIndex, lastIndex uint64) error {\r\n\treq.RPCHeader = r.getRPCHeader()\r\n\treq.Term = s.currentTerm\r\n\treq.Leader = r.trans.EncodePeer(r.localID, r.localAddr)\r\n\treq.LeaderCommitIndex = r.getCommitIndex()\r\n\tif err := r.setPreviousLog(req, nextIndex); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := r.setNewLogs(req, nextIndex, lastIndex); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":174,"reference":"\/\/ setupAppendEntries is used to setup an append entries request.","result":"Setup the append entries request.","score":[0.1821,0.3947]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) setPreviousLog(req *AppendEntriesRequest, nextIndex uint64) error {\r\n\t\r\n\t\r\n\tlastSnapIdx, lastSnapTerm := r.getLastSnapshot()\r\n\tif nextIndex == 1 {\r\n\t\treq.PrevLogEntry = 0\r\n\t\treq.PrevLogTerm = 0\r\n\t} else if (nextIndex - 1) == lastSnapIdx {\r\n\t\treq.PrevLogEntry = lastSnapIdx\r\n\t\treq.PrevLogTerm = lastSnapTerm\r\n\t} else {\r\n\t\tvar l Log\r\n\t\tif err := r.logs.GetLog(nextIndex-1, &l); err != nil {\r\n\t\t\tr.logger.Error(fmt.Sprintf(\"Failed to get log at index %d: %v\", nextIndex-1, err))\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\treq.PrevLogEntry = l.Index\r\n\t\treq.PrevLogTerm = l.Term\r\n\t}\r\n\treturn nil\r\n}","code-length":249,"reference":"\/\/ setPreviousLog is used to setup the PrevLogEntry and PrevLogTerm for an\n\/\/ AppendEntriesRequest given the next index to replicate.","result":"Set the previous log index.","score":[0.012,0.027]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) setNewLogs(req *AppendEntriesRequest, nextIndex, lastIndex uint64) error {\r\n\t\r\n\treq.Entries = make([]*Log, 0, r.conf.MaxAppendEntries)\r\n\tmaxIndex := min(nextIndex+uint64(r.conf.MaxAppendEntries)-1, lastIndex)\r\n\tfor i := nextIndex; i <= maxIndex; i++ {\r\n\t\toldLog := new(Log)\r\n\t\tif err := r.logs.GetLog(i, oldLog); err != nil {\r\n\t\t\tr.logger.Error(fmt.Sprintf(\"Failed to get log at index %d: %v\", i, err))\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treq.Entries = append(req.Entries, oldLog)\r\n\t}\r\n\treturn nil\r\n}","code-length":204,"reference":"\/\/ setNewLogs is used to setup the logs which should be appended for a request.","result":"Set the log index.","score":[0.0204,0.1349]}
{"code":"\/*is used to<extra_id_0>\r\nfunc appendStats(peer string, start time.Time, logs float32) {\r\n\tmetrics.MeasureSince([]string{\"raft\", \"replication\", \"appendEntries\", \"rpc\", peer}, start)\r\n\tmetrics.IncrCounter([]string{\"raft\", \"replication\", \"appendEntries\", \"logs\", peer}, logs)\r\n}","code-length":84,"reference":"\/\/ appendStats is used to emit stats about an AppendEntries invocation.","result":"Collect raft stats.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) handleStaleTerm(s *followerReplication) {\r\n\tr.logger.Error(fmt.Sprintf(\"peer %v has newer term, stopping replication\", s.peer))\r\n\ts.notifyAll(false)\r\n\tasyncNotifyCh(s.stepDown)\r\n}","code-length":80,"reference":"\/\/ handleStaleTerm is used when a follower indicates that we have a stale term.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *transport) AppendEntries(id raft.ServerID, target raft.ServerAddress, args *raft.AppendEntriesRequest, resp *raft.AppendEntriesResponse) error {\r\n\tae := appendEntries{\r\n\t\tsource:      t.node,\r\n\t\ttarget:      target,\r\n\t\tfirstIndex:  firstIndex(args),\r\n\t\tlastIndex:   lastIndex(args),\r\n\t\tcommitIndex: args.LeaderCommitIndex,\r\n\t}\r\n\tif len(t.ae) < cap(t.ae) {\r\n\t\tt.ae = append(t.ae, ae)\r\n\t}\r\n\treturn t.sendRPC(string(target), args, resp)\r\n}","code-length":176,"reference":"\/\/ AppendEntries sends the appropriate RPC to the target node.","result":"Transport AppendEntries RPCs.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *transport) RequestVote(id raft.ServerID, target raft.ServerAddress, args *raft.RequestVoteRequest, resp *raft.RequestVoteResponse) error {\r\n\treturn t.sendRPC(string(target), args, resp)\r\n}","code-length":68,"reference":"\/\/ RequestVote sends the appropriate RPC to the target node.","result":"RequestVoteRequest.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *transport) InstallSnapshot(id raft.ServerID, target raft.ServerAddress, args *raft.InstallSnapshotRequest, resp *raft.InstallSnapshotResponse, data io.Reader) error {\r\n\tt.log.Printf(\"INSTALL SNAPSHOT *************************************\")\r\n\treturn errors.New(\"huh\")\r\n}","code-length":82,"reference":"\/\/ InstallSnapshot is used to push a snapshot down to a follower. The data is read from\n\/\/ the ReadCloser and streamed to the client.","result":"Create a new snapshot.","score":[0.0017,0.0218]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *transport) EncodePeer(id raft.ServerID, p raft.ServerAddress) []byte {\r\n\treturn []byte(p)\r\n}","code-length":45,"reference":"\/\/ EncodePeer is used to serialize a peer name.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *transport) DecodePeer(p []byte) raft.ServerAddress {\r\n\treturn raft.ServerAddress(p)\r\n}","code-length":41,"reference":"\/\/ DecodePeer is used to deserialize a peer name.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *pipeline) AppendEntries(args *raft.AppendEntriesRequest, resp *raft.AppendEntriesResponse) (raft.AppendFuture, error) {\r\n\te := &appendEntry{\r\n\t\treq:      args,\r\n\t\tres:      resp,\r\n\t\tstart:    time.Now(),\r\n\t\tready:    make(chan error),\r\n\t\tconsumer: p.consumer,\r\n\t}\r\n\tp.work <- e\r\n\treturn e, nil\r\n}","code-length":125,"reference":"\/\/ AppendEntries is used to add another request to the pipeline.\n\/\/ The send may block which is an effective form of back-pressure.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReadPeersJSON(path string) (Configuration, error) {\r\n\t\r\n\tbuf, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\treturn Configuration{}, err\r\n\t}\r\n\t\r\n\tvar peers []string\r\n\tdec := json.NewDecoder(bytes.NewReader(buf))\r\n\tif err := dec.Decode(&peers); err != nil {\r\n\t\treturn Configuration{}, err\r\n\t}\r\n\t\r\n\t\r\n\tvar configuration Configuration\r\n\tfor _, peer := range peers {\r\n\t\tserver := Server{\r\n\t\t\tSuffrage: Voter,\r\n\t\t\tID:       ServerID(peer),\r\n\t\t\tAddress:  ServerAddress(peer),\r\n\t\t}\r\n\t\tconfiguration.Servers = append(configuration.Servers, server)\r\n\t}\r\n\t\r\n\tif err := checkConfiguration(configuration); err != nil {\r\n\t\treturn Configuration{}, err\r\n\t}\r\n\treturn configuration, nil\r\n}","code-length":251,"reference":"\/\/ ReadPeersJSON consumes a legacy peers.json file in the format of the old JSON\n\/\/ peer store and creates a new-style configuration structure. This can be used\n\/\/ to migrate this data or perform manual recovery when running protocol versions\n\/\/ that can interoperate with older, unversioned Raft servers. This should not be\n\/\/ used once server IDs are in use, because the old peers.json file didn't have\n\/\/ support for these, nor non-voter suffrage types.","result":"Read peers from a JSON file.","score":[0.0,0.0217]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReadConfigJSON(path string) (Configuration, error) {\r\n\t\r\n\tbuf, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\treturn Configuration{}, err\r\n\t}\r\n\t\r\n\tvar peers []configEntry\r\n\tdec := json.NewDecoder(bytes.NewReader(buf))\r\n\tif err := dec.Decode(&peers); err != nil {\r\n\t\treturn Configuration{}, err\r\n\t}\r\n\t\r\n\tvar configuration Configuration\r\n\tfor _, peer := range peers {\r\n\t\tsuffrage := Voter\r\n\t\tif peer.NonVoter {\r\n\t\t\tsuffrage = Nonvoter\r\n\t\t}\r\n\t\tserver := Server{\r\n\t\t\tSuffrage: suffrage,\r\n\t\t\tID:       peer.ID,\r\n\t\t\tAddress:  peer.Address,\r\n\t\t}\r\n\t\tconfiguration.Servers = append(configuration.Servers, server)\r\n\t}\r\n\t\r\n\tif err := checkConfiguration(configuration); err != nil {\r\n\t\treturn Configuration{}, err\r\n\t}\r\n\treturn configuration, nil\r\n}","code-length":288,"reference":"\/\/ ReadConfigJSON reads a new-style peers.json and returns a configuration\n\/\/ structure. This can be used to perform manual recovery when running protocol\n\/\/ versions that use server IDs.","result":"Read the config file.","score":[0,0.0189]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTCPTransport(\r\n\tbindAddr string,\r\n\tadvertise net.Addr,\r\n\tmaxPool int,\r\n\ttimeout time.Duration,\r\n\tlogOutput io.Writer,\r\n) (*NetworkTransport, error) {\r\n\treturn newTCPTransport(bindAddr, advertise, func(stream StreamLayer) *NetworkTransport {\r\n\t\treturn NewNetworkTransport(stream, maxPool, timeout, logOutput)\r\n\t})\r\n}","code-length":114,"reference":"\/\/ NewTCPTransport returns a NetworkTransport that is built on top of\n\/\/ a TCP streaming transport layer.","result":"Create a new TCP transport.","score":[0.0259,0.0633]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTCPTransportWithLogger(\r\n\tbindAddr string,\r\n\tadvertise net.Addr,\r\n\tmaxPool int,\r\n\ttimeout time.Duration,\r\n\tlogger *log.Logger,\r\n) (*NetworkTransport, error) {\r\n\treturn newTCPTransport(bindAddr, advertise, func(stream StreamLayer) *NetworkTransport {\r\n\t\treturn NewNetworkTransportWithLogger(stream, maxPool, timeout, logger)\r\n\t})\r\n}","code-length":117,"reference":"\/\/ NewTCPTransportWithLogger returns a NetworkTransport that is built on top of\n\/\/ a TCP streaming transport layer, with log output going to the supplied Logger","result":"Create a new TCP transport with a logger.","score":[0.0248,0.1073]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTCPTransportWithConfig(\r\n\tbindAddr string,\r\n\tadvertise net.Addr,\r\n\tconfig *NetworkTransportConfig,\r\n) (*NetworkTransport, error) {\r\n\treturn newTCPTransport(bindAddr, advertise, func(stream StreamLayer) *NetworkTransport {\r\n\t\tconfig.Stream = stream\r\n\t\treturn NewNetworkTransportWithConfig(config)\r\n\t})\r\n}","code-length":104,"reference":"\/\/ NewTCPTransportWithConfig returns a NetworkTransport that is built on top of\n\/\/ a TCP streaming transport layer, using the given config struct.","result":"Create a new TCP transport.","score":[0.0095,0.0493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *TCPStreamLayer) Dial(address ServerAddress, timeout time.Duration) (net.Conn, error) {\r\n\treturn net.DialTimeout(\"tcp\", string(address), timeout)\r\n}","code-length":56,"reference":"\/\/ Dial implements the StreamLayer interface.","result":"Create the stream layer.","score":[0.1938,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *TCPStreamLayer) Accept() (c net.Conn, err error) {\r\n\treturn t.listener.Accept()\r\n}","code-length":42,"reference":"\/\/ Accept implements the net.Listener interface.","result":"Generate the code.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *TCPStreamLayer) Addr() net.Addr {\r\n\t\r\n\tif t.advertise != nil {\r\n\t\treturn t.advertise\r\n\t}\r\n\treturn t.listener.Addr()\r\n}","code-length":63,"reference":"\/\/ Addr implements the net.Listener interface.","result":"Get the address of the layer.","score":[0.193,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) restoreSnapshot() error {\r\n\tsnapshots, err := r.snapshots.List()\r\n\tif err != nil {\r\n\t\tr.logger.Error(fmt.Sprintf(\"Failed to list snapshots: %v\", err))\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tfor _, snapshot := range snapshots {\r\n\t\t_, source, err := r.snapshots.Open(snapshot.ID)\r\n\t\tif err != nil {\r\n\t\t\tr.logger.Error(fmt.Sprintf(\"Failed to open snapshot %v: %v\", snapshot.ID, err))\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tdefer source.Close()\r\n\t\tif err := r.fsm.Restore(source); err != nil {\r\n\t\t\tr.logger.Error(fmt.Sprintf(\"Failed to restore snapshot %v: %v\", snapshot.ID, err))\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tr.logger.Info(fmt.Sprintf(\"Restored from snapshot %v\", snapshot.ID))\r\n\t\t\r\n\t\tr.setLastApplied(snapshot.Index)\r\n\t\t\r\n\t\tr.setLastSnapshot(snapshot.Index, snapshot.Term)\r\n\t\t\r\n\t\tif snapshot.Version > 0 {\r\n\t\t\tr.configurations.committed = snapshot.Configuration\r\n\t\t\tr.configurations.committedIndex = snapshot.ConfigurationIndex\r\n\t\t\tr.configurations.latest = snapshot.Configuration\r\n\t\t\tr.configurations.latestIndex = snapshot.ConfigurationIndex\r\n\t\t} else {\r\n\t\t\tconfiguration := decodePeers(snapshot.Peers, r.trans)\r\n\t\t\tr.configurations.committed = configuration\r\n\t\t\tr.configurations.committedIndex = snapshot.Index\r\n\t\t\tr.configurations.latest = configuration\r\n\t\t\tr.configurations.latestIndex = snapshot.Index\r\n\t\t}\r\n\t\t\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\tif len(snapshots) > 0 {\r\n\t\treturn fmt.Errorf(\"failed to load any existing snapshots\")\r\n\t}\r\n\treturn nil\r\n}","code-length":506,"reference":"\/\/ restoreSnapshot attempts to restore the latest snapshots, and fails if none\n\/\/ of them can be restored. This is called at initialization time, and is\n\/\/ completely unsafe to call at any other time.","result":"Restore a snapshot.","score":[0,0.0157]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) BootstrapCluster(configuration Configuration) Future {\r\n\tbootstrapReq := &bootstrapFuture{}\r\n\tbootstrapReq.init()\r\n\tbootstrapReq.configuration = configuration\r\n\tselect {\r\n\tcase <-r.shutdownCh:\r\n\t\treturn errorFuture{ErrRaftShutdown}\r\n\tcase r.bootstrapCh <- bootstrapReq:\r\n\t\treturn bootstrapReq\r\n\t}\r\n}","code-length":105,"reference":"\/\/ BootstrapCluster is equivalent to non-member BootstrapCluster but can be\n\/\/ called on an un-bootstrapped Raft instance after it has been created. This\n\/\/ should only be called at the beginning of time for the cluster, and you\n\/\/ absolutely must make sure that you call it with the same configuration on all\n\/\/ the Voter servers. There is no need to bootstrap Nonvoter and Staging\n\/\/ servers.","result":"Create a new cluster.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) Leader() ServerAddress {\r\n\tr.leaderLock.RLock()\r\n\tleader := r.leader\r\n\tr.leaderLock.RUnlock()\r\n\treturn leader\r\n}","code-length":59,"reference":"\/\/ Leader is used to return the current leader of the cluster.\n\/\/ It may return empty string if there is no current leader\n\/\/ or the leader is unknown.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) Apply(cmd []byte, timeout time.Duration) ApplyFuture {\r\n\tmetrics.IncrCounter([]string{\"raft\", \"apply\"}, 1)\r\n\tvar timer <-chan time.Time\r\n\tif timeout > 0 {\r\n\t\ttimer = time.After(timeout)\r\n\t}\r\n\t\r\n\tlogFuture := &logFuture{\r\n\t\tlog: Log{\r\n\t\t\tType: LogCommand,\r\n\t\t\tData: cmd,\r\n\t\t},\r\n\t}\r\n\tlogFuture.init()\r\n\tselect {\r\n\tcase <-timer:\r\n\t\treturn errorFuture{ErrEnqueueTimeout}\r\n\tcase <-r.shutdownCh:\r\n\t\treturn errorFuture{ErrRaftShutdown}\r\n\tcase r.applyCh <- logFuture:\r\n\t\treturn logFuture\r\n\t}\r\n}","code-length":212,"reference":"\/\/ Apply is used to apply a command to the FSM in a highly consistent\n\/\/ manner. This returns a future that can be used to wait on the application.\n\/\/ An optional timeout can be provided to limit the amount of time we wait\n\/\/ for the command to be started. This must be run on the leader or it\n\/\/ will fail.","result":"Apply a command to a raft node.","score":[0.0001,0.0638]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) Barrier(timeout time.Duration) Future {\r\n\tmetrics.IncrCounter([]string{\"raft\", \"barrier\"}, 1)\r\n\tvar timer <-chan time.Time\r\n\tif timeout > 0 {\r\n\t\ttimer = time.After(timeout)\r\n\t}\r\n\t\r\n\tlogFuture := &logFuture{\r\n\t\tlog: Log{\r\n\t\t\tType: LogBarrier,\r\n\t\t},\r\n\t}\r\n\tlogFuture.init()\r\n\tselect {\r\n\tcase <-timer:\r\n\t\treturn errorFuture{ErrEnqueueTimeout}\r\n\tcase <-r.shutdownCh:\r\n\t\treturn errorFuture{ErrRaftShutdown}\r\n\tcase r.applyCh <- logFuture:\r\n\t\treturn logFuture\r\n\t}\r\n}","code-length":202,"reference":"\/\/ Barrier is used to issue a command that blocks until all preceeding\n\/\/ operations have been applied to the FSM. It can be used to ensure the\n\/\/ FSM reflects all queued writes. An optional timeout can be provided to\n\/\/ limit the amount of time we wait for the command to be started. This\n\/\/ must be run on the leader or it will fail.","result":"Avoid the need for the following code.","score":[0.0,0.0328]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) VerifyLeader() Future {\r\n\tmetrics.IncrCounter([]string{\"raft\", \"verify_leader\"}, 1)\r\n\tverifyFuture := &verifyFuture{}\r\n\tverifyFuture.init()\r\n\tselect {\r\n\tcase <-r.shutdownCh:\r\n\t\treturn errorFuture{ErrRaftShutdown}\r\n\tcase r.verifyCh <- verifyFuture:\r\n\t\treturn verifyFuture\r\n\t}\r\n}","code-length":115,"reference":"\/\/ VerifyLeader is used to ensure the current node is still\n\/\/ the leader. This can be done to prevent stale reads when a\n\/\/ new leader has potentially been elected.","result":"Verify the leader.","score":[0.0001,0.0665]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) AddVoter(id ServerID, address ServerAddress, prevIndex uint64, timeout time.Duration) IndexFuture {\r\n\tif r.protocolVersion < 2 {\r\n\t\treturn errorFuture{ErrUnsupportedProtocol}\r\n\t}\r\n\treturn r.requestConfigChange(configurationChangeRequest{\r\n\t\tcommand:       AddStaging,\r\n\t\tserverID:      id,\r\n\t\tserverAddress: address,\r\n\t\tprevIndex:     prevIndex,\r\n\t}, timeout)\r\n}","code-length":132,"reference":"\/\/ AddVoter will add the given server to the cluster as a staging server. If the\n\/\/ server is already in the cluster as a voter, this updates the server's address.\n\/\/ This must be run on the leader or it will fail. The leader will promote the\n\/\/ staging server to a voter once that server is ready. If nonzero, prevIndex is\n\/\/ the index of the only configuration upon which this change may be applied; if\n\/\/ another configuration entry has been added in the meantime, this request will\n\/\/ fail. If nonzero, timeout is how long this server should wait before the\n\/\/ configuration change log entry is appended.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) RemoveServer(id ServerID, prevIndex uint64, timeout time.Duration) IndexFuture {\r\n\tif r.protocolVersion < 2 {\r\n\t\treturn errorFuture{ErrUnsupportedProtocol}\r\n\t}\r\n\treturn r.requestConfigChange(configurationChangeRequest{\r\n\t\tcommand:   RemoveServer,\r\n\t\tserverID:  id,\r\n\t\tprevIndex: prevIndex,\r\n\t}, timeout)\r\n}","code-length":116,"reference":"\/\/ RemoveServer will remove the given server from the cluster. If the current\n\/\/ leader is being removed, it will cause a new election to occur. This must be\n\/\/ run on the leader or it will fail. For prevIndex and timeout, see AddVoter.","result":"Remove a server from the raft.","score":[0.0008,0.0925]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) Shutdown() Future {\r\n\tr.shutdownLock.Lock()\r\n\tdefer r.shutdownLock.Unlock()\r\n\tif !r.shutdown {\r\n\t\tclose(r.shutdownCh)\r\n\t\tr.shutdown = true\r\n\t\tr.setState(Shutdown)\r\n\t\treturn &shutdownFuture{r}\r\n\t}\r\n\t\r\n\treturn &shutdownFuture{nil}\r\n}","code-length":112,"reference":"\/\/ Shutdown is used to stop the Raft background routines.\n\/\/ This is not a graceful operation. Provides a future that\n\/\/ can be used to block until all background routines have exited.","result":"Shutdown the raft.","score":[0.0,0.0333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) Snapshot() SnapshotFuture {\r\n\tfuture := &userSnapshotFuture{}\r\n\tfuture.init()\r\n\tselect {\r\n\tcase r.userSnapshotCh <- future:\r\n\t\treturn future\r\n\tcase <-r.shutdownCh:\r\n\t\tfuture.respond(ErrRaftShutdown)\r\n\t\treturn future\r\n\t}\r\n}","code-length":97,"reference":"\/\/ Snapshot is used to manually force Raft to take a snapshot. Returns a future\n\/\/ that can be used to block until complete, and that contains a function that\n\/\/ can be used to open the snapshot.","result":"Create a snapshot of the raft.","score":[0.0011,0.0431]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) Restore(meta *SnapshotMeta, reader io.Reader, timeout time.Duration) error {\r\n\tmetrics.IncrCounter([]string{\"raft\", \"restore\"}, 1)\r\n\tvar timer <-chan time.Time\r\n\tif timeout > 0 {\r\n\t\ttimer = time.After(timeout)\r\n\t}\r\n\t\r\n\trestore := &userRestoreFuture{\r\n\t\tmeta:   meta,\r\n\t\treader: reader,\r\n\t}\r\n\trestore.init()\r\n\tselect {\r\n\tcase <-timer:\r\n\t\treturn ErrEnqueueTimeout\r\n\tcase <-r.shutdownCh:\r\n\t\treturn ErrRaftShutdown\r\n\tcase r.userRestoreCh <- restore:\r\n\t\t\r\n\t\tif err := restore.Error(); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tnoop := &logFuture{\r\n\t\tlog: Log{\r\n\t\t\tType: LogNoop,\r\n\t\t},\r\n\t}\r\n\tnoop.init()\r\n\tselect {\r\n\tcase <-timer:\r\n\t\treturn ErrEnqueueTimeout\r\n\tcase <-r.shutdownCh:\r\n\t\treturn ErrRaftShutdown\r\n\tcase r.applyCh <- noop:\r\n\t\treturn noop.Error()\r\n\t}\r\n}","code-length":337,"reference":"\/\/ Restore is used to manually force Raft to consume an external snapshot, such\n\/\/ as if restoring from a backup. We will use the current Raft configuration,\n\/\/ not the one from the snapshot, so that we can restore into a new cluster. We\n\/\/ will also use the higher of the index of the snapshot, or the current index,\n\/\/ and then add 1 to that, so we force a new state with a hole in the Raft log,\n\/\/ so that the snapshot will be sent to followers and used for any new joiners.\n\/\/ This can only be run on the leader, and blocks until the restore is complete\n\/\/ or an error occurs.\n\/\/\n\/\/ WARNING! This operation has the leader take on the state of the snapshot and\n\/\/ then sets itself up so that it replicates that to its followers though the\n\/\/ install snapshot process. This involves a potentially dangerous period where\n\/\/ the leader commits ahead of its followers, so should only be used for disaster\n\/\/ recovery into a fresh cluster, and should not be used in normal operations.","result":"Restore a snapshot.","score":[5.753e-28,0.0059]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) String() string {\r\n\treturn fmt.Sprintf(\"Node at %s [%v]\", r.localAddr, r.getState())\r\n}","code-length":50,"reference":"\/\/ String returns a string representation of this Raft node.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) LastContact() time.Time {\r\n\tr.lastContactLock.RLock()\r\n\tlast := r.lastContact\r\n\tr.lastContactLock.RUnlock()\r\n\treturn last\r\n}","code-length":64,"reference":"\/\/ LastContact returns the time of last contact by a leader.\n\/\/ This only makes sense if we are currently a follower.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *LoggerAdapter) Logf(s string, v ...interface{}) {\r\n\ta.log.Printf(s, v...)\r\n}","code-length":44,"reference":"\/\/ Logf will record a formatted message to the contained debug log","result":"Log messages.","score":[0,0.0455]}
{"code":"\/*is used to<extra_id_0>\r\nfunc containsNode(nodes []*raftNode, n *raftNode) bool {\r\n\tfor _, rn := range nodes {\r\n\t\tif rn == n {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":69,"reference":"\/\/ containsNode returns true if the slice 'nodes' contains 'n'","result":"Check if the node is in the list.","score":[0.153,0.1531]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *cluster) LeaderPlus(n int) []*raftNode {\r\n\tr := make([]*raftNode, 0, n+1)\r\n\tldr := c.Leader(time.Second)\r\n\tif ldr != nil {\r\n\t\tr = append(r, ldr)\r\n\t}\r\n\tif len(r) >= n {\r\n\t\treturn r\r\n\t}\r\n\tfor _, node := range c.nodes {\r\n\t\tif !containsNode(r, node) {\r\n\t\t\tr = append(r, node)\r\n\t\t\tif len(r) >= n {\r\n\t\t\t\treturn r\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn r\r\n}","code-length":182,"reference":"\/\/ LeaderPlus returns the leader + n additional nodes from the cluster\n\/\/ the leader is always the first node in the returned slice.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *cluster) WaitTilUptoDate(t *testing.T, maxWait time.Duration) {\r\n\tidx := c.lastApplySuccess.Index()\r\n\tstart := time.Now()\r\n\tfor true {\r\n\t\tallAtIdx := true\r\n\t\tfor i := 0; i < len(c.nodes); i++ {\r\n\t\t\tnodeAppliedIdx := c.nodes[i].raft.AppliedIndex()\r\n\t\t\tif nodeAppliedIdx < idx {\r\n\t\t\t\tallAtIdx = false\r\n\t\t\t\tbreak\r\n\t\t\t} else if nodeAppliedIdx > idx {\r\n\t\t\t\tallAtIdx = false\r\n\t\t\t\tidx = nodeAppliedIdx\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif allAtIdx {\r\n\t\t\tt.Logf(\"All nodes have appliedIndex=%d\", idx)\r\n\t\t\treturn\r\n\t\t}\r\n\t\tif time.Now().Sub(start) > maxWait {\r\n\t\t\tt.Fatalf(\"Gave up waiting for all nodes to reach raft Index %d, [currently at %v]\", idx, c.appliedIndexes())\r\n\t\t}\r\n\t\ttime.Sleep(time.Millisecond * 10)\r\n\t}\r\n}","code-length":305,"reference":"\/\/ WaitTilUptoDate blocks until all nodes in the cluster have gotten their\n\/\/ commitedIndex upto the Index from the last successful call to Apply","result":"Test the code.","score":[0.0004,0.0228]}
{"code":"\/*is used to<extra_id_0>\r\nfunc assertLogEntryEqual(t *testing.T, node string, exp *raft.Log, act *raft.Log) bool {\r\n\tres := true\r\n\tif exp.Term != act.Term {\r\n\t\tt.Errorf(\"Log Entry at Index %d for node %v has mismatched terms %d\/%d\", exp.Index, node, exp.Term, act.Term)\r\n\t\tres = false\r\n\t}\r\n\tif exp.Index != act.Index {\r\n\t\tt.Errorf(\"Node %v, Log Entry should be Index %d,but is %d\", node, exp.Index, act.Index)\r\n\t\tres = false\r\n\t}\r\n\tif exp.Type != act.Type {\r\n\t\tt.Errorf(\"Node %v, Log Entry at Index %d should have type %v but is %v\", node, exp.Index, exp.Type, act.Type)\r\n\t\tres = false\r\n\t}\r\n\tif !bytes.Equal(exp.Data, act.Data) {\r\n\t\tt.Errorf(\"Node %v, Log Entry at Index %d should have data %v, but has %v\", node, exp.Index, exp.Data, act.Data)\r\n\t\tres = false\r\n\t}\r\n\treturn res\r\n}","code-length":311,"reference":"\/\/ assertLogEntryEqual compares the 2 raft Log entries and reports any differences to the supplied testing.T instance\n\/\/ it return true if the 2 entries are equal, false otherwise.","result":"Assert log entries are equal .","score":[0.0059,0.0957]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) runFSM() {\r\n\tvar lastIndex, lastTerm uint64\r\n\tcommit := func(req *commitTuple) {\r\n\t\t\r\n\t\tvar resp interface{}\r\n\t\tif req.log.Type == LogCommand {\r\n\t\t\tstart := time.Now()\r\n\t\t\tresp = r.fsm.Apply(req.log)\r\n\t\t\tmetrics.MeasureSince([]string{\"raft\", \"fsm\", \"apply\"}, start)\r\n\t\t}\r\n\t\t\r\n\t\tlastIndex = req.log.Index\r\n\t\tlastTerm = req.log.Term\r\n\t\t\r\n\t\tif req.future != nil {\r\n\t\t\treq.future.response = resp\r\n\t\t\treq.future.respond(nil)\r\n\t\t}\r\n\t}\r\n\trestore := func(req *restoreFuture) {\r\n\t\t\r\n\t\tmeta, source, err := r.snapshots.Open(req.ID)\r\n\t\tif err != nil {\r\n\t\t\treq.respond(fmt.Errorf(\"failed to open snapshot %v: %v\", req.ID, err))\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\tstart := time.Now()\r\n\t\tif err := r.fsm.Restore(source); err != nil {\r\n\t\t\treq.respond(fmt.Errorf(\"failed to restore snapshot %v: %v\", req.ID, err))\r\n\t\t\tsource.Close()\r\n\t\t\treturn\r\n\t\t}\r\n\t\tsource.Close()\r\n\t\tmetrics.MeasureSince([]string{\"raft\", \"fsm\", \"restore\"}, start)\r\n\t\t\r\n\t\tlastIndex = meta.Index\r\n\t\tlastTerm = meta.Term\r\n\t\treq.respond(nil)\r\n\t}\r\n\tsnapshot := func(req *reqSnapshotFuture) {\r\n\t\t\r\n\t\tif lastIndex == 0 {\r\n\t\t\treq.respond(ErrNothingNewToSnapshot)\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\tstart := time.Now()\r\n\t\tsnap, err := r.fsm.Snapshot()\r\n\t\tmetrics.MeasureSince([]string{\"raft\", \"fsm\", \"snapshot\"}, start)\r\n\t\t\r\n\t\treq.index = lastIndex\r\n\t\treq.term = lastTerm\r\n\t\treq.snapshot = snap\r\n\t\treq.respond(err)\r\n\t}\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase ptr := <-r.fsmMutateCh:\r\n\t\t\tswitch req := ptr.(type) {\r\n\t\t\tcase *commitTuple:\r\n\t\t\t\tcommit(req)\r\n\t\t\tcase *restoreFuture:\r\n\t\t\t\trestore(req)\r\n\t\t\tdefault:\r\n\t\t\t\tpanic(fmt.Errorf(\"bad type passed to fsmMutateCh: %#v\", ptr))\r\n\t\t\t}\r\n\t\tcase req := <-r.fsmSnapshotCh:\r\n\t\t\tsnapshot(req)\r\n\t\tcase <-r.shutdownCh:\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":738,"reference":"\/\/ runFSM is a long running goroutine responsible for applying logs\n\/\/ to the FSM. This is done async of other logs since we don't want\n\/\/ the FSM to block our internal operations.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Configuration) Clone() (copy Configuration) {\r\n\tcopy.Servers = append(copy.Servers, c.Servers...)\r\n\treturn\r\n}","code-length":46,"reference":"\/\/ Clone makes a deep copy of a Configuration.","result":"Clone the configuration.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *configurations) Clone() (copy configurations) {\r\n\tcopy.committed = c.committed.Clone()\r\n\tcopy.committedIndex = c.committedIndex\r\n\tcopy.latest = c.latest.Clone()\r\n\tcopy.latestIndex = c.latestIndex\r\n\treturn\r\n}","code-length":83,"reference":"\/\/ Clone makes a deep copy of a configurations object.","result":"Clone the configurations.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc hasVote(configuration Configuration, id ServerID) bool {\r\n\tfor _, server := range configuration.Servers {\r\n\t\tif server.ID == id {\r\n\t\t\treturn server.Suffrage == Voter\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":77,"reference":"\/\/ hasVote returns true if the server identified by 'id' is a Voter in the\n\/\/ provided Configuration.","result":"Check if a server has a vote.","score":[0.0442,0.0888]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkConfiguration(configuration Configuration) error {\r\n\tidSet := make(map[ServerID]bool)\r\n\taddressSet := make(map[ServerAddress]bool)\r\n\tvar voters int\r\n\tfor _, server := range configuration.Servers {\r\n\t\tif server.ID == \"\" {\r\n\t\t\treturn fmt.Errorf(\"Empty ID in configuration: %v\", configuration)\r\n\t\t}\r\n\t\tif server.Address == \"\" {\r\n\t\t\treturn fmt.Errorf(\"Empty address in configuration: %v\", server)\r\n\t\t}\r\n\t\tif idSet[server.ID] {\r\n\t\t\treturn fmt.Errorf(\"Found duplicate ID in configuration: %v\", server.ID)\r\n\t\t}\r\n\t\tidSet[server.ID] = true\r\n\t\tif addressSet[server.Address] {\r\n\t\t\treturn fmt.Errorf(\"Found duplicate address in configuration: %v\", server.Address)\r\n\t\t}\r\n\t\taddressSet[server.Address] = true\r\n\t\tif server.Suffrage == Voter {\r\n\t\t\tvoters++\r\n\t\t}\r\n\t}\r\n\tif voters == 0 {\r\n\t\treturn fmt.Errorf(\"Need at least one voter in configuration: %v\", configuration)\r\n\t}\r\n\treturn nil\r\n}","code-length":322,"reference":"\/\/ checkConfiguration tests a cluster membership configuration for common\n\/\/ errors.","result":"Check the configuration of the server.","score":[0.0839,0.0476]}
{"code":"\/*is used to<extra_id_0>\r\nfunc nextConfiguration(current Configuration, currentIndex uint64, change configurationChangeRequest) (Configuration, error) {\r\n\tif change.prevIndex > 0 && change.prevIndex != currentIndex {\r\n\t\treturn Configuration{}, fmt.Errorf(\"Configuration changed since %v (latest is %v)\", change.prevIndex, currentIndex)\r\n\t}\r\n\tconfiguration := current.Clone()\r\n\tswitch change.command {\r\n\tcase AddStaging:\r\n\t\t\r\n\t\tnewServer := Server{\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tSuffrage: Voter,\r\n\t\t\tID:       change.serverID,\r\n\t\t\tAddress:  change.serverAddress,\r\n\t\t}\r\n\t\tfound := false\r\n\t\tfor i, server := range configuration.Servers {\r\n\t\t\tif server.ID == change.serverID {\r\n\t\t\t\tif server.Suffrage == Voter {\r\n\t\t\t\t\tconfiguration.Servers[i].Address = change.serverAddress\r\n\t\t\t\t} else {\r\n\t\t\t\t\tconfiguration.Servers[i] = newServer\r\n\t\t\t\t}\r\n\t\t\t\tfound = true\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif !found {\r\n\t\t\tconfiguration.Servers = append(configuration.Servers, newServer)\r\n\t\t}\r\n\tcase AddNonvoter:\r\n\t\tnewServer := Server{\r\n\t\t\tSuffrage: Nonvoter,\r\n\t\t\tID:       change.serverID,\r\n\t\t\tAddress:  change.serverAddress,\r\n\t\t}\r\n\t\tfound := false\r\n\t\tfor i, server := range configuration.Servers {\r\n\t\t\tif server.ID == change.serverID {\r\n\t\t\t\tif server.Suffrage != Nonvoter {\r\n\t\t\t\t\tconfiguration.Servers[i].Address = change.serverAddress\r\n\t\t\t\t} else {\r\n\t\t\t\t\tconfiguration.Servers[i] = newServer\r\n\t\t\t\t}\r\n\t\t\t\tfound = true\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif !found {\r\n\t\t\tconfiguration.Servers = append(configuration.Servers, newServer)\r\n\t\t}\r\n\tcase DemoteVoter:\r\n\t\tfor i, server := range configuration.Servers {\r\n\t\t\tif server.ID == change.serverID {\r\n\t\t\t\tconfiguration.Servers[i].Suffrage = Nonvoter\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\tcase RemoveServer:\r\n\t\tfor i, server := range configuration.Servers {\r\n\t\t\tif server.ID == change.serverID {\r\n\t\t\t\tconfiguration.Servers = append(configuration.Servers[:i], configuration.Servers[i+1:]...)\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\tcase Promote:\r\n\t\tfor i, server := range configuration.Servers {\r\n\t\t\tif server.ID == change.serverID && server.Suffrage == Staging {\r\n\t\t\t\tconfiguration.Servers[i].Suffrage = Voter\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\tif err := checkConfiguration(configuration); err != nil {\r\n\t\treturn Configuration{}, err\r\n\t}\r\n\treturn configuration, nil\r\n}","code-length":794,"reference":"\/\/ nextConfiguration generates a new Configuration from the current one and a\n\/\/ configuration change request. It's split from appendConfigurationEntry so\n\/\/ that it can be unit tested easily.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc encodePeers(configuration Configuration, trans Transport) []byte {\r\n\t\r\n\t\r\n\tvar encPeers [][]byte\r\n\tfor _, server := range configuration.Servers {\r\n\t\tif server.Suffrage == Voter {\r\n\t\t\tencPeers = append(encPeers, trans.EncodePeer(server.ID, server.Address))\r\n\t\t}\r\n\t}\r\n\t\r\n\tbuf, err := encodeMsgPack(encPeers)\r\n\tif err != nil {\r\n\t\tpanic(fmt.Errorf(\"failed to encode peers: %v\", err))\r\n\t}\r\n\treturn buf.Bytes()\r\n}","code-length":160,"reference":"\/\/ encodePeers is used to serialize a Configuration into the old peers format.\n\/\/ This is here for backwards compatibility when operating with a mix of old\n\/\/ servers and should be removed once we deprecate support for protocol version 1.","result":"Encode peers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc decodePeers(buf []byte, trans Transport) Configuration {\r\n\t\r\n\tvar encPeers [][]byte\r\n\tif err := decodeMsgPack(buf, &encPeers); err != nil {\r\n\t\tpanic(fmt.Errorf(\"failed to decode peers: %v\", err))\r\n\t}\r\n\t\r\n\tvar servers []Server\r\n\tfor _, enc := range encPeers {\r\n\t\tp := trans.DecodePeer(enc)\r\n\t\tservers = append(servers, Server{\r\n\t\t\tSuffrage: Voter,\r\n\t\t\tID:       ServerID(p),\r\n\t\t\tAddress:  ServerAddress(p),\r\n\t\t})\r\n\t}\r\n\treturn Configuration{\r\n\t\tServers: servers,\r\n\t}\r\n}","code-length":192,"reference":"\/\/ decodePeers is used to deserialize an old list of peers into a Configuration.\n\/\/ This is here for backwards compatibility with old log entries and snapshots;\n\/\/ it should be removed eventually.","result":"Decode peers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc encodeConfiguration(configuration Configuration) []byte {\r\n\tbuf, err := encodeMsgPack(configuration)\r\n\tif err != nil {\r\n\t\tpanic(fmt.Errorf(\"failed to encode configuration: %v\", err))\r\n\t}\r\n\treturn buf.Bytes()\r\n}","code-length":76,"reference":"\/\/ encodeConfiguration serializes a Configuration using MsgPack, or panics on\n\/\/ errors.","result":"Encode the configuration.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc decodeConfiguration(buf []byte) Configuration {\r\n\tvar configuration Configuration\r\n\tif err := decodeMsgPack(buf, &configuration); err != nil {\r\n\t\tpanic(fmt.Errorf(\"failed to decode configuration: %v\", err))\r\n\t}\r\n\treturn configuration\r\n}","code-length":77,"reference":"\/\/ decodeConfiguration deserializes a Configuration using MsgPack, or panics on\n\/\/ errors.","result":"Decode configuration messages.","score":[0,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raftState) goFunc(f func()) {\r\n\tr.routinesGroup.Add(1)\r\n\tgo func() {\r\n\t\tdefer r.routinesGroup.Done()\r\n\t\tf()\r\n\t}()\r\n}","code-length":70,"reference":"\/\/ Start a goroutine and properly handle the race between a routine\n\/\/ starting and incrementing, and exiting and decrementing.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raftState) getLastIndex() uint64 {\r\n\tr.lastLock.Lock()\r\n\tdefer r.lastLock.Unlock()\r\n\treturn max(r.lastLogIndex, r.lastSnapshotIndex)\r\n}","code-length":64,"reference":"\/\/ getLastIndex returns the last index in stable storage.\n\/\/ Either from the last log or from the last snapshot.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *raftState) getLastEntry() (uint64, uint64) {\r\n\tr.lastLock.Lock()\r\n\tdefer r.lastLock.Unlock()\r\n\tif r.lastLogIndex >= r.lastSnapshotIndex {\r\n\t\treturn r.lastLogIndex, r.lastLogTerm\r\n\t}\r\n\treturn r.lastSnapshotIndex, r.lastSnapshotTerm\r\n}","code-length":102,"reference":"\/\/ getLastEntry returns the last index and term in stable storage.\n\/\/ Either from the last log or from the last snapshot.","result":"Get the last entry in the raft state.","score":[0.0406,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) checkRPCHeader(rpc RPC) error {\r\n\t\r\n\twh, ok := rpc.Command.(WithRPCHeader)\r\n\tif !ok {\r\n\t\treturn fmt.Errorf(\"RPC does not have a header\")\r\n\t}\r\n\theader := wh.GetRPCHeader()\r\n\t\r\n\t\r\n\tif header.ProtocolVersion < ProtocolVersionMin ||\r\n\t\theader.ProtocolVersion > ProtocolVersionMax {\r\n\t\treturn ErrUnsupportedProtocol\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif header.ProtocolVersion < r.conf.ProtocolVersion-1 {\r\n\t\treturn ErrUnsupportedProtocol\r\n\t}\r\n\treturn nil\r\n}","code-length":178,"reference":"\/\/ checkRPCHeader houses logic about whether this instance of Raft can process\n\/\/ the given RPC message.","result":"Check the RPC header.","score":[0.0147,0.0637]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) setLeader(leader ServerAddress) {\r\n\tr.leaderLock.Lock()\r\n\toldLeader := r.leader\r\n\tr.leader = leader\r\n\tr.leaderLock.Unlock()\r\n\tif oldLeader != leader {\r\n\t\tr.observe(LeaderObservation{leader: leader})\r\n\t}\r\n}","code-length":94,"reference":"\/\/ setLeader is used to modify the current leader of the cluster","result":"Set the leader of the raft.","score":[0.1572,0.3289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) requestConfigChange(req configurationChangeRequest, timeout time.Duration) IndexFuture {\r\n\tvar timer <-chan time.Time\r\n\tif timeout > 0 {\r\n\t\ttimer = time.After(timeout)\r\n\t}\r\n\tfuture := &configurationChangeFuture{\r\n\t\treq: req,\r\n\t}\r\n\tfuture.init()\r\n\tselect {\r\n\tcase <-timer:\r\n\t\treturn errorFuture{ErrEnqueueTimeout}\r\n\tcase r.configurationChangeCh <- future:\r\n\t\treturn future\r\n\tcase <-r.shutdownCh:\r\n\t\treturn errorFuture{ErrRaftShutdown}\r\n\t}\r\n}","code-length":168,"reference":"\/\/ requestConfigChange is a helper for the above functions that make\n\/\/ configuration change requests. 'req' describes the change. For timeout,\n\/\/ see AddVoter.","result":"Send configuration change requests to the Raft.","score":[0.0223,0.1146]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) run() {\r\n\tfor {\r\n\t\t\r\n\t\tselect {\r\n\t\tcase <-r.shutdownCh:\r\n\t\t\t\r\n\t\t\tr.setLeader(\"\")\r\n\t\t\treturn\r\n\t\tdefault:\r\n\t\t}\r\n\t\t\r\n\t\tswitch r.getState() {\r\n\t\tcase Follower:\r\n\t\t\tr.runFollower()\r\n\t\tcase Candidate:\r\n\t\t\tr.runCandidate()\r\n\t\tcase Leader:\r\n\t\t\tr.runLeader()\r\n\t\t}\r\n\t}\r\n}","code-length":150,"reference":"\/\/ run is a long running goroutine that runs the Raft FSM.","result":"Run the raft.","score":[0.0203,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) runFollower() {\r\n\tdidWarn := false\r\n\tr.logger.Info(fmt.Sprintf(\"%v entering Follower state (Leader: %q)\", r, r.Leader()))\r\n\tmetrics.IncrCounter([]string{\"raft\", \"state\", \"follower\"}, 1)\r\n\theartbeatTimer := randomTimeout(r.conf.HeartbeatTimeout)\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase rpc := <-r.rpcCh:\r\n\t\t\tr.processRPC(rpc)\r\n\t\tcase c := <-r.configurationChangeCh:\r\n\t\t\t\r\n\t\t\tc.respond(ErrNotLeader)\r\n\t\tcase a := <-r.applyCh:\r\n\t\t\t\r\n\t\t\ta.respond(ErrNotLeader)\r\n\t\tcase v := <-r.verifyCh:\r\n\t\t\t\r\n\t\t\tv.respond(ErrNotLeader)\r\n\t\tcase r := <-r.userRestoreCh:\r\n\t\t\t\r\n\t\t\tr.respond(ErrNotLeader)\r\n\t\tcase c := <-r.configurationsCh:\r\n\t\t\tc.configurations = r.configurations.Clone()\r\n\t\t\tc.respond(nil)\r\n\t\tcase b := <-r.bootstrapCh:\r\n\t\t\tb.respond(r.liveBootstrap(b.configuration))\r\n\t\tcase <-heartbeatTimer:\r\n\t\t\t\r\n\t\t\theartbeatTimer = randomTimeout(r.conf.HeartbeatTimeout)\r\n\t\t\t\r\n\t\t\tlastContact := r.LastContact()\r\n\t\t\tif time.Now().Sub(lastContact) < r.conf.HeartbeatTimeout {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tlastLeader := r.Leader()\r\n\t\t\tr.setLeader(\"\")\r\n\t\t\tif r.configurations.latestIndex == 0 {\r\n\t\t\t\tif !didWarn {\r\n\t\t\t\t\tr.logger.Warn(\"no known peers, aborting election\")\r\n\t\t\t\t\tdidWarn = true\r\n\t\t\t\t}\r\n\t\t\t} else if r.configurations.latestIndex == r.configurations.committedIndex &&\r\n\t\t\t\t!hasVote(r.configurations.latest, r.localID) {\r\n\t\t\t\tif !didWarn {\r\n\t\t\t\t\tr.logger.Warn(\"not part of stable configuration, aborting election\")\r\n\t\t\t\t\tdidWarn = true\r\n\t\t\t\t}\r\n\t\t\t} else {\r\n\t\t\t\tr.logger.Warn(fmt.Sprintf(\"Heartbeat timeout from %q reached, starting election\", lastLeader))\r\n\t\t\t\tmetrics.IncrCounter([]string{\"raft\", \"transition\", \"heartbeat_timeout\"}, 1)\r\n\t\t\t\tr.setState(Candidate)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\tcase <-r.shutdownCh:\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":665,"reference":"\/\/ runFollower runs the FSM for a follower.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) liveBootstrap(configuration Configuration) error {\r\n\t\r\n\terr := BootstrapCluster(&r.conf, r.logs, r.stable, r.snapshots,\r\n\t\tr.trans, configuration)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tvar entry Log\r\n\tif err := r.logs.GetLog(1, &entry); err != nil {\r\n\t\tpanic(err)\r\n\t}\r\n\tr.setCurrentTerm(1)\r\n\tr.setLastLog(entry.Index, entry.Term)\r\n\tr.processConfigurationLogEntry(&entry)\r\n\treturn nil\r\n}","code-length":172,"reference":"\/\/ liveBootstrap attempts to seed an initial configuration for the cluster. See\n\/\/ the Raft object's member BootstrapCluster for more details. This must only be\n\/\/ called on the main thread, and only makes sense in the follower state.","result":"Avoid the need for the function to be executed.","score":[0.0077,0.0694]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) runCandidate() {\r\n\tr.logger.Info(fmt.Sprintf(\"%v entering Candidate state in term %v\", r, r.getCurrentTerm()+1))\r\n\tmetrics.IncrCounter([]string{\"raft\", \"state\", \"candidate\"}, 1)\r\n\t\r\n\tvoteCh := r.electSelf()\r\n\telectionTimer := randomTimeout(r.conf.ElectionTimeout)\r\n\t\r\n\tgrantedVotes := 0\r\n\tvotesNeeded := r.quorumSize()\r\n\tr.logger.Debug(fmt.Sprintf(\"Votes needed: %d\", votesNeeded))\r\n\tfor r.getState() == Candidate {\r\n\t\tselect {\r\n\t\tcase rpc := <-r.rpcCh:\r\n\t\t\tr.processRPC(rpc)\r\n\t\tcase vote := <-voteCh:\r\n\t\t\t\r\n\t\t\tif vote.Term > r.getCurrentTerm() {\r\n\t\t\t\tr.logger.Debug(\"Newer term discovered, fallback to follower\")\r\n\t\t\t\tr.setState(Follower)\r\n\t\t\t\tr.setCurrentTerm(vote.Term)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif vote.Granted {\r\n\t\t\t\tgrantedVotes++\r\n\t\t\t\tr.logger.Debug(fmt.Sprintf(\"Vote granted from %s in term %v. Tally: %d\",\r\n\t\t\t\t\tvote.voterID, vote.Term, grantedVotes))\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif grantedVotes >= votesNeeded {\r\n\t\t\t\tr.logger.Info(fmt.Sprintf(\"Election won. Tally: %d\", grantedVotes))\r\n\t\t\t\tr.setState(Leader)\r\n\t\t\t\tr.setLeader(r.localAddr)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\tcase c := <-r.configurationChangeCh:\r\n\t\t\t\r\n\t\t\tc.respond(ErrNotLeader)\r\n\t\tcase a := <-r.applyCh:\r\n\t\t\t\r\n\t\t\ta.respond(ErrNotLeader)\r\n\t\tcase v := <-r.verifyCh:\r\n\t\t\t\r\n\t\t\tv.respond(ErrNotLeader)\r\n\t\tcase r := <-r.userRestoreCh:\r\n\t\t\t\r\n\t\t\tr.respond(ErrNotLeader)\r\n\t\tcase c := <-r.configurationsCh:\r\n\t\t\tc.configurations = r.configurations.Clone()\r\n\t\t\tc.respond(nil)\r\n\t\tcase b := <-r.bootstrapCh:\r\n\t\t\tb.respond(ErrCantBootstrap)\r\n\t\tcase <-electionTimer:\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tr.logger.Warn(\"Election timeout reached, restarting election\")\r\n\t\t\treturn\r\n\t\tcase <-r.shutdownCh:\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":677,"reference":"\/\/ runCandidate runs the FSM for a candidate.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) runLeader() {\r\n\tr.logger.Info(fmt.Sprintf(\"%v entering Leader state\", r))\r\n\tmetrics.IncrCounter([]string{\"raft\", \"state\", \"leader\"}, 1)\r\n\t\r\n\tasyncNotifyBool(r.leaderCh, true)\r\n\t\r\n\tif notify := r.conf.NotifyCh; notify != nil {\r\n\t\tselect {\r\n\t\tcase notify <- true:\r\n\t\tcase <-r.shutdownCh:\r\n\t\t}\r\n\t}\r\n\t\r\n\tr.leaderState.commitCh = make(chan struct{}, 1)\r\n\tr.leaderState.commitment = newCommitment(r.leaderState.commitCh,\r\n\t\tr.configurations.latest,\r\n\t\tr.getLastIndex()+1 )\r\n\tr.leaderState.inflight = list.New()\r\n\tr.leaderState.replState = make(map[ServerID]*followerReplication)\r\n\tr.leaderState.notify = make(map[*verifyFuture]struct{})\r\n\tr.leaderState.stepDown = make(chan struct{}, 1)\r\n\t\r\n\tdefer func() {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tr.setLastContact()\r\n\t\t\r\n\t\tfor _, p := range r.leaderState.replState {\r\n\t\t\tclose(p.stopCh)\r\n\t\t}\r\n\t\t\r\n\t\tfor e := r.leaderState.inflight.Front(); e != nil; e = e.Next() {\r\n\t\t\te.Value.(*logFuture).respond(ErrLeadershipLost)\r\n\t\t}\r\n\t\t\r\n\t\tfor future := range r.leaderState.notify {\r\n\t\t\tfuture.respond(ErrLeadershipLost)\r\n\t\t}\r\n\t\t\r\n\t\tr.leaderState.commitCh = nil\r\n\t\tr.leaderState.commitment = nil\r\n\t\tr.leaderState.inflight = nil\r\n\t\tr.leaderState.replState = nil\r\n\t\tr.leaderState.notify = nil\r\n\t\tr.leaderState.stepDown = nil\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tr.leaderLock.Lock()\r\n\t\tif r.leader == r.localAddr {\r\n\t\t\tr.leader = \"\"\r\n\t\t}\r\n\t\tr.leaderLock.Unlock()\r\n\t\t\r\n\t\tasyncNotifyBool(r.leaderCh, false)\r\n\t\t\r\n\t\tif notify := r.conf.NotifyCh; notify != nil {\r\n\t\t\tselect {\r\n\t\t\tcase notify <- false:\r\n\t\t\tcase <-r.shutdownCh:\r\n\t\t\t\t\r\n\t\t\t\tselect {\r\n\t\t\t\tcase notify <- false:\r\n\t\t\t\tdefault:\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}()\r\n\t\r\n\tr.startStopReplication()\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tnoop := &logFuture{\r\n\t\tlog: Log{\r\n\t\t\tType: LogNoop,\r\n\t\t},\r\n\t}\r\n\tr.dispatchLogs([]*logFuture{noop})\r\n\t\r\n\tr.leaderLoop()\r\n}","code-length":788,"reference":"\/\/ runLeader runs the FSM for a leader. Do the setup here and drop into\n\/\/ the leaderLoop for the hot loop.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) startStopReplication() {\r\n\tinConfig := make(map[ServerID]bool, len(r.configurations.latest.Servers))\r\n\tlastIdx := r.getLastIndex()\r\n\t\r\n\tfor _, server := range r.configurations.latest.Servers {\r\n\t\tif server.ID == r.localID {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tinConfig[server.ID] = true\r\n\t\tif _, ok := r.leaderState.replState[server.ID]; !ok {\r\n\t\t\tr.logger.Info(fmt.Sprintf(\"Added peer %v, starting replication\", server.ID))\r\n\t\t\ts := &followerReplication{\r\n\t\t\t\tpeer:        server,\r\n\t\t\t\tcommitment:  r.leaderState.commitment,\r\n\t\t\t\tstopCh:      make(chan uint64, 1),\r\n\t\t\t\ttriggerCh:   make(chan struct{}, 1),\r\n\t\t\t\tcurrentTerm: r.getCurrentTerm(),\r\n\t\t\t\tnextIndex:   lastIdx + 1,\r\n\t\t\t\tlastContact: time.Now(),\r\n\t\t\t\tnotify:      make(map[*verifyFuture]struct{}),\r\n\t\t\t\tnotifyCh:    make(chan struct{}, 1),\r\n\t\t\t\tstepDown:    r.leaderState.stepDown,\r\n\t\t\t}\r\n\t\t\tr.leaderState.replState[server.ID] = s\r\n\t\t\tr.goFunc(func() { r.replicate(s) })\r\n\t\t\tasyncNotifyCh(s.triggerCh)\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor serverID, repl := range r.leaderState.replState {\r\n\t\tif inConfig[serverID] {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tr.logger.Info(fmt.Sprintf(\"Removed peer %v, stopping replication after %v\", serverID, lastIdx))\r\n\t\trepl.stopCh <- lastIdx\r\n\t\tclose(repl.stopCh)\r\n\t\tdelete(r.leaderState.replState, serverID)\r\n\t}\r\n}","code-length":512,"reference":"\/\/ startStopReplication will set up state and start asynchronous replication to\n\/\/ new peers, and stop replication to removed peers. Before removing a peer,\n\/\/ it'll instruct the replication routines to try to replicate to the current\n\/\/ index. This must only be called from the main thread.","result":"Start stop replication.","score":[0.0,0.023]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) configurationChangeChIfStable() chan *configurationChangeFuture {\r\n\t\r\n\t\r\n\t\r\n\tdex &&\r\n\t\tr.getCommitIndex() >= r.leaderState.commitment.startIndex {\r\n\t\treturn r.configurationChangeCh\r\n\t}\r\n\treturn nil\r\n}","code-length":86,"reference":"\/\/ configurationChangeChIfStable returns r.configurationChangeCh if it's safe\n\/\/ to process requests from it, or nil otherwise. This must only be called\n\/\/ from the main thread.\n\/\/\n\/\/ Note that if the conditions here were to change outside of leaderLoop to take\n\/\/ this from nil to non-nil, we would need leaderLoop to be kicked.","result":"Get the configuration change channel.","score":[0.0,0.03]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) verifyLeader(v *verifyFuture) {\r\n\t\r\n\tv.votes = 1\r\n\t\r\n\tv.quorumSize = r.quorumSize()\r\n\tif v.quorumSize == 1 {\r\n\t\tv.respond(nil)\r\n\t\treturn\r\n\t}\r\n\t\r\n\tv.notifyCh = r.verifyCh\r\n\tr.leaderState.notify[v] = struct{}{}\r\n\t\r\n\tfor _, repl := range r.leaderState.replState {\r\n\t\trepl.notifyLock.Lock()\r\n\t\trepl.notify[v] = struct{}{}\r\n\t\trepl.notifyLock.Unlock()\r\n\t\tasyncNotifyCh(repl.notifyCh)\r\n\t}\r\n}","code-length":192,"reference":"\/\/ verifyLeader must be called from the main thread for safety.\n\/\/ Causes the followers to attempt an immediate heartbeat.","result":"Verify the leader.","score":[0.0014,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) checkLeaderLease() time.Duration {\r\n\t\r\n\tcontacted := 1\r\n\t\r\n\tvar maxDiff time.Duration\r\n\tnow := time.Now()\r\n\tfor peer, f := range r.leaderState.replState {\r\n\t\tdiff := now.Sub(f.LastContact())\r\n\t\tif diff <= r.conf.LeaderLeaseTimeout {\r\n\t\t\tcontacted++\r\n\t\t\tif diff > maxDiff {\r\n\t\t\t\tmaxDiff = diff\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\t\r\n\t\t\tif diff <= 3*r.conf.LeaderLeaseTimeout {\r\n\t\t\t\tr.logger.Warn(fmt.Sprintf(\"Failed to contact %v in %v\", peer, diff))\r\n\t\t\t} else {\r\n\t\t\t\tr.logger.Debug(fmt.Sprintf(\"Failed to contact %v in %v\", peer, diff))\r\n\t\t\t}\r\n\t\t}\r\n\t\tmetrics.AddSample([]string{\"raft\", \"leader\", \"lastContact\"}, float32(diff\/time.Millisecond))\r\n\t}\r\n\t\r\n\tquorum := r.quorumSize()\r\n\tif contacted < quorum {\r\n\t\tr.logger.Warn(\"Failed to contact quorum of nodes, stepping down\")\r\n\t\tr.setState(Follower)\r\n\t\tmetrics.IncrCounter([]string{\"raft\", \"transition\", \"leader_lease_timeout\"}, 1)\r\n\t}\r\n\treturn maxDiff\r\n}","code-length":367,"reference":"\/\/ checkLeaderLease is used to check if we can contact a quorum of nodes\n\/\/ within the last leader lease interval. If not, we need to step down,\n\/\/ as we may have lost connectivity. Returns the maximum duration without\n\/\/ contact. This must only be called from the main thread.","result":"Check the leader lease timeout.","score":[0.0,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) restoreUserSnapshot(meta *SnapshotMeta, reader io.Reader) error {\r\n\tdefer metrics.MeasureSince([]string{\"raft\", \"restoreUserSnapshot\"}, time.Now())\r\n\t\r\n\tversion := meta.Version\r\n\tif version < SnapshotVersionMin || version > SnapshotVersionMax {\r\n\t\treturn fmt.Errorf(\"unsupported snapshot version %d\", version)\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tcommittedIndex := r.configurations.committedIndex\r\n\tlatestIndex := r.configurations.latestIndex\r\n\tif committedIndex != latestIndex {\r\n\t\treturn fmt.Errorf(\"cannot restore snapshot now, wait until the configuration entry at %v has been applied (have applied %v)\",\r\n\t\t\tlatestIndex, committedIndex)\r\n\t}\r\n\t\r\n\tfor {\r\n\t\te := r.leaderState.inflight.Front()\r\n\t\tif e == nil {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\te.Value.(*logFuture).respond(ErrAbortedByRestore)\r\n\t\tr.leaderState.inflight.Remove(e)\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tterm := r.getCurrentTerm()\r\n\tlastIndex := r.getLastIndex()\r\n\tif meta.Index > lastIndex {\r\n\t\tlastIndex = meta.Index\r\n\t}\r\n\tlastIndex++\r\n\t\r\n\t\r\n\tsink, err := r.snapshots.Create(version, lastIndex, term,\r\n\t\tr.configurations.latest, r.configurations.latestIndex, r.trans)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to create snapshot: %v\", err)\r\n\t}\r\n\tn, err := io.Copy(sink, reader)\r\n\tif err != nil {\r\n\t\tsink.Cancel()\r\n\t\treturn fmt.Errorf(\"failed to write snapshot: %v\", err)\r\n\t}\r\n\tif n != meta.Size {\r\n\t\tsink.Cancel()\r\n\t\treturn fmt.Errorf(\"failed to write snapshot, size didn't match (%d != %d)\", n, meta.Size)\r\n\t}\r\n\tif err := sink.Close(); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to close snapshot: %v\", err)\r\n\t}\r\n\tr.logger.Info(fmt.Sprintf(\"Copied %d bytes to local snapshot\", n))\r\n\t\r\n\t\r\n\tfsm := &restoreFuture{ID: sink.ID()}\r\n\tfsm.init()\r\n\tselect {\r\n\tcase r.fsmMutateCh <- fsm:\r\n\tcase <-r.shutdownCh:\r\n\t\treturn ErrRaftShutdown\r\n\t}\r\n\tif err := fsm.Error(); err != nil {\r\n\t\tpanic(fmt.Errorf(\"failed to restore snapshot: %v\", err))\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tr.setLastLog(lastIndex, term)\r\n\tr.setLastApplied(lastIndex)\r\n\tr.setLastSnapshot(lastIndex, term)\r\n\tr.logger.Info(fmt.Sprintf(\"Restored user snapshot (index %d)\", lastIndex))\r\n\treturn nil\r\n}","code-length":790,"reference":"\/\/ restoreUserSnapshot is used to manually consume an external snapshot, such\n\/\/ as if restoring from a backup. We will use the current Raft configuration,\n\/\/ not the one from the snapshot, so that we can restore into a new cluster. We\n\/\/ will also use the higher of the index of the snapshot, or the current index,\n\/\/ and then add 1 to that, so we force a new state with a hole in the Raft log,\n\/\/ so that the snapshot will be sent to followers and used for any new joiners.\n\/\/ This can only be run on the leader, and returns a future that can be used to\n\/\/ block until complete.","result":"Code too long,keep in 512.","score":[0.0,0.0095]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) appendConfigurationEntry(future *configurationChangeFuture) {\r\n\tconfiguration, err := nextConfiguration(r.configurations.latest, r.configurations.latestIndex, future.req)\r\n\tif err != nil {\r\n\t\tfuture.respond(err)\r\n\t\treturn\r\n\t}\r\n\tr.logger.Info(fmt.Sprintf(\"Updating configuration with %s (%v, %v) to %+v\",\r\n\t\tfuture.req.command, future.req.serverID, future.req.serverAddress, configuration.Servers))\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif r.protocolVersion < 2 {\r\n\t\tfuture.log = Log{\r\n\t\t\tType: LogRemovePeerDeprecated,\r\n\t\t\tData: encodePeers(configuration, r.trans),\r\n\t\t}\r\n\t} else {\r\n\t\tfuture.log = Log{\r\n\t\t\tType: LogConfiguration,\r\n\t\t\tData: encodeConfiguration(configuration),\r\n\t\t}\r\n\t}\r\n\tr.dispatchLogs([]*logFuture{&future.logFuture})\r\n\tindex := future.Index()\r\n\tr.configurations.latest = configuration\r\n\tr.configurations.latestIndex = index\r\n\tr.leaderState.commitment.setConfiguration(configuration)\r\n\tr.startStopReplication()\r\n}","code-length":333,"reference":"\/\/ appendConfigurationEntry changes the configuration and adds a new\n\/\/ configuration entry to the log. This must only be called from the\n\/\/ main thread.","result":"Update the raft raft configuration.","score":[0.0044,0.0217]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) dispatchLogs(applyLogs []*logFuture) {\r\n\tnow := time.Now()\r\n\tdefer metrics.MeasureSince([]string{\"raft\", \"leader\", \"dispatchLog\"}, now)\r\n\tterm := r.getCurrentTerm()\r\n\tlastIndex := r.getLastIndex()\r\n\tn := len(applyLogs)\r\n\tlogs := make([]*Log, n)\r\n\tmetrics.SetGauge([]string{\"raft\", \"leader\", \"dispatchNumLogs\"}, float32(n))\r\n\tfor idx, applyLog := range applyLogs {\r\n\t\tapplyLog.dispatch = now\r\n\t\tlastIndex++\r\n\t\tapplyLog.log.Index = lastIndex\r\n\t\tapplyLog.log.Term = term\r\n\t\tlogs[idx] = &applyLog.log\r\n\t\tr.leaderState.inflight.PushBack(applyLog)\r\n\t}\r\n\t\r\n\tif err := r.logs.StoreLogs(logs); err != nil {\r\n\t\tr.logger.Error(fmt.Sprintf(\"Failed to commit logs: %v\", err))\r\n\t\tfor _, applyLog := range applyLogs {\r\n\t\t\tapplyLog.respond(err)\r\n\t\t}\r\n\t\tr.setState(Follower)\r\n\t\treturn\r\n\t}\r\n\tr.leaderState.commitment.match(r.localID, lastIndex)\r\n\t\r\n\tr.setLastLog(lastIndex, term)\r\n\t\r\n\tfor _, f := range r.leaderState.replState {\r\n\t\tasyncNotifyCh(f.triggerCh)\r\n\t}\r\n}","code-length":397,"reference":"\/\/ dispatchLog is called on the leader to push a log to disk, mark it\n\/\/ as inflight and begin replication of it.","result":"Dispatch logs.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) processLogs(index uint64, future *logFuture) {\r\n\t\r\n\tlastApplied := r.getLastApplied()\r\n\tif index <= lastApplied {\r\n\t\tr.logger.Warn(fmt.Sprintf(\"Skipping application of old log: %d\", index))\r\n\t\treturn\r\n\t}\r\n\t\r\n\tfor idx := r.getLastApplied() + 1; idx <= index; idx++ {\r\n\t\t\r\n\t\tif future != nil && future.log.Index == idx {\r\n\t\t\tr.processLog(&future.log, future)\r\n\t\t} else {\r\n\t\t\tl := new(Log)\r\n\t\t\tif err := r.logs.GetLog(idx, l); err != nil {\r\n\t\t\t\tr.logger.Error(fmt.Sprintf(\"Failed to get log at %d: %v\", idx, err))\r\n\t\t\t\tpanic(err)\r\n\t\t\t}\r\n\t\t\tr.processLog(l, nil)\r\n\t\t}\r\n\t\t\r\n\t\tr.setLastApplied(idx)\r\n\t}\r\n}","code-length":272,"reference":"\/\/ processLogs is used to apply all the committed entries that haven't been\n\/\/ applied up to the given index limit.\n\/\/ This can be called from both leaders and followers.\n\/\/ Followers call this from AppendEntries, for n entries at a time, and always\n\/\/ pass future=nil.\n\/\/ Leaders call this once per inflight when entries are committed. They pass\n\/\/ the future from inflights.","result":"Process logs in the raft .","score":[0.0,0.0083]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) processLog(l *Log, future *logFuture) {\r\n\tswitch l.Type {\r\n\tcase LogBarrier:\r\n\t\t\r\n\t\tfallthrough\r\n\tcase LogCommand:\r\n\t\t\r\n\t\tselect {\r\n\t\tcase r.fsmMutateCh <- &commitTuple{l, future}:\r\n\t\tcase <-r.shutdownCh:\r\n\t\t\tif future != nil {\r\n\t\t\t\tfuture.respond(ErrRaftShutdown)\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\treturn\r\n\tcase LogConfiguration:\r\n\tcase LogAddPeerDeprecated:\r\n\tcase LogRemovePeerDeprecated:\r\n\tcase LogNoop:\r\n\t\t\r\n\tdefault:\r\n\t\tpanic(fmt.Errorf(\"unrecognized log type: %#v\", l))\r\n\t}\r\n\t\r\n\tif future != nil {\r\n\t\tfuture.respond(nil)\r\n\t}\r\n}","code-length":240,"reference":"\/\/ processLog is invoked to process the application of a single committed log entry.","result":"Generate code for the generated code.","score":[0.0509,0.0379]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) processRPC(rpc RPC) {\r\n\tif err := r.checkRPCHeader(rpc); err != nil {\r\n\t\trpc.Respond(nil, err)\r\n\t\treturn\r\n\t}\r\n\tswitch cmd := rpc.Command.(type) {\r\n\tcase *AppendEntriesRequest:\r\n\t\tr.appendEntries(rpc, cmd)\r\n\tcase *RequestVoteRequest:\r\n\t\tr.requestVote(rpc, cmd)\r\n\tcase *InstallSnapshotRequest:\r\n\t\tr.installSnapshot(rpc, cmd)\r\n\tdefault:\r\n\t\tr.logger.Error(fmt.Sprintf(\"Got unexpected command: %#v\", rpc.Command))\r\n\t\trpc.Respond(nil, fmt.Errorf(\"unexpected command\"))\r\n\t}\r\n}","code-length":198,"reference":"\/\/ processRPC is called to handle an incoming RPC request. This must only be\n\/\/ called from the main thread.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) processHeartbeat(rpc RPC) {\r\n\tdefer metrics.MeasureSince([]string{\"raft\", \"rpc\", \"processHeartbeat\"}, time.Now())\r\n\t\r\n\tselect {\r\n\tcase <-r.shutdownCh:\r\n\t\treturn\r\n\tdefault:\r\n\t}\r\n\t\r\n\tswitch cmd := rpc.Command.(type) {\r\n\tcase *AppendEntriesRequest:\r\n\t\tr.appendEntries(rpc, cmd)\r\n\tdefault:\r\n\t\tr.logger.Error(fmt.Sprintf(\"Expected heartbeat, got command: %#v\", rpc.Command))\r\n\t\trpc.Respond(nil, fmt.Errorf(\"unexpected command\"))\r\n\t}\r\n}","code-length":179,"reference":"\/\/ processHeartbeat is a special handler used just for heartbeat requests\n\/\/ so that they can be fast-pathed if a transport supports it. This must only\n\/\/ be called from the main thread.","result":"Trigger the raft heartbeat routine.","score":[0.0011,0.0331]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) setLastContact() {\r\n\tr.lastContactLock.Lock()\r\n\tr.lastContact = time.Now()\r\n\tr.lastContactLock.Unlock()\r\n}","code-length":57,"reference":"\/\/ setLastContact is used to set the last contact time to now","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) persistVote(term uint64, candidate []byte) error {\r\n\tif err := r.stable.SetUint64(keyLastVoteTerm, term); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := r.stable.Set(keyLastVoteCand, candidate); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":106,"reference":"\/\/ persistVote is used to persist our vote for safety.","result":"Store the last vote in the raft.","score":[0.1052,0.0515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) setCurrentTerm(t uint64) {\r\n\t\r\n\tif err := r.stable.SetUint64(keyCurrentTerm, t); err != nil {\r\n\t\tpanic(fmt.Errorf(\"failed to save current term: %v\", err))\r\n\t}\r\n\tr.raftState.setCurrentTerm(t)\r\n}","code-length":94,"reference":"\/\/ setCurrentTerm is used to set the current term in a durable manner.","result":"Set the current term in the raft state.","score":[0.2327,0.3568]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) setState(state RaftState) {\r\n\tr.setLeader(\"\")\r\n\toldState := r.raftState.getState()\r\n\tr.raftState.setState(state)\r\n\tif oldState != state {\r\n\t\tr.observe(state)\r\n\t}\r\n}","code-length":85,"reference":"\/\/ setState is used to update the current state. Any state\n\/\/ transition causes the known leader to be cleared. This means\n\/\/ that leader should be set only after updating the state.","result":"Set the state of the raft.","score":[0.0028,0.066]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *commitment) getCommitIndex() uint64 {\r\n\tc.Lock()\r\n\tdefer c.Unlock()\r\n\treturn c.commitIndex\r\n}","code-length":49,"reference":"\/\/ Called by leader after commitCh is notified","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *commitment) recalculate() {\r\n\tif len(c.matchIndexes) == 0 {\r\n\t\treturn\r\n\t}\r\n\tmatched := make([]uint64, 0, len(c.matchIndexes))\r\n\tfor _, idx := range c.matchIndexes {\r\n\t\tmatched = append(matched, idx)\r\n\t}\r\n\tsort.Sort(uint64Slice(matched))\r\n\tquorumMatchIndex := matched[(len(matched)-1)\/2]\r\n\tif quorumMatchIndex > c.commitIndex && quorumMatchIndex >= c.startIndex {\r\n\t\tc.commitIndex = quorumMatchIndex\r\n\t\tasyncNotifyCh(c.commitCh)\r\n\t}\r\n}","code-length":178,"reference":"\/\/ Internal helper to calculate new commitIndex from matchIndexes.\n\/\/ Must be called with lock held.","result":"Recalculate commit indexes.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc randomTimeout(minVal time.Duration) <-chan time.Time {\r\n\tif minVal == 0 {\r\n\t\treturn nil\r\n\t}\r\n\textra := (time.Duration(rand.Int63()) % minVal)\r\n\treturn time.After(minVal + extra)\r\n}","code-length":79,"reference":"\/\/ randomTimeout returns a value that is between the minVal and 2x minVal.","result":"Generate a random timeout .","score":[0.0485,0.041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc generateUUID() string {\r\n\tbuf := make([]byte, 16)\r\n\tif _, err := crand.Read(buf); err != nil {\r\n\t\tpanic(fmt.Errorf(\"failed to read random bytes: %v\", err))\r\n\t}\r\n\treturn fmt.Sprintf(\"%08x-%04x-%04x-%04x-%12x\",\r\n\t\tbuf[0:4],\r\n\t\tbuf[4:6],\r\n\t\tbuf[6:8],\r\n\t\tbuf[8:10],\r\n\t\tbuf[10:16])\r\n}","code-length":149,"reference":"\/\/ generateUUID is used to generate a random UUID.","result":"Generate a random UUID.","score":[0.1885,0.4669]}
{"code":"\/*is used to<extra_id_0>\r\nfunc decodeMsgPack(buf []byte, out interface{}) error {\r\n\tr := bytes.NewBuffer(buf)\r\n\thd := codec.MsgpackHandle{}\r\n\tdec := codec.NewDecoder(r, &hd)\r\n\treturn dec.Decode(out)\r\n}","code-length":75,"reference":"\/\/ Decode reverses the encode operation on a byte slice input.","result":"Decode a message.","score":[0.0337,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc encodeMsgPack(in interface{}) (*bytes.Buffer, error) {\r\n\tbuf := bytes.NewBuffer(nil)\r\n\thd := codec.MsgpackHandle{}\r\n\tenc := codec.NewEncoder(buf, &hd)\r\n\terr := enc.Encode(in)\r\n\treturn buf, err\r\n}","code-length":86,"reference":"\/\/ Encode writes an encoded object to a new bytes buffer.","result":"Encode a message.","score":[0.0337,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc backoff(base time.Duration, round, limit uint64) time.Duration {\r\n\tpower := min(round, limit)\r\n\tfor power > 2 {\r\n\t\tbase *= 2\r\n\t\tpower--\r\n\t}\r\n\treturn base\r\n}","code-length":71,"reference":"\/\/ backoff is used to compute an exponential backoff\n\/\/ duration. Base time is scaled by the current round,\n\/\/ up to some maximum scale factor.","result":"Generate the code.","score":[0.0002,0.0211]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newApplySource(seed string) *applySource {\r\n\th := fnv.New32()\r\n\th.Write([]byte(seed))\r\n\ts := &applySource{seed: int64(h.Sum32())}\r\n\ts.reset()\r\n\treturn s\r\n}","code-length":79,"reference":"\/\/ newApplySource will create a new source, any source created with the same seed will generate the same sequence of data.","result":"Create a new applySource.","score":[0.0064,0.1526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *applySource) reset() {\r\n\ta.rnd = rand.New(rand.NewSource(a.seed))\r\n}","code-length":43,"reference":"\/\/ reset this source back to its initial state, it'll generate the same sequence of data it initially did","result":"Reset the source.","score":[0.002,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DefaultConfig() *Config {\r\n\treturn &Config{\r\n\t\tProtocolVersion:    ProtocolVersionMax,\r\n\t\tHeartbeatTimeout:   1000 * time.Millisecond,\r\n\t\tElectionTimeout:    1000 * time.Millisecond,\r\n\t\tCommitTimeout:      50 * time.Millisecond,\r\n\t\tMaxAppendEntries:   64,\r\n\t\tShutdownOnRemove:   true,\r\n\t\tTrailingLogs:       10240,\r\n\t\tSnapshotInterval:   120 * time.Second,\r\n\t\tSnapshotThreshold:  8192,\r\n\t\tLeaderLeaseTimeout: 500 * time.Millisecond,\r\n\t\tLogLevel:           \"DEBUG\",\r\n\t}\r\n}","code-length":172,"reference":"\/\/ DefaultConfig returns a Config with usable defaults.","result":"Initialize the default config.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ValidateConfig(config *Config) error {\r\n\t\r\n\t\r\n\tprotocolMin := ProtocolVersionMin\r\n\tif protocolMin == 0 {\r\n\t\tprotocolMin = 1\r\n\t}\r\n\tif config.ProtocolVersion < protocolMin ||\r\n\t\tconfig.ProtocolVersion > ProtocolVersionMax {\r\n\t\treturn fmt.Errorf(\"Protocol version %d must be >= %d and <= %d\",\r\n\t\t\tconfig.ProtocolVersion, protocolMin, ProtocolVersionMax)\r\n\t}\r\n\tif len(config.LocalID) == 0 {\r\n\t\treturn fmt.Errorf(\"LocalID cannot be empty\")\r\n\t}\r\n\tif config.HeartbeatTimeout < 5*time.Millisecond {\r\n\t\treturn fmt.Errorf(\"Heartbeat timeout is too low\")\r\n\t}\r\n\tif config.ElectionTimeout < 5*time.Millisecond {\r\n\t\treturn fmt.Errorf(\"Election timeout is too low\")\r\n\t}\r\n\tif config.CommitTimeout < time.Millisecond {\r\n\t\treturn fmt.Errorf(\"Commit timeout is too low\")\r\n\t}\r\n\tif config.MaxAppendEntries <= 0 {\r\n\t\treturn fmt.Errorf(\"MaxAppendEntries must be positive\")\r\n\t}\r\n\tif config.MaxAppendEntries > 1024 {\r\n\t\treturn fmt.Errorf(\"MaxAppendEntries is too large\")\r\n\t}\r\n\tif config.SnapshotInterval < 5*time.Millisecond {\r\n\t\treturn fmt.Errorf(\"Snapshot interval is too low\")\r\n\t}\r\n\tif config.LeaderLeaseTimeout < 5*time.Millisecond {\r\n\t\treturn fmt.Errorf(\"Leader lease timeout is too low\")\r\n\t}\r\n\tif config.LeaderLeaseTimeout > config.HeartbeatTimeout {\r\n\t\treturn fmt.Errorf(\"Leader lease timeout cannot be larger than heartbeat timeout\")\r\n\t}\r\n\tif config.ElectionTimeout < config.HeartbeatTimeout {\r\n\t\treturn fmt.Errorf(\"Election timeout must be equal or greater than Heartbeat Timeout\")\r\n\t}\r\n\treturn nil\r\n}","code-length":481,"reference":"\/\/ ValidateConfig is used to validate a sane configuration","result":"Validate the config.","score":[0,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) runSnapshots() {\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase <-randomTimeout(r.conf.SnapshotInterval):\r\n\t\t\t\r\n\t\t\tif !r.shouldSnapshot() {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif _, err := r.takeSnapshot(); err != nil {\r\n\t\t\t\tr.logger.Error(fmt.Sprintf(\"Failed to take snapshot: %v\", err))\r\n\t\t\t}\r\n\t\tcase future := <-r.userSnapshotCh:\r\n\t\t\t\r\n\t\t\tid, err := r.takeSnapshot()\r\n\t\t\tif err != nil {\r\n\t\t\t\tr.logger.Error(fmt.Sprintf(\"Failed to take snapshot: %v\", err))\r\n\t\t\t} else {\r\n\t\t\t\tfuture.opener = func() (*SnapshotMeta, io.ReadCloser, error) {\r\n\t\t\t\t\treturn r.snapshots.Open(id)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tfuture.respond(err)\r\n\t\tcase <-r.shutdownCh:\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":278,"reference":"\/\/ runSnapshots is a long running goroutine used to manage taking\n\/\/ new snapshots of the FSM. It runs in parallel to the FSM and\n\/\/ main goroutines, so that snapshots do not block normal operation.","result":"Run the snapshot routine .","score":[0.0005,0.0456]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) shouldSnapshot() bool {\r\n\t\r\n\tlastSnap, _ := r.getLastSnapshot()\r\n\t\r\n\tlastIdx, err := r.logs.LastIndex()\r\n\tif err != nil {\r\n\t\tr.logger.Error(fmt.Sprintf(\"Failed to get last log index: %v\", err))\r\n\t\treturn false\r\n\t}\r\n\t\r\n\tdelta := lastIdx - lastSnap\r\n\treturn delta >= r.conf.SnapshotThreshold\r\n}","code-length":129,"reference":"\/\/ shouldSnapshot checks if we meet the conditions to take\n\/\/ a new snapshot.","result":"Create a new function to create a new snapshot.","score":[0.1547,0.2778]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) takeSnapshot() (string, error) {\r\n\tdefer metrics.MeasureSince([]string{\"raft\", \"snapshot\", \"takeSnapshot\"}, time.Now())\r\n\t\r\n\tsnapReq := &reqSnapshotFuture{}\r\n\tsnapReq.init()\r\n\t\r\n\tselect {\r\n\tcase r.fsmSnapshotCh <- snapReq:\r\n\tcase <-r.shutdownCh:\r\n\t\treturn \"\", ErrRaftShutdown\r\n\t}\r\n\t\r\n\tif err := snapReq.Error(); err != nil {\r\n\t\tif err != ErrNothingNewToSnapshot {\r\n\t\t\terr = fmt.Errorf(\"failed to start snapshot: %v\", err)\r\n\t\t}\r\n\t\treturn \"\", err\r\n\t}\r\n\tdefer snapReq.snapshot.Release()\r\n\t\r\n\t\r\n\t\r\n\tconfigReq := &configurationsFuture{}\r\n\tconfigReq.init()\r\n\tselect {\r\n\tcase r.configurationsCh <- configReq:\r\n\tcase <-r.shutdownCh:\r\n\t\treturn \"\", ErrRaftShutdown\r\n\t}\r\n\tif err := configReq.Error(); err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tcommitted := configReq.configurations.committed\r\n\tcommittedIndex := configReq.configurations.committedIndex\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif snapReq.index < committedIndex {\r\n\t\treturn \"\", fmt.Errorf(\"cannot take snapshot now, wait until the configuration entry at %v has been applied (have applied %v)\",\r\n\t\t\tcommittedIndex, snapReq.index)\r\n\t}\r\n\t\r\n\tr.logger.Info(fmt.Sprintf(\"Starting snapshot up to %d\", snapReq.index))\r\n\tstart := time.Now()\r\n\tversion := getSnapshotVersion(r.protocolVersion)\r\n\tsink, err := r.snapshots.Create(version, snapReq.index, snapReq.term, committed, committedIndex, r.trans)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"failed to create snapshot: %v\", err)\r\n\t}\r\n\tmetrics.MeasureSince([]string{\"raft\", \"snapshot\", \"create\"}, start)\r\n\t\r\n\tstart = time.Now()\r\n\tif err := snapReq.snapshot.Persist(sink); err != nil {\r\n\t\tsink.Cancel()\r\n\t\treturn \"\", fmt.Errorf(\"failed to persist snapshot: %v\", err)\r\n\t}\r\n\tmetrics.MeasureSince([]string{\"raft\", \"snapshot\", \"persist\"}, start)\r\n\t\r\n\tif err := sink.Close(); err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"failed to close snapshot: %v\", err)\r\n\t}\r\n\t\r\n\tr.setLastSnapshot(snapReq.index, snapReq.term)\r\n\t\r\n\tif err := r.compactLogs(snapReq.index); err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tr.logger.Info(fmt.Sprintf(\"Snapshot to %d complete\", snapReq.index))\r\n\treturn sink.ID(), nil\r\n}","code-length":764,"reference":"\/\/ takeSnapshot is used to take a new snapshot. This must only be called from\n\/\/ the snapshot thread, never the main thread. This returns the ID of the new\n\/\/ snapshot, along with an error.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Raft) compactLogs(snapIdx uint64) error {\r\n\tdefer metrics.MeasureSince([]string{\"raft\", \"compactLogs\"}, time.Now())\r\n\t\r\n\tminLog, err := r.logs.FirstIndex()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to get first log index: %v\", err)\r\n\t}\r\n\t\r\n\tlastLogIdx, _ := r.getLastLog()\r\n\tif lastLogIdx <= r.conf.TrailingLogs {\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tmaxLog := min(snapIdx, lastLogIdx-r.conf.TrailingLogs)\r\n\t\r\n\tr.logger.Info(fmt.Sprintf(\"Compacting logs from %d to %d\", minLog, maxLog))\r\n\t\r\n\tif err := r.logs.DeleteRange(minLog, maxLog); err != nil {\r\n\t\treturn fmt.Errorf(\"log compaction failed: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":266,"reference":"\/\/ compactLogs takes the last inclusive index of a snapshot\n\/\/ and trims the logs that are no longer needed.","result":"Avoid the need for a function to be called.","score":[0.0427,0.0794]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WebpackCheck(r *Runner) error {\r\n\tfmt.Println(\"~~~ Checking webpack.config.js ~~~\")\r\n\tif !r.App.WithWebpack {\r\n\t\treturn nil\r\n\t}\r\n\tbox := webpack.Templates\r\n\tf, err := box.FindString(\"webpack.config.js.tmpl\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ttmpl, err := template.New(\"webpack\").Parse(f)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tbb := &bytes.Buffer{}\r\n\terr = tmpl.Execute(bb, map[string]interface{}{\r\n\t\t\"opts\": &webpack.Options{\r\n\t\t\tApp: r.App,\r\n\t\t},\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tb, err := ioutil.ReadFile(\"webpack.config.js\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif string(b) == bb.String() {\r\n\t\treturn nil\r\n\t}\r\n\tif !ask(\"Your webpack.config.js file is different from the latest Buffalo template.\\nWould you like to replace yours with the latest template?\") {\r\n\t\tfmt.Println(\"\\tSkipping webpack.config.js\")\r\n\t\treturn nil\r\n\t}\r\n\twf, err := os.Create(\"webpack.config.js\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t_, err = wf.Write(bb.Bytes())\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn wf.Close()\r\n}","code-length":427,"reference":"\/\/ WebpackCheck will compare the current default Buffalo\n\/\/ webpack.config.js against the applications webpack.config.js. If they are\n\/\/ different you have the option to overwrite the existing webpack.config.js\n\/\/ file with the new one.","result":"Check the webpack.","score":[0.0,0.0162]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Generator, error) {\r\n\tg := genny.New()\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn g, err\r\n\t}\r\n\tif opts.Provider == \"none\" {\r\n\t\treturn g, nil\r\n\t}\r\n\tbox := packr.New(\"buffalo:genny:vcs\", \"..\/vcs\/templates\")\r\n\ts, err := box.FindString(\"ignore.tmpl\")\r\n\tif err != nil {\r\n\t\treturn g, err\r\n\t}\r\n\tp := opts.Provider\r\n\tn := fmt.Sprintf(\".%signore\", p)\r\n\tg.File(genny.NewFileS(n, s))\r\n\tg.Command(exec.Command(p, \"init\"))\r\n\targs := []string{\"add\", \".\"}\r\n\tif p == \"bzr\" {\r\n\t\t\r\n\t\targs = append(args, \"-q\")\r\n\t}\r\n\tg.Command(exec.Command(p, args...))\r\n\tg.Command(exec.Command(p, \"commit\", \"-q\", \"-m\", \"Initial Commit\"))\r\n\treturn g, nil\r\n}","code-length":302,"reference":"\/\/ New generator for adding VCS to an application","result":"Generate the generator.","score":[0,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UnixSocket(addr string) (*Listener, error) {\r\n\tlistener, err := net.Listen(\"unix\", addr)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &Listener{\r\n\t\tServer:   &http.Server{},\r\n\t\tListener: listener,\r\n\t}, nil\r\n}","code-length":94,"reference":"\/\/ UnixSocket returns a new Listener on that address","result":"Listen on unix socket.","score":[0.0915,0.2206]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e ErrorHandlers) Get(status int) ErrorHandler {\r\n\tif eh, ok := e[status]; ok {\r\n\t\treturn eh\r\n\t}\r\n\tif eh, ok := e[0]; ok {\r\n\t\treturn eh\r\n\t}\r\n\treturn defaultErrorHandler\r\n}","code-length":79,"reference":"\/\/ Get a registered ErrorHandler for this status code. If\n\/\/ no ErrorHandler has been registered, a default one will\n\/\/ be returned.","result":"Get error handlers for status.","score":[0.0078,0.0472]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *App) PanicHandler(next Handler) Handler {\r\n\treturn func(c Context) error {\r\n\t\tdefer func() {\r\n\t\t\tr := recover()\r\n\t\t\tvar err error\r\n\t\t\tif r != nil {\r\n\t\t\t\tswitch t := r.(type) {\r\n\t\t\t\tcase error:\r\n\t\t\t\t\terr = t\r\n\t\t\t\tcase string:\r\n\t\t\t\t\terr = errors.New(t)\r\n\t\t\t\tdefault:\r\n\t\t\t\t\terr = errors.New(fmt.Sprint(t))\r\n\t\t\t\t}\r\n\t\t\t\terr = err\r\n\t\t\t\tevents.EmitError(events.ErrPanic, err,\r\n\t\t\t\t\tmap[string]interface{}{\r\n\t\t\t\t\t\t\"context\": c,\r\n\t\t\t\t\t\t\"app\":     a,\r\n\t\t\t\t\t},\r\n\t\t\t\t)\r\n\t\t\t\teh := a.ErrorHandlers.Get(500)\r\n\t\t\t\teh(500, err, c)\r\n\t\t\t}\r\n\t\t}()\r\n\t\treturn next(c)\r\n\t}\r\n}","code-length":259,"reference":"\/\/ PanicHandler recovers from panics gracefully and calls\n\/\/ the error handling code for a 500 error.","result":"Handle panic in the application.","score":[0.0218,0.0949]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s templateRenderer) partialFeeder(name string) (string, error) {\r\n\tct := strings.ToLower(s.contentType)\r\n\td, f := filepath.Split(name)\r\n\tname = filepath.Join(d, \"_\"+f)\r\n\tname = fixExtension(name, ct)\r\n\treturn s.TemplatesBox.FindString(name)\r\n}","code-length":99,"reference":"\/\/ partialFeeder returns template string for the name from `TemplateBox`.\n\/\/ It should be registered as helper named `partialFeeder` so plush can\n\/\/ find it with the name.","result":"Generate feeder templates.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts Options) *Engine {\r\n\tif opts.Helpers == nil {\r\n\t\topts.Helpers = map[string]interface{}{}\r\n\t}\r\n\tif opts.TemplateEngines == nil {\r\n\t\topts.TemplateEngines = map[string]TemplateEngine{}\r\n\t}\r\n\tif _, ok := opts.TemplateEngines[\"html\"]; !ok {\r\n\t\topts.TemplateEngines[\"html\"] = plush.BuffaloRenderer\r\n\t}\r\n\tif _, ok := opts.TemplateEngines[\"text\"]; !ok {\r\n\t\topts.TemplateEngines[\"text\"] = plush.BuffaloRenderer\r\n\t}\r\n\tif _, ok := opts.TemplateEngines[\"txt\"]; !ok {\r\n\t\topts.TemplateEngines[\"txt\"] = plush.BuffaloRenderer\r\n\t}\r\n\tif _, ok := opts.TemplateEngines[\"js\"]; !ok {\r\n\t\topts.TemplateEngines[\"js\"] = plush.BuffaloRenderer\r\n\t}\r\n\tif _, ok := opts.TemplateEngines[\"md\"]; !ok {\r\n\t\topts.TemplateEngines[\"md\"] = MDTemplateEngine\r\n\t}\r\n\tif _, ok := opts.TemplateEngines[\"tmpl\"]; !ok {\r\n\t\topts.TemplateEngines[\"tmpl\"] = GoTemplateEngine\r\n\t}\r\n\tif opts.DefaultContentType == \"\" {\r\n\t\topts.DefaultContentType = \"text\/html; charset=utf-8\"\r\n\t}\r\n\te := &Engine{\r\n\t\tOptions: opts,\r\n\t}\r\n\treturn e\r\n}","code-length":399,"reference":"\/\/ New render.Engine ready to go with your Options\n\/\/ and some defaults we think you might like.","result":"Create a new engine.","score":[0,0.0301]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) WriteTo(w io.Writer) (int64, error) {\r\n\tmw := &messageWriter{w: w}\r\n\tmw.writeMessage(m)\r\n\treturn mw.n, mw.err\r\n}","code-length":68,"reference":"\/\/ WriteTo implements io.WriterTo. It dumps the whole message into w.","result":"Write message to.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (sm SMTPSender) Send(message Message) error {\r\n\tgm := gomail.NewMessage()\r\n\tgm.SetHeader(\"From\", message.From)\r\n\tgm.SetHeader(\"To\", message.To...)\r\n\tgm.SetHeader(\"Subject\", message.Subject)\r\n\tgm.SetHeader(\"Cc\", message.CC...)\r\n\tgm.SetHeader(\"Bcc\", message.Bcc...)\r\n\tsm.addBodies(message, gm)\r\n\tsm.addAttachments(message, gm)\r\n\tfor field, value := range message.Headers {\r\n\t\tgm.SetHeader(field, value)\r\n\t}\r\n\terr := sm.Dialer.DialAndSend(gm)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":204,"reference":"\/\/Send a message using SMTP configuration or returns an error if something goes wrong.","result":"Send messages.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSMTPSender(host string, port string, user string, password string) (SMTPSender, error) {\r\n\tiport, err := strconv.Atoi(port)\r\n\tif err != nil {\r\n\t\treturn SMTPSender{}, errors.New(\"invalid port for the SMTP mail\")\r\n\t}\r\n\tdialer := &gomail.Dialer{\r\n\t\tHost: host,\r\n\t\tPort: iport,\r\n\t}\r\n\tif user != \"\" {\r\n\t\tdialer.Username = user\r\n\t\tdialer.Password = password\r\n\t}\r\n\treturn SMTPSender{\r\n\t\tDialer: dialer,\r\n\t}, nil\r\n}","code-length":177,"reference":"\/\/NewSMTPSender builds a SMTP mail based in passed config.","result":"Create a new sender.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DefaultContext) Param(key string) string {\r\n\treturn d.Params().Get(key)\r\n}","code-length":38,"reference":"\/\/ Param returns a param, either named or query string,\n\/\/ based on the key.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DefaultContext) Set(key string, value interface{}) {\r\n\td.moot.Lock()\r\n\td.data[key] = value\r\n\td.moot.Unlock()\r\n}","code-length":60,"reference":"\/\/ Set a value onto the Context. Any value set onto the Context\n\/\/ will be automatically available in templates.","result":"Set the value of a key in the default context.","score":[0.0625,0.1842]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DefaultContext) Value(key interface{}) interface{} {\r\n\tif k, ok := key.(string); ok {\r\n\t\td.moot.RLock()\r\n\t\tdefer d.moot.RUnlock()\r\n\t\tif v, ok := d.data[k]; ok {\r\n\t\t\treturn v\r\n\t\t}\r\n\t}\r\n\treturn d.Context.Value(key)\r\n}","code-length":112,"reference":"\/\/ Value that has previously stored on the context.","result":"Access the value of a context value.","score":[0.1214,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DefaultContext) Redirect(status int, url string, args ...interface{}) error {\r\n\td.Flash().persist(d.Session())\r\n\tif strings.HasSuffix(url, \"Path()\") {\r\n\t\tif len(args) > 1 {\r\n\t\t\treturn fmt.Errorf(\"you must pass only a map[string]interface{} to a route path: %T\", args)\r\n\t\t}\r\n\t\tvar m map[string]interface{}\r\n\t\tif len(args) == 1 {\r\n\t\t\trv := reflect.Indirect(reflect.ValueOf(args[0]))\r\n\t\t\tif !rv.Type().ConvertibleTo(mapType) {\r\n\t\t\t\treturn fmt.Errorf(\"you must pass only a map[string]interface{} to a route path: %T\", args)\r\n\t\t\t}\r\n\t\t\tm = rv.Convert(mapType).Interface().(map[string]interface{})\r\n\t\t}\r\n\t\th, ok := d.Value(strings.TrimSuffix(url, \"()\")).(RouteHelperFunc)\r\n\t\tif !ok {\r\n\t\t\treturn fmt.Errorf(\"could not find a route helper named %s\", url)\r\n\t\t}\r\n\t\turl, err := h(m)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\thttp.Redirect(d.Response(), d.Request(), string(url), status)\r\n\t\treturn nil\r\n\t}\r\n\tif len(args) > 0 {\r\n\t\turl = fmt.Sprintf(url, args...)\r\n\t}\r\n\thttp.Redirect(d.Response(), d.Request(), url, status)\r\n\treturn nil\r\n}","code-length":414,"reference":"\/\/ Redirect a request with the given status to the given URL.","result":"Redirect to a specific URL.","score":[0.0838,0.177]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DefaultContext) File(name string) (binding.File, error) {\r\n\treq := d.Request()\r\n\tif err := req.ParseMultipartForm(5 * 1024 * 1024); err != nil {\r\n\t\treturn binding.File{}, err\r\n\t}\r\n\tf, h, err := req.FormFile(name)\r\n\tbf := binding.File{\r\n\t\tFile:       f,\r\n\t\tFileHeader: h,\r\n\t}\r\n\tif err != nil {\r\n\t\treturn bf, err\r\n\t}\r\n\treturn bf, nil\r\n}","code-length":152,"reference":"\/\/ File returns an uploaded file by name, or an error","result":"Generate the file binding.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DefaultContext) MarshalJSON() ([]byte, error) {\r\n\tm := map[string]interface{}{}\r\n\tdata := d.Data()\r\n\tfor k, v := range data {\r\n\t\t\r\n\t\tif _, ok := v.(*DefaultContext); ok {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif _, err := json.Marshal(v); err == nil {\r\n\t\t\t\r\n\t\t\tm[k] = v\r\n\t\t}\r\n\t}\r\n\treturn json.Marshal(m)\r\n}","code-length":141,"reference":"\/\/ MarshalJSON implements json marshaling for the context","result":"Serialize the context.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Group, error) {\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tgg, err := core.New(opts.Options)\r\n\tif err != nil {\r\n\t\treturn gg, err\r\n\t}\r\n\tg := genny.New()\r\n\tdata := map[string]interface{}{\r\n\t\t\"opts\": opts,\r\n\t}\r\n\thelpers := template.FuncMap{}\r\n\tt := gogen.TemplateTransformer(data, helpers)\r\n\tg.Transformer(t)\r\n\tg.Box(packr.New(\"buffalo:genny:newapp:api\", \"..\/api\/templates\"))\r\n\tgg.Add(g)\r\n\treturn gg, nil\r\n}","code-length":206,"reference":"\/\/ New generator for creating a Buffalo API application","result":"Create a new app.","score":[0.0915,0.3007]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts Options) *App {\r\n\tLoadPlugins()\r\n\tenvy.Load()\r\n\topts = optionsWithDefaults(opts)\r\n\ta := &App{\r\n\t\tOptions: opts,\r\n\t\tErrorHandlers: ErrorHandlers{\r\n\t\t\t404: defaultErrorHandler,\r\n\t\t\t500: defaultErrorHandler,\r\n\t\t},\r\n\t\trouter:   mux.NewRouter(),\r\n\t\tmoot:     &sync.RWMutex{},\r\n\t\troutes:   RouteList{},\r\n\t\tchildren: []*App{},\r\n\t}\r\n\tdem := a.defaultErrorMiddleware\r\n\ta.Middleware = newMiddlewareStack(dem)\r\n\tnotFoundHandler := func(errorf string, code int) http.HandlerFunc {\r\n\t\treturn func(res http.ResponseWriter, req *http.Request) {\r\n\t\t\tc := a.newContext(RouteInfo{}, res, req)\r\n\t\t\terr := fmt.Errorf(errorf, req.Method, req.URL.Path)\r\n\t\t\ta.ErrorHandlers.Get(code)(code, err, c)\r\n\t\t}\r\n\t}\r\n\ta.router.NotFoundHandler = notFoundHandler(\"path not found: %s %s\", 404)\r\n\ta.router.MethodNotAllowedHandler = notFoundHandler(\"method not found: %s %s\", 405)\r\n\tif a.MethodOverride == nil {\r\n\t\ta.MethodOverride = MethodOverride\r\n\t}\r\n\ta.Use(a.PanicHandler)\r\n\ta.Use(RequestLogger)\r\n\ta.Use(sessionSaver)\r\n\treturn a\r\n}","code-length":396,"reference":"\/\/ New returns a new instance of App and adds some sane, and useful, defaults.","result":"Create a new app.","score":[0.0289,0.1349]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DeprecrationsCheck(r *Runner) error {\r\n\tfmt.Println(\"~~~ Checking for deprecations ~~~\")\r\n\tb, err := ioutil.ReadFile(\"main.go\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif bytes.Contains(b, []byte(\"app.Start\")) {\r\n\t\tr.Warnings = append(r.Warnings, \"app.Start has been removed in v0.11.0. Use app.Serve Instead. [main.go]\")\r\n\t}\r\n\treturn filepath.Walk(filepath.Join(r.App.Root, \"actions\"), func(path string, info os.FileInfo, _ error) error {\r\n\t\tif info.IsDir() {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tif filepath.Ext(path) != \".go\" {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tb, err := ioutil.ReadFile(path)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif bytes.Contains(b, []byte(\"Websocket()\")) {\r\n\t\t\tr.Warnings = append(r.Warnings, fmt.Sprintf(\"buffalo.Context#Websocket has been deprecated in v0.11.0, and removed in v0.12.0. Use github.com\/gorilla\/websocket directly. [%s]\", path))\r\n\t\t}\r\n\t\tif bytes.Contains(b, []byte(\"meta.Name\")) {\r\n\t\t\tr.Warnings = append(r.Warnings, fmt.Sprintf(\"meta.Name has been deprecated in v0.11.0, and removed in v0.12.0. Use github.com\/markbates\/inflect.Name directly. [%s]\", path))\r\n\t\t}\r\n\t\tif bytes.Contains(b, []byte(\"generators.Find(\")) {\r\n\t\t\tr.Warnings = append(r.Warnings, fmt.Sprintf(\"generators.Find(string) has been deprecated in v0.11.0, and removed in v0.12.0. Use generators.FindByBox() instead. [%s]\", path))\r\n\t\t}\r\n\t\t\r\n\t\tif bytes.Contains(b, []byte(\"T.CookieName\")) {\r\n\t\t\tb = bytes.Replace(b, []byte(\"T.CookieName\"), []byte(\"T.LanguageExtractorOptions[\\\"CookieName\\\"]\"), -1)\r\n\t\t}\r\n\t\tif bytes.Contains(b, []byte(\"T.SessionName\")) {\r\n\t\t\tb = bytes.Replace(b, []byte(\"T.SessionName\"), []byte(\"T.LanguageExtractorOptions[\\\"SessionName\\\"]\"), -1)\r\n\t\t}\r\n\t\tif bytes.Contains(b, []byte(\"T.LanguageFinder=\")) || bytes.Contains(b, []byte(\"T.LanguageFinder \")) {\r\n\t\t\tr.Warnings = append(r.Warnings, fmt.Sprintf(\"i18n.Translator#LanguageFinder has been deprecated in v0.11.1, and has been removed in v0.12.0. Use i18n.Translator#LanguageExtractors instead. [%s]\", path))\r\n\t\t}\r\n\t\tioutil.WriteFile(path, b, 0664)\r\n\t\treturn nil\r\n\t})\r\n}","code-length":794,"reference":"\/\/ DeprecrationsCheck will either log, or fix, deprecated items in the application","result":"Code too long,keep in 512.","score":[0.0593,0.0442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v BaseResource) List(c Context) error {\r\n\treturn c.Error(404, errors.New(\"resource not implemented\"))\r\n}","code-length":44,"reference":"\/\/ List default implementation. Returns a 404","result":"Generate the list of resources.","score":[0,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s funcRenderer) Render(w io.Writer, data Data) error {\r\n\treturn s.renderFunc(w, data)\r\n}","code-length":43,"reference":"\/\/ Render the provided Data to the provider Writer using the\n\/\/ RendererFunc provide.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Session) Save() error {\r\n\treturn s.Session.Save(s.req, s.res)\r\n}","code-length":40,"reference":"\/\/ Save the current session.","result":"Save the session.","score":[0.328,0.5324]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Session) GetOnce(name interface{}) interface{} {\r\n\tif x, ok := s.Session.Values[name]; ok {\r\n\t\ts.Delete(name)\r\n\t\treturn x\r\n\t}\r\n\treturn nil\r\n}","code-length":71,"reference":"\/\/ GetOnce gets a value from the current session and then deletes it.","result":"Get the value of a session value.","score":[0.0969,0.2016]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Session) Set(name, value interface{}) {\r\n\ts.Session.Values[name] = value\r\n}","code-length":40,"reference":"\/\/ Set a value onto the current session. If a value with that name\n\/\/ already exists it will be overridden with the new value.","result":"Set values in session.","score":[0.002,0.0655]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Session) Clear() {\r\n\tfor k := range s.Session.Values {\r\n\t\ts.Delete(k)\r\n\t}\r\n}","code-length":48,"reference":"\/\/ Clear the current session","result":"Clear the session.","score":[0.2964,0.3906]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *App) getSession(r *http.Request, w http.ResponseWriter) *Session {\r\n\tif a.root != nil {\r\n\t\treturn a.root.getSession(r, w)\r\n\t}\r\n\tsession, _ := a.SessionStore.Get(r, a.SessionName)\r\n\treturn &Session{\r\n\t\tSession: session,\r\n\t\treq:     r,\r\n\t\tres:     w,\r\n\t}\r\n}","code-length":123,"reference":"\/\/ Get a session using a request and response.","result":"Get the session from the session store.","score":[0.1443,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Generator, error) {\r\n\tg := genny.New()\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn g, err\r\n\t}\r\n\tdata := map[string]interface{}{\r\n\t\t\"opts\": opts,\r\n\t}\r\n\tt := gogen.TemplateTransformer(data, template.FuncMap{})\r\n\tg.Transformer(t)\r\n\tg.RunFn(func(r *genny.Runner) error {\r\n\t\treturn genFile(r, opts)\r\n\t})\r\n\treturn g, nil\r\n}","code-length":160,"reference":"\/\/ New generator to create a grift task","result":"Generate the generator.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Generator, error) {\r\n\tg := genny.New()\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn g, err\r\n\t}\r\n\tg.RunFn(func(r *genny.Runner) error {\r\n\t\tif _, err := r.LookPath(\"npm\"); err != nil {\r\n\t\t\treturn errors.New(\"could not find npm executable\")\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tg.Box(Templates)\r\n\tdata := map[string]interface{}{\r\n\t\t\"opts\": opts,\r\n\t}\r\n\tt := gogen.TemplateTransformer(data, gogen.TemplateHelpers)\r\n\tg.Transformer(t)\r\n\tg.Transformer(genny.Dot())\r\n\tg.RunFn(func(r *genny.Runner) error {\r\n\t\treturn installPkgs(r, opts)\r\n\t})\r\n\treturn g, nil\r\n}","code-length":251,"reference":"\/\/ New generator for creating webpack asset files","result":"Create a new generator.","score":[0,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Generator, error) {\r\n\tg := genny.New()\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn g, err\r\n\t}\r\n\tg.Box(packr.New(\"buffalo:genny:refresh\", \"..\/refresh\/templates\"))\r\n\tctx := plush.NewContext()\r\n\tctx.Set(\"app\", opts.App)\r\n\tg.Transformer(plushgen.Transformer(ctx))\r\n\tg.Transformer(genny.Dot())\r\n\treturn g, nil\r\n}","code-length":151,"reference":"\/\/ New generator to generate refresh templates","result":"Generate the generator.","score":[0,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMessage(settings ...MessageSetting) *Message {\r\n\tm := &Message{\r\n\t\theader:   make(header),\r\n\t\tcharset:  \"UTF-8\",\r\n\t\tencoding: QuotedPrintable,\r\n\t}\r\n\tm.applySettings(settings)\r\n\tif m.encoding == Base64 {\r\n\t\tm.hEncoder = bEncoding\r\n\t} else {\r\n\t\tm.hEncoder = qEncoding\r\n\t}\r\n\treturn m\r\n}","code-length":128,"reference":"\/\/ NewMessage creates a new message. It uses UTF-8 and quoted-printable encoding\n\/\/ by default.","result":"Create a new message.","score":[0.0421,0.2855]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) Reset() {\r\n\tfor k := range m.header {\r\n\t\tdelete(m.header, k)\r\n\t}\r\n\tm.parts = nil\r\n\tm.attachments = nil\r\n\tm.embedded = nil\r\n}","code-length":72,"reference":"\/\/ Reset resets the message so it can be reused. The message keeps its previous\n\/\/ settings so it is in the same state that after a call to NewMessage.","result":"Reset the message.","score":[0.0001,0.0366]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) SetHeader(field string, value ...string) {\r\n\tm.encodeHeader(value)\r\n\tm.header[field] = value\r\n}","code-length":50,"reference":"\/\/ SetHeader sets a value to the given header field.","result":"Set header fields.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) SetHeaders(h map[string][]string) {\r\n\tfor k, v := range h {\r\n\t\tm.SetHeader(k, v...)\r\n\t}\r\n}","code-length":58,"reference":"\/\/ SetHeaders sets the message headers.","result":"Set headers in the message.","score":[0.1967,0.1695]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) SetAddressHeader(field, address, name string) {\r\n\tm.header[field] = []string{m.FormatAddress(address, name)}\r\n}","code-length":52,"reference":"\/\/ SetAddressHeader sets an address to the given header field.","result":"Set address header.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) FormatAddress(address, name string) string {\r\n\tif name == \"\" {\r\n\t\treturn address\r\n\t}\r\n\tenc := m.encodeString(name)\r\n\tif enc == name {\r\n\t\tm.buf.WriteByte('\"')\r\n\t\tfor i := 0; i < len(name); i++ {\r\n\t\t\tb := name[i]\r\n\t\t\tif b == '\\\\' || b == '\"' {\r\n\t\t\t\tm.buf.WriteByte('\\\\')\r\n\t\t\t}\r\n\t\t\tm.buf.WriteByte(b)\r\n\t\t}\r\n\t\tm.buf.WriteByte('\"')\r\n\t} else if hasSpecials(name) {\r\n\t\tm.buf.WriteString(bEncoding.Encode(m.charset, name))\r\n\t} else {\r\n\t\tm.buf.WriteString(enc)\r\n\t}\r\n\tm.buf.WriteString(\" <\")\r\n\tm.buf.WriteString(address)\r\n\tm.buf.WriteByte('>')\r\n\taddr := m.buf.String()\r\n\tm.buf.Reset()\r\n\treturn addr\r\n}","code-length":288,"reference":"\/\/ FormatAddress formats an address and a name as a valid RFC 5322 address.","result":"Format addresses in the form of a string.","score":[0.0656,0.1119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) SetDateHeader(field string, date time.Time) {\r\n\tm.header[field] = []string{m.FormatDate(date)}\r\n}","code-length":51,"reference":"\/\/ SetDateHeader sets a date to the given header field.","result":"Set the date header.","score":[0.0848,0.1596]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) FormatDate(date time.Time) string {\r\n\treturn date.Format(time.RFC1123Z)\r\n}","code-length":42,"reference":"\/\/ FormatDate formats a date as a valid RFC 5322 date.","result":"Format the date of the message.","score":[0.0839,0.0952]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) SetBody(contentType, body string, settings ...PartSetting) {\r\n\tm.SetBodyWriter(contentType, newCopier(body), settings...)\r\n}","code-length":51,"reference":"\/\/ SetBody sets the body of the message. It replaces any content previously set\n\/\/ by SetBody, SetBodyWriter, AddAlternative or AddAlternativeWriter.","result":"Set the body of a message.","score":[0.0351,0.1908]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetPartEncoding(e Encoding) PartSetting {\r\n\treturn PartSetting(func(p *part) {\r\n\t\tp.encoding = e\r\n\t})\r\n}","code-length":50,"reference":"\/\/ SetPartEncoding sets the encoding of the part added to the message. By\n\/\/ default, parts use the same encoding than the message.","result":"Set the part encoding .","score":[0.0103,0.0943]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetHeader(h map[string][]string) FileSetting {\r\n\treturn func(f *file) {\r\n\t\tfor k, v := range h {\r\n\t\t\tf.Header[k] = v\r\n\t\t}\r\n\t}\r\n}","code-length":71,"reference":"\/\/ SetHeader is a file setting to set the MIME header of the message part that\n\/\/ contains the file content.\n\/\/\n\/\/ Mandatory headers are automatically added if they are not set when sending\n\/\/ the email.","result":"Set the header of the file.","score":[0.0021,0.1069]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetCopyFunc(f func(io.Writer) error) FileSetting {\r\n\treturn func(fi *file) {\r\n\t\tfi.CopyFunc = f\r\n\t}\r\n}","code-length":54,"reference":"\/\/ SetCopyFunc is a file setting to replace the function that runs when the\n\/\/ message is sent. It should copy the content of the file to the io.Writer.\n\/\/\n\/\/ The default copy function opens the file with the given filename, and copy\n\/\/ its content to the io.Writer.","result":"Copy files.","score":[0,0.0111]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) AttachReader(name string, r io.Reader, settings ...FileSetting) {\r\n\tm.attachments = m.appendFile(m.attachments, fileFromReader(name, r), settings)\r\n}","code-length":61,"reference":"\/\/ AttachReader attaches a file using an io.Reader","result":"Attach a file to a message.","score":[0.1956,0.1923]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) Attach(filename string, settings ...FileSetting) {\r\n\tm.attachments = m.appendFile(m.attachments, fileFromFilename(filename), settings)\r\n}","code-length":53,"reference":"\/\/ Attach attaches the files to the email.","result":"Add attachments to a message.","score":[0.1319,0.1299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) EmbedReader(name string, r io.Reader, settings ...FileSetting) {\r\n\tm.embedded = m.appendFile(m.embedded, fileFromReader(name, r), settings)\r\n}","code-length":61,"reference":"\/\/ EmbedReader embeds the images to the email.","result":"Embed embedded files.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) Embed(filename string, settings ...FileSetting) {\r\n\tm.embedded = m.appendFile(m.embedded, fileFromFilename(filename), settings)\r\n}","code-length":53,"reference":"\/\/ Embed embeds the images to the email.","result":"Embed messages.","score":[0.0249,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ValidateTemplates(walk packd.Walker, tvs []TemplateValidator) genny.RunFn {\r\n\tif len(tvs) == 0 {\r\n\t\treturn func(r *genny.Runner) error {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t}\r\n\treturn func(r *genny.Runner) error {\r\n\t\tvar errs []string\r\n\t\terr := packd.SkipWalker(walk, packd.CommonSkipPrefixes, func(path string, file packd.File) error {\r\n\t\t\tinfo, err := file.FileInfo()\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif info.IsDir() {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\tf := genny.NewFile(path, file)\r\n\t\t\tfor _, tv := range tvs {\r\n\t\t\t\terr := safe.Run(func() {\r\n\t\t\t\t\tif err := tv(f); err != nil {\r\n\t\t\t\t\t\terrs = append(errs, fmt.Sprintf(\"template error in file %s: %s\", path, err.Error()))\r\n\t\t\t\t\t}\r\n\t\t\t\t})\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t})\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif len(errs) == 0 {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\treturn errors.New(strings.Join(errs, \"\\n\"))\r\n\t}\r\n}","code-length":393,"reference":"\/\/ ValidateTemplates returns a genny.RunFn that will walk the\n\/\/ given box and run each of the files found through each of the\n\/\/ template validators","result":"Validate templates.","score":[0,0.0212]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PlushValidator(f genny.File) error {\r\n\tif !genny.HasExt(f, \".html\", \".md\", \".plush\") {\r\n\t\treturn nil\r\n\t}\r\n\t_, err := plush.Parse(f.String())\r\n\treturn err\r\n}","code-length":80,"reference":"\/\/ PlushValidator validates the file is a valid\n\/\/ Plush file if the extension is .md, .html, or .plush","result":"Validate Plush files.","score":[0.002,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (opts *Options) Validate() error {\r\n\tif opts.App.IsZero() {\r\n\t\topts.App = meta.New(\".\")\r\n\t}\r\n\tif len(opts.Name.String()) == 0 {\r\n\t\treturn errors.New(\"you must supply a name for your mailer\")\r\n\t}\r\n\treturn nil\r\n}","code-length":94,"reference":"\/\/ Validate options are useful","result":"Validate the options.","score":[0.2096,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadPlugins() error {\r\n\tvar err error\r\n\toncer.Do(\"events.LoadPlugins\", func() {\r\n\t\t\r\n\t\tif envy.Get(\"GO_ENV\", \"development\") == \"test\" {\r\n\t\t\treturn\r\n\t\t}\r\n\t\tplugs, err := plugins.Available()\r\n\t\tif err != nil {\r\n\t\t\terr = err\r\n\t\t\treturn\r\n\t\t}\r\n\t\tfor _, cmds := range plugs {\r\n\t\t\tfor _, c := range cmds {\r\n\t\t\t\tif c.BuffaloCommand != \"events\" {\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\terr := func(c plugins.Command) error {\r\n\t\t\t\t\treturn safe.RunE(func() error {\r\n\t\t\t\t\t\tn := fmt.Sprintf(\"[PLUGIN] %s %s\", c.Binary, c.Name)\r\n\t\t\t\t\t\tfn := func(e events.Event) {\r\n\t\t\t\t\t\t\tb, err := json.Marshal(e)\r\n\t\t\t\t\t\t\tif err != nil {\r\n\t\t\t\t\t\t\t\tfmt.Println(\"error trying to marshal event\", e, err)\r\n\t\t\t\t\t\t\t\treturn\r\n\t\t\t\t\t\t\t}\r\n\t\t\t\t\t\t\tcmd := exec.Command(c.Binary, c.UseCommand, string(b))\r\n\t\t\t\t\t\t\tcmd.Stderr = os.Stderr\r\n\t\t\t\t\t\t\tcmd.Stdout = os.Stdout\r\n\t\t\t\t\t\t\tcmd.Stdin = os.Stdin\r\n\t\t\t\t\t\t\tif err := cmd.Run(); err != nil {\r\n\t\t\t\t\t\t\t\tfmt.Println(\"error trying to send event\", strings.Join(cmd.Args, \" \"), err)\r\n\t\t\t\t\t\t\t}\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\t_, err := events.NamedListen(n, events.Filter(c.ListenFor, fn))\r\n\t\t\t\t\t\tif err != nil {\r\n\t\t\t\t\t\t\treturn err\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\treturn nil\r\n\t\t\t\t\t})\r\n\t\t\t\t}(c)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\terr = err\r\n\t\t\t\t\treturn\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t})\r\n\treturn err\r\n}","code-length":521,"reference":"\/\/ LoadPlugins will add listeners for any plugins that support \"events\"","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *Response) WriteHeader(i int) {\r\n\tw.Status = i\r\n\tw.ResponseWriter.WriteHeader(i)\r\n}","code-length":45,"reference":"\/\/ WriteHeader sets the status code for a response","result":"Write code to the file.","score":[0.1284,0.1163]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *Response) Write(b []byte) (int, error) {\r\n\tw.Size = binary.Size(b)\r\n\treturn w.ResponseWriter.Write(b)\r\n}","code-length":56,"reference":"\/\/ Write the body of the response","result":"Write to the response.","score":[0.1795,0.1493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *Response) Flush() {\r\n\tif f, ok := w.ResponseWriter.(http.Flusher); ok {\r\n\t\tf.Flush()\r\n\t}\r\n}","code-length":54,"reference":"\/\/ Flush the response","result":"Flush the response.","score":[0.4137,0.4808]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *Response) CloseNotify() <-chan bool {\r\n\tif cn, ok := w.ResponseWriter.(closeNotifier); ok {\r\n\t\treturn cn.CloseNotify()\r\n\t}\r\n\treturn nil\r\n}","code-length":63,"reference":"\/\/ CloseNotify implements the http.CloseNotifier interface","result":"Close the response.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Run() error {\r\n\tfmt.Printf(\"! This updater will attempt to update your application to Buffalo version: %s\\n\", runtime.Version)\r\n\tif !ask(\"Do you wish to continue?\") {\r\n\t\tfmt.Println(\"~~~ cancelling update ~~~\")\r\n\t\treturn nil\r\n\t}\r\n\tr := &Runner{\r\n\t\tApp:      meta.New(\".\"),\r\n\t\tWarnings: []string{},\r\n\t}\r\n\tdefer func() {\r\n\t\tif len(r.Warnings) == 0 {\r\n\t\t\treturn\r\n\t\t}\r\n\t\tfmt.Println(\"\\n\\n----------------------------\")\r\n\t\tfmt.Printf(\"!!! (%d) Warnings Were Found !!!\\n\\n\", len(r.Warnings))\r\n\t\tfor _, w := range r.Warnings {\r\n\t\t\tfmt.Printf(\"[WARNING]: %s\\n\", w)\r\n\t\t}\r\n\t}()\r\n\tfor _, c := range checks {\r\n\t\tif err := c(r); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":290,"reference":"\/\/ Run all compatible checks","result":"Update your application.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc onlyRelevantFiles(p string, fi os.FileInfo, err error, fn func(p string) error) error {\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif fi.IsDir() {\r\n\t\tbase := filepath.Base(p)\r\n\t\tif strings.HasPrefix(base, \"_\") {\r\n\t\t\treturn filepath.SkipDir\r\n\t\t}\r\n\t\tfor _, n := range []string{\"vendor\", \"node_modules\", \".git\"} {\r\n\t\t\tif base == n {\r\n\t\t\t\treturn filepath.SkipDir\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\text := filepath.Ext(p)\r\n\tif ext != \".go\" {\r\n\t\treturn nil\r\n\t}\r\n\treturn fn(p)\r\n}","code-length":210,"reference":"\/\/onlyRelevantFiles processes only .go files excluding folders like node_modules and vendor.","result":"Exclude files in the generated code.","score":[0.0839,0.0952]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GoTemplateEngine(input string, data map[string]interface{}, helpers map[string]interface{}) (string, error) {\r\n\t\r\n\t\r\n\t\r\n\tdata[\"nilOpts\"] = map[string]interface{}{}\r\n\tt := template.New(input)\r\n\tif helpers != nil {\r\n\t\tt = t.Funcs(helpers)\r\n\t}\r\n\tt, err := t.Parse(input)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tbb := &bytes.Buffer{}\r\n\terr = t.Execute(bb, data)\r\n\treturn bb.String(), err\r\n}","code-length":166,"reference":"\/\/ GoTemplateEngine implements the TemplateEngine interface for using standard Go templates","result":"Generate the template engine.","score":[0.0555,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *App) GET(p string, h Handler) *RouteInfo {\r\n\treturn a.addRoute(\"GET\", p, h)\r\n}","code-length":45,"reference":"\/\/ GET maps an HTTP \"GET\" request to the path and the specified handler.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *App) Redirect(status int, from, to string) *RouteInfo {\r\n\treturn a.GET(from, func(c Context) error {\r\n\t\treturn c.Redirect(status, to)\r\n\t})\r\n}","code-length":66,"reference":"\/\/ Redirect from one URL to another URL. Only works for \"GET\" requests.","result":"Redirect to a different path.","score":[0.0577,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *App) ANY(p string, h Handler) {\r\n\ta.GET(p, h)\r\n\ta.POST(p, h)\r\n\ta.PUT(p, h)\r\n\ta.PATCH(p, h)\r\n\ta.HEAD(p, h)\r\n\ta.OPTIONS(p, h)\r\n\ta.DELETE(p, h)\r\n}","code-length":104,"reference":"\/\/ ANY accepts a request across any HTTP method for the specified path\n\/\/ and routes it to the specified Handler.","result":"Match the route.","score":[0.001,0.026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *App) buildRouteName(p string) string {\r\n\tif p == \"\/\" || p == \"\" {\r\n\t\treturn \"root\"\r\n\t}\r\n\tresultParts := []string{}\r\n\tparts := strings.Split(p, \"\/\")\r\n\tfor index, part := range parts {\r\n\t\tif strings.Contains(part, \"{\") || part == \"\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tshouldSingularize := (len(parts) > index+1) && strings.Contains(parts[index+1], \"{\")\r\n\t\tif shouldSingularize {\r\n\t\t\tpart = flect.Singularize(part)\r\n\t\t}\r\n\t\tif parts[index] == \"new\" || parts[index] == \"edit\" {\r\n\t\t\tresultParts = append([]string{part}, resultParts...)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif index > 0 && strings.Contains(parts[index-1], \"}\") {\r\n\t\t\tresultParts = append(resultParts, part)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tresultParts = append(resultParts, part)\r\n\t}\r\n\tif len(resultParts) == 0 {\r\n\t\treturn \"unnamed\"\r\n\t}\r\n\tunderscore := strings.TrimSpace(strings.Join(resultParts, \"_\"))\r\n\treturn name.VarCase(underscore)\r\n}","code-length":341,"reference":"\/\/buildRouteName builds a route based on the path passed.","result":"Build the route name .","score":[0.1284,0.1744]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Group, error) {\r\n\tgg := &genny.Group{}\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn gg, err\r\n\t}\r\n\tif !opts.SkipInit {\r\n\t\tg, err := initGenerator(opts)\r\n\t\tif err != nil {\r\n\t\t\treturn gg, err\r\n\t\t}\r\n\t\tgg.Add(g)\r\n\t}\r\n\tg := genny.New()\r\n\th := template.FuncMap{}\r\n\tdata := map[string]interface{}{\r\n\t\t\"opts\": opts,\r\n\t}\r\n\tt := gogen.TemplateTransformer(data, h)\r\n\tg.Transformer(t)\r\n\tfn := opts.Name.File().String()\r\n\tg.File(genny.NewFileS(\"mailers\/\"+fn+\".go.tmpl\", mailerTmpl))\r\n\tg.File(genny.NewFileS(\"templates\/mail\/\"+fn+\".html.tmpl\", mailTmpl))\r\n\tgg.Add(g)\r\n\treturn gg, nil\r\n}","code-length":282,"reference":"\/\/ New mailer generator. It will init the mailers directory if it doesn't already exist","result":"Generate a new generator.","score":[0.0204,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDialer(host string, port int, username, password string) *Dialer {\r\n\treturn &Dialer{\r\n\t\tHost:         host,\r\n\t\tPort:         port,\r\n\t\tUsername:     username,\r\n\t\tPassword:     password,\r\n\t\tSSL:          port == 465,\r\n\t\tTimeout:      10 * time.Second,\r\n\t\tRetryFailure: true,\r\n\t}\r\n}","code-length":111,"reference":"\/\/ NewDialer returns a new SMTP Dialer. The given parameters are used to connect\n\/\/ to the SMTP server.","result":"Create a new dialer.","score":[0.0106,0.146]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *Dialer) Dial() (SendCloser, error) {\r\n\tconn, err := NetDialTimeout(\"tcp\", addr(d.Host, d.Port), d.Timeout)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif d.SSL {\r\n\t\tconn = tlsClient(conn, d.tlsConfig())\r\n\t}\r\n\tc, err := smtpNewClient(conn, d.Host)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif d.Timeout > 0 {\r\n\t\tconn.SetDeadline(time.Now().Add(d.Timeout))\r\n\t}\r\n\tif d.LocalName != \"\" {\r\n\t\tif err := c.Hello(d.LocalName); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\tif !d.SSL && d.StartTLSPolicy != NoStartTLS {\r\n\t\tok, _ := c.Extension(\"STARTTLS\")\r\n\t\tif !ok && d.StartTLSPolicy == MandatoryStartTLS {\r\n\t\t\terr := StartTLSUnsupportedError{\r\n\t\t\t\tPolicy: d.StartTLSPolicy}\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tif ok {\r\n\t\t\tif err := c.StartTLS(d.tlsConfig()); err != nil {\r\n\t\t\t\tc.Close()\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif d.Auth == nil && d.Username != \"\" {\r\n\t\tif ok, auths := c.Extension(\"AUTH\"); ok {\r\n\t\t\tif strings.Contains(auths, \"CRAM-MD5\") {\r\n\t\t\t\td.Auth = smtp.CRAMMD5Auth(d.Username, d.Password)\r\n\t\t\t} else if strings.Contains(auths, \"LOGIN\") &&\r\n\t\t\t\t!strings.Contains(auths, \"PLAIN\") {\r\n\t\t\t\td.Auth = &loginAuth{\r\n\t\t\t\t\tusername: d.Username,\r\n\t\t\t\t\tpassword: d.Password,\r\n\t\t\t\t\thost:     d.Host,\r\n\t\t\t\t}\r\n\t\t\t} else {\r\n\t\t\t\td.Auth = smtp.PlainAuth(\"\", d.Username, d.Password, d.Host)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif d.Auth != nil {\r\n\t\tif err = c.Auth(d.Auth); err != nil {\r\n\t\t\tc.Close()\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\treturn &smtpSender{c, conn, d}, nil\r\n}","code-length":641,"reference":"\/\/ Dial dials and authenticates to an SMTP server. The returned SendCloser\n\/\/ should be closed when done using it.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *Dialer) DialAndSend(m ...*Message) error {\r\n\ts, err := d.Dial()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer s.Close()\r\n\treturn Send(s, m...)\r\n}","code-length":76,"reference":"\/\/ DialAndSend opens a connection to the SMTP server, sends the given emails and\n\/\/ closes the connection.","result":"Dial and send messages.","score":[0.0096,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f Flash) Set(key string, values []string) {\r\n\tf.data[key] = values\r\n}","code-length":38,"reference":"\/\/Set allows to set a list of values into a particular key.","result":"Set flash data.","score":[0,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f Flash) Add(key, value string) {\r\n\tif len(f.data[key]) == 0 {\r\n\t\tf.data[key] = []string{value}\r\n\t\treturn\r\n\t}\r\n\tf.data[key] = append(f.data[key], value)\r\n}","code-length":85,"reference":"\/\/Add adds a flash value for a flash key, if the key already has values the list for that value grows.","result":"Add a new item to the flash.","score":[0.026,0.0765]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f Flash) persist(session *Session) {\r\n\tb, _ := json.Marshal(f.data)\r\n\tsession.Set(flashKey, b)\r\n\tsession.Save()\r\n}","code-length":58,"reference":"\/\/Persist the flash inside the session.","result":"Persist flash data.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newFlash(session *Session) *Flash {\r\n\tresult := &Flash{\r\n\t\tdata: map[string][]string{},\r\n\t}\r\n\tif session.Session != nil {\r\n\t\tif f := session.Get(flashKey); f != nil {\r\n\t\t\tjson.Unmarshal(f.([]byte), &result.data)\r\n\t\t}\r\n\t}\r\n\treturn result\r\n}","code-length":110,"reference":"\/\/newFlash creates a new Flash and loads the session data inside its data.","result":"Create a new flash object.","score":[0.0686,0.3253]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cookies) Get(name string) (string, error) {\r\n\tck, err := c.req.Cookie(name)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn ck.Value, nil\r\n}","code-length":72,"reference":"\/\/ Get returns the value of the cookie with the given name. Returns http.ErrNoCookie if there's no cookie with that name in the request.","result":"Get the value of a cookie.","score":[0.0213,0.1422]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cookies) Set(name, value string, maxAge time.Duration) {\r\n\tck := http.Cookie{\r\n\t\tName:   name,\r\n\t\tValue:  value,\r\n\t\tMaxAge: int(maxAge.Seconds()),\r\n\t}\r\n\thttp.SetCookie(c.res, &ck)\r\n}","code-length":92,"reference":"\/\/ Set a cookie on the response, which will expire after the given duration.","result":"Set cookies.","score":[0.0012,0.0391]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cookies) SetWithExpirationTime(name, value string, expires time.Time) {\r\n\tck := http.Cookie{\r\n\t\tName:    name,\r\n\t\tValue:   value,\r\n\t\tExpires: expires,\r\n\t}\r\n\thttp.SetCookie(c.res, &ck)\r\n}","code-length":88,"reference":"\/\/ SetWithExpirationTime sets a cookie that will expire at a specific time.\n\/\/ Note that the time is determined by the client's browser, so it might not expire at the expected time,\n\/\/ for example if the client has changed the time on their computer.","result":"Set cookies with expiration time.","score":[0.0001,0.0488]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cookies) Delete(name string) {\r\n\tck := http.Cookie{\r\n\t\tName:  name,\r\n\t\tValue: \"v\",\r\n\t\t\r\n\t\t\r\n\t\tExpires: time.Unix(0, 0),\r\n\t}\r\n\thttp.SetCookie(c.res, &ck)\r\n}","code-length":90,"reference":"\/\/ Delete sets a header that tells the browser to remove the cookie with the given name.","result":"Delete a cookie.","score":[0.0046,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMessage() Message {\r\n\treturn Message{\r\n\t\tContext: context.Background(),\r\n\t\tHeaders: map[string]string{},\r\n\t\tData:    render.Data{},\r\n\t\tmoot:    &sync.RWMutex{},\r\n\t}\r\n}","code-length":78,"reference":"\/\/ NewMessage builds a new message.","result":"Create a new message.","score":[0.3991,0.5077]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFromData(data render.Data) Message {\r\n\td := render.Data{}\r\n\tfor k, v := range data {\r\n\t\td[k] = v\r\n\t}\r\n\tm := NewMessage()\r\n\tm.Data = d\r\n\treturn m\r\n}","code-length":79,"reference":"\/\/ NewFromData builds a new message with raw template data given","result":"Create a new message.","score":[0.0785,0.182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(c buffalo.Context) Message {\r\n\tm := NewFromData(c.Data())\r\n\tm.Context = c\r\n\treturn m\r\n}","code-length":50,"reference":"\/\/ New builds a new message with the current buffalo.Context","result":"Create a new message.","score":[0.1008,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (es *EventSource) CloseNotify() <-chan bool {\r\n\tif cn, ok := es.w.(closeNotifier); ok {\r\n\t\treturn cn.CloseNotify()\r\n\t}\r\n\treturn nil\r\n}","code-length":62,"reference":"\/\/ CloseNotify return true across the channel when the connection\n\/\/ in the browser has been severed.","result":"Close the stream.","score":[0.0038,0.0321]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewEventSource(w http.ResponseWriter) (*EventSource, error) {\r\n\tes := &EventSource{w: w}\r\n\tvar ok bool\r\n\tes.fl, ok = w.(http.Flusher)\r\n\tif !ok {\r\n\t\treturn es, errors.New(\"streaming is not supported\")\r\n\t}\r\n\tes.w.Header().Set(\"Content-Type\", \"text\/event-stream\")\r\n\tes.w.Header().Set(\"Cache-Control\", \"no-cache\")\r\n\tes.w.Header().Set(\"Connection\", \"keep-alive\")\r\n\tes.w.Header().Set(\"Access-Control-Allow-Origin\", \"*\")\r\n\treturn es, nil\r\n}","code-length":180,"reference":"\/\/ NewEventSource returns a new EventSource instance while ensuring\n\/\/ that the http.ResponseWriter is able to handle EventSource messages.\n\/\/ It also makes sure to set the proper response heads.","result":"Create a new event stream.","score":[0.0023,0.0682]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSimpleWithContext(ctx context.Context) *Simple {\r\n\tctx, cancel := context.WithCancel(ctx)\r\n\tl := logrus.New()\r\n\tl.Level = logrus.InfoLevel\r\n\tl.Formatter = &logrus.TextFormatter{}\r\n\treturn &Simple{\r\n\t\tLogger:   l,\r\n\t\tctx:      ctx,\r\n\t\tcancel:   cancel,\r\n\t\thandlers: map[string]Handler{},\r\n\t\tmoot:     &sync.Mutex{},\r\n\t}\r\n}","code-length":138,"reference":"\/\/ NewSimpleWithContext creates a basic implementation of the Worker interface\n\/\/ that is backed using just the standard library and goroutines.","result":"Create a new context.","score":[0.0046,0.0972]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *Simple) Register(name string, h Handler) error {\r\n\tw.moot.Lock()\r\n\tdefer w.moot.Unlock()\r\n\tif _, ok := w.handlers[name]; ok {\r\n\t\treturn fmt.Errorf(\"handler already mapped for name %s\", name)\r\n\t}\r\n\tw.handlers[name] = h\r\n\treturn nil\r\n}","code-length":104,"reference":"\/\/ Register Handler with the worker","result":"Register handlers.","score":[0.0677,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w *Simple) Start(ctx context.Context) error {\r\n\tw.Logger.Info(\"Starting Simple Background Worker\")\r\n\tw.ctx, w.cancel = context.WithCancel(ctx)\r\n\treturn nil\r\n}","code-length":64,"reference":"\/\/ Start the worker","result":"Start the background worker.","score":[0.4518,0.4688]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w Simple) Stop() error {\r\n\tw.Logger.Info(\"Stopping Simple Background Worker\")\r\n\tw.cancel()\r\n\treturn nil\r\n}","code-length":47,"reference":"\/\/ Stop the worker","result":"Stop the background worker.","score":[0.4518,0.4688]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w Simple) Perform(job Job) error {\r\n\tw.Logger.Debugf(\"Performing job %s\", job)\r\n\tif job.Handler == \"\" {\r\n\t\terr := fmt.Errorf(\"no handler name given for %s\", job)\r\n\t\tw.Logger.Error(err)\r\n\t\treturn err\r\n\t}\r\n\tw.moot.Lock()\r\n\tdefer w.moot.Unlock()\r\n\tif h, ok := w.handlers[job.Handler]; ok {\r\n\t\tgo func() {\r\n\t\t\terr := safe.RunE(func() error {\r\n\t\t\t\treturn h(job.Args)\r\n\t\t\t})\r\n\t\t\tif err != nil {\r\n\t\t\t\tw.Logger.Error(err)\r\n\t\t\t}\r\n\t\t\tw.Logger.Debugf(\"Completed job %s\", job)\r\n\t\t}()\r\n\t\treturn nil\r\n\t}\r\n\terr := fmt.Errorf(\"no handler mapped for name %s\", job.Handler)\r\n\tw.Logger.Error(err)\r\n\treturn err\r\n}","code-length":267,"reference":"\/\/ Perform a job as soon as possibly using a goroutine.","result":"Perform a job.","score":[0.0401,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w Simple) PerformAt(job Job, t time.Time) error {\r\n\treturn w.PerformIn(job, time.Until(t))\r\n}","code-length":47,"reference":"\/\/ PerformAt performs a job at a particular time using a goroutine.","result":"Create a new function.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (w Simple) PerformIn(job Job, d time.Duration) error {\r\n\tgo func() {\r\n\t\tselect {\r\n\t\tcase <-time.After(d):\r\n\t\t\tw.Perform(job)\r\n\t\tcase <-w.ctx.Done():\r\n\t\t\tw.cancel()\r\n\t\t}\r\n\t}()\r\n\treturn nil\r\n}","code-length":100,"reference":"\/\/ PerformIn performs a job after waiting for a specified amount\n\/\/ using a goroutine.","result":"Create a job in the job queue.","score":[0.0728,0.0704]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ri RouteInfo) String() string {\r\n\tb, _ := json.MarshalIndent(ri, \"\", \"  \")\r\n\treturn string(b)\r\n}","code-length":48,"reference":"\/\/ String returns a JSON representation of the RouteInfo","result":"Generate the route info string.","score":[0.108,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ri *RouteInfo) Alias(aliases ...string) *RouteInfo {\r\n\tri.Aliases = append(ri.Aliases, aliases...)\r\n\tfor _, a := range aliases {\r\n\t\tri.App.router.Handle(a, ri).Methods(ri.Method)\r\n\t}\r\n\treturn ri\r\n}","code-length":86,"reference":"\/\/ Alias path patterns to the this route. This is not the\n\/\/ same as a redirect.","result":"Set the alias on the route info.","score":[0.046,0.0938]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ri *RouteInfo) Name(name string) *RouteInfo {\r\n\trouteIndex := -1\r\n\tfor index, route := range ri.App.Routes() {\r\n\t\tif route.Path == ri.Path && route.Method == ri.Method {\r\n\t\t\trouteIndex = index\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tname = flect.Camelize(name)\r\n\tif !strings.HasSuffix(name, \"Path\") {\r\n\t\tname = name + \"Path\"\r\n\t}\r\n\tri.PathName = name\r\n\tif routeIndex != -1 {\r\n\t\tri.App.Routes()[routeIndex] = reflect.ValueOf(ri).Interface().(*RouteInfo)\r\n\t}\r\n\treturn ri\r\n}","code-length":195,"reference":"\/\/ Name allows users to set custom names for the routes.","result":"Set the name of the route .","score":[0.0912,0.1415]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ri *RouteInfo) BuildPathHelper() RouteHelperFunc {\r\n\tcRoute := ri\r\n\treturn func(opts map[string]interface{}) (template.HTML, error) {\r\n\t\tpairs := []string{}\r\n\t\tfor k, v := range opts {\r\n\t\t\tpairs = append(pairs, k)\r\n\t\t\tpairs = append(pairs, fmt.Sprintf(\"%v\", v))\r\n\t\t}\r\n\t\turl, err := cRoute.MuxRoute.URL(pairs...)\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", errors.Wrapf(err, \"missing parameters for %v\", cRoute.Path)\r\n\t\t}\r\n\t\tresult := url.Path\r\n\t\tresult = addExtraParamsTo(result, opts)\r\n\t\treturn template.HTML(result), nil\r\n\t}\r\n}","code-length":209,"reference":"\/\/ BuildPathHelper Builds a routeHelperfunc for a particular RouteInfo","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Generator, error) {\r\n\tg := genny.New()\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn g, err\r\n\t}\r\n\tg.Transformer(genny.Replace(\"-no-pop\", \"\"))\r\n\tg.Transformer(genny.Dot())\r\n\tbox := packr.New(\"buffalo:genny:ci\", \"..\/ci\/templates\")\r\n\tvar fname string\r\n\tswitch opts.Provider {\r\n\tcase \"travis\", \"travis-ci\":\r\n\t\tfname = \"-dot-travis.yml.tmpl\"\r\n\tcase \"gitlab\", \"gitlab-ci\":\r\n\t\tif opts.App.WithPop {\r\n\t\t\tfname = \"-dot-gitlab-ci.yml.tmpl\"\r\n\t\t} else {\r\n\t\t\tfname = \"-dot-gitlab-ci-no-pop.yml.tmpl\"\r\n\t\t}\r\n\tdefault:\r\n\t\treturn g, fmt.Errorf(\"could not find a template for %s\", opts.Provider)\r\n\t}\r\n\tf, err := box.FindString(fname)\r\n\tif err != nil {\r\n\t\treturn g, err\r\n\t}\r\n\tg.File(genny.NewFileS(fname, f))\r\n\tdata := map[string]interface{}{\r\n\t\t\"opts\": opts,\r\n\t}\r\n\tif opts.DBType == \"postgres\" {\r\n\t\tdata[\"testDbUrl\"] = \"postgres:\r\n\t} else if opts.DBType == \"mysql\" {\r\n\t\tdata[\"testDbUrl\"] = \"mysql:\r\n\t} else {\r\n\t\tdata[\"testDbUrl\"] = \"\"\r\n\t}\r\n\thelpers := template.FuncMap{}\r\n\tt := gogen.TemplateTransformer(data, helpers)\r\n\tg.Transformer(t)\r\n\treturn g, nil\r\n}","code-length":477,"reference":"\/\/ New generator for adding travis or gitlab","result":"Generate the generator.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Generator, error) {\r\n\tg := genny.New()\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn g, err\r\n\t}\r\n\tg.RunFn(construct(opts))\r\n\treturn g, nil\r\n}","code-length":84,"reference":"\/\/ New returns a new generator for build actions on a Buffalo app","result":"Create a new generator.","score":[0.0476,0.0826]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterCustomDecoder(fn CustomTypeDecoder, types []interface{}, fields []interface{}) {\r\n\trawFunc := (func([]string) (interface{}, error))(fn)\r\n\tdecoder.RegisterCustomType(rawFunc, types, fields)\r\n}","code-length":70,"reference":"\/\/ RegisterCustomDecoder allows to define custom type decoders.","result":"Register custom type decoders.","score":[0.2421,0.3874]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ms *MiddlewareStack) Replace(mw1 MiddlewareFunc, mw2 MiddlewareFunc) {\r\n\tm1k := funcKey(mw1)\r\n\tstack := []MiddlewareFunc{}\r\n\tfor _, mw := range ms.stack {\r\n\t\tif funcKey(mw) == m1k {\r\n\t\t\tstack = append(stack, mw2)\r\n\t\t} else {\r\n\t\t\tstack = append(stack, mw)\r\n\t\t}\r\n\t}\r\n\tms.stack = stack\r\n}","code-length":134,"reference":"\/\/ Replace a piece of middleware with another piece of middleware. Great for\n\/\/ testing.","result":"Replace middleware functions in the stack.","score":[0.0512,0.0709]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *App) Routes() RouteList {\r\n\tif a.root != nil {\r\n\t\treturn a.root.routes\r\n\t}\r\n\treturn a.routes\r\n}","code-length":54,"reference":"\/\/ Routes returns a list of all of the routes defined\n\/\/ in this application.","result":"Get the routes.","score":[0.0075,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc WrapBuffaloHandler(h Handler) http.Handler {\r\n\ta := New(Options{})\r\n\t\r\n\t\r\n\t\r\n\tri := a.GET(\"\/\", h)\r\n\treturn ri\r\n}","code-length":63,"reference":"\/\/ WrapBuffaloHandler wraps a buffalo.Handler to\n\/\/ standard http.Handler","result":"Wrap handler .","score":[0,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PackageJSONCheck(r *Runner) error {\r\n\tfmt.Println(\"~~~ Checking package.json ~~~\")\r\n\tif !r.App.WithWebpack {\r\n\t\treturn nil\r\n\t}\r\n\tbox := webpack.Templates\r\n\tf, err := box.FindString(\"package.json.tmpl\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ttmpl, err := template.New(\"package.json\").Parse(f)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tbb := &bytes.Buffer{}\r\n\terr = tmpl.Execute(bb, map[string]interface{}{\r\n\t\t\"opts\": &webpack.Options{\r\n\t\t\tApp: r.App,\r\n\t\t},\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tb, err := ioutil.ReadFile(\"package.json\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif string(b) == bb.String() {\r\n\t\treturn nil\r\n\t}\r\n\tif !ask(\"Your package.json file is different from the latest Buffalo template.\\nWould you like to REPLACE yours with the latest template?\") {\r\n\t\tfmt.Println(\"\\tskipping package.json\")\r\n\t\treturn nil\r\n\t}\r\n\tpf, err := os.Create(\"package.json\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t_, err = pf.Write(bb.Bytes())\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = pf.Close()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tos.RemoveAll(filepath.Join(r.App.Root, \"node_modules\"))\r\n\tvar cmd *exec.Cmd\r\n\tif r.App.WithYarn {\r\n\t\tcmd = exec.Command(\"yarnpkg\", \"install\")\r\n\t} else {\r\n\t\tcmd = exec.Command(\"npm\", \"install\")\r\n\t}\r\n\tcmd.Stdin = os.Stdin\r\n\tcmd.Stdout = os.Stdout\r\n\tcmd.Stderr = os.Stderr\r\n\treturn cmd.Run()\r\n}","code-length":564,"reference":"\/\/ PackageJSONCheck will compare the current default Buffalo\n\/\/ package.json against the applications package.json. If they are\n\/\/ different you have the option to overwrite the existing package.json\n\/\/ file with the new one.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c ImportConverter) match(importpath string) (string, bool) {\r\n\tfor key, value := range c.Data {\r\n\t\tif !strings.HasPrefix(importpath, key) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tresult := strings.Replace(importpath, key, value, 1)\r\n\t\treturn result, true\r\n\t}\r\n\treturn importpath, false\r\n}","code-length":109,"reference":"\/\/ match takes an import path and replacement map.","result":"Match the importpath.","score":[0,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Send(s Sender, msg ...*Message) error {\r\n\tfor i, m := range msg {\r\n\t\tif err := send(s, m); err != nil {\r\n\t\t\treturn &SendError{Cause: err, Index: uint(i)}\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":86,"reference":"\/\/ Send sends emails using the given Sender.","result":"Send messages to the sender.","score":[0.1568,0.1948]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (opts Options) Last(n name.Ident) bool {\r\n\treturn opts.Parts[len(opts.Parts)-1].String() == n.String()\r\n}","code-length":49,"reference":"\/\/ Last checks if the name is the last of the parts","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *App) Stop(err error) error {\r\n\ta.cancel()\r\n\tif err != nil && errors.Cause(err) != context.Canceled {\r\n\t\ta.Logger.Error(err)\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":78,"reference":"\/\/ Stop the application and attempt to gracefully shutdown","result":"Stop the app.","score":[0.0781,0.2232]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DepEnsure(r *Runner) error {\r\n\tif r.App.WithPop {\r\n\t\tupkg = append(upkg, \"github.com\/gobuffalo\/fizz\", \"github.com\/gobuffalo\/pop\")\r\n\t}\r\n\tif !r.App.WithDep {\r\n\t\tfmt.Println(\"~~~ Running go get ~~~\")\r\n\t\treturn modGetUpdate(r)\r\n\t}\r\n\tfmt.Println(\"~~~ Running dep ensure ~~~\")\r\n\treturn runDepEnsure(r)\r\n}","code-length":146,"reference":"\/\/ DepEnsure runs `dep ensure -v` or `go get -u` depending on app tooling\n\/\/ to make sure that any newly changed imports are added to dep or installed.","result":"Ensure dependencies are present.","score":[0.0006,0.0566]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b BuildInfo) String() string {\r\n\treturn fmt.Sprintf(\"%s (%s)\", b.Version, b.Time)\r\n}","code-length":44,"reference":"\/\/ String implements fmt.String","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Generator, error) {\r\n\tg := genny.New()\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn g, err\r\n\t}\r\n\tif !opts.SkipTemplates {\r\n\t\tcore := packr.New(\"github.com\/gobuffalo\/buffalo\/genny\/resource\/templates\/core\", \"..\/resource\/templates\/core\")\r\n\t\tif err := g.Box(core); err != nil {\r\n\t\t\treturn g, err\r\n\t\t}\r\n\t}\r\n\tvar abox packd.Box\r\n\tif opts.SkipModel {\r\n\t\tabox = packr.New(\"github.com\/gobuffalo\/buffalo\/genny\/resource\/templates\/standard\", \"..\/resource\/templates\/standard\")\r\n\t} else {\r\n\t\tabox = packr.New(\"github.com\/gobuffalo\/buffalo\/genny\/resource\/templates\/use_model\", \"..\/resource\/templates\/use_model\")\r\n\t}\r\n\tif err := g.Box(abox); err != nil {\r\n\t\treturn g, err\r\n\t}\r\n\tpres := presenter{\r\n\t\tApp:   opts.App,\r\n\t\tName:  name.New(opts.Name),\r\n\t\tModel: name.New(opts.Model),\r\n\t\tAttrs: opts.Attrs,\r\n\t}\r\n\tx := pres.Name.Resource().File().String()\r\n\tfolder := pres.Name.Folder().Pluralize().String()\r\n\tg.Transformer(genny.Replace(\"resource-name\", x))\r\n\tg.Transformer(genny.Replace(\"resource-use_model\", x))\r\n\tg.Transformer(genny.Replace(\"folder-name\", folder))\r\n\tdata := map[string]interface{}{\r\n\t\t\"opts\":    pres,\r\n\t\t\"actions\": actions(opts),\r\n\t\t\"folder\":  folder,\r\n\t}\r\n\thelpers := template.FuncMap{\r\n\t\t\"camelize\": func(s string) string {\r\n\t\t\treturn flect.Camelize(s)\r\n\t\t},\r\n\t}\r\n\tg.Transformer(gogen.TemplateTransformer(data, helpers))\r\n\tg.RunFn(installPop(opts))\r\n\tg.RunFn(addResource(pres))\r\n\treturn g, nil\r\n}","code-length":588,"reference":"\/\/ New resource generator","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) AddBody(r render.Renderer, data render.Data) error {\r\n\tbuf := bytes.NewBuffer([]byte{})\r\n\terr := r.Render(buf, m.merge(data))\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tm.Bodies = append(m.Bodies, Body{\r\n\t\tContent:     buf.String(),\r\n\t\tContentType: r.ContentType(),\r\n\t})\r\n\treturn nil\r\n}","code-length":129,"reference":"\/\/ AddBody the message by receiving a renderer and rendering data, first message will be\n\/\/ used as the main message Body rest of them will be passed as alternative bodies on the\n\/\/ email message","result":"Add a body to a message.","score":[0.0013,0.0303]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) AddBodies(data render.Data, renderers ...render.Renderer) error {\r\n\tfor _, r := range renderers {\r\n\t\terr := m.AddBody(r, data)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":90,"reference":"\/\/ AddBodies Allows to add multiple bodies to the message, it returns errors that\n\/\/ could happen in the rendering.","result":"Add a body.","score":[0,0.0273]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) AddAttachment(name, contentType string, r io.Reader) error {\r\n\tm.Attachments = append(m.Attachments, Attachment{\r\n\t\tName:        name,\r\n\t\tContentType: contentType,\r\n\t\tReader:      r,\r\n\t\tEmbedded:    false,\r\n\t})\r\n\treturn nil\r\n}","code-length":92,"reference":"\/\/AddAttachment adds the attachment to the list of attachments the Message has.","result":"Add attachments to a message.","score":[0.0705,0.1327]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) AddEmbedded(name string, r io.Reader) error {\r\n\tm.Attachments = append(m.Attachments, Attachment{\r\n\t\tName:     name,\r\n\t\tReader:   r,\r\n\t\tEmbedded: true,\r\n\t})\r\n\treturn nil\r\n}","code-length":81,"reference":"\/\/AddEmbedded adds the attachment to the list of attachments\n\/\/ the Message has and uses inline instead of attachement property.","result":"Add embedded attachments to a message.","score":[0.0223,0.0806]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *Message) SetHeader(field, value string) {\r\n\tm.Headers[field] = value\r\n}","code-length":38,"reference":"\/\/ SetHeader sets the heder field and value for the message","result":"Set headers in the message.","score":[0.0724,0.0962]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Group, error) {\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tgg, err := core.New(opts.Options)\r\n\tif err != nil {\r\n\t\treturn gg, err\r\n\t}\r\n\tg := genny.New()\r\n\tg.Transformer(genny.Dot())\r\n\tdata := map[string]interface{}{\r\n\t\t\"opts\": opts,\r\n\t}\r\n\thelpers := template.FuncMap{}\r\n\tt := gogen.TemplateTransformer(data, helpers)\r\n\tg.Transformer(t)\r\n\tg.Box(packr.New(\"buffalo:genny:newapp:web\", \"..\/web\/templates\"))\r\n\tgg.Add(g)\r\n\tif opts.Webpack != nil {\r\n\t\t\r\n\t\tg, err = webpack.New(opts.Webpack)\r\n\t\tif err != nil {\r\n\t\t\treturn gg, err\r\n\t\t}\r\n\t\tgg.Add(g)\r\n\t}\r\n\tif opts.Standard != nil {\r\n\t\t\r\n\t\tg, err = standard.New(opts.Standard)\r\n\t\tif err != nil {\r\n\t\t\treturn gg, err\r\n\t\t}\r\n\t\tgg.Add(g)\r\n\t}\r\n\treturn gg, nil\r\n}","code-length":350,"reference":"\/\/ New generator for creating a Buffalo Web application","result":"Create a new app.","score":[0.0915,0.3007]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Generator, error) {\r\n\tg := genny.New()\r\n\tg.Box(packr.New(\"buffalo:genny:assets:standard\", \"..\/standard\/templates\"))\r\n\tdata := map[string]interface{}{}\r\n\th := template.FuncMap{}\r\n\tt := gogen.TemplateTransformer(data, h)\r\n\tg.Transformer(t)\r\n\tg.RunFn(func(r *genny.Runner) error {\r\n\t\tf, err := r.FindFile(\"templates\/application.html\")\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\ts := strings.Replace(f.String(), \"<\/title>\", \"<\/title>\\n\"+bs4, 1)\r\n\t\treturn r.File(genny.NewFileS(f.Name(), s))\r\n\t})\r\n\treturn g, nil\r\n}","code-length":235,"reference":"\/\/ New generator for creating basic asset files","result":"Generate the generator.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(opts *Options) (*genny.Generator, error) {\r\n\tg := genny.New()\r\n\tif err := opts.Validate(); err != nil {\r\n\t\treturn g, errors.WithStack(err)\r\n\t}\r\n\tg.RunFn(appDetails(opts))\r\n\tcBox := packr.Folder(filepath.Join(opts.App.Root, \"config\"))\r\n\tg.RunFn(configs(opts, cBox))\r\n\taBox := packr.Folder(opts.App.Root)\r\n\tg.RunFn(pkgChecks(opts, aBox))\r\n\treturn g, nil\r\n}","code-length":164,"reference":"\/\/ New returns a generator that performs buffalo\n\/\/ related rx checks","result":"Generate the generator.","score":[0,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Cleanup(opts *Options) genny.RunFn {\r\n\treturn func(r *genny.Runner) error {\r\n\t\tdefer os.RemoveAll(filepath.Join(opts.Root, \"a\"))\r\n\t\tif err := jam.Clean(); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tvar err error\r\n\t\topts.rollback.Range(func(k, v interface{}) bool {\r\n\t\t\tf := genny.NewFileS(k.(string), v.(string))\r\n\t\t\tr.Logger.Debugf(\"Rollback: %s\", f.Name())\r\n\t\t\tif err = r.File(f); err != nil {\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\t\tr.Disk.Remove(f.Name())\r\n\t\t\treturn true\r\n\t\t})\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tfor _, f := range r.Disk.Files() {\r\n\t\t\tif err := r.Disk.Delete(f.Name()); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\tif envy.Mods() {\r\n\t\t\tif err := r.Exec(exec.Command(genny.GoBin(), \"mod\", \"tidy\")); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n}","code-length":356,"reference":"\/\/ Cleanup all of the generated files","result":"Cleanup the temporary files.","score":[0.1795,0.1493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MDTemplateEngine(input string, data map[string]interface{}, helpers map[string]interface{}) (string, error) {\r\n\tif ct, ok := data[\"contentType\"].(string); ok && ct == \"text\/plain\" {\r\n\t\treturn plush.BuffaloRenderer(input, data, helpers)\r\n\t}\r\n\tsource := github_flavored_markdown.Markdown([]byte(input))\r\n\tsource = []byte(html.UnescapeString(string(source)))\r\n\treturn plush.BuffaloRenderer(string(source), data, helpers)\r\n}","code-length":149,"reference":"\/\/ MDTemplateEngine runs the input through github flavored markdown before sending it to the Plush engine.","result":"Render markdown.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Update(fg FileGetter, kc corev1.ConfigMapInterface, name, namespace string, updates []ConfigMapUpdate, logger *logrus.Entry) error {\r\n\tcm, getErr := kc.Get(name, metav1.GetOptions{})\r\n\tisNotFound := errors.IsNotFound(getErr)\r\n\tif getErr != nil && !isNotFound {\r\n\t\treturn fmt.Errorf(\"failed to fetch current state of configmap: %v\", getErr)\r\n\t}\r\n\tif cm == nil || isNotFound {\r\n\t\tcm = &coreapi.ConfigMap{\r\n\t\t\tObjectMeta: metav1.ObjectMeta{\r\n\t\t\t\tName:      name,\r\n\t\t\t\tNamespace: namespace,\r\n\t\t\t},\r\n\t\t}\r\n\t}\r\n\tif cm.Data == nil {\r\n\t\tcm.Data = map[string]string{}\r\n\t}\r\n\tif cm.BinaryData == nil {\r\n\t\tcm.BinaryData = map[string][]byte{}\r\n\t}\r\n\tfor _, upd := range updates {\r\n\t\tif upd.Filename == \"\" {\r\n\t\t\tlogger.WithField(\"key\", upd.Key).Debug(\"Deleting key.\")\r\n\t\t\tdelete(cm.Data, upd.Key)\r\n\t\t\tdelete(cm.BinaryData, upd.Key)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tcontent, err := fg.GetFile(upd.Filename)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"get file err: %v\", err)\r\n\t\t}\r\n\t\tlogger.WithFields(logrus.Fields{\"key\": upd.Key, \"filename\": upd.Filename}).Debug(\"Populating key.\")\r\n\t\tvalue := content\r\n\t\tif upd.GZIP {\r\n\t\t\tbuff := bytes.NewBuffer([]byte{})\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tz := gzip.NewWriter(buff)\r\n\t\t\tif _, err := z.Write(content); err != nil {\r\n\t\t\t\tlogger.WithError(err).Error(\"failed to gzip content, falling back to raw\")\r\n\t\t\t} else {\r\n\t\t\t\tif err := z.Close(); err != nil {\r\n\t\t\t\t\tlogger.WithError(err).Error(\"failed to flush gzipped content (!?), falling back to raw\")\r\n\t\t\t\t} else {\r\n\t\t\t\t\tvalue = buff.Bytes()\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\tif utf8.ValidString(string(value)) {\r\n\t\t\tdelete(cm.BinaryData, upd.Key)\r\n\t\t\tcm.Data[upd.Key] = string(value)\r\n\t\t} else {\r\n\t\t\tdelete(cm.Data, upd.Key)\r\n\t\t\tcm.BinaryData[upd.Key] = value\r\n\t\t}\r\n\t}\r\n\tvar updateErr error\r\n\tvar verb string\r\n\tif getErr != nil && isNotFound {\r\n\t\tverb = \"create\"\r\n\t\t_, updateErr = kc.Create(cm)\r\n\t} else {\r\n\t\tverb = \"update\"\r\n\t\t_, updateErr = kc.Update(cm)\r\n\t}\r\n\tif updateErr != nil {\r\n\t\treturn fmt.Errorf(\"%s config map err: %v\", verb, updateErr)\r\n\t}\r\n\treturn nil\r\n}","code-length":804,"reference":"\/\/ Update updates the configmap with the data from the identified files","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FilterChanges(cfg plugins.ConfigUpdater, changes []github.PullRequestChange, log *logrus.Entry) map[ConfigMapID][]ConfigMapUpdate {\r\n\ttoUpdate := map[ConfigMapID][]ConfigMapUpdate{}\r\n\tfor _, change := range changes {\r\n\t\tvar cm plugins.ConfigMapSpec\r\n\t\tfound := false\r\n\t\tfor key, configMap := range cfg.Maps {\r\n\t\t\tvar matchErr error\r\n\t\t\tfound, matchErr = zglob.Match(key, change.Filename)\r\n\t\t\tif matchErr != nil {\r\n\t\t\t\t\r\n\t\t\t\tlog.WithError(matchErr).Info(\"key matching error\")\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tif found {\r\n\t\t\t\tcm = configMap\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif !found {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tfor _, ns := range append(cm.Namespaces) {\r\n\t\t\tid := ConfigMapID{Name: cm.Name, Namespace: ns}\r\n\t\t\tkey := cm.Key\r\n\t\t\tif key == \"\" {\r\n\t\t\t\tkey = path.Base(change.Filename)\r\n\t\t\t\t\r\n\t\t\t\tif change.Status == github.PullRequestFileRenamed {\r\n\t\t\t\t\toldKey := path.Base(change.PreviousFilename)\r\n\t\t\t\t\t\r\n\t\t\t\t\t\r\n\t\t\t\t\ttoUpdate[id] = append(toUpdate[id], ConfigMapUpdate{Key: oldKey})\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tif change.Status == github.PullRequestFileRemoved {\r\n\t\t\t\ttoUpdate[id] = append(toUpdate[id], ConfigMapUpdate{Key: key})\r\n\t\t\t} else {\r\n\t\t\t\tgzip := cfg.GZIP\r\n\t\t\t\tif cm.GZIP != nil {\r\n\t\t\t\t\tgzip = *cm.GZIP\r\n\t\t\t\t}\r\n\t\t\t\ttoUpdate[id] = append(toUpdate[id], ConfigMapUpdate{Key: key, Filename: change.Filename, GZIP: gzip})\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn toUpdate\r\n}","code-length":502,"reference":"\/\/ FilterChanges determines which of the changes are relevant for config updating, returning mapping of\n\/\/ config map to key to filename to update that key from.","result":"Filter changes .","score":[0.0001,0.0203]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getLabelsFromREMatches(matches [][]string) (labels []string) {\r\n\tfor _, match := range matches {\r\n\t\tfor _, label := range strings.Split(match[0], \" \")[1:] {\r\n\t\t\tlabel = strings.ToLower(match[1] + \"\/\" + strings.TrimSpace(label))\r\n\t\t\tlabels = append(labels, label)\r\n\t\t}\r\n\t}\r\n\treturn\r\n}","code-length":115,"reference":"\/\/ Get Labels from Regexp matches","result":"Get labels from REMatches.","score":[0.2304,0.5077]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getLabelsFromGenericMatches(matches [][]string, additionalLabels []string) []string {\r\n\tif len(additionalLabels) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\tvar labels []string\r\n\tfor _, match := range matches {\r\n\t\tparts := strings.Split(match[0], \" \")\r\n\t\tif ((parts[0] != \"\/label\") && (parts[0] != \"\/remove-label\")) || len(parts) != 2 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tfor _, l := range additionalLabels {\r\n\t\t\tif l == parts[1] {\r\n\t\t\t\tlabels = append(labels, parts[1])\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn labels\r\n}","code-length":191,"reference":"\/\/ getLabelsFromGenericMatches returns label matches with extra labels if those\n\/\/ have been configured in the plugin config.","result":"Get labels from generic matches.","score":[0.0178,0.0599]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ca *Agent) Start(prowConfig, jobConfig string) error {\r\n\tc, err := Load(prowConfig, jobConfig)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tca.Set(c)\r\n\tgo func() {\r\n\t\tvar lastModTime time.Time\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tskips := 0\r\n\t\tfor range time.Tick(1 * time.Second) {\r\n\t\t\tif skips < 600 {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tprowStat, err := os.Stat(prowConfig)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tlogrus.WithField(\"prowConfig\", prowConfig).WithError(err).Error(\"Error loading prow config.\")\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\trecentModTime := prowStat.ModTime()\r\n\t\t\t\t\r\n\t\t\t\tif jobConfig != \"\" {\r\n\t\t\t\t\tjobConfigStat, err := os.Stat(jobConfig)\r\n\t\t\t\t\tif err != nil {\r\n\t\t\t\t\t\tlogrus.WithField(\"jobConfig\", jobConfig).WithError(err).Error(\"Error loading job configs.\")\r\n\t\t\t\t\t\tcontinue\r\n\t\t\t\t\t}\r\n\t\t\t\t\tif jobConfigStat.ModTime().After(recentModTime) {\r\n\t\t\t\t\t\trecentModTime = jobConfigStat.ModTime()\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t\tif !recentModTime.After(lastModTime) {\r\n\t\t\t\t\tskips++\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\tlastModTime = recentModTime\r\n\t\t\t}\r\n\t\t\tif c, err := Load(prowConfig, jobConfig); err != nil {\r\n\t\t\t\tlogrus.WithField(\"prowConfig\", prowConfig).\r\n\t\t\t\t\tWithField(\"jobConfig\", jobConfig).\r\n\t\t\t\t\tWithError(err).Error(\"Error loading config.\")\r\n\t\t\t} else {\r\n\t\t\t\tskips = 0\r\n\t\t\t\tca.Set(c)\r\n\t\t\t}\r\n\t\t}\r\n\t}()\r\n\treturn nil\r\n}","code-length":507,"reference":"\/\/ Start will begin polling the config file at the path. If the first load\n\/\/ fails, Start will return the error and abort. Future load failures will log\n\/\/ the failure message but continue attempting to load.","result":"Start the agent.","score":[0.0,0.029]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ca *Agent) Subscribe(subscription DeltaChan) {\r\n\tca.mut.Lock()\r\n\tdefer ca.mut.Unlock()\r\n\tca.subscriptions = append(ca.subscriptions, subscription)\r\n}","code-length":59,"reference":"\/\/ Subscribe registers the channel for messages on config reload.\n\/\/ The caller can expect a copy of the previous and current config\n\/\/ to be sent down the subscribed channel when a new configuration\n\/\/ is loaded.","result":"Subscribe to events.","score":[0.0,0.029]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ca *Agent) Config() *Config {\r\n\tca.mut.RLock()\r\n\tdefer ca.mut.RUnlock()\r\n\treturn ca.c\r\n}","code-length":51,"reference":"\/\/ Config returns the latest config. Do not modify the config.","result":"Get the config from the agent.","score":[0.0998,0.1429]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ca *Agent) Set(c *Config) {\r\n\tca.mut.Lock()\r\n\tdefer ca.mut.Unlock()\r\n\tvar oldConfig Config\r\n\tif ca.c != nil {\r\n\t\toldConfig = *ca.c\r\n\t}\r\n\tdelta := Delta{oldConfig, *c}\r\n\tca.c = c\r\n\tfor _, subscription := range ca.subscriptions {\r\n\t\tgo func(sub DeltaChan) {\r\n\t\t\tend := time.NewTimer(time.Minute)\r\n\t\t\tselect {\r\n\t\t\tcase sub <- delta:\r\n\t\t\tcase <-end.C:\r\n\t\t\t}\r\n\t\t\tif !end.Stop() {\r\n\t\t\t\t<-end.C\r\n\t\t\t}\r\n\t\t}(subscription)\r\n\t}\r\n}","code-length":204,"reference":"\/\/ Set sets the config. Useful for testing.","result":"Set the agent.","score":[0.0917,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) IsMember(org, user string) (bool, error) {\r\n\tfor _, m := range f.OrgMembers[org] {\r\n\t\tif m == user {\r\n\t\t\treturn true, nil\r\n\t\t}\r\n\t}\r\n\treturn false, nil\r\n}","code-length":83,"reference":"\/\/ IsMember returns true if user is in org.","result":"Test if the user is a member of an org.","score":[0.1826,0.3468]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ListIssueComments(owner, repo string, number int) ([]github.IssueComment, error) {\r\n\treturn append([]github.IssueComment{}, f.IssueComments[number]...), nil\r\n}","code-length":64,"reference":"\/\/ ListIssueComments returns comments.","result":"List comments in a repo.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ListPullRequestComments(owner, repo string, number int) ([]github.ReviewComment, error) {\r\n\treturn append([]github.ReviewComment{}, f.PullRequestComments[number]...), nil\r\n}","code-length":64,"reference":"\/\/ ListPullRequestComments returns review comments.","result":"List comments in a github issue.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ListReviews(owner, repo string, number int) ([]github.Review, error) {\r\n\treturn append([]github.Review{}, f.Reviews[number]...), nil\r\n}","code-length":62,"reference":"\/\/ ListReviews returns reviews.","result":"Test if the file is not empty.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ListIssueEvents(owner, repo string, number int) ([]github.ListedIssueEvent, error) {\r\n\treturn append([]github.ListedIssueEvent{}, f.IssueEvents[number]...), nil\r\n}","code-length":68,"reference":"\/\/ ListIssueEvents returns issue events","result":"List all issues in a repo.","score":[0,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) CreateComment(owner, repo string, number int, comment string) error {\r\n\tf.IssueCommentsAdded = append(f.IssueCommentsAdded, fmt.Sprintf(\"%s\/%s#%d:%s\", owner, repo, number, comment))\r\n\tf.IssueComments[number] = append(f.IssueComments[number], github.IssueComment{\r\n\t\tID:   f.IssueCommentID,\r\n\t\tBody: comment,\r\n\t\tUser: github.User{Login: botName},\r\n\t})\r\n\tf.IssueCommentID++\r\n\treturn nil\r\n}","code-length":153,"reference":"\/\/ CreateComment adds a comment to a PR","result":"Create a comment in the repo.","score":[0.1956,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) CreateReview(org, repo string, number int, r github.DraftReview) error {\r\n\tf.Reviews[number] = append(f.Reviews[number], github.Review{\r\n\t\tID:   f.ReviewID,\r\n\t\tUser: github.User{Login: botName},\r\n\t\tBody: r.Body,\r\n\t})\r\n\tf.ReviewID++\r\n\treturn nil\r\n}","code-length":116,"reference":"\/\/ CreateReview adds a review to a PR","result":"Create a review.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) CreateCommentReaction(org, repo string, ID int, reaction string) error {\r\n\tf.CommentReactionsAdded = append(f.CommentReactionsAdded, fmt.Sprintf(\"%s\/%s#%d:%s\", org, repo, ID, reaction))\r\n\treturn nil\r\n}","code-length":82,"reference":"\/\/ CreateCommentReaction adds emoji to a comment.","result":"Create comment reactions.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) CreateIssueReaction(org, repo string, ID int, reaction string) error {\r\n\tf.IssueReactionsAdded = append(f.IssueReactionsAdded, fmt.Sprintf(\"%s\/%s#%d:%s\", org, repo, ID, reaction))\r\n\treturn nil\r\n}","code-length":82,"reference":"\/\/ CreateIssueReaction adds an emoji to an issue.","result":"Create issue reactions.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) DeleteComment(owner, repo string, ID int) error {\r\n\tf.IssueCommentsDeleted = append(f.IssueCommentsDeleted, fmt.Sprintf(\"%s\/%s#%d\", owner, repo, ID))\r\n\tfor num, ics := range f.IssueComments {\r\n\t\tfor i, ic := range ics {\r\n\t\t\tif ic.ID == ID {\r\n\t\t\t\tf.IssueComments[num] = append(ics[:i], ics[i+1:]...)\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn fmt.Errorf(\"could not find issue comment %d\", ID)\r\n}","code-length":170,"reference":"\/\/ DeleteComment deletes a comment.","result":"Delete comments.","score":[0,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) DeleteStaleComments(org, repo string, number int, comments []github.IssueComment, isStale func(github.IssueComment) bool) error {\r\n\tif comments == nil {\r\n\t\tcomments, _ = f.ListIssueComments(org, repo, number)\r\n\t}\r\n\tfor _, comment := range comments {\r\n\t\tif isStale(comment) {\r\n\t\t\tif err := f.DeleteComment(org, repo, comment.ID); err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"failed to delete stale comment with ID '%d'\", comment.ID)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":172,"reference":"\/\/ DeleteStaleComments deletes comments flagged by isStale.","result":"Delete stale comments.","score":[0,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetPullRequest(owner, repo string, number int) (*github.PullRequest, error) {\r\n\tval, exists := f.PullRequests[number]\r\n\tif !exists {\r\n\t\treturn nil, fmt.Errorf(\"Pull request number %d does not exit\", number)\r\n\t}\r\n\treturn val, nil\r\n}","code-length":93,"reference":"\/\/ GetPullRequest returns details about the PR.","result":"Test if the code is executed.","score":[0.1634,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetPullRequestChanges(org, repo string, number int) ([]github.PullRequestChange, error) {\r\n\treturn f.PullRequestChanges[number], nil\r\n}","code-length":53,"reference":"\/\/ GetPullRequestChanges returns the file modifications in a PR.","result":"Generate the generated code.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetRef(owner, repo, ref string) (string, error) {\r\n\treturn TestRef, nil\r\n}","code-length":43,"reference":"\/\/ GetRef returns the hash of a ref.","result":"Generate the generated code.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) DeleteRef(owner, repo, ref string) error {\r\n\tf.RefsDeleted = append(f.RefsDeleted, struct{ Org, Repo, Ref string }{Org: owner, Repo: repo, Ref: ref})\r\n\treturn nil\r\n}","code-length":73,"reference":"\/\/ DeleteRef returns an error indicating if deletion of the given ref was successful","result":"Delete refs.","score":[0,0.0391]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetSingleCommit(org, repo, SHA string) (github.SingleCommit, error) {\r\n\treturn f.Commits[SHA], nil\r\n}","code-length":50,"reference":"\/\/ GetSingleCommit returns a single commit.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) CreateStatus(owner, repo, SHA string, s github.Status) error {\r\n\tif f.CreatedStatuses == nil {\r\n\t\tf.CreatedStatuses = make(map[string][]github.Status)\r\n\t}\r\n\tstatuses := f.CreatedStatuses[SHA]\r\n\tvar updated bool\r\n\tfor i := range statuses {\r\n\t\tif statuses[i].Context == s.Context {\r\n\t\t\tstatuses[i] = s\r\n\t\t\tupdated = true\r\n\t\t}\r\n\t}\r\n\tif !updated {\r\n\t\tstatuses = append(statuses, s)\r\n\t}\r\n\tf.CreatedStatuses[SHA] = statuses\r\n\treturn nil\r\n}","code-length":179,"reference":"\/\/ CreateStatus adds a status context to a commit.","result":"Create a new status.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ListStatuses(org, repo, ref string) ([]github.Status, error) {\r\n\treturn f.CreatedStatuses[ref], nil\r\n}","code-length":50,"reference":"\/\/ ListStatuses returns individual status contexts on a commit.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetCombinedStatus(owner, repo, ref string) (*github.CombinedStatus, error) {\r\n\treturn f.CombinedStatuses[ref], nil\r\n}","code-length":52,"reference":"\/\/ GetCombinedStatus returns the overall status for a commit.","result":"Get the combined status.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetRepoLabels(owner, repo string) ([]github.Label, error) {\r\n\tla := []github.Label{}\r\n\tfor _, l := range f.RepoLabelsExisting {\r\n\t\tla = append(la, github.Label{Name: l})\r\n\t}\r\n\treturn la, nil\r\n}","code-length":91,"reference":"\/\/ GetRepoLabels gets labels in a repo.","result":"Get labels from github.","score":[0.1509,0.2799]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetIssueLabels(owner, repo string, number int) ([]github.Label, error) {\r\n\tre := regexp.MustCompile(fmt.Sprintf(`^%s\/%s#%d:(.*)$`, owner, repo, number))\r\n\tla := []github.Label{}\r\n\tallLabels := sets.NewString(f.IssueLabelsExisting...)\r\n\tallLabels.Insert(f.IssueLabelsAdded...)\r\n\tallLabels.Delete(f.IssueLabelsRemoved...)\r\n\tfor _, l := range allLabels.List() {\r\n\t\tgroups := re.FindStringSubmatch(l)\r\n\t\tif groups != nil {\r\n\t\t\tla = append(la, github.Label{Name: groups[1]})\r\n\t\t}\r\n\t}\r\n\treturn la, nil\r\n}","code-length":204,"reference":"\/\/ GetIssueLabels gets labels on an issue","result":"Test if the file is not empty.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) AddLabel(owner, repo string, number int, label string) error {\r\n\tlabelString := fmt.Sprintf(\"%s\/%s#%d:%s\", owner, repo, number, label)\r\n\tif sets.NewString(f.IssueLabelsAdded...).Has(labelString) {\r\n\t\treturn fmt.Errorf(\"cannot add %v to %s\/%s\/#%d\", label, owner, repo, number)\r\n\t}\r\n\tif f.RepoLabelsExisting == nil {\r\n\t\tf.IssueLabelsAdded = append(f.IssueLabelsAdded, labelString)\r\n\t\treturn nil\r\n\t}\r\n\tfor _, l := range f.RepoLabelsExisting {\r\n\t\tif label == l {\r\n\t\t\tf.IssueLabelsAdded = append(f.IssueLabelsAdded, labelString)\r\n\t\t\treturn nil\r\n\t\t}\r\n\t}\r\n\treturn fmt.Errorf(\"cannot add %v to %s\/%s\/#%d\", label, owner, repo, number)\r\n}","code-length":251,"reference":"\/\/ AddLabel adds a label","result":"Add labels to a github issue.","score":[0.193,0.2941]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) RemoveLabel(owner, repo string, number int, label string) error {\r\n\tlabelString := fmt.Sprintf(\"%s\/%s#%d:%s\", owner, repo, number, label)\r\n\tif !sets.NewString(f.IssueLabelsRemoved...).Has(labelString) {\r\n\t\tf.IssueLabelsRemoved = append(f.IssueLabelsRemoved, labelString)\r\n\t\treturn nil\r\n\t}\r\n\treturn fmt.Errorf(\"cannot remove %v from %s\/%s\/#%d\", label, owner, repo, number)\r\n}","code-length":146,"reference":"\/\/ RemoveLabel removes a label","result":"Remove labels from github.","score":[0,0.2041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) FindIssues(query, sort string, asc bool) ([]github.Issue, error) {\r\n\treturn f.Issues, nil\r\n}","code-length":48,"reference":"\/\/ FindIssues returns f.Issues","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) AssignIssue(owner, repo string, number int, assignees []string) error {\r\n\tvar m github.MissingUsers\r\n\tfor _, a := range assignees {\r\n\t\tif a == \"not-in-the-org\" {\r\n\t\t\tm.Users = append(m.Users, a)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tf.AssigneesAdded = append(f.AssigneesAdded, fmt.Sprintf(\"%s\/%s#%d:%s\", owner, repo, number, a))\r\n\t}\r\n\tif m.Users == nil {\r\n\t\treturn nil\r\n\t}\r\n\treturn m\r\n}","code-length":170,"reference":"\/\/ AssignIssue adds assignees.","result":"Test if the file is not empty.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetFile(org, repo, file, commit string) ([]byte, error) {\r\n\tcontents, ok := f.RemoteFiles[file]\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"could not find file %s\", file)\r\n\t}\r\n\tif commit == \"\" {\r\n\t\tif master, ok := contents[\"master\"]; ok {\r\n\t\t\treturn []byte(master), nil\r\n\t\t}\r\n\t\treturn nil, fmt.Errorf(\"could not find file %s in master\", file)\r\n\t}\r\n\tif content, ok := contents[commit]; ok {\r\n\t\treturn []byte(content), nil\r\n\t}\r\n\treturn nil, fmt.Errorf(\"could not find file %s with ref %s\", file, commit)\r\n}","code-length":203,"reference":"\/\/ GetFile returns the bytes of the file.","result":"Test if the file is not in the package.","score":[0.1449,0.1235]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ListTeams(org string) ([]github.Team, error) {\r\n\treturn []github.Team{\r\n\t\t{\r\n\t\t\tID:   0,\r\n\t\t\tName: \"Admins\",\r\n\t\t},\r\n\t\t{\r\n\t\t\tID:   42,\r\n\t\t\tName: \"Leads\",\r\n\t\t},\r\n\t}, nil\r\n}","code-length":107,"reference":"\/\/ ListTeams return a list of fake teams that correspond to the fake team members returned by ListTeamMembers","result":"List teams in the org.","score":[0.0212,0.0898]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ListTeamMembers(teamID int, role string) ([]github.TeamMember, error) {\r\n\tif role != github.RoleAll {\r\n\t\treturn nil, fmt.Errorf(\"unsupported role %v (only all supported)\", role)\r\n\t}\r\n\tteams := map[int][]github.TeamMember{\r\n\t\t0:  {{Login: \"default-sig-lead\"}},\r\n\t\t42: {{Login: \"sig-lead\"}},\r\n\t}\r\n\tmembers, ok := teams[teamID]\r\n\tif !ok {\r\n\t\treturn []github.TeamMember{}, nil\r\n\t}\r\n\treturn members, nil\r\n}","code-length":173,"reference":"\/\/ ListTeamMembers return a fake team with a single \"sig-lead\" GitHub teammember","result":"Test if the code is not compiled with.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) IsCollaborator(org, repo, login string) (bool, error) {\r\n\tnormed := github.NormLogin(login)\r\n\tfor _, collab := range f.Collaborators {\r\n\t\tif github.NormLogin(collab) == normed {\r\n\t\t\treturn true, nil\r\n\t\t}\r\n\t}\r\n\treturn false, nil\r\n}","code-length":104,"reference":"\/\/ IsCollaborator returns true if the user is a collaborator of the repo.","result":"Test if the repo is a collaborator.","score":[0.1276,0.2545]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ListCollaborators(org, repo string) ([]github.User, error) {\r\n\tresult := make([]github.User, 0, len(f.Collaborators))\r\n\tfor _, login := range f.Collaborators {\r\n\t\tresult = append(result, github.User{Login: login})\r\n\t}\r\n\treturn result, nil\r\n}","code-length":101,"reference":"\/\/ ListCollaborators lists the collaborators.","result":"List collaborators.","score":[0.1116,0.2128]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ClearMilestone(org, repo string, issueNum int) error {\r\n\tf.Milestone = 0\r\n\treturn nil\r\n}","code-length":48,"reference":"\/\/ ClearMilestone removes the milestone","result":"Test the code.","score":[0.2096,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) SetMilestone(org, repo string, issueNum, milestoneNum int) error {\r\n\tif milestoneNum < 0 {\r\n\t\treturn fmt.Errorf(\"Milestone Numbers Cannot Be Negative\")\r\n\t}\r\n\tf.Milestone = milestoneNum\r\n\treturn nil\r\n}","code-length":82,"reference":"\/\/ SetMilestone sets the milestone.","result":"Test if the code is not compiled with.","score":[0.1389,0.0943]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ListMilestones(org, repo string) ([]github.Milestone, error) {\r\n\tmilestones := []github.Milestone{}\r\n\tfor k, v := range f.MilestoneMap {\r\n\t\tmilestones = append(milestones, github.Milestone{Title: k, Number: v})\r\n\t}\r\n\treturn milestones, nil\r\n}","code-length":107,"reference":"\/\/ ListMilestones lists milestones.","result":"List milestones.","score":[0.1839,0.4934]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) ListPRCommits(org, repo string, prNumber int) ([]github.RepositoryCommit, error) {\r\n\tk := fmt.Sprintf(\"%s\/%s#%d\", org, repo, prNumber)\r\n\treturn f.CommitMap[k], nil\r\n}","code-length":78,"reference":"\/\/ ListPRCommits lists commits for a given PR.","result":"List PR commits.","score":[0,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetRepoProjects(owner, repo string) ([]github.Project, error) {\r\n\treturn f.RepoProjects[fmt.Sprintf(\"%s\/%s\", owner, repo)], nil\r\n}","code-length":61,"reference":"\/\/ GetRepoProjects returns the list of projects under a repo.","result":"Get the list of all projects in a repo.","score":[0.287,0.5682]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetOrgProjects(org string) ([]github.Project, error) {\r\n\treturn f.RepoProjects[fmt.Sprintf(\"%s\/*\", org)], nil\r\n}","code-length":56,"reference":"\/\/ GetOrgProjects returns the list of projects under an org","result":"Get all the projects in a org.","score":[0.1251,0.1031]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) GetProjectColumns(projectID int) ([]github.ProjectColumn, error) {\r\n\t\r\n\tfor _, projects := range f.RepoProjects {\r\n\t\tfor _, project := range projects {\r\n\t\t\tif projectID == project.ID {\r\n\t\t\t\treturn f.ProjectColumnsMap[project.Name], nil\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn nil, fmt.Errorf(\"Cannot find project ID\")\r\n}","code-length":123,"reference":"\/\/ GetProjectColumns returns the list of columns for a given project.","result":"Test if the project is not in a package.","score":[0.116,0.0926]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) CreateProjectCard(columnID int, projectCard github.ProjectCard) (*github.ProjectCard, error) {\r\n\tif f.ColumnCardsMap == nil {\r\n\t\tf.ColumnCardsMap = make(map[int][]github.ProjectCard)\r\n\t}\r\n\tfor project, columnIDMap := range f.ColumnIDMap {\r\n\t\tcolumnName, exists := columnIDMap[columnID]\r\n\t\tif exists {\r\n\t\t\tf.ColumnCardsMap[columnID] = append(\r\n\t\t\t\tf.ColumnCardsMap[columnID],\r\n\t\t\t\tprojectCard,\r\n\t\t\t)\r\n\t\t\tf.Column = columnName\r\n\t\t\tf.Project = project\r\n\t\t\treturn &projectCard, nil\r\n\t\t}\r\n\t}\r\n\treturn nil, fmt.Errorf(\"Provided column %d does not exist, ColumnIDMap is %v\", columnID, f.ColumnIDMap)\r\n}","code-length":234,"reference":"\/\/ CreateProjectCard creates a project card under a given column.","result":"Create a project card.","score":[0.1008,0.1596]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) DeleteProjectCard(projectCardID int) error {\r\n\tif f.ColumnCardsMap == nil {\r\n\t\treturn fmt.Errorf(\"Project card doesn't exist\")\r\n\t}\r\n\tf.Project = \"\"\r\n\tf.Column = \"\"\r\n\tnewCards := []github.ProjectCard{}\r\n\toldColumnID := -1\r\n\tfor column, cards := range f.ColumnCardsMap {\r\n\t\tremovalIndex := -1\r\n\t\tfor i, existingCard := range cards {\r\n\t\t\tif existingCard.ContentID == projectCardID {\r\n\t\t\t\toldColumnID = column\r\n\t\t\t\tremovalIndex = i\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif removalIndex != -1 {\r\n\t\t\tnewCards = cards\r\n\t\t\tnewCards[removalIndex] = newCards[len(newCards)-1]\r\n\t\t\tnewCards = newCards[:len(newCards)-1]\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\t\r\n\tif oldColumnID != -1 {\r\n\t\tf.ColumnCardsMap[oldColumnID] = newCards\r\n\t}\r\n\treturn nil\r\n}","code-length":296,"reference":"\/\/ DeleteProjectCard deletes the project card of a specific issue or PR","result":"Delete the project card.","score":[0.0611,0.2629]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *FakeClient) MoveProjectCard(projectCardID int, newColumnID int) error {\r\n\t\r\n\tnewCards := []github.ProjectCard{}\r\n\toldColumnID := -1\r\n\tprojectCard := github.ProjectCard{}\r\n\tfor column, cards := range f.ColumnCardsMap {\r\n\t\tremovalIndex := -1\r\n\t\tfor i, existingCard := range cards {\r\n\t\t\tif existingCard.ContentID == projectCardID {\r\n\t\t\t\toldColumnID = column\r\n\t\t\t\tremovalIndex = i\r\n\t\t\t\tprojectCard = existingCard\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif removalIndex != -1 {\r\n\t\t\tnewCards = cards\r\n\t\t\tnewCards[removalIndex] = newCards[len(newCards)-1]\r\n\t\t\tnewCards = newCards[:len(newCards)-1]\r\n\t\t}\r\n\t}\r\n\tif oldColumnID != -1 {\r\n\t\t\r\n\t\tf.ColumnCardsMap[oldColumnID] = newCards\r\n\t}\r\n\tfor project, columnIDMap := range f.ColumnIDMap {\r\n\t\tif columnName, exists := columnIDMap[newColumnID]; exists {\r\n\t\t\t\r\n\t\t\tf.ColumnCardsMap[newColumnID] = append(\r\n\t\t\t\tf.ColumnCardsMap[newColumnID],\r\n\t\t\t\tprojectCard,\r\n\t\t\t)\r\n\t\t\tf.Column = columnName\r\n\t\t\tf.Project = project\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":386,"reference":"\/\/ MoveProjectCard moves a specific project card to a specified column in the same project","result":"Move a project card.","score":[0.0243,0.1079]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (config *InfluxConfig) CreateDatabaseClient() (*InfluxDB, error) {\r\n\tclient, err := influxdb.NewHTTPClient(influxdb.HTTPConfig{\r\n\t\tAddr:     config.Host,\r\n\t\tUsername: config.User,\r\n\t\tPassword: config.Password,\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &InfluxDB{\r\n\t\tclient:   client,\r\n\t\tdatabase: config.DB,\r\n\t}, nil\r\n}","code-length":139,"reference":"\/\/ CreateDatabaseClient creates and connects a new instance of an InfluxDB\n\/\/ It is created based on the fields set in the configuration.","result":"Create a database client.","score":[0.0028,0.0474]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InfluxDB) Push(measurement string, tags map[string]string, fields map[string]interface{}, date time.Time) error {\r\n\tbatch, err := influxdb.NewBatchPoints(influxdb.BatchPointsConfig{\r\n\t\tDatabase:  i.database,\r\n\t\tPrecision: \"s\",\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tpt, err := influxdb.NewPoint(measurement, tags, fields, date)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tbatch.AddPoint(pt)\r\n\terr = i.client.Write(batch)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tglog.Infof(\"Sent to influx: %s %+v %+v %s\", measurement, tags, fields, date)\r\n\treturn nil\r\n}","code-length":225,"reference":"\/\/ Push a point to the database","result":"Send metrics to influx.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewProwJobWithAnnotation(spec prowapi.ProwJobSpec, labels, annotations map[string]string) prowapi.ProwJob {\r\n\treturn newProwJob(spec, labels, annotations)\r\n}","code-length":62,"reference":"\/\/ NewProwJobWithAnnotation initializes a ProwJob out of a ProwJobSpec with annotations.","result":"Create annotation for the ProwJob.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewProwJob(spec prowapi.ProwJobSpec, labels map[string]string) prowapi.ProwJob {\r\n\treturn newProwJob(spec, labels, nil)\r\n}","code-length":58,"reference":"\/\/ NewProwJob initializes a ProwJob out of a ProwJobSpec.","result":"Create a new ProwJob.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPresubmit(pr github.PullRequest, baseSHA string, job config.Presubmit, eventGUID string) prowapi.ProwJob {\r\n\trefs := createRefs(pr, baseSHA)\r\n\tlabels := make(map[string]string)\r\n\tfor k, v := range job.Labels {\r\n\t\tlabels[k] = v\r\n\t}\r\n\tlabels[github.EventGUID] = eventGUID\r\n\treturn NewProwJob(PresubmitSpec(job, refs), labels)\r\n}","code-length":132,"reference":"\/\/ NewPresubmit converts a config.Presubmit into a prowapi.ProwJob.\n\/\/ The prowapi.Refs are configured correctly per the pr, baseSHA.\n\/\/ The eventGUID becomes a github.EventGUID label.","result":"Create a new PR.","score":[0.0017,0.0218]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PresubmitSpec(p config.Presubmit, refs prowapi.Refs) prowapi.ProwJobSpec {\r\n\tpjs := specFromJobBase(p.JobBase)\r\n\tpjs.Type = prowapi.PresubmitJob\r\n\tpjs.Context = p.Context\r\n\tpjs.Report = !p.SkipReport\r\n\tpjs.RerunCommand = p.RerunCommand\r\n\tif p.JenkinsSpec != nil {\r\n\t\tpjs.JenkinsSpec = &prowapi.JenkinsSpec{\r\n\t\t\tGitHubBranchSourceJob: p.JenkinsSpec.GitHubBranchSourceJob,\r\n\t\t}\r\n\t}\r\n\tpjs.Refs = completePrimaryRefs(refs, p.JobBase)\r\n\treturn pjs\r\n}","code-length":198,"reference":"\/\/ PresubmitSpec initializes a ProwJobSpec for a given presubmit job.","result":"Generate the spec for the job.","score":[0.1179,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PostsubmitSpec(p config.Postsubmit, refs prowapi.Refs) prowapi.ProwJobSpec {\r\n\tpjs := specFromJobBase(p.JobBase)\r\n\tpjs.Type = prowapi.PostsubmitJob\r\n\tpjs.Context = p.Context\r\n\tpjs.Report = !p.SkipReport\r\n\tpjs.Refs = completePrimaryRefs(refs, p.JobBase)\r\n\tif p.JenkinsSpec != nil {\r\n\t\tpjs.JenkinsSpec = &prowapi.JenkinsSpec{\r\n\t\t\tGitHubBranchSourceJob: p.JenkinsSpec.GitHubBranchSourceJob,\r\n\t\t}\r\n\t}\r\n\treturn pjs\r\n}","code-length":180,"reference":"\/\/ PostsubmitSpec initializes a ProwJobSpec for a given postsubmit job.","result":"Generate the spec for the postsubmit job.","score":[0.1647,0.2635]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PeriodicSpec(p config.Periodic) prowapi.ProwJobSpec {\r\n\tpjs := specFromJobBase(p.JobBase)\r\n\tpjs.Type = prowapi.PeriodicJob\r\n\treturn pjs\r\n}","code-length":67,"reference":"\/\/ PeriodicSpec initializes a ProwJobSpec for a given periodic job.","result":"Generate the spec file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc BatchSpec(p config.Presubmit, refs prowapi.Refs) prowapi.ProwJobSpec {\r\n\tpjs := specFromJobBase(p.JobBase)\r\n\tpjs.Type = prowapi.BatchJob\r\n\tpjs.Context = p.Context\r\n\tpjs.Refs = completePrimaryRefs(refs, p.JobBase)\r\n\treturn pjs\r\n}","code-length":105,"reference":"\/\/ BatchSpec initializes a ProwJobSpec for a given batch job and ref spec.","result":"Generate the batch job spec.","score":[0.0759,0.2095]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PartitionActive(pjs []prowapi.ProwJob) (pending, triggered chan prowapi.ProwJob) {\r\n\t\r\n\tpendingCount, triggeredCount := 0, 0\r\n\tfor _, pj := range pjs {\r\n\t\tswitch pj.Status.State {\r\n\t\tcase prowapi.PendingState:\r\n\t\t\tpendingCount++\r\n\t\tcase prowapi.TriggeredState:\r\n\t\t\ttriggeredCount++\r\n\t\t}\r\n\t}\r\n\tpending = make(chan prowapi.ProwJob, pendingCount)\r\n\ttriggered = make(chan prowapi.ProwJob, triggeredCount)\r\n\t\r\n\tfor _, pj := range pjs {\r\n\t\tswitch pj.Status.State {\r\n\t\tcase prowapi.PendingState:\r\n\t\t\tpending <- pj\r\n\t\tcase prowapi.TriggeredState:\r\n\t\t\ttriggered <- pj\r\n\t\t}\r\n\t}\r\n\tclose(pending)\r\n\tclose(triggered)\r\n\treturn pending, triggered\r\n}","code-length":270,"reference":"\/\/ PartitionActive separates the provided prowjobs into pending and triggered\n\/\/ and returns them inside channels so that they can be consumed in parallel\n\/\/ by different goroutines. Complete prowjobs are filtered out. Controller\n\/\/ loops need to handle pending jobs first so they can conform to maximum\n\/\/ concurrency requirements that different jobs may have.","result":"Partition the active jobs in the cluster.","score":[0.0002,0.0294]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ProwJobFields(pj *prowapi.ProwJob) logrus.Fields {\r\n\tfields := make(logrus.Fields)\r\n\tfields[\"name\"] = pj.ObjectMeta.Name\r\n\tfields[\"job\"] = pj.Spec.Job\r\n\tfields[\"type\"] = pj.Spec.Type\r\n\tif len(pj.ObjectMeta.Labels[github.EventGUID]) > 0 {\r\n\t\tfields[github.EventGUID] = pj.ObjectMeta.Labels[github.EventGUID]\r\n\t}\r\n\tif pj.Spec.Refs != nil && len(pj.Spec.Refs.Pulls) == 1 {\r\n\t\tfields[github.PrLogField] = pj.Spec.Refs.Pulls[0].Number\r\n\t\tfields[github.RepoLogField] = pj.Spec.Refs.Repo\r\n\t\tfields[github.OrgLogField] = pj.Spec.Refs.Org\r\n\t}\r\n\tif pj.Spec.JenkinsSpec != nil {\r\n\t\tfields[\"github_based_job\"] = pj.Spec.JenkinsSpec.GitHubBranchSourceJob\r\n\t}\r\n\treturn fields\r\n}","code-length":289,"reference":"\/\/ ProwJobFields extracts logrus fields from a prowjob useful for logging.","result":"Log the fields of the pj.","score":[0.0839,0.0476]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ClusterToCtx(cluster string) string {\r\n\tif cluster == kube.InClusterContext {\r\n\t\treturn kube.DefaultClusterAlias\r\n\t}\r\n\treturn cluster\r\n}","code-length":53,"reference":"\/\/ ClusterToCtx converts the prow job's cluster to a cluster context","result":"Generate the code.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pluginHelp *PluginHelp) AddCommand(command Command) {\r\n\tpluginHelp.Commands = append(pluginHelp.Commands, command)\r\n}","code-length":44,"reference":"\/\/ AddCommand registers new help text for a bot command.","result":"Add commands to plugins.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *FakeProwJobs) Get(name string, options v1.GetOptions) (result *prowjobsv1.ProwJob, err error) {\r\n\tobj, err := c.Fake.\r\n\t\tInvokes(testing.NewGetAction(prowjobsResource, c.ns, name), &prowjobsv1.ProwJob{})\r\n\tif obj == nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn obj.(*prowjobsv1.ProwJob), err\r\n}","code-length":135,"reference":"\/\/ Get takes name of the prowJob, and returns the corresponding prowJob object, and an error if there is any.","result":"Get the specified ProwJob.","score":[0.007,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *FakeProwJobs) Watch(opts v1.ListOptions) (watch.Interface, error) {\r\n\treturn c.Fake.\r\n\t\tInvokesWatch(testing.NewWatchAction(prowjobsResource, c.ns, opts))\r\n}","code-length":70,"reference":"\/\/ Watch returns a watch.Interface that watches the requested prowJobs.","result":"Watch a resource for changes to be persisted.","score":[0.1286,0.102]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *FakeProwJobs) Delete(name string, options *v1.DeleteOptions) error {\r\n\t_, err := c.Fake.\r\n\t\tInvokes(testing.NewDeleteAction(prowjobsResource, c.ns, name), &prowjobsv1.ProwJob{})\r\n\treturn err\r\n}","code-length":88,"reference":"\/\/ Delete takes name of the prowJob and deletes it. Returns an error if one occurs.","result":"Delete the ProwJob.","score":[0.0064,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *FakeProwJobs) Patch(name string, pt types.PatchType, data []byte, subresources ...string) (result *prowjobsv1.ProwJob, err error) {\r\n\tobj, err := c.Fake.\r\n\t\tInvokes(testing.NewPatchSubresourceAction(prowjobsResource, c.ns, name, data, subresources...), &prowjobsv1.ProwJob{})\r\n\tif obj == nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn obj.(*prowjobsv1.ProwJob), err\r\n}","code-length":151,"reference":"\/\/ Patch applies the patch and returns the patched prowJob.","result":"Test if the file contains a comment.","score":[0.1052,0.0515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *Tide) MergeMethod(org, repo string) github.PullRequestMergeType {\r\n\tname := org + \"\/\" + repo\r\n\tv, ok := t.MergeType[name]\r\n\tif !ok {\r\n\t\tif ov, found := t.MergeType[org]; found {\r\n\t\t\treturn ov\r\n\t\t}\r\n\t\treturn github.MergeMerge\r\n\t}\r\n\treturn v\r\n}","code-length":111,"reference":"\/\/ MergeMethod returns the merge method to use for a repo. The default of merge is\n\/\/ returned when not overridden.","result":"Define the merge method.","score":[0.0064,0.0518]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tq *TideQuery) Query() string {\r\n\ttoks := []string{\"is:pr\", \"state:open\"}\r\n\tfor _, o := range tq.Orgs {\r\n\t\ttoks = append(toks, fmt.Sprintf(\"org:\\\"%s\\\"\", o))\r\n\t}\r\n\tfor _, r := range tq.Repos {\r\n\t\ttoks = append(toks, fmt.Sprintf(\"repo:\\\"%s\\\"\", r))\r\n\t}\r\n\tfor _, r := range tq.ExcludedRepos {\r\n\t\ttoks = append(toks, fmt.Sprintf(\"-repo:\\\"%s\\\"\", r))\r\n\t}\r\n\tfor _, b := range tq.ExcludedBranches {\r\n\t\ttoks = append(toks, fmt.Sprintf(\"-base:\\\"%s\\\"\", b))\r\n\t}\r\n\tfor _, b := range tq.IncludedBranches {\r\n\t\ttoks = append(toks, fmt.Sprintf(\"base:\\\"%s\\\"\", b))\r\n\t}\r\n\tfor _, l := range tq.Labels {\r\n\t\ttoks = append(toks, fmt.Sprintf(\"label:\\\"%s\\\"\", l))\r\n\t}\r\n\tfor _, l := range tq.MissingLabels {\r\n\t\ttoks = append(toks, fmt.Sprintf(\"-label:\\\"%s\\\"\", l))\r\n\t}\r\n\tif tq.Milestone != \"\" {\r\n\t\ttoks = append(toks, fmt.Sprintf(\"milestone:\\\"%s\\\"\", tq.Milestone))\r\n\t}\r\n\tif tq.ReviewApprovedRequired {\r\n\t\ttoks = append(toks, \"review:approved\")\r\n\t}\r\n\treturn strings.Join(toks, \" \")\r\n}","code-length":442,"reference":"\/\/ Query returns the corresponding github search string for the tide query.","result":"Query the tide.","score":[0.0242,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tq TideQuery) ForRepo(org, repo string) bool {\r\n\tfullName := fmt.Sprintf(\"%s\/%s\", org, repo)\r\n\tfor _, queryOrg := range tq.Orgs {\r\n\t\tif queryOrg != org {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tfor _, excludedRepo := range tq.ExcludedRepos {\r\n\t\t\tif excludedRepo == fullName {\r\n\t\t\t\treturn false\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn true\r\n\t}\r\n\tfor _, queryRepo := range tq.Repos {\r\n\t\tif queryRepo == fullName {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":183,"reference":"\/\/ ForRepo indicates if the tide query applies to the specified repo.","result":"Query tide for repo .","score":[0.0593,0.0885]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tqs TideQueries) OrgExceptionsAndRepos() (map[string]sets.String, sets.String) {\r\n\torgs := make(map[string]sets.String)\r\n\tfor i := range tqs {\r\n\t\tfor _, org := range tqs[i].Orgs {\r\n\t\t\tapplicableRepos := sets.NewString(reposInOrg(org, tqs[i].ExcludedRepos)...)\r\n\t\t\tif excepts, ok := orgs[org]; !ok {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\torgs[org] = applicableRepos\r\n\t\t\t} else {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\torgs[org] = excepts.Intersection(applicableRepos)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\trepos := sets.NewString()\r\n\tfor i := range tqs {\r\n\t\trepos.Insert(tqs[i].Repos...)\r\n\t}\r\n\t\r\n\treposList := repos.UnsortedList()\r\n\tfor _, excepts := range orgs {\r\n\t\texcepts.Delete(reposList...)\r\n\t}\r\n\treturn orgs, repos\r\n}","code-length":281,"reference":"\/\/ OrgExceptionsAndRepos determines which orgs and repos a set of queries cover.\n\/\/ Output is returned as a mapping from 'included org'->'repos excluded in the org'\n\/\/ and a set of included repos.","result":"Generate the TideQuery.","score":[0.0,0.0167]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tqs TideQueries) QueryMap() *QueryMap {\r\n\treturn &QueryMap{\r\n\t\tqueries: tqs,\r\n\t\tcache:   make(map[string]TideQueries),\r\n\t}\r\n}","code-length":65,"reference":"\/\/ QueryMap creates a QueryMap from TideQueries","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (qm *QueryMap) ForRepo(org, repo string) TideQueries {\r\n\tres := TideQueries(nil)\r\n\tfullName := fmt.Sprintf(\"%s\/%s\", org, repo)\r\n\tqm.Lock()\r\n\tdefer qm.Unlock()\r\n\tif qs, ok := qm.cache[fullName]; ok {\r\n\t\treturn append(res, qs...)\r\n\t}\r\n\t\r\n\tfor _, query := range qm.queries {\r\n\t\tif query.ForRepo(org, repo) {\r\n\t\t\tres = append(res, query)\r\n\t\t}\r\n\t}\r\n\tqm.cache[fullName] = res\r\n\treturn res\r\n}","code-length":177,"reference":"\/\/ ForRepo returns the tide queries that apply to a repo.","result":"Query the TideQueryMap.","score":[0.0284,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cp *TideContextPolicy) Validate() error {\r\n\tif inter := sets.NewString(cp.RequiredContexts...).Intersection(sets.NewString(cp.OptionalContexts...)); inter.Len() > 0 {\r\n\t\treturn fmt.Errorf(\"contexts %s are defined as required and optional\", strings.Join(inter.List(), \", \"))\r\n\t}\r\n\tif inter := sets.NewString(cp.RequiredContexts...).Intersection(sets.NewString(cp.RequiredIfPresentContexts...)); inter.Len() > 0 {\r\n\t\treturn fmt.Errorf(\"contexts %s are defined as required and required if present\", strings.Join(inter.List(), \", \"))\r\n\t}\r\n\tif inter := sets.NewString(cp.OptionalContexts...).Intersection(sets.NewString(cp.RequiredIfPresentContexts...)); inter.Len() > 0 {\r\n\t\treturn fmt.Errorf(\"contexts %s are defined as optional and required if present\", strings.Join(inter.List(), \", \"))\r\n\t}\r\n\treturn nil\r\n}","code-length":251,"reference":"\/\/ Validate returns an error if any contexts are listed more than once in the config.","result":"Validate the context.","score":[0.0064,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c Config) GetTideContextPolicy(org, repo, branch string) (*TideContextPolicy, error) {\r\n\toptions := parseTideContextPolicyOptions(org, repo, branch, c.Tide.ContextOptions)\r\n\t\r\n\trequired := sets.NewString(options.RequiredContexts...)\r\n\trequiredIfPresent := sets.NewString(options.RequiredIfPresentContexts...)\r\n\toptional := sets.NewString(options.OptionalContexts...)\r\n\t\r\n\tprowRequired, prowRequiredIfPresent, prowOptional := BranchRequirements(org, repo, branch, c.Presubmits)\r\n\trequired.Insert(prowRequired...)\r\n\trequiredIfPresent.Insert(prowRequiredIfPresent...)\r\n\toptional.Insert(prowOptional...)\r\n\t\r\n\tif options.FromBranchProtection != nil && *options.FromBranchProtection {\r\n\t\tbp, err := c.GetBranchProtection(org, repo, branch)\r\n\t\tif err != nil {\r\n\t\t\tlogrus.WithError(err).Warningf(\"Error getting branch protection for %s\/%s+%s\", org, repo, branch)\r\n\t\t} else if bp != nil && bp.Protect != nil && *bp.Protect && bp.RequiredStatusChecks != nil {\r\n\t\t\trequired.Insert(bp.RequiredStatusChecks.Contexts...)\r\n\t\t}\r\n\t}\r\n\tt := &TideContextPolicy{\r\n\t\tRequiredContexts:          required.List(),\r\n\t\tRequiredIfPresentContexts: requiredIfPresent.List(),\r\n\t\tOptionalContexts:          optional.List(),\r\n\t\tSkipUnknownContexts:       options.SkipUnknownContexts,\r\n\t}\r\n\tif err := t.Validate(); err != nil {\r\n\t\treturn t, err\r\n\t}\r\n\treturn t, nil\r\n}","code-length":431,"reference":"\/\/ GetTideContextPolicy parses the prow config to find context merge options.\n\/\/ If none are set, it will use the prow jobs configured and use the default github combined status.\n\/\/ Otherwise if set it will use the branch protection setting, or the listed jobs.","result":"Validate the tide context policy.","score":[0.0001,0.0244]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cp *TideContextPolicy) IsOptional(c string) bool {\r\n\tif sets.NewString(cp.OptionalContexts...).Has(c) {\r\n\t\treturn true\r\n\t}\r\n\tif sets.NewString(cp.RequiredContexts...).Has(c) {\r\n\t\treturn false\r\n\t}\r\n\t\r\n\tif sets.NewString(cp.RequiredIfPresentContexts...).Has(c) {\r\n\t\treturn false\r\n\t}\r\n\tif cp.SkipUnknownContexts != nil && *cp.SkipUnknownContexts {\r\n\t\treturn true\r\n\t}\r\n\treturn false\r\n}","code-length":158,"reference":"\/\/ IsOptional checks whether a context can be ignored.\n\/\/ Will return true if\n\/\/ - context is registered as optional\n\/\/ - required contexts are registered and the context provided is not required\n\/\/ Will return false otherwise. Every context is required.","result":"Check if a context is optional.","score":[0.0008,0.0947]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cp *TideContextPolicy) MissingRequiredContexts(contexts []string) []string {\r\n\tif len(cp.RequiredContexts) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\texistingContexts := sets.NewString()\r\n\tfor _, c := range contexts {\r\n\t\texistingContexts.Insert(c)\r\n\t}\r\n\tvar missingContexts []string\r\n\tfor c := range sets.NewString(cp.RequiredContexts...).Difference(existingContexts) {\r\n\t\tmissingContexts = append(missingContexts, c)\r\n\t}\r\n\treturn missingContexts\r\n}","code-length":149,"reference":"\/\/ MissingRequiredContexts discard the optional contexts and only look of extra required contexts that are not provided.","result":"Check if the context is not in.","score":[0.046,0.0938]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ValidateWebhook(w http.ResponseWriter, r *http.Request, hmacSecret []byte) (string, string, []byte, bool, int) {\r\n\tdefer r.Body.Close()\r\n\t\r\n\tif r.Method == http.MethodGet {\r\n\t\treturn \"\", \"\", nil, false, http.StatusOK\r\n\t}\r\n\t\r\n\tif r.Method != http.MethodPost {\r\n\t\tresponseHTTPError(w, http.StatusMethodNotAllowed, \"405 Method not allowed\")\r\n\t\treturn \"\", \"\", nil, false, http.StatusMethodNotAllowed\r\n\t}\r\n\teventType := r.Header.Get(\"X-GitHub-Event\")\r\n\tif eventType == \"\" {\r\n\t\tresponseHTTPError(w, http.StatusBadRequest, \"400 Bad Request: Missing X-GitHub-Event Header\")\r\n\t\treturn \"\", \"\", nil, false, http.StatusBadRequest\r\n\t}\r\n\teventGUID := r.Header.Get(\"X-GitHub-Delivery\")\r\n\tif eventGUID == \"\" {\r\n\t\tresponseHTTPError(w, http.StatusBadRequest, \"400 Bad Request: Missing X-GitHub-Delivery Header\")\r\n\t\treturn \"\", \"\", nil, false, http.StatusBadRequest\r\n\t}\r\n\tsig := r.Header.Get(\"X-Hub-Signature\")\r\n\tif sig == \"\" {\r\n\t\tresponseHTTPError(w, http.StatusForbidden, \"403 Forbidden: Missing X-Hub-Signature\")\r\n\t\treturn \"\", \"\", nil, false, http.StatusForbidden\r\n\t}\r\n\tcontentType := r.Header.Get(\"content-type\")\r\n\tif contentType != \"application\/json\" {\r\n\t\tresponseHTTPError(w, http.StatusBadRequest, \"400 Bad Request: Hook only accepts content-type: application\/json - please reconfigure this hook on GitHub\")\r\n\t\treturn \"\", \"\", nil, false, http.StatusBadRequest\r\n\t}\r\n\tpayload, err := ioutil.ReadAll(r.Body)\r\n\tif err != nil {\r\n\t\tresponseHTTPError(w, http.StatusInternalServerError, \"500 Internal Server Error: Failed to read request body\")\r\n\t\treturn \"\", \"\", nil, false, http.StatusInternalServerError\r\n\t}\r\n\t\r\n\tif !ValidatePayload(payload, sig, hmacSecret) {\r\n\t\tresponseHTTPError(w, http.StatusForbidden, \"403 Forbidden: Invalid X-Hub-Signature\")\r\n\t\treturn \"\", \"\", nil, false, http.StatusForbidden\r\n\t}\r\n\treturn eventType, eventGUID, payload, true, http.StatusOK\r\n}","code-length":605,"reference":"\/\/ ValidateWebhook ensures that the provided request conforms to the\n\/\/ format of a GitHub webhook and the payload can be validated with\n\/\/ the provided hmac secret. It returns the event type, the event guid,\n\/\/ the payload of the request, whether the webhook is valid or not,\n\/\/ and finally the resultant HTTP status code","result":"Code too long,keep in 512.","score":[0,0.0097]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HelpProvider(enabledRepos []string) (*pluginhelp.PluginHelp, error) {\r\n\treturn &pluginhelp.PluginHelp{\r\n\t\t\tDescription: `The needs-rebase plugin manages the '` + labels.NeedsRebase + `' label by removing it from Pull Requests that are mergeable and adding it to those which are not.\r\nThe plugin reacts to commit changes on PRs in addition to periodically scanning all open PRs for any changes to mergeability that could have resulted from changes in other PRs.`,\r\n\t\t},\r\n\t\tnil\r\n}","code-length":138,"reference":"\/\/ HelpProvider constructs the PluginHelp for this plugin that takes into account enabled repositories.\n\/\/ HelpProvider defines the type for function that construct the PluginHelp for plugins.","result":"Provide the help message.","score":[0.001,0.0202]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HandleEvent(log *logrus.Entry, ghc githubClient, pre *github.PullRequestEvent) error {\r\n\tif pre.Action != github.PullRequestActionOpened && pre.Action != github.PullRequestActionSynchronize && pre.Action != github.PullRequestActionReopened {\r\n\t\treturn nil\r\n\t}\r\n\t\r\n\t\r\n\tsleep(time.Second * 5)\r\n\torg := pre.Repo.Owner.Login\r\n\trepo := pre.Repo.Name\r\n\tnumber := pre.Number\r\n\tsha := pre.PullRequest.Head.SHA\r\n\tmergeable, err := ghc.IsMergeable(org, repo, number, sha)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tissueLabels, err := ghc.GetIssueLabels(org, repo, number)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\thasLabel := github.HasLabel(labels.NeedsRebase, issueLabels)\r\n\treturn takeAction(log, ghc, org, repo, number, pre.PullRequest.User.Login, hasLabel, mergeable)\r\n}","code-length":274,"reference":"\/\/ HandleEvent handles a GitHub PR event to determine if the \"needs-rebase\"\n\/\/ label needs to be added or removed. It depends on GitHub mergeability check\n\/\/ to decide the need for a rebase.","result":"Handle PR events.","score":[0.0,0.0324]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HandleAll(log *logrus.Entry, ghc githubClient, config *plugins.Configuration) error {\r\n\tlog.Info(\"Checking all PRs.\")\r\n\torgs, repos := config.EnabledReposForExternalPlugin(PluginName)\r\n\tif len(orgs) == 0 && len(repos) == 0 {\r\n\t\tlog.Warnf(\"No repos have been configured for the %s plugin\", PluginName)\r\n\t\treturn nil\r\n\t}\r\n\tvar buf bytes.Buffer\r\n\tfmt.Fprint(&buf, \"is:pr is:open\")\r\n\tfor _, org := range orgs {\r\n\t\tfmt.Fprintf(&buf, \" org:\\\"%s\\\"\", org)\r\n\t}\r\n\tfor _, repo := range repos {\r\n\t\tfmt.Fprintf(&buf, \" repo:\\\"%s\\\"\", repo)\r\n\t}\r\n\tprs, err := search(context.Background(), log, ghc, buf.String())\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tlog.Infof(\"Considering %d PRs.\", len(prs))\r\n\tfor _, pr := range prs {\r\n\t\t\r\n\t\tif pr.Mergeable == githubql.MergeableStateUnknown {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\torg := string(pr.Repository.Owner.Login)\r\n\t\trepo := string(pr.Repository.Name)\r\n\t\tnum := int(pr.Number)\r\n\t\tl := log.WithFields(logrus.Fields{\r\n\t\t\t\"org\":  org,\r\n\t\t\t\"repo\": repo,\r\n\t\t\t\"pr\":   num,\r\n\t\t})\r\n\t\thasLabel := false\r\n\t\tfor _, label := range pr.Labels.Nodes {\r\n\t\t\tif label.Name == labels.NeedsRebase {\r\n\t\t\t\thasLabel = true\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\terr := takeAction(\r\n\t\t\tl,\r\n\t\t\tghc,\r\n\t\t\torg,\r\n\t\t\trepo,\r\n\t\t\tnum,\r\n\t\t\tstring(pr.Author.Login),\r\n\t\t\thasLabel,\r\n\t\t\tpr.Mergeable == githubql.MergeableStateMergeable,\r\n\t\t)\r\n\t\tif err != nil {\r\n\t\t\tl.WithError(err).Error(\"Error handling PR.\")\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":603,"reference":"\/\/ HandleAll checks all orgs and repos that enabled this plugin for open PRs to\n\/\/ determine if the \"needs-rebase\" label needs to be added or removed. It\n\/\/ depends on GitHub's mergeability check to decide the need for a rebase.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDryRunProwJobClient(deckURL string) prowv1.ProwJobInterface {\r\n\treturn &dryRunProwJobClient{\r\n\t\tdeckURL: deckURL,\r\n\t\tclient:  &http.Client{},\r\n\t}\r\n}","code-length":74,"reference":"\/\/ NewDryRunProwJobClient creates a new client that uses deck as a read-only proxy for ProwJob data","result":"Test if the client is created in production.","score":[0.0511,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dryRunProwJobClient) Create(*prowapi.ProwJob) (*prowapi.ProwJob, error) {\r\n\treturn nil, nil\r\n}","code-length":53,"reference":"\/\/ Create does nothing on a dry-run client","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dryRunProwJobClient) Update(*prowapi.ProwJob) (*prowapi.ProwJob, error) {\r\n\treturn nil, nil\r\n}","code-length":53,"reference":"\/\/ Update does nothing on a dry-run client","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dryRunProwJobClient) UpdateStatus(*prowapi.ProwJob) (*prowapi.ProwJob, error) {\r\n\treturn nil, nil\r\n}","code-length":54,"reference":"\/\/ UpdateStatus does nothing on a dry-run client","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dryRunProwJobClient) Delete(name string, options *metav1.DeleteOptions) error {\r\n\treturn nil\r\n}","code-length":44,"reference":"\/\/ Delete does nothing on a dry-run client","result":"Delete the file.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dryRunProwJobClient) DeleteCollection(options *metav1.DeleteOptions, listOptions metav1.ListOptions) error {\r\n\treturn nil\r\n}","code-length":49,"reference":"\/\/ DeleteCollection does nothing on a dry-run client","result":"Delete the entire object.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dryRunProwJobClient) Get(name string, options metav1.GetOptions) (*prowapi.ProwJob, error) {\r\n\treturn nil, nil\r\n}","code-length":55,"reference":"\/\/ Get does nothing on a dry-run client","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dryRunProwJobClient) List(opts metav1.ListOptions) (*prowapi.ProwJobList, error) {\r\n\tvar jl prowapi.ProwJobList\r\n\terr := c.request(\"\/prowjobs.js\", map[string]string{\"labelSelector\": opts.LabelSelector}, &jl)\r\n\treturn &jl, err\r\n}","code-length":102,"reference":"\/\/ List reaches out to `deck` to retrieve the ProwJobs on the cluster via proxy","result":"List all prowjobs in a single file.","score":[0.0515,0.0704]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dryRunProwJobClient) Watch(opts metav1.ListOptions) (watch.Interface, error) {\r\n\treturn nil, nil\r\n}","code-length":46,"reference":"\/\/ Watch does nothing on a dry-run client","result":"Watch for changes to the.","score":[0.1319,0.0649]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dryRunProwJobClient) Patch(name string, pt types.PatchType, data []byte, subresources ...string) (result *prowapi.ProwJob, err error) {\r\n\treturn nil, nil\r\n}","code-length":65,"reference":"\/\/ Patch does nothing on a dry-run client","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *controller) hasSynced() bool {\r\n\tif !c.pjInformer.HasSynced() {\r\n\t\tif c.wait != \"prowjobs\" {\r\n\t\t\tc.wait = \"prowjobs\"\r\n\t\t\tns := c.pjNamespace()\r\n\t\t\tif ns == \"\" {\r\n\t\t\t\tns = \"controllers\"\r\n\t\t\t}\r\n\t\t\tlogrus.Infof(\"Waiting on prowjobs in %s namespace...\", ns)\r\n\t\t}\r\n\t\treturn false\r\n\t}\r\n\tif !c.prowJobsDone {\r\n\t\tc.prowJobsDone = true\r\n\t\tlogrus.Info(\"Synced prow jobs\")\r\n\t}\r\n\tif c.pipelinesDone == nil {\r\n\t\tc.pipelinesDone = map[string]bool{}\r\n\t}\r\n\tfor n, cfg := range c.pipelines {\r\n\t\tif !cfg.informer.Informer().HasSynced() {\r\n\t\t\tif c.wait != n {\r\n\t\t\t\tc.wait = n\r\n\t\t\t\tlogrus.Infof(\"Waiting on %s pipelines...\", n)\r\n\t\t\t}\r\n\t\t\treturn false\r\n\t\t} else if !c.pipelinesDone[n] {\r\n\t\t\tc.pipelinesDone[n] = true\r\n\t\t\tlogrus.Infof(\"Synced %s pipelines\", n)\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":356,"reference":"\/\/ hasSynced returns true when every prowjob and pipeline informer has synced.","result":"Test if the controller hasSynced.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *controller) Run(threads int, stop <-chan struct{}) error {\r\n\tdefer runtime.HandleCrash()\r\n\tdefer c.workqueue.ShutDown()\r\n\tlogrus.Info(\"Starting Pipeline controller\")\r\n\tlogrus.Info(\"Waiting for informer caches to sync\")\r\n\tif ok := cache.WaitForCacheSync(stop, c.hasSynced); !ok {\r\n\t\treturn fmt.Errorf(\"failed to wait for caches to sync\")\r\n\t}\r\n\tlogrus.Info(\"Starting workers\")\r\n\tfor i := 0; i < threads; i++ {\r\n\t\tgo wait.Until(c.runWorker, time.Second, stop)\r\n\t}\r\n\tlogrus.Info(\"Started workers\")\r\n\t<-stop\r\n\tlogrus.Info(\"Shutting down workers\")\r\n\treturn nil\r\n}","code-length":209,"reference":"\/\/ Run starts threads workers, returning after receiving a stop signal.","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *controller) runWorker() {\r\n\tfor {\r\n\t\tkey, shutdown := c.workqueue.Get()\r\n\t\tif shutdown {\r\n\t\t\treturn\r\n\t\t}\r\n\t\tfunc() {\r\n\t\t\tdefer c.workqueue.Done(key)\r\n\t\t\tif err := reconcile(c, key.(string)); err != nil {\r\n\t\t\t\truntime.HandleError(fmt.Errorf(\"failed to reconcile %s: %v\", key, err))\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tc.workqueue.Forget(key)\r\n\t\t}()\r\n\t}\r\n}","code-length":160,"reference":"\/\/ runWorker dequeues to reconcile, until the queue has closed.","result":"Run the worker .","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc fromKey(key string) (string, string, string, error) {\r\n\tparts := strings.Split(key, \"\/\")\r\n\tif len(parts) != 3 {\r\n\t\treturn \"\", \"\", \"\", fmt.Errorf(\"bad key: %q\", key)\r\n\t}\r\n\treturn parts[0], parts[1], parts[2], nil\r\n}","code-length":94,"reference":"\/\/ fromKey converts toKey back into its parts","result":"Create a new key.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *controller) enqueueKey(ctx string, obj interface{}) {\r\n\tswitch o := obj.(type) {\r\n\tcase *prowjobv1.ProwJob:\r\n\t\tns := o.Spec.Namespace\r\n\t\tif ns == \"\" {\r\n\t\t\tns = o.Namespace\r\n\t\t}\r\n\t\tc.workqueue.AddRateLimited(toKey(ctx, ns, o.Name))\r\n\tcase *pipelinev1alpha1.PipelineRun:\r\n\t\tc.workqueue.AddRateLimited(toKey(ctx, o.Namespace, o.Name))\r\n\tdefault:\r\n\t\tlogrus.Warnf(\"cannot enqueue unknown type %T: %v\", o, obj)\r\n\t\treturn\r\n\t}\r\n}","code-length":192,"reference":"\/\/ enqueueKey schedules an item for reconciliation","result":"Register the key to the workqueue.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc finalState(status prowjobv1.ProwJobState) bool {\r\n\tswitch status {\r\n\tcase \"\", prowjobv1.PendingState, prowjobv1.TriggeredState:\r\n\t\treturn false\r\n\t}\r\n\treturn true\r\n}","code-length":75,"reference":"\/\/ finalState returns true if the prowjob has already finished","result":"Check if the final state is valid.","score":[0.1488,0.1933]}
{"code":"\/*is used to<extra_id_0>\r\nfunc description(cond duckv1alpha1.Condition, fallback string) string {\r\n\tswitch {\r\n\tcase cond.Message != \"\":\r\n\t\treturn cond.Message\r\n\tcase cond.Reason != \"\":\r\n\t\treturn cond.Reason\r\n\t}\r\n\treturn fallback\r\n}","code-length":80,"reference":"\/\/ description computes the ProwJobStatus description for this condition or falling back to a default if none is provided.","result":"Generate the description.","score":[0.002,0.0287]}
{"code":"\/*is used to<extra_id_0>\r\nfunc prowJobStatus(ps pipelinev1alpha1.PipelineRunStatus) (prowjobv1.ProwJobState, string) {\r\n\tstarted := ps.StartTime\r\n\tfinished := ps.CompletionTime\r\n\tpcond := ps.GetCondition(duckv1alpha1.ConditionSucceeded)\r\n\tif pcond == nil {\r\n\t\tif !finished.IsZero() {\r\n\t\t\treturn prowjobv1.ErrorState, descMissingCondition\r\n\t\t}\r\n\t\treturn prowjobv1.TriggeredState, descScheduling\r\n\t}\r\n\tcond := *pcond\r\n\tswitch {\r\n\tcase cond.Status == untypedcorev1.ConditionTrue:\r\n\t\treturn prowjobv1.SuccessState, description(cond, descSucceeded)\r\n\tcase cond.Status == untypedcorev1.ConditionFalse:\r\n\t\treturn prowjobv1.FailureState, description(cond, descFailed)\r\n\tcase started.IsZero():\r\n\t\treturn prowjobv1.TriggeredState, description(cond, descInitializing)\r\n\tcase cond.Status == untypedcorev1.ConditionUnknown, finished.IsZero():\r\n\t\treturn prowjobv1.PendingState, description(cond, descRunning)\r\n\t}\r\n\tlogrus.Warnf(\"Unknown condition %#v\", cond)\r\n\treturn prowjobv1.ErrorState, description(cond, descUnknown)\r\n}","code-length":346,"reference":"\/\/ prowJobStatus returns the desired state and description based on the pipeline status","result":"Generate the prow job status .","score":[0.0715,0.0813]}
{"code":"\/*is used to<extra_id_0>\r\nfunc pipelineMeta(pj prowjobv1.ProwJob) metav1.ObjectMeta {\r\n\tlabels, annotations := decorate.LabelsAndAnnotationsForJob(pj)\r\n\treturn metav1.ObjectMeta{\r\n\t\tAnnotations: annotations,\r\n\t\tName:        pj.Name,\r\n\t\tNamespace:   pj.Spec.Namespace,\r\n\t\tLabels:      labels,\r\n\t}\r\n}","code-length":109,"reference":"\/\/ pipelineMeta builds the pipeline metadata from prow job definition","result":"Generate the pipeline meta .","score":[0.125,0.1974]}
{"code":"\/*is used to<extra_id_0>\r\nfunc sourceURL(pj prowjobv1.ProwJob) string {\r\n\tif pj.Spec.Refs == nil {\r\n\t\treturn \"\"\r\n\t}\r\n\tsourceURL := pj.Spec.Refs.CloneURI\r\n\tif sourceURL == \"\" {\r\n\t\tsourceURL = fmt.Sprintf(\"%s.git\", pj.Spec.Refs.RepoLink)\r\n\t}\r\n\treturn sourceURL\r\n}","code-length":113,"reference":"\/\/ sourceURL returns the source URL from prow jobs repository reference","result":"Generate the sourceURL function.","score":[0.066,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc makePipelineGitResource(pj prowjobv1.ProwJob) *pipelinev1alpha1.PipelineResource {\r\n\tvar revision string\r\n\tif pj.Spec.Refs != nil {\r\n\t\tif len(pj.Spec.Refs.Pulls) > 0 {\r\n\t\t\trevision = pj.Spec.Refs.Pulls[0].SHA\r\n\t\t} else {\r\n\t\t\trevision = pj.Spec.Refs.BaseSHA\r\n\t\t}\r\n\t}\r\n\tpr := pipelinev1alpha1.PipelineResource{\r\n\t\tObjectMeta: pipelineMeta(pj),\r\n\t\tSpec: pipelinev1alpha1.PipelineResourceSpec{\r\n\t\t\tType: pipelinev1alpha1.PipelineResourceTypeGit,\r\n\t\t\tParams: []pipelinev1alpha1.Param{\r\n\t\t\t\t{\r\n\t\t\t\t\tName:  \"url\",\r\n\t\t\t\t\tValue: sourceURL(pj),\r\n\t\t\t\t},\r\n\t\t\t\t{\r\n\t\t\t\t\tName:  \"revision\",\r\n\t\t\t\t\tValue: revision,\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n\treturn &pr\r\n}","code-length":283,"reference":"\/\/ makePipelineGitResource creates a pipeline git resource from prow job","result":"Create a pipeline resource for a git repository.","score":[0.1819,0.2551]}
{"code":"\/*is used to<extra_id_0>\r\nfunc makePipelineRun(pj prowjobv1.ProwJob, pr *pipelinev1alpha1.PipelineResource) (*pipelinev1alpha1.PipelineRun, error) {\r\n\tif pj.Spec.PipelineRunSpec == nil {\r\n\t\treturn nil, errors.New(\"no PipelineSpec defined\")\r\n\t}\r\n\tp := pipelinev1alpha1.PipelineRun{\r\n\t\tObjectMeta: pipelineMeta(pj),\r\n\t\tSpec:       *pj.Spec.PipelineRunSpec.DeepCopy(),\r\n\t}\r\n\tbuildID := pj.Status.BuildID\r\n\tif buildID == \"\" {\r\n\t\treturn nil, errors.New(\"empty BuildID in status\")\r\n\t}\r\n\tp.Spec.Params = append(p.Spec.Params, pipelinev1alpha1.Param{\r\n\t\tName:  \"build_id\",\r\n\t\tValue: buildID,\r\n\t})\r\n\trb := pipelinev1alpha1.PipelineResourceBinding{\r\n\t\tName: pr.Name,\r\n\t\tResourceRef: pipelinev1alpha1.PipelineResourceRef{\r\n\t\t\tName:       pr.Name,\r\n\t\t\tAPIVersion: pr.APIVersion,\r\n\t\t},\r\n\t}\r\n\tp.Spec.Resources = append(p.Spec.Resources, rb)\r\n\treturn &p, nil\r\n}","code-length":333,"reference":"\/\/ makePipeline creates a PipelineRun from a prow job using the PipelineRunSpec defined in the prow job","result":"Create a pipeline run .","score":[0.0218,0.0633]}
{"code":"\/*is used to<extra_id_0>\r\nfunc matchingConfigs(org, repo, branch, label string, allConfigs []plugins.RequireMatchingLabel) []plugins.RequireMatchingLabel {\r\n\tvar filtered []plugins.RequireMatchingLabel\r\n\tfor _, cfg := range allConfigs {\r\n\t\t\r\n\t\tif (branch == \"\" && !cfg.Issues) || (branch != \"\" && !cfg.PRs) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tif org != cfg.Org ||\r\n\t\t\t(cfg.Repo != \"\" && cfg.Repo != repo) ||\r\n\t\t\t(cfg.Branch != \"\" && branch != \"\" && cfg.Branch != branch) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tif label != \"\" && !cfg.Re.MatchString(label) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tfiltered = append(filtered, cfg)\r\n\t}\r\n\treturn filtered\r\n}","code-length":223,"reference":"\/\/ matchingConfigs filters irrelevant RequireMtchingLabel configs from\n\/\/ the list of all configs.\n\/\/ `branch` should be empty for Issues and non-empty for PRs.\n\/\/ `label` should be omitted in the case of 'open' and 'reopen' actions.","result":"Filter the list of allConfigs to only return matching configs.","score":[0.0161,0.0729]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SuggestCodeChange(p lint.Problem) string {\r\n\tvar suggestion = \"\"\r\n\tfor regex, handler := range lintHandlersMap {\r\n\t\tmatches := regex.FindStringSubmatch(p.Text)\r\n\t\tsuggestion = handler(p, matches)\r\n\t\tif suggestion != \"\" && suggestion != p.LineText {\r\n\t\t\treturn formatSuggestion(suggestion)\r\n\t\t}\r\n\t}\r\n\treturn \"\"\r\n}","code-length":115,"reference":"\/\/ SuggestCodeChange returns code suggestions for a given lint.Problem\n\/\/ Returns empty string if no suggestion can be given","result":"Suggest code change.","score":[0.002,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ServeExternalPluginHelp(mux *http.ServeMux, log *logrus.Entry, provider ExternalPluginHelpProvider) {\r\n\tmux.HandleFunc(\r\n\t\t\"\/help\",\r\n\t\tfunc(w http.ResponseWriter, r *http.Request) {\r\n\t\t\tw.Header().Set(\"Cache-Control\", \"no-cache\")\r\n\t\t\tserverError := func(action string, err error) {\r\n\t\t\t\tlog.WithError(err).Errorf(\"Error %s.\", action)\r\n\t\t\t\tmsg := fmt.Sprintf(\"500 Internal server error %s: %v\", action, err)\r\n\t\t\t\thttp.Error(w, msg, http.StatusInternalServerError)\r\n\t\t\t}\r\n\t\t\tif r.Method != http.MethodPost {\r\n\t\t\t\tlog.Errorf(\"Invalid request method: %v.\", r.Method)\r\n\t\t\t\thttp.Error(w, \"405 Method not allowed\", http.StatusMethodNotAllowed)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tb, err := ioutil.ReadAll(r.Body)\r\n\t\t\tif err != nil {\r\n\t\t\t\tserverError(\"reading request body\", err)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tvar enabledRepos []string\r\n\t\t\tif err := json.Unmarshal(b, &enabledRepos); err != nil {\r\n\t\t\t\tserverError(\"unmarshaling request body\", err)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tif provider == nil {\r\n\t\t\t\tserverError(\"generating plugin help\", errors.New(\"help provider is nil\"))\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\thelp, err := provider(enabledRepos)\r\n\t\t\tif err != nil {\r\n\t\t\t\tserverError(\"generating plugin help\", err)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tb, err = json.Marshal(help)\r\n\t\t\tif err != nil {\r\n\t\t\t\tserverError(\"marshaling plugin help\", err)\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tfmt.Fprint(w, string(b))\r\n\t\t},\r\n\t)\r\n}","code-length":506,"reference":"\/\/ ServeExternalPluginHelp returns a HandlerFunc that serves plugin help information that is\n\/\/ provided by the specified ExternalPluginHelpProvider.","result":"Serve external plugin help.","score":[0.0096,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *protector) protect() {\r\n\tbp := p.cfg.BranchProtection\r\n\t\r\n\tfor orgName := range bp.Orgs {\r\n\t\torg := bp.GetOrg(orgName)\r\n\t\tif err := p.UpdateOrg(orgName, *org); err != nil {\r\n\t\t\tp.errors.add(fmt.Errorf(\"update %s: %v\", orgName, err))\r\n\t\t}\r\n\t}\r\n\t\r\n\tif !bp.ProtectTested {\r\n\t\treturn\r\n\t}\r\n\t\r\n\tfor repo := range p.cfg.Presubmits {\r\n\t\tif p.completedRepos[repo] == true {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tparts := strings.Split(repo, \"\/\")\r\n\t\tif len(parts) != 2 {\r\n\t\t\tp.errors.add(fmt.Errorf(\"bad presubmit repo: %s\", repo))\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\torgName := parts[0]\r\n\t\trepoName := parts[1]\r\n\t\trepo := bp.GetOrg(orgName).GetRepo(repoName)\r\n\t\tif err := p.UpdateRepo(orgName, repoName, *repo); err != nil {\r\n\t\t\tp.errors.add(fmt.Errorf(\"update %s\/%s: %v\", orgName, repoName, err))\r\n\t\t}\r\n\t}\r\n}","code-length":354,"reference":"\/\/ protect protects branches specified in the presubmit and branch-protection config sections.","result":"Protect branch.","score":[0,0.0455]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *protector) UpdateOrg(orgName string, org config.Org) error {\r\n\tvar repos []string\r\n\tif org.Protect != nil {\r\n\t\t\r\n\t\trs, err := p.client.GetRepos(orgName, false)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"list repos: %v\", err)\r\n\t\t}\r\n\t\tfor _, r := range rs {\r\n\t\t\tif !r.Archived {\r\n\t\t\t\trepos = append(repos, r.Name)\r\n\t\t\t}\r\n\t\t}\r\n\t} else {\r\n\t\t\r\n\t\tfor r := range org.Repos {\r\n\t\t\trepos = append(repos, r)\r\n\t\t}\r\n\t}\r\n\tfor _, repoName := range repos {\r\n\t\trepo := org.GetRepo(repoName)\r\n\t\tif err := p.UpdateRepo(orgName, repoName, *repo); err != nil {\r\n\t\t\treturn fmt.Errorf(\"update %s: %v\", repoName, err)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":279,"reference":"\/\/ UpdateOrg updates all repos in the org with the specified defaults","result":"Update org config.","score":[0.0203,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *protector) UpdateRepo(orgName string, repoName string, repo config.Repo) error {\r\n\tp.completedRepos[orgName+\"\/\"+repoName] = true\r\n\tgithubRepo, err := p.client.GetRepo(orgName, repoName)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"could not get repo to check for archival: %v\", err)\r\n\t}\r\n\tif githubRepo.Archived {\r\n\t\t\r\n\t\treturn nil\r\n\t}\r\n\tbranches := map[string]github.Branch{}\r\n\tfor _, onlyProtected := range []bool{false, true} {\r\n\t\tbs, err := p.client.GetBranches(orgName, repoName, onlyProtected)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"list branches: %v\", err)\r\n\t\t}\r\n\t\tfor _, b := range bs {\r\n\t\t\tbranches[b.Name] = b\r\n\t\t}\r\n\t}\r\n\tfor bn, githubBranch := range branches {\r\n\t\tif branch, err := repo.GetBranch(bn); err != nil {\r\n\t\t\treturn fmt.Errorf(\"get %s: %v\", bn, err)\r\n\t\t} else if err = p.UpdateBranch(orgName, repoName, bn, *branch, githubBranch.Protected); err != nil {\r\n\t\t\treturn fmt.Errorf(\"update %s from protected=%t: %v\", bn, githubBranch.Protected, err)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":383,"reference":"\/\/ UpdateRepo updates all branches in the repo with the specified defaults","result":"Protect the repo.","score":[0.0203,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *protector) UpdateBranch(orgName, repo string, branchName string, branch config.Branch, protected bool) error {\r\n\tbp, err := p.cfg.GetPolicy(orgName, repo, branchName, branch)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"get policy: %v\", err)\r\n\t}\r\n\tif bp == nil || bp.Protect == nil {\r\n\t\treturn nil\r\n\t}\r\n\tif !protected && !*bp.Protect {\r\n\t\tlogrus.Infof(\"%s\/%s=%s: already unprotected\", orgName, repo, branchName)\r\n\t\treturn nil\r\n\t}\r\n\tvar req *github.BranchProtectionRequest\r\n\tif *bp.Protect {\r\n\t\tr := makeRequest(*bp)\r\n\t\treq = &r\r\n\t}\r\n\tp.updates <- requirements{\r\n\t\tOrg:     orgName,\r\n\t\tRepo:    repo,\r\n\t\tBranch:  branchName,\r\n\t\tRequest: req,\r\n\t}\r\n\treturn nil\r\n}","code-length":263,"reference":"\/\/ UpdateBranch updates the branch with the specified configuration","result":"BranchConfig config.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *Options) LoadConfig(config string) error {\r\n\treturn json.Unmarshal([]byte(config), o)\r\n}","code-length":41,"reference":"\/\/ LoadConfig loads options from serialized config","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *Options) Run() error {\r\n\tclusterConfig, err := loadClusterConfig()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to load cluster config: %v\", err)\r\n\t}\r\n\tclient, err := kubernetes.NewForConfig(clusterConfig)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tprowJobClient, err := kube.NewClientInCluster(o.ProwJobNamespace)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tcontroller := artifact_uploader.NewController(client.CoreV1(), prowJobClient, o.Options)\r\n\tstop := make(chan struct{})\r\n\tdefer close(stop)\r\n\tgo controller.Run(o.NumWorkers, stop)\r\n\t\r\n\tselect {}\r\n}","code-length":210,"reference":"\/\/ Run uploads artifacts with the specified options forever.\n\/\/\n\/\/ Sends a stop message to the artifact uploader when it is interrupted.","result":"Run the controller.","score":[0.0006,0.0476]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Agent) Start(paths []string) error {\r\n\tsecretsMap, err := LoadSecrets(paths)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ta.secretsMap = secretsMap\r\n\t\r\n\tfor secretPath := range secretsMap {\r\n\t\tgo a.reloadSecret(secretPath)\r\n\t}\r\n\treturn nil\r\n}","code-length":105,"reference":"\/\/ Start creates goroutines to monitor the files that contain the secret value.","result":"Start the agent.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Agent) reloadSecret(secretPath string) {\r\n\tvar lastModTime time.Time\r\n\tlogger := logrus.NewEntry(logrus.StandardLogger())\r\n\tskips := 0\r\n\tfor range time.Tick(1 * time.Second) {\r\n\t\tif skips < 600 {\r\n\t\t\t\r\n\t\t\tsecretStat, err := os.Stat(secretPath)\r\n\t\t\tif err != nil {\r\n\t\t\t\tlogger.WithField(\"secret-path\", secretPath).\r\n\t\t\t\t\tWithError(err).Error(\"Error loading secret file.\")\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\trecentModTime := secretStat.ModTime()\r\n\t\t\tif !recentModTime.After(lastModTime) {\r\n\t\t\t\tskips++\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tlastModTime = recentModTime\r\n\t\t}\r\n\t\tif secretValue, err := LoadSingleSecret(secretPath); err != nil {\r\n\t\t\tlogger.WithField(\"secret-path: \", secretPath).\r\n\t\t\t\tWithError(err).Error(\"Error loading secret.\")\r\n\t\t} else {\r\n\t\t\ta.setSecret(secretPath, secretValue)\r\n\t\t\tskips = 0\r\n\t\t}\r\n\t}\r\n}","code-length":310,"reference":"\/\/ reloadSecret will begin polling the secret file at the path. If the first load\n\/\/ fails, Start with return the error and abort. Future load failures will log\n\/\/ the failure message but continue attempting to load.","result":"Reload secret from file.","score":[0.0001,0.0145]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Agent) GetSecret(secretPath string) []byte {\r\n\ta.RLock()\r\n\tdefer a.RUnlock()\r\n\treturn a.secretsMap[secretPath]\r\n}","code-length":58,"reference":"\/\/ GetSecret returns the value of a secret stored in a map.","result":"Generate the generated code.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Agent) setSecret(secretPath string, secretValue []byte) {\r\n\ta.Lock()\r\n\tdefer a.Unlock()\r\n\ta.secretsMap[secretPath] = secretValue\r\n}","code-length":61,"reference":"\/\/ setSecret sets a value in a map of secrets.","result":"Set secret in the agent.","score":[0.0884,0.1053]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Agent) GetTokenGenerator(secretPath string) func() []byte {\r\n\treturn func() []byte {\r\n\t\treturn a.GetSecret(secretPath)\r\n\t}\r\n}","code-length":57,"reference":"\/\/ GetTokenGenerator returns a function that gets the value of a given secret.","result":"Generate tokens.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(maxRecordsPerKey int, opener io.Opener, path string) (*History, error) {\r\n\thist := &History{\r\n\t\tlogs:         map[string]*recordLog{},\r\n\t\tlogSizeLimit: maxRecordsPerKey,\r\n\t\topener:       opener,\r\n\t\tpath:         path,\r\n\t}\r\n\tif path != \"\" {\r\n\t\t\r\n\t\tvar err error\r\n\t\tstart := time.Now()\r\n\t\thist.logs, err = readHistory(maxRecordsPerKey, hist.opener, hist.path)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tlogrus.WithFields(logrus.Fields{\r\n\t\t\t\"duration\": time.Since(start).String(),\r\n\t\t\t\"path\":     hist.path,\r\n\t\t}).Debugf(\"Successfully read action history for %d pools.\", len(hist.logs))\r\n\t}\r\n\treturn hist, nil\r\n}","code-length":248,"reference":"\/\/ New creates a new History struct with the specificed recordLog size limit.","result":"Create a new history object.","score":[0.0686,0.3253]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *History) Record(poolKey, action, baseSHA, err string, targets []prowapi.Pull) {\r\n\tt := now()\r\n\tsort.Sort(ByNum(targets))\r\n\th.addRecord(\r\n\t\tpoolKey,\r\n\t\t&Record{\r\n\t\t\tTime:    t,\r\n\t\t\tAction:  action,\r\n\t\t\tBaseSHA: baseSHA,\r\n\t\t\tTarget:  targets,\r\n\t\t\tErr:     err,\r\n\t\t},\r\n\t)\r\n}","code-length":136,"reference":"\/\/ Record appends an entry to the recordlog specified by the poolKey.","result":"Record the state of a pool.","score":[0.0845,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *History) ServeHTTP(w http.ResponseWriter, r *http.Request) {\r\n\tb, err := json.Marshal(h.AllRecords())\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Error(\"Encoding JSON history.\")\r\n\t\tb = []byte(\"{}\")\r\n\t}\r\n\tif _, err = w.Write(b); err != nil {\r\n\t\tlogrus.WithError(err).Error(\"Writing JSON history response.\")\r\n\t}\r\n}","code-length":131,"reference":"\/\/ ServeHTTP serves a JSON mapping from pool key -> sorted records for the pool.","result":"Serve the history request.","score":[0.0204,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *History) Flush() {\r\n\tif h.path == \"\" {\r\n\t\treturn\r\n\t}\r\n\trecords := h.AllRecords()\r\n\tstart := time.Now()\r\n\terr := writeHistory(h.opener, h.path, records)\r\n\tlog := logrus.WithFields(logrus.Fields{\r\n\t\t\"duration\": time.Since(start).String(),\r\n\t\t\"path\":     h.path,\r\n\t})\r\n\tif err != nil {\r\n\t\tlog.WithError(err).Error(\"Error flushing action history to GCS.\")\r\n\t} else {\r\n\t\tlog.Debugf(\"Successfully flushed action history for %d pools.\", len(h.logs))\r\n\t}\r\n}","code-length":185,"reference":"\/\/ Flush writes the action history to persistent storage if configured to do so.","result":"Flush the action history to GCS.","score":[0.1684,0.3379]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *History) AllRecords() map[string][]*Record {\r\n\th.Lock()\r\n\tdefer h.Unlock()\r\n\tres := make(map[string][]*Record, len(h.logs))\r\n\tfor key, log := range h.logs {\r\n\t\tres[key] = log.toSlice()\r\n\t}\r\n\treturn res\r\n}","code-length":99,"reference":"\/\/ AllRecords generates a map from pool key -> sorted records for the pool.","result":"Return all records in the history.","score":[0.0605,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MakeCommand() *cobra.Command {\r\n\tflags := &flags{}\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"download [bucket] [prowjob]\",\r\n\t\tShort: \"Finds and downloads the coverage profile file from the latest healthy build\",\r\n\t\tLong: `Finds and downloads the coverage profile file from the latest healthy build \r\nstored in given gcs directory.`,\r\n\t\tRun: func(cmd *cobra.Command, args []string) {\r\n\t\t\trun(flags, cmd, args)\r\n\t\t},\r\n\t}\r\n\tcmd.Flags().StringVarP(&flags.outputFile, \"output\", \"o\", \"-\", \"output file\")\r\n\tcmd.Flags().StringVarP(&flags.artifactsDirName, \"artifactsDir\", \"a\", \"artifacts\", \"artifact directory name in GCS\")\r\n\tcmd.Flags().StringVarP(&flags.profileName, \"profile\", \"p\", \"coverage-profile\", \"code coverage profile file name in GCS\")\r\n\treturn cmd\r\n}","code-length":256,"reference":"\/\/ MakeCommand returns a `download` command.","result":"Generate code coverage profile file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *CommentCounterPlugin) CheckFlags() error {\r\n\tfor _, pattern := range c.pattern {\r\n\t\tmatcher, err := regexp.Compile(pattern)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tc.matcher = append(c.matcher, matcher)\r\n\t}\r\n\treturn nil\r\n}","code-length":97,"reference":"\/\/ CheckFlags looks for comments matching regexes","result":"Generate a comment counter.","score":[0,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *CommentCounterPlugin) ReceiveComment(comment sql.Comment) []Point {\r\n\tpoints := []Point{}\r\n\tfor _, matcher := range c.matcher {\r\n\t\tif matcher.MatchString(comment.Body) {\r\n\t\t\tpoints = append(points, Point{\r\n\t\t\t\tValues: map[string]interface{}{\r\n\t\t\t\t\t\"comment\": 1,\r\n\t\t\t\t},\r\n\t\t\t\tDate: comment.CommentCreatedAt,\r\n\t\t\t})\r\n\t\t}\r\n\t}\r\n\treturn points\r\n}","code-length":136,"reference":"\/\/ ReceiveComment adds matching comments to InfluxDB","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewController(\r\n\tpjclientset clientset.Interface,\r\n\tqueue workqueue.RateLimitingInterface,\r\n\tinformer pjinformers.ProwJobInformer,\r\n\treporter reportClient,\r\n\tnumWorkers int,\r\n\twg *sync.WaitGroup) *Controller {\r\n\treturn &Controller{\r\n\t\tpjclientset: pjclientset,\r\n\t\tqueue:       queue,\r\n\t\tinformer:    informer,\r\n\t\treporter:    reporter,\r\n\t\tnumWorkers:  numWorkers,\r\n\t\twg:          wg,\r\n\t}\r\n}","code-length":157,"reference":"\/\/ NewController constructs a new instance of the crier controller.","result":"Create a new controller.","score":[0.1116,0.2719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) Run(stopCh <-chan struct{}) {\r\n\t\r\n\tdefer utilruntime.HandleCrash()\r\n\t\r\n\t\r\n\tdefer c.queue.ShutDown()\r\n\tlogrus.Info(\"Initiating controller\")\r\n\tc.informer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{\r\n\t\tAddFunc: func(obj interface{}) {\r\n\t\t\tkey, err := cache.MetaNamespaceKeyFunc(obj)\r\n\t\t\tlogrus.WithField(\"prowjob\", key).Infof(\"Add prowjob\")\r\n\t\t\tif err != nil {\r\n\t\t\t\tlogrus.WithError(err).Error(\"Cannot get key from object meta\")\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tc.queue.AddRateLimited(key)\r\n\t\t},\r\n\t\tUpdateFunc: func(oldObj, newObj interface{}) {\r\n\t\t\tkey, err := cache.MetaNamespaceKeyFunc(newObj)\r\n\t\t\tlogrus.WithField(\"prowjob\", key).Infof(\"Update prowjob\")\r\n\t\t\tif err != nil {\r\n\t\t\t\tlogrus.WithError(err).Error(\"Cannot get key from object meta\")\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tc.queue.AddRateLimited(key)\r\n\t\t},\r\n\t})\r\n\t\r\n\tgo c.informer.Informer().Run(stopCh)\r\n\t\r\n\tif !cache.WaitForCacheSync(stopCh, c.HasSynced) {\r\n\t\tutilruntime.HandleError(fmt.Errorf(\"Error syncing cache\"))\r\n\t\treturn\r\n\t}\r\n\tlogrus.Info(\"Controller.Run: cache sync complete\")\r\n\t\r\n\tfor i := 0; i < c.numWorkers; i++ {\r\n\t\tgo wait.Until(c.runWorker, time.Second, stopCh)\r\n\t}\r\n\tlogrus.Infof(\"Started %d workers\", c.numWorkers)\r\n\t<-stopCh\r\n\tlogrus.Info(\"Shutting down workers\")\r\n}","code-length":495,"reference":"\/\/ Run is the main path of execution for the controller loop.","result":"Run the controller .","score":[0.0677,0.2282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) runWorker() {\r\n\tc.wg.Add(1)\r\n\tfor c.processNextItem() {\r\n\t}\r\n\tc.wg.Done()\r\n}","code-length":57,"reference":"\/\/ runWorker executes the loop to process new items added to the queue.","result":"Run the worker.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New() (*LocalGit, *git.Client, error) {\r\n\tg, err := exec.LookPath(\"git\")\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\tt, err := ioutil.TempDir(\"\", \"localgit\")\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\tc, err := git.NewClient()\r\n\tif err != nil {\r\n\t\tos.RemoveAll(t)\r\n\t\treturn nil, nil, err\r\n\t}\r\n\tgetSecret := func() []byte {\r\n\t\treturn []byte(\"\")\r\n\t}\r\n\tc.SetCredentials(\"\", getSecret)\r\n\tc.SetRemote(t)\r\n\treturn &LocalGit{\r\n\t\tDir: t,\r\n\t\tGit: g,\r\n\t}, c, nil\r\n}","code-length":223,"reference":"\/\/ New creates a LocalGit and a git.Client pointing at it.","result":"Create a new instance of the local git repository.","score":[0.0976,0.1389]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lg *LocalGit) MakeFakeRepo(org, repo string) error {\r\n\trdir := filepath.Join(lg.Dir, org, repo)\r\n\tif err := os.MkdirAll(rdir, os.ModePerm); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := runCmd(lg.Git, rdir, \"init\"); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := runCmd(lg.Git, rdir, \"config\", \"user.email\", \"test@test.test\"); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := runCmd(lg.Git, rdir, \"config\", \"user.name\", \"test test\"); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := runCmd(lg.Git, rdir, \"config\", \"commit.gpgsign\", \"false\"); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := lg.AddCommit(org, repo, map[string][]byte{\"initial\": {}}); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":290,"reference":"\/\/ MakeFakeRepo creates the given repo and makes an initial commit.","result":"Generate the code.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lg *LocalGit) AddCommit(org, repo string, files map[string][]byte) error {\r\n\trdir := filepath.Join(lg.Dir, org, repo)\r\n\tfor f, b := range files {\r\n\t\tpath := filepath.Join(rdir, f)\r\n\t\tif err := os.MkdirAll(filepath.Dir(path), os.ModePerm); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif err := ioutil.WriteFile(path, b, os.ModePerm); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tif err := runCmd(lg.Git, rdir, \"add\", f); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn runCmd(lg.Git, rdir, \"commit\", \"-m\", \"wow\")\r\n}","code-length":221,"reference":"\/\/ AddCommit adds the files to a new commit in the repo.","result":"Add files to a commit.","score":[0.122,0.3319]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lg *LocalGit) CheckoutNewBranch(org, repo, branch string) error {\r\n\trdir := filepath.Join(lg.Dir, org, repo)\r\n\treturn runCmd(lg.Git, rdir, \"checkout\", \"-b\", branch)\r\n}","code-length":72,"reference":"\/\/ CheckoutNewBranch does git checkout -b.","result":"Create a new branch.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lg *LocalGit) Checkout(org, repo, commitlike string) error {\r\n\trdir := filepath.Join(lg.Dir, org, repo)\r\n\treturn runCmd(lg.Git, rdir, \"checkout\", commitlike)\r\n}","code-length":69,"reference":"\/\/ Checkout does git checkout.","result":"Create a local git repository.","score":[0.2403,0.1]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lg *LocalGit) RevParse(org, repo, commitlike string) (string, error) {\r\n\trdir := filepath.Join(lg.Dir, org, repo)\r\n\treturn runCmdOutput(lg.Git, rdir, \"rev-parse\", commitlike)\r\n}","code-length":77,"reference":"\/\/ RevParse does git rev-parse.","result":"Generate the rev.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CleanAll(sess *session.Session, region string) error {\r\n\tacct, err := account.GetAccount(sess, regions.Default)\r\n\tif err != nil {\r\n\t\treturn errors.Wrap(err, \"Failed to retrieve account\")\r\n\t}\r\n\tklog.V(1).Infof(\"Account: %s\", acct)\r\n\tvar regionList []string\r\n\tif region == \"\" {\r\n\t\tregionList, err = regions.GetAll(sess)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Couldn't retrieve list of regions\")\r\n\t\t}\r\n\t} else {\r\n\t\tregionList = []string{region}\r\n\t}\r\n\tklog.Infof(\"Regions: %+v\", regionList)\r\n\tfor _, r := range regionList {\r\n\t\tfor _, typ := range RegionalTypeList {\r\n\t\t\tset, err := typ.ListAll(sess, acct, r)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn errors.Wrapf(err, \"Failed to list resources of type %T\", typ)\r\n\t\t\t}\r\n\t\t\tif err := typ.MarkAndSweep(sess, acct, r, set); err != nil {\r\n\t\t\t\treturn errors.Wrapf(err, \"Couldn't sweep resources of type %T\", typ)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tfor _, typ := range GlobalTypeList {\r\n\t\tset, err := typ.ListAll(sess, acct, regions.Default)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"Failed to list resources of type %T\", typ)\r\n\t\t}\r\n\t\tif err := typ.MarkAndSweep(sess, acct, regions.Default, set); err != nil {\r\n\t\t\treturn errors.Wrapf(err, \"Couldn't sweep resources of type %T\", typ)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":485,"reference":"\/\/ CleanAll cleans all of the resources for all of the regions visible to\n\/\/ the provided AWS session.","result":"Clean all resources in a region.","score":[0.0263,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc optionsForRepo(config *plugins.Configuration, org, repo string) *plugins.Lgtm {\r\n\tfullName := fmt.Sprintf(\"%s\/%s\", org, repo)\r\n\tfor i := range config.Lgtm {\r\n\t\tif !strInSlice(org, config.Lgtm[i].Repos) && !strInSlice(fullName, config.Lgtm[i].Repos) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\treturn &config.Lgtm[i]\r\n\t}\r\n\treturn &plugins.Lgtm{}\r\n}","code-length":148,"reference":"\/\/ optionsForRepo gets the plugins.Lgtm struct that is applicable to the indicated repo.","result":"Get options for a specific repo.","score":[0.0601,0.0813]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getChangedFiles(gc githubClient, org, repo string, number int) ([]string, error) {\r\n\tchanges, err := gc.GetPullRequestChanges(org, repo, number)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"cannot get PR changes for %s\/%s#%d\", org, repo, number)\r\n\t}\r\n\tvar filenames []string\r\n\tfor _, change := range changes {\r\n\t\tfilenames = append(filenames, change.Filename)\r\n\t}\r\n\treturn filenames, nil\r\n}","code-length":140,"reference":"\/\/ getChangedFiles returns all the changed files for the provided pull request.","result":"Get the changed files from the github API.","score":[0.1864,0.3233]}
{"code":"\/*is used to<extra_id_0>\r\nfunc loadReviewers(ro repoowners.RepoOwner, filenames []string) sets.String {\r\n\treviewers := sets.String{}\r\n\tfor _, filename := range filenames {\r\n\t\treviewers = reviewers.Union(ro.Approvers(filename)).Union(ro.Reviewers(filename))\r\n\t}\r\n\treturn reviewers\r\n}","code-length":93,"reference":"\/\/ loadReviewers returns all reviewers and approvers from all OWNERS files that\n\/\/ cover the provided filenames.","result":"Load reviewers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewController(lastSyncFallback, cookiefilePath string, projects map[string][]string, kc *kube.Client, cfg config.Getter) (*Controller, error) {\r\n\tif lastSyncFallback == \"\" {\r\n\t\treturn nil, errors.New(\"empty lastSyncFallback\")\r\n\t}\r\n\tvar lastUpdate time.Time\r\n\tif buf, err := ioutil.ReadFile(lastSyncFallback); err == nil {\r\n\t\tunix, err := strconv.ParseInt(string(buf), 10, 64)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tlastUpdate = time.Unix(unix, 0)\r\n\t} else if err != nil && !os.IsNotExist(err) {\r\n\t\treturn nil, fmt.Errorf(\"failed to read lastSyncFallback: %v\", err)\r\n\t} else {\r\n\t\tlogrus.Warnf(\"lastSyncFallback not found: %s\", lastSyncFallback)\r\n\t\tlastUpdate = time.Now()\r\n\t}\r\n\tc, err := client.NewClient(projects)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tc.Start(cookiefilePath)\r\n\treturn &Controller{\r\n\t\tkc:               kc,\r\n\t\tconfig:           cfg,\r\n\t\tgc:               c,\r\n\t\tlastUpdate:       lastUpdate,\r\n\t\tlastSyncFallback: lastSyncFallback,\r\n\t}, nil\r\n}","code-length":361,"reference":"\/\/ NewController returns a new gerrit controller client","result":"Create a new controller.","score":[0.1662,0.2467]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) SaveLastSync(lastSync time.Time) error {\r\n\tif c.lastSyncFallback == \"\" {\r\n\t\treturn nil\r\n\t}\r\n\tlastSyncUnix := strconv.FormatInt(lastSync.Unix(), 10)\r\n\tlogrus.Infof(\"Writing last sync: %s\", lastSyncUnix)\r\n\ttempFile, err := ioutil.TempFile(filepath.Dir(c.lastSyncFallback), \"temp\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer os.Remove(tempFile.Name())\r\n\terr = ioutil.WriteFile(tempFile.Name(), []byte(lastSyncUnix), 0644)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = os.Rename(tempFile.Name(), c.lastSyncFallback)\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Info(\"Rename failed, fallback to copyfile\")\r\n\t\treturn copyFile(tempFile.Name(), c.lastSyncFallback)\r\n\t}\r\n\treturn nil\r\n}","code-length":264,"reference":"\/\/ SaveLastSync saves last sync time in Unix to a volume","result":"Save the last sync time.","score":[0.1023,0.2457]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) Sync() error {\r\n\tsyncTime := c.lastUpdate\r\n\tfor instance, changes := range c.gc.QueryChanges(c.lastUpdate, c.config().Gerrit.RateLimit) {\r\n\t\tfor _, change := range changes {\r\n\t\t\tif err := c.ProcessChange(instance, change); err != nil {\r\n\t\t\t\tlogrus.WithError(err).Errorf(\"Failed process change %v\", change.CurrentRevision)\r\n\t\t\t}\r\n\t\t\tif syncTime.Before(change.Updated.Time) {\r\n\t\t\t\tsyncTime = change.Updated.Time\r\n\t\t\t}\r\n\t\t}\r\n\t\tlogrus.Infof(\"Processed %d changes for instance %s\", len(changes), instance)\r\n\t}\r\n\tc.lastUpdate = syncTime\r\n\tif err := c.SaveLastSync(syncTime); err != nil {\r\n\t\tlogrus.WithError(err).Errorf(\"last sync %v, cannot save to path %v\", syncTime, c.lastSyncFallback)\r\n\t}\r\n\treturn nil\r\n}","code-length":264,"reference":"\/\/ Sync looks for newly made gerrit changes\n\/\/ and creates prowjobs according to specs","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *EventCounterPlugin) AddFlags(cmd *cobra.Command) {\r\n\tcmd.Flags().StringVar(&e.desc, \"event\", \"\", \"Match event (eg: `opened`)\")\r\n}","code-length":62,"reference":"\/\/ AddFlags adds \"event\" to the command help","result":"Add flags to the command.","score":[0.1865,0.3319]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *EventCounterPlugin) CheckFlags() error {\r\n\te.matcher = NewEventMatcher(e.desc)\r\n\treturn nil\r\n}","code-length":45,"reference":"\/\/ CheckFlags is delegated to EventMatcher","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (e *EventCounterPlugin) ReceiveIssueEvent(event sql.IssueEvent) []Point {\r\n\tvar label string\r\n\tif event.Label != nil {\r\n\t\tlabel = *event.Label\r\n\t}\r\n\tif !e.matcher.Match(event.Event, label) {\r\n\t\treturn nil\r\n\t}\r\n\treturn []Point{\r\n\t\t{\r\n\t\t\tValues: map[string]interface{}{\"event\": 1},\r\n\t\t\tDate:   event.EventCreatedAt,\r\n\t\t},\r\n\t}\r\n}","code-length":141,"reference":"\/\/ ReceiveIssueEvent adds issue events to InfluxDB","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Upload(bucket *storage.BucketHandle, uploadTargets map[string]UploadFunc) error {\r\n\terrCh := make(chan error, len(uploadTargets))\r\n\tgroup := &sync.WaitGroup{}\r\n\tgroup.Add(len(uploadTargets))\r\n\tfor dest, upload := range uploadTargets {\r\n\t\tobj := bucket.Object(dest)\r\n\t\tlogrus.WithField(\"dest\", dest).Info(\"Queued for upload\")\r\n\t\tgo func(f UploadFunc, obj *storage.ObjectHandle, name string) {\r\n\t\t\tdefer group.Done()\r\n\t\t\tif err := f(obj); err != nil {\r\n\t\t\t\terrCh <- err\r\n\t\t\t}\r\n\t\t\tlogrus.WithField(\"dest\", name).Info(\"Finished upload\")\r\n\t\t}(upload, obj, dest)\r\n\t}\r\n\tgroup.Wait()\r\n\tclose(errCh)\r\n\tif len(errCh) != 0 {\r\n\t\tvar uploadErrors []error\r\n\t\tfor err := range errCh {\r\n\t\t\tuploadErrors = append(uploadErrors, err)\r\n\t\t}\r\n\t\treturn fmt.Errorf(\"encountered errors during upload: %v\", uploadErrors)\r\n\t}\r\n\treturn nil\r\n}","code-length":305,"reference":"\/\/ Upload uploads all of the data in the\n\/\/ uploadTargets map to GCS in parallel. The map is\n\/\/ keyed on GCS path under the bucket","result":"Upload objects.","score":[0.0,0.0204]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FileUploadWithMetadata(file string, metadata map[string]string) UploadFunc {\r\n\treturn func(obj *storage.ObjectHandle) error {\r\n\t\treader, err := os.Open(file)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tuploadErr := DataUploadWithMetadata(reader, metadata)(obj)\r\n\t\tcloseErr := reader.Close()\r\n\t\treturn errorutil.NewAggregate(uploadErr, closeErr)\r\n\t}\r\n}","code-length":130,"reference":"\/\/ FileUploadWithMetadata returns an UploadFunc which copies all\n\/\/ data from the file on disk into GCS object and also sets the provided\n\/\/ metadata fields on the object.","result":"Upload a file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DataUploadWithMetadata(src io.Reader, metadata map[string]string) UploadFunc {\r\n\treturn func(obj *storage.ObjectHandle) error {\r\n\t\twriter := obj.NewWriter(context.Background())\r\n\t\twriter.Metadata = metadata\r\n\t\t_, copyErr := io.Copy(writer, src)\r\n\t\tcloseErr := writer.Close()\r\n\t\treturn errorutil.NewAggregate(copyErr, closeErr)\r\n\t}\r\n}","code-length":121,"reference":"\/\/ DataUploadWithMetadata returns an UploadFunc which copies all\n\/\/ data from src reader into GCS and also sets the provided metadata\n\/\/ fields onto the object.","result":"Upload data.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HasLabel(label string, issueLabels []Label) bool {\r\n\tfor _, l := range issueLabels {\r\n\t\tif strings.ToLower(l.Name) == strings.ToLower(label) {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":81,"reference":"\/\/ HasLabel checks if label is in the label set \"issueLabels\".","result":"Check if label exists in issueLabels.","score":[0.1313,0.3006]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ImageTooBig(url string) (bool, error) {\r\n\t\r\n\tlimit := 10000000\r\n\t\r\n\tresp, err := http.Head(url)\r\n\tif err != nil {\r\n\t\treturn true, fmt.Errorf(\"HEAD error: %v\", err)\r\n\t}\r\n\tif sc := resp.StatusCode; sc != http.StatusOK {\r\n\t\treturn true, fmt.Errorf(\"failing %d response\", sc)\r\n\t}\r\n\tsize, _ := strconv.Atoi(resp.Header.Get(\"Content-Length\"))\r\n\tif size > limit {\r\n\t\treturn true, nil\r\n\t}\r\n\treturn false, nil\r\n}","code-length":173,"reference":"\/\/ ImageTooBig checks if image is bigger than github limits","result":"Check if the image is too big.","score":[0.1647,0.3866]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LevelFromPermissions(permissions RepoPermissions) RepoPermissionLevel {\r\n\tif permissions.Admin {\r\n\t\treturn Admin\r\n\t} else if permissions.Push {\r\n\t\treturn Write\r\n\t} else if permissions.Pull {\r\n\t\treturn Read\r\n\t} else {\r\n\t\treturn None\r\n\t}\r\n}","code-length":87,"reference":"\/\/ LevelFromPermissions adapts a repo permissions struct to the\n\/\/ appropriate permission level used elsewhere","result":"Get the level from the permissions.","score":[0.0512,0.0709]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PermissionsFromLevel(permission RepoPermissionLevel) RepoPermissions {\r\n\tswitch permission {\r\n\tcase None:\r\n\t\treturn RepoPermissions{}\r\n\tcase Read:\r\n\t\treturn RepoPermissions{Pull: true}\r\n\tcase Write:\r\n\t\treturn RepoPermissions{Pull: true, Push: true}\r\n\tcase Admin:\r\n\t\treturn RepoPermissions{Pull: true, Push: true, Admin: true}\r\n\tdefault:\r\n\t\treturn RepoPermissions{}\r\n\t}\r\n}","code-length":128,"reference":"\/\/ PermissionsFromLevel adapts a repo permission level to the\n\/\/ appropriate permissions struct used elsewhere","result":"Generate the code.","score":[0.0075,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newProwJobs(c *ProwV1Client, namespace string) *prowJobs {\r\n\treturn &prowJobs{\r\n\t\tclient: c.RESTClient(),\r\n\t\tns:     namespace,\r\n\t}\r\n}","code-length":67,"reference":"\/\/ newProwJobs returns a ProwJobs","result":"Create new ProwJobs objects.","score":[0.2488,0.102]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b Blockers) GetApplicable(org, repo, branch string) []Blocker {\r\n\tvar res []Blocker\r\n\tres = append(res, b.Repo[orgRepo{org: org, repo: repo}]...)\r\n\tres = append(res, b.Branch[orgRepoBranch{org: org, repo: repo, branch: branch}]...)\r\n\tsort.Slice(res, func(i, j int) bool {\r\n\t\treturn res[i].Number < res[j].Number\r\n\t})\r\n\treturn res\r\n}","code-length":138,"reference":"\/\/ GetApplicable returns the subset of blockers applicable to the specified branch.","result":"Get the list of applicable blockers.","score":[0.0935,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc serve(jc *jenkins.Client) {\r\n\thttp.Handle(\"\/\", gziphandler.GzipHandler(handleLog(jc)))\r\n\thttp.Handle(\"\/metrics\", promhttp.Handler())\r\n\tlogrus.WithError(http.ListenAndServe(\":8080\", nil)).Fatal(\"ListenAndServe returned.\")\r\n}","code-length":87,"reference":"\/\/ serve starts a http server and serves Jenkins logs\n\/\/ and prometheus metrics. Meant to be called inside\n\/\/ a goroutine.","result":"Serve the logs.","score":[0,0.0249]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCountPlugin(runner func(Plugin) error) *cobra.Command {\r\n\tstateCounter := &StatePlugin{}\r\n\teventCounter := &EventCounterPlugin{}\r\n\tcommentsAsEvents := NewFakeCommentPluginWrapper(eventCounter)\r\n\tcommentCounter := &CommentCounterPlugin{}\r\n\tauthorLoggable := NewMultiplexerPluginWrapper(\r\n\t\tcommentsAsEvents,\r\n\t\tcommentCounter,\r\n\t)\r\n\tauthorLogged := NewAuthorLoggerPluginWrapper(authorLoggable)\r\n\tfullMultiplex := NewMultiplexerPluginWrapper(authorLogged, stateCounter)\r\n\tfakeOpen := NewFakeOpenPluginWrapper(fullMultiplex)\r\n\ttypeFilter := NewTypeFilterWrapperPlugin(fakeOpen)\r\n\tauthorFilter := NewAuthorFilterPluginWrapper(typeFilter)\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"count\",\r\n\t\tShort: \"Count events and number of issues in given state, and for how long\",\r\n\t\tRunE: func(cmd *cobra.Command, args []string) error {\r\n\t\t\tif err := eventCounter.CheckFlags(); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif err := stateCounter.CheckFlags(); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif err := typeFilter.CheckFlags(); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif err := commentCounter.CheckFlags(); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\treturn runner(authorFilter)\r\n\t\t},\r\n\t}\r\n\teventCounter.AddFlags(cmd)\r\n\tstateCounter.AddFlags(cmd)\r\n\tcommentCounter.AddFlags(cmd)\r\n\ttypeFilter.AddFlags(cmd)\r\n\tauthorFilter.AddFlags(cmd)\r\n\tauthorLogged.AddFlags(cmd)\r\n\treturn cmd\r\n}","code-length":463,"reference":"\/\/ NewCountPlugin counts events and number of issues in given state, and for how long.","result":"Create a plugin for counting events and issues.","score":[0.0906,0.2207]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *FakeCommentPluginWrapper) ReceiveComment(comment sql.Comment) []Point {\r\n\t\r\n\tfakeEvent := sql.IssueEvent{\r\n\t\tIssueID:        comment.IssueID,\r\n\t\tEvent:          \"commented\",\r\n\t\tEventCreatedAt: comment.CommentCreatedAt,\r\n\t\tActor:          &comment.User,\r\n\t}\r\n\treturn append(\r\n\t\to.plugin.ReceiveComment(comment),\r\n\t\to.plugin.ReceiveIssueEvent(fakeEvent)...,\r\n\t)\r\n}","code-length":138,"reference":"\/\/ ReceiveComment creates a fake \"commented\" event","result":"Test if the comment plugin is not used.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc updateMetrics(interval time.Duration, diskRoot string) {\r\n\tlogger := logrus.WithField(\"sync-loop\", \"updateMetrics\")\r\n\tticker := time.NewTicker(interval)\r\n\tfor ; true; <-ticker.C {\r\n\t\tlogger.Info(\"tick\")\r\n\t\t_, bytesFree, bytesUsed, err := diskutil.GetDiskUsage(diskRoot)\r\n\t\tif err != nil {\r\n\t\t\tlogger.WithError(err).Error(\"Failed to get disk metrics\")\r\n\t\t} else {\r\n\t\t\tpromMetrics.DiskFree.Set(float64(bytesFree) \/ 1e9)\r\n\t\t\tpromMetrics.DiskUsed.Set(float64(bytesUsed) \/ 1e9)\r\n\t\t\tpromMetrics.DiskTotal.Set(float64(bytesFree+bytesUsed) \/ 1e9)\r\n\t\t}\r\n\t}\r\n}","code-length":219,"reference":"\/\/ helper to update disk metrics","result":"Update metrics in sync.","score":[0.1938,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Ranch) LogStatus() {\r\n\tresources, err := r.Storage.GetResources()\r\n\tif err != nil {\r\n\t\treturn\r\n\t}\r\n\tresJSON, err := json.Marshal(resources)\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Errorf(\"Fail to marshal Resources. %v\", resources)\r\n\t}\r\n\tlogrus.Infof(\"Current Resources : %v\", string(resJSON))\r\n}","code-length":124,"reference":"\/\/ LogStatus outputs current status of all resources","result":"Log the status of the resource.","score":[0.1956,0.2404]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Ranch) SyncConfig(config string) error {\r\n\tresources, err := ParseConfig(config)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := r.Storage.SyncResources(resources); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":92,"reference":"\/\/ SyncConfig updates resource list from a file","result":"Sync config.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Ranch) Metric(rtype string) (common.Metric, error) {\r\n\tmetric := common.Metric{\r\n\t\tType:    rtype,\r\n\t\tCurrent: map[string]int{},\r\n\t\tOwners:  map[string]int{},\r\n\t}\r\n\tresources, err := r.Storage.GetResources()\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Error(\"cannot find resources\")\r\n\t\treturn metric, &ResourceNotFound{rtype}\r\n\t}\r\n\tfor _, res := range resources {\r\n\t\tif res.Type != rtype {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif _, ok := metric.Current[res.State]; !ok {\r\n\t\t\tmetric.Current[res.State] = 0\r\n\t\t}\r\n\t\tif _, ok := metric.Owners[res.Owner]; !ok {\r\n\t\t\tmetric.Owners[res.Owner] = 0\r\n\t\t}\r\n\t\tmetric.Current[res.State]++\r\n\t\tmetric.Owners[res.Owner]++\r\n\t}\r\n\tif len(metric.Current) == 0 && len(metric.Owners) == 0 {\r\n\t\treturn metric, &ResourceNotFound{rtype}\r\n\t}\r\n\treturn metric, nil\r\n}","code-length":332,"reference":"\/\/ Metric returns a metric object with metrics filled in","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FormatURL(dogURL string) (string, error) {\r\n\tif dogURL == \"\" {\r\n\t\treturn \"\", errors.New(\"empty url\")\r\n\t}\r\n\tsrc, err := url.ParseRequestURI(dogURL)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"invalid url %s: %v\", dogURL, err)\r\n\t}\r\n\treturn fmt.Sprintf(\"[![dog image](%s)](%s)\", src, src), nil\r\n}","code-length":132,"reference":"\/\/ FormatURL will return the GH markdown to show the image for a specific dogURL.","result":"Format the dog image url.","score":[0.0387,0.0714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc runAndSkipJobs(c Client, pr *github.PullRequest, requestedJobs []config.Presubmit, skippedJobs []config.Presubmit, eventGUID string, elideSkippedContexts bool) error {\r\n\tif err := validateContextOverlap(requestedJobs, skippedJobs); err != nil {\r\n\t\tc.Logger.WithError(err).Warn(\"Could not run or skip requested jobs, overlapping contexts.\")\r\n\t\treturn err\r\n\t}\r\n\trunErr := RunRequested(c, pr, requestedJobs, eventGUID)\r\n\tvar skipErr error\r\n\tif !elideSkippedContexts {\r\n\t\tskipErr = skipRequested(c, pr, skippedJobs)\r\n\t}\r\n\treturn errorutil.NewAggregate(runErr, skipErr)\r\n}","code-length":186,"reference":"\/\/ runAndSkipJobs executes the config.Presubmits that are requested and posts skipped statuses\n\/\/ for the reporting jobs that are skipped","result":"Run jobs and skip them.","score":[0.0142,0.0811]}
{"code":"\/*is used to<extra_id_0>\r\nfunc validateContextOverlap(toRun, toSkip []config.Presubmit) error {\r\n\trequestedContexts := sets.NewString()\r\n\tfor _, job := range toRun {\r\n\t\trequestedContexts.Insert(job.Context)\r\n\t}\r\n\tskippedContexts := sets.NewString()\r\n\tfor _, job := range toSkip {\r\n\t\tskippedContexts.Insert(job.Context)\r\n\t}\r\n\tif overlap := requestedContexts.Intersection(skippedContexts).List(); len(overlap) > 0 {\r\n\t\treturn fmt.Errorf(\"the following contexts are both triggered and skipped: %s\", strings.Join(overlap, \", \"))\r\n\t}\r\n\treturn nil\r\n}","code-length":173,"reference":"\/\/ validateContextOverlap ensures that there will be no overlap in contexts between a set of jobs running and a set to skip","result":"Validate the context overlap.","score":[0,0.0248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RunRequested(c Client, pr *github.PullRequest, requestedJobs []config.Presubmit, eventGUID string) error {\r\n\tbaseSHA, err := c.GitHubClient.GetRef(pr.Base.Repo.Owner.Login, pr.Base.Repo.Name, \"heads\/\"+pr.Base.Ref)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tvar errors []error\r\n\tfor _, job := range requestedJobs {\r\n\t\tc.Logger.Infof(\"Starting %s build.\", job.Name)\r\n\t\tpj := pjutil.NewPresubmit(*pr, baseSHA, job, eventGUID)\r\n\t\tc.Logger.WithFields(pjutil.ProwJobFields(&pj)).Info(\"Creating a new prowjob.\")\r\n\t\tif _, err := c.ProwJobClient.Create(&pj); err != nil {\r\n\t\t\tc.Logger.WithError(err).Error(\"Failed to create prowjob.\")\r\n\t\t\terrors = append(errors, err)\r\n\t\t}\r\n\t}\r\n\treturn errorutil.NewAggregate(errors...)\r\n}","code-length":284,"reference":"\/\/ RunRequested executes the config.Presubmits that are requested","result":"Run the build .","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc skipRequested(c Client, pr *github.PullRequest, skippedJobs []config.Presubmit) error {\r\n\tvar errors []error\r\n\tfor _, job := range skippedJobs {\r\n\t\tif job.SkipReport {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tc.Logger.Infof(\"Skipping %s build.\", job.Name)\r\n\t\tif err := c.GitHubClient.CreateStatus(pr.Base.Repo.Owner.Login, pr.Base.Repo.Name, pr.Head.SHA, skippedStatusFor(job.Context)); err != nil {\r\n\t\t\terrors = append(errors, err)\r\n\t\t}\r\n\t}\r\n\treturn errorutil.NewAggregate(errors...)\r\n}","code-length":180,"reference":"\/\/ skipRequested posts skipped statuses for the config.Presubmits that are requested","result":"Skip the build.","score":[0.0284,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l LabelEvent) Match(eventName, label string) bool {\r\n\treturn eventName == \"labeled\" && label == l.Label\r\n}","code-length":44,"reference":"\/\/ Match is \"labeled\" with label","result":"Match labels.","score":[0.0677,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u UnlabelEvent) Match(eventName, label string) bool {\r\n\treturn eventName == \"unlabeled\" && label == u.Label\r\n}","code-length":46,"reference":"\/\/ Match is \"unlabeled\"","result":"Match UnlabelEvent.","score":[0.1839,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *GitHubOptions) AddFlags(fs *flag.FlagSet) {\r\n\to.addFlags(true, fs)\r\n}","code-length":42,"reference":"\/\/ AddFlags injects GitHub options into the given FlagSet.","result":"Generate the code.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *GitHubOptions) AddFlagsWithoutDefaultGitHubTokenPath(fs *flag.FlagSet) {\r\n\to.addFlags(false, fs)\r\n}","code-length":47,"reference":"\/\/ AddFlagsWithoutDefaultGitHubTokenPath injects GitHub options into the given\n\/\/ Flagset without setting a default for for the githubTokenPath, allowing to\n\/\/ use an anonymous GitHub client","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *GitHubOptions) Validate(dryRun bool) error {\r\n\tfor _, uri := range o.endpoint.Strings() {\r\n\t\tif uri == \"\" {\r\n\t\t\turi = github.DefaultAPIEndpoint\r\n\t\t} else if _, err := url.ParseRequestURI(uri); err != nil {\r\n\t\t\treturn fmt.Errorf(\"invalid -github-endpoint URI: %q\", uri)\r\n\t\t}\r\n\t}\r\n\tif o.graphqlEndpoint == \"\" {\r\n\t\to.graphqlEndpoint = github.DefaultGraphQLEndpoint\r\n\t} else if _, err := url.Parse(o.graphqlEndpoint); err != nil {\r\n\t\treturn fmt.Errorf(\"invalid -github-graphql-endpoint URI: %q\", o.graphqlEndpoint)\r\n\t}\r\n\tif o.deprecatedTokenFile != \"\" {\r\n\t\to.TokenPath = o.deprecatedTokenFile\r\n\t\tlogrus.Error(\"-github-token-file is deprecated and may be removed anytime after 2019-01-01.  Use -github-token-path instead.\")\r\n\t}\r\n\tif o.TokenPath == \"\" {\r\n\t\tlogrus.Warn(\"empty -github-token-path, will use anonymous github client\")\r\n\t}\r\n\treturn nil\r\n}","code-length":314,"reference":"\/\/ Validate validates GitHub options.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *GitHubOptions) GitHubClientWithLogFields(secretAgent *secret.Agent, dryRun bool, fields logrus.Fields) (client *github.Client, err error) {\r\n\tvar generator *func() []byte\r\n\tif o.TokenPath == \"\" {\r\n\t\tgeneratorFunc := func() []byte {\r\n\t\t\treturn []byte{}\r\n\t\t}\r\n\t\tgenerator = &generatorFunc\r\n\t} else {\r\n\t\tif secretAgent == nil {\r\n\t\t\treturn nil, fmt.Errorf(\"cannot store token from %q without a secret agent\", o.TokenPath)\r\n\t\t}\r\n\t\tgeneratorFunc := secretAgent.GetTokenGenerator(o.TokenPath)\r\n\t\tgenerator = &generatorFunc\r\n\t}\r\n\tif dryRun {\r\n\t\treturn github.NewDryRunClientWithFields(fields, *generator, o.graphqlEndpoint, o.endpoint.Strings()...), nil\r\n\t}\r\n\treturn github.NewClientWithFields(fields, *generator, o.graphqlEndpoint, o.endpoint.Strings()...), nil\r\n}","code-length":259,"reference":"\/\/ GitHubClientWithLogFields returns a GitHub client with extra logging fields","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *GitHubOptions) GitHubClient(secretAgent *secret.Agent, dryRun bool) (client *github.Client, err error) {\r\n\treturn o.GitHubClientWithLogFields(secretAgent, dryRun, logrus.Fields{})\r\n}","code-length":65,"reference":"\/\/ GitHubClient returns a GitHub client.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *GitHubOptions) GitClient(secretAgent *secret.Agent, dryRun bool) (client *git.Client, err error) {\r\n\tclient, err = git.NewClient()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tdefer func(client *git.Client) {\r\n\t\tif err != nil {\r\n\t\t\tclient.Clean()\r\n\t\t}\r\n\t}(client)\r\n\t\r\n\tgithubClient, err := o.GitHubClient(secretAgent, dryRun)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error getting GitHub client: %v\", err)\r\n\t}\r\n\tbotName, err := githubClient.BotName()\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error getting bot name: %v\", err)\r\n\t}\r\n\tclient.SetCredentials(botName, secretAgent.GetTokenGenerator(o.TokenPath))\r\n\treturn client, nil\r\n}","code-length":256,"reference":"\/\/ GitClient returns a Git client.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc toMap(g *calculation.CoverageList) map[string]calculation.Coverage {\r\n\tm := make(map[string]calculation.Coverage)\r\n\tfor _, cov := range g.Group {\r\n\t\tm[cov.Name] = cov\r\n\t}\r\n\treturn m\r\n}","code-length":79,"reference":"\/\/ toMap returns maps the file name to its coverage for faster retrieval\n\/\/ & membership check","result":"Generate the map to return.","score":[0.0259,0.0949]}
{"code":"\/*is used to<extra_id_0>\r\nfunc findChanges(baseList *calculation.CoverageList, newList *calculation.CoverageList) []*coverageChange {\r\n\tvar changes []*coverageChange\r\n\tbaseFilesMap := toMap(baseList)\r\n\tfor _, newCov := range newList.Group {\r\n\t\tbaseCov, ok := baseFilesMap[newCov.Name]\r\n\t\tvar baseRatio float32\r\n\t\tif !ok {\r\n\t\t\tbaseRatio = -1\r\n\t\t} else {\r\n\t\t\tbaseRatio = baseCov.Ratio()\r\n\t\t}\r\n\t\tnewRatio := newCov.Ratio()\r\n\t\tif isChangeSignificant(baseRatio, newRatio) {\r\n\t\t\tchanges = append(changes, &coverageChange{\r\n\t\t\t\tname:      newCov.Name,\r\n\t\t\t\tbaseRatio: baseRatio,\r\n\t\t\t\tnewRatio:  newRatio,\r\n\t\t\t})\r\n\t\t}\r\n\t}\r\n\treturn changes\r\n}","code-length":239,"reference":"\/\/ findChanges compares the newList of coverage against the base list and returns the result","result":"Find changes in the coverage list.","score":[0.0512,0.0709]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (config *MySQLConfig) CreateDatabase() (*gorm.DB, error) {\r\n\tdb, err := gorm.Open(\"mysql\", config.getDSN(\"\"))\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdb.Exec(fmt.Sprintf(\"CREATE DATABASE IF NOT EXISTS %v;\", config.Db))\r\n\tdb.Close()\r\n\tdb, err = gorm.Open(\"mysql\", config.getDSN(config.Db))\r\n\terr = db.AutoMigrate(&Assignee{}, &Issue{}, &IssueEvent{}, &Label{}, &Comment{}).Error\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn db, nil\r\n}","code-length":188,"reference":"\/\/ CreateDatabase for the MySQLConfig","result":"Create a new database.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) ShouldReport(pj *v1.ProwJob) bool {\r\n\tif !pj.Spec.Report {\r\n\t\t\r\n\t\treturn false\r\n\t}\r\n\tif pj.Spec.Type != v1.PresubmitJob && pj.Spec.Type != v1.PostsubmitJob {\r\n\t\t\r\n\t\treturn false\r\n\t}\r\n\tif c.reportAgent != \"\" && pj.Spec.Agent != c.reportAgent {\r\n\t\t\r\n\t\treturn false\r\n\t}\r\n\treturn true\r\n}","code-length":145,"reference":"\/\/ ShouldReport returns if this prowjob should be reported by the github reporter","result":"Generate code for the generated code.","score":[0.0601,0.0407]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Report(pj *v1.ProwJob) ([]*v1.ProwJob, error) {\r\n\t\r\n\treturn []*v1.ProwJob{pj}, report.Report(c.gc, c.config().Plank.ReportTemplate, *pj, c.config().GitHubReporter.JobTypesToReport)\r\n}","code-length":95,"reference":"\/\/ Report will report via reportlib","result":"Report the plank.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Set) MarkComplete() int {\r\n\tvar gone []string\r\n\tfor key := range s.firstSeen {\r\n\t\tif !s.marked[key] {\r\n\t\t\tgone = append(gone, key)\r\n\t\t}\r\n\t}\r\n\tfor _, key := range gone {\r\n\t\tklog.V(1).Infof(\"%s: deleted since last run\", key)\r\n\t\tdelete(s.firstSeen, key)\r\n\t}\r\n\tif len(s.swept) > 0 {\r\n\t\tklog.Errorf(\"%d resources swept: %v\", len(s.swept), s.swept)\r\n\t}\r\n\treturn len(s.swept)\r\n}","code-length":193,"reference":"\/\/ MarkComplete figures out which ARNs were in previous passes but not\n\/\/ this one, and eliminates them. It should only be run after all\n\/\/ resources have been marked.","result":"Mark all resources as complete.","score":[0.0019,0.0364]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewJobAgent(kc serviceClusterClient, plClients map[string]PodLogClient, cfg config.Getter) *JobAgent {\r\n\treturn &JobAgent{\r\n\t\tkc:     kc,\r\n\t\tpkcs:   plClients,\r\n\t\tconfig: cfg,\r\n\t}\r\n}","code-length":83,"reference":"\/\/ NewJobAgent is a JobAgent constructor.","result":"Pkcs map[string]PodLogClient.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ja *JobAgent) Start() {\r\n\tja.tryUpdate()\r\n\tgo func() {\r\n\t\tt := time.Tick(period)\r\n\t\tfor range t {\r\n\t\t\tja.tryUpdate()\r\n\t\t}\r\n\t}()\r\n}","code-length":76,"reference":"\/\/ Start will start the job and periodically update it.","result":"Start the job agent.","score":[0.1116,0.3132]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ja *JobAgent) Jobs() []Job {\r\n\tja.mut.Lock()\r\n\tdefer ja.mut.Unlock()\r\n\tres := make([]Job, len(ja.jobs))\r\n\tcopy(res, ja.jobs)\r\n\treturn res\r\n}","code-length":75,"reference":"\/\/ Jobs returns a thread-safe snapshot of the current job state.","result":"Get the list of jobs in the agent.","score":[0.1135,0.1402]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ja *JobAgent) ProwJobs() []prowapi.ProwJob {\r\n\tja.mut.Lock()\r\n\tdefer ja.mut.Unlock()\r\n\tres := make([]prowapi.ProwJob, len(ja.prowJobs))\r\n\tcopy(res, ja.prowJobs)\r\n\treturn res\r\n}","code-length":93,"reference":"\/\/ ProwJobs returns a thread-safe snapshot of the current prow jobs.","result":"Collect the job.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ja *JobAgent) GetProwJob(job, id string) (prowapi.ProwJob, error) {\r\n\tif ja == nil {\r\n\t\treturn prowapi.ProwJob{}, fmt.Errorf(\"Prow job agent doesn't exist (are you running locally?)\")\r\n\t}\r\n\tvar j prowapi.ProwJob\r\n\tja.mut.Lock()\r\n\tidMap, ok := ja.jobsIDMap[job]\r\n\tif ok {\r\n\t\tj, ok = idMap[id]\r\n\t}\r\n\tja.mut.Unlock()\r\n\tif !ok {\r\n\t\treturn prowapi.ProwJob{}, errProwjobNotFound\r\n\t}\r\n\treturn j, nil\r\n}","code-length":192,"reference":"\/\/ GetProwJob finds the corresponding Prowjob resource from the provided job name and build ID","result":"Get the job from the job agent.","score":[0.0866,0.3141]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ja *JobAgent) GetJobLog(job, id string) ([]byte, error) {\r\n\tj, err := ja.GetProwJob(job, id)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error getting prowjob: %v\", err)\r\n\t}\r\n\tif j.Spec.Agent == prowapi.KubernetesAgent {\r\n\t\tclient, ok := ja.pkcs[j.ClusterAlias()]\r\n\t\tif !ok {\r\n\t\t\treturn nil, fmt.Errorf(\"cannot get logs for prowjob %q with agent %q: unknown cluster alias %q\", j.ObjectMeta.Name, j.Spec.Agent, j.ClusterAlias())\r\n\t\t}\r\n\t\treturn client.GetLogs(j.Status.PodName, &coreapi.PodLogOptions{Container: kube.TestContainerName})\r\n\t}\r\n\tfor _, agentToTmpl := range ja.config().Deck.ExternalAgentLogs {\r\n\t\tif agentToTmpl.Agent != string(j.Spec.Agent) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif !agentToTmpl.Selector.Matches(labels.Set(j.ObjectMeta.Labels)) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvar b bytes.Buffer\r\n\t\tif err := agentToTmpl.URLTemplate.Execute(&b, &j); err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"cannot execute URL template for prowjob %q with agent %q: %v\", j.ObjectMeta.Name, j.Spec.Agent, err)\r\n\t\t}\r\n\t\tresp, err := http.Get(b.String())\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tdefer resp.Body.Close()\r\n\t\treturn ioutil.ReadAll(resp.Body)\r\n\t}\r\n\treturn nil, fmt.Errorf(\"cannot get logs for prowjob %q with agent %q: the agent is missing from the prow config file\", j.ObjectMeta.Name, j.Spec.Agent)\r\n}","code-length":514,"reference":"\/\/ GetJobLog returns the job logs, works for both kubernetes and jenkins agent types.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc unionStrings(parent, child []string) []string {\r\n\tif child == nil {\r\n\t\treturn parent\r\n\t}\r\n\tif parent == nil {\r\n\t\treturn child\r\n\t}\r\n\ts := sets.NewString(parent...)\r\n\ts.Insert(child...)\r\n\treturn s.List()\r\n}","code-length":90,"reference":"\/\/ unionStrings merges the parent and child items together","result":"Create a union of two sets of strings.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p Policy) Apply(child Policy) Policy {\r\n\treturn Policy{\r\n\t\tProtect:                    selectBool(p.Protect, child.Protect),\r\n\t\tRequiredStatusChecks:       mergeContextPolicy(p.RequiredStatusChecks, child.RequiredStatusChecks),\r\n\t\tAdmins:                     selectBool(p.Admins, child.Admins),\r\n\t\tRestrictions:               mergeRestrictions(p.Restrictions, child.Restrictions),\r\n\t\tRequiredPullRequestReviews: mergeReviewPolicy(p.RequiredPullRequestReviews, child.RequiredPullRequestReviews),\r\n\t}\r\n}","code-length":143,"reference":"\/\/ Apply returns a policy that merges the child into the parent","result":"Apply a policy to a child policy.","score":[0.133,0.1739]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (bp BranchProtection) GetOrg(name string) *Org {\r\n\to, ok := bp.Orgs[name]\r\n\tif ok {\r\n\t\to.Policy = bp.Apply(o.Policy)\r\n\t} else {\r\n\t\to.Policy = bp.Policy\r\n\t}\r\n\treturn &o\r\n}","code-length":90,"reference":"\/\/ GetOrg returns the org config after merging in any global policies.","result":"Get the org from the branch protection.","score":[0.1118,0.087]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Org) GetRepo(name string) *Repo {\r\n\tr, ok := o.Repos[name]\r\n\tif ok {\r\n\t\tr.Policy = o.Apply(r.Policy)\r\n\t} else {\r\n\t\tr.Policy = o.Policy\r\n\t}\r\n\treturn &r\r\n}","code-length":88,"reference":"\/\/ GetRepo returns the repo config after merging in any org policies.","result":"Get the repo from the org.","score":[0.1004,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r Repo) GetBranch(name string) (*Branch, error) {\r\n\tb, ok := r.Branches[name]\r\n\tif ok {\r\n\t\tb.Policy = r.Apply(b.Policy)\r\n\t\tif b.Protect == nil {\r\n\t\t\treturn nil, errors.New(\"defined branch policies must set protect\")\r\n\t\t}\r\n\t} else {\r\n\t\tb.Policy = r.Policy\r\n\t}\r\n\treturn &b, nil\r\n}","code-length":128,"reference":"\/\/ GetBranch returns the branch config after merging in any repo policies.","result":"Get the branch.","score":[0.0203,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) GetPolicy(org, repo, branch string, b Branch) (*Policy, error) {\r\n\tpolicy := b.Policy\r\n\t\r\n\tif prowContexts, _, _ := BranchRequirements(org, repo, branch, c.Presubmits); len(prowContexts) > 0 {\r\n\t\t\r\n\t\tif policy.Protect != nil && !*policy.Protect {\r\n\t\t\treturn nil, fmt.Errorf(\"required prow jobs require branch protection\")\r\n\t\t}\r\n\t\tps := Policy{\r\n\t\t\tRequiredStatusChecks: &ContextPolicy{\r\n\t\t\t\tContexts: prowContexts,\r\n\t\t\t},\r\n\t\t}\r\n\t\t\r\n\t\tif c.BranchProtection.ProtectTested {\r\n\t\t\tyes := true\r\n\t\t\tps.Protect = &yes\r\n\t\t}\r\n\t\tpolicy = policy.Apply(ps)\r\n\t}\r\n\tif policy.Protect != nil && !*policy.Protect {\r\n\t\t\r\n\t\tvar old *bool\r\n\t\told, policy.Protect = policy.Protect, old\r\n\t\tswitch {\r\n\t\tcase policy.defined() && c.BranchProtection.AllowDisabledPolicies:\r\n\t\t\tlogrus.Warnf(\"%s\/%s=%s defines a policy but has protect: false\", org, repo, branch)\r\n\t\t\tpolicy = Policy{\r\n\t\t\t\tProtect: policy.Protect,\r\n\t\t\t}\r\n\t\tcase policy.defined():\r\n\t\t\treturn nil, fmt.Errorf(\"%s\/%s=%s defines a policy, which requires protect: true\", org, repo, branch)\r\n\t\t}\r\n\t\tpolicy.Protect = old\r\n\t}\r\n\tif !policy.defined() {\r\n\t\treturn nil, nil\r\n\t}\r\n\treturn &policy, nil\r\n}","code-length":433,"reference":"\/\/ GetPolicy returns the protection policy for the branch, after merging in presubmits.","result":"Get the policy for a branch.","score":[0.0941,0.2078]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UpdateIssueEvents(issueID int, db *gorm.DB, client ClientInterface) {\r\n\tlatest, err := findLatestEvent(issueID, db, client.RepositoryName())\r\n\tif err != nil {\r\n\t\tglog.Error(\"Failed to find last event: \", err)\r\n\t\treturn\r\n\t}\r\n\tc := make(chan *github.IssueEvent, 500)\r\n\tgo client.FetchIssueEvents(issueID, latest, c)\r\n\tfor event := range c {\r\n\t\teventOrm, err := NewIssueEvent(event, issueID, client.RepositoryName())\r\n\t\tif err != nil {\r\n\t\t\tglog.Error(\"Failed to create issue-event\", err)\r\n\t\t}\r\n\t\tdb.Create(eventOrm)\r\n\t}\r\n}","code-length":201,"reference":"\/\/ UpdateIssueEvents fetches all events until we find the most recent we\n\/\/ have in db, and saves everything in database","result":"Update the issue events in the database.","score":[0.0288,0.0765]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *controller) enqueueKey(ctx string, obj interface{}) {\r\n\tswitch o := obj.(type) {\r\n\tcase *prowjobv1.ProwJob:\r\n\t\tc.workqueue.AddRateLimited(toKey(ctx, o.Spec.Namespace, o.Name))\r\n\tcase *buildv1alpha1.Build:\r\n\t\tc.workqueue.AddRateLimited(toKey(ctx, o.Namespace, o.Name))\r\n\tdefault:\r\n\t\tlogrus.Warnf(\"cannot enqueue unknown type %T: %v\", o, obj)\r\n\t\treturn\r\n\t}\r\n}","code-length":161,"reference":"\/\/ enqueueKey schedules an item for reconciliation.","result":"Queue work for all objects.","score":[0.1611,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc prowJobStatus(bs buildv1alpha1.BuildStatus) (prowjobv1.ProwJobState, string) {\r\n\tstarted := bs.StartTime\r\n\tfinished := bs.CompletionTime\r\n\tpcond := bs.GetCondition(buildv1alpha1.BuildSucceeded)\r\n\tif pcond == nil {\r\n\t\tif !finished.IsZero() {\r\n\t\t\treturn prowjobv1.ErrorState, descMissingCondition\r\n\t\t}\r\n\t\treturn prowjobv1.TriggeredState, descScheduling\r\n\t}\r\n\tcond := *pcond\r\n\tswitch {\r\n\tcase cond.Status == coreapi.ConditionTrue:\r\n\t\treturn prowjobv1.SuccessState, description(cond, descSucceeded)\r\n\tcase cond.Status == coreapi.ConditionFalse:\r\n\t\treturn prowjobv1.FailureState, description(cond, descFailed)\r\n\tcase started.IsZero():\r\n\t\treturn prowjobv1.TriggeredState, description(cond, descInitializing)\r\n\tcase cond.Status == coreapi.ConditionUnknown, finished.IsZero():\r\n\t\treturn prowjobv1.PendingState, description(cond, descRunning)\r\n\t}\r\n\tlogrus.Warnf(\"Unknown condition %#v\", cond)\r\n\treturn prowjobv1.ErrorState, description(cond, descUnknown)\r\n}","code-length":337,"reference":"\/\/ prowJobStatus returns the desired state and description based on the build status.","result":"Determine the state of the prow job .","score":[0.0978,0.12]}
{"code":"\/*is used to<extra_id_0>\r\nfunc buildEnv(pj prowjobv1.ProwJob, buildID string) (map[string]string, error) {\r\n\treturn downwardapi.EnvForSpec(downwardapi.NewJobSpec(pj.Spec, buildID, pj.Name))\r\n}","code-length":75,"reference":"\/\/ buildEnv constructs the environment map for the job","result":"Build the environment.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc defaultArguments(t *buildv1alpha1.TemplateInstantiationSpec, rawEnv map[string]string) {\r\n\tkeys := sets.String{}\r\n\tfor _, arg := range t.Arguments {\r\n\t\tkeys.Insert(arg.Name)\r\n\t}\r\n\tfor _, k := range sets.StringKeySet(rawEnv).List() {\r\n\t\tif keys.Has(k) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tt.Arguments = append(t.Arguments, buildv1alpha1.ArgumentSpec{Name: k, Value: rawEnv[k]})\r\n\t}\r\n}","code-length":157,"reference":"\/\/ defaultArguments will append each arg to the template, except where the argument name is already defined.","result":"Set default arguments.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc defaultEnv(c *coreapi.Container, rawEnv map[string]string) {\r\n\tkeys := sets.String{}\r\n\tfor _, arg := range c.Env {\r\n\t\tkeys.Insert(arg.Name)\r\n\t}\r\n\tfor _, k := range sets.StringKeySet(rawEnv).List() {\r\n\t\tif keys.Has(k) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tc.Env = append(c.Env, coreapi.EnvVar{Name: k, Value: rawEnv[k]})\r\n\t}\r\n}","code-length":149,"reference":"\/\/ defaultEnv adds the map of environment variables to the container, except keys already defined.","result":"Set the default environment variables.","score":[0.0387,0.0714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc injectSource(b *buildv1alpha1.Build, pj prowjobv1.ProwJob) (bool, error) {\r\n\tif b.Spec.Source != nil {\r\n\t\treturn false, nil\r\n\t}\r\n\tsrcContainer, refs, cloneVolumes, err := decorate.CloneRefs(pj, codeMount, logMount)\r\n\tif err != nil {\r\n\t\treturn false, fmt.Errorf(\"clone source error: %v\", err)\r\n\t}\r\n\tif srcContainer == nil {\r\n\t\treturn false, nil\r\n\t} else {\r\n\t\tsrcContainer.Name = \"\"\r\n\t}\r\n\tb.Spec.Source = &buildv1alpha1.SourceSpec{\r\n\t\tCustom: srcContainer,\r\n\t}\r\n\tb.Spec.Volumes = append(b.Spec.Volumes, cloneVolumes...)\r\n\twd := workDir(refs[0])\r\n\t\r\n\tfor i := range b.Spec.Steps {\r\n\t\tif b.Spec.Steps[i].WorkingDir != \"\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tb.Spec.Steps[i].WorkingDir = wd.Value\r\n\t}\r\n\tif b.Spec.Template != nil {\r\n\t\t\r\n\t\tb.Spec.Template.Arguments = append(b.Spec.Template.Arguments, wd)\r\n\t}\r\n\treturn true, nil\r\n}","code-length":344,"reference":"\/\/ injectSource adds the custom source container to call clonerefs correctly.\n\/\/\n\/\/ Returns true if it added this container\n\/\/\n\/\/ Does nothing if the build spec predefines Source","result":"Inject source into build.","score":[0.0005,0.0182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc injectedSteps(encodedJobSpec string, dc prowjobv1.DecorationConfig, injectedSource bool, toolsMount coreapi.VolumeMount, entries []wrapper.Options) ([]coreapi.Container, *coreapi.Container, *coreapi.Volume, error) {\r\n\tgcsVol, gcsMount, gcsOptions := decorate.GCSOptions(dc)\r\n\tsidecar, err := decorate.Sidecar(dc.UtilityImages.Sidecar, gcsOptions, gcsMount, logMount, encodedJobSpec, decorate.RequirePassingEntries, entries...)\r\n\tif err != nil {\r\n\t\treturn nil, nil, nil, fmt.Errorf(\"inject sidecar: %v\", err)\r\n\t}\r\n\tvar cloneLogMount *coreapi.VolumeMount\r\n\tif injectedSource {\r\n\t\tcloneLogMount = &logMount\r\n\t}\r\n\tinitUpload, err := decorate.InitUpload(dc.UtilityImages.InitUpload, gcsOptions, gcsMount, cloneLogMount, encodedJobSpec)\r\n\tif err != nil {\r\n\t\treturn nil, nil, nil, fmt.Errorf(\"inject initupload: %v\", err)\r\n\t}\r\n\tplacer := decorate.PlaceEntrypoint(dc.UtilityImages.Entrypoint, toolsMount)\r\n\treturn []coreapi.Container{placer, *initUpload}, sidecar, &gcsVol, nil\r\n}","code-length":327,"reference":"\/\/ injectedSteps returns initial containers, a final container and an additional volume.","result":"Generate the steps to be injected.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc determineTimeout(spec *buildv1alpha1.BuildSpec, dc *prowjobv1.DecorationConfig, defaultTimeout time.Duration) time.Duration {\r\n\tswitch {\r\n\tcase spec.Timeout != nil:\r\n\t\treturn spec.Timeout.Duration\r\n\tcase dc != nil && dc.Timeout.Duration > 0:\r\n\t\treturn dc.Timeout.Duration\r\n\tdefault:\r\n\t\treturn defaultTimeout\r\n\t}\r\n}","code-length":116,"reference":"\/\/ determineTimeout decides the timeout value used for build","result":"Determine the timeout of the build.","score":[0.1656,0.1149]}
{"code":"\/*is used to<extra_id_0>\r\nfunc makeBuild(pj prowjobv1.ProwJob, defaultTimeout time.Duration) (*buildv1alpha1.Build, error) {\r\n\tif pj.Spec.BuildSpec == nil {\r\n\t\treturn nil, errors.New(\"nil BuildSpec in spec\")\r\n\t}\r\n\tbuildID := pj.Status.BuildID\r\n\tif buildID == \"\" {\r\n\t\treturn nil, errors.New(\"empty BuildID in status\")\r\n\t}\r\n\tb := buildv1alpha1.Build{\r\n\t\tObjectMeta: buildMeta(pj),\r\n\t\tSpec:       *pj.Spec.BuildSpec.DeepCopy(),\r\n\t}\r\n\trawEnv, err := buildEnv(pj, buildID)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"environment error: %v\", err)\r\n\t}\r\n\tinjectEnvironment(&b, rawEnv)\r\n\tinjectedSource, err := injectSource(&b, pj)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"inject source: %v\", err)\r\n\t}\r\n\tinjectTimeout(&b.Spec, pj.Spec.DecorationConfig, defaultTimeout)\r\n\tif pj.Spec.DecorationConfig != nil {\r\n\t\tencodedJobSpec := rawEnv[downwardapi.JobSpecEnv]\r\n\t\terr = decorateBuild(&b.Spec, encodedJobSpec, *pj.Spec.DecorationConfig, injectedSource)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"decorate build: %v\", err)\r\n\t\t}\r\n\t}\r\n\treturn &b, nil\r\n}","code-length":415,"reference":"\/\/ makeBuild creates a build from the prowjob, using the prowjob's buildspec.","result":"Create a new build .","score":[0.0705,0.2262]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newLabels(issueID int, gLabels []github.Label, repository string) ([]sql.Label, error) {\r\n\tlabels := []sql.Label{}\r\n\trepository = strings.ToLower(repository)\r\n\tfor _, label := range gLabels {\r\n\t\tif label.Name == nil {\r\n\t\t\treturn nil, fmt.Errorf(\"Label is missing name field\")\r\n\t\t}\r\n\t\tlabels = append(labels, sql.Label{\r\n\t\t\tIssueID:    strconv.Itoa(issueID),\r\n\t\t\tName:       *label.Name,\r\n\t\t\tRepository: repository,\r\n\t\t})\r\n\t}\r\n\treturn labels, nil\r\n}","code-length":172,"reference":"\/\/ newLabels creates a new Label for each label in the issue","result":"Create labels in the database.","score":[0.0838,0.3319]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newAssignees(issueID int, gAssignees []*github.User, repository string) ([]sql.Assignee, error) {\r\n\tassignees := []sql.Assignee{}\r\n\trepository = strings.ToLower(repository)\r\n\tfor _, assignee := range gAssignees {\r\n\t\tif assignee != nil && assignee.Login == nil {\r\n\t\t\treturn nil, fmt.Errorf(\"Assignee is missing Login field\")\r\n\t\t}\r\n\t\tassignees = append(assignees, sql.Assignee{\r\n\t\t\tIssueID:    strconv.Itoa(issueID),\r\n\t\t\tName:       *assignee.Login,\r\n\t\t\tRepository: repository,\r\n\t\t})\r\n\t}\r\n\treturn assignees, nil\r\n}","code-length":192,"reference":"\/\/ newAssignees creates a new Label for each label in the issue","result":"Create a new assignee .","score":[0.0838,0.2606]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewIssueComment(issueID int, gComment *github.IssueComment, repository string) (*sql.Comment, error) {\r\n\tif gComment.ID == nil ||\r\n\t\tgComment.Body == nil ||\r\n\t\tgComment.CreatedAt == nil ||\r\n\t\tgComment.UpdatedAt == nil {\r\n\t\treturn nil, fmt.Errorf(\"IssueComment is missing mandatory field: %s\", gComment)\r\n\t}\r\n\tvar login string\r\n\tif gComment.User != nil && gComment.User.Login != nil {\r\n\t\tlogin = *gComment.User.Login\r\n\t}\r\n\treturn &sql.Comment{\r\n\t\tID:               itoa(*gComment.ID),\r\n\t\tIssueID:          strconv.Itoa(issueID),\r\n\t\tBody:             *gComment.Body,\r\n\t\tUser:             login,\r\n\t\tCommentCreatedAt: *gComment.CreatedAt,\r\n\t\tCommentUpdatedAt: *gComment.UpdatedAt,\r\n\t\tPullRequest:      false,\r\n\t\tRepository:       strings.ToLower(repository),\r\n\t}, nil\r\n}","code-length":272,"reference":"\/\/ NewIssueComment creates a Comment from a github.IssueComment","result":"Create a new comment in the database.","score":[0.14,0.1899]}
{"code":"\/*is used to<extra_id_0>\r\nfunc messageFilter(lastUpdate time.Time, change client.ChangeInfo, presubmits []config.Presubmit) (pjutil.Filter, error) {\r\n\tvar filters []pjutil.Filter\r\n\tcurrentRevision := change.Revisions[change.CurrentRevision].Number\r\n\tfor _, message := range change.Messages {\r\n\t\tmessageTime := message.Date.Time\r\n\t\tif message.RevisionNumber != currentRevision || !messageTime.After(lastUpdate) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif !pjutil.TestAllRe.MatchString(message.Message) {\r\n\t\t\tfor _, presubmit := range presubmits {\r\n\t\t\t\tif presubmit.TriggerMatches(message.Message) {\r\n\t\t\t\t\tlogrus.Infof(\"Change %d: Comment %s matches triggering regex, for %s.\", change.Number, message.Message, presubmit.Name)\r\n\t\t\t\t\tfilters = append(filters, pjutil.CommandFilter(message.Message))\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\tfilters = append(filters, pjutil.TestAllFilter())\r\n\t\t}\r\n\t}\r\n\treturn pjutil.AggregateFilter(filters), nil\r\n}","code-length":307,"reference":"\/\/ messageFilter builds a filter for jobs based on the messageBody matching the trigger regex of the jobs.","result":"Filter messages by command.","score":[0,0.0301]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (jb *Build) IsSuccess() bool {\r\n\treturn jb.Result != nil && *jb.Result == success\r\n}","code-length":39,"reference":"\/\/ IsSuccess means the job passed","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (jb *Build) IsFailure() bool {\r\n\treturn jb.Result != nil && (*jb.Result == failure || *jb.Result == unstable)\r\n}","code-length":49,"reference":"\/\/ IsFailure means the job completed with problems.","result":"Generate the code.","score":[0.0771,0.0667]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (jb *Build) IsAborted() bool {\r\n\treturn jb.Result != nil && *jb.Result == aborted\r\n}","code-length":39,"reference":"\/\/ IsAborted means something stopped the job before it could finish.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (jb *Build) ProwJobID() string {\r\n\tfor _, action := range jb.Actions {\r\n\t\tfor _, p := range action.Parameters {\r\n\t\t\tif p.Name == prowJobID {\r\n\t\t\t\tvalue, ok := p.Value.(string)\r\n\t\t\t\tif !ok {\r\n\t\t\t\t\tlogrus.Errorf(\"Cannot determine %s value for %#v\", p.Name, jb)\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\treturn value\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn \"\"\r\n}","code-length":149,"reference":"\/\/ ProwJobID extracts the ProwJob identifier for the\n\/\/ Jenkins build in order to correlate the build with\n\/\/ a ProwJob. If the build has an empty PROW_JOB_ID\n\/\/ it didn't start by prow.","result":"Generate the code.","score":[0.0,0.0162]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (jb *Build) BuildID() string {\r\n\tvar buildID string\r\n\thasProwJobID := false\r\n\tfor _, action := range jb.Actions {\r\n\t\tfor _, p := range action.Parameters {\r\n\t\t\thasProwJobID = hasProwJobID || p.Name == prowJobID\r\n\t\t\tif p.Name == statusBuildID {\r\n\t\t\t\tvalue, ok := p.Value.(string)\r\n\t\t\t\tif !ok {\r\n\t\t\t\t\tlogrus.Errorf(\"Cannot determine %s value for %#v\", p.Name, jb)\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t\tbuildID = value\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif !hasProwJobID {\r\n\t\treturn \"\"\r\n\t}\r\n\treturn buildID\r\n}","code-length":211,"reference":"\/\/ BuildID extracts the build identifier used for\n\/\/ placing and discovering build artifacts.\n\/\/ This identifier can either originate from tot\n\/\/ or the snowflake library, depending on how the\n\/\/ Jenkins operator is configured to run.\n\/\/ We return an empty string if we are dealing with\n\/\/ a build that does not have the ProwJobID set\n\/\/ explicitly, as in that case the Jenkins build has\n\/\/ not started by prow.","result":"Determine the build ID of.","score":[0.0,0.0149]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) CrumbRequest() error {\r\n\tif c.authConfig.csrfToken != \"\" && c.authConfig.csrfRequestField != \"\" {\r\n\t\treturn nil\r\n\t}\r\n\tc.logger.Debug(\"CrumbRequest\")\r\n\tdata, err := c.GetSkipMetrics(\"\/crumbIssuer\/api\/json\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tcrumbResp := struct {\r\n\t\tCrumb             string `json:\"crumb\"`\r\n\t\tCrumbRequestField string `json:\"crumbRequestField\"`\r\n\t}{}\r\n\tif err := json.Unmarshal(data, &crumbResp); err != nil {\r\n\t\treturn fmt.Errorf(\"cannot unmarshal crumb response: %v\", err)\r\n\t}\r\n\tc.authConfig.csrfToken = crumbResp.Crumb\r\n\tc.authConfig.csrfRequestField = crumbResp.CrumbRequestField\r\n\treturn nil\r\n}","code-length":241,"reference":"\/\/ CrumbRequest requests a CSRF protection token from Jenkins to\n\/\/ use it in subsequent requests. Required for Jenkins masters that\n\/\/ prevent cross site request forgery exploits.","result":"Generate code for the generated code.","score":[0.0049,0.0194]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) measure(method, path string, code int, start time.Time) {\r\n\tif c.metrics == nil {\r\n\t\treturn\r\n\t}\r\n\tc.metrics.RequestLatency.WithLabelValues(method, path).Observe(time.Since(start).Seconds())\r\n\tc.metrics.Requests.WithLabelValues(method, path, fmt.Sprintf(\"%d\", code)).Inc()\r\n}","code-length":111,"reference":"\/\/ measure records metrics about the provided method, path, and code.\n\/\/ start needs to be recorded before doing the request.","result":"Measure the request latency.","score":[0.0046,0.0518]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) GetSkipMetrics(path string) ([]byte, error) {\r\n\tresp, err := c.request(http.MethodGet, path, nil, false)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn readResp(resp)\r\n}","code-length":83,"reference":"\/\/ GetSkipMetrics fetches the data found in the provided path. It returns the\n\/\/ content of the response or any errors that occurred during the request or\n\/\/ http errors. Metrics will not be gathered for this request.","result":"Get skip metrics.","score":[0,0.0145]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Get(path string) ([]byte, error) {\r\n\tresp, err := c.request(http.MethodGet, path, nil, true)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn readResp(resp)\r\n}","code-length":81,"reference":"\/\/ Get fetches the data found in the provided path. It returns the\n\/\/ content of the response or any errors that occurred during the\n\/\/ request or http errors.","result":"Call the Get method.","score":[0.0006,0.0365]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) request(method, path string, params url.Values, measure bool) (*http.Response, error) {\r\n\tvar resp *http.Response\r\n\tvar err error\r\n\tbackoff := retryDelay\r\n\turlPath := fmt.Sprintf(\"%s%s\", c.baseURL, path)\r\n\tif params != nil {\r\n\t\turlPath = fmt.Sprintf(\"%s?%s\", urlPath, params.Encode())\r\n\t}\r\n\tstart := time.Now()\r\n\tfor retries := 0; retries < maxRetries; retries++ {\r\n\t\tresp, err = c.doRequest(method, urlPath)\r\n\t\tif err == nil && resp.StatusCode < 500 {\r\n\t\t\tbreak\r\n\t\t} else if err == nil && retries+1 < maxRetries {\r\n\t\t\tresp.Body.Close()\r\n\t\t}\r\n\t\t\r\n\t\tif measure && c.metrics != nil {\r\n\t\t\tc.metrics.RequestRetries.Inc()\r\n\t\t}\r\n\t\ttime.Sleep(backoff)\r\n\t\tbackoff *= 2\r\n\t}\r\n\tif measure && resp != nil {\r\n\t\tc.measure(method, path, resp.StatusCode, start)\r\n\t}\r\n\treturn resp, err\r\n}","code-length":311,"reference":"\/\/ request executes a request with the provided method and path.\n\/\/ It retries on transport failures and 500s. measure is provided\n\/\/ to enable or disable gathering metrics for specific requests\n\/\/ to avoid high-cardinality metrics.","result":"Create a new client.","score":[0.0001,0.0148]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) doRequest(method, path string) (*http.Response, error) {\r\n\treq, err := http.NewRequest(method, path, nil)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif c.authConfig != nil {\r\n\t\tif c.authConfig.Basic != nil {\r\n\t\t\treq.SetBasicAuth(c.authConfig.Basic.User, string(c.authConfig.Basic.GetToken()))\r\n\t\t}\r\n\t\tif c.authConfig.BearerToken != nil {\r\n\t\t\treq.Header.Set(\"Authorization\", fmt.Sprintf(\"Bearer %s\", c.authConfig.BearerToken.GetToken()))\r\n\t\t}\r\n\t\tif c.authConfig.CSRFProtect && c.authConfig.csrfRequestField != \"\" && c.authConfig.csrfToken != \"\" {\r\n\t\t\treq.Header.Set(c.authConfig.csrfRequestField, c.authConfig.csrfToken)\r\n\t\t}\r\n\t}\r\n\treturn c.client.Do(req)\r\n}","code-length":269,"reference":"\/\/ doRequest executes a request with the provided method and path\n\/\/ exactly once. It sets up authentication if the jenkins client\n\/\/ is configured accordingly. It's up to callers of this function\n\/\/ to build retries and error handling.","result":"Generate the code for the client .","score":[0.0019,0.0409]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getJobName(spec *prowapi.ProwJobSpec) string {\r\n\tif spec.JenkinsSpec != nil && spec.JenkinsSpec.GitHubBranchSourceJob && spec.Refs != nil {\r\n\t\tif len(spec.Refs.Pulls) > 0 {\r\n\t\t\treturn fmt.Sprintf(\"%s\/view\/change-requests\/job\/PR-%d\", spec.Job, spec.Refs.Pulls[0].Number)\r\n\t\t}\r\n\t\treturn fmt.Sprintf(\"%s\/job\/%s\", spec.Job, spec.Refs.BaseRef)\r\n\t}\r\n\treturn spec.Job\r\n}","code-length":157,"reference":"\/\/ getJobName generates the correct job name for this job type","result":"Generate the job name.","score":[0.066,0.2481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getBuildPath(spec *prowapi.ProwJobSpec) string {\r\n\tjenkinsJobName := getJobName(spec)\r\n\tjenkinsPath := fmt.Sprintf(\"\/job\/%s\/build\", jenkinsJobName)\r\n\treturn jenkinsPath\r\n}","code-length":71,"reference":"\/\/ getBuildPath builds a path to trigger a regular build for this job","result":"Generate the build path.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) GetJobInfo(spec *prowapi.ProwJobSpec) (*JobInfo, error) {\r\n\tpath := getJobInfoPath(spec)\r\n\tc.logger.Debugf(\"getJobInfoPath: %s\", path)\r\n\tdata, err := c.Get(path)\r\n\tif err != nil {\r\n\t\tc.logger.Errorf(\"Failed to get job info: %v\", err)\r\n\t\treturn nil, err\r\n\t}\r\n\tvar jobInfo JobInfo\r\n\tif err := json.Unmarshal(data, &jobInfo); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"Cannot unmarshal job info from API: %v\", err)\r\n\t}\r\n\tc.logger.Tracef(\"JobInfo: %+v\", jobInfo)\r\n\treturn &jobInfo, nil\r\n}","code-length":209,"reference":"\/\/ GetJobInfo retrieves Jenkins job information","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) JobParameterized(jobInfo *JobInfo) bool {\r\n\tfor _, prop := range jobInfo.Property {\r\n\t\tif prop.ParameterDefinitions != nil && len(prop.ParameterDefinitions) > 0 {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":85,"reference":"\/\/ JobParameterized tells us if the Jenkins job for this ProwJob is parameterized","result":"Generate the code.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) EnsureBuildableJob(spec *prowapi.ProwJobSpec) error {\r\n\tvar jobInfo *JobInfo\r\n\t\r\n\tgetJobInfoBackoff := wait.Backoff{\r\n\t\tDuration: time.Duration(10) * time.Second,\r\n\t\tFactor:   1,\r\n\t\tJitter:   0,\r\n\t\tSteps:    2,\r\n\t}\r\n\tgetJobErr := wait.ExponentialBackoff(getJobInfoBackoff, func() (bool, error) {\r\n\t\tvar jobErr error\r\n\t\tjobInfo, jobErr = c.GetJobInfo(spec)\r\n\t\tif jobErr != nil && !strings.Contains(strings.ToLower(jobErr.Error()), \"404 not found\") {\r\n\t\t\treturn false, jobErr\r\n\t\t}\r\n\t\treturn jobInfo != nil, nil\r\n\t})\r\n\tif getJobErr != nil {\r\n\t\treturn fmt.Errorf(\"Job %v does not exist\", spec.Job)\r\n\t}\r\n\tisParameterized := c.JobParameterized(jobInfo)\r\n\tc.logger.Tracef(\"JobHasParameters: %v\", isParameterized)\r\n\tif isParameterized || len(jobInfo.Builds) > 0 {\r\n\t\treturn nil\r\n\t}\r\n\tbuildErr := c.LaunchBuild(spec, nil)\r\n\tif buildErr != nil {\r\n\t\treturn buildErr\r\n\t}\r\n\tbackoff := wait.Backoff{\r\n\t\tDuration: time.Duration(5) * time.Second,\r\n\t\tFactor:   1,\r\n\t\tJitter:   1,\r\n\t\tSteps:    10,\r\n\t}\r\n\treturn wait.ExponentialBackoff(backoff, func() (bool, error) {\r\n\t\tc.logger.Debugf(\"Waiting for job %v to become parameterized\", spec.Job)\r\n\t\tjobInfo, _ := c.GetJobInfo(spec)\r\n\t\tisParameterized := false\r\n\t\tif jobInfo != nil {\r\n\t\t\tisParameterized = c.JobParameterized(jobInfo)\r\n\t\t\tif isParameterized && jobInfo.LastBuild != nil {\r\n\t\t\t\tc.logger.Debugf(\"Job %v is now parameterized, aborting the build\", spec.Job)\r\n\t\t\t\terr := c.Abort(getJobName(spec), jobInfo.LastBuild)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tc.logger.Infof(\"Couldn't abort build #%v for job %v: %v\", jobInfo.LastBuild.Number, spec.Job, err)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\treturn isParameterized, nil\r\n\t})\r\n}","code-length":646,"reference":"\/\/ EnsureBuildableJob attempts to detect a job that hasn't yet ran and populated\n\/\/ its parameters. If detected, it tries to run a build until the job parameters\n\/\/ are processed, then it aborts the build.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) LaunchBuild(spec *prowapi.ProwJobSpec, params url.Values) error {\r\n\tvar path string\r\n\tif params != nil {\r\n\t\tpath = getBuildWithParametersPath(spec)\r\n\t} else {\r\n\t\tpath = getBuildPath(spec)\r\n\t}\r\n\tc.logger.Debugf(\"getBuildPath\/getBuildWithParametersPath: %s\", path)\r\n\tresp, err := c.request(http.MethodPost, path, params, true)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\tif resp.StatusCode != 201 {\r\n\t\treturn fmt.Errorf(\"response not 201: %s\", resp.Status)\r\n\t}\r\n\treturn nil\r\n}","code-length":200,"reference":"\/\/ LaunchBuild launches a regular or parameterized Jenkins build, depending on\n\/\/ whether or not we have `params` to POST","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Build(pj *prowapi.ProwJob, buildID string) error {\r\n\tc.logger.WithFields(pjutil.ProwJobFields(pj)).Info(\"Build\")\r\n\treturn c.BuildFromSpec(&pj.Spec, buildID, pj.ObjectMeta.Name)\r\n}","code-length":91,"reference":"\/\/ Build triggers a Jenkins build for the provided ProwJob. The name of\n\/\/ the ProwJob is going to be used as the Prow Job ID parameter that will\n\/\/ help us track the build before it's scheduled by Jenkins.","result":"Build the pj.","score":[0.0,0.0275]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) BuildFromSpec(spec *prowapi.ProwJobSpec, buildID, prowJobID string) error {\r\n\tif c.dryRun {\r\n\t\treturn nil\r\n\t}\r\n\tenv, err := downwardapi.EnvForSpec(downwardapi.NewJobSpec(*spec, buildID, prowJobID))\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tparams := url.Values{}\r\n\tfor key, value := range env {\r\n\t\tparams.Set(key, value)\r\n\t}\r\n\tif err := c.EnsureBuildableJob(spec); err != nil {\r\n\t\treturn fmt.Errorf(\"Job %v cannot be build: %v\", spec.Job, err)\r\n\t}\r\n\treturn c.LaunchBuild(spec, params)\r\n}","code-length":211,"reference":"\/\/ BuildFromSpec triggers a Jenkins build for the provided ProwJobSpec.\n\/\/ prowJobID helps us track the build before it's scheduled by Jenkins.","result":"Generate the generated code.","score":[0.0035,0.0248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) GetEnqueuedBuilds(jobs []BuildQueryParams) (map[string]Build, error) {\r\n\tc.logger.Debug(\"GetEnqueuedBuilds\")\r\n\tdata, err := c.Get(\"\/queue\/api\/json?tree=items[task[name],actions[parameters[name,value]]]\")\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"cannot list builds from the queue: %v\", err)\r\n\t}\r\n\tpage := struct {\r\n\t\tQueuedBuilds []Build `json:\"items\"`\r\n\t}{}\r\n\tif err := json.Unmarshal(data, &page); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"cannot unmarshal builds from the queue: %v\", err)\r\n\t}\r\n\tjenkinsBuilds := make(map[string]Build)\r\n\tfor _, jb := range page.QueuedBuilds {\r\n\t\tprowJobID := jb.ProwJobID()\r\n\t\t\r\n\t\tif prowJobID == \"\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tvar exists bool\r\n\t\tfor _, job := range jobs {\r\n\t\t\tif prowJobID == job.ProwJobID {\r\n\t\t\t\texists = true\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif !exists {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tjb.enqueued = true\r\n\t\tjenkinsBuilds[prowJobID] = jb\r\n\t}\r\n\treturn jenkinsBuilds, nil\r\n}","code-length":381,"reference":"\/\/ GetEnqueuedBuilds lists all enqueued builds for the provided jobs.","result":"Get the build jobs from the queue.","score":[0.1052,0.1031]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Abort(job string, build *Build) error {\r\n\tc.logger.Debugf(\"Abort(%v %v)\", job, build.Number)\r\n\tif c.dryRun {\r\n\t\treturn nil\r\n\t}\r\n\tresp, err := c.request(http.MethodPost, fmt.Sprintf(\"\/job\/%s\/%d\/stop\", job, build.Number), nil, false)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\tif resp.StatusCode < 200 || resp.StatusCode >= 300 {\r\n\t\treturn fmt.Errorf(\"response not 2XX: %s\", resp.Status)\r\n\t}\r\n\treturn nil\r\n}","code-length":184,"reference":"\/\/ Abort aborts the provided Jenkins build for job.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PresubmitToJobSpec(pre config.Presubmit) *downwardapi.JobSpec {\r\n\treturn &downwardapi.JobSpec{\r\n\t\tType: prowapi.PresubmitJob,\r\n\t\tJob:  pre.Name,\r\n\t}\r\n}","code-length":77,"reference":"\/\/ PresubmitToJobSpec generates a downwardapi.JobSpec out of a Presubmit.\n\/\/ Useful for figuring out GCS paths when parsing jobs out\n\/\/ of a prow config.","result":"Generate the job spec.","score":[0,0.0437]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PostsubmitToJobSpec(post config.Postsubmit) *downwardapi.JobSpec {\r\n\treturn &downwardapi.JobSpec{\r\n\t\tType: prowapi.PostsubmitJob,\r\n\t\tJob:  post.Name,\r\n\t}\r\n}","code-length":74,"reference":"\/\/ PostsubmitToJobSpec generates a downwardapi.JobSpec out of a Postsubmit.\n\/\/ Useful for figuring out GCS paths when parsing jobs out\n\/\/ of a prow config.","result":"Convert postsubmit config to job spec.","score":[0,0.0216]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PeriodicToJobSpec(periodic config.Periodic) *downwardapi.JobSpec {\r\n\treturn &downwardapi.JobSpec{\r\n\t\tType: prowapi.PeriodicJob,\r\n\t\tJob:  periodic.Name,\r\n\t}\r\n}","code-length":73,"reference":"\/\/ PeriodicToJobSpec generates a downwardapi.JobSpec out of a Periodic.\n\/\/ Useful for figuring out GCS paths when parsing jobs out\n\/\/ of a prow config.","result":"Generate the job spec.","score":[0,0.0437]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetBuildID(name, totURL string) (string, error) {\r\n\tif totURL == \"\" {\r\n\t\treturn node.Generate().String(), nil\r\n\t}\r\n\tvar err error\r\n\turl, err := url.Parse(totURL)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"invalid tot url: %v\", err)\r\n\t}\r\n\turl.Path = path.Join(url.Path, \"vend\", name)\r\n\tsleepDuration := 100 * time.Millisecond\r\n\tfor retries := 0; retries < 10; retries++ {\r\n\t\tif retries > 0 {\r\n\t\t\tsleep(sleepDuration)\r\n\t\t\tsleepDuration = sleepDuration * 2\r\n\t\t}\r\n\t\tvar resp *http.Response\r\n\t\tresp, err = http.Get(url.String())\r\n\t\tif err != nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tdefer resp.Body.Close()\r\n\t\tif resp.StatusCode != 200 {\r\n\t\t\terr = fmt.Errorf(\"got unexpected response from tot: %v\", resp.Status)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tvar buf []byte\r\n\t\tbuf, err = ioutil.ReadAll(resp.Body)\r\n\t\tif err == nil {\r\n\t\t\treturn string(buf), nil\r\n\t\t}\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn \"\", err\r\n}","code-length":354,"reference":"\/\/ GetBuildID calls out to `tot` in order\n\/\/ to vend build identifier for the job","result":"Generate a unique build ID.","score":[0.0266,0.0336]}
{"code":"\/*is used to<extra_id_0>\r\nfunc listGcsObjects(ctx context.Context, client *storage.Client, bucketName, prefix, delim string) (\r\n\t[]string, error) {\r\n\tvar objects []string\r\n\tit := client.Bucket(bucketName).Objects(ctx, &storage.Query{\r\n\t\tPrefix:    prefix,\r\n\t\tDelimiter: delim,\r\n\t})\r\n\tfor {\r\n\t\tattrs, err := it.Next()\r\n\t\tif err == iterator.Done {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn objects, fmt.Errorf(\"error iterating: %v\", err)\r\n\t\t}\r\n\t\tif attrs.Prefix != \"\" {\r\n\t\t\tobjects = append(objects, path.Base(attrs.Prefix))\r\n\t\t}\r\n\t}\r\n\tlogrus.Info(\"end of listGcsObjects(...)\")\r\n\treturn objects, nil\r\n}","code-length":227,"reference":"\/\/listGcsObjects get the slice of gcs objects under a given path","result":"List GCS objects.","score":[0,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FindBaseProfile(ctx context.Context, client *storage.Client, bucket, prowJobName, artifactsDirName,\r\n\tcovProfileName string) ([]byte, error) {\r\n\tdirOfJob := path.Join(\"logs\", prowJobName)\r\n\tstrBuilds, err := listGcsObjects(ctx, client, bucket, dirOfJob+\"\/\", \"\/\")\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error listing gcs objects: %v\", err)\r\n\t}\r\n\tbuilds := sortBuilds(strBuilds)\r\n\tprofilePath := \"\"\r\n\tfor _, build := range builds {\r\n\t\tbuildDirPath := path.Join(dirOfJob, strconv.Itoa(build))\r\n\t\tdirOfStatusJSON := path.Join(buildDirPath, statusJSON)\r\n\t\tstatusText, err := readGcsObject(ctx, client, bucket, dirOfStatusJSON)\r\n\t\tif err != nil {\r\n\t\t\tlogrus.Infof(\"Cannot read finished.json (%s) in bucket '%s'\", dirOfStatusJSON, bucket)\r\n\t\t} else if isBuildSucceeded(statusText) {\r\n\t\t\tartifactsDirPath := path.Join(buildDirPath, artifactsDirName)\r\n\t\t\tprofilePath = path.Join(artifactsDirPath, covProfileName)\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif profilePath == \"\" {\r\n\t\treturn nil, fmt.Errorf(\"no healthy build found for job '%s' in bucket '%s'; total # builds = %v\", dirOfJob, bucket, len(builds))\r\n\t}\r\n\treturn readGcsObject(ctx, client, bucket, profilePath)\r\n}","code-length":401,"reference":"\/\/ FindBaseProfile finds the coverage profile file from the latest healthy build\n\/\/ stored in given gcs directory","result":"Find the base profile for a given job.","score":[0.0524,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc sortBuilds(strBuilds []string) []int {\r\n\tvar res []int\r\n\tfor _, buildStr := range strBuilds {\r\n\t\tnum, err := strconv.Atoi(buildStr)\r\n\t\tif err != nil {\r\n\t\t\tlogrus.Infof(\"Non-int build number found: '%s'\", buildStr)\r\n\t\t} else {\r\n\t\t\tres = append(res, num)\r\n\t\t}\r\n\t}\r\n\tsort.Sort(sort.Reverse(sort.IntSlice(res)))\r\n\treturn res\r\n}","code-length":144,"reference":"\/\/ sortBuilds converts all build from str to int and sorts all builds in descending order and\n\/\/ returns the sorted slice","result":"Sort the builds in the build list.","score":[0.0319,0.1815]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetAll(sess *session.Session) ([]string, error) {\r\n\tvar regions []string\r\n\tsvc := ec2.New(sess, &aws.Config{Region: aws.String(Default)})\r\n\tresp, err := svc.DescribeRegions(nil)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tfor _, region := range resp.Regions {\r\n\t\tregions = append(regions, *region.RegionName)\r\n\t}\r\n\treturn regions, nil\r\n}","code-length":135,"reference":"\/\/ GetAll retrieves all regions from the AWS API","result":"Get all the available regions.","score":[0.1284,0.1163]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewEventClient(ghc githubClient, log *logrus.Entry, org, repo string, number int) *EventClient {\r\n\treturn &EventClient{\r\n\t\torg:    org,\r\n\t\trepo:   repo,\r\n\t\tnumber: number,\r\n\t\tghc: ghc,\r\n\t\tlog: log,\r\n\t}\r\n}","code-length":97,"reference":"\/\/ NewEventClient creates an EventClient struct. This should be used once per webhook event.","result":"Create a new event client.","score":[0,0.0382]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *EventClient) PruneComments(shouldPrune func(github.IssueComment) bool) {\r\n\tc.once.Do(func() {\r\n\t\tbotName, err := c.ghc.BotName()\r\n\t\tif err != nil {\r\n\t\t\tc.log.WithError(err).Error(\"failed to get the bot's name. Pruning will consider all comments.\")\r\n\t\t}\r\n\t\tcomments, err := c.ghc.ListIssueComments(c.org, c.repo, c.number)\r\n\t\tif err != nil {\r\n\t\t\tc.log.WithError(err).Errorf(\"failed to list comments for %s\/%s#%d\", c.org, c.repo, c.number)\r\n\t\t}\r\n\t\tif botName != \"\" {\r\n\t\t\tfor _, comment := range comments {\r\n\t\t\t\tif comment.User.Login == botName {\r\n\t\t\t\t\tc.comments = append(c.comments, comment)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t})\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tvar remaining []github.IssueComment\r\n\tfor _, comment := range c.comments {\r\n\t\tremoved := false\r\n\t\tif shouldPrune(comment) {\r\n\t\t\tif err := c.ghc.DeleteComment(c.org, c.repo, comment.ID); err != nil {\r\n\t\t\t\tc.log.WithError(err).Errorf(\"failed to delete stale comment with ID '%d'\", comment.ID)\r\n\t\t\t} else {\r\n\t\t\t\tremoved = true\r\n\t\t\t}\r\n\t\t}\r\n\t\tif !removed {\r\n\t\t\tremaining = append(remaining, comment)\r\n\t\t}\r\n\t}\r\n\tc.comments = remaining\r\n}","code-length":442,"reference":"\/\/ PruneComments fetches issue comments if they have not yet been fetched for this webhook event\n\/\/ and then deletes any bot comments indicated by the func 'shouldPrune'.","result":"Prune comments from github events.","score":[0.0024,0.0195]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FormatResponse(to, message, reason string) string {\r\n\tformat := `@%s: %s\r\n<details>\r\n%s\r\n%s\r\n<\/details>`\r\n\treturn fmt.Sprintf(format, to, message, reason, AboutThisBotWithoutCommands)\r\n}","code-length":79,"reference":"\/\/ FormatResponse nicely formats a response to a generic reason.","result":"Format the response.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FormatSimpleResponse(to, message string) string {\r\n\tformat := `@%s: %s\r\n<details>\r\n%s\r\n<\/details>`\r\n\treturn fmt.Sprintf(format, to, message, AboutThisBotWithoutCommands)\r\n}","code-length":72,"reference":"\/\/ FormatSimpleResponse formats a response that does not warrant additional explanation in the\n\/\/ details section.","result":"Format the response.","score":[0.0054,0.068]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FormatICResponse(ic github.IssueComment, s string) string {\r\n\treturn FormatResponseRaw(ic.Body, ic.HTMLURL, ic.User.Login, s)\r\n}","code-length":53,"reference":"\/\/ FormatICResponse nicely formats a response to an issue comment.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FormatResponseRaw(body, bodyURL, login, reply string) string {\r\n\tformat := `In response to [this](%s):\r\n%s\r\n`\r\n\t\r\n\tvar quoted []string\r\n\tfor _, l := range strings.Split(body, \"\\n\") {\r\n\t\tquoted = append(quoted, \">\"+l)\r\n\t}\r\n\treturn FormatResponse(login, reply, fmt.Sprintf(format, bodyURL, strings.Join(quoted, \"\\n\")))\r\n}","code-length":129,"reference":"\/\/ FormatResponseRaw nicely formats a response for one does not have an issue comment","result":"Format the response.","score":[0,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *Options) Validate() error {\r\n\tif o.gcsPath.String() != \"\" {\r\n\t\to.Bucket = o.gcsPath.Bucket()\r\n\t\to.PathPrefix = o.gcsPath.Object()\r\n\t}\r\n\tif !o.DryRun {\r\n\t\tif o.Bucket == \"\" {\r\n\t\t\treturn errors.New(\"GCS upload was requested no GCS bucket was provided\")\r\n\t\t}\r\n\t\tif o.GcsCredentialsFile == \"\" {\r\n\t\t\treturn errors.New(\"GCS upload was requested but no GCS credentials file was provided\")\r\n\t\t}\r\n\t}\r\n\treturn o.GCSConfiguration.Validate()\r\n}","code-length":175,"reference":"\/\/ Validate ensures that the set of options are\n\/\/ self-consistent and valid.","result":"Validate the options.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Encode(options Options) (string, error) {\r\n\tencoded, err := json.Marshal(options)\r\n\treturn string(encoded), err\r\n}","code-length":46,"reference":"\/\/ Encode will encode the set of options in the format that\n\/\/ is expected for the configuration environment variable.","result":"Encode json.","score":[0.0001,0.0275]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterIssueHandler(name string, fn IssueHandler, help HelpProvider) {\r\n\tpluginHelp[name] = help\r\n\tissueHandlers[name] = fn\r\n}","code-length":49,"reference":"\/\/ RegisterIssueHandler registers a plugin's github.IssueEvent handler.","result":"Register issue handlers.","score":[0,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterIssueCommentHandler(name string, fn IssueCommentHandler, help HelpProvider) {\r\n\tpluginHelp[name] = help\r\n\tissueCommentHandlers[name] = fn\r\n}","code-length":52,"reference":"\/\/ RegisterIssueCommentHandler registers a plugin's github.IssueCommentEvent handler.","result":"Register a comment handler.","score":[0.1795,0.3814]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterPullRequestHandler(name string, fn PullRequestHandler, help HelpProvider) {\r\n\tpluginHelp[name] = help\r\n\tpullRequestHandlers[name] = fn\r\n}","code-length":50,"reference":"\/\/ RegisterPullRequestHandler registers a plugin's github.PullRequestEvent handler.","result":"Register plugins.","score":[0,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterStatusEventHandler(name string, fn StatusEventHandler, help HelpProvider) {\r\n\tpluginHelp[name] = help\r\n\tstatusEventHandlers[name] = fn\r\n}","code-length":50,"reference":"\/\/ RegisterStatusEventHandler registers a plugin's github.StatusEvent handler.","result":"Register plugin status event handlers.","score":[0,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterPushEventHandler(name string, fn PushEventHandler, help HelpProvider) {\r\n\tpluginHelp[name] = help\r\n\tpushEventHandlers[name] = fn\r\n}","code-length":50,"reference":"\/\/ RegisterPushEventHandler registers a plugin's github.PushEvent handler.","result":"Register push event handlers.","score":[0,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterReviewEventHandler(name string, fn ReviewEventHandler, help HelpProvider) {\r\n\tpluginHelp[name] = help\r\n\treviewEventHandlers[name] = fn\r\n}","code-length":50,"reference":"\/\/ RegisterReviewEventHandler registers a plugin's github.ReviewEvent handler.","result":"RegisterReviewEventHandler.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterReviewCommentEventHandler(name string, fn ReviewCommentEventHandler, help HelpProvider) {\r\n\tpluginHelp[name] = help\r\n\treviewCommentEventHandlers[name] = fn\r\n}","code-length":53,"reference":"\/\/ RegisterReviewCommentEventHandler registers a plugin's github.ReviewCommentEvent handler.","result":"Register events on review comments.","score":[0,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterGenericCommentHandler(name string, fn GenericCommentHandler, help HelpProvider) {\r\n\tpluginHelp[name] = help\r\n\tgenericCommentHandlers[name] = fn\r\n}","code-length":52,"reference":"\/\/ RegisterGenericCommentHandler registers a plugin's github.GenericCommentEvent handler.","result":"Register generic comment handlers.","score":[0,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewAgent(configAgent *config.Agent, pluginConfigAgent *ConfigAgent, clientAgent *ClientAgent, logger *logrus.Entry) Agent {\r\n\tprowConfig := configAgent.Config()\r\n\tpluginConfig := pluginConfigAgent.Config()\r\n\treturn Agent{\r\n\t\tGitHubClient:     clientAgent.GitHubClient,\r\n\t\tKubernetesClient: clientAgent.KubernetesClient,\r\n\t\tProwJobClient:    clientAgent.ProwJobClient,\r\n\t\tGitClient:        clientAgent.GitClient,\r\n\t\tSlackClient:      clientAgent.SlackClient,\r\n\t\tOwnersClient:     clientAgent.OwnersClient,\r\n\t\tConfig:           prowConfig,\r\n\t\tPluginConfig:     pluginConfig,\r\n\t\tLogger:           logger,\r\n\t}\r\n}","code-length":203,"reference":"\/\/ NewAgent bootstraps a new config.Agent struct from the passed dependencies.","result":"Create a new agent.","score":[0.0785,0.182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Agent) InitializeCommentPruner(org, repo string, pr int) {\r\n\ta.commentPruner = commentpruner.NewEventClient(\r\n\t\ta.GitHubClient, a.Logger.WithField(\"client\", \"commentpruner\"),\r\n\t\torg, repo, pr,\r\n\t)\r\n}","code-length":87,"reference":"\/\/ InitializeCommentPruner attaches a commentpruner.EventClient to the agent to handle\n\/\/ pruning comments.","result":"Initialize comment pruner.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *Agent) CommentPruner() (*commentpruner.EventClient, error) {\r\n\tif a.commentPruner == nil {\r\n\t\treturn nil, errors.New(\"comment pruner client never initialized\")\r\n\t}\r\n\treturn a.commentPruner, nil\r\n}","code-length":79,"reference":"\/\/ CommentPruner will return the commentpruner.EventClient attached to the agent or an error\n\/\/ if one is not attached.","result":"Start comment pruner.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) Load(path string) error {\r\n\tb, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tnp := &Configuration{}\r\n\tif err := yaml.Unmarshal(b, np); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := np.Validate(); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tpa.Set(np)\r\n\treturn nil\r\n}","code-length":132,"reference":"\/\/ Load attempts to load config from the path. It returns an error if either\n\/\/ the file can't be read or the configuration is invalid.","result":"Load the configuration file.","score":[0.002,0.1074]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) Config() *Configuration {\r\n\tpa.mut.Lock()\r\n\tdefer pa.mut.Unlock()\r\n\treturn pa.configuration\r\n}","code-length":50,"reference":"\/\/ Config returns the agent current Configuration.","result":"Generate the config file.","score":[0.1509,0.1493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) Set(pc *Configuration) {\r\n\tpa.mut.Lock()\r\n\tdefer pa.mut.Unlock()\r\n\tpa.configuration = pc\r\n}","code-length":53,"reference":"\/\/ Set attempts to set the plugins that are enabled on repos. Plugins are listed\n\/\/ as a map from repositories to the list of plugins that are enabled on them.\n\/\/ Specifying simply an org name will also work, and will enable the plugin on\n\/\/ all repos in the org.","result":"Set the configuration.","score":[0.0,0.0212]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) Start(path string) error {\r\n\tif err := pa.Load(path); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tticker := time.Tick(1 * time.Minute)\r\n\tgo func() {\r\n\t\tfor range ticker {\r\n\t\t\tif err := pa.Load(path); err != nil {\r\n\t\t\t\tlogrus.WithField(\"path\", path).WithError(err).Error(\"Error loading plugin config.\")\r\n\t\t\t}\r\n\t\t}\r\n\t}()\r\n\treturn nil\r\n}","code-length":146,"reference":"\/\/ Start starts polling path for plugin config. If the first attempt fails,\n\/\/ then start returns the error. Future errors will halt updates but not stop.","result":"Start the agent.","score":[0.0002,0.0407]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) GenericCommentHandlers(owner, repo string) map[string]GenericCommentHandler {\r\n\tpa.mut.Lock()\r\n\tdefer pa.mut.Unlock()\r\n\ths := map[string]GenericCommentHandler{}\r\n\tfor _, p := range pa.getPlugins(owner, repo) {\r\n\t\tif h, ok := genericCommentHandlers[p]; ok {\r\n\t\t\ths[p] = h\r\n\t\t}\r\n\t}\r\n\treturn hs\r\n}","code-length":128,"reference":"\/\/ GenericCommentHandlers returns a map of plugin names to handlers for the repo.","result":"Generate the code.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) IssueHandlers(owner, repo string) map[string]IssueHandler {\r\n\tpa.mut.Lock()\r\n\tdefer pa.mut.Unlock()\r\n\ths := map[string]IssueHandler{}\r\n\tfor _, p := range pa.getPlugins(owner, repo) {\r\n\t\tif h, ok := issueHandlers[p]; ok {\r\n\t\t\ths[p] = h\r\n\t\t}\r\n\t}\r\n\treturn hs\r\n}","code-length":124,"reference":"\/\/ IssueHandlers returns a map of plugin names to handlers for the repo.","result":"Generate the code.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) IssueCommentHandlers(owner, repo string) map[string]IssueCommentHandler {\r\n\tpa.mut.Lock()\r\n\tdefer pa.mut.Unlock()\r\n\ths := map[string]IssueCommentHandler{}\r\n\tfor _, p := range pa.getPlugins(owner, repo) {\r\n\t\tif h, ok := issueCommentHandlers[p]; ok {\r\n\t\t\ths[p] = h\r\n\t\t}\r\n\t}\r\n\treturn hs\r\n}","code-length":128,"reference":"\/\/ IssueCommentHandlers returns a map of plugin names to handlers for the repo.","result":"Register issue comment handlers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) PullRequestHandlers(owner, repo string) map[string]PullRequestHandler {\r\n\tpa.mut.Lock()\r\n\tdefer pa.mut.Unlock()\r\n\ths := map[string]PullRequestHandler{}\r\n\tfor _, p := range pa.getPlugins(owner, repo) {\r\n\t\tif h, ok := pullRequestHandlers[p]; ok {\r\n\t\t\ths[p] = h\r\n\t\t}\r\n\t}\r\n\treturn hs\r\n}","code-length":125,"reference":"\/\/ PullRequestHandlers returns a map of plugin names to handlers for the repo.","result":"Get the list of pull.","score":[0.0577,0.123]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) ReviewEventHandlers(owner, repo string) map[string]ReviewEventHandler {\r\n\tpa.mut.Lock()\r\n\tdefer pa.mut.Unlock()\r\n\ths := map[string]ReviewEventHandler{}\r\n\tfor _, p := range pa.getPlugins(owner, repo) {\r\n\t\tif h, ok := reviewEventHandlers[p]; ok {\r\n\t\t\ths[p] = h\r\n\t\t}\r\n\t}\r\n\treturn hs\r\n}","code-length":126,"reference":"\/\/ ReviewEventHandlers returns a map of plugin names to handlers for the repo.","result":"Get the map of review.","score":[0.0759,0.2095]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) ReviewCommentEventHandlers(owner, repo string) map[string]ReviewCommentEventHandler {\r\n\tpa.mut.Lock()\r\n\tdefer pa.mut.Unlock()\r\n\ths := map[string]ReviewCommentEventHandler{}\r\n\tfor _, p := range pa.getPlugins(owner, repo) {\r\n\t\tif h, ok := reviewCommentEventHandlers[p]; ok {\r\n\t\t\ths[p] = h\r\n\t\t}\r\n\t}\r\n\treturn hs\r\n}","code-length":130,"reference":"\/\/ ReviewCommentEventHandlers returns a map of plugin names to handlers for the repo.","result":"Register event handlers for plugins.","score":[0.0686,0.1537]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) StatusEventHandlers(owner, repo string) map[string]StatusEventHandler {\r\n\tpa.mut.Lock()\r\n\tdefer pa.mut.Unlock()\r\n\ths := map[string]StatusEventHandler{}\r\n\tfor _, p := range pa.getPlugins(owner, repo) {\r\n\t\tif h, ok := statusEventHandlers[p]; ok {\r\n\t\t\ths[p] = h\r\n\t\t}\r\n\t}\r\n\treturn hs\r\n}","code-length":126,"reference":"\/\/ StatusEventHandlers returns a map of plugin names to handlers for the repo.","result":"Get the status event handlers.","score":[0.0485,0.041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pa *ConfigAgent) PushEventHandlers(owner, repo string) map[string]PushEventHandler {\r\n\tpa.mut.Lock()\r\n\tdefer pa.mut.Unlock()\r\n\ths := map[string]PushEventHandler{}\r\n\tfor _, p := range pa.getPlugins(owner, repo) {\r\n\t\tif h, ok := pushEventHandlers[p]; ok {\r\n\t\t\ths[p] = h\r\n\t\t}\r\n\t}\r\n\treturn hs\r\n}","code-length":126,"reference":"\/\/ PushEventHandlers returns a map of plugin names to handlers for the repo.","result":"Get push event handlers.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EventsForPlugin(name string) []string {\r\n\tvar events []string\r\n\tif _, ok := issueHandlers[name]; ok {\r\n\t\tevents = append(events, \"issue\")\r\n\t}\r\n\tif _, ok := issueCommentHandlers[name]; ok {\r\n\t\tevents = append(events, \"issue_comment\")\r\n\t}\r\n\tif _, ok := pullRequestHandlers[name]; ok {\r\n\t\tevents = append(events, \"pull_request\")\r\n\t}\r\n\tif _, ok := pushEventHandlers[name]; ok {\r\n\t\tevents = append(events, \"push\")\r\n\t}\r\n\tif _, ok := reviewEventHandlers[name]; ok {\r\n\t\tevents = append(events, \"pull_request_review\")\r\n\t}\r\n\tif _, ok := reviewCommentEventHandlers[name]; ok {\r\n\t\tevents = append(events, \"pull_request_review_comment\")\r\n\t}\r\n\tif _, ok := statusEventHandlers[name]; ok {\r\n\t\tevents = append(events, \"status\")\r\n\t}\r\n\tif _, ok := genericCommentHandlers[name]; ok {\r\n\t\tevents = append(events, \"GenericCommentEvent (any event for user text)\")\r\n\t}\r\n\treturn events\r\n}","code-length":322,"reference":"\/\/ EventsForPlugin returns the registered events for the passed plugin.","result":"Generate the events for plugins.","score":[0.1383,0.269]}
{"code":"\/*is used to<extra_id_0>\r\nfunc insertLink(started *gcs.Started, viewURL string) (bool, error) {\r\n\tif started.Metadata == nil {\r\n\t\tstarted.Metadata = metadata.Metadata{}\r\n\t}\r\n\tmeta := started.Metadata\r\n\tvar changed bool\r\n\ttop, present := meta.String(resultstoreKey)\r\n\tif !present || top == nil || *top != viewURL {\r\n\t\tchanged = true\r\n\t\tmeta[resultstoreKey] = viewURL\r\n\t}\r\n\tlinks, present := meta.Meta(linksKey)\r\n\tif present && links == nil {\r\n\t\treturn false, fmt.Errorf(\"metadata.links is not a Metadata value: %v\", meta[linksKey])\r\n\t}\r\n\tif links == nil {\r\n\t\tlinks = &metadata.Metadata{}\r\n\t\tchanged = true\r\n\t}\r\n\tresultstoreMeta, present := links.Meta(resultstoreKey)\r\n\tif present && resultstoreMeta == nil {\r\n\t\treturn false, fmt.Errorf(\"metadata.links.resultstore is not a Metadata value: %v\", (*links)[resultstoreKey])\r\n\t}\r\n\tif resultstoreMeta == nil {\r\n\t\tresultstoreMeta = &metadata.Metadata{}\r\n\t\tchanged = true\r\n\t}\r\n\tval, present := resultstoreMeta.String(urlKey)\r\n\tif present && val == nil {\r\n\t\treturn false, fmt.Errorf(\"metadata.links.resultstore.url is not a string value: %v\", (*resultstoreMeta)[urlKey])\r\n\t}\r\n\tif !changed && val != nil && *val == viewURL {\r\n\t\treturn false, nil\r\n\t}\r\n\t(*resultstoreMeta)[urlKey] = viewURL\r\n\t(*links)[resultstoreKey] = *resultstoreMeta\r\n\tmeta[linksKey] = *links\r\n\treturn true, nil\r\n}","code-length":459,"reference":"\/\/ insertLink attempts to set metadata.links.resultstore.url to viewURL.\n\/\/\n\/\/ returns true if started metadata was updated.","result":"Insert a link to a started object.","score":[0.046,0.0625]}
{"code":"\/*is used to<extra_id_0>\r\nfunc HelpProvider(enabledRepos []string) (*pluginhelp.PluginHelp, error) {\r\n\tpluginHelp := &pluginhelp.PluginHelp{\r\n\t\tDescription: `The cherrypick plugin is used for cherrypicking PRs across branches. For every successful cherrypick invocation a new PR is opened against the target branch and assigned to the requester. If the parent PR contains a release note, it is copied to the cherrypick PR.`,\r\n\t}\r\n\tpluginHelp.AddCommand(pluginhelp.Command{\r\n\t\tUsage:       \"\/cherrypick [branch]\",\r\n\t\tDescription: \"Cherrypick a PR to a different branch. This command works both in merged PRs (the cherrypick PR is opened immediately) and open PRs (the cherrypick PR opens as soon as the original PR merges).\",\r\n\t\tFeatured:    true,\r\n\t\t\r\n\t\tWhoCanUse: \"Members of the trusted organization for the repo.\",\r\n\t\tExamples:  []string{\"\/cherrypick release-3.9\"},\r\n\t})\r\n\treturn pluginHelp, nil\r\n}","code-length":274,"reference":"\/\/ HelpProvider construct the pluginhelp.PluginHelp for this plugin.","result":"Provide help for cherrypicking plugins.","score":[0.1319,0.0649]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Server) getPatch(org, repo, targetBranch string, num int) (string, error) {\r\n\tpatch, err := s.ghc.GetPullRequestPatch(org, repo, num)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tlocalPath := fmt.Sprintf(\"\/tmp\/%s_%s_%d_%s.patch\", org, repo, num, normalize(targetBranch))\r\n\tout, err := os.Create(localPath)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tdefer out.Close()\r\n\tif _, err := io.Copy(out, bytes.NewBuffer(patch)); err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn localPath, nil\r\n}","code-length":198,"reference":"\/\/ getPatch gets the patch for the provided PR and creates a local\n\/\/ copy of it. It returns its location in the filesystem and any\n\/\/ encountered error.","result":"Generate the generated code.","score":[0.0006,0.0189]}
{"code":"\/*is used to<extra_id_0>\r\nfunc releaseNoteFromParentPR(body string) string {\r\n\tpotentialMatch := releaseNoteRe.FindStringSubmatch(body)\r\n\tif potentialMatch == nil {\r\n\t\treturn \"\"\r\n\t}\r\n\treturn fmt.Sprintf(\"```release-note\\n%s\\n```\", strings.TrimSpace(potentialMatch[1]))\r\n}","code-length":92,"reference":"\/\/ releaseNoteNoteFromParentPR gets the release note from the\n\/\/ parent PR and formats it as per the PR template so that\n\/\/ it can be copied to the cherry-pick PR.","result":"Extract release notes from parent PR.","score":[0.005,0.1616]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ValidatePayload(payload []byte, sig string, key []byte) bool {\r\n\tif !strings.HasPrefix(sig, \"sha1=\") {\r\n\t\treturn false\r\n\t}\r\n\tsig = sig[5:]\r\n\tsb, err := hex.DecodeString(sig)\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\tmac := hmac.New(sha1.New, key)\r\n\tmac.Write(payload)\r\n\texpected := mac.Sum(nil)\r\n\treturn hmac.Equal(sb, expected)\r\n}","code-length":146,"reference":"\/\/ ValidatePayload ensures that the request payload signature matches the key.","result":"Validate payload.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PayloadSignature(payload []byte, key []byte) string {\r\n\tmac := hmac.New(sha1.New, key)\r\n\tmac.Write(payload)\r\n\tsum := mac.Sum(nil)\r\n\treturn \"sha1=\" + hex.EncodeToString(sum)\r\n}","code-length":78,"reference":"\/\/ PayloadSignature returns the signature that matches the payload.","result":"Generate the payload signature.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc updateString(have, want *string) bool {\r\n\tswitch {\r\n\tcase have == nil:\r\n\t\tpanic(\"have must be non-nil\")\r\n\tcase want == nil:\r\n\t\treturn false\r\n\tcase *have == *want:\r\n\t\treturn false\r\n\t}\r\n\t*have = *want\r\n\treturn true\r\n}","code-length":98,"reference":"\/\/ updateString will return true and set have to want iff they are set and different.","result":"Update the string field in the string field.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc updateBool(have, want *bool) bool {\r\n\tswitch {\r\n\tcase have == nil:\r\n\t\tpanic(\"have must not be nil\")\r\n\tcase want == nil:\r\n\t\treturn false\r\n\tcase *have == *want:\r\n\t\treturn false\r\n\t}\r\n\t*have = *want\r\n\treturn true\r\n}","code-length":97,"reference":"\/\/ updateBool will return true and set have to want iff they are set and different.","result":"Update a bool.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc configureOrgMeta(client orgMetadataClient, orgName string, want org.Metadata) error {\r\n\tcur, err := client.GetOrg(orgName)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to get %s metadata: %v\", orgName, err)\r\n\t}\r\n\tchange := false\r\n\tchange = updateString(&cur.BillingEmail, want.BillingEmail) || change\r\n\tchange = updateString(&cur.Company, want.Company) || change\r\n\tchange = updateString(&cur.Email, want.Email) || change\r\n\tchange = updateString(&cur.Name, want.Name) || change\r\n\tchange = updateString(&cur.Description, want.Description) || change\r\n\tchange = updateString(&cur.Location, want.Location) || change\r\n\tif want.DefaultRepositoryPermission != nil {\r\n\t\tw := string(*want.DefaultRepositoryPermission)\r\n\t\tchange = updateString(&cur.DefaultRepositoryPermission, &w)\r\n\t}\r\n\tchange = updateBool(&cur.HasOrganizationProjects, want.HasOrganizationProjects) || change\r\n\tchange = updateBool(&cur.HasRepositoryProjects, want.HasRepositoryProjects) || change\r\n\tchange = updateBool(&cur.MembersCanCreateRepositories, want.MembersCanCreateRepositories) || change\r\n\tif change {\r\n\t\tif _, err := client.EditOrg(orgName, *cur); err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to edit %s metadata: %v\", orgName, err)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":394,"reference":"\/\/ configureOrgMeta will update github to have the non-nil wanted metadata values.","result":"Configure org metadata.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc configureTeamRepos(client teamRepoClient, githubTeams map[string]github.Team, name, orgName string, team org.Team) error {\r\n\tgt, ok := githubTeams[name]\r\n\tif !ok {\r\n\t\treturn fmt.Errorf(\"%s not found in id list\", name)\r\n\t}\r\n\twant := team.Repos\r\n\thave := map[string]github.RepoPermissionLevel{}\r\n\trepos, err := client.ListTeamRepos(gt.ID)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to list team %d(%s) repos: %v\", gt.ID, name, err)\r\n\t}\r\n\tfor _, repo := range repos {\r\n\t\thave[repo.Name] = github.LevelFromPermissions(repo.Permissions)\r\n\t}\r\n\tactions := map[string]github.RepoPermissionLevel{}\r\n\tfor wantRepo, wantPermission := range want {\r\n\t\tif havePermission, haveRepo := have[wantRepo]; haveRepo && havePermission == wantPermission {\r\n\t\t\t\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tactions[wantRepo] = wantPermission\r\n\t}\r\n\tfor haveRepo := range have {\r\n\t\tif _, wantRepo := want[haveRepo]; !wantRepo {\r\n\t\t\t\r\n\t\t\tactions[haveRepo] = github.None\r\n\t\t}\r\n\t}\r\n\tvar updateErrors []error\r\n\tfor repo, permission := range actions {\r\n\t\tvar err error\r\n\t\tif permission == github.None {\r\n\t\t\terr = client.RemoveTeamRepo(gt.ID, orgName, repo)\r\n\t\t} else {\r\n\t\t\terr = client.UpdateTeamRepo(gt.ID, orgName, repo, permission)\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\tupdateErrors = append(updateErrors, fmt.Errorf(\"failed to update team %d(%s) permissions on repo %s to %s: %v\", gt.ID, name, repo, permission, err))\r\n\t\t}\r\n\t}\r\n\treturn errorutil.NewAggregate(updateErrors...)\r\n}","code-length":519,"reference":"\/\/ configureTeamRepos updates the list of repos that the team has permissions for when necessary","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) ShouldReport(pj *prowapi.ProwJob) bool {\r\n\tpubSubMap := findLabels(pj, PubSubProjectLabel, PubSubTopicLabel)\r\n\treturn pubSubMap[PubSubProjectLabel] != \"\" && pubSubMap[PubSubTopicLabel] != \"\"\r\n}","code-length":80,"reference":"\/\/ ShouldReport tells if a prowjob should be reported by this reporter","result":"Report the status of the job.","score":[0,0.0439]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Options) Run(spec *downwardapi.JobSpec, extra map[string]gcs.UploadFunc) error {\r\n\tuploadTargets := o.assembleTargets(spec, extra)\r\n\tif !o.DryRun {\r\n\t\tctx := context.Background()\r\n\t\tgcsClient, err := storage.NewClient(ctx, option.WithCredentialsFile(o.GcsCredentialsFile))\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"could not connect to GCS: %v\", err)\r\n\t\t}\r\n\t\tif err := gcs.Upload(gcsClient.Bucket(o.Bucket), uploadTargets); err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to upload to GCS: %v\", err)\r\n\t\t}\r\n\t} else {\r\n\t\tfor destination := range uploadTargets {\r\n\t\t\tlogrus.WithField(\"dest\", destination).Info(\"Would upload\")\r\n\t\t}\r\n\t}\r\n\tlogrus.Info(\"Finished upload to GCS\")\r\n\treturn nil\r\n}","code-length":255,"reference":"\/\/ Run will upload files to GCS as prescribed by\n\/\/ the options. Any extra files can be passed as\n\/\/ a parameter and will have the prefix prepended\n\/\/ to their destination in GCS, so the caller can\n\/\/ operate relative to the base of the GCS dir.","result":"Generate the code.","score":[0.0,0.0113]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DefaultFieldsFormatter) Format(entry *logrus.Entry) ([]byte, error) {\r\n\tdata := make(logrus.Fields, len(entry.Data)+len(d.DefaultFields))\r\n\tfor k, v := range d.DefaultFields {\r\n\t\tdata[k] = v\r\n\t}\r\n\tfor k, v := range entry.Data {\r\n\t\tdata[k] = v\r\n\t}\r\n\treturn d.WrappedFormatter.Format(&logrus.Entry{\r\n\t\tLogger:  entry.Logger,\r\n\t\tData:    data,\r\n\t\tTime:    entry.Time,\r\n\t\tLevel:   entry.Level,\r\n\t\tMessage: entry.Message,\r\n\t})\r\n}","code-length":189,"reference":"\/\/ Format implements logrus.Formatter's Format. We allocate a new Fields\n\/\/ map in order to not modify the caller's Entry, as that is not a thread\n\/\/ safe operation.","result":"Format the log entry .","score":[0.0024,0.0376]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (issue *Issue) FindLabels(regex *regexp.Regexp) []Label {\r\n\tlabels := []Label{}\r\n\tfor _, label := range issue.Labels {\r\n\t\tif regex.MatchString(label.Name) {\r\n\t\t\tlabels = append(labels, label)\r\n\t\t}\r\n\t}\r\n\treturn labels\r\n}","code-length":92,"reference":"\/\/ FindLabels returns the list of labels matching the regex","result":"Find labels in the issue.","score":[0.1051,0.1053]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *Options) AddFlags(flags *flag.FlagSet) {\r\n\tflags.StringVar(&o.Log, \"clone-log\", \"\", \"Path to the clone records log\")\r\n\to.Options.AddFlags(flags)\r\n}","code-length":68,"reference":"\/\/ AddFlags binds flags to options.","result":"Add flags to the options.","score":[0.3079,0.4331]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewAgent(config *config.GitHubOAuthConfig, logger *logrus.Entry) *Agent {\r\n\treturn &Agent{\r\n\t\tgc:     config,\r\n\t\tlogger: logger,\r\n\t}\r\n}","code-length":62,"reference":"\/\/ NewAgent returns a new GitHub OAuth Agent.","result":"Create a new agent.","score":[0.1662,0.3363]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ga *Agent) HandleLogin(client OAuthClient) http.HandlerFunc {\r\n\treturn func(w http.ResponseWriter, r *http.Request) {\r\n\t\tstateToken := xsrftoken.Generate(ga.gc.ClientSecret, \"\", \"\")\r\n\t\tstate := hex.EncodeToString([]byte(stateToken))\r\n\t\toauthSession, err := ga.gc.CookieStore.New(r, oauthSessionCookie)\r\n\t\toauthSession.Options.Secure = true\r\n\t\toauthSession.Options.HttpOnly = true\r\n\t\tif err != nil {\r\n\t\t\tga.serverError(w, \"Creating new OAuth session\", err)\r\n\t\t\treturn\r\n\t\t}\r\n\t\toauthSession.Options.MaxAge = 10 * 60\r\n\t\toauthSession.Values[stateKey] = state\r\n\t\tif err := oauthSession.Save(r, w); err != nil {\r\n\t\t\tga.serverError(w, \"Save oauth session\", err)\r\n\t\t\treturn\r\n\t\t}\r\n\t\tredirectURL := client.AuthCodeURL(state, oauth2.ApprovalForce, oauth2.AccessTypeOnline)\r\n\t\thttp.Redirect(w, r, redirectURL, http.StatusFound)\r\n\t}\r\n}","code-length":306,"reference":"\/\/ HandleLogin handles GitHub login request from front-end. It starts a new git oauth session and\n\/\/ redirect user to GitHub OAuth end-point for authentication.","result":"Log in to the Google Analytics API.","score":[0.0123,0.0216]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ga *Agent) HandleLogout(client OAuthClient) http.HandlerFunc {\r\n\treturn func(w http.ResponseWriter, r *http.Request) {\r\n\t\taccessTokenSession, err := ga.gc.CookieStore.Get(r, tokenSession)\r\n\t\tif err != nil {\r\n\t\t\tga.serverError(w, \"get cookie\", err)\r\n\t\t\treturn\r\n\t\t}\r\n\t\t\r\n\t\taccessTokenSession.Options.MaxAge = -1\r\n\t\tif err := accessTokenSession.Save(r, w); err != nil {\r\n\t\t\tga.serverError(w, \"Save invalidated session on log out\", err)\r\n\t\t\treturn\r\n\t\t}\r\n\t\tloginCookie, err := r.Cookie(loginSession)\r\n\t\tif err == nil {\r\n\t\t\tloginCookie.MaxAge = -1\r\n\t\t\tloginCookie.Expires = time.Now().Add(-time.Hour * 24)\r\n\t\t\thttp.SetCookie(w, loginCookie)\r\n\t\t}\r\n\t\thttp.Redirect(w, r, ga.gc.FinalRedirectURL, http.StatusFound)\r\n\t}\r\n}","code-length":284,"reference":"\/\/ HandleLogout handles GitHub logout request from front-end. It invalidates cookie sessions and\n\/\/ redirect back to the front page.","result":"Handle logout requests.","score":[0.0014,0.0546]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ga *Agent) serverError(w http.ResponseWriter, action string, err error) {\r\n\tga.logger.WithError(err).Errorf(\"Error %s.\", action)\r\n\tmsg := fmt.Sprintf(\"500 Internal server error %s: %v\", action, err)\r\n\thttp.Error(w, msg, http.StatusInternalServerError)\r\n}","code-length":94,"reference":"\/\/ Handles server errors.","result":"Handle errors.","score":[0.1839,0.2632]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ResourcesConfigObject) FromItem(i common.Item) {\r\n\tc, err := common.ItemToResourcesConfig(i)\r\n\tif err == nil {\r\n\t\tin.fromConfig(c)\r\n\t}\r\n}","code-length":68,"reference":"\/\/ FromItem implements the Object interface","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ResourcesConfigCollection) GetItems() []Object {\r\n\tvar items []Object\r\n\tfor _, i := range in.Items {\r\n\t\titems = append(items, i)\r\n\t}\r\n\treturn items\r\n}","code-length":67,"reference":"\/\/ GetItems implements the Collection interface","result":"Generate code that generates the code that is generated by the go.","score":[0.0891,0.0758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ResourcesConfigCollection) SetItems(objects []Object) {\r\n\tvar items []*ResourcesConfigObject\r\n\tfor _, b := range objects {\r\n\t\titems = append(items, b.(*ResourcesConfigObject))\r\n\t}\r\n\tin.Items = items\r\n}","code-length":78,"reference":"\/\/ SetItems implements the Collection interface","result":"Set items of an ResourcesConfigCollection.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l *RepoPermissionLevel) UnmarshalText(text []byte) error {\r\n\tv := RepoPermissionLevel(text)\r\n\tif _, ok := repoPermissionLevels[v]; !ok {\r\n\t\treturn fmt.Errorf(\"bad repo permission: %s not in %v\", v, repoPermissionLevels)\r\n\t}\r\n\t*l = v\r\n\treturn nil\r\n}","code-length":99,"reference":"\/\/ UnmarshalText validates the text is a valid string","result":"Unmarshal the repo permission level.","score":[0.108,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i Issue) IsAssignee(login string) bool {\r\n\tfor _, assignee := range i.Assignees {\r\n\t\tif NormLogin(login) == NormLogin(assignee.Login) {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":81,"reference":"\/\/ IsAssignee checks if a user is assigned to the issue.","result":"Check if the user is a member of a group.","score":[0.1747,0.4689]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i Issue) IsAuthor(login string) bool {\r\n\treturn NormLogin(i.User.Login) == NormLogin(login)\r\n}","code-length":44,"reference":"\/\/ IsAuthor checks if a user is the author of the issue.","result":"Check if the author is in the issue.","score":[0.1735,0.5471]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i Issue) HasLabel(labelToFind string) bool {\r\n\tfor _, label := range i.Labels {\r\n\t\tif strings.ToLower(label.Name) == strings.ToLower(labelToFind) {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":85,"reference":"\/\/ HasLabel checks if an issue has a given label.","result":"Check if a label exists in the issue.","score":[0.1286,0.2608]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pe PushEvent) Branch() string {\r\n\tref := strings.TrimPrefix(pe.Ref, \"refs\/heads\/\")\r\n\tref = strings.TrimPrefix(ref, \"refs\/tags\/\")\r\n\treturn ref\r\n}","code-length":65,"reference":"\/\/ Branch returns the name of the branch to which the user pushed.","result":"Get the branch of the event.","score":[0.1119,0.2566]}
{"code":"\/*is used to<extra_id_0>\r\nfunc truncate(in string) string {\r\n\tconst (\r\n\t\thalf = (maxLen - len(elide)) \/ 2\r\n\t)\r\n\tif len(in) <= maxLen {\r\n\t\treturn in\r\n\t}\r\n\treturn in[:half] + elide + in[len(in)-half:]\r\n}","code-length":87,"reference":"\/\/ truncate converts \"really long messages\" into \"really ... messages\".","result":"Truncate strings.","score":[0,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc reportStatus(ghc GitHubClient, pj prowapi.ProwJob) error {\r\n\trefs := pj.Spec.Refs\r\n\tif pj.Spec.Report {\r\n\t\tcontextState, err := prowjobStateToGitHubStatus(pj.Status.State)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tsha := refs.BaseSHA\r\n\t\tif len(refs.Pulls) > 0 {\r\n\t\t\tsha = refs.Pulls[0].SHA\r\n\t\t}\r\n\t\tif err := ghc.CreateStatus(refs.Org, refs.Repo, sha, github.Status{\r\n\t\t\tState:       contextState,\r\n\t\t\tDescription: truncate(pj.Status.Description),\r\n\t\t\tContext:     pj.Spec.Context,\r\n\t\t\tTargetURL:   pj.Status.URL,\r\n\t\t}); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":253,"reference":"\/\/ reportStatus should be called on any prowjob status changes","result":"Report status of a prowjob.","score":[0.0884,0.0526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc parseIssueComments(pj prowapi.ProwJob, botName string, ics []github.IssueComment) ([]int, []string, int) {\r\n\tvar delete []int\r\n\tvar previousComments []int\r\n\tvar latestComment int\r\n\tvar entries []string\r\n\t\r\n\tfor _, ic := range ics {\r\n\t\tif ic.User.Login != botName {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tif strings.HasPrefix(ic.Body, pj.Spec.Context) {\r\n\t\t\tdelete = append(delete, ic.ID)\r\n\t\t}\r\n\t\tif !strings.Contains(ic.Body, commentTag) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif latestComment != 0 {\r\n\t\t\tpreviousComments = append(previousComments, latestComment)\r\n\t\t}\r\n\t\tlatestComment = ic.ID\r\n\t\tvar tracking bool\r\n\t\tfor _, line := range strings.Split(ic.Body, \"\\n\") {\r\n\t\t\tline = strings.TrimSpace(line)\r\n\t\t\tif strings.HasPrefix(line, \"---\") {\r\n\t\t\t\ttracking = true\r\n\t\t\t} else if len(line) == 0 {\r\n\t\t\t\ttracking = false\r\n\t\t\t} else if tracking {\r\n\t\t\t\tentries = append(entries, line)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tvar newEntries []string\r\n\t\r\n\tfor i := range entries {\r\n\t\tkeep := true\r\n\t\tf1 := strings.Split(entries[i], \" | \")\r\n\t\tfor j := range entries {\r\n\t\t\tif i == j {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tf2 := strings.Split(entries[j], \" | \")\r\n\t\t\t\r\n\t\t\tif j > i && f2[0] == f1[0] {\r\n\t\t\t\tkeep = false\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tif pj.Spec.Context == f1[0] {\r\n\t\t\tkeep = false\r\n\t\t}\r\n\t\tif keep {\r\n\t\t\tnewEntries = append(newEntries, entries[i])\r\n\t\t}\r\n\t}\r\n\tvar createNewComment bool\r\n\tif string(pj.Status.State) == github.StatusFailure {\r\n\t\tnewEntries = append(newEntries, createEntry(pj))\r\n\t\tcreateNewComment = true\r\n\t}\r\n\tdelete = append(delete, previousComments...)\r\n\tif (createNewComment || len(newEntries) == 0) && latestComment != 0 {\r\n\t\tdelete = append(delete, latestComment)\r\n\t\tlatestComment = 0\r\n\t}\r\n\treturn delete, newEntries, latestComment\r\n}","code-length":679,"reference":"\/\/ parseIssueComments returns a list of comments to delete, a list of table\n\/\/ entries, and the ID of the comment to update. If there are no table entries\n\/\/ then don't make a new comment. Otherwise, if the comment to update is 0,\n\/\/ create a new comment.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc createComment(reportTemplate *template.Template, pj prowapi.ProwJob, entries []string) (string, error) {\r\n\tplural := \"\"\r\n\tif len(entries) > 1 {\r\n\t\tplural = \"s\"\r\n\t}\r\n\tvar b bytes.Buffer\r\n\tif reportTemplate != nil {\r\n\t\tif err := reportTemplate.Execute(&b, &pj); err != nil {\r\n\t\t\treturn \"\", err\r\n\t\t}\r\n\t}\r\n\tlines := []string{\r\n\t\tfmt.Sprintf(\"@%s: The following test%s **failed**, say `\/retest` to rerun them all:\", pj.Spec.Refs.Pulls[0].Author, plural),\r\n\t\t\"\",\r\n\t\t\"Test name | Commit | Details | Rerun command\",\r\n\t\t\"--- | --- | --- | ---\",\r\n\t}\r\n\tlines = append(lines, entries...)\r\n\tif reportTemplate != nil {\r\n\t\tlines = append(lines, \"\", b.String())\r\n\t}\r\n\tlines = append(lines, []string{\r\n\t\t\"\",\r\n\t\t\"<details>\",\r\n\t\t\"\",\r\n\t\tplugins.AboutThisBot,\r\n\t\t\"<\/details>\",\r\n\t\tcommentTag,\r\n\t}...)\r\n\treturn strings.Join(lines, \"\\n\"), nil\r\n}","code-length":345,"reference":"\/\/ createComment take a ProwJob and a list of entries generated with\n\/\/ createEntry and returns a nicely formatted comment. It may fail if template\n\/\/ execution fails.","result":"Create a comment for the prow job.","score":[0.008,0.0193]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lens Lens) Config() lenses.LensConfig {\r\n\treturn lenses.LensConfig{\r\n\t\tName:     name,\r\n\t\tTitle:    title,\r\n\t\tPriority: priority,\r\n\t}\r\n}","code-length":68,"reference":"\/\/ Config returns the lens's configuration.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lens Lens) Callback(artifacts []lenses.Artifact, resourceDir string, data string) string {\r\n\treturn \"\"\r\n}","code-length":41,"reference":"\/\/ Callback does nothing.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FormatRecord(record Record) string {\r\n\toutput := bytes.Buffer{}\r\n\tif record.Failed {\r\n\t\tfmt.Fprintln(&output, \"# FAILED!\")\r\n\t}\r\n\tfmt.Fprintf(&output, \"# Cloning %s\/%s at %s\", record.Refs.Org, record.Refs.Repo, record.Refs.BaseRef)\r\n\tif record.Refs.BaseSHA != \"\" {\r\n\t\tfmt.Fprintf(&output, \"(%s)\", record.Refs.BaseSHA)\r\n\t}\r\n\toutput.WriteString(\"\\n\")\r\n\tif len(record.Refs.Pulls) > 0 {\r\n\t\toutput.WriteString(\"# Checking out pulls:\\n\")\r\n\t\tfor _, pull := range record.Refs.Pulls {\r\n\t\t\tfmt.Fprintf(&output, \"#\\t%d\", pull.Number)\r\n\t\t\tif pull.SHA != \"\" {\r\n\t\t\t\tfmt.Fprintf(&output, \"(%s)\", pull.SHA)\r\n\t\t\t}\r\n\t\t\tfmt.Fprint(&output, \"\\n\")\r\n\t\t}\r\n\t}\r\n\tfor _, command := range record.Commands {\r\n\t\tfmt.Fprintf(&output, \"$ %s\\n\", command.Command)\r\n\t\tfmt.Fprint(&output, command.Output)\r\n\t\tif command.Error != \"\" {\r\n\t\t\tfmt.Fprintf(&output, \"# Error: %s\\n\", command.Error)\r\n\t\t}\r\n\t}\r\n\treturn output.String()\r\n}","code-length":386,"reference":"\/\/ FormatRecord describes the record in a human-readable\n\/\/ manner for inclusion into build logs","result":"Format the record.","score":[0.0075,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Namespace(ns string) *Client {\r\n\tnc := *c\r\n\tnc.namespace = ns\r\n\treturn &nc\r\n}","code-length":47,"reference":"\/\/ Namespace returns a copy of the client pointing at the specified namespace.","result":"Set the namespace.","score":[0.0173,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFakeClient(deckURL string) *Client {\r\n\treturn &Client{\r\n\t\tnamespace: \"default\",\r\n\t\tdeckURL:   deckURL,\r\n\t\tclient:    &http.Client{},\r\n\t\tfake:      true,\r\n\t}\r\n}","code-length":79,"reference":"\/\/ NewFakeClient creates a client that doesn't do anything. If you provide a\n\/\/ deck URL then the client will hit that for the supported calls.","result":"Create a fake client.","score":[0.0013,0.042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClientInCluster(namespace string) (*Client, error) {\r\n\ttokenFile := \"\/var\/run\/secrets\/kubernetes.io\/serviceaccount\/token\"\r\n\ttoken, err := ioutil.ReadFile(tokenFile)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\trootCAFile := \"\/var\/run\/secrets\/kubernetes.io\/serviceaccount\/ca.crt\"\r\n\tcertData, err := ioutil.ReadFile(rootCAFile)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tcp := x509.NewCertPool()\r\n\tcp.AppendCertsFromPEM(certData)\r\n\ttr := &http.Transport{\r\n\t\tTLSClientConfig: &tls.Config{\r\n\t\t\tMinVersion: tls.VersionTLS12,\r\n\t\t\tRootCAs:    cp,\r\n\t\t},\r\n\t}\r\n\treturn &Client{\r\n\t\tlogger:    logrus.WithField(\"client\", \"kube\"),\r\n\t\tbaseURL:   inClusterBaseURL,\r\n\t\tclient:    &http.Client{Transport: tr, Timeout: requestTimeout},\r\n\t\ttoken:     string(token),\r\n\t\tnamespace: namespace,\r\n\t}, nil\r\n}","code-length":313,"reference":"\/\/ NewClientInCluster creates a Client that works from within a pod.","result":"Create a client in cluster.","score":[0.0724,0.1442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClientFromFile(clusterPath, namespace string) (*Client, error) {\r\n\tdata, err := ioutil.ReadFile(clusterPath)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar c Cluster\r\n\tif err := yaml.Unmarshal(data, &c); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn NewClient(&c, namespace)\r\n}","code-length":112,"reference":"\/\/ NewClientFromFile reads a Cluster object at clusterPath and returns an\n\/\/ authenticated client using the keys within.","result":"Create a client from a file.","score":[0.0311,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(c *Cluster, namespace string) (*Client, error) {\r\n\t\r\n\tientKey\r\n\tca := c.ClusterCACertificate\r\n\tcert, err := tls.X509KeyPair(cc, ck)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tcp := x509.NewCertPool()\r\n\tcp.AppendCertsFromPEM(ca)\r\n\ttr := &http.Transport{\r\n\t\tTLSClientConfig: &tls.Config{\r\n\t\t\tMinVersion:   tls.VersionTLS12,\r\n\t\t\tCertificates: []tls.Certificate{cert},\r\n\t\t\tRootCAs:      cp,\r\n\t\t},\r\n\t}\r\n\treturn &Client{\r\n\t\tlogger:    logrus.WithField(\"client\", \"kube\"),\r\n\t\tbaseURL:   c.Endpoint,\r\n\t\tclient:    &http.Client{Transport: tr, Timeout: requestTimeout},\r\n\t\tnamespace: namespace,\r\n\t}, nil\r\n}","code-length":248,"reference":"\/\/ NewClient returns an authenticated Client using the keys in the Cluster.","result":"Create a client for the cluster.","score":[0.071,0.2242]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) ReplaceConfigMap(name string, config ConfigMap) (ConfigMap, error) {\r\n\tc.log(\"ReplaceConfigMap\", name)\r\n\tnamespace := c.namespace\r\n\tif config.Namespace != \"\" {\r\n\t\tnamespace = config.Namespace\r\n\t}\r\n\tvar retConfigMap ConfigMap\r\n\terr := c.request(&request{\r\n\t\tmethod:      http.MethodPut,\r\n\t\tpath:        fmt.Sprintf(\"\/api\/v1\/namespaces\/%s\/configmaps\/%s\", namespace, name),\r\n\t\trequestBody: &config,\r\n\t}, &retConfigMap)\r\n\treturn retConfigMap, err\r\n}","code-length":164,"reference":"\/\/ ReplaceConfigMap puts the configmap into name.\n\/\/\n\/\/ Analogous to kubectl replace configmap\n\/\/\n\/\/ If config.Namespace is empty, the client's specified namespace is used.\n\/\/ Returns the content returned by the apiserver","result":"Replace the configmap in the cluster.","score":[0.0028,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetDiskUsage(path string) (percentBlocksFree float64, bytesFree, bytesUsed uint64, err error) {\r\n\tvar stat syscall.Statfs_t\r\n\terr = syscall.Statfs(path, &stat)\r\n\tif err != nil {\r\n\t\treturn 0, 0, 0, err\r\n\t}\r\n\tpercentBlocksFree = float64(stat.Bfree) \/ float64(stat.Blocks) * 100\r\n\tbytesFree = stat.Bfree * uint64(stat.Bsize)\r\n\tbytesUsed = (stat.Blocks - stat.Bfree) * uint64(stat.Bsize)\r\n\treturn percentBlocksFree, bytesFree, bytesUsed, nil\r\n}","code-length":173,"reference":"\/\/ GetDiskUsage wraps syscall.Statfs for usage in GCing the disk","result":"Get the disk usage.","score":[0.1008,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetATime(path string, defaultTime time.Time) time.Time {\r\n\tat, err := atime.Stat(path)\r\n\tif err != nil {\r\n\t\tlog.WithError(err).Errorf(\"Could not get atime for %s\", path)\r\n\t\treturn defaultTime\r\n\t}\r\n\treturn at\r\n}","code-length":91,"reference":"\/\/ GetATime the atime for a file, logging errors instead of failing\n\/\/ and returning defaultTime instead","result":"Get the atime of a file.","score":[0.0519,0.1985]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterLens(lens Lens) error {\r\n\tconfig := lens.Config()\r\n\t_, ok := lensReg[config.Name]\r\n\tif ok {\r\n\t\treturn fmt.Errorf(\"viewer already registered with name %s\", config.Name)\r\n\t}\r\n\tif config.Title == \"\" {\r\n\t\treturn errors.New(\"empty title field in view metadata\")\r\n\t}\r\n\tif config.Priority < 0 {\r\n\t\treturn errors.New(\"priority must be >=0\")\r\n\t}\r\n\tlensReg[config.Name] = lens\r\n\tlogrus.Infof(\"Spyglass registered viewer %s with title %s.\", config.Name, config.Title)\r\n\treturn nil\r\n}","code-length":184,"reference":"\/\/ RegisterLens registers new viewers","result":"Register viewer with Spyglass.","score":[0,0.2041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetLens(name string) (Lens, error) {\r\n\tlens, ok := lensReg[name]\r\n\tif !ok {\r\n\t\treturn nil, ErrInvalidLensName\r\n\t}\r\n\treturn lens, nil\r\n}","code-length":68,"reference":"\/\/ GetLens returns a Lens by name, if it exists; otherwise it returns an error.","result":"Get the Lens object from the registry.","score":[0.0515,0.0352]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LastNLines(a Artifact, n int64) ([]string, error) {\r\n\t\r\n\treturn LastNLinesChunked(a, n, 300*n+1)\r\n}","code-length":54,"reference":"\/\/ LastNLines reads the last n lines from an artifact.","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(tokenGenerator func() []byte) *Client {\r\n\treturn &Client{\r\n\t\tlogger:         logrus.WithField(\"client\", \"slack\"),\r\n\t\ttokenGenerator: tokenGenerator,\r\n\t}\r\n}","code-length":65,"reference":"\/\/ NewClient creates a slack client with an API token.","result":"Create a client.","score":[0.0396,0.2016]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (sl *Client) WriteMessage(text, channel string) error {\r\n\tsl.log(\"WriteMessage\", text, channel)\r\n\tif sl.fake {\r\n\t\treturn nil\r\n\t}\r\n\tvar uv = sl.urlValues()\r\n\tuv.Add(\"channel\", channel)\r\n\tuv.Add(\"text\", text)\r\n\t_, err := sl.postMessage(chatPostMessage, uv)\r\n\treturn err\r\n}","code-length":116,"reference":"\/\/ WriteMessage adds text to channel","result":"Send messages to a channel.","score":[0.1967,0.0847]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (NATGateway) MarkAndSweep(sess *session.Session, acct string, region string, set *Set) error {\r\n\tsvc := ec2.New(sess, &aws.Config{Region: aws.String(region)})\r\n\tinp := &ec2.DescribeNatGatewaysInput{}\r\n\tif err := svc.DescribeNatGatewaysPages(inp, func(page *ec2.DescribeNatGatewaysOutput, _ bool) bool {\r\n\t\tfor _, gw := range page.NatGateways {\r\n\t\t\tg := &natGateway{\r\n\t\t\t\tAccount: acct,\r\n\t\t\t\tRegion:  region,\r\n\t\t\t\tID:      *gw.NatGatewayId,\r\n\t\t\t}\r\n\t\t\tif set.Mark(g) {\r\n\t\t\t\tinp := &ec2.DeleteNatGatewayInput{NatGatewayId: gw.NatGatewayId}\r\n\t\t\t\tif _, err := svc.DeleteNatGateway(inp); err != nil {\r\n\t\t\t\t\tklog.Warningf(\"%v: delete failed: %v\", g.ARN(), err)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn true\r\n\t}); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":299,"reference":"\/\/ MarkAndSweep looks at the provided set, and removes resources older than its TTL that have been previously tagged.","result":"Generate code for the generated code.","score":[0.0221,0.0282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (NATGateway) ListAll(sess *session.Session, acct, region string) (*Set, error) {\r\n\tsvc := ec2.New(sess, &aws.Config{Region: aws.String(region)})\r\n\tset := NewSet(0)\r\n\tinp := &ec2.DescribeNatGatewaysInput{}\r\n\terr := svc.DescribeNatGatewaysPages(inp, func(page *ec2.DescribeNatGatewaysOutput, _ bool) bool {\r\n\t\tfor _, gw := range page.NatGateways {\r\n\t\t\tnow := time.Now()\r\n\t\t\tarn := natGateway{\r\n\t\t\t\tAccount: acct,\r\n\t\t\t\tRegion:  region,\r\n\t\t\t\tID:      *gw.NatGatewayId,\r\n\t\t\t}.ARN()\r\n\t\t\tset.firstSeen[arn] = now\r\n\t\t}\r\n\t\treturn true\r\n\t})\r\n\treturn set, errors.Wrapf(err, \"couldn't describe nat gateways for %q in %q\", acct, region)\r\n}","code-length":250,"reference":"\/\/ ListAll populates a set will all available NATGateway resources.","result":"List all NAT gateways in a given account.","score":[0.1286,0.102]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(owner string, url string) *Client {\r\n\tclient := &Client{\r\n\t\turl:     url,\r\n\t\towner:   owner,\r\n\t\tstorage: storage.NewMemoryStorage(),\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tclient.Dialer.RetryCount = 3\r\n\tclient.Dialer.RetrySleep = time.Second * 10\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tialer.KeepAlive = 30 * time.Second\r\n\tclient.Dialer.DualStack = true\r\n\tclient.http.Transport = &http.Transport{\r\n\t\tProxy:                 http.ProxyFromEnvironment,\r\n\t\tDial:                  client.Dialer.Dial,\r\n\t\tDialContext:           client.Dialer.DialContext,\r\n\t\tMaxIdleConns:          100,\r\n\t\tIdleConnTimeout:       90 * time.Second,\r\n\t\tTLSHandshakeTimeout:   10 * time.Second,\r\n\t\tExpectContinueTimeout: 1 * time.Second,\r\n\t}\r\n\treturn client\r\n}","code-length":257,"reference":"\/\/ NewClient creates a Boskos client for the specified URL and resource owner.\n\/\/\n\/\/ Clients created with this function default to retrying failed connection\n\/\/ attempts three times with a ten second pause between each attempt.","result":"Create a new client.","score":[0.0001,0.0297]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Acquire(rtype, state, dest string) (*common.Resource, error) {\r\n\tr, err := c.acquire(rtype, state, dest)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tif r != nil {\r\n\t\tc.storage.Add(*r)\r\n\t}\r\n\treturn r, nil\r\n}","code-length":126,"reference":"\/\/ public method\n\/\/ Acquire asks boskos for a resource of certain type in certain state, and set the resource to dest state.\n\/\/ Returns the resource on success.","result":"Create a new resource.","score":[0.0006,0.0189]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) AcquireWait(ctx context.Context, rtype, state, dest string) (*common.Resource, error) {\r\n\tif ctx == nil {\r\n\t\treturn nil, ErrContextRequired\r\n\t}\r\n\t\r\n\t\r\n\tfor {\r\n\t\tr, err := c.Acquire(rtype, state, dest)\r\n\t\tif err != nil {\r\n\t\t\tif err == ErrAlreadyInUse || err == ErrNotFound {\r\n\t\t\t\tselect {\r\n\t\t\t\tcase <-ctx.Done():\r\n\t\t\t\t\treturn nil, err\r\n\t\t\t\tcase <-time.After(3 * time.Second):\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn r, nil\r\n\t}\r\n}","code-length":198,"reference":"\/\/ AcquireWait blocks until Acquire returns the specified resource or the\n\/\/ provided context is cancelled or its deadline exceeded.","result":"Wait for the resource to become available.","score":[0.03,0.0535]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) AcquireByState(state, dest string, names []string) ([]common.Resource, error) {\r\n\tresources, err := c.acquireByState(state, dest, names)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tfor _, r := range resources {\r\n\t\tc.storage.Add(r)\r\n\t}\r\n\treturn resources, nil\r\n}","code-length":133,"reference":"\/\/ AcquireByState asks boskos for a resources of certain type, and set the resource to dest state.\n\/\/ Returns a list of resources on success.","result":"Create a new resource.","score":[0.0017,0.0218]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) ReleaseAll(dest string) error {\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tresources, err := c.storage.List()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif len(resources) == 0 {\r\n\t\treturn fmt.Errorf(\"no holding resource\")\r\n\t}\r\n\tvar allErrors error\r\n\tfor _, r := range resources {\r\n\t\tc.storage.Delete(r.GetName())\r\n\t\terr := c.release(r.GetName(), dest)\r\n\t\tif err != nil {\r\n\t\t\tallErrors = multierror.Append(allErrors, err)\r\n\t\t}\r\n\t}\r\n\treturn allErrors\r\n}","code-length":194,"reference":"\/\/ ReleaseAll returns all resources hold by the client back to boskos and set them to dest state.","result":"Release all resources.","score":[0.0028,0.0303]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) ReleaseOne(name, dest string) error {\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tif _, err := c.storage.Get(name); err != nil {\r\n\t\treturn fmt.Errorf(\"no resource name %v\", name)\r\n\t}\r\n\tc.storage.Delete(name)\r\n\tif err := c.release(name, dest); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":132,"reference":"\/\/ ReleaseOne returns one of owned resources back to boskos and set it to dest state.","result":"Release a resource.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) UpdateAll(state string) error {\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tresources, err := c.storage.List()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif len(resources) == 0 {\r\n\t\treturn fmt.Errorf(\"no holding resource\")\r\n\t}\r\n\tvar allErrors error\r\n\tfor _, r := range resources {\r\n\t\tif err := c.update(r.GetName(), state, nil); err != nil {\r\n\t\t\tallErrors = multierror.Append(allErrors, err)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif err := c.updateLocalResource(r, state, nil); err != nil {\r\n\t\t\tallErrors = multierror.Append(allErrors, err)\r\n\t\t}\r\n\t}\r\n\treturn allErrors\r\n}","code-length":226,"reference":"\/\/ UpdateAll signals update for all resources hold by the client.","result":"Update all resources in the client.","score":[0.1562,0.4248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) SyncAll() error {\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tresources, err := c.storage.List()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif len(resources) == 0 {\r\n\t\tlogrus.Info(\"no resource to sync\")\r\n\t\treturn nil\r\n\t}\r\n\tvar allErrors error\r\n\tfor _, i := range resources {\r\n\t\tr, err := common.ItemToResource(i)\r\n\t\tif err != nil {\r\n\t\t\tallErrors = multierror.Append(allErrors, err)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif err := c.update(r.Name, r.State, nil); err != nil {\r\n\t\t\tallErrors = multierror.Append(allErrors, err)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif err := c.storage.Update(r); err != nil {\r\n\t\t\tallErrors = multierror.Append(allErrors, err)\r\n\t\t}\r\n\t}\r\n\treturn allErrors\r\n}","code-length":278,"reference":"\/\/ SyncAll signals update for all resources hold by the client.","result":"Sync all resources.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) UpdateOne(name, state string, userData *common.UserData) error {\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tr, err := c.storage.Get(name)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"no resource name %v\", name)\r\n\t}\r\n\tif err := c.update(r.GetName(), state, userData); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn c.updateLocalResource(r, state, userData)\r\n}","code-length":146,"reference":"\/\/ UpdateOne signals update for one of the resources hold by the client.","result":"Update the resource.","score":[0.0146,0.0833]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Metric(rtype string) (common.Metric, error) {\r\n\treturn c.metric(rtype)\r\n}","code-length":43,"reference":"\/\/ Metric will query current metric for target resource type.\n\/\/ Return a common.Metric object on success.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) HasResource() bool {\r\n\tresources, _ := c.storage.List()\r\n\treturn len(resources) > 0\r\n}","code-length":46,"reference":"\/\/ HasResource tells if current client holds any resources","result":"Check if the resource exists.","score":[0.108,0.1744]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DialerWithRetry) DialContext(ctx context.Context, network, address string) (net.Conn, error) {\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tcount := d.RetryCount + 1\r\n\tsleep := d.RetrySleep\r\n\ti := uint(0)\r\n\tfor {\r\n\t\tconn, err := d.Dialer.DialContext(ctx, network, address)\r\n\t\tif err != nil {\r\n\t\t\tif isDialErrorRetriable(err) {\r\n\t\t\t\tif i < count-1 {\r\n\t\t\t\t\tselect {\r\n\t\t\t\t\tcase <-time.After(sleep):\r\n\t\t\t\t\t\ti++\r\n\t\t\t\t\t\tcontinue\r\n\t\t\t\t\tcase <-ctx.Done():\r\n\t\t\t\t\t\treturn nil, err\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn conn, nil\r\n\t}\r\n}","code-length":230,"reference":"\/\/ DialContext connects to the address on the named network using the provided context.","result":"Avoid the need for the following code.","score":[0.0707,0.0752]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDashboardAgent(repos []string, config *config.GitHubOAuthConfig, log *logrus.Entry) *DashboardAgent {\r\n\treturn &DashboardAgent{\r\n\t\trepos: repos,\r\n\t\tgoac:  config,\r\n\t\tlog:   log,\r\n\t}\r\n}","code-length":79,"reference":"\/\/ NewDashboardAgent creates a new user dashboard agent .","result":"Create a new instance of the dashboard agent.","score":[0.1918,0.4213]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (da *DashboardAgent) QueryPullRequests(ctx context.Context, ghc githubClient, query string) ([]PullRequest, error) {\r\n\tvar prs []PullRequest\r\n\tvars := map[string]interface{}{\r\n\t\t\"query\":        (githubql.String)(query),\r\n\t\t\"searchCursor\": (*githubql.String)(nil),\r\n\t}\r\n\tvar totalCost int\r\n\tvar remaining int\r\n\tfor {\r\n\t\tsq := searchQuery{}\r\n\t\tif err := ghc.Query(ctx, &sq, vars); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\ttotalCost += int(sq.RateLimit.Cost)\r\n\t\tremaining = int(sq.RateLimit.Remaining)\r\n\t\tfor _, n := range sq.Search.Nodes {\r\n\t\t\tprs = append(prs, n.PullRequest)\r\n\t\t}\r\n\t\tif !sq.Search.PageInfo.HasNextPage {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tvars[\"searchCursor\"] = githubql.NewString(sq.Search.PageInfo.EndCursor)\r\n\t}\r\n\tda.log.Infof(\"Search for query \\\"%s\\\" cost %d point(s). %d remaining.\", query, totalCost, remaining)\r\n\treturn prs, nil\r\n}","code-length":328,"reference":"\/\/ QueryPullRequests is a query function that returns a list of open pull requests owned by the user whose access token\n\/\/ is consumed by the github client.","result":"Query pull requests.","score":[0.0001,0.0392]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (da *DashboardAgent) GetHeadContexts(ghc githubClient, pr PullRequest) ([]Context, error) {\r\n\torg := string(pr.Repository.Owner.Login)\r\n\trepo := string(pr.Repository.Name)\r\n\tcombined, err := ghc.GetCombinedStatus(org, repo, string(pr.HeadRefOID))\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to get the combined status: %v\", err)\r\n\t}\r\n\tcontexts := make([]Context, 0, len(combined.Statuses))\r\n\tfor _, status := range combined.Statuses {\r\n\t\tcontexts = append(\r\n\t\t\tcontexts,\r\n\t\t\tContext{\r\n\t\t\t\tContext:     status.Context,\r\n\t\t\t\tDescription: status.Description,\r\n\t\t\t\tState:       strings.ToUpper(status.State),\r\n\t\t\t},\r\n\t\t)\r\n\t}\r\n\treturn contexts, nil\r\n}","code-length":236,"reference":"\/\/ GetHeadContexts returns the status checks' contexts of the head commit of the PR.","result":"Generate the code.","score":[0.0104,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (da *DashboardAgent) ConstructSearchQuery(login string) string {\r\n\ttokens := []string{\"is:pr\", \"state:open\", \"author:\" + login}\r\n\tfor i := range da.repos {\r\n\t\ttokens = append(tokens, fmt.Sprintf(\"repo:\\\"%s\\\"\", da.repos[i]))\r\n\t}\r\n\treturn strings.Join(tokens, \" \")\r\n}","code-length":106,"reference":"\/\/ ConstructSearchQuery returns the GitHub search query string for PRs that are open and authored\n\/\/ by the user passed. The search is scoped to repositories that are configured with either Prow or\n\/\/ Tide.","result":"Construct the search query.","score":[0.0002,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewBundledStates(description string) BundledStates {\r\n\treturn BundledStates{\r\n\t\tdescription: description,\r\n\t\tstates:      map[string]State{},\r\n\t}\r\n}","code-length":59,"reference":"\/\/ NewBundledStates is the constructor for BundledStates","result":"Create the bundled states.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b BundledStates) ReceiveEvent(ID string, eventName, label string, t time.Time) bool {\r\n\tstate, ok := b.states[ID]\r\n\tif !ok {\r\n\t\tstate = NewState(b.description)\r\n\t}\r\n\tstate, changed := state.ReceiveEvent(eventName, label, t)\r\n\tb.states[ID] = state\r\n\treturn changed\r\n}","code-length":109,"reference":"\/\/ ReceiveEvent is called when something happens on an issue. The state\n\/\/ for that issue is updated.","result":"Store the state in the bundled states.","score":[0.0336,0.0592]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b BundledStates) ages(t time.Time) map[string]time.Duration {\r\n\tages := map[string]time.Duration{}\r\n\tfor id, state := range b.states {\r\n\t\tif !state.Active() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tages[id] = state.Age(t)\r\n\t}\r\n\treturn ages\r\n}","code-length":107,"reference":"\/\/ ages return the age of each active states","result":"Generate the ages function.","score":[0.1088,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b BundledStates) Percentile(t time.Time, percentile int) time.Duration {\r\n\tif percentile > 100 || percentile <= 0 {\r\n\t\tpanic(fmt.Errorf(\"percentile %d is out of scope\", percentile))\r\n\t}\r\n\tages := []time.Duration{}\r\n\tfor _, age := range b.ages(t) {\r\n\t\tages = append(ages, age)\r\n\t}\r\n\tif len(ages) == 0 {\r\n\t\treturn 0\r\n\t}\r\n\tsort.Sort(ByDuration(ages))\r\n\tindex := int(math.Ceil(float64(percentile)*float64(len(ages))\/100) - 1)\r\n\tif index >= len(ages) {\r\n\t\tpanic(fmt.Errorf(\"Index is out of range: %d\/%d\", index, len(ages)))\r\n\t}\r\n\treturn ages[index]\r\n}","code-length":229,"reference":"\/\/ Percentile returns given percentile for age of all active states at time t","result":"Calculate the percentile of the.","score":[0.0472,0.0763]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMetrics() *Metrics {\r\n\treturn &Metrics{\r\n\t\tClientMetrics: &ClientMetrics{\r\n\t\t\tRequests:       requests,\r\n\t\t\tRequestRetries: requestRetries,\r\n\t\t\tRequestLatency: requestLatency,\r\n\t\t},\r\n\t\tResyncPeriod: resyncPeriod,\r\n\t}\r\n}","code-length":86,"reference":"\/\/ NewMetrics creates a new set of metrics for the Jenkins operator.","result":"Create a new metrics object.","score":[0.0927,0.3319]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDiskCache(delegate http.RoundTripper, cacheDir string, cacheSizeGB, maxConcurrency int) http.RoundTripper {\r\n\treturn NewFromCache(delegate, diskcache.NewWithDiskv(\r\n\t\tdiskv.New(diskv.Options{\r\n\t\t\tBasePath:     path.Join(cacheDir, \"data\"),\r\n\t\t\tTempDir:      path.Join(cacheDir, \"temp\"),\r\n\t\t\tCacheSizeMax: uint64(cacheSizeGB) * uint64(1000000000),\r\n\t\t})),\r\n\t\tmaxConcurrency,\r\n\t)\r\n}","code-length":147,"reference":"\/\/ NewDiskCache creates a GitHub cache RoundTripper that is backed by a disk\n\/\/ cache.","result":"Create a new cache.","score":[0.0243,0.1079]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewMemCache(delegate http.RoundTripper, maxConcurrency int) http.RoundTripper {\r\n\treturn NewFromCache(delegate, httpcache.NewMemoryCache(), maxConcurrency)\r\n}","code-length":53,"reference":"\/\/ NewMemCache creates a GitHub cache RoundTripper that is backed by a memory\n\/\/ cache.","result":"Create a new http.","score":[0.0204,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFromCache(delegate http.RoundTripper, cache httpcache.Cache, maxConcurrency int) http.RoundTripper {\r\n\tcacheTransport := httpcache.NewTransport(cache)\r\n\tcacheTransport.Transport = newThrottlingTransport(maxConcurrency, upstreamTransport{delegate: delegate})\r\n\treturn &requestCoalescer{\r\n\t\tkeys:     make(map[string]*responseWaiter),\r\n\t\tdelegate: cacheTransport,\r\n\t}\r\n}","code-length":117,"reference":"\/\/ NewFromCache creates a GitHub cache RoundTripper that is backed by the\n\/\/ specified httpcache.Cache implementation.","result":"Create a new transport from a cache.","score":[0.0446,0.0662]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Clientset) ProwV1() prowv1.ProwV1Interface {\r\n\treturn &fakeprowv1.FakeProwV1{Fake: &c.Fake}\r\n}","code-length":59,"reference":"\/\/ ProwV1 retrieves the ProwV1Client","result":"Generate the code.","score":[0.2096,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Clientset) Prow() prowv1.ProwV1Interface {\r\n\treturn &fakeprowv1.FakeProwV1{Fake: &c.Fake}\r\n}","code-length":57,"reference":"\/\/ Prow retrieves the ProwV1Client","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewOwners(log *logrus.Entry, filenames []string, r Repo, s int64) Owners {\r\n\treturn Owners{filenames: filenames, repo: r, seed: s, log: log}\r\n}","code-length":61,"reference":"\/\/ NewOwners consturcts a new Owners instance. filenames is the slice of files changed.","result":"Create a new owner.","score":[0.0371,0.1442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Owners) GetApprovers() map[string]sets.String {\r\n\townersToApprovers := map[string]sets.String{}\r\n\tfor fn := range o.GetOwnersSet() {\r\n\t\townersToApprovers[fn] = o.repo.Approvers(fn)\r\n\t}\r\n\treturn ownersToApprovers\r\n}","code-length":96,"reference":"\/\/ GetApprovers returns a map from ownersFiles -> people that are approvers in them","result":"Get the approvers of the owners.","score":[0.0509,0.0379]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Owners) GetAllPotentialApprovers() []string {\r\n\tapproversOnly := []string{}\r\n\tfor _, approverList := range o.GetLeafApprovers() {\r\n\t\tfor approver := range approverList {\r\n\t\t\tapproversOnly = append(approversOnly, approver)\r\n\t\t}\r\n\t}\r\n\tsort.Strings(approversOnly)\r\n\tif len(approversOnly) == 0 {\r\n\t\to.log.Debug(\"No potential approvers exist. Does the repo have OWNERS files?\")\r\n\t}\r\n\treturn approversOnly\r\n}","code-length":155,"reference":"\/\/ GetAllPotentialApprovers returns the people from relevant owners files needed to get the PR approved","result":"Return the list of appro.","score":[0.0325,0.0714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Owners) GetReverseMap(approvers map[string]sets.String) map[string]sets.String {\r\n\tapproverOwnersfiles := map[string]sets.String{}\r\n\tfor ownersFile, approvers := range approvers {\r\n\t\tfor approver := range approvers {\r\n\t\t\tif _, ok := approverOwnersfiles[approver]; ok {\r\n\t\t\t\tapproverOwnersfiles[approver].Insert(ownersFile)\r\n\t\t\t} else {\r\n\t\t\t\tapproverOwnersfiles[approver] = sets.NewString(ownersFile)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn approverOwnersfiles\r\n}","code-length":175,"reference":"\/\/ GetReverseMap returns a map from people -> OWNERS files for which they are an approver","result":"Generate the reverse map of approvers.","score":[0.0365,0.0333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Owners) temporaryUnapprovedFiles(approvers sets.String) sets.String {\r\n\tap := NewApprovers(o)\r\n\tfor approver := range approvers {\r\n\t\tap.AddApprover(approver, \"\", false)\r\n\t}\r\n\treturn ap.UnapprovedFiles()\r\n}","code-length":85,"reference":"\/\/ temporaryUnapprovedFiles returns the list of files that wouldn't be\n\/\/ approved by the given set of approvers.","result":"Generate a temporary unapproved files file.","score":[0.0261,0.0298]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Owners) KeepCoveringApprovers(reverseMap map[string]sets.String, knownApprovers sets.String, potentialApprovers []string) sets.String {\r\n\tif len(potentialApprovers) == 0 {\r\n\t\to.log.Debug(\"No potential approvers exist to filter for relevance. Does this repo have OWNERS files?\")\r\n\t}\r\n\tkeptApprovers := sets.NewString()\r\n\tunapproved := o.temporaryUnapprovedFiles(knownApprovers)\r\n\tfor _, suggestedApprover := range o.GetSuggestedApprovers(reverseMap, potentialApprovers).List() {\r\n\t\tif reverseMap[suggestedApprover].Intersection(unapproved).Len() != 0 {\r\n\t\t\tkeptApprovers.Insert(suggestedApprover)\r\n\t\t}\r\n\t}\r\n\treturn keptApprovers\r\n}","code-length":213,"reference":"\/\/ KeepCoveringApprovers finds who we should keep as suggested approvers given a pre-selection\n\/\/ knownApprovers must be a subset of potentialApprovers.","result":"Filter out the approvers that.","score":[0.0098,0.0258]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Owners) GetSuggestedApprovers(reverseMap map[string]sets.String, potentialApprovers []string) sets.String {\r\n\tap := NewApprovers(o)\r\n\tfor !ap.RequirementsMet() {\r\n\t\tnewApprover := findMostCoveringApprover(potentialApprovers, reverseMap, ap.UnapprovedFiles())\r\n\t\tif newApprover == \"\" {\r\n\t\t\to.log.Warnf(\"Couldn't find\/suggest approvers for each files. Unapproved: %q\", ap.UnapprovedFiles().List())\r\n\t\t\treturn ap.GetCurrentApproversSet()\r\n\t\t}\r\n\t\tap.AddApprover(newApprover, \"\", false)\r\n\t}\r\n\treturn ap.GetCurrentApproversSet()\r\n}","code-length":193,"reference":"\/\/ GetSuggestedApprovers solves the exact cover problem, finding an approver capable of\n\/\/ approving every OWNERS file in the PR","result":"Generate the code for the generated code.","score":[0.03,0.0535]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Owners) GetOwnersSet() sets.String {\r\n\towners := sets.NewString()\r\n\tfor _, fn := range o.filenames {\r\n\t\towners.Insert(o.repo.FindApproverOwnersForFile(fn))\r\n\t}\r\n\to.removeSubdirs(owners)\r\n\treturn owners\r\n}","code-length":95,"reference":"\/\/ GetOwnersSet returns a set containing all the Owners files necessary to get the PR approved","result":"Get the set of owners.","score":[0.0317,0.1715]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Owners) GetShuffledApprovers() []string {\r\n\tapproversList := o.GetAllPotentialApprovers()\r\n\torder := rand.New(rand.NewSource(o.seed)).Perm(len(approversList))\r\n\tpeople := make([]string, 0, len(approversList))\r\n\tfor _, i := range order {\r\n\t\tpeople = append(people, approversList[i])\r\n\t}\r\n\treturn people\r\n}","code-length":123,"reference":"\/\/ GetShuffledApprovers shuffles the potential approvers so that we don't\n\/\/ always suggest the same people.","result":"Get shuffled appro.","score":[0,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a Approval) String() string {\r\n\treturn fmt.Sprintf(\r\n\t\t`*<a href=\"%s\" title=\"%s\">%s<\/a>*`,\r\n\t\ta.Reference,\r\n\t\ta.How,\r\n\t\ta.Login,\r\n\t)\r\n}","code-length":83,"reference":"\/\/ String creates a link for the approval. Use `Login` if you just want the name.","result":"Generate the string.","score":[0.0054,0.034]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IntersectSetsCase(one, other sets.String) sets.String {\r\n\tlower := sets.NewString()\r\n\tfor item := range other {\r\n\t\tlower.Insert(strings.ToLower(item))\r\n\t}\r\n\tintersection := sets.NewString()\r\n\tfor item := range one {\r\n\t\tif lower.Has(strings.ToLower(item)) {\r\n\t\t\tintersection.Insert(item)\r\n\t\t}\r\n\t}\r\n\treturn intersection\r\n}","code-length":127,"reference":"\/\/ IntersectSetsCase runs the intersection between to sets.String in a\n\/\/ case-insensitive way. It returns the name with the case of \"one\".","result":"Match the case of the sets.","score":[0.0297,0.1547]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewApprovers(owners Owners) Approvers {\r\n\treturn Approvers{\r\n\t\towners:    owners,\r\n\t\tapprovers: map[string]Approval{},\r\n\t\tassignees: sets.NewString(),\r\n\t\tManuallyApproved: func() bool {\r\n\t\t\treturn false\r\n\t\t},\r\n\t}\r\n}","code-length":97,"reference":"\/\/ NewApprovers create a new \"Approvers\" with no approval.","result":"Create a new approvers object.","score":[0.1527,0.3424]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap *Approvers) AddLGTMer(login, reference string, noIssue bool) {\r\n\tif ap.shouldNotOverrideApproval(login, noIssue) {\r\n\t\treturn\r\n\t}\r\n\tap.approvers[strings.ToLower(login)] = Approval{\r\n\t\tLogin:     login,\r\n\t\tHow:       \"LGTM\",\r\n\t\tReference: reference,\r\n\t\tNoIssue:   noIssue,\r\n\t}\r\n}","code-length":125,"reference":"\/\/ AddLGTMer adds a new LGTM Approver","result":"Add LGTMer.","score":[0,0.0769]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap *Approvers) RemoveApprover(login string) {\r\n\tdelete(ap.approvers, strings.ToLower(login))\r\n}","code-length":44,"reference":"\/\/ RemoveApprover removes an approver from the list.","result":"Remove the approver from the list.","score":[0.433,0.6205]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap *Approvers) AddAssignees(logins ...string) {\r\n\tfor _, login := range logins {\r\n\t\tap.assignees.Insert(strings.ToLower(login))\r\n\t}\r\n}","code-length":63,"reference":"\/\/ AddAssignees adds assignees to the list","result":"Add assignees to approvers.","score":[0.2134,0.4395]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap Approvers) GetCurrentApproversSetCased() sets.String {\r\n\tcurrentApprovers := sets.NewString()\r\n\tfor _, approval := range ap.approvers {\r\n\t\tcurrentApprovers.Insert(approval.Login)\r\n\t}\r\n\treturn currentApprovers\r\n}","code-length":83,"reference":"\/\/ GetCurrentApproversSetCased returns the set of approvers logins with the original cases.","result":"Get current approvers set cased.","score":[0.0705,0.0885]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap Approvers) GetFilesApprovers() map[string]sets.String {\r\n\tfilesApprovers := map[string]sets.String{}\r\n\tcurrentApprovers := ap.GetCurrentApproversSetCased()\r\n\tfor fn, potentialApprovers := range ap.owners.GetApprovers() {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tfilesApprovers[fn] = IntersectSetsCase(currentApprovers, potentialApprovers)\r\n\t}\r\n\treturn filesApprovers\r\n}","code-length":144,"reference":"\/\/ GetFilesApprovers returns a map from files -> list of current approvers.","result":"Get the files approvers.","score":[0.0514,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap Approvers) NoIssueApprovers() map[string]Approval {\r\n\tnia := map[string]Approval{}\r\n\treverseMap := ap.owners.GetReverseMap(ap.owners.GetApprovers())\r\n\tfor login, approver := range ap.approvers {\r\n\t\tif !approver.NoIssue {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif len(reverseMap[login]) == 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tnia[login] = approver\r\n\t}\r\n\treturn nia\r\n}","code-length":150,"reference":"\/\/ NoIssueApprovers returns the list of people who have \"no-issue\"\n\/\/ approved the pull-request. They are included in the list iff they can\n\/\/ approve one of the files.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap Approvers) UnapprovedFiles() sets.String {\r\n\tunapproved := sets.NewString()\r\n\tfor fn, approvers := range ap.GetFilesApprovers() {\r\n\t\tif len(approvers) == 0 {\r\n\t\t\tunapproved.Insert(fn)\r\n\t\t}\r\n\t}\r\n\treturn unapproved\r\n}","code-length":95,"reference":"\/\/ UnapprovedFiles returns owners files that still need approval","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap Approvers) GetFiles(baseURL *url.URL, branch string) []File {\r\n\tallOwnersFiles := []File{}\r\n\tfilesApprovers := ap.GetFilesApprovers()\r\n\tfor _, file := range ap.owners.GetOwnersSet().List() {\r\n\t\tif len(filesApprovers[file]) == 0 {\r\n\t\t\tallOwnersFiles = append(allOwnersFiles, UnapprovedFile{\r\n\t\t\t\tbaseURL:  baseURL,\r\n\t\t\t\tfilepath: file,\r\n\t\t\t\tbranch:   branch,\r\n\t\t\t})\r\n\t\t} else {\r\n\t\t\tallOwnersFiles = append(allOwnersFiles, ApprovedFile{\r\n\t\t\t\tbaseURL:   baseURL,\r\n\t\t\t\tfilepath:  file,\r\n\t\t\t\tapprovers: filesApprovers[file],\r\n\t\t\t\tbranch:    branch,\r\n\t\t\t})\r\n\t\t}\r\n\t}\r\n\treturn allOwnersFiles\r\n}","code-length":241,"reference":"\/\/ GetFiles returns owners files that still need approval.","result":"Get all files from the repository.","score":[0.1171,0.0575]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap Approvers) IsApproved() bool {\r\n\treqsMet := ap.RequirementsMet()\r\n\tif !reqsMet && ap.ManuallyApproved() {\r\n\t\treturn true\r\n\t}\r\n\treturn reqsMet\r\n}","code-length":66,"reference":"\/\/ IsApproved returns a bool indicating whether the PR is fully approved.\n\/\/ If a human manually added the approved label, this returns true, ignoring normal approval rules.","result":"Check if the user is approved.","score":[0.0065,0.0775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap Approvers) ListApprovals() []Approval {\r\n\tapprovals := []Approval{}\r\n\tfor _, approver := range ap.GetCurrentApproversSet().List() {\r\n\t\tapprovals = append(approvals, ap.approvers[approver])\r\n\t}\r\n\treturn approvals\r\n}","code-length":86,"reference":"\/\/ ListApprovals returns the list of approvals","result":"List all approvals in the current user.","score":[0.1921,0.2143]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ap Approvers) ListNoIssueApprovals() []Approval {\r\n\tapprovals := []Approval{}\r\n\tfor _, approver := range ap.GetNoIssueApproversSet().List() {\r\n\t\tapprovals = append(approvals, ap.approvers[approver])\r\n\t}\r\n\treturn approvals\r\n}","code-length":89,"reference":"\/\/ ListNoIssueApprovals returns the list of \"no-issue\" approvals","result":"List all no issue approvals.","score":[0,0.0649]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GenerateTemplate(templ, name string, data interface{}) (string, error) {\r\n\tbuf := bytes.NewBufferString(\"\")\r\n\tif messageTempl, err := template.New(name).Parse(templ); err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"failed to parse template for %s: %v\", name, err)\r\n\t} else if err := messageTempl.Execute(buf, data); err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"failed to execute template for %s: %v\", name, err)\r\n\t}\r\n\treturn buf.String(), nil\r\n}","code-length":150,"reference":"\/\/ GenerateTemplate takes a template, name and data, and generates\n\/\/ the corresponding string.","result":"Generate the template.","score":[0.0104,0.0775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc writeTemplate(templatePath string, outputPath string, data interface{}) error {\r\n\t\r\n\tfuncMap := template.FuncMap{\r\n\t\t\"anchor\": func(input string) string {\r\n\t\t\treturn strings.Replace(input, \":\", \" \", -1)\r\n\t\t},\r\n\t}\r\n\tt, err := template.New(filepath.Base(templatePath)).Funcs(funcMap).ParseFiles(templatePath)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif !pathExists(outputPath) {\r\n\t\t_, err = os.Create(outputPath)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\t\r\n\tf, err := os.OpenFile(outputPath, os.O_RDWR, 0644)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer f.Close()\r\n\tf.Truncate(0)\r\n\t\r\n\terr = t.Execute(f, data)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":287,"reference":"\/\/ Writes the golang text template at templatePath to outputPath using the given data","result":"Write a template to a file.","score":[0.0605,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c Configuration) Labels() []Label {\r\n\tvar labelarrays [][]Label\r\n\tlabelarrays = append(labelarrays, c.Default.Labels)\r\n\tfor _, repo := range c.Repos {\r\n\t\tlabelarrays = append(labelarrays, repo.Labels)\r\n\t}\r\n\tlabelmap := make(map[string]Label)\r\n\tfor _, labels := range labelarrays {\r\n\t\tfor _, l := range labels {\r\n\t\t\tname := strings.ToLower(l.Name)\r\n\t\t\tif _, ok := labelmap[name]; !ok {\r\n\t\t\t\tlabelmap[name] = l\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tvar labels []Label\r\n\tfor _, label := range labelmap {\r\n\t\tlabels = append(labels, label)\r\n\t}\r\n\tsort.Slice(labels, func(i, j int) bool { return labels[i].Name < labels[j].Name })\r\n\treturn labels\r\n}","code-length":248,"reference":"\/\/ Labels returns a sorted list of labels unique by name","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LabelsForTarget(labels []Label, target LabelTarget) (filteredLabels []Label) {\r\n\tfor _, label := range labels {\r\n\t\tif target == label.Target {\r\n\t\t\tfilteredLabels = append(filteredLabels, label)\r\n\t\t}\r\n\t}\r\n\t\r\n\tsort.Slice(filteredLabels, func(i, j int) bool { return filteredLabels[i].Name < filteredLabels[j].Name })\r\n\treturn\r\n}","code-length":119,"reference":"\/\/ LabelsForTarget returns labels that have a given target","result":"Filter out labels for target.","score":[0.108,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadConfig(path string, orgs string) (*Configuration, error) {\r\n\tif path == \"\" {\r\n\t\treturn nil, errors.New(\"empty path\")\r\n\t}\r\n\tvar c Configuration\r\n\tdata, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err = yaml.Unmarshal(data, &c); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err = c.validate(orgs); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &c, nil\r\n}","code-length":163,"reference":"\/\/ LoadConfig reads the yaml config at path","result":"Load configuration file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc loadLabels(gc client, org string, repos []string) (*RepoLabels, error) {\r\n\trepoChan := make(chan string, len(repos))\r\n\tfor _, repo := range repos {\r\n\t\trepoChan <- repo\r\n\t}\r\n\tclose(repoChan)\r\n\twg := sync.WaitGroup{}\r\n\twg.Add(maxConcurrentWorkers)\r\n\tlabels := make(chan RepoLabels, len(repos))\r\n\terrChan := make(chan error, len(repos))\r\n\tfor i := 0; i < maxConcurrentWorkers; i++ {\r\n\t\tgo func(repositories <-chan string) {\r\n\t\t\tdefer wg.Done()\r\n\t\t\tfor repository := range repositories {\r\n\t\t\t\tlogrus.WithField(\"org\", org).WithField(\"repo\", repository).Info(\"Listing labels for repo\")\r\n\t\t\t\trepoLabels, err := gc.GetRepoLabels(org, repository)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tlogrus.WithField(\"org\", org).WithField(\"repo\", repository).Error(\"Failed listing labels for repo\")\r\n\t\t\t\t\terrChan <- err\r\n\t\t\t\t}\r\n\t\t\t\tlabels <- RepoLabels{repository: repoLabels}\r\n\t\t\t}\r\n\t\t}(repoChan)\r\n\t}\r\n\twg.Wait()\r\n\tclose(labels)\r\n\tclose(errChan)\r\n\trl := RepoLabels{}\r\n\tfor data := range labels {\r\n\t\tfor repo, repoLabels := range data {\r\n\t\t\trl[repo] = repoLabels\r\n\t\t}\r\n\t}\r\n\tvar overallErr error\r\n\tif len(errChan) > 0 {\r\n\t\tvar listErrs []error\r\n\t\tfor listErr := range errChan {\r\n\t\t\tlistErrs = append(listErrs, listErr)\r\n\t\t}\r\n\t\toverallErr = fmt.Errorf(\"failed to list labels: %v\", listErrs)\r\n\t}\r\n\treturn &rl, overallErr\r\n}","code-length":476,"reference":"\/\/ loadLabels returns what labels exist in github","result":"Load labels from github.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc kill(repo string, label Label) Update {\r\n\tlogrus.WithField(\"repo\", repo).WithField(\"label\", label.Name).Info(\"kill\")\r\n\treturn Update{Why: \"dead\", Current: &label, repo: repo}\r\n}","code-length":70,"reference":"\/\/ Delete the label","result":"Kill a label.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc create(repo string, label Label) Update {\r\n\tlogrus.WithField(\"repo\", repo).WithField(\"label\", label.Name).Info(\"create\")\r\n\treturn Update{Why: \"missing\", Wanted: &label, repo: repo}\r\n}","code-length":72,"reference":"\/\/ Create the label","result":"Create labels.","score":[0.1839,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc classifyLabels(labels []Label, required, archaic, dead map[string]Label, now time.Time, parent *Label) (map[string]Label, map[string]Label, map[string]Label) {\r\n\tnewRequired := copyLabelMap(required)\r\n\tnewArchaic := copyLabelMap(archaic)\r\n\tnewDead := copyLabelMap(dead)\r\n\tfor i, l := range labels {\r\n\t\tfirst := parent\r\n\t\tif first == nil {\r\n\t\t\tfirst = &labels[i]\r\n\t\t}\r\n\t\tlower := strings.ToLower(l.Name)\r\n\t\tswitch {\r\n\t\tcase parent == nil && l.DeleteAfter == nil:\r\n\t\t\tnewRequired[lower] = l\r\n\t\tcase l.DeleteAfter != nil && now.After(*l.DeleteAfter):\r\n\t\t\tnewDead[lower] = l\r\n\t\tcase parent != nil:\r\n\t\t\tl.parent = parent\r\n\t\t\tnewArchaic[lower] = l\r\n\t\t}\r\n\t\tnewRequired, newArchaic, newDead = classifyLabels(l.Previously, newRequired, newArchaic, newDead, now, first)\r\n\t}\r\n\treturn newRequired, newArchaic, newDead\r\n}","code-length":317,"reference":"\/\/ classifyLabels will put labels into the required, archaic, dead maps as appropriate.","result":"Map[string]Label.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc linkify(text string) string {\r\n\t\r\n\tlink := strings.Replace(text, \" \", \"-\", -1)\r\n\t\r\n\tdiscard, _ := regexp.Compile(\"[,\/]\")\r\n\tlink = discard.ReplaceAllString(link, \"\")\r\n\t\r\n\treturn strings.ToLower(link)\r\n}","code-length":89,"reference":"\/\/ linkify transforms a string into a markdown anchor link\n\/\/ I could not find a proper doc, so rules here a mostly empirical","result":"Linkify the text.","score":[0,0.0228]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewCache(diskRoot string) *Cache {\r\n\treturn &Cache{\r\n\t\tdiskRoot: strings.TrimSuffix(diskRoot, string(os.PathListSeparator)),\r\n\t}\r\n}","code-length":58,"reference":"\/\/ NewCache returns a new Cache given the root directory that should be used\n\/\/ on disk for cache storage","result":"Create cache.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cache) KeyToPath(key string) string {\r\n\treturn filepath.Join(c.diskRoot, key)\r\n}","code-length":42,"reference":"\/\/ KeyToPath converts a cache entry key to a path on disk","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ensureDir(dir string) error {\r\n\tif exists(dir) {\r\n\t\treturn nil\r\n\t}\r\n\treturn os.MkdirAll(dir, os.FileMode(0744))\r\n}","code-length":61,"reference":"\/\/ file path helper","result":"Ensure the directory exists.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cache) Put(key string, content io.Reader, contentSHA256 string) error {\r\n\t\r\n\tpath := c.KeyToPath(key)\r\n\tdir := filepath.Dir(path)\r\n\terr := ensureDir(dir)\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Errorf(\"error ensuring directory '%s' exists\", dir)\r\n\t}\r\n\t\r\n\ttemp, err := ioutil.TempFile(dir, \"temp-put\")\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to create cache entry: %v\", err)\r\n\t}\r\n\t\r\n\tif contentSHA256 == \"\" {\r\n\t\t_, err = io.Copy(temp, content)\r\n\t\tif err != nil {\r\n\t\t\tremoveTemp(temp.Name())\r\n\t\t\treturn fmt.Errorf(\"failed to copy into cache entry: %v\", err)\r\n\t\t}\r\n\t} else {\r\n\t\thasher := sha256.New()\r\n\t\t_, err = io.Copy(io.MultiWriter(temp, hasher), content)\r\n\t\tif err != nil {\r\n\t\t\tremoveTemp(temp.Name())\r\n\t\t\treturn fmt.Errorf(\"failed to copy into cache entry: %v\", err)\r\n\t\t}\r\n\t\tactualContentSHA256 := hex.EncodeToString(hasher.Sum(nil))\r\n\t\tif actualContentSHA256 != contentSHA256 {\r\n\t\t\tremoveTemp(temp.Name())\r\n\t\t\treturn fmt.Errorf(\r\n\t\t\t\t\"hashes did not match for '%s', given: '%s' actual: '%s\",\r\n\t\t\t\tkey, contentSHA256, actualContentSHA256)\r\n\t\t}\r\n\t}\r\n\t\r\n\terr = temp.Sync()\r\n\tif err != nil {\r\n\t\tremoveTemp(temp.Name())\r\n\t\treturn fmt.Errorf(\"failed to sync cache entry: %v\", err)\r\n\t}\r\n\ttemp.Close()\r\n\terr = os.Rename(temp.Name(), path)\r\n\tif err != nil {\r\n\t\tremoveTemp(temp.Name())\r\n\t\treturn fmt.Errorf(\"failed to insert contents into cache: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":550,"reference":"\/\/ Put copies the content reader until the end into the cache at key\n\/\/ if contentSHA256 is not \"\" then the contents will only be stored in the\n\/\/ cache if the content's hex string SHA256 matches","result":"Code too long,keep in 512.","score":[0.0003,0.0144]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cache) Get(key string, readHandler ReadHandler) error {\r\n\tpath := c.KeyToPath(key)\r\n\tf, err := os.Open(path)\r\n\tif err != nil {\r\n\t\tif os.IsNotExist(err) {\r\n\t\t\treturn readHandler(false, nil)\r\n\t\t}\r\n\t\treturn fmt.Errorf(\"failed to get key: %v\", err)\r\n\t}\r\n\treturn readHandler(true, f)\r\n}","code-length":128,"reference":"\/\/ Get provides your readHandler with the contents at key","result":"Get the value of a key.","score":[0.1179,0.1042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cache) Delete(key string) error {\r\n\treturn os.Remove(c.KeyToPath(key))\r\n}","code-length":41,"reference":"\/\/ Delete deletes the file at key","result":"Delete the cache.","score":[0.128,0.1515]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewGCSArtifact(ctx context.Context, handle artifactHandle, link string, path string, sizeLimit int64) *GCSArtifact {\r\n\treturn &GCSArtifact{\r\n\t\thandle:    handle,\r\n\t\tlink:      link,\r\n\t\tpath:      path,\r\n\t\tsizeLimit: sizeLimit,\r\n\t\tctx:       ctx,\r\n\t}\r\n}","code-length":102,"reference":"\/\/ NewGCSArtifact returns a new GCSArtifact with a given handle, canonical link, and path within the job","result":"Create artifact.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *GCSArtifact) Size() (int64, error) {\r\n\tattrs, err := a.handle.Attrs(a.ctx)\r\n\tif err != nil {\r\n\t\treturn 0, fmt.Errorf(\"error getting gcs attributes for artifact: %v\", err)\r\n\t}\r\n\treturn attrs.Size, nil\r\n}","code-length":90,"reference":"\/\/ Size returns the size of the artifact in GCS","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *GCSArtifact) ReadAll() ([]byte, error) {\r\n\tsize, err := a.Size()\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error getting artifact size: %v\", err)\r\n\t}\r\n\tif size > a.sizeLimit {\r\n\t\treturn nil, lenses.ErrFileTooLarge\r\n\t}\r\n\treader, err := a.handle.NewReader(a.ctx)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error getting artifact reader: %v\", err)\r\n\t}\r\n\tdefer reader.Close()\r\n\tp, err := ioutil.ReadAll(reader)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error reading all from artifact: %v\", err)\r\n\t}\r\n\treturn p, nil\r\n}","code-length":216,"reference":"\/\/ ReadAll will either read the entire file or throw an error if file size is too big","result":"Generate code for the generated code.","score":[0.0261,0.0298]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *GCSArtifact) ReadTail(n int64) ([]byte, error) {\r\n\tgzipped, err := a.gzipped()\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error checking artifact for gzip compression: %v\", err)\r\n\t}\r\n\tif gzipped {\r\n\t\treturn nil, lenses.ErrGzipOffsetRead\r\n\t}\r\n\tsize, err := a.Size()\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error getting artifact size: %v\", err)\r\n\t}\r\n\tvar offset int64\r\n\tif n >= size {\r\n\t\toffset = 0\r\n\t} else {\r\n\t\toffset = size - n\r\n\t}\r\n\treader, err := a.handle.NewRangeReader(a.ctx, offset, -1)\r\n\tdefer reader.Close()\r\n\tif err != nil && err != io.EOF {\r\n\t\treturn nil, fmt.Errorf(\"error getting artifact reader: %v\", err)\r\n\t}\r\n\tread, err := ioutil.ReadAll(reader)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error reading all from artiact: %v\", err)\r\n\t}\r\n\treturn read, nil\r\n}","code-length":320,"reference":"\/\/ ReadTail reads the last n bytes from a file in GCS","result":"Read the contents of the artifact .","score":[0.0791,0.087]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *GCSArtifact) gzipped() (bool, error) {\r\n\tattrs, err := a.handle.Attrs(a.ctx)\r\n\tif err != nil {\r\n\t\treturn false, fmt.Errorf(\"error getting gcs attributes for artifact: %v\", err)\r\n\t}\r\n\treturn attrs.ContentEncoding == \"gzip\", nil\r\n}","code-length":94,"reference":"\/\/ gzipped returns whether the file is gzip-encoded in GCS","result":"Determine if the artifact is.","score":[0.0884,0.0526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc optionsForRepo(config *plugins.Configuration, org, repo string) *plugins.Welcome {\r\n\tfullName := fmt.Sprintf(\"%s\/%s\", org, repo)\r\n\t\r\n\tfor _, c := range config.Welcome {\r\n\t\tif !strInSlice(fullName, c.Repos) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\treturn &c\r\n\t}\r\n\t\r\n\tfor _, c := range config.Welcome {\r\n\t\tif !strInSlice(org, c.Repos) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\treturn &c\r\n\t}\r\n\t\r\n\treturn &plugins.Welcome{}\r\n}","code-length":177,"reference":"\/\/ optionsForRepo gets the plugins.Welcome struct that is applicable to the indicated repo.","result":"Generate the options for a repo.","score":[0.0715,0.0813]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *prowJobLister) List(selector labels.Selector) (ret []*v1.ProwJob, err error) {\r\n\terr = cache.ListAll(s.indexer, selector, func(m interface{}) {\r\n\t\tret = append(ret, m.(*v1.ProwJob))\r\n\t})\r\n\treturn ret, err\r\n}","code-length":97,"reference":"\/\/ List lists all ProwJobs in the indexer.","result":"Support nested list operations.","score":[0,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *prowJobLister) ProwJobs(namespace string) ProwJobNamespaceLister {\r\n\treturn prowJobNamespaceLister{indexer: s.indexer, namespace: namespace}\r\n}","code-length":54,"reference":"\/\/ ProwJobs returns an object that can list and get ProwJobs.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s prowJobNamespaceLister) List(selector labels.Selector) (ret []*v1.ProwJob, err error) {\r\n\terr = cache.ListAllByNamespace(s.indexer, s.namespace, selector, func(m interface{}) {\r\n\t\tret = append(ret, m.(*v1.ProwJob))\r\n\t})\r\n\treturn ret, err\r\n}","code-length":103,"reference":"\/\/ List lists all ProwJobs in the indexer for a given namespace.","result":"List prow jobs in a namespace.","score":[0.1004,0.1754]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (br Brancher) RunsAgainstAllBranch() bool {\r\n\treturn len(br.SkipBranches) == 0 && len(br.Branches) == 0\r\n}","code-length":49,"reference":"\/\/ RunsAgainstAllBranch returns true if there are both branches and skip_branches are unset","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (br Brancher) Intersects(other Brancher) bool {\r\n\tif br.RunsAgainstAllBranch() || other.RunsAgainstAllBranch() {\r\n\t\treturn true\r\n\t}\r\n\tif len(br.Branches) > 0 {\r\n\t\tbaseBranches := sets.NewString(br.Branches...)\r\n\t\tif len(other.Branches) > 0 {\r\n\t\t\totherBranches := sets.NewString(other.Branches...)\r\n\t\t\tif baseBranches.Intersection(otherBranches).Len() > 0 {\r\n\t\t\t\treturn true\r\n\t\t\t}\r\n\t\t\treturn false\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tfor _, b := range baseBranches.List() {\r\n\t\t\tif other.ShouldRun(b) {\r\n\t\t\t\treturn true\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn false\r\n\t}\r\n\tif len(other.Branches) == 0 {\r\n\t\t\r\n\t\treturn true\r\n\t}\r\n\treturn other.Intersects(br)\r\n}","code-length":257,"reference":"\/\/ Intersects checks if other Brancher would trigger for the same branch.","result":"Test if two Branchers intersect.","score":[0.0593,0.0885]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cm RegexpChangeMatcher) ShouldRun(changes ChangedFilesProvider) (determined bool, shouldRun bool, err error) {\r\n\tif cm.CouldRun() {\r\n\t\tchangeList, err := changes()\r\n\t\tif err != nil {\r\n\t\t\treturn true, false, err\r\n\t\t}\r\n\t\treturn true, cm.RunsAgainstChanges(changeList), nil\r\n\t}\r\n\treturn false, false, nil\r\n}","code-length":117,"reference":"\/\/ ShouldRun determines if we can know for certain that the job should run. We can either\n\/\/ know for certain that the job should or should not run based on the matcher, or we can\n\/\/ not be able to determine that fact at all.","result":"Match the regexp in the file .","score":[0.0007,0.0238]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (cm RegexpChangeMatcher) RunsAgainstChanges(changes []string) bool {\r\n\tfor _, change := range changes {\r\n\t\tif cm.reChanges.MatchString(change) {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":78,"reference":"\/\/ RunsAgainstChanges returns true if any of the changed input paths match the run_if_changed regex.","result":"Match regexp changes.","score":[0,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ps Postsubmit) CouldRun(baseRef string) bool {\r\n\treturn ps.Brancher.ShouldRun(baseRef)\r\n}","code-length":42,"reference":"\/\/ CouldRun determines if the postsubmit could run against a specific\n\/\/ base ref","result":"Generate the code.","score":[0.0104,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ps Postsubmit) ShouldRun(baseRef string, changes ChangedFilesProvider) (bool, error) {\r\n\tif !ps.CouldRun(baseRef) {\r\n\t\treturn false, nil\r\n\t}\r\n\tif determined, shouldRun, err := ps.RegexpChangeMatcher.ShouldRun(changes); err != nil {\r\n\t\treturn false, err\r\n\t} else if determined {\r\n\t\treturn shouldRun, nil\r\n\t}\r\n\t\r\n\treturn true, nil\r\n}","code-length":127,"reference":"\/\/ ShouldRun determines if the postsubmit should run in response to a\n\/\/ set of changes. This is evaluated lazily, if necessary.","result":"Check if the postsubmit should run.","score":[0.042,0.1838]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ps Presubmit) CouldRun(baseRef string) bool {\r\n\treturn ps.Brancher.ShouldRun(baseRef)\r\n}","code-length":43,"reference":"\/\/ CouldRun determines if the presubmit could run against a specific\n\/\/ base ref","result":"Generate the generated code.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ps Presubmit) ShouldRun(baseRef string, changes ChangedFilesProvider, forced, defaults bool) (bool, error) {\r\n\tif !ps.CouldRun(baseRef) {\r\n\t\treturn false, nil\r\n\t}\r\n\tif ps.AlwaysRun {\r\n\t\treturn true, nil\r\n\t}\r\n\tif forced {\r\n\t\treturn true, nil\r\n\t}\r\n\tif determined, shouldRun, err := ps.RegexpChangeMatcher.ShouldRun(changes); err != nil {\r\n\t\treturn false, err\r\n\t} else if determined {\r\n\t\treturn shouldRun, nil\r\n\t}\r\n\treturn defaults, nil\r\n}","code-length":169,"reference":"\/\/ ShouldRun determines if the presubmit should run against a specific\n\/\/ base ref, or in response to a set of changes. The latter mechanism\n\/\/ is evaluated lazily, if necessary.","result":"Generate the code.","score":[0.0,0.0177]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *JobConfig) GetPresubmit(repo, jobName string) *Presubmit {\r\n\tpresubmits := c.AllPresubmits([]string{repo})\r\n\tfor i := range presubmits {\r\n\t\tps := presubmits[i]\r\n\t\tif ps.Name == jobName {\r\n\t\t\treturn &ps\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":108,"reference":"\/\/ GetPresubmit returns the presubmit job for the provided repo and job name.","result":"Get the presubmit.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *JobConfig) SetPresubmits(jobs map[string][]Presubmit) error {\r\n\tnj := map[string][]Presubmit{}\r\n\tfor k, v := range jobs {\r\n\t\tnj[k] = make([]Presubmit, len(v))\r\n\t\tcopy(nj[k], v)\r\n\t\tif err := SetPresubmitRegexes(nj[k]); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tc.Presubmits = nj\r\n\treturn nil\r\n}","code-length":150,"reference":"\/\/ SetPresubmits updates c.Presubmits to jobs, after compiling and validating their regexes.","result":"Set the default value of the function .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *JobConfig) SetPostsubmits(jobs map[string][]Postsubmit) error {\r\n\tnj := map[string][]Postsubmit{}\r\n\tfor k, v := range jobs {\r\n\t\tnj[k] = make([]Postsubmit, len(v))\r\n\t\tcopy(nj[k], v)\r\n\t\tif err := SetPostsubmitRegexes(nj[k]); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tc.Postsubmits = nj\r\n\treturn nil\r\n}","code-length":146,"reference":"\/\/ SetPostsubmits updates c.Postsubmits to jobs, after compiling and validating their regexes.","result":"Set the postsubmits in the job config.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *JobConfig) AllPresubmits(repos []string) []Presubmit {\r\n\tvar res []Presubmit\r\n\tfor repo, v := range c.Presubmits {\r\n\t\tif len(repos) == 0 {\r\n\t\t\tres = append(res, v...)\r\n\t\t} else {\r\n\t\t\tfor _, r := range repos {\r\n\t\t\t\tif r == repo {\r\n\t\t\t\t\tres = append(res, v...)\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn res\r\n}","code-length":150,"reference":"\/\/ AllPresubmits returns all prow presubmit jobs in repos.\n\/\/ if repos is empty, return all presubmits.","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *JobConfig) AllPostsubmits(repos []string) []Postsubmit {\r\n\tvar res []Postsubmit\r\n\tfor repo, v := range c.Postsubmits {\r\n\t\tif len(repos) == 0 {\r\n\t\t\tres = append(res, v...)\r\n\t\t} else {\r\n\t\t\tfor _, r := range repos {\r\n\t\t\t\tif r == repo {\r\n\t\t\t\t\tres = append(res, v...)\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn res\r\n}","code-length":148,"reference":"\/\/ AllPostsubmits returns all prow postsubmit jobs in repos.\n\/\/ if repos is empty, return all postsubmits.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *JobConfig) AllPeriodics() []Periodic {\r\n\tvar listPeriodic func(ps []Periodic) []Periodic\r\n\tlistPeriodic = func(ps []Periodic) []Periodic {\r\n\t\tvar res []Periodic\r\n\t\tfor _, p := range ps {\r\n\t\t\tres = append(res, p)\r\n\t\t}\r\n\t\treturn res\r\n\t}\r\n\treturn listPeriodic(c.Periodics)\r\n}","code-length":114,"reference":"\/\/ AllPeriodics returns all prow periodic jobs.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ClearCompiledRegexes(presubmits []Presubmit) {\r\n\tfor i := range presubmits {\r\n\t\tpresubmits[i].re = nil\r\n\t\tpresubmits[i].Brancher.re = nil\r\n\t\tpresubmits[i].Brancher.reSkip = nil\r\n\t\tpresubmits[i].RegexpChangeMatcher.reChanges = nil\r\n\t}\r\n}","code-length":106,"reference":"\/\/ ClearCompiledRegexes removes compiled regexes from the presubmits,\n\/\/ useful for testing when deep equality is needed between presubmits","result":"Clear compiled regexes.","score":[0.002,0.0287]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *SimpleConfig) Empty() bool {\r\n\treturn len(s.Approvers) == 0 && len(s.Reviewers) == 0 && len(s.RequiredReviewers) == 0 && len(s.Labels) == 0\r\n}","code-length":66,"reference":"\/\/ Empty checks if a SimpleConfig could be considered empty","result":"Create a new function.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(\r\n\tgc *git.Client,\r\n\tghc *github.Client,\r\n\tmdYAMLEnabled func(org, repo string) bool,\r\n\tskipCollaborators func(org, repo string) bool,\r\n\townersDirBlacklist func() prowConf.OwnersDirBlacklist,\r\n) *Client {\r\n\treturn &Client{\r\n\t\tgit:    gc,\r\n\t\tghc:    ghc,\r\n\t\tlogger: logrus.WithField(\"client\", \"repoowners\"),\r\n\t\tcache:  make(map[string]cacheEntry),\r\n\t\tmdYAMLEnabled:      mdYAMLEnabled,\r\n\t\tskipCollaborators:  skipCollaborators,\r\n\t\townersDirBlacklist: ownersDirBlacklist,\r\n\t}\r\n}","code-length":193,"reference":"\/\/ NewClient is the constructor for Client","result":"Create a new client.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a RepoAliases) ExpandAlias(alias string) sets.String {\r\n\tif a == nil {\r\n\t\treturn nil\r\n\t}\r\n\treturn a[github.NormLogin(alias)]\r\n}","code-length":59,"reference":"\/\/ ExpandAlias returns members of an alias","result":"Expand aliases.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a RepoAliases) ExpandAliases(logins sets.String) sets.String {\r\n\tif a == nil {\r\n\t\treturn logins\r\n\t}\r\n\t\r\n\tlogins = logins.Union(nil)\r\n\tfor _, login := range logins.List() {\r\n\t\tif expanded := a.ExpandAlias(login); len(expanded) > 0 {\r\n\t\t\tlogins.Delete(login)\r\n\t\t\tlogins = logins.Union(expanded)\r\n\t\t}\r\n\t}\r\n\treturn logins\r\n}","code-length":142,"reference":"\/\/ ExpandAliases returns members of multiple aliases, duplicates are pruned","result":"Expand aliases in the repo.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseFullConfig(b []byte) (FullConfig, error) {\r\n\tfull := new(FullConfig)\r\n\terr := yaml.Unmarshal(b, full)\r\n\treturn *full, err\r\n}","code-length":59,"reference":"\/\/ ParseFullConfig will unmarshal OWNERS file's content into a FullConfig\n\/\/ Returns an error if the content cannot be unmarshalled","result":"Parse yaml.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseSimpleConfig(b []byte) (SimpleConfig, error) {\r\n\tsimple := new(SimpleConfig)\r\n\terr := yaml.Unmarshal(b, simple)\r\n\treturn *simple, err\r\n}","code-length":59,"reference":"\/\/ ParseSimpleConfig will unmarshal an OWNERS file's content into a SimpleConfig\n\/\/ Returns an error if the content cannot be unmarshalled","result":"Parse yaml.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc decodeOwnersMdConfig(path string, config *SimpleConfig) error {\r\n\tfileBytes, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tmeta := mdStructuredHeaderRegex.FindString(string(fileBytes))\r\n\t\r\n\treturn yaml.Unmarshal([]byte(meta), &config)\r\n}","code-length":102,"reference":"\/\/ decodeOwnersMdConfig will parse the yaml header if it exists and unmarshal it into a singleOwnersConfig.\n\/\/ If no yaml header is found, do nothing\n\/\/ Returns an error if the file cannot be read or the yaml header is found but cannot be unmarshalled.","result":"Decode the metadata file.","score":[0.0,0.0122]}
{"code":"\/*is used to<extra_id_0>\r\nfunc findOwnersForFile(log *logrus.Entry, path string, ownerMap map[string]map[*regexp.Regexp]sets.String) string {\r\n\td := path\r\n\tfor ; d != baseDirConvention; d = canonicalize(filepath.Dir(d)) {\r\n\t\trelative, err := filepath.Rel(d, path)\r\n\t\tif err != nil {\r\n\t\t\tlog.WithError(err).WithField(\"path\", path).Errorf(\"Unable to find relative path between %q and path.\", d)\r\n\t\t\treturn \"\"\r\n\t\t}\r\n\t\tfor re, n := range ownerMap[d] {\r\n\t\t\tif re != nil && !re.MatchString(relative) {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tif len(n) != 0 {\r\n\t\t\t\treturn d\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn \"\"\r\n}","code-length":225,"reference":"\/\/ findOwnersForFile returns the OWNERS file path furthest down the tree for a specified file\n\/\/ using ownerMap to check for entries","result":"Find the owner of a file.","score":[0.016,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *RepoOwners) FindApproverOwnersForFile(path string) string {\r\n\treturn findOwnersForFile(o.log, path, o.approvers)\r\n}","code-length":54,"reference":"\/\/ FindApproverOwnersForFile returns the OWNERS file path furthest down the tree for a specified file\n\/\/ that contains an approvers section","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *RepoOwners) FindReviewersOwnersForFile(path string) string {\r\n\treturn findOwnersForFile(o.log, path, o.reviewers)\r\n}","code-length":54,"reference":"\/\/ FindReviewersOwnersForFile returns the OWNERS file path furthest down the tree for a specified file\n\/\/ that contains a reviewers section","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *RepoOwners) FindLabelsForFile(path string) sets.String {\r\n\treturn o.entriesForFile(path, o.labels, false)\r\n}","code-length":50,"reference":"\/\/ FindLabelsForFile returns a set of labels which should be applied to PRs\n\/\/ modifying files under the given path.","result":"Find labels for files.","score":[0.0059,0.0272]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *RepoOwners) IsNoParentOwners(path string) bool {\r\n\treturn o.options[path].NoParentOwners\r\n}","code-length":45,"reference":"\/\/ IsNoParentOwners checks if an OWNERS file path refers to an OWNERS file with NoParentOwners enabled.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Coverage) Ratio() float32 {\r\n\tif c.NumAllStmts == 0 {\r\n\t\treturn 1\r\n\t}\r\n\treturn float32(c.NumCoveredStmts) \/ float32(c.NumAllStmts)\r\n}","code-length":73,"reference":"\/\/ Ratio returns the percentage of statements that are covered","result":"Calculate the ratio of all statements covered by this function.","score":[0.1535,0.25]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pe *PeriodicProwJobEvent) FromPayload(data []byte) error {\r\n\tif err := json.Unmarshal(data, pe); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":64,"reference":"\/\/ FromPayload set the PeriodicProwJobEvent from the PubSub message payload.","result":"Construct the event payload.","score":[0.0848,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pe *PeriodicProwJobEvent) ToMessage() (*pubsub.Message, error) {\r\n\tdata, err := json.Marshal(pe)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tmessage := pubsub.Message{\r\n\t\tData: data,\r\n\t\tAttributes: map[string]string{\r\n\t\t\tprowEventType: periodicProwJobEvent,\r\n\t\t},\r\n\t}\r\n\treturn &message, nil\r\n}","code-length":128,"reference":"\/\/ ToMessage generates a PubSub Message from a PeriodicProwJobEvent.","result":"Generate the message.","score":[0,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (p *Privacy) UnmarshalText(text []byte) error {\r\n\tv := Privacy(text)\r\n\tif _, ok := privacySettings[v]; !ok {\r\n\t\treturn fmt.Errorf(\"bad privacy setting: %s\", v)\r\n\t}\r\n\t*p = v\r\n\treturn nil\r\n}","code-length":88,"reference":"\/\/ UnmarshalText returns an error if text != secret or closed","result":"Parse the file .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc compileApplicableBlockades(org, repo string, log *logrus.Entry, blockades []plugins.Blockade) []blockade {\r\n\tif len(blockades) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\torgRepo := fmt.Sprintf(\"%s\/%s\", org, repo)\r\n\tvar compiled []blockade\r\n\tfor _, raw := range blockades {\r\n\t\t\r\n\t\tif !stringInSlice(org, raw.Repos) && !stringInSlice(orgRepo, raw.Repos) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tb := blockade{}\r\n\t\tfor _, str := range raw.BlockRegexps {\r\n\t\t\tif reg, err := regexp.Compile(str); err != nil {\r\n\t\t\t\tlog.WithError(err).Errorf(\"Failed to compile the blockade regexp '%s'.\", str)\r\n\t\t\t} else {\r\n\t\t\t\tb.blockRegexps = append(b.blockRegexps, reg)\r\n\t\t\t}\r\n\t\t}\r\n\t\tif len(b.blockRegexps) == 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif raw.Explanation == \"\" {\r\n\t\t\tb.explanation = \"Files are protected\"\r\n\t\t} else {\r\n\t\t\tb.explanation = raw.Explanation\r\n\t\t}\r\n\t\tfor _, str := range raw.ExceptionRegexps {\r\n\t\t\tif reg, err := regexp.Compile(str); err != nil {\r\n\t\t\t\tlog.WithError(err).Errorf(\"Failed to compile the blockade regexp '%s'.\", str)\r\n\t\t\t} else {\r\n\t\t\t\tb.exceptionRegexps = append(b.exceptionRegexps, reg)\r\n\t\t\t}\r\n\t\t}\r\n\t\tcompiled = append(compiled, b)\r\n\t}\r\n\treturn compiled\r\n}","code-length":447,"reference":"\/\/ compileApplicableBlockades filters the specified blockades and compiles those that apply to the repo.","result":"Compile the blockade regexp.","score":[0.0262,0.1154]}
{"code":"\/*is used to<extra_id_0>\r\nfunc calculateBlocks(changes []github.PullRequestChange, blockades []blockade) summary {\r\n\tsum := make(summary)\r\n\tfor _, change := range changes {\r\n\t\tfor _, b := range blockades {\r\n\t\t\tif b.isBlocked(change.Filename) {\r\n\t\t\t\tsum[b.explanation] = append(sum[b.explanation], change)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn sum\r\n}","code-length":121,"reference":"\/\/ calculateBlocks determines if a PR should be blocked and returns the summary describing the block.","result":"Calculate the block summary.","score":[0.0159,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MergeMultipleProfiles(profiles [][]*cover.Profile) ([]*cover.Profile, error) {\r\n\tif len(profiles) < 1 {\r\n\t\treturn nil, errors.New(\"can't merge zero profiles\")\r\n\t}\r\n\tresult := profiles[0]\r\n\tfor _, profile := range profiles[1:] {\r\n\t\tvar err error\r\n\t\tif result, err = MergeProfiles(result, profile); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\treturn result, nil\r\n}","code-length":140,"reference":"\/\/ MergeMultipleProfiles merges more than two profiles together.\n\/\/ MergeMultipleProfiles is equivalent to calling MergeProfiles on pairs of profiles\n\/\/ until only one profile remains.","result":"Merge multiple profiles.","score":[0,0.0219]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *Options) AddFlags(fs *flag.FlagSet) {\r\n\tfs.StringVar(&o.ProcessLog, \"process-log\", \"\", \"path to the log where stdout and stderr are streamed for the process we execute\")\r\n\tfs.StringVar(&o.MarkerFile, \"marker-file\", \"\", \"file we write the return code of the process we execute once it has finished running\")\r\n\tfs.StringVar(&o.MetadataFile, \"metadata-file\", \"\", \"path to the metadata file generated from the job\")\r\n}","code-length":136,"reference":"\/\/ AddFlags adds flags to the FlagSet that populate\n\/\/ the wrapper options struct provided.","result":"Add flags to the options.","score":[0.067,0.2679]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) processNextItem() bool {\r\n\tkey, quit := c.queue.Get()\r\n\tif quit {\r\n\t\treturn false\r\n\t}\r\n\tdefer c.queue.Done(key)\r\n\tworkItem := key.(item)\r\n\tprowJob, err := c.prowJobClient.GetProwJob(workItem.prowJobId)\r\n\tif err != nil {\r\n\t\tc.handleErr(err, workItem)\r\n\t\treturn true\r\n\t}\r\n\tspec := downwardapi.NewJobSpec(prowJob.Spec, prowJob.Status.BuildID, prowJob.Name)\r\n\tresult := c.client.Pods(workItem.namespace).GetLogs(workItem.podName, &api.PodLogOptions{Container: workItem.containerName}).Do()\r\n\tif err := result.Error(); err != nil {\r\n\t\tc.handleErr(err, workItem)\r\n\t\treturn true\r\n\t}\r\n\t\r\n\tlog, _ := result.Raw()\r\n\tvar target string\r\n\tif workItem.podName == workItem.prowJobId {\r\n\t\ttarget = path.Join(ContainerLogDir, fmt.Sprintf(\"%s.txt\", workItem.containerName))\r\n\t} else {\r\n\t\ttarget = path.Join(ContainerLogDir, workItem.podName, fmt.Sprintf(\"%s.txt\", workItem.containerName))\r\n\t}\r\n\tdata := gcs.DataUpload(bytes.NewReader(log))\r\n\tif err := c.gcsConfig.Run(&spec, map[string]gcs.UploadFunc{target: data}); err != nil {\r\n\t\tc.handleErr(err, workItem)\r\n\t\treturn true\r\n\t}\r\n\tc.queue.Forget(key)\r\n\treturn true\r\n}","code-length":455,"reference":"\/\/ processNextItem attempts to upload container logs to GCS","result":"Process the work item.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) handleErr(err error, key item) {\r\n\tif c.queue.NumRequeues(key) < 5 {\r\n\t\tglog.Infof(\"Error uploading logs for container %v in pod %v: %v\", key.containerName, key.podName, err)\r\n\t\tc.queue.AddRateLimited(key)\r\n\t\treturn\r\n\t}\r\n\tc.queue.Forget(key)\r\n\tglog.Infof(\"Giving up on upload of logs for container %v in pod %v: %v\", key.containerName, key.podName, err)\r\n}","code-length":157,"reference":"\/\/ handleErr checks if an error happened and makes sure we will retry later.","result":"Handle errors in the controller.","score":[0,0.0382]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AggregateFilter(filters []Filter) Filter {\r\n\treturn func(presubmit config.Presubmit) (bool, bool, bool) {\r\n\t\tfor _, filter := range filters {\r\n\t\t\tif shouldRun, forced, defaults := filter(presubmit); shouldRun {\r\n\t\t\t\treturn shouldRun, forced, defaults\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn false, false, false\r\n\t}\r\n}","code-length":113,"reference":"\/\/ AggregateFilter builds a filter that evaluates the child filters in order\n\/\/ and returns the first match","result":"Aggregate filters.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FilterPresubmits(filter Filter, changes config.ChangedFilesProvider, branch string, presubmits []config.Presubmit, logger *logrus.Entry) ([]config.Presubmit, []config.Presubmit, error) {\r\n\tvar toTrigger []config.Presubmit\r\n\tvar toSkip []config.Presubmit\r\n\tfor _, presubmit := range presubmits {\r\n\t\tmatches, forced, defaults := filter(presubmit)\r\n\t\tif !matches {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tshouldRun, err := presubmit.ShouldRun(branch, changes, forced, defaults)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, nil, err\r\n\t\t}\r\n\t\tif shouldRun {\r\n\t\t\ttoTrigger = append(toTrigger, presubmit)\r\n\t\t} else {\r\n\t\t\ttoSkip = append(toSkip, presubmit)\r\n\t\t}\r\n\t}\r\n\tlogger.WithFields(logrus.Fields{\"to-trigger\": toTrigger, \"to-skip\": toSkip}).Debugf(\"Filtered %d jobs, found %d to trigger and %d to skip.\", len(presubmits), len(toTrigger), len(toSkip))\r\n\treturn toTrigger, toSkip, nil\r\n}","code-length":318,"reference":"\/\/ FilterPresubmits determines which presubmits should run and which should be skipped\n\/\/ by evaluating the user-provided filter.","result":"Filter the presubmits.","score":[0.0028,0.0303]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MakeCommand() *cobra.Command {\r\n\tflags := &flags{}\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"filter [file]\",\r\n\t\tShort: \"Filters a Go coverage file.\",\r\n\t\tLong:  `Filters a Go coverage file, removing entries that do not match the given flags.`,\r\n\t\tRun: func(cmd *cobra.Command, args []string) {\r\n\t\t\trun(flags, cmd, args)\r\n\t\t},\r\n\t}\r\n\tcmd.Flags().StringVarP(&flags.OutputFile, \"output\", \"o\", \"-\", \"output file\")\r\n\tcmd.Flags().StringSliceVar(&flags.IncludePaths, \"include-path\", nil, \"If specified at least once, only files with paths matching one of these regexes are included.\")\r\n\tcmd.Flags().StringSliceVar(&flags.ExcludePaths, \"exclude-path\", nil, \"Files with paths matching one of these regexes are excluded. Can be used repeatedly.\")\r\n\treturn cmd\r\n}","code-length":257,"reference":"\/\/ MakeCommand returns a `filter` command.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *EventTimeHeap) Push(x interface{}) {\r\n\t*t = append(*t, x.(sql.IssueEvent))\r\n}","code-length":45,"reference":"\/\/ Push adds event to the heap","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *EventTimeHeap) Pop() interface{} {\r\n\told := *t\r\n\tn := len(old)\r\n\tx := old[n-1]\r\n\t*t = old[0 : n-1]\r\n\treturn x\r\n}","code-length":71,"reference":"\/\/ Pop retrieves the last added event","result":"Avoid recursion.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFakeOpenPluginWrapper(plugin Plugin) *FakeOpenPluginWrapper {\r\n\treturn &FakeOpenPluginWrapper{\r\n\t\tplugin:      plugin,\r\n\t\talreadyOpen: map[string]bool{},\r\n\t}\r\n}","code-length":65,"reference":"\/\/ NewFakeOpenPluginWrapper is the constructor for FakeOpenPluginWrapper","result":"Wrap plugin .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *FakeOpenPluginWrapper) ReceiveIssue(issue sql.Issue) []Point {\r\n\tif _, ok := o.alreadyOpen[issue.ID]; !ok {\r\n\t\t\r\n\t\theap.Push(&o.openEvents, sql.IssueEvent{\r\n\t\t\tEvent:          \"opened\",\r\n\t\t\tIssueID:        issue.ID,\r\n\t\t\tActor:          &issue.User,\r\n\t\t\tEventCreatedAt: issue.IssueCreatedAt,\r\n\t\t})\r\n\t\to.alreadyOpen[issue.ID] = true\r\n\t}\r\n\treturn o.plugin.ReceiveIssue(issue)\r\n}","code-length":157,"reference":"\/\/ ReceiveIssue creates a fake \"opened\" event","result":"Test if the file contains a comment.","score":[0.1615,0.0714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *Options) Validate() error {\r\n\tif o.SrcRoot == \"\" {\r\n\t\treturn errors.New(\"no source root specified\")\r\n\t}\r\n\tif o.Log == \"\" {\r\n\t\treturn errors.New(\"no log file specified\")\r\n\t}\r\n\tif len(o.GitRefs) == 0 {\r\n\t\treturn errors.New(\"no refs specified to clone\")\r\n\t}\r\n\tseen := map[string]sets.String{}\r\n\tfor _, ref := range o.GitRefs {\r\n\t\tif _, seenOrg := seen[ref.Org]; seenOrg {\r\n\t\t\tif seen[ref.Org].Has(ref.Repo) {\r\n\t\t\t\treturn errors.New(\"sync config for %s\/%s provided more than once\")\r\n\t\t\t}\r\n\t\t\tseen[ref.Org].Insert(ref.Repo)\r\n\t\t} else {\r\n\t\t\tseen[ref.Org] = sets.NewString(ref.Repo)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":259,"reference":"\/\/ Validate ensures that the configuration options are valid","result":"Validate the options.","score":[0.0657,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *Options) Complete(args []string) {\r\n\to.GitRefs = o.refs.gitRefs\r\n\to.KeyFiles = o.keys.data\r\n\tfor _, ref := range o.GitRefs {\r\n\t\talias, err := o.clonePath.Execute(OrgRepo{Org: ref.Org, Repo: ref.Repo})\r\n\t\tif err != nil {\r\n\t\t\tpanic(err)\r\n\t\t}\r\n\t\tref.PathAlias = alias\r\n\t\talias, err = o.cloneURI.Execute(OrgRepo{Org: ref.Org, Repo: ref.Repo})\r\n\t\tif err != nil {\r\n\t\t\tpanic(err)\r\n\t\t}\r\n\t\tref.CloneURI = alias\r\n\t}\r\n}","code-length":196,"reference":"\/\/ Complete internalizes command line arguments","result":"Complete the command.","score":[0.1502,0.0877]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *orgRepoFormat) Set(value string) error {\r\n\ttempl, err := template.New(\"format\").Parse(value)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ta.raw = value\r\n\ta.format = templ\r\n\treturn nil\r\n}","code-length":83,"reference":"\/\/ Set parses out overrides from user input","result":"Set the format of the org.","score":[0.1383,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ensure(binary, install string) error {\r\n\tif _, err := exec.LookPath(binary); err != nil {\r\n\t\treturn fmt.Errorf(\"%s: %s\", binary, install)\r\n\t}\r\n\treturn nil\r\n}","code-length":68,"reference":"\/\/ ensure will ensure binary is on path or return an error with install message.","result":"Ensure the binary is installed.","score":[0.046,0.1825]}
{"code":"\/*is used to<extra_id_0>\r\nfunc output(args ...string) (string, error) {\r\n\tcmd := exec.Command(args[0], args[1:]...)\r\n\tcmd.Stderr = os.Stderr\r\n\tcmd.Stdin = os.Stdin\r\n\tb, err := cmd.Output()\r\n\treturn strings.TrimSpace(string(b)), err\r\n}","code-length":91,"reference":"\/\/ output returns the trimmed output of running args, or an err on non-zero exit.","result":"Output to stdout.","score":[0,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc projects(max int) ([]string, error) {\r\n\tout, err := output(\"gcloud\", \"projects\", \"list\", fmt.Sprintf(\"--limit=%d\", max), \"--format=value(project_id)\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn strings.Split(out, \"\\n\"), nil\r\n}","code-length":100,"reference":"\/\/ projects returns the list of accessible gcp projects","result":"Get the list of projects in the cloud provider.","score":[0.2697,0.3507]}
{"code":"\/*is used to<extra_id_0>\r\nfunc selectProject(choice string) (string, error) {\r\n\tfmt.Print(\"Getting active GCP account...\")\r\n\twho, err := currentAccount()\r\n\tif err != nil {\r\n\t\tlogrus.Warn(\"Run gcloud auth login to initialize gcloud\")\r\n\t\treturn \"\", err\r\n\t}\r\n\tfmt.Println(who)\r\n\tvar projs []string\r\n\tif choice == \"\" {\r\n\t\tfmt.Printf(\"Projects available to %s:\", who)\r\n\t\tfmt.Println()\r\n\t\tconst max = 20\r\n\t\tprojs, err = projects(max)\r\n\t\tfor _, proj := range projs {\r\n\t\t\tfmt.Println(\"  *\", proj)\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"list projects: %v\", err)\r\n\t\t}\r\n\t\tif len(projs) == 0 {\r\n\t\t\tfmt.Println(\"Create a project at https:\r\n\t\t\treturn \"\", errors.New(\"no projects\")\r\n\t\t}\r\n\t\tif len(projs) == max {\r\n\t\t\tfmt.Println(\"  ... Wow, that is a lot of projects!\")\r\n\t\t\tfmt.Println(\"Type the name of any project, including ones not in this truncated list\")\r\n\t\t}\r\n\t\tdef, err := currentProject()\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"get current project: %v\", err)\r\n\t\t}\r\n\t\tfmt.Printf(\"Select project [%s]: \", def)\r\n\t\tfmt.Scanln(&choice)\r\n\t\t\r\n\t\tif choice == \"\" {\r\n\t\t\treturn def, nil\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor _, p := range projs {\r\n\t\tif p == choice {\r\n\t\t\treturn choice, nil\r\n\t\t}\r\n\t}\r\n\tfmt.Printf(\"Ensuring %s has access to %s...\", who, choice)\r\n\tfmt.Println()\r\n\t\r\n\tif err = exec.Command(\"gcloud\", \"projects\", \"describe\", choice).Run(); err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"%s cannot describe project: %v\", who, err)\r\n\t}\r\n\treturn choice, nil\r\n}","code-length":572,"reference":"\/\/ selectProject returns the user-selected project, defaulting to the current gcloud one.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc createCluster(proj, choice string) (*cluster, error) {\r\n\tconst def = \"prow\"\r\n\tif choice == \"\" {\r\n\t\tfmt.Printf(\"Cluster name [%s]: \", def)\r\n\t\tfmt.Scanln(&choice)\r\n\t\tif choice == \"\" {\r\n\t\t\tchoice = def\r\n\t\t}\r\n\t}\r\n\tcmd := exec.Command(\"gcloud\", \"container\", \"clusters\", \"create\", choice)\r\n\tcmd.Stdin = os.Stdin\r\n\tcmd.Stdout = os.Stdout\r\n\tcmd.Stderr = os.Stderr\r\n\tif err := cmd.Run(); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"create cluster: %v\", err)\r\n\t}\r\n\tout, err := output(\"gcloud\", \"container\", \"clusters\", \"describe\", choice, \"--format=value(name,zone)\")\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"describe cluster: %v\", err)\r\n\t}\r\n\tparts := strings.Split(out, \"\\t\")\r\n\tif len(parts) != 2 {\r\n\t\treturn nil, fmt.Errorf(\"bad describe cluster output: %s\", out)\r\n\t}\r\n\treturn &cluster{name: parts[0], zone: parts[1], project: proj}, nil\r\n}","code-length":329,"reference":"\/\/ createCluster causes gcloud to create a cluster in project, returning the context name","result":"Create a cluster in the cloud .","score":[0.1315,0.3639]}
{"code":"\/*is used to<extra_id_0>\r\nfunc createContext(co contextOptions) (string, error) {\r\n\tproj, err := selectProject(co.project)\r\n\tif err != nil {\r\n\t\tlogrus.Info(\"Run gcloud auth login to initialize gcloud\")\r\n\t\treturn \"\", fmt.Errorf(\"get current project: %v\", err)\r\n\t}\r\n\tfmt.Printf(\"Existing GKE clusters in %s:\", proj)\r\n\tfmt.Println()\r\n\tclusters, err := currentClusters(proj)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"list %s clusters: %v\", proj, err)\r\n\t}\r\n\tfor name := range clusters {\r\n\t\tfmt.Println(\"  *\", name)\r\n\t}\r\n\tif len(clusters) == 0 {\r\n\t\tfmt.Println(\"  No clusters\")\r\n\t}\r\n\tvar choice string\r\n\tcreate := co.create\r\n\treuse := co.reuse\r\n\tswitch {\r\n\tcase create != \"\" && reuse != \"\":\r\n\t\treturn \"\", errors.New(\"Cannot use both --create and --reuse\")\r\n\tcase create != \"\":\r\n\t\tfmt.Println(\"Creating new \" + create + \" cluster...\")\r\n\t\tchoice = \"new\"\r\n\tcase reuse != \"\":\r\n\t\tfmt.Println(\"Reusing existing \" + reuse + \" cluster...\")\r\n\t\tchoice = reuse\r\n\tdefault:\r\n\t\tfmt.Print(\"Get credentials for existing cluster or [create new]: \")\r\n\t\tfmt.Scanln(&choice)\r\n\t}\r\n\tif choice == \"\" || choice == \"new\" {\r\n\t\tcluster, err := createCluster(proj, create)\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"create cluster in %s: %v\", proj, err)\r\n\t\t}\r\n\t\treturn cluster.context(), nil\r\n\t}\r\n\tcluster, ok := clusters[choice]\r\n\tif !ok {\r\n\t\treturn \"\", fmt.Errorf(\"cluster not found: %s\", choice)\r\n\t}\r\n\tcmd := exec.Command(\"gcloud\", \"container\", \"clusters\", \"get-credentials\", cluster.name, \"--project=\"+cluster.project, \"--zone=\"+cluster.zone)\r\n\tcmd.Stdin = os.Stdin\r\n\tcmd.Stdout = os.Stdout\r\n\tcmd.Stderr = os.Stderr\r\n\tif err := cmd.Run(); err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"get credentials: %v\", err)\r\n\t}\r\n\treturn cluster.context(), nil\r\n}","code-length":630,"reference":"\/\/ createContext has the user create a context.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc contextConfig() (clientcmd.ClientConfigLoader, *clientcmdapi.Config, error) {\r\n\tif err := ensureKubectl(); err != nil {\r\n\t\tfmt.Println(\"Prow's tackler requires kubectl, please install:\")\r\n\t\tfmt.Println(\"  *\", err)\r\n\t\tif gerr := ensureGcloud(); gerr != nil {\r\n\t\t\tfmt.Println(\"  *\", gerr)\r\n\t\t}\r\n\t\treturn nil, nil, errors.New(\"missing kubectl\")\r\n\t}\r\n\tl := clientcmd.NewDefaultClientConfigLoadingRules()\r\n\tc, err := l.Load()\r\n\treturn l, c, err\r\n}","code-length":179,"reference":"\/\/ contextConfig returns the loader and config, which can create a clientconfig.","result":"Create a context config.","score":[0.0432,0.1674]}
{"code":"\/*is used to<extra_id_0>\r\nfunc selectContext(co contextOptions) (string, error) {\r\n\tfmt.Println(\"Existing kubernetes contexts:\")\r\n\t\r\n\t_, cfg, err := contextConfig()\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Fatal(\"Failed to load ~\/.kube\/config from any obvious location\")\r\n\t}\r\n\t\r\n\toptions := map[int]string{}\r\n\tvar ctxs []string\r\n\tfor ctx := range cfg.Contexts {\r\n\t\tctxs = append(ctxs, ctx)\r\n\t}\r\n\tsort.Strings(ctxs)\r\n\tfor idx, ctx := range ctxs {\r\n\t\toptions[idx] = ctx\r\n\t\tif ctx == cfg.CurrentContext {\r\n\t\t\tfmt.Printf(\"* %d: %s (current)\", idx, ctx)\r\n\t\t} else {\r\n\t\t\tfmt.Printf(\"  %d: %s\", idx, ctx)\r\n\t\t}\r\n\t\tfmt.Println()\r\n\t}\r\n\tfmt.Println()\r\n\tchoice := co.context\r\n\tswitch {\r\n\tcase choice != \"\":\r\n\t\tfmt.Println(\"Reuse \" + choice + \" context...\")\r\n\tcase co.create != \"\" || co.reuse != \"\":\r\n\t\tchoice = \"create\"\r\n\t\tfmt.Println(\"Create new context...\")\r\n\tdefault:\r\n\t\tfmt.Print(\"Choose context or [create new]: \")\r\n\t\tfmt.Scanln(&choice)\r\n\t}\r\n\tif choice == \"create\" || choice == \"\" || choice == \"create new\" || choice == \"new\" {\r\n\t\tctx, err := createContext(co)\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"create context: %v\", err)\r\n\t\t}\r\n\t\treturn ctx, nil\r\n\t}\r\n\tif _, ok := cfg.Contexts[choice]; ok {\r\n\t\treturn choice, nil\r\n\t}\r\n\tidx, err := strconv.Atoi(choice)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"invalid context: %q\", choice)\r\n\t}\r\n\tif ctx, ok := options[idx]; ok {\r\n\t\treturn ctx, nil\r\n\t}\r\n\treturn \"\", fmt.Errorf(\"invalid index: %d\", idx)\r\n}","code-length":577,"reference":"\/\/ selectContext allows the user to choose a context\n\/\/ This may involve creating a cluster","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc applyCreate(ctx string, args ...string) error {\r\n\tcreate := exec.Command(\"kubectl\", append([]string{\"--dry-run=true\", \"--output=yaml\", \"create\"}, args...)...)\r\n\tcreate.Stderr = os.Stderr\r\n\tobj, err := create.StdoutPipe()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"rolebinding pipe: %v\", err)\r\n\t}\r\n\tif err := create.Start(); err != nil {\r\n\t\treturn fmt.Errorf(\"start create: %v\", err)\r\n\t}\r\n\tif err := apply(ctx, obj); err != nil {\r\n\t\treturn fmt.Errorf(\"apply: %v\", err)\r\n\t}\r\n\tif err := create.Wait(); err != nil {\r\n\t\treturn fmt.Errorf(\"create: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":224,"reference":"\/\/ applyCreate will dry-run create and then pipe this to kubectl apply.\n\/\/\n\/\/ If we use the create verb it will fail if the secret already exists.\n\/\/ And kubectl will reject the apply verb with a secret.","result":"Apply rolebindings to a rolebinding.","score":[0.0003,0.0421]}
{"code":"\/*is used to<extra_id_0>\r\nfunc determineSkippedPresubmits(toTrigger, toSkipSuperset []config.Presubmit, logger *logrus.Entry) []config.Presubmit {\r\n\ttriggeredContexts := sets.NewString()\r\n\tfor _, presubmit := range toTrigger {\r\n\t\ttriggeredContexts.Insert(presubmit.Context)\r\n\t}\r\n\tvar toSkip []config.Presubmit\r\n\tfor _, presubmit := range toSkipSuperset {\r\n\t\tif triggeredContexts.Has(presubmit.Context) {\r\n\t\t\tlogger.WithFields(logrus.Fields{\"context\": presubmit.Context, \"job\": presubmit.Name}).Debug(\"Not skipping job as context will be created by a triggered job.\")\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\ttoSkip = append(toSkip, presubmit)\r\n\t}\r\n\treturn toSkip\r\n}","code-length":222,"reference":"\/\/ determineSkippedPresubmits identifies the largest set of contexts we can actually\n\/\/ post skipped contexts for, given a set of presubmits we're triggering. We don't\n\/\/ want to skip a job that posts a context that will be written to by a job we just\n\/\/ identified for triggering or the skipped context will override the triggered one","result":"Determine skipped presubmits.","score":[0.0,0.0095]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Dispatch(plugin plugins.Plugin, DB *InfluxDB, issues chan sql.Issue, eventsCommentsChannel chan interface{}) {\r\n\tfor {\r\n\t\tvar points []plugins.Point\r\n\t\tselect {\r\n\t\tcase issue, ok := <-issues:\r\n\t\t\tif !ok {\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tpoints = plugin.ReceiveIssue(issue)\r\n\t\tcase event, ok := <-eventsCommentsChannel:\r\n\t\t\tif !ok {\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tswitch event := event.(type) {\r\n\t\t\tcase sql.IssueEvent:\r\n\t\t\t\tpoints = plugin.ReceiveIssueEvent(event)\r\n\t\t\tcase sql.Comment:\r\n\t\t\t\tpoints = plugin.ReceiveComment(event)\r\n\t\t\tdefault:\r\n\t\t\t\tglog.Fatal(\"Received invalid object: \", event)\r\n\t\t\t}\r\n\t\t}\r\n\t\tfor _, point := range points {\r\n\t\t\tif err := DB.Push(point.Tags, point.Values, point.Date); err != nil {\r\n\t\t\t\tglog.Fatal(\"Failed to push point: \", err)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":297,"reference":"\/\/ Dispatch receives channels to each type of events, and dispatch them to each plugins.","result":"Dispatch events to the InfluxDB .","score":[0.0512,0.0709]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) CreateIssue(org, repo, title, body string, labels, assignees []string) (*github.Issue, error) {\r\n\tglog.Infof(\"CreateIssue(dry=%t) Title:%q, Labels:%q, Assignees:%q\\n\", c.dryRun, title, labels, assignees)\r\n\tif c.dryRun {\r\n\t\treturn nil, nil\r\n\t}\r\n\tissue := &github.IssueRequest{\r\n\t\tTitle: &title,\r\n\t\tBody:  &body,\r\n\t}\r\n\tif len(labels) > 0 {\r\n\t\tissue.Labels = &labels\r\n\t}\r\n\tif len(assignees) > 0 {\r\n\t\tissue.Assignees = &assignees\r\n\t}\r\n\tvar result *github.Issue\r\n\t_, err := c.retry(\r\n\t\tfmt.Sprintf(\"creating issue '%s'\", title),\r\n\t\tfunc() (*github.Response, error) {\r\n\t\t\tvar resp *github.Response\r\n\t\t\tvar err error\r\n\t\t\tresult, resp, err = c.issueService.Create(context.Background(), org, repo, issue)\r\n\t\t\treturn resp, err\r\n\t\t},\r\n\t)\r\n\treturn result, err\r\n}","code-length":317,"reference":"\/\/ CreateIssue tries to create and return a new github issue.","result":"Create a new issue.","score":[0.0869,0.3064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) CreateStatus(owner, repo, ref string, status *github.RepoStatus) (*github.RepoStatus, error) {\r\n\tglog.Infof(\"CreateStatus(dry=%t) ref:%s: %s:%s\", c.dryRun, ref, *status.Context, *status.State)\r\n\tif c.dryRun {\r\n\t\treturn nil, nil\r\n\t}\r\n\tvar result *github.RepoStatus\r\n\tmsg := fmt.Sprintf(\"creating status for ref '%s'\", ref)\r\n\t_, err := c.retry(msg, func() (*github.Response, error) {\r\n\t\tvar resp *github.Response\r\n\t\tvar err error\r\n\t\tresult, resp, err = c.repoService.CreateStatus(context.Background(), owner, repo, ref, status)\r\n\t\treturn resp, err\r\n\t})\r\n\treturn result, err\r\n}","code-length":228,"reference":"\/\/ CreateStatus creates or updates a status context on the indicated reference.","result":"Create a new repo status.","score":[0.0593,0.0885]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) ForEachPR(owner, repo string, opts *github.PullRequestListOptions, continueOnError bool, mungePR PRMungeFunc) error {\r\n\tvar lastPage int\r\n\t\r\n\t\r\n\t\r\n\t_, err := c.depaginate(\r\n\t\t\"processing PRs\",\r\n\t\t&opts.ListOptions,\r\n\t\tfunc() ([]interface{}, *github.Response, error) {\r\n\t\t\tlist, resp, err := c.prService.List(context.Background(), owner, repo, opts)\r\n\t\t\tif err == nil {\r\n\t\t\t\tfor _, pr := range list {\r\n\t\t\t\t\tif pr == nil {\r\n\t\t\t\t\t\tglog.Errorln(\"Received a nil PR from go-github while listing PRs. Skipping...\")\r\n\t\t\t\t\t}\r\n\t\t\t\t\tif mungeErr := mungePR(pr); mungeErr != nil {\r\n\t\t\t\t\t\tif pr.Number == nil {\r\n\t\t\t\t\t\t\tmungeErr = fmt.Errorf(\"error munging pull request with nil Number field: %v\", mungeErr)\r\n\t\t\t\t\t\t} else {\r\n\t\t\t\t\t\t\tmungeErr = fmt.Errorf(\"error munging pull request #%d: %v\", *pr.Number, mungeErr)\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\tif !continueOnError {\r\n\t\t\t\t\t\t\treturn nil, resp, &retryAbort{mungeErr}\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\tglog.Errorf(\"%v\\n\", mungeErr)\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t\tif resp.LastPage > 0 {\r\n\t\t\t\t\tlastPage = resp.LastPage\r\n\t\t\t\t}\r\n\t\t\t\tglog.Infof(\"ForEachPR processed page %d\/%d\\n\", opts.ListOptions.Page, lastPage)\r\n\t\t\t}\r\n\t\t\treturn nil, resp, err\r\n\t\t},\r\n\t)\r\n\treturn err\r\n}","code-length":456,"reference":"\/\/ ForEachPR iterates over all PRs that fit the specified criteria, calling the munge function on every PR.\n\/\/ If the munge function returns a non-nil error, ForEachPR will return immediately with a non-nil\n\/\/ error unless continueOnError is true in which case an error will be logged and the remaining PRs will be munged.","result":"Get the list of pull requests from github.","score":[0.0004,0.0099]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) GetCollaborators(org, repo string) ([]*github.User, error) {\r\n\topts := &github.ListCollaboratorsOptions{}\r\n\tcollaborators, err := c.depaginate(\r\n\t\tfmt.Sprintf(\"getting collaborators for '%s\/%s'\", org, repo),\r\n\t\t&opts.ListOptions,\r\n\t\tfunc() ([]interface{}, *github.Response, error) {\r\n\t\t\tpage, resp, err := c.repoService.ListCollaborators(context.Background(), org, repo, opts)\r\n\t\t\tvar interfaceList []interface{}\r\n\t\t\tif err == nil {\r\n\t\t\t\tinterfaceList = make([]interface{}, 0, len(page))\r\n\t\t\t\tfor _, user := range page {\r\n\t\t\t\t\tinterfaceList = append(interfaceList, user)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn interfaceList, resp, err\r\n\t\t},\r\n\t)\r\n\tresult := make([]*github.User, 0, len(collaborators))\r\n\tfor _, user := range collaborators {\r\n\t\tresult = append(result, user.(*github.User))\r\n\t}\r\n\treturn result, err\r\n}","code-length":299,"reference":"\/\/ GetCollaborators returns all github users who are members or outside collaborators of the repo.","result":"Get the list of collaborators for a given repo.","score":[0.0885,0.1736]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) GetCombinedStatus(owner, repo, ref string) (*github.CombinedStatus, error) {\r\n\tvar result *github.CombinedStatus\r\n\tlistOpts := &github.ListOptions{}\r\n\tstatuses, err := c.depaginate(\r\n\t\tfmt.Sprintf(\"getting combined status for ref '%s'\", ref),\r\n\t\tlistOpts,\r\n\t\tfunc() ([]interface{}, *github.Response, error) {\r\n\t\t\tcombined, resp, err := c.repoService.GetCombinedStatus(\r\n\t\t\t\tcontext.Background(),\r\n\t\t\t\towner,\r\n\t\t\t\trepo,\r\n\t\t\t\tref,\r\n\t\t\t\tlistOpts,\r\n\t\t\t)\r\n\t\t\tif result == nil {\r\n\t\t\t\tresult = combined\r\n\t\t\t}\r\n\t\t\tvar interfaceList []interface{}\r\n\t\t\tif err == nil {\r\n\t\t\t\tinterfaceList = make([]interface{}, 0, len(combined.Statuses))\r\n\t\t\t\tfor _, status := range combined.Statuses {\r\n\t\t\t\t\tinterfaceList = append(interfaceList, status)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn interfaceList, resp, err\r\n\t\t},\r\n\t)\r\n\tif result != nil {\r\n\t\tresult.Statuses = make([]github.RepoStatus, 0, len(statuses))\r\n\t\tfor _, status := range statuses {\r\n\t\t\tresult.Statuses = append(result.Statuses, status.(github.RepoStatus))\r\n\t\t}\r\n\t}\r\n\treturn result, err\r\n}","code-length":376,"reference":"\/\/ GetCombinedStatus retrieves the CombinedStatus for the specified reference.","result":"Get the combined status of a repo.","score":[0.1214,0.0568]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) GetIssues(org, repo string, opts *github.IssueListByRepoOptions) ([]*github.Issue, error) {\r\n\tissues, err := c.depaginate(\r\n\t\tfmt.Sprintf(\"getting issues from '%s\/%s'\", org, repo),\r\n\t\t&opts.ListOptions,\r\n\t\tfunc() ([]interface{}, *github.Response, error) {\r\n\t\t\tpage, resp, err := c.issueService.ListByRepo(context.Background(), org, repo, opts)\r\n\t\t\tvar interfaceList []interface{}\r\n\t\t\tif err == nil {\r\n\t\t\t\tinterfaceList = make([]interface{}, 0, len(page))\r\n\t\t\t\tfor _, issue := range page {\r\n\t\t\t\t\tinterfaceList = append(interfaceList, issue)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn interfaceList, resp, err\r\n\t\t},\r\n\t)\r\n\tresult := make([]*github.Issue, 0, len(issues))\r\n\tfor _, issue := range issues {\r\n\t\tresult = append(result, issue.(*github.Issue))\r\n\t}\r\n\treturn result, err\r\n}","code-length":289,"reference":"\/\/ GetIssues gets all the issues in a repo that meet the list options.","result":"List all issues in a repo.","score":[0.1126,0.3379]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) GetRepoLabels(org, repo string) ([]*github.Label, error) {\r\n\topts := &github.ListOptions{}\r\n\tlabels, err := c.depaginate(\r\n\t\tfmt.Sprintf(\"getting valid labels for '%s\/%s'\", org, repo),\r\n\t\topts,\r\n\t\tfunc() ([]interface{}, *github.Response, error) {\r\n\t\t\tpage, resp, err := c.issueService.ListLabels(context.Background(), org, repo, opts)\r\n\t\t\tvar interfaceList []interface{}\r\n\t\t\tif err == nil {\r\n\t\t\t\tinterfaceList = make([]interface{}, 0, len(page))\r\n\t\t\t\tfor _, label := range page {\r\n\t\t\t\t\tinterfaceList = append(interfaceList, label)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn interfaceList, resp, err\r\n\t\t},\r\n\t)\r\n\tresult := make([]*github.Label, 0, len(labels))\r\n\tfor _, label := range labels {\r\n\t\tresult = append(result, label.(*github.Label))\r\n\t}\r\n\treturn result, err\r\n}","code-length":287,"reference":"\/\/ GetRepoLabels gets all the labels that valid in the specified repo.","result":"Get all labels for a given repository.","score":[0.094,0.2222]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) GetUser(login string) (*github.User, error) {\r\n\tvar result *github.User\r\n\t_, err := c.retry(\r\n\t\tfmt.Sprintf(\"getting user '%s'\", login),\r\n\t\tfunc() (*github.Response, error) {\r\n\t\t\tvar resp *github.Response\r\n\t\t\tvar err error\r\n\t\t\tresult, resp, err = c.userService.Get(context.Background(), login)\r\n\t\t\treturn resp, err\r\n\t\t},\r\n\t)\r\n\treturn result, err\r\n}","code-length":149,"reference":"\/\/ GetUser gets the github user with the specified login or the currently authenticated user.\n\/\/ To get the currently authenticated user specify a login of \"\".","result":"Get the user.","score":[0.0002,0.1039]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkConfigValidity() error {\r\n\tglog.Info(\"Verifying if a valid config has been provided through the flags\")\r\n\tif *nodeName == \"\" {\r\n\t\treturn fmt.Errorf(\"Flag --node-name has its value unspecified\")\r\n\t}\r\n\tif *gcsPath == \"\" {\r\n\t\treturn fmt.Errorf(\"Flag --gcs-path has its value unspecified\")\r\n\t}\r\n\tif _, err := os.Stat(*gcloudAuthFilePath); err != nil {\r\n\t\treturn fmt.Errorf(\"Could not find the gcloud service account file: %v\", err)\r\n\t} else {\r\n\t\tglog.Infof(\"Running gcloud auth activate-service-account --key-file=%s\\n\", *gcloudAuthFilePath)\r\n\t\tcmd := exec.Command(\"gcloud\", \"auth\", \"activate-service-account\", \"--key-file=\"+*gcloudAuthFilePath)\r\n\t\tvar stderr, stdout bytes.Buffer\r\n\t\tcmd.Stderr, cmd.Stdout = &stderr, &stdout\r\n\t\terr = cmd.Run()\r\n\t\tglog.Infof(\"Stdout:\\n%s\\n\", stdout.String())\r\n\t\tglog.Infof(\"Stderr:\\n%s\\n\", stderr.String())\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"Failed to activate gcloud service account: %v\", err)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":355,"reference":"\/\/ Check if the config provided through the flags take valid values.","result":"Check if a config is valid.","score":[0.1112,0.2242]}
{"code":"\/*is used to<extra_id_0>\r\nfunc createSystemdLogfile(service string, outputMode string, outputDir string) error {\r\n\t\r\n\tjournalCmdArgs := []string{fmt.Sprintf(\"--output=%v\", outputMode), \"-D\", *journalPath}\r\n\tif service == \"kern\" {\r\n\t\tjournalCmdArgs = append(journalCmdArgs, \"-k\")\r\n\t} else {\r\n\t\tjournalCmdArgs = append(journalCmdArgs, \"-u\", fmt.Sprintf(\"%v.service\", service))\r\n\t}\r\n\tcmd := exec.Command(\"journalctl\", journalCmdArgs...)\r\n\t\r\n\toutput, err := cmd.Output()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"Journalctl command for '%v' service failed: %v\", service, err)\r\n\t}\r\n\tlogfile := filepath.Join(outputDir, service+\".log\")\r\n\tif err := ioutil.WriteFile(logfile, output, 0444); err != nil {\r\n\t\treturn fmt.Errorf(\"Writing to file of journalctl logs for '%v' service failed: %v\", service, err)\r\n\t}\r\n\treturn nil\r\n}","code-length":277,"reference":"\/\/ Create logfile for systemd service in outputDir with the given journalctl outputMode.","result":"Create a log file for systemd.","score":[0.0715,0.0813]}
{"code":"\/*is used to<extra_id_0>\r\nfunc createFullSystemdLogfile(outputDir string) error {\r\n\tcmd := exec.Command(\"journalctl\", \"--output=short-precise\", \"-D\", *journalPath)\r\n\t\r\n\toutput, err := cmd.Output()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"Journalctl command failed: %v\", err)\r\n\t}\r\n\tlogfile := filepath.Join(outputDir, \"systemd.log\")\r\n\tif err := ioutil.WriteFile(logfile, output, 0444); err != nil {\r\n\t\treturn fmt.Errorf(\"Writing full journalctl logs to file failed: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":171,"reference":"\/\/ createFullSystemdLogfile creates logfile for full systemd journal in the outputDir.","result":"Create a log file for systemd.","score":[0.0839,0.0952]}
{"code":"\/*is used to<extra_id_0>\r\nfunc createSystemdLogfiles(outputDir string) {\r\n\tservices := append(systemdServices, nodeSystemdServices...)\r\n\tfor _, service := range services {\r\n\t\tif err := createSystemdLogfile(service, \"cat\", outputDir); err != nil {\r\n\t\t\tglog.Warningf(\"Failed to record journalctl logs: %v\", err)\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor _, service := range systemdSetupServices {\r\n\t\tif err := createSystemdLogfile(service, \"short-precise\", outputDir); err != nil {\r\n\t\t\tglog.Warningf(\"Failed to record journalctl logs: %v\", err)\r\n\t\t}\r\n\t}\r\n\tif *dumpSystemdJournal {\r\n\t\tif err := createFullSystemdLogfile(outputDir); err != nil {\r\n\t\t\tglog.Warningf(\"Failed to record journalctl logs: %v\", err)\r\n\t\t}\r\n\t}\r\n}","code-length":242,"reference":"\/\/ Create logfiles for systemd services in outputDir.","result":"Create systemd logfiles.","score":[0.0917,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc prepareLogfiles(logDir string) {\r\n\tglog.Info(\"Preparing logfiles relevant to this node\")\r\n\tlogfiles := nodeLogs[:]\r\n\tswitch *cloudProvider {\r\n\tcase \"gce\", \"gke\":\r\n\t\tlogfiles = append(logfiles, gceLogs...)\r\n\tcase \"aws\":\r\n\t\tlogfiles = append(logfiles, awsLogs...)\r\n\tdefault:\r\n\t\tglog.Errorf(\"Unknown cloud provider '%v' provided, skipping any provider specific logs\", *cloudProvider)\r\n\t}\r\n\t\r\n\tif *enableHollowNodeLogs {\r\n\t\tlogfiles = append(logfiles, kubemarkLogs...)\r\n\t}\r\n\t\r\n\tif _, err := os.Stat(\"\/workspace\/etc\/systemd\/journald.conf\"); err == nil {\r\n\t\tglog.Info(\"Journalctl found on host. Collecting systemd logs\")\r\n\t\tcreateSystemdLogfiles(logDir)\r\n\t} else {\r\n\t\tglog.Infof(\"Journalctl not found on host (%v). Collecting supervisord logs instead\", err)\r\n\t\tlogfiles = append(logfiles, kernelLog)\r\n\t\tlogfiles = append(logfiles, initdLogs...)\r\n\t\tlogfiles = append(logfiles, supervisordLogs...)\r\n\t}\r\n\t\r\n\tfor _, logfile := range logfiles {\r\n\t\tlogfileFullPath := filepath.Join(localLogPath, logfile+\".log*\")\r\n\t\tcmd := exec.Command(\"\/bin\/sh\", \"-c\", fmt.Sprintf(\"cp %v %v\", logfileFullPath, logDir))\r\n\t\tif err := cmd.Run(); err != nil {\r\n\t\t\tglog.Warningf(\"Failed to copy any logfiles with pattern '%v': %v\", logfileFullPath, err)\r\n\t\t}\r\n\t}\r\n}","code-length":452,"reference":"\/\/ Copy logfiles specific to this node based on the cloud-provider, system services, etc\n\/\/ to a temporary directory. Also create logfiles for systemd services if journalctl is present.\n\/\/ We do not expect this function to see an error.","result":"Collect logfiles relevant to this node.","score":[0.001,0.041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc writeSuccessMarkerFile() error {\r\n\tmarkerFilePath := *gcsPath + \"\/logexported-nodes-registry\/\" + *nodeName + \".txt\"\r\n\tcmd := exec.Command(\"gsutil\", \"-q\", \"cp\", \"-a\", \"public-read\", \"-\", markerFilePath)\r\n\tstdin, err := cmd.StdinPipe()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"Failed to get stdin pipe to write marker file: %v\", err)\r\n\t}\r\n\tio.WriteString(stdin, \"\")\r\n\tstdin.Close()\r\n\tif err = cmd.Run(); err != nil {\r\n\t\treturn fmt.Errorf(\"Failed to write marker file to GCS: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":192,"reference":"\/\/ Write a marker file to GCS named after this node to indicate logexporter's success.\n\/\/ The directory to which we write this file can then be used as a registry to quickly\n\/\/ fetch the list of nodes on which logexporter succeeded.","result":"Write the success marker file to GCS.","score":[0.0022,0.0635]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MakeCommand() *cobra.Command {\r\n\tflags := &flags{}\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"junit [profile]\",\r\n\t\tShort: \"Summarize coverage profile and produce the result in junit xml format.\",\r\n\t\tLong: `Summarize coverage profile and produce the result in junit xml format.\r\nSummary done at per-file and per-package level. Any coverage below coverage-threshold will be marked\r\nwith a <failure> tag in the xml produced.`,\r\n\t\tRun: func(cmd *cobra.Command, args []string) {\r\n\t\t\trun(flags, cmd, args)\r\n\t\t},\r\n\t}\r\n\tcmd.Flags().StringVarP(&flags.outputFile, \"output\", \"o\", \"-\", \"output file\")\r\n\tcmd.Flags().Float32VarP(&flags.threshold, \"threshold\", \"t\", .8, \"code coverage threshold\")\r\n\treturn cmd\r\n}","code-length":244,"reference":"\/\/ MakeCommand returns a `junit` command.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc warnDeprecated(last *time.Time, freq time.Duration, msg string) {\r\n\t\r\n\twarnLock.RLock()\r\n\tfresh := time.Now().Sub(*last) <= freq\r\n\twarnLock.RUnlock()\r\n\tif fresh {\r\n\t\treturn\r\n\t}\r\n\t\r\n\twarnLock.Lock()\r\n\tdefer warnLock.Unlock()\r\n\tnow := time.Now()\r\n\tif now.Sub(*last) <= freq {\r\n\t\treturn\r\n\t}\r\n\t*last = now\r\n\tlogrus.Warn(msg)\r\n}","code-length":151,"reference":"\/\/ warnDeprecated prints a deprecation warning for a particular configuration\n\/\/ option.","result":"Warn deprecated functions.","score":[0,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r RequireMatchingLabel) Describe() string {\r\n\tstr := &strings.Builder{}\r\n\tfmt.Fprintf(str, \"Applies the '%s' label \", r.MissingLabel)\r\n\tif r.MissingComment == \"\" {\r\n\t\tfmt.Fprint(str, \"to \")\r\n\t} else {\r\n\t\tfmt.Fprint(str, \"and comments on \")\r\n\t}\r\n\tif r.Issues {\r\n\t\tfmt.Fprint(str, \"Issues \")\r\n\t\tif r.PRs {\r\n\t\t\tfmt.Fprint(str, \"and \")\r\n\t\t}\r\n\t}\r\n\tif r.PRs {\r\n\t\tif r.Branch != \"\" {\r\n\t\t\tfmt.Fprintf(str, \"'%s' branch \", r.Branch)\r\n\t\t}\r\n\t\tfmt.Fprint(str, \"PRs \")\r\n\t}\r\n\tif r.Repo == \"\" {\r\n\t\tfmt.Fprintf(str, \"in the '%s' GitHub org \", r.Org)\r\n\t} else {\r\n\t\tfmt.Fprintf(str, \"in the '%s\/%s' GitHub repo \", r.Org, r.Repo)\r\n\t}\r\n\tfmt.Fprintf(str, \"that have no labels matching the regular expression '%s'.\", r.Regexp)\r\n\treturn str.String()\r\n}","code-length":335,"reference":"\/\/ Describe generates a human readable description of the behavior that this\n\/\/ configuration specifies.","result":"Describe the required label.","score":[0.0243,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Configuration) TriggerFor(org, repo string) Trigger {\r\n\tfor _, tr := range c.Triggers {\r\n\t\tfor _, r := range tr.Repos {\r\n\t\t\tif r == org || r == fmt.Sprintf(\"%s\/%s\", org, repo) {\r\n\t\t\t\treturn tr\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn Trigger{}\r\n}","code-length":106,"reference":"\/\/ TriggerFor finds the Trigger for a repo, if one exists\n\/\/ a trigger can be listed for the repo itself or for the\n\/\/ owning organization","result":"Generate the code.","score":[0.0001,0.0203]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Configuration) EnabledReposForPlugin(plugin string) (orgs, repos []string) {\r\n\tfor repo, plugins := range c.Plugins {\r\n\t\tfound := false\r\n\t\tfor _, candidate := range plugins {\r\n\t\t\tif candidate == plugin {\r\n\t\t\t\tfound = true\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif found {\r\n\t\t\tif strings.Contains(repo, \"\/\") {\r\n\t\t\t\trepos = append(repos, repo)\r\n\t\t\t} else {\r\n\t\t\t\torgs = append(orgs, repo)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn\r\n}","code-length":170,"reference":"\/\/ EnabledReposForPlugin returns the orgs and repos that have enabled the passed plugin.","result":"Find enabled repos for a.","score":[0.0577,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Configuration) EnabledReposForExternalPlugin(plugin string) (orgs, repos []string) {\r\n\tfor repo, plugins := range c.ExternalPlugins {\r\n\t\tfound := false\r\n\t\tfor _, candidate := range plugins {\r\n\t\t\tif candidate.Name == plugin {\r\n\t\t\t\tfound = true\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif found {\r\n\t\t\tif strings.Contains(repo, \"\/\") {\r\n\t\t\t\trepos = append(repos, repo)\r\n\t\t\t} else {\r\n\t\t\t\torgs = append(orgs, repo)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn\r\n}","code-length":174,"reference":"\/\/ EnabledReposForExternalPlugin returns the orgs and repos that have enabled the passed\n\/\/ external plugin.","result":"Determine the enabled repos for.","score":[0.0428,0.1071]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ConfigUpdater) SetDefaults() {\r\n\tif len(c.Maps) == 0 {\r\n\t\tcf := c.ConfigFile\r\n\t\tif cf == \"\" {\r\n\t\t\tcf = \"prow\/config.yaml\"\r\n\t\t} else {\r\n\t\t\tlogrus.Warnf(`config_file is deprecated, please switch to \"maps\": {\"%s\": \"config\"} before July 2018`, cf)\r\n\t\t}\r\n\t\tpf := c.PluginFile\r\n\t\tif pf == \"\" {\r\n\t\t\tpf = \"prow\/plugins.yaml\"\r\n\t\t} else {\r\n\t\t\tlogrus.Warnf(`plugin_file is deprecated, please switch to \"maps\": {\"%s\": \"plugins\"} before July 2018`, pf)\r\n\t\t}\r\n\t\tc.Maps = map[string]ConfigMapSpec{\r\n\t\t\tcf: {\r\n\t\t\t\tName: \"config\",\r\n\t\t\t},\r\n\t\t\tpf: {\r\n\t\t\t\tName: \"plugins\",\r\n\t\t\t},\r\n\t\t}\r\n\t}\r\n\tfor name, spec := range c.Maps {\r\n\t\tspec.Namespaces = append([]string{spec.Namespace}, spec.AdditionalNamespaces...)\r\n\t\tc.Maps[name] = spec\r\n\t}\r\n}","code-length":320,"reference":"\/\/ SetDefaults sets default options for config updating","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc validatePlugins(plugins map[string][]string) error {\r\n\tvar errors []string\r\n\tfor _, configuration := range plugins {\r\n\t\tfor _, plugin := range configuration {\r\n\t\t\tif _, ok := pluginHelp[plugin]; !ok {\r\n\t\t\t\terrors = append(errors, fmt.Sprintf(\"unknown plugin: %s\", plugin))\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tfor repo, repoConfig := range plugins {\r\n\t\tif strings.Contains(repo, \"\/\") {\r\n\t\t\torg := strings.Split(repo, \"\/\")[0]\r\n\t\t\tif dupes := findDuplicatedPluginConfig(repoConfig, plugins[org]); len(dupes) > 0 {\r\n\t\t\t\terrors = append(errors, fmt.Sprintf(\"plugins %v are duplicated for %s and %s\", dupes, repo, org))\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif len(errors) > 0 {\r\n\t\treturn fmt.Errorf(\"invalid plugin configuration:\\n\\t%v\", strings.Join(errors, \"\\n\\t\"))\r\n\t}\r\n\treturn nil\r\n}","code-length":280,"reference":"\/\/ validatePlugins will return error if\n\/\/ there are unknown or duplicated plugins.","result":"Validate plugins configuration.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) ShouldReport(pj *v1.ProwJob) bool {\r\n\tif pj.Status.State == v1.TriggeredState || pj.Status.State == v1.PendingState {\r\n\t\t\r\n\t\tlogrus.WithField(\"prowjob\", pj.ObjectMeta.Name).Info(\"PJ not finished\")\r\n\t\treturn false\r\n\t}\r\n\tif pj.Status.State == v1.AbortedState {\r\n\t\t\r\n\t\tlogrus.WithField(\"prowjob\", pj.ObjectMeta.Name).Info(\"PJ aborted\")\r\n\t\treturn false\r\n\t}\r\n\t\r\n\tif pj.ObjectMeta.Annotations[client.GerritID] == \"\" ||\r\n\t\tpj.ObjectMeta.Annotations[client.GerritInstance] == \"\" ||\r\n\t\tpj.ObjectMeta.Labels[client.GerritRevision] == \"\" {\r\n\t\tlogrus.WithField(\"prowjob\", pj.ObjectMeta.Name).Info(\"Not a gerrit job\")\r\n\t\treturn false\r\n\t}\r\n\t\r\n\tselector := labels.Set{\r\n\t\tclient.GerritRevision: pj.ObjectMeta.Labels[client.GerritRevision],\r\n\t\tkube.ProwJobTypeLabel: pj.ObjectMeta.Labels[kube.ProwJobTypeLabel],\r\n\t}\r\n\tif pj.ObjectMeta.Labels[client.GerritReportLabel] == \"\" {\r\n\t\t\r\n\t\tlogrus.Errorf(\"Gerrit report label not set for job %s\", pj.Spec.Job)\r\n\t} else {\r\n\t\tselector[client.GerritReportLabel] = pj.ObjectMeta.Labels[client.GerritReportLabel]\r\n\t}\r\n\tpjs, err := c.lister.List(selector.AsSelector())\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Errorf(\"Cannot list prowjob with selector %v\", selector)\r\n\t\treturn false\r\n\t}\r\n\tfor _, pjob := range pjs {\r\n\t\tif pjob.Status.State == v1.TriggeredState || pjob.Status.State == v1.PendingState {\r\n\t\t\t\r\n\t\t\tlogrus.WithField(\"prowjob\", pjob.ObjectMeta.Name).Info(\"Other jobs with same label are still running on this revision\")\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":598,"reference":"\/\/ ShouldReport returns if this prowjob should be reported by the gerrit reporter","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Run(refs prowapi.Refs, dir, gitUserName, gitUserEmail, cookiePath string, env []string) Record {\r\n\tlogrus.WithFields(logrus.Fields{\"refs\": refs}).Info(\"Cloning refs\")\r\n\trecord := Record{Refs: refs}\r\n\t\r\n\t\r\n\trunCommands := func(commands []cloneCommand) error {\r\n\t\tfor _, command := range commands {\r\n\t\t\tformattedCommand, output, err := command.run()\r\n\t\t\tlogrus.WithFields(logrus.Fields{\"command\": formattedCommand, \"output\": output, \"error\": err}).Info(\"Ran command\")\r\n\t\t\tmessage := \"\"\r\n\t\t\tif err != nil {\r\n\t\t\t\tmessage = err.Error()\r\n\t\t\t\trecord.Failed = true\r\n\t\t\t}\r\n\t\t\trecord.Commands = append(record.Commands, Command{Command: formattedCommand, Output: output, Error: message})\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\tg := gitCtxForRefs(refs, dir, env)\r\n\tif err := runCommands(g.commandsForBaseRef(refs, gitUserName, gitUserEmail, cookiePath)); err != nil {\r\n\t\treturn record\r\n\t}\r\n\ttimestamp, err := g.gitHeadTimestamp()\r\n\tif err != nil {\r\n\t\ttimestamp = int(time.Now().Unix())\r\n\t}\r\n\tif err := runCommands(g.commandsForPullRefs(refs, timestamp)); err != nil {\r\n\t\treturn record\r\n\t}\r\n\tfinalSHA, err := g.gitRevParse()\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Warnf(\"Cannot resolve finalSHA for ref %#v\", refs)\r\n\t} else {\r\n\t\trecord.FinalSHA = finalSHA\r\n\t}\r\n\treturn record\r\n}","code-length":471,"reference":"\/\/ Run clones the refs under the prescribed directory and optionally\n\/\/ configures the git username and email in the repository as well.","result":"Run a git command.","score":[0.0033,0.0474]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PathForRefs(baseDir string, refs prowapi.Refs) string {\r\n\tvar clonePath string\r\n\tif refs.PathAlias != \"\" {\r\n\t\tclonePath = refs.PathAlias\r\n\t} else {\r\n\t\tclonePath = fmt.Sprintf(\"github.com\/%s\/%s\", refs.Org, refs.Repo)\r\n\t}\r\n\treturn fmt.Sprintf(\"%s\/src\/%s\", baseDir, clonePath)\r\n}","code-length":117,"reference":"\/\/ PathForRefs determines the full path to where\n\/\/ refs should be cloned","result":"Generate the path for the refs.","score":[0.0715,0.0813]}
{"code":"\/*is used to<extra_id_0>\r\nfunc gitCtxForRefs(refs prowapi.Refs, baseDir string, env []string) gitCtx {\r\n\tg := gitCtx{\r\n\t\tcloneDir:      PathForRefs(baseDir, refs),\r\n\t\tenv:           env,\r\n\t\trepositoryURI: fmt.Sprintf(\"https:\r\n\t}\r\n\tif refs.CloneURI != \"\" {\r\n\t\tg.repositoryURI = refs.CloneURI\r\n\t}\r\n\treturn g\r\n}","code-length":120,"reference":"\/\/ gitCtxForRefs creates a gitCtx based on the provide refs and baseDir.","result":"Create a new git context.","score":[0.0593,0.1659]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *gitCtx) commandsForBaseRef(refs prowapi.Refs, gitUserName, gitUserEmail, cookiePath string) []cloneCommand {\r\n\tcommands := []cloneCommand{{dir: \"\/\", env: g.env, command: \"mkdir\", args: []string{\"-p\", g.cloneDir}}}\r\n\tcommands = append(commands, g.gitCommand(\"init\"))\r\n\tif gitUserName != \"\" {\r\n\t\tcommands = append(commands, g.gitCommand(\"config\", \"user.name\", gitUserName))\r\n\t}\r\n\tif gitUserEmail != \"\" {\r\n\t\tcommands = append(commands, g.gitCommand(\"config\", \"user.email\", gitUserEmail))\r\n\t}\r\n\tif cookiePath != \"\" {\r\n\t\tcommands = append(commands, g.gitCommand(\"config\", \"http.cookiefile\", cookiePath))\r\n\t}\r\n\tcommands = append(commands, g.gitCommand(\"fetch\", g.repositoryURI, \"--tags\", \"--prune\"))\r\n\tcommands = append(commands, g.gitCommand(\"fetch\", g.repositoryURI, refs.BaseRef))\r\n\tvar target string\r\n\tif refs.BaseSHA != \"\" {\r\n\t\ttarget = refs.BaseSHA\r\n\t} else {\r\n\t\ttarget = \"FETCH_HEAD\"\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tcommands = append(commands, g.gitCommand(\"checkout\", target))\r\n\tcommands = append(commands, g.gitCommand(\"branch\", \"--force\", refs.BaseRef, target))\r\n\tcommands = append(commands, g.gitCommand(\"checkout\", refs.BaseRef))\r\n\treturn commands\r\n}","code-length":408,"reference":"\/\/ commandsForBaseRef returns the list of commands needed to initialize and\n\/\/ configure a local git directory, as well as fetch and check out the provided\n\/\/ base ref.","result":"Create a new git repository.","score":[0.0024,0.0376]}
{"code":"\/*is used to<extra_id_0>\r\nfunc gitTimestampEnvs(timestamp int) []string {\r\n\treturn []string{\r\n\t\tfmt.Sprintf(\"GIT_AUTHOR_DATE=%d\", timestamp),\r\n\t\tfmt.Sprintf(\"GIT_COMMITTER_DATE=%d\", timestamp),\r\n\t}\r\n}","code-length":77,"reference":"\/\/ gitTimestampEnvs returns the list of environment variables needed to override\n\/\/ git's author and commit timestamps when creating new commits.","result":"Set git timestamp env vars.","score":[0,0.0258]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *gitCtx) gitRevParse() (string, error) {\r\n\tgitRevParseCommand := g.gitCommand(\"rev-parse\", \"HEAD\")\r\n\t_, commit, err := gitRevParseCommand.run()\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Error(\"git rev-parse HEAD failed!\")\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn strings.TrimSpace(commit), nil\r\n}","code-length":117,"reference":"\/\/ gitRevParse returns current commit from HEAD in a git tree","result":"Get the current commit.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *gitCtx) commandsForPullRefs(refs prowapi.Refs, fakeTimestamp int) []cloneCommand {\r\n\tvar commands []cloneCommand\r\n\tfor _, prRef := range refs.Pulls {\r\n\t\tref := fmt.Sprintf(\"pull\/%d\/head\", prRef.Number)\r\n\t\tif prRef.Ref != \"\" {\r\n\t\t\tref = prRef.Ref\r\n\t\t}\r\n\t\tcommands = append(commands, g.gitCommand(\"fetch\", g.repositoryURI, ref))\r\n\t\tvar prCheckout string\r\n\t\tif prRef.SHA != \"\" {\r\n\t\t\tprCheckout = prRef.SHA\r\n\t\t} else {\r\n\t\t\tprCheckout = \"FETCH_HEAD\"\r\n\t\t}\r\n\t\tfakeTimestamp++\r\n\t\tgitMergeCommand := g.gitCommand(\"merge\", \"--no-ff\", prCheckout)\r\n\t\tgitMergeCommand.env = append(gitMergeCommand.env, gitTimestampEnvs(fakeTimestamp)...)\r\n\t\tcommands = append(commands, gitMergeCommand)\r\n\t}\r\n\t\r\n\tif !refs.SkipSubmodules {\r\n\t\tcommands = append(commands, g.gitCommand(\"submodule\", \"update\", \"--init\", \"--recursive\"))\r\n\t}\r\n\treturn commands\r\n}","code-length":316,"reference":"\/\/ commandsForPullRefs returns the list of commands needed to fetch and\n\/\/ merge any pull refs as well as submodules. These commands should be run only\n\/\/ after the commands provided by commandsForBaseRef have been run\n\/\/ successfully.\n\/\/ Each merge commit will be created at sequential seconds after fakeTimestamp.\n\/\/ It's recommended that fakeTimestamp be set to the timestamp of the base ref.\n\/\/ This enables reproducible timestamps and git tree digests every time the same\n\/\/ set of base and pull refs are used.","result":"Avoid the need for the following code.","score":[0.0,0.0256]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ProduceCovList(profiles []*cover.Profile) *CoverageList {\r\n\tcovList := newCoverageList(\"summary\")\r\n\tfor _, prof := range profiles {\r\n\t\tcovList.Group = append(covList.Group, summarizeBlocks(prof))\r\n\t}\r\n\treturn covList\r\n}","code-length":83,"reference":"\/\/ ProduceCovList summarizes profiles and returns the result","result":"Produce the coverage list.","score":[0.1175,0.0658]}
{"code":"\/*is used to<extra_id_0>\r\nfunc popRandom(set sets.String) string {\r\n\tlist := set.List()\r\n\tsort.Strings(list)\r\n\tsel := list[rand.Intn(len(list))]\r\n\tset.Delete(sel)\r\n\treturn sel\r\n}","code-length":72,"reference":"\/\/ popRandom randomly selects an element of 'set' and pops it.","result":"Pop a random string from a set.","score":[0,0.0472]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *ExperimentalKubernetesOptions) resolve(dryRun bool) (err error) {\r\n\tif o.resolved {\r\n\t\treturn nil\r\n\t}\r\n\to.dryRun = dryRun\r\n\tif dryRun {\r\n\t\treturn nil\r\n\t}\r\n\tclusterConfigs, err := kube.LoadClusterConfigs(o.kubeconfig, o.buildCluster)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"load --kubeconfig=%q --build-cluster=%q configs: %v\", o.kubeconfig, o.buildCluster, err)\r\n\t}\r\n\tclients := map[string]kubernetes.Interface{}\r\n\tfor context, config := range clusterConfigs {\r\n\t\tclient, err := kubernetes.NewForConfig(&config)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"create %s kubernetes client: %v\", context, err)\r\n\t\t}\r\n\t\tclients[context] = client\r\n\t}\r\n\tlocalCfg := clusterConfigs[kube.InClusterContext]\r\n\tpjClient, err := prow.NewForConfig(&localCfg)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\to.prowJobClientset = pjClient\r\n\to.kubernetesClientsByContext = clients\r\n\to.resolved = true\r\n\treturn nil\r\n}","code-length":334,"reference":"\/\/ resolve loads all of the clients we need and caches them for future calls.","result":"Resolve the kubernetes client.","score":[0.0204,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *ExperimentalKubernetesOptions) ProwJobClientset(namespace string, dryRun bool) (prowJobClientset prow.Interface, err error) {\r\n\tif err := o.resolve(dryRun); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif o.dryRun {\r\n\t\treturn nil, errors.New(\"no dry-run prowjob clientset is supported in dry-run mode\")\r\n\t}\r\n\treturn o.prowJobClientset, nil\r\n}","code-length":132,"reference":"\/\/ ProwJobClientset returns a ProwJob clientset for use in informer factories.","result":"Create prowjob client.","score":[0,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *ExperimentalKubernetesOptions) ProwJobClient(namespace string, dryRun bool) (prowJobClient prowv1.ProwJobInterface, err error) {\r\n\tif err := o.resolve(dryRun); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif o.dryRun {\r\n\t\treturn kube.NewDryRunProwJobClient(o.DeckURI), nil\r\n\t}\r\n\treturn o.prowJobClientset.ProwV1().ProwJobs(namespace), nil\r\n}","code-length":138,"reference":"\/\/ ProwJobClient returns a ProwJob client.","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *ExperimentalKubernetesOptions) InfrastructureClusterClient(dryRun bool) (kubernetesClient kubernetes.Interface, err error) {\r\n\tif err := o.resolve(dryRun); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif o.dryRun {\r\n\t\treturn nil, errors.New(\"no dry-run kubernetes client is supported in dry-run mode\")\r\n\t}\r\n\treturn o.kubernetesClientsByContext[kube.InClusterContext], nil\r\n}","code-length":130,"reference":"\/\/ InfrastructureClusterClient returns a Kubernetes client for the infrastructure cluster.","result":"Generate code for generated code.","score":[0.0884,0.0526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *ExperimentalKubernetesOptions) BuildClusterClients(namespace string, dryRun bool) (buildClusterClients map[string]corev1.PodInterface, err error) {\r\n\tif err := o.resolve(dryRun); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif o.dryRun {\r\n\t\treturn nil, errors.New(\"no dry-run pod client is supported for build clusters in dry-run mode\")\r\n\t}\r\n\tbuildClients := map[string]corev1.PodInterface{}\r\n\tfor context, client := range o.kubernetesClientsByContext {\r\n\t\tbuildClients[context] = client.CoreV1().Pods(namespace)\r\n\t}\r\n\treturn buildClients, nil\r\n}","code-length":187,"reference":"\/\/ BuildClusterClients returns Pod clients for build clusters.","result":"Build the cluster client for the cluster.","score":[0.14,0.3235]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *ActiveState) Age(t time.Time) time.Duration {\r\n\treturn t.Sub(a.startTime)\r\n}","code-length":44,"reference":"\/\/ Age gives the time since the state has been activated.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *ActiveState) ReceiveEvent(eventName, label string, t time.Time) (State, bool) {\r\n\tif a.exit.Match(eventName, label) {\r\n\t\treturn &InactiveState{\r\n\t\t\tentry: a.exit.Opposite(),\r\n\t\t}, true\r\n\t}\r\n\treturn a, false\r\n}","code-length":94,"reference":"\/\/ ReceiveEvent checks if the event matches the exit criteria.\n\/\/ Returns a new InactiveState or self, and true if it changed.","result":"Receive events from the active state.","score":[0.0134,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InactiveState) ReceiveEvent(eventName, label string, t time.Time) (State, bool) {\r\n\tif i.entry.Match(eventName, label) {\r\n\t\treturn &ActiveState{\r\n\t\t\tstartTime: t,\r\n\t\t\texit:      i.entry.Opposite(),\r\n\t\t}, true\r\n\t}\r\n\treturn i, false\r\n}","code-length":104,"reference":"\/\/ ReceiveEvent checks if the event matches the entry criteria\n\/\/ Returns a new ActiveState or self, and true if it changed.","result":"Receive events from an inactive state.","score":[0,0.0245]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *MultiState) Active() bool {\r\n\tfor _, state := range m.states {\r\n\t\tif !state.Active() {\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\treturn true\r\n}","code-length":67,"reference":"\/\/ Active is true if all the states are active.","result":"Check if the state is active.","score":[0.1402,0.3875]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *MultiState) Age(t time.Time) time.Duration {\r\n\tminAge := time.Duration(1<<63 - 1)\r\n\tfor _, state := range m.states {\r\n\t\tstateAge := state.Age(t)\r\n\t\tif stateAge < minAge {\r\n\t\t\tminAge = stateAge\r\n\t\t}\r\n\t}\r\n\treturn minAge\r\n}","code-length":108,"reference":"\/\/ Age returns the time since all states have been activated.\n\/\/ It will panic if any of the state is not active.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (m *MultiState) ReceiveEvent(eventName, label string, t time.Time) (State, bool) {\r\n\toneChanged := false\r\n\tfor i := range m.states {\r\n\t\tstate, changed := m.states[i].ReceiveEvent(eventName, label, t)\r\n\t\tif changed {\r\n\t\t\toneChanged = true\r\n\t\t}\r\n\t\tm.states[i] = state\r\n\t}\r\n\treturn m, oneChanged\r\n}","code-length":125,"reference":"\/\/ ReceiveEvent will send the event to each individual state, and update\n\/\/ them if they change.","result":"Receive events from multiple states.","score":[0,0.0316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (v *version) ProwJobs() ProwJobInformer {\r\n\treturn &prowJobInformer{factory: v.factory, namespace: v.namespace, tweakListOptions: v.tweakListOptions}\r\n}","code-length":58,"reference":"\/\/ ProwJobs returns a ProwJobInformer.","result":"Test the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ItemToResourcesConfig(i Item) (ResourcesConfig, error) {\r\n\tconf, ok := i.(ResourcesConfig)\r\n\tif !ok {\r\n\t\treturn ResourcesConfig{}, fmt.Errorf(\"cannot construct Resource from received object %v\", i)\r\n\t}\r\n\treturn conf, nil\r\n}","code-length":83,"reference":"\/\/ ItemToResourcesConfig casts an Item object to a ResourcesConfig","result":"Convert the item to a resource config.","score":[0.1716,0.2904]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t TypeToResources) Copy() TypeToResources {\r\n\tn := TypeToResources{}\r\n\tfor k, v := range t {\r\n\t\tn[k] = v\r\n\t}\r\n\treturn n\r\n}","code-length":64,"reference":"\/\/ Copy returns a copy of the TypeToResources","result":"Copy the typeToResources.","score":[0.0917,0.1333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MakeCommand() *cobra.Command {\r\n\tflags := &flags{}\r\n\tcmd := &cobra.Command{\r\n\t\tUse:   \"aggregate [files...]\",\r\n\t\tShort: \"Aggregates multiple Go coverage files.\",\r\n\t\tLong: `Given multiple Go coverage files from identical binaries recorded in\r\n\"count\" or \"atomic\" mode, produces a new Go coverage file in the same mode\r\nthat counts how many of those coverage profiles hit a block at least once.`,\r\n\t\tRun: func(cmd *cobra.Command, args []string) {\r\n\t\t\trun(flags, cmd, args)\r\n\t\t},\r\n\t}\r\n\tcmd.Flags().StringVarP(&flags.OutputFile, \"output\", \"o\", \"-\", \"output file\")\r\n\treturn cmd\r\n}","code-length":204,"reference":"\/\/ MakeCommand returns an `aggregate` command.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) incrementNumPendingJobs(job string) {\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tc.pendingJobs[job]++\r\n}","code-length":57,"reference":"\/\/ incrementNumPendingJobs increments the amount of\n\/\/ pending ProwJobs for the given job identifier","result":"Increment the number of pending.","score":[0.0472,0.2409]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) setPreviousReportState(pj prowapi.ProwJob) error {\r\n\t\r\n\tlatestPJ, err := c.kc.GetProwJob(pj.ObjectMeta.Name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif latestPJ.Status.PrevReportStates == nil {\r\n\t\tlatestPJ.Status.PrevReportStates = map[string]prowapi.ProwJobState{}\r\n\t}\r\n\tlatestPJ.Status.PrevReportStates[reporter.GitHubReporterName] = latestPJ.Status.State\r\n\t_, err = c.kc.ReplaceProwJob(latestPJ.ObjectMeta.Name, latestPJ)\r\n\treturn err\r\n}","code-length":193,"reference":"\/\/ setPreviousReportState sets the github key for PrevReportStates\n\/\/ to current state. This is a work-around for plank -> crier\n\/\/ migration to become seamless.","result":"Set the previous report state.","score":[0.0052,0.1111]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) SyncMetrics() {\r\n\tc.pjLock.RLock()\r\n\tdefer c.pjLock.RUnlock()\r\n\tkube.GatherProwJobMetrics(c.pjs)\r\n}","code-length":64,"reference":"\/\/ SyncMetrics records metrics for the cached prowjobs.","result":"Sync metrics.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DumpProfile(profiles []*cover.Profile, writer io.Writer) error {\r\n\tif len(profiles) == 0 {\r\n\t\treturn errors.New(\"can't write an empty profile\")\r\n\t}\r\n\tif _, err := io.WriteString(writer, \"mode: \"+profiles[0].Mode+\"\\n\"); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfor _, profile := range profiles {\r\n\t\tfor _, block := range profile.Blocks {\r\n\t\t\tif _, err := fmt.Fprintf(writer, \"%s:%d.%d,%d.%d %d %d\\n\", profile.FileName, block.StartLine, block.StartCol, block.EndLine, block.EndCol, block.NumStmt, block.Count); err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":223,"reference":"\/\/ DumpProfile dumps the profiles given to writer in go coverage format.","result":"Dump the profile to a file.","score":[0.0845,0.3289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc blocksEqual(a cover.ProfileBlock, b cover.ProfileBlock) bool {\r\n\treturn a.StartCol == b.StartCol && a.StartLine == b.StartLine &&\r\n\t\ta.EndCol == b.EndCol && a.EndLine == b.EndLine && a.NumStmt == b.NumStmt\r\n}","code-length":87,"reference":"\/\/ blocksEqual returns true if the blocks refer to the same code, otherwise false.\n\/\/ It does not care about Count.","result":"Compare profile blocks.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewProwJobInformer(client versioned.Interface, namespace string, resyncPeriod time.Duration, indexers cache.Indexers) cache.SharedIndexInformer {\r\n\treturn NewFilteredProwJobInformer(client, namespace, resyncPeriod, indexers, nil)\r\n}","code-length":67,"reference":"\/\/ NewProwJobInformer constructs a new informer for ProwJob type.\n\/\/ Always prefer using an informer factory to get a shared informer instead of getting an independent\n\/\/ one. This reduces memory footprint and number of connections to the server.","result":"ResyncPeriod time.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFilteredProwJobInformer(client versioned.Interface, namespace string, resyncPeriod time.Duration, indexers cache.Indexers, tweakListOptions internalinterfaces.TweakListOptionsFunc) cache.SharedIndexInformer {\r\n\treturn cache.NewSharedIndexInformer(\r\n\t\t&cache.ListWatch{\r\n\t\t\tListFunc: func(options metav1.ListOptions) (runtime.Object, error) {\r\n\t\t\t\tif tweakListOptions != nil {\r\n\t\t\t\t\ttweakListOptions(&options)\r\n\t\t\t\t}\r\n\t\t\t\treturn client.ProwV1().ProwJobs(namespace).List(options)\r\n\t\t\t},\r\n\t\t\tWatchFunc: func(options metav1.ListOptions) (watch.Interface, error) {\r\n\t\t\t\tif tweakListOptions != nil {\r\n\t\t\t\t\ttweakListOptions(&options)\r\n\t\t\t\t}\r\n\t\t\t\treturn client.ProwV1().ProwJobs(namespace).Watch(options)\r\n\t\t\t},\r\n\t\t},\r\n\t\t&prowjobsv1.ProwJob{},\r\n\t\tresyncPeriod,\r\n\t\tindexers,\r\n\t)\r\n}","code-length":269,"reference":"\/\/ NewFilteredProwJobInformer constructs a new informer for ProwJob type.\n\/\/ Always prefer using an informer factory to get a shared informer instead of getting an independent\n\/\/ one. This reduces memory footprint and number of connections to the server.","result":"Test if the informer is used to test if the informer is not nil.","score":[0.0179,0.0685]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New(ja *jobs.JobAgent, cfg config.Getter, c *storage.Client, ctx context.Context) *Spyglass {\r\n\treturn &Spyglass{\r\n\t\tJobAgent:              ja,\r\n\t\tconfig:                cfg,\r\n\t\tPodLogArtifactFetcher: NewPodLogArtifactFetcher(ja),\r\n\t\tGCSArtifactFetcher:    NewGCSArtifactFetcher(c),\r\n\t\ttestgrid: &TestGrid{\r\n\t\t\tconf:   cfg,\r\n\t\t\tclient: c,\r\n\t\t\tctx:    ctx,\r\n\t\t},\r\n\t}\r\n}","code-length":154,"reference":"\/\/ New constructs a Spyglass object from a JobAgent, a config.Agent, and a storage Client.","result":"Create the Spyglass.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Spyglass) Lenses(matchCache map[string][]string) []lenses.Lens {\r\n\tls := []lenses.Lens{}\r\n\tfor lensName, matches := range matchCache {\r\n\t\tif len(matches) == 0 {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tlens, err := lenses.GetLens(lensName)\r\n\t\tif err != nil {\r\n\t\t\tlogrus.WithField(\"lensName\", lens).WithError(err).Error(\"Could not find artifact lens\")\r\n\t\t} else {\r\n\t\t\tls = append(ls, lens)\r\n\t\t}\r\n\t}\r\n\t\r\n\tsort.Slice(ls, func(i, j int) bool {\r\n\t\ticonf := ls[i].Config()\r\n\t\tjconf := ls[j].Config()\r\n\t\tiname := iconf.Name\r\n\t\tjname := jconf.Name\r\n\t\tpi := iconf.Priority\r\n\t\tpj := jconf.Priority\r\n\t\tif pi == pj {\r\n\t\t\treturn iname < jname\r\n\t\t}\r\n\t\treturn pi < pj\r\n\t})\r\n\treturn ls\r\n}","code-length":302,"reference":"\/\/ Lenses gets all views of all artifact files matching each regexp with a registered lens","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Spyglass) JobPath(src string) (string, error) {\r\n\tsrc = strings.TrimSuffix(src, \"\/\")\r\n\tkeyType, key, err := splitSrc(src)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error parsing src: %v\", src)\r\n\t}\r\n\tsplit := strings.Split(key, \"\/\")\r\n\tswitch keyType {\r\n\tcase gcsKeyType:\r\n\t\tif len(split) < 4 {\r\n\t\t\treturn \"\", fmt.Errorf(\"invalid key %s: expected <bucket-name>\/<log-type>\/...\/<job-name>\/<build-id>\", key)\r\n\t\t}\r\n\t\t split[len(split)-2]\r\n\t\tif logType == gcs.NonPRLogs {\r\n\t\t\treturn path.Dir(key), nil\r\n\t\t} else if logType == gcs.PRLogs {\r\n\t\t\treturn path.Join(bktName, gcs.PRLogs, \"directory\", jobName), nil\r\n\t\t}\r\n\t\treturn \"\", fmt.Errorf(\"unrecognized GCS key: %s\", key)\r\n\tcase prowKeyType:\r\n\t\tif len(split) < 2 {\r\n\t\t\treturn \"\", fmt.Errorf(\"invalid key %s: expected <job-name>\/<build-id>\", key)\r\n\t\t}\r\n\t\tjobName := split[0]\r\n\t\tbuildID := split[1]\r\n\t\tjob, err := s.jobAgent.GetProwJob(jobName, buildID)\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"failed to get prow job from src %q: %v\", key, err)\r\n\t\t}\r\n\t\tif job.Spec.DecorationConfig == nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"failed to locate GCS upload bucket for %s: job is undecorated\", jobName)\r\n\t\t}\r\n\t\tif job.Spec.DecorationConfig.GCSConfiguration == nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"failed to locate GCS upload bucket for %s: missing GCS configuration\", jobName)\r\n\t\t}\r\n\t\tbktName := job.Spec.DecorationConfig.GCSConfiguration.Bucket\r\n\t\tif job.Spec.Type == prowapi.PresubmitJob {\r\n\t\t\treturn path.Join(bktName, gcs.PRLogs, \"directory\", jobName), nil\r\n\t\t}\r\n\t\treturn path.Join(bktName, gcs.NonPRLogs, jobName), nil\r\n\tdefault:\r\n\t\treturn \"\", fmt.Errorf(\"unrecognized key type for src: %v\", src)\r\n\t}\r\n}","code-length":640,"reference":"\/\/ JobPath returns a link to the GCS directory for the job specified in src","result":"Code too long,keep in 512.","score":[0.0325,0.0357]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Spyglass) RunPath(src string) (string, error) {\r\n\tsrc = strings.TrimSuffix(src, \"\/\")\r\n\tkeyType, key, err := splitSrc(src)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error parsing src: %v\", src)\r\n\t}\r\n\tswitch keyType {\r\n\tcase gcsKeyType:\r\n\t\treturn key, nil\r\n\tcase prowKeyType:\r\n\t\treturn s.prowToGCS(key)\r\n\tdefault:\r\n\t\treturn \"\", fmt.Errorf(\"unrecognized key type for src: %v\", src)\r\n\t}\r\n}","code-length":168,"reference":"\/\/ RunPath returns the path to the GCS directory for the job run specified in src.","result":"Run the code .","score":[0.0159,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (sg *Spyglass) ExtraLinks(src string) ([]ExtraLink, error) {\r\n\tartifacts, err := sg.FetchArtifacts(src, \"\", 1000000, []string{\"started.json\"})\r\n\t\r\n\tif err != nil || len(artifacts) == 0 {\r\n\t\tlogrus.WithError(err).Debugf(\"Failed to find started.json while looking for extra links.\")\r\n\t\treturn nil, nil\r\n\t}\r\n\t\r\n\tcontent, err := artifacts[0].ReadAll()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tstarted := metadata.Started{}\r\n\tif err := json.Unmarshal(content, &started); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tlinks, ok := started.Metadata.Meta(\"links\")\r\n\tif !ok {\r\n\t\treturn nil, nil\r\n\t}\r\n\textraLinks := make([]ExtraLink, 0, len(*links))\r\n\tfor _, name := range links.Keys() {\r\n\t\tm, ok := links.Meta(name)\r\n\t\tif !ok {\r\n\t\t\t\r\n\t\t\tlogrus.Debugf(\"Got bad link key %q from %s, but that should be impossible.\", name, artifacts[0].CanonicalLink())\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\ts := m.Strings()\r\n\t\tlink := ExtraLink{\r\n\t\t\tName:        name,\r\n\t\t\tURL:         s[\"url\"],\r\n\t\t\tDescription: s[\"description\"],\r\n\t\t}\r\n\t\tif link.URL == \"\" || link.Name == \"\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\textraLinks = append(extraLinks, link)\r\n\t}\r\n\treturn extraLinks, nil\r\n}","code-length":444,"reference":"\/\/ ExtraLinks fetches started.json and extracts links from metadata.links.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Server) needDemux(eventType, srcRepo string) []plugins.ExternalPlugin {\r\n\tvar matching []plugins.ExternalPlugin\r\n\tsrcOrg := strings.Split(srcRepo, \"\/\")[0]\r\n\tfor repo, plugins := range s.Plugins.Config().ExternalPlugins {\r\n\t\t\r\n\t\tif repo != srcRepo && repo != srcOrg {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\tfor _, p := range plugins {\r\n\t\t\tif len(p.Events) == 0 {\r\n\t\t\t\tmatching = append(matching, p)\r\n\t\t\t} else {\r\n\t\t\t\tfor _, et := range p.Events {\r\n\t\t\t\t\tif et != eventType {\r\n\t\t\t\t\t\tcontinue\r\n\t\t\t\t\t}\r\n\t\t\t\t\tmatching = append(matching, p)\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn matching\r\n}","code-length":230,"reference":"\/\/ needDemux returns whether there are any external plugins that need to\n\/\/ get the present event.","result":"Generate the generated code.","score":[0.0124,0.0318]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Server) demuxExternal(l *logrus.Entry, externalPlugins []plugins.ExternalPlugin, payload []byte, h http.Header) {\r\n\th.Set(\"User-Agent\", \"ProwHook\")\r\n\tfor _, p := range externalPlugins {\r\n\t\ts.wg.Add(1)\r\n\t\tgo func(p plugins.ExternalPlugin) {\r\n\t\t\tdefer s.wg.Done()\r\n\t\t\tif err := s.dispatch(p.Endpoint, payload, h); err != nil {\r\n\t\t\t\tl.WithError(err).WithField(\"external-plugin\", p.Name).Error(\"Error dispatching event to external plugin.\")\r\n\t\t\t} else {\r\n\t\t\t\tl.WithField(\"external-plugin\", p.Name).Info(\"Dispatched event to external plugin\")\r\n\t\t\t}\r\n\t\t}(p)\r\n\t}\r\n}","code-length":217,"reference":"\/\/ demuxExternal dispatches the provided payload to the external plugins.","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Server) dispatch(endpoint string, payload []byte, h http.Header) error {\r\n\treq, err := http.NewRequest(http.MethodPost, endpoint, bytes.NewBuffer(payload))\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treq.Header = h\r\n\tresp, err := s.do(req)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\trb, err := ioutil.ReadAll(resp.Body)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif resp.StatusCode < 200 || resp.StatusCode > 299 {\r\n\t\treturn fmt.Errorf(\"response has status %q and body %q\", resp.Status, string(rb))\r\n\t}\r\n\treturn nil\r\n}","code-length":213,"reference":"\/\/ dispatch creates a new request using the provided payload and headers\n\/\/ and dispatches the request to the provided endpoint.","result":"Dispatch requests to the endpoint.","score":[0.0153,0.2299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *StatePlugin) AddFlags(cmd *cobra.Command) {\r\n\tcmd.Flags().StringVar(&s.desc, \"state\", \"\", \"Description of the state (eg: `opened,!merged,labeled:cool`)\")\r\n\tcmd.Flags().IntSliceVar(&s.percentiles, \"percentiles\", []int{}, \"Age percentiles for state\")\r\n}","code-length":104,"reference":"\/\/ AddFlags adds \"state\" and \"percentiles\" to the command help","result":"Generate the state description.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *StatePlugin) CheckFlags() error {\r\n\ts.states = NewBundledStates(s.desc)\r\n\treturn nil\r\n}","code-length":45,"reference":"\/\/ CheckFlags configures which states to monitor","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *StatePlugin) ReceiveIssueEvent(event sql.IssueEvent) []Point {\r\n\tlabel := \"\"\r\n\tif event.Label != nil {\r\n\t\tlabel = *event.Label\r\n\t}\r\n\tif !s.states.ReceiveEvent(event.IssueID, event.Event, label, event.EventCreatedAt) {\r\n\t\treturn nil\r\n\t}\r\n\ttotal, sum := s.states.Total(event.EventCreatedAt)\r\n\tvalues := map[string]interface{}{\r\n\t\t\"count\": total,\r\n\t\t\"sum\":   int(sum),\r\n\t}\r\n\tfor _, percentile := range s.percentiles {\r\n\t\tvalues[fmt.Sprintf(\"%d%%\", percentile)] = int(s.states.Percentile(event.EventCreatedAt, percentile))\r\n\t}\r\n\treturn []Point{\r\n\t\t{\r\n\t\t\tValues: values,\r\n\t\t\tDate:   event.EventCreatedAt,\r\n\t\t},\r\n\t}\r\n}","code-length":248,"reference":"\/\/ ReceiveIssueEvent computes age percentiles and saves them to InfluxDB","result":"Receive issue events .","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Load(prowConfig, jobConfig string) (c *Config, err error) {\r\n\t\r\n\tdefer func() {\r\n\t\tif r := recover(); r != nil {\r\n\t\t\tc, err = nil, fmt.Errorf(\"panic loading config: %v\", r)\r\n\t\t}\r\n\t}()\r\n\tc, err = loadConfig(prowConfig, jobConfig)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err := c.finalizeJobConfig(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err := c.validateComponentConfig(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err := c.validateJobConfig(); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn c, nil\r\n}","code-length":216,"reference":"\/\/ Load loads and parses the config at path.","result":"Load the config file .","score":[0.169,0.2972]}
{"code":"\/*is used to<extra_id_0>\r\nfunc loadConfig(prowConfig, jobConfig string) (*Config, error) {\r\n\tstat, err := os.Stat(prowConfig)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif stat.IsDir() {\r\n\t\treturn nil, fmt.Errorf(\"prowConfig cannot be a dir - %s\", prowConfig)\r\n\t}\r\n\tvar nc Config\r\n\tif err := yamlToConfig(prowConfig, &nc); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err := parseProwConfig(&nc); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\t\r\n\tif jobConfig == \"\" {\r\n\t\treturn &nc, nil\r\n\t}\r\n\tstat, err = os.Stat(jobConfig)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif !stat.IsDir() {\r\n\t\t\r\n\t\tvar jc JobConfig\r\n\t\tif err := yamlToConfig(jobConfig, &jc); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tif err := nc.mergeJobConfig(jc); err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn &nc, nil\r\n\t}\r\n\t\r\n\t\r\n\tuniqueBasenames := sets.String{}\r\n\terr = filepath.Walk(jobConfig, func(path string, info os.FileInfo, err error) error {\r\n\t\tif err != nil {\r\n\t\t\tlogrus.WithError(err).Errorf(\"walking path %q.\", path)\r\n\t\t\t\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tif strings.HasPrefix(info.Name(), \"..\") {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tif info.IsDir() {\r\n\t\t\t\treturn filepath.SkipDir\r\n\t\t\t}\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tif filepath.Ext(path) != \".yaml\" && filepath.Ext(path) != \".yml\" {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tif info.IsDir() {\r\n\t\t\treturn nil\r\n\t\t}\r\n\t\tbase := filepath.Base(path)\r\n\t\tif uniqueBasenames.Has(base) {\r\n\t\t\treturn fmt.Errorf(\"duplicated basename is not allowed: %s\", base)\r\n\t\t}\r\n\t\tuniqueBasenames.Insert(base)\r\n\t\tvar subConfig JobConfig\r\n\t\tif err := yamlToConfig(path, &subConfig); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn nc.mergeJobConfig(subConfig)\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &nc, nil\r\n}","code-length":699,"reference":"\/\/ loadConfig loads one or multiple config files and returns a config object.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc yamlToConfig(path string, nc interface{}) error {\r\n\tb, err := ReadFileMaybeGZIP(path)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"error reading %s: %v\", path, err)\r\n\t}\r\n\tif err := yaml.Unmarshal(b, nc); err != nil {\r\n\t\treturn fmt.Errorf(\"error unmarshaling %s: %v\", path, err)\r\n\t}\r\n\tvar jc *JobConfig\r\n\tswitch v := nc.(type) {\r\n\tcase *JobConfig:\r\n\t\tjc = v\r\n\tcase *Config:\r\n\t\tjc = &v.JobConfig\r\n\t}\r\n\tfor rep := range jc.Presubmits {\r\n\t\tvar fix func(*Presubmit)\r\n\t\tfix = func(job *Presubmit) {\r\n\t\t\tjob.SourcePath = path\r\n\t\t}\r\n\t\tfor i := range jc.Presubmits[rep] {\r\n\t\t\tfix(&jc.Presubmits[rep][i])\r\n\t\t}\r\n\t}\r\n\tfor rep := range jc.Postsubmits {\r\n\t\tvar fix func(*Postsubmit)\r\n\t\tfix = func(job *Postsubmit) {\r\n\t\t\tjob.SourcePath = path\r\n\t\t}\r\n\t\tfor i := range jc.Postsubmits[rep] {\r\n\t\t\tfix(&jc.Postsubmits[rep][i])\r\n\t\t}\r\n\t}\r\n\tvar fix func(*Periodic)\r\n\tfix = func(job *Periodic) {\r\n\t\tjob.SourcePath = path\r\n\t}\r\n\tfor i := range jc.Periodics {\r\n\t\tfix(&jc.Periodics[i])\r\n\t}\r\n\treturn nil\r\n}","code-length":443,"reference":"\/\/ yamlToConfig converts a yaml file into a Config object","result":"Convert yaml to config.","score":[0.0713,0.1064]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReadFileMaybeGZIP(path string) ([]byte, error) {\r\n\tb, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tyte(\"\\x1F\\x8B\")) {\r\n\t\t\r\n\t\treturn b, nil\r\n\t}\r\n\t\r\n\tgzipReader, err := gzip.NewReader(bytes.NewBuffer(b))\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn ioutil.ReadAll(gzipReader)\r\n}","code-length":147,"reference":"\/\/ ReadFileMaybeGZIP wraps ioutil.ReadFile, returning the decompressed contents\n\/\/ if the file is gzipped, or otherwise the raw contents","result":"Read a file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) finalizeJobConfig() error {\r\n\tif c.decorationRequested() {\r\n\t\tif c.Plank.DefaultDecorationConfig == nil {\r\n\t\t\treturn errors.New(\"no default decoration config provided for plank\")\r\n\t\t}\r\n\t\tif c.Plank.DefaultDecorationConfig.UtilityImages == nil {\r\n\t\t\treturn errors.New(\"no default decoration image pull specs provided for plank\")\r\n\t\t}\r\n\t\tif c.Plank.DefaultDecorationConfig.GCSConfiguration == nil {\r\n\t\t\treturn errors.New(\"no default GCS decoration config provided for plank\")\r\n\t\t}\r\n\t\tif c.Plank.DefaultDecorationConfig.GCSCredentialsSecret == \"\" {\r\n\t\t\treturn errors.New(\"no default GCS credentials secret provided for plank\")\r\n\t\t}\r\n\t\tfor _, vs := range c.Presubmits {\r\n\t\t\tfor i := range vs {\r\n\t\t\t\tsetPresubmitDecorationDefaults(c, &vs[i])\r\n\t\t\t}\r\n\t\t}\r\n\t\tfor _, js := range c.Postsubmits {\r\n\t\t\tfor i := range js {\r\n\t\t\t\tsetPostsubmitDecorationDefaults(c, &js[i])\r\n\t\t\t}\r\n\t\t}\r\n\t\tfor i := range c.Periodics {\r\n\t\t\tsetPeriodicDecorationDefaults(c, &c.Periodics[i])\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor _, vs := range c.Presubmits {\r\n\t\tc.defaultPresubmitFields(vs)\r\n\t\tif err := SetPresubmitRegexes(vs); err != nil {\r\n\t\t\treturn fmt.Errorf(\"could not set regex: %v\", err)\r\n\t\t}\r\n\t}\r\n\tfor _, js := range c.Postsubmits {\r\n\t\tc.defaultPostsubmitFields(js)\r\n\t\tif err := SetPostsubmitRegexes(js); err != nil {\r\n\t\t\treturn fmt.Errorf(\"could not set regex: %v\", err)\r\n\t\t}\r\n\t}\r\n\tc.defaultPeriodicFields(c.Periodics)\r\n\tfor _, v := range c.AllPresubmits(nil) {\r\n\t\tif err := resolvePresets(v.Name, v.Labels, v.Spec, v.BuildSpec, c.Presets); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tfor _, v := range c.AllPostsubmits(nil) {\r\n\t\tif err := resolvePresets(v.Name, v.Labels, v.Spec, v.BuildSpec, c.Presets); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tfor _, v := range c.AllPeriodics() {\r\n\t\tif err := resolvePresets(v.Name, v.Labels, v.Spec, v.BuildSpec, c.Presets); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":740,"reference":"\/\/ finalizeJobConfig mutates and fixes entries for jobspecs","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) validateComponentConfig() error {\r\n\tif c.Plank.JobURLPrefix != \"\" && c.Plank.JobURLPrefixConfig[\"*\"] != \"\" {\r\n\t\treturn errors.New(`Planks job_url_prefix must be unset when job_url_prefix_config[\"*\"] is set. The former is deprecated, use the latter`)\r\n\t}\r\n\tfor k, v := range c.Plank.JobURLPrefixConfig {\r\n\t\tif _, err := url.Parse(v); err != nil {\r\n\t\t\treturn fmt.Errorf(`Invalid value for Planks job_url_prefix_config[\"%s\"]: %v`, k, err)\r\n\t\t}\r\n\t}\r\n\tif c.SlackReporter != nil {\r\n\t\tif err := c.SlackReporter.DefaultAndValidate(); err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to validate slackreporter config: %v\", err)\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":251,"reference":"\/\/ validateComponentConfig validates the infrastructure component configuration","result":"Generate the generated code.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ConfigPath(value string) string {\r\n\tif value != \"\" {\r\n\t\treturn value\r\n\t}\r\n\tlogrus.Warningf(\"defaulting to %s until 15 July 2019, please migrate\", DefaultConfigPath)\r\n\treturn DefaultConfigPath\r\n}","code-length":72,"reference":"\/\/ ConfigPath returns the value for the component's configPath if provided\n\/\/ explicitly or default otherwise.","result":"Generate the config path.","score":[0.0159,0.0338]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ValidateController(c *Controller) error {\r\n\turlTmpl, err := template.New(\"JobURL\").Parse(c.JobURLTemplateString)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"parsing template: %v\", err)\r\n\t}\r\n\tc.JobURLTemplate = urlTmpl\r\n\treportTmpl, err := template.New(\"Report\").Parse(c.ReportTemplateString)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"parsing template: %v\", err)\r\n\t}\r\n\tc.ReportTemplate = reportTmpl\r\n\tif c.MaxConcurrency < 0 {\r\n\t\treturn fmt.Errorf(\"controller has invalid max_concurrency (%d), it needs to be a non-negative number\", c.MaxConcurrency)\r\n\t}\r\n\tif c.MaxGoroutines == 0 {\r\n\t\tc.MaxGoroutines = 20\r\n\t}\r\n\tif c.MaxGoroutines <= 0 {\r\n\t\treturn fmt.Errorf(\"controller has invalid max_goroutines (%d), it needs to be a positive number\", c.MaxGoroutines)\r\n\t}\r\n\treturn nil\r\n}","code-length":285,"reference":"\/\/ ValidateController validates the provided controller config.","result":"Validate the controller configuration.","score":[0.1795,0.3814]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ProwConfig) defaultJobBase(base *JobBase) {\r\n\tif base.Agent == \"\" {\r\n\t\tbase.Agent = string(prowapi.KubernetesAgent)\r\n\t}\r\n\tif base.Namespace == nil || *base.Namespace == \"\" {\r\n\t\ts := c.PodNamespace\r\n\t\tbase.Namespace = &s\r\n\t}\r\n\tif base.Cluster == \"\" {\r\n\t\tbase.Cluster = kube.DefaultClusterAlias\r\n\t}\r\n}","code-length":130,"reference":"\/\/ defaultJobBase configures common parameters, currently Agent and Namespace.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetPresubmitRegexes(js []Presubmit) error {\r\n\tfor i, j := range js {\r\n\t\tif re, err := regexp.Compile(j.Trigger); err == nil {\r\n\t\t\tjs[i].re = re\r\n\t\t} else {\r\n\t\t\treturn fmt.Errorf(\"could not compile trigger regex for %s: %v\", j.Name, err)\r\n\t\t}\r\n\t\tif !js[i].re.MatchString(j.RerunCommand) {\r\n\t\t\treturn fmt.Errorf(\"for job %s, rerun command \\\"%s\\\" does not match trigger \\\"%s\\\"\", j.Name, j.RerunCommand, j.Trigger)\r\n\t\t}\r\n\t\tb, err := setBrancherRegexes(j.Brancher)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"could not set branch regexes for %s: %v\", j.Name, err)\r\n\t\t}\r\n\t\tjs[i].Brancher = b\r\n\t\tc, err := setChangeRegexes(j.RegexpChangeMatcher)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"could not set change regexes for %s: %v\", j.Name, err)\r\n\t\t}\r\n\t\tjs[i].RegexpChangeMatcher = c\r\n\t}\r\n\treturn nil\r\n}","code-length":333,"reference":"\/\/ SetPresubmitRegexes compiles and validates all the regular expressions for\n\/\/ the provided presubmits.","result":"Set the regexps for the presubmit regexps.","score":[0.0782,0.1128]}
{"code":"\/*is used to<extra_id_0>\r\nfunc setBrancherRegexes(br Brancher) (Brancher, error) {\r\n\tif len(br.Branches) > 0 {\r\n\t\tif re, err := regexp.Compile(strings.Join(br.Branches, `|`)); err == nil {\r\n\t\t\tbr.re = re\r\n\t\t} else {\r\n\t\t\treturn br, fmt.Errorf(\"could not compile positive branch regex: %v\", err)\r\n\t\t}\r\n\t}\r\n\tif len(br.SkipBranches) > 0 {\r\n\t\tif re, err := regexp.Compile(strings.Join(br.SkipBranches, `|`)); err == nil {\r\n\t\t\tbr.reSkip = re\r\n\t\t} else {\r\n\t\t\treturn br, fmt.Errorf(\"could not compile negative branch regex: %v\", err)\r\n\t\t}\r\n\t}\r\n\treturn br, nil\r\n}","code-length":220,"reference":"\/\/ setBrancherRegexes compiles and validates all the regular expressions for\n\/\/ the provided branch specifiers.","result":"Set the brancher regexes.","score":[0.0204,0.036]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SetPostsubmitRegexes(ps []Postsubmit) error {\r\n\tfor i, j := range ps {\r\n\t\tb, err := setBrancherRegexes(j.Brancher)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"could not set branch regexes for %s: %v\", j.Name, err)\r\n\t\t}\r\n\t\tps[i].Brancher = b\r\n\t\tc, err := setChangeRegexes(j.RegexpChangeMatcher)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"could not set change regexes for %s: %v\", j.Name, err)\r\n\t\t}\r\n\t\tps[i].RegexpChangeMatcher = c\r\n\t}\r\n\treturn nil\r\n}","code-length":191,"reference":"\/\/ SetPostsubmitRegexes compiles and validates all the regular expressions for\n\/\/ the provided postsubmits.","result":"Set the postsubmit regexes.","score":[0.0262,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lens Lens) Body(artifacts []lenses.Artifact, resourceDir string, data string) string {\r\n\tvar buf bytes.Buffer\r\n\ttype MetadataViewData struct {\r\n\t\tStatus       string\r\n\t\tStartTime    time.Time\r\n\t\tFinishedTime time.Time\r\n\t\tElapsed      time.Duration\r\n\t\tMetadata     map[string]string\r\n\t}\r\n\tmetadataViewData := MetadataViewData{Status: \"Pending\"}\r\n\tstarted := gcs.Started{}\r\n\tfinished := gcs.Finished{}\r\n\tfor _, a := range artifacts {\r\n\t\tread, err := a.ReadAll()\r\n\t\tif err != nil {\r\n\t\t\tlogrus.WithError(err).Error(\"Failed reading from artifact.\")\r\n\t\t}\r\n\t\tif a.JobPath() == \"started.json\" {\r\n\t\t\tif err = json.Unmarshal(read, &started); err != nil {\r\n\t\t\t\tlogrus.WithError(err).Error(\"Error unmarshaling started.json\")\r\n\t\t\t}\r\n\t\t\tmetadataViewData.StartTime = time.Unix(started.Timestamp, 0)\r\n\t\t} else if a.JobPath() == \"finished.json\" {\r\n\t\t\tif err = json.Unmarshal(read, &finished); err != nil {\r\n\t\t\t\tlogrus.WithError(err).Error(\"Error unmarshaling finished.json\")\r\n\t\t\t}\r\n\t\t\tif finished.Timestamp != nil {\r\n\t\t\t\tmetadataViewData.FinishedTime = time.Unix(*finished.Timestamp, 0)\r\n\t\t\t}\r\n\t\t\tmetadataViewData.Status = finished.Result\r\n\t\t}\r\n\t}\r\n\tif !metadataViewData.StartTime.IsZero() {\r\n\t\tif metadataViewData.FinishedTime.IsZero() {\r\n\t\t\tmetadataViewData.Elapsed = time.Now().Sub(metadataViewData.StartTime)\r\n\t\t} else {\r\n\t\t\tmetadataViewData.Elapsed =\r\n\t\t\t\tmetadataViewData.FinishedTime.Sub(metadataViewData.StartTime)\r\n\t\t}\r\n\t\tmetadataViewData.Elapsed = metadataViewData.Elapsed.Round(time.Second)\r\n\t}\r\n\tmetadataViewData.Metadata = map[string]string{\"node\": started.Node}\r\n\tmetadatas := []metadata.Metadata{started.Metadata, finished.Metadata}\r\n\tfor _, m := range metadatas {\r\n\t\tfor k, v := range m {\r\n\t\t\tif s, ok := v.(string); ok && v != \"\" {\r\n\t\t\t\tmetadataViewData.Metadata[k] = s\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tmetadataTemplate, err := template.ParseFiles(filepath.Join(resourceDir, \"template.html\"))\r\n\tif err != nil {\r\n\t\treturn fmt.Sprintf(\"Failed to load template: %v\", err)\r\n\t}\r\n\tif err := metadataTemplate.ExecuteTemplate(&buf, \"body\", metadataViewData); err != nil {\r\n\t\tlogrus.WithError(err).Error(\"Error executing template.\")\r\n\t}\r\n\treturn buf.String()\r\n}","code-length":727,"reference":"\/\/ Body creates a view for prow job metadata.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewBoskosHandler(r *ranch.Ranch) *http.ServeMux {\r\n\tmux := http.NewServeMux()\r\n\tmux.Handle(\"\/\", handleDefault(r))\r\n\tmux.Handle(\"\/acquire\", handleAcquire(r))\r\n\tmux.Handle(\"\/acquirebystate\", handleAcquireByState(r))\r\n\tmux.Handle(\"\/release\", handleRelease(r))\r\n\tmux.Handle(\"\/reset\", handleReset(r))\r\n\tmux.Handle(\"\/update\", handleUpdate(r))\r\n\tmux.Handle(\"\/metric\", handleMetric(r))\r\n\treturn mux\r\n}","code-length":169,"reference":"\/\/NewBoskosHandler constructs the boskos handler.","result":"Create a handler for boskos.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ErrorToStatus(err error) int {\r\n\tswitch err.(type) {\r\n\tdefault:\r\n\t\treturn http.StatusInternalServerError\r\n\tcase *ranch.OwnerNotMatch:\r\n\t\treturn http.StatusUnauthorized\r\n\tcase *ranch.ResourceNotFound:\r\n\t\treturn http.StatusNotFound\r\n\tcase *ranch.ResourceTypeNotFound:\r\n\t\treturn http.StatusNotFound\r\n\tcase *ranch.StateNotMatch:\r\n\t\treturn http.StatusConflict\r\n\t}\r\n}","code-length":128,"reference":"\/\/ ErrorToStatus translates error into http code","result":"Convert error to status.","score":[0.1509,0.0746]}
{"code":"\/*is used to<extra_id_0>\r\nfunc DumpProfile(destination string, profile []*cover.Profile) error {\r\n\tvar output io.Writer\r\n\tif destination == \"-\" {\r\n\t\toutput = os.Stdout\r\n\t} else {\r\n\t\tf, err := os.Create(destination)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to open %s: %v\", destination, err)\r\n\t\t}\r\n\t\tdefer f.Close()\r\n\t\toutput = f\r\n\t}\r\n\terr := cov.DumpProfile(profile, output)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to dump profile: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":179,"reference":"\/\/ DumpProfile dumps the profile to the given file destination.\n\/\/ If the destination is \"-\", it instead writes to stdout.","result":"Dump profile to stdout.","score":[0.0079,0.1635]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadProfile(origin string) ([]*cover.Profile, error) {\r\n\tfilename := origin\r\n\tif origin == \"-\" {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\ttf, err := ioutil.TempFile(\"\", \"\")\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"failed to create temp file: %v\", err)\r\n\t\t}\r\n\t\tdefer tf.Close()\r\n\t\tdefer os.Remove(tf.Name())\r\n\t\tif _, err := io.Copy(tf, os.Stdin); err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"failed to copy stdin to temp file: %v\", err)\r\n\t\t}\r\n\t\tfilename = tf.Name()\r\n\t}\r\n\treturn cover.ParseProfiles(filename)\r\n}","code-length":202,"reference":"\/\/ LoadProfile loads a profile from the given filename.\n\/\/ If the filename is \"-\", it instead reads from stdin.","result":"Load a profile from a file.","score":[0.0386,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient() (*Client, error) {\r\n\tg, err := exec.LookPath(\"git\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tt, err := ioutil.TempDir(\"\", \"git\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &Client{\r\n\t\tlogger:    logrus.WithField(\"client\", \"git\"),\r\n\t\tdir:       t,\r\n\t\tgit:       g,\r\n\t\tbase:      fmt.Sprintf(\"https:\r\n\t\trepoLocks: make(map[string]*sync.Mutex),\r\n\t}, nil\r\n}","code-length":171,"reference":"\/\/ NewClient returns a client that talks to GitHub. It will fail if git is not\n\/\/ in the PATH.","result":"Create a new client.","score":[0.0059,0.0272]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) SetCredentials(user string, tokenGenerator func() []byte) {\r\n\tc.credLock.Lock()\r\n\tdefer c.credLock.Unlock()\r\n\tc.user = user\r\n\tc.tokenGenerator = tokenGenerator\r\n}","code-length":71,"reference":"\/\/ SetCredentials sets credentials in the client to be used for pushing to\n\/\/ or pulling from remote repositories.","result":"Set credentials.","score":[0,0.0289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Repo) Checkout(commitlike string) error {\r\n\tr.logger.Infof(\"Checkout %s.\", commitlike)\r\n\tco := r.gitCommand(\"checkout\", commitlike)\r\n\tif b, err := co.CombinedOutput(); err != nil {\r\n\t\treturn fmt.Errorf(\"error checking out %s: %v. output: %s\", commitlike, err, string(b))\r\n\t}\r\n\treturn nil\r\n}","code-length":117,"reference":"\/\/ Checkout runs git checkout.","result":"Create a new function to create a new repository.","score":[0,0.0926]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Repo) CheckoutNewBranch(branch string) error {\r\n\tr.logger.Infof(\"Create and checkout %s.\", branch)\r\n\tco := r.gitCommand(\"checkout\", \"-b\", branch)\r\n\tif b, err := co.CombinedOutput(); err != nil {\r\n\t\treturn fmt.Errorf(\"error checking out %s: %v. output: %s\", branch, err, string(b))\r\n\t}\r\n\treturn nil\r\n}","code-length":120,"reference":"\/\/ CheckoutNewBranch creates a new branch and checks it out.","result":"Create a new branch.","score":[0.1008,0.3132]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Repo) Merge(commitlike string) (bool, error) {\r\n\tr.logger.Infof(\"Merging %s.\", commitlike)\r\n\tco := r.gitCommand(\"merge\", \"--no-ff\", \"--no-stat\", \"-m merge\", commitlike)\r\n\tb, err := co.CombinedOutput()\r\n\tif err == nil {\r\n\t\treturn true, nil\r\n\t}\r\n\tr.logger.WithError(err).Infof(\"Merge failed with output: %s\", string(b))\r\n\tif b, err := r.gitCommand(\"merge\", \"--abort\").CombinedOutput(); err != nil {\r\n\t\treturn false, fmt.Errorf(\"error aborting merge for commitlike %s: %v. output: %s\", commitlike, err, string(b))\r\n\t}\r\n\treturn false, nil\r\n}","code-length":210,"reference":"\/\/ Merge attempts to merge commitlike into the current branch. It returns true\n\/\/ if the merge completes. It returns an error if the abort fails.","result":"Generate code for the generated code.","score":[0.0069,0.0208]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Repo) CheckoutPullRequest(number int) error {\r\n\tr.logger.Infof(\"Fetching and checking out %s#%d.\", r.repo, number)\r\n\tif b, err := retryCmd(r.logger, r.Dir, r.git, \"fetch\", r.base+\"\/\"+r.repo, fmt.Sprintf(\"pull\/%d\/head:pull%d\", number, number)); err != nil {\r\n\t\treturn fmt.Errorf(\"git fetch failed for PR %d: %v. output: %s\", number, err, string(b))\r\n\t}\r\n\tco := r.gitCommand(\"checkout\", fmt.Sprintf(\"pull%d\", number))\r\n\tif b, err := co.CombinedOutput(); err != nil {\r\n\t\treturn fmt.Errorf(\"git checkout failed for PR %d: %v. output: %s\", number, err, string(b))\r\n\t}\r\n\treturn nil\r\n}","code-length":231,"reference":"\/\/ CheckoutPullRequest does exactly that.","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *Repo) Config(key, value string) error {\r\n\tr.logger.Infof(\"Running git config %s %s\", key, value)\r\n\tif b, err := r.gitCommand(\"config\", key, value).CombinedOutput(); err != nil {\r\n\t\treturn fmt.Errorf(\"git config %s %s failed: %v. output: %s\", key, value, err, string(b))\r\n\t}\r\n\treturn nil\r\n}","code-length":119,"reference":"\/\/ Config runs git config.","result":"Set the config value of a repo.","score":[0,0.0962]}
{"code":"\/*is used to<extra_id_0>\r\nfunc retryCmd(l *logrus.Entry, dir, cmd string, arg ...string) ([]byte, error) {\r\n\tvar b []byte\r\n\tvar err error\r\n\tsleepyTime := time.Second\r\n\tfor i := 0; i < 3; i++ {\r\n\t\tc := exec.Command(cmd, arg...)\r\n\t\tc.Dir = dir\r\n\t\tb, err = c.CombinedOutput()\r\n\t\tif err != nil {\r\n\t\t\tl.Warningf(\"Running %s %v returned error %v with output %s.\", cmd, arg, err, string(b))\r\n\t\t\ttime.Sleep(sleepyTime)\r\n\t\t\tsleepyTime *= 2\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tbreak\r\n\t}\r\n\treturn b, err\r\n}","code-length":203,"reference":"\/\/ retryCmd will retry the command a few times with backoff. Use this for any\n\/\/ commands that will be talking to GitHub, such as clones or fetches.","result":"Retry commands.","score":[0,0.0197]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LabelsAndAnnotationsForSpec(spec prowapi.ProwJobSpec, extraLabels, extraAnnotations map[string]string) (map[string]string, map[string]string) {\r\n\tjobNameForLabel := spec.Job\r\n\tif len(jobNameForLabel) > validation.LabelValueMaxLength {\r\n\t\t\r\n\t\tjobNameForLabel = strings.TrimRight(spec.Job[:validation.LabelValueMaxLength], \".-\")\r\n\t\tlogrus.WithFields(logrus.Fields{\r\n\t\t\t\"job\":       spec.Job,\r\n\t\t\t\"key\":       kube.ProwJobAnnotation,\r\n\t\t\t\"value\":     spec.Job,\r\n\t\t\t\"truncated\": jobNameForLabel,\r\n\t\t}).Info(\"Cannot use full job name, will truncate.\")\r\n\t}\r\n\tlabels := map[string]string{\r\n\t\tkube.CreatedByProw:     \"true\",\r\n\t\tkube.ProwJobTypeLabel:  string(spec.Type),\r\n\t\tkube.ProwJobAnnotation: jobNameForLabel,\r\n\t}\r\n\tif spec.Type != prowapi.PeriodicJob && spec.Refs != nil {\r\n\t\tlabels[kube.OrgLabel] = spec.Refs.Org\r\n\t\tlabels[kube.RepoLabel] = spec.Refs.Repo\r\n\t\tif len(spec.Refs.Pulls) > 0 {\r\n\t\t\tlabels[kube.PullLabel] = strconv.Itoa(spec.Refs.Pulls[0].Number)\r\n\t\t}\r\n\t}\r\n\tfor k, v := range extraLabels {\r\n\t\tlabels[k] = v\r\n\t}\r\n\t\r\n\tfor key, value := range labels {\r\n\t\tif errs := validation.IsValidLabelValue(value); len(errs) > 0 {\r\n\t\t\t\tbase := filepath.Base(value)\r\n\t\t\tif errs := validation.IsValidLabelValue(base); len(errs) == 0 {\r\n\t\t\t\tlabels[key] = base\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tlogrus.WithFields(logrus.Fields{\r\n\t\t\t\t\"key\":    key,\r\n\t\t\t\t\"value\":  value,\r\n\t\t\t\t\"errors\": errs,\r\n\t\t\t}).Warn(\"Removing invalid label\")\r\n\t\t\tdelete(labels, key)\r\n\t\t}\r\n\t}\r\n\tannotations := map[string]string{\r\n\t\tkube.ProwJobAnnotation: spec.Job,\r\n\t}\r\n\tfor k, v := range extraAnnotations {\r\n\t\tannotations[k] = v\r\n\t}\r\n\treturn labels, annotations\r\n}","code-length":637,"reference":"\/\/ LabelsAndAnnotationsForSpec returns a minimal set of labels to add to prowjobs or its owned resources.\n\/\/\n\/\/ User-provided extraLabels and extraAnnotations values will take precedence over auto-provided values.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ProwJobToPod(pj prowapi.ProwJob, buildID string) (*coreapi.Pod, error) {\r\n\tif pj.Spec.PodSpec == nil {\r\n\t\treturn nil, fmt.Errorf(\"prowjob %q lacks a pod spec\", pj.Name)\r\n\t}\r\n\trawEnv, err := downwardapi.EnvForSpec(downwardapi.NewJobSpec(pj.Spec, buildID, pj.Name))\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tspec := pj.Spec.PodSpec.DeepCopy()\r\n\tspec.RestartPolicy = \"Never\"\r\n\tspec.Containers[0].Name = kube.TestContainerName\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tif spec.AutomountServiceAccountToken == nil && spec.ServiceAccountName == \"\" {\r\n\t\tmyFalse := false\r\n\t\tspec.AutomountServiceAccountToken = &myFalse\r\n\t}\r\n\tif pj.Spec.DecorationConfig == nil {\r\n\t\tspec.Containers[0].Env = append(spec.Containers[0].Env, kubeEnv(rawEnv)...)\r\n\t} else {\r\n\t\tif err := decorate(spec, &pj, rawEnv); err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"error decorating podspec: %v\", err)\r\n\t\t}\r\n\t}\r\n\tpodLabels, annotations := LabelsAndAnnotationsForJob(pj)\r\n\treturn &coreapi.Pod{\r\n\t\tObjectMeta: metav1.ObjectMeta{\r\n\t\t\tName:        pj.ObjectMeta.Name,\r\n\t\t\tLabels:      podLabels,\r\n\t\t\tAnnotations: annotations,\r\n\t\t},\r\n\t\tSpec: *spec,\r\n\t}, nil\r\n}","code-length":441,"reference":"\/\/ ProwJobToPod converts a ProwJob to a Pod that will run the tests.","result":"Convert ProwJob to pod.","score":[0.0476,0.2112]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CloneLogPath(logMount coreapi.VolumeMount) string {\r\n\treturn filepath.Join(logMount.MountPath, cloneLogPath)\r\n}","code-length":45,"reference":"\/\/ CloneLogPath returns the path to the clone log file in the volume mount.\n\/\/ CloneLogPath returns the path to the clone log file in the volume mount.","result":"Generate the generated code.","score":[0.0008,0.0195]}
{"code":"\/*is used to<extra_id_0>\r\nfunc cloneEnv(opt clonerefs.Options) ([]coreapi.EnvVar, error) {\r\n\t\r\n\tcloneConfigEnv, err := clonerefs.Encode(opt)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn kubeEnv(map[string]string{clonerefs.JSONConfigEnvVar: cloneConfigEnv}), nil\r\n}","code-length":105,"reference":"\/\/ cloneEnv encodes clonerefs Options into json and puts it into an environment variable","result":"Clone the environment.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc sshVolume(secret string) (coreapi.Volume, coreapi.VolumeMount) {\r\n\tvar sshKeyMode int32 = 0400\r\n\tname := strings.Join([]string{\"ssh-keys\", secret}, \"-\")\r\n\tmountPath := path.Join(\"\/secrets\/ssh\", secret)\r\n\tv := coreapi.Volume{\r\n\t\tName: name,\r\n\t\tVolumeSource: coreapi.VolumeSource{\r\n\t\t\tSecret: &coreapi.SecretVolumeSource{\r\n\t\t\t\tSecretName:  secret,\r\n\t\t\t\tDefaultMode: &sshKeyMode,\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n\tvm := coreapi.VolumeMount{\r\n\t\tName:      name,\r\n\t\tMountPath: mountPath,\r\n\t\tReadOnly:  true,\r\n\t}\r\n\treturn v, vm\r\n}","code-length":210,"reference":"\/\/ sshVolume converts a secret holding ssh keys into the corresponding volume and mount.\n\/\/\n\/\/ This is used by CloneRefs to attach the mount to the clonerefs container.","result":"Mount a secret to a volume.","score":[0.0065,0.0749]}
{"code":"\/*is used to<extra_id_0>\r\nfunc InjectEntrypoint(c *coreapi.Container, timeout, gracePeriod time.Duration, prefix, previousMarker string, exitZero bool, log, tools coreapi.VolumeMount) (*wrapper.Options, error) {\r\n\twrapperOptions := &wrapper.Options{\r\n\t\tArgs:         append(c.Command, c.Args...),\r\n\t\tProcessLog:   processLog(log, prefix),\r\n\t\tMarkerFile:   markerFile(log, prefix),\r\n\t\tMetadataFile: metadataFile(log, prefix),\r\n\t}\r\n\t\r\n\tentrypointConfigEnv, err := entrypoint.Encode(entrypoint.Options{\r\n\t\tArtifactDir:    artifactsDir(log),\r\n\t\tGracePeriod:    gracePeriod,\r\n\t\tOptions:        wrapperOptions,\r\n\t\tTimeout:        timeout,\r\n\t\tAlwaysZero:     exitZero,\r\n\t\tPreviousMarker: previousMarker,\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tc.Command = []string{entrypointLocation(tools)}\r\n\tc.Args = nil\r\n\tc.Env = append(c.Env, kubeEnv(map[string]string{entrypoint.JSONConfigEnvVar: entrypointConfigEnv})...)\r\n\tc.VolumeMounts = append(c.VolumeMounts, log, tools)\r\n\treturn wrapperOptions, nil\r\n}","code-length":333,"reference":"\/\/ InjectEntrypoint will make the entrypoint binary in the tools volume the container's entrypoint, which will output to the log volume.","result":"Inject the entrypoint.","score":[0.001,0.026]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PlaceEntrypoint(image string, toolsMount coreapi.VolumeMount) coreapi.Container {\r\n\treturn coreapi.Container{\r\n\t\tName:         \"place-entrypoint\",\r\n\t\tImage:        image,\r\n\t\tCommand:      []string{\"\/bin\/cp\"},\r\n\t\tArgs:         []string{\"\/entrypoint\", entrypointLocation(toolsMount)},\r\n\t\tVolumeMounts: []coreapi.VolumeMount{toolsMount},\r\n\t}\r\n}","code-length":122,"reference":"\/\/ PlaceEntrypoint will copy entrypoint from the entrypoint image to the tools volume","result":"Place the entrypoint.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc kubeEnv(environment map[string]string) []coreapi.EnvVar {\r\n\tvar keys []string\r\n\tfor key := range environment {\r\n\t\tkeys = append(keys, key)\r\n\t}\r\n\tsort.Strings(keys)\r\n\tvar kubeEnvironment []coreapi.EnvVar\r\n\tfor _, key := range keys {\r\n\t\tkubeEnvironment = append(kubeEnvironment, coreapi.EnvVar{\r\n\t\t\tName:  key,\r\n\t\t\tValue: environment[key],\r\n\t\t})\r\n\t}\r\n\treturn kubeEnvironment\r\n}","code-length":148,"reference":"\/\/ kubeEnv transforms a mapping of environment variables\n\/\/ into their serialized form for a PodSpec, sorting by\n\/\/ the name of the env vars","result":"Generate the kubeEnv function.","score":[0.002,0.0437]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *KubernetesOptions) Client(namespace string, dryRun bool) (*kube.Client, error) {\r\n\tif dryRun {\r\n\t\treturn kube.NewFakeClient(o.DeckURI), nil\r\n\t}\r\n\tif o.cluster == \"\" {\r\n\t\treturn kube.NewClientInCluster(namespace)\r\n\t}\r\n\treturn kube.NewClientFromFile(o.cluster, namespace)\r\n}","code-length":108,"reference":"\/\/ Client returns a Kubernetes client.","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc handle(gc githubClient, le *logrus.Entry, e *event) error {\r\n\tneedsLabel := e.draft || titleRegex.MatchString(e.title)\r\n\tif needsLabel && !e.hasLabel {\r\n\t\tif err := gc.AddLabel(e.org, e.repo, e.number, labels.WorkInProgress); err != nil {\r\n\t\t\tle.Warnf(\"error while adding Label %q: %v\", labels.WorkInProgress, err)\r\n\t\t\treturn err\r\n\t\t}\r\n\t} else if !needsLabel && e.hasLabel {\r\n\t\tif err := gc.RemoveLabel(e.org, e.repo, e.number, labels.WorkInProgress); err != nil {\r\n\t\t\tle.Warnf(\"error while removing Label %q: %v\", labels.WorkInProgress, err)\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":229,"reference":"\/\/ handle interacts with GitHub to drive the pull request to the\n\/\/ proper state by adding and removing comments and labels. If a\n\/\/ PR has a WIP prefix, it needs an explanatory comment and label.\n\/\/ Otherwise, neither should be present.","result":"Handle events in github.","score":[0,0.0128]}
{"code":"\/*is used to<extra_id_0>\r\nfunc SendHook(address, eventType string, payload, hmac []byte) error {\r\n\treq, err := http.NewRequest(http.MethodPost, address, bytes.NewBuffer(payload))\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treq.Header.Set(\"X-GitHub-Event\", eventType)\r\n\treq.Header.Set(\"X-GitHub-Delivery\", \"GUID\")\r\n\treq.Header.Set(\"X-Hub-Signature\", github.PayloadSignature(payload, hmac))\r\n\treq.Header.Set(\"content-type\", \"application\/json\")\r\n\tc := &http.Client{}\r\n\tresp, err := c.Do(req)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\trb, err := ioutil.ReadAll(resp.Body)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif resp.StatusCode != 200 {\r\n\t\treturn fmt.Errorf(\"response from hook has status %d and body %s\", resp.StatusCode, string(bytes.TrimSpace(rb)))\r\n\t}\r\n\treturn nil\r\n}","code-length":288,"reference":"\/\/ SendHook sends a GitHub event of type eventType to the provided address.","result":"Send a hook to a GitHub address.","score":[0.1153,0.3]}
{"code":"\/*is used to<extra_id_0>\r\nfunc janitorClean(resource *common.Resource, flags []string) error {\r\n\targs := append([]string{fmt.Sprintf(\"--%s=%s\", format(resource.Type), resource.Name)}, flags...)\r\n\tlogrus.Infof(\"executing janitor: %s %s\", *janitorPath, strings.Join(args, \" \"))\r\n\tcmd := exec.Command(*janitorPath, args...)\r\n\tb, err := cmd.CombinedOutput()\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Errorf(\"failed to clean up project %s, error info: %s\", resource.Name, string(b))\r\n\t} else {\r\n\t\tlogrus.Tracef(\"output from janitor: %s\", string(b))\r\n\t\tlogrus.Infof(\"successfully cleaned up resource %s\", resource.Name)\r\n\t}\r\n\treturn err\r\n}","code-length":230,"reference":"\/\/ Clean by janitor script","result":"Clean up project .","score":[0.2488,0.102]}
{"code":"\/*is used to<extra_id_0>\r\nfunc janitor(c boskosClient, buffer <-chan *common.Resource, fn clean, flags []string) {\r\n\tfor {\r\n\t\tresource := <-buffer\r\n\t\tdest := common.Free\r\n\t\tif err := fn(resource, flags); err != nil {\r\n\t\t\tlogrus.WithError(err).Errorf(\"%s failed!\", *janitorPath)\r\n\t\t\tdest = common.Dirty\r\n\t\t}\r\n\t\tif err := c.ReleaseOne(resource.Name, dest); err != nil {\r\n\t\t\tlogrus.WithError(err).Error(\"boskos release failed!\")\r\n\t\t}\r\n\t}\r\n}","code-length":167,"reference":"\/\/ async janitor goroutine","result":"Avoid the need for the janitor .","score":[0.1615,0.1163]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *PullServer) Run(ctx context.Context) error {\r\n\tconfigEvent := make(chan config.Delta, 2)\r\n\ts.Subscriber.ConfigAgent.Subscribe(configEvent)\r\n\tvar err error\r\n\tdefer func() {\r\n\t\tif err != nil {\r\n\t\t\tlogrus.WithError(ctx.Err()).Error(\"Pull server shutting down\")\r\n\t\t}\r\n\t\tlogrus.Warn(\"Pull server shutting down\")\r\n\t}()\r\n\tcurrentConfig := s.Subscriber.ConfigAgent.Config().PubSubSubscriptions\r\n\terrGroup, derivedCtx, err := s.handlePulls(ctx, currentConfig)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tfor {\r\n\t\tselect {\r\n\t\t\r\n\t\tcase <-ctx.Done():\r\n\t\t\treturn ctx.Err()\r\n\t\t\r\n\t\tcase <-derivedCtx.Done():\r\n\t\t\terr = errGroup.Wait()\r\n\t\t\treturn err\r\n\t\t\r\n\t\tcase event := <-configEvent:\r\n\t\t\tnewConfig := event.After.PubSubSubscriptions\r\n\t\t\tlogrus.Info(\"Received new config\")\r\n\t\t\tif !reflect.DeepEqual(currentConfig, newConfig) {\r\n\t\t\t\tlogrus.Warn(\"New config found, reloading pull Server\")\r\n\t\t\t\t\r\n\t\t\t\terrGroup.Wait()\r\n\t\t\t\t\r\n\t\t\t\terrGroup, derivedCtx, err = s.handlePulls(ctx, newConfig)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t\tcurrentConfig = newConfig\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":402,"reference":"\/\/ Run will block listening to all subscriptions and return once the context is cancelled\n\/\/ or one of the subscription has a unrecoverable error.","result":"Run the server.","score":[0.0003,0.0439]}
{"code":"\/*is used to<extra_id_0>\r\nfunc specToStarted(spec *downwardapi.JobSpec, mainRefSHA string) gcs.Started {\r\n\tstarted := gcs.Started{\r\n\t\tTimestamp:   time.Now().Unix(),\r\n\t\tRepoVersion: downwardapi.GetRevisionFromSpec(spec),\r\n\t}\r\n\tif mainRefSHA != \"\" {\r\n\t\tstarted.RepoVersion = mainRefSHA\r\n\t}\r\n\t\r\n\tif spec.Refs != nil && len(spec.Refs.Pulls) > 0 {\r\n\t\tstarted.Pull = strconv.Itoa(spec.Refs.Pulls[0].Number)\r\n\t}\r\n\tstarted.Repos = map[string]string{}\r\n\tif spec.Refs != nil {\r\n\t\tstarted.Repos[spec.Refs.Org+\"\/\"+spec.Refs.Repo] = spec.Refs.String()\r\n\t}\r\n\tfor _, ref := range spec.ExtraRefs {\r\n\t\tstarted.Repos[ref.Org+\"\/\"+ref.Repo] = ref.String()\r\n\t}\r\n\treturn started\r\n}","code-length":260,"reference":"\/\/ specToStarted translate a jobspec into a started struct\n\/\/ optionally overwrite RepoVersion with provided mainRefSHA","result":"Convert spec to started object.","score":[0.0266,0.0336]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Options) Run() error {\r\n\tspec, err := downwardapi.ResolveSpecFromEnv()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"could not resolve job spec: %v\", err)\r\n\t}\r\n\tuploadTargets := map[string]gcs.UploadFunc{}\r\n\tvar failed bool\r\n\tvar mainRefSHA string\r\n\tif o.Log != \"\" {\r\n\t\tif failed, mainRefSHA, err = processCloneLog(o.Log, uploadTargets); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\tstarted := specToStarted(spec, mainRefSHA)\r\n\tstartedData, err := json.Marshal(&started)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"could not marshal starting data: %v\", err)\r\n\t}\r\n\tuploadTargets[\"started.json\"] = gcs.DataUpload(bytes.NewReader(startedData))\r\n\tif err := o.Options.Run(spec, uploadTargets); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to upload to GCS: %v\", err)\r\n\t}\r\n\tif failed {\r\n\t\treturn errors.New(\"cloning the appropriate refs failed\")\r\n\t}\r\n\treturn nil\r\n}","code-length":314,"reference":"\/\/ Run will start the initupload job to upload the artifacts, logs and clone status.","result":"Clone the appropriate refs.","score":[0.0204,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc hasPRChanged(pr github.PullRequestEvent) bool {\r\n\tswitch pr.Action {\r\n\tcase github.PullRequestActionOpened:\r\n\t\treturn true\r\n\tcase github.PullRequestActionReopened:\r\n\t\treturn true\r\n\tcase github.PullRequestActionSynchronize:\r\n\t\treturn true\r\n\tdefault:\r\n\t\treturn false\r\n\t}\r\n}","code-length":98,"reference":"\/\/ hasPRChanged indicates that the code diff may have changed.","result":"Check if PR has changed.","score":[0.0884,0.0526]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UpdateIssues(db *gorm.DB, client ClientInterface) {\r\n\tlatest, err := findLatestIssueUpdate(db, client.RepositoryName())\r\n\tif err != nil {\r\n\t\tglog.Error(\"Failed to find last issue update: \", err)\r\n\t\treturn\r\n\t}\r\n\tc := make(chan *github.Issue, 200)\r\n\tgo client.FetchIssues(latest, c)\r\n\tfor issue := range c {\r\n\t\tissueOrm, err := NewIssue(issue, client.RepositoryName())\r\n\t\tif err != nil {\r\n\t\t\tglog.Error(\"Can't create issue:\", err)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif db.Create(issueOrm).Error != nil {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tdb.Delete(sql.Label{},\r\n\t\t\t\t\"issue_id = ? AND repository = ?\",\r\n\t\t\t\tissueOrm.ID, client.RepositoryName())\r\n\t\t\tdb.Delete(sql.Assignee{},\r\n\t\t\t\t\"issue_id = ? AND repository = ?\",\r\n\t\t\t\tissueOrm.ID, client.RepositoryName())\r\n\t\t\tif err := db.Save(issueOrm).Error; err != nil {\r\n\t\t\t\tglog.Error(\"Failed to update database issue: \", err)\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tUpdateComments(*issue.Number, issueOrm.IsPR, db, client)\r\n\t\t\r\n\t\tUpdateIssueEvents(*issue.Number, db, client)\r\n\t}\r\n}","code-length":383,"reference":"\/\/ UpdateIssues downloads new issues and saves in database","result":"Update issues in the database.","score":[0.1284,0.1163]}
{"code":"\/*is used to<extra_id_0>\r\nfunc handleReviewEvent(pc plugins.Agent, re github.ReviewEvent) error {\r\n\treturn handleReview(\r\n\t\tpc.Logger,\r\n\t\tpc.GitHubClient,\r\n\t\tpc.OwnersClient,\r\n\t\tpc.Config.GitHubOptions,\r\n\t\tpc.PluginConfig,\r\n\t\t&re,\r\n\t)\r\n}","code-length":95,"reference":"\/\/ handleReviewEvent should only handle reviews that have no approval command.\n\/\/ Reviews with approval commands will be handled by handleGenericCommentEvent.","result":"Handle review events.","score":[0,0.0521]}
{"code":"\/*is used to<extra_id_0>\r\nfunc findAssociatedIssue(body, org string) (int, error) {\r\n\tassociatedIssueRegex, err := regexp.Compile(fmt.Sprintf(associatedIssueRegexFormat, org))\r\n\tif err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\tmatch := associatedIssueRegex.FindStringSubmatch(body)\r\n\tif len(match) == 0 {\r\n\t\treturn 0, nil\r\n\t}\r\n\tv, err := strconv.Atoi(match[1])\r\n\tif err != nil {\r\n\t\treturn 0, err\r\n\t}\r\n\treturn v, nil\r\n}","code-length":154,"reference":"\/\/ Returns associated issue, or 0 if it can't find any.\n\/\/ This is really simple, and could be improved later.","result":"Find associated issues in a body.","score":[0.0158,0.0513]}
{"code":"\/*is used to<extra_id_0>\r\nfunc optionsForRepo(config *plugins.Configuration, org, repo string) *plugins.Approve {\r\n\tfullName := fmt.Sprintf(\"%s\/%s\", org, repo)\r\n\ta := func() *plugins.Approve {\r\n\t\t\r\n\t\tfor _, c := range config.Approve {\r\n\t\t\tif !strInSlice(fullName, c.Repos) {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\treturn &c\r\n\t\t}\r\n\t\t\r\n\t\tfor _, c := range config.Approve {\r\n\t\t\tif !strInSlice(org, c.Repos) {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\treturn &c\r\n\t\t}\r\n\t\t\r\n\t\treturn &plugins.Approve{}\r\n\t}()\r\n\tif a.DeprecatedImplicitSelfApprove == nil && a.RequireSelfApproval == nil && config.UseDeprecatedSelfApprove {\r\n\t\tno := false\r\n\t\ta.DeprecatedImplicitSelfApprove = &no\r\n\t}\r\n\tif a.DeprecatedReviewActsAsApprove == nil && a.IgnoreReviewState == nil && config.UseDeprecatedReviewApprove {\r\n\t\tno := false\r\n\t\ta.DeprecatedReviewActsAsApprove = &no\r\n\t}\r\n\treturn a\r\n}","code-length":319,"reference":"\/\/ optionsForRepo gets the plugins.Approve struct that is applicable to the indicated repo.","result":"Generate the options for a repo.","score":[0.0715,0.0813]}
{"code":"\/*is used to<extra_id_0>\r\nfunc localOnlyMain(cfg config.Getter, o options, mux *http.ServeMux) *http.ServeMux {\r\n\tmux.Handle(\"\/github-login\", gziphandler.GzipHandler(handleSimpleTemplate(o, cfg, \"github-login.html\", nil)))\r\n\tif o.spyglass {\r\n\t\tinitSpyglass(cfg, o, mux, nil)\r\n\t}\r\n\treturn mux\r\n}","code-length":111,"reference":"\/\/ localOnlyMain contains logic used only when running locally, and is mutually exclusive with\n\/\/ prodOnlyMain.","result":"Run local only main.","score":[0.0159,0.0676]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (covList *CoverageList) summarize() {\r\n\tcovList.NumCoveredStmts = 0\r\n\tcovList.NumAllStmts = 0\r\n\tfor _, item := range covList.Group {\r\n\t\tcovList.NumCoveredStmts += item.NumCoveredStmts\r\n\t\tcovList.NumAllStmts += item.NumAllStmts\r\n\t}\r\n}","code-length":104,"reference":"\/\/ summarize summarizes all items in the Group and stores the result","result":"Summarize the coverage list.","score":[0.0432,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (covList *CoverageList) Subset(prefix string) *CoverageList {\r\n\ts := newCoverageList(\"Filtered Summary\")\r\n\tfor _, c := range covList.Group {\r\n\t\tif strings.HasPrefix(c.Name, prefix) {\r\n\t\t\tcovList.Group = append(covList.Group, c)\r\n\t\t}\r\n\t}\r\n\treturn s\r\n}","code-length":105,"reference":"\/\/ Subset returns the subset obtained through applying filter","result":"Filter the summary.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (covList CoverageList) ListDirectories() []string {\r\n\tdirSet := map[string]bool{}\r\n\tfor _, cov := range covList.Group {\r\n\t\tdirSet[path.Dir(cov.Name)] = true\r\n\t}\r\n\tvar result []string\r\n\tfor key := range dirSet {\r\n\t\tresult = append(result, key)\r\n\t}\r\n\treturn result\r\n}","code-length":110,"reference":"\/\/ ListDirectories gets a list a sub-directories that contains source code.","result":"List the directories in the list of directories.","score":[0.0955,0.0467]}
{"code":"\/*is used to<extra_id_0>\r\nfunc readRequest(r io.Reader, contentType string) (*admissionapi.AdmissionRequest, error) {\r\n\tif contentType != contentTypeJSON {\r\n\t\treturn nil, fmt.Errorf(\"Content-Type=%s, expected %s\", contentType, contentTypeJSON)\r\n\t}\r\n\t\r\n\tif r == nil {\r\n\t\treturn nil, fmt.Errorf(\"no body\")\r\n\t}\r\n\tbody, err := ioutil.ReadAll(r)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"read body: %v\", err)\r\n\t}\r\n\t\r\n\tvar ar admissionapi.AdmissionReview\r\n\tdeserializer := codecs.UniversalDeserializer()\r\n\tif _, _, err := deserializer.Decode(body, nil, &ar); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"decode body: %v\", err)\r\n\t}\r\n\treturn ar.Request, nil\r\n}","code-length":233,"reference":"\/\/ readRequest extracts the request from the AdmissionReview reader","result":"Read the request from the body.","score":[0.3665,0.4562]}
{"code":"\/*is used to<extra_id_0>\r\nfunc handle(w http.ResponseWriter, r *http.Request) {\r\n\treq, err := readRequest(r.Body, r.Header.Get(\"Content-Type\"))\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Error(\"read\")\r\n\t}\r\n\tif err := writeResponse(*req, w, onlyUpdateStatus); err != nil {\r\n\t\tlogrus.WithError(err).Error(\"write\")\r\n\t}\r\n}","code-length":120,"reference":"\/\/ handle reads the request and writes the response","result":"Handle requests.","score":[0,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc writeResponse(ar admissionapi.AdmissionRequest, w io.Writer, decide decider) error {\r\n\tresponse, err := decide(ar)\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Error(\"failed decision\")\r\n\t\tresponse = &admissionapi.AdmissionResponse{\r\n\t\t\tResult: &meta.Status{\r\n\t\t\t\tMessage: err.Error(),\r\n\t\t\t},\r\n\t\t}\r\n\t}\r\n\tvar result admissionapi.AdmissionReview\r\n\tresult.Response = response\r\n\tresult.Response.UID = ar.UID\r\n\tout, err := json.Marshal(result)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"encode response: %v\", err)\r\n\t}\r\n\tif _, err := w.Write(out); err != nil {\r\n\t\treturn fmt.Errorf(\"write response: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":237,"reference":"\/\/ writeResponse gets the response from onlyUpdateStatus and writes it to w.","result":"Write the response to the writer.","score":[0.1112,0.1754]}
{"code":"\/*is used to<extra_id_0>\r\nfunc onlyUpdateStatus(req admissionapi.AdmissionRequest) (*admissionapi.AdmissionResponse, error) {\r\n\tlogger := logrus.WithFields(logrus.Fields{\r\n\t\t\"resource\":    req.Resource,\r\n\t\t\"subresource\": req.SubResource,\r\n\t\t\"name\":        req.Name,\r\n\t\t\"namespace\":   req.Namespace,\r\n\t\t\"operation\":   req.Operation,\r\n\t})\r\n\t\r\n\tif req.SubResource == \"status\" {\r\n\t\tlogrus.Info(\"accept status update\")\r\n\t\treturn &allow, nil\r\n\t}\r\n\t\r\n\tvar new prowjobv1.ProwJob\r\n\tif _, _, err := codecs.UniversalDeserializer().Decode(req.Object.Raw, nil, &new); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"decode new: %v\", err)\r\n\t}\r\n\tvar old prowjobv1.ProwJob\r\n\tif _, _, err := codecs.UniversalDeserializer().Decode(req.OldObject.Raw, nil, &old); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"decode old: %v\", err)\r\n\t}\r\n\tif equality.Semantic.DeepEqual(old.Spec, new.Spec) {\r\n\t\tlogrus.Info(\"accept update with equivalent spec\")\r\n\t\treturn &allow, nil\r\n\t}\r\n\tlogger.Info(\"reject\")\r\n\treturn &reject, nil\r\n}","code-length":370,"reference":"\/\/ onlyUpdateStatus returns the response to the request","result":"Check if the status is updated.","score":[0.1383,0.0641]}
{"code":"\/*is used to<extra_id_0>\r\nfunc convertSuiteMeta(suiteMeta gcs.SuitesMeta) resultstore.Suite {\r\n\tout := resultstore.Suite{\r\n\t\tName: path.Base(suiteMeta.Path),\r\n\t\tFiles: []resultstore.File{\r\n\t\t\t{\r\n\t\t\t\tContentType: \"text\/xml\",\r\n\t\t\t\tID:          resultstore.UUID(),\r\n\t\t\t\tURL:         suiteMeta.Path,\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n\tfor _, suite := range suiteMeta.Suites.Suites {\r\n\t\tchild := resultstore.Suite{\r\n\t\t\tName:     suite.Name,\r\n\t\t\tDuration: dur(suite.Time),\r\n\t\t}\r\n\t\tswitch {\r\n\t\tcase suite.Failures > 0 && suite.Tests >= suite.Failures:\r\n\t\t\tchild.Failures = append(child.Failures, resultstore.Failure{\r\n\t\t\t\tMessage: fmt.Sprintf(\"%d out of %d tests failed (%.1f%% passing)\", suite.Failures, suite.Tests, float64(suite.Tests-suite.Failures)*100.0\/float64(suite.Tests)),\r\n\t\t\t})\r\n\t\tcase suite.Failures > 0:\r\n\t\t\tchild.Failures = append(child.Failures, resultstore.Failure{\r\n\t\t\t\tMessage: fmt.Sprintf(\"%d tests failed\", suite.Failures),\r\n\t\t\t})\r\n\t\t}\r\n\t\tfor _, result := range suite.Results {\r\n\t\t\tname, tags := stripTags(result.Name)\r\n\t\t\tclass := result.ClassName\r\n\t\t\tif class == \"\" {\r\n\t\t\t\tclass = strings.Join(tags, \" \")\r\n\t\t\t} else {\r\n\t\t\t\tclass += \" \" + strings.Join(tags, \" \")\r\n\t\t\t}\r\n\t\t\tc := resultstore.Case{\r\n\t\t\t\tName:     name,\r\n\t\t\t\tClass:    class,\r\n\t\t\t\tDuration: dur(result.Time),\r\n\t\t\t\tResult:   resultstore.Completed,\r\n\t\t\t}\r\n\t\t\tconst max = 5000\r\n\t\t\tmsg := result.Message(max)\r\n\t\t\tswitch {\r\n\t\t\tcase result.Failure != nil:\r\n\t\t\t\t\r\n\t\t\t\tif msg == \"\" {\r\n\t\t\t\t\tmsg = \"unknown failure\"\r\n\t\t\t\t}\r\n\t\t\t\tc.Failures = append(c.Failures, resultstore.Failure{\r\n\t\t\t\t\tMessage: msg,\r\n\t\t\t\t})\r\n\t\t\tcase result.Skipped != nil:\r\n\t\t\t\tc.Result = resultstore.Skipped\r\n\t\t\t\tif msg != \"\" {\r\n\t\t\t\t\tc.Errors = append(c.Errors, resultstore.Error{\r\n\t\t\t\t\t\tMessage: msg,\r\n\t\t\t\t\t})\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tchild.Cases = append(child.Cases, c)\r\n\t\t\tif c.Duration > child.Duration {\r\n\t\t\t\tchild.Duration = c.Duration\r\n\t\t\t}\r\n\t\t}\r\n\t\tif child.Duration > out.Duration {\r\n\t\t\t\r\n\t\t\tout.Duration = child.Duration\r\n\t\t}\r\n\t\tout.Suites = append(out.Suites, child)\r\n\t}\r\n\treturn out\r\n}","code-length":765,"reference":"\/\/ convertSuiteMeta converts a junit result in gcs to a ResultStore Suite.","result":"Code too long,keep in 512.","score":[0.0593,0.0442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewHealth() *Health {\r\n\thealthMux := http.NewServeMux()\r\n\thealthMux.HandleFunc(\"\/healthz\", func(w http.ResponseWriter, r *http.Request) { fmt.Fprint(w, \"OK\") })\r\n\tgo func() {\r\n\t\tlogrus.WithError(http.ListenAndServe(\":\"+strconv.Itoa(healthPort), healthMux)).Fatal(\"ListenAndServe returned.\")\r\n\t}()\r\n\treturn &Health{\r\n\t\thealthMux: healthMux,\r\n\t}\r\n}","code-length":140,"reference":"\/\/ NewHealth creates a new health request multiplexer and starts serving the liveness endpoint\n\/\/ on the given port","result":"Create a new health object.","score":[0.0301,0.2255]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *Health) ServeReady() {\r\n\th.healthMux.HandleFunc(\"\/healthz\/ready\", func(w http.ResponseWriter, r *http.Request) { fmt.Fprint(w, \"OK\") })\r\n}","code-length":66,"reference":"\/\/ ServeReady starts serving the readiness endpoint","result":"Serve the ready event.","score":[0.1509,0.4395]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewController(ghcSync, ghcStatus *github.Client, prowJobClient prowv1.ProwJobInterface, cfg config.Getter, gc *git.Client, maxRecordsPerPool int, opener io.Opener, historyURI, statusURI string, logger *logrus.Entry) (*Controller, error) {\r\n\tif logger == nil {\r\n\t\tlogger = logrus.NewEntry(logrus.StandardLogger())\r\n\t}\r\n\thist, err := history.New(maxRecordsPerPool, opener, historyURI)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error initializing history client from %q: %v\", historyURI, err)\r\n\t}\r\n\tsc := &statusController{\r\n\t\tlogger:         logger.WithField(\"controller\", \"status-update\"),\r\n\t\tghc:            ghcStatus,\r\n\t\tconfig:         cfg,\r\n\t\tnewPoolPending: make(chan bool, 1),\r\n\t\tshutDown:       make(chan bool),\r\n\t\topener:         opener,\r\n\t\tpath:           statusURI,\r\n\t}\r\n\tgo sc.run()\r\n\treturn &Controller{\r\n\t\tlogger:        logger.WithField(\"controller\", \"sync\"),\r\n\t\tghc:           ghcSync,\r\n\t\tprowJobClient: prowJobClient,\r\n\t\tconfig:        cfg,\r\n\t\tgc:            gc,\r\n\t\tsc:            sc,\r\n\t\tchangedFiles: &changedFilesAgent{\r\n\t\t\tghc:             ghcSync,\r\n\t\t\tnextChangeCache: make(map[changeCacheKey][]string),\r\n\t\t},\r\n\t\tHistory: hist,\r\n\t}, nil\r\n}","code-length":422,"reference":"\/\/ NewController makes a Controller out of the given clients.","result":"Create a new controller.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newExpectedContext(c string) Context {\r\n\treturn Context{\r\n\t\tContext:     githubql.String(c),\r\n\t\tState:       githubql.StatusStateExpected,\r\n\t\tDescription: githubql.String(\"\"),\r\n\t}\r\n}","code-length":73,"reference":"\/\/ newExpectedContext creates a Context with Expected state.","result":"Create a new context.","score":[0.1175,0.2467]}
{"code":"\/*is used to<extra_id_0>\r\nfunc contextsToStrings(contexts []Context) []string {\r\n\tvar names []string\r\n\tfor _, c := range contexts {\r\n\t\tnames = append(names, string(c.Context))\r\n\t}\r\n\treturn names\r\n}","code-length":67,"reference":"\/\/ contextsToStrings converts a list Context to a list of string","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) filterSubpools(goroutines int, raw map[string]*subpool) map[string]*subpool {\r\n\tfiltered := make(map[string]*subpool)\r\n\tvar lock sync.Mutex\r\n\tsubpoolsInParallel(\r\n\t\tgoroutines,\r\n\t\traw,\r\n\t\tfunc(sp *subpool) {\r\n\t\t\tif err := c.initSubpoolData(sp); err != nil {\r\n\t\t\t\tsp.log.WithError(err).Error(\"Error initializing subpool.\")\r\n\t\t\t\treturn\r\n\t\t\t}\r\n\t\t\tkey := poolKey(sp.org, sp.repo, sp.branch)\r\n\t\t\tif spFiltered := filterSubpool(c.ghc, sp); spFiltered != nil {\r\n\t\t\t\tsp.log.WithField(\"key\", key).WithField(\"pool\", spFiltered).Debug(\"filtered sub-pool\")\r\n\t\t\t\tlock.Lock()\r\n\t\t\t\tfiltered[key] = spFiltered\r\n\t\t\t\tlock.Unlock()\r\n\t\t\t} else {\r\n\t\t\t\tsp.log.WithField(\"key\", key).WithField(\"pool\", spFiltered).Debug(\"filtering sub-pool removed all PRs\")\r\n\t\t\t}\r\n\t\t},\r\n\t)\r\n\treturn filtered\r\n}","code-length":309,"reference":"\/\/ filterSubpools filters non-pool PRs out of the initially identified subpools,\n\/\/ deleting any pools that become empty.\n\/\/ See filterSubpool for filtering details.","result":"Filter subpools .","score":[0,0.0228]}
{"code":"\/*is used to<extra_id_0>\r\nfunc filterSubpool(ghc githubClient, sp *subpool) *subpool {\r\n\tvar toKeep []PullRequest\r\n\tfor _, pr := range sp.prs {\r\n\t\tif !filterPR(ghc, sp, &pr) {\r\n\t\t\ttoKeep = append(toKeep, pr)\r\n\t\t}\r\n\t}\r\n\tif len(toKeep) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\tsp.prs = toKeep\r\n\treturn sp\r\n}","code-length":131,"reference":"\/\/ filterSubpool filters PRs from an initially identified subpool, returning the\n\/\/ filtered subpool.\n\/\/ If the subpool becomes empty 'nil' is returned to indicate that the subpool\n\/\/ should be deleted.","result":"Filter subpool.","score":[0.0,0.0647]}
{"code":"\/*is used to<extra_id_0>\r\nfunc poolPRMap(subpoolMap map[string]*subpool) map[string]PullRequest {\r\n\tprs := make(map[string]PullRequest)\r\n\tfor _, sp := range subpoolMap {\r\n\t\tfor _, pr := range sp.prs {\r\n\t\t\tprs[prKey(&pr)] = pr\r\n\t\t}\r\n\t}\r\n\treturn prs\r\n}","code-length":105,"reference":"\/\/ poolPRMap collects all subpool PRs into a map containing all pooled PRs.","result":"Generate the PR map.","score":[0,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc unsuccessfulContexts(contexts []Context, cc contextChecker, log *logrus.Entry) []Context {\r\n\tvar failed []Context\r\n\tfor _, ctx := range contexts {\r\n\t\tif string(ctx.Context) == statusContext {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif cc.IsOptional(string(ctx.Context)) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif ctx.State != githubql.StatusStateSuccess {\r\n\t\t\tfailed = append(failed, ctx)\r\n\t\t}\r\n\t}\r\n\tfor _, c := range cc.MissingRequiredContexts(contextsToStrings(contexts)) {\r\n\t\tfailed = append(failed, newExpectedContext(c))\r\n\t}\r\n\tlog.Debugf(\"from %d total contexts (%v) found %d failing contexts: %v\", len(contexts), contextsToStrings(contexts), len(failed), contextsToStrings(failed))\r\n\treturn failed\r\n}","code-length":232,"reference":"\/\/ unsuccessfulContexts determines which contexts from the list that we care about are\n\/\/ failed. For instance, we do not care about our own context.\n\/\/ If the branchProtection is set to only check for required checks, we will skip\n\/\/ all non-required tests. If required tests are missing from the list, they will be\n\/\/ added to the list of failed contexts.","result":"Check for missing required contexts.","score":[0.0,0.065]}
{"code":"\/*is used to<extra_id_0>\r\nfunc accumulate(presubmits map[int][]config.Presubmit, prs []PullRequest, pjs []prowapi.ProwJob, log *logrus.Entry) (successes, pendings, nones []PullRequest) {\r\n\tfor _, pr := range prs {\r\n\t\t\r\n\t\tpsStates := make(map[string]simpleState)\r\n\t\tfor _, pj := range pjs {\r\n\t\t\tif pj.Spec.Type != prowapi.PresubmitJob {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tif pj.Spec.Refs.Pulls[0].Number != int(pr.Number) {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tif pj.Spec.Refs.Pulls[0].SHA != string(pr.HeadRefOID) {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tname := pj.Spec.Context\r\n\t\t\toldState := psStates[name]\r\n\t\t\tnewState := toSimpleState(pj.Status.State)\r\n\t\t\tif oldState == failureState || oldState == \"\" {\r\n\t\t\t\tpsStates[name] = newState\r\n\t\t\t} else if oldState == pendingState && newState == successState {\r\n\t\t\t\tpsStates[name] = successState\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\toverallState := successState\r\n\t\tfor _, ps := range presubmits[int(pr.Number)] {\r\n\t\t\tif s, ok := psStates[ps.Context]; !ok {\r\n\t\t\t\toverallState = failureState\r\n\t\t\t\tlog.WithFields(pr.logFields()).Debugf(\"missing presubmit %s\", ps.Context)\r\n\t\t\t\tbreak\r\n\t\t\t} else if s == failureState {\r\n\t\t\t\toverallState = failureState\r\n\t\t\t\tlog.WithFields(pr.logFields()).Debugf(\"presubmit %s not passing\", ps.Context)\r\n\t\t\t\tbreak\r\n\t\t\t} else if s == pendingState {\r\n\t\t\t\tlog.WithFields(pr.logFields()).Debugf(\"presubmit %s pending\", ps.Context)\r\n\t\t\t\toverallState = pendingState\r\n\t\t\t}\r\n\t\t}\r\n\t\tif overallState == successState {\r\n\t\t\tsuccesses = append(successes, pr)\r\n\t\t} else if overallState == pendingState {\r\n\t\t\tpendings = append(pendings, pr)\r\n\t\t} else {\r\n\t\t\tnones = append(nones, pr)\r\n\t\t}\r\n\t}\r\n\treturn\r\n}","code-length":615,"reference":"\/\/ accumulate returns the supplied PRs sorted into three buckets based on their\n\/\/ accumulated state across the presubmits.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc tryMerge(mergeFunc func() error) (bool, error) {\r\n\tvar err error\r\n\tconst maxRetries = 3\r\n\tbackoff := time.Second * 4\r\n\tfor retry := 0; retry < maxRetries; retry++ {\r\n\t\tif err = mergeFunc(); err == nil {\r\n\t\t\t\r\n\t\t\treturn true, nil\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tok {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\treturn true, fmt.Errorf(\"PR was modified: %v\", err)\r\n\t\t} else if _, ok = err.(github.UnmergablePRBaseChangedError); ok {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tmodified: %v\", err)\r\n\t\t\tif retry+1 < maxRetries {\r\n\t\t\t\tsleep(backoff)\r\n\t\t\t\tbackoff *= 2\r\n\t\t\t}\r\n\t\t} else if _, ok = err.(github.UnauthorizedToPushError); ok {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\treturn false, fmt.Errorf(\"branch needs to be configured to allow this robot to push: %v\", err)\r\n\t\t} else if _, ok = err.(github.MergeCommitsForbiddenError); ok {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\treturn false, fmt.Errorf(\"Tide needs to be configured to use the 'rebase' merge method for this repo or the repo needs to allow merge commits: %v\", err)\r\n\t\t} else if _, ok = err.(github.UnmergablePRError); ok {\r\n\t\t\treturn true, fmt.Errorf(\"PR is unmergable. Do the Tide merge requirements match the GitHub settings for the repo? %v\", err)\r\n\t\t} else {\r\n\t\t\treturn true, err\r\n\t\t}\r\n\t}\r\n\t\r\n\treturn true, err\r\n}","code-length":479,"reference":"\/\/ tryMerge attempts 1 merge and returns a bool indicating if we should try\n\/\/ to merge the remaining PRs and possibly an error.","result":"Try to merge the PRs.","score":[0.0111,0.1697]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *changedFilesAgent) prChanges(pr *PullRequest) config.ChangedFilesProvider {\r\n\treturn func() ([]string, error) {\r\n\t\tcacheKey := changeCacheKey{\r\n\t\t\torg:    string(pr.Repository.Owner.Login),\r\n\t\t\trepo:   string(pr.Repository.Name),\r\n\t\t\tnumber: int(pr.Number),\r\n\t\t\tsha:    string(pr.HeadRefOID),\r\n\t\t}\r\n\t\tc.RLock()\r\n\t\tchangedFiles, ok := c.changeCache[cacheKey]\r\n\t\tif ok {\r\n\t\t\tc.RUnlock()\r\n\t\t\tc.Lock()\r\n\t\t\tc.nextChangeCache[cacheKey] = changedFiles\r\n\t\t\tc.Unlock()\r\n\t\t\treturn changedFiles, nil\r\n\t\t}\r\n\t\tif changedFiles, ok = c.nextChangeCache[cacheKey]; ok {\r\n\t\t\tc.RUnlock()\r\n\t\t\treturn changedFiles, nil\r\n\t\t}\r\n\t\tc.RUnlock()\r\n\t\t\r\n\t\tchanges, err := c.ghc.GetPullRequestChanges(\r\n\t\t\tstring(pr.Repository.Owner.Login),\r\n\t\t\tstring(pr.Repository.Name),\r\n\t\t\tint(pr.Number),\r\n\t\t)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"error getting PR changes for #%d: %v\", int(pr.Number), err)\r\n\t\t}\r\n\t\tchangedFiles = make([]string, 0, len(changes))\r\n\t\tfor _, change := range changes {\r\n\t\t\tchangedFiles = append(changedFiles, change.Filename)\r\n\t\t}\r\n\t\tc.Lock()\r\n\t\tc.nextChangeCache[cacheKey] = changedFiles\r\n\t\tc.Unlock()\r\n\t\treturn changedFiles, nil\r\n\t}\r\n}","code-length":462,"reference":"\/\/ prChanges gets the files changed by the PR, either from the cache or by\n\/\/ querying GitHub.","result":"Get the PR changes.","score":[0.0096,0.0602]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *changedFilesAgent) prune() {\r\n\tc.Lock()\r\n\tdefer c.Unlock()\r\n\tc.changeCache = c.nextChangeCache\r\n\tc.nextChangeCache = make(map[changeCacheKey][]string)\r\n}","code-length":70,"reference":"\/\/ prune removes any cached file changes that were not used since the last prune.","result":"Prune the changed files cache.","score":[0.0325,0.1429]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) dividePool(pool map[string]PullRequest, pjs []prowapi.ProwJob) (map[string]*subpool, error) {\r\n\tsps := make(map[string]*subpool)\r\n\tfor _, pr := range pool {\r\n\t\torg := string(pr.Repository.Owner.Login)\r\n\t\trepo := string(pr.Repository.Name)\r\n\t\tbranch := string(pr.BaseRef.Name)\r\n\t\tbranchRef := string(pr.BaseRef.Prefix) + string(pr.BaseRef.Name)\r\n\t\tfn := poolKey(org, repo, branch)\r\n\t\tif sps[fn] == nil {\r\n\t\t\tsha, err := c.ghc.GetRef(org, repo, strings.TrimPrefix(branchRef, \"refs\/\"))\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\tsps[fn] = &subpool{\r\n\t\t\t\tlog: c.logger.WithFields(logrus.Fields{\r\n\t\t\t\t\t\"org\":      org,\r\n\t\t\t\t\t\"repo\":     repo,\r\n\t\t\t\t\t\"branch\":   branch,\r\n\t\t\t\t\t\"base-sha\": sha,\r\n\t\t\t\t}),\r\n\t\t\t\torg:    org,\r\n\t\t\t\trepo:   repo,\r\n\t\t\t\tbranch: branch,\r\n\t\t\t\tsha:    sha,\r\n\t\t\t}\r\n\t\t}\r\n\t\tsps[fn].prs = append(sps[fn].prs, pr)\r\n\t}\r\n\tfor _, pj := range pjs {\r\n\t\tif pj.Spec.Type != prowapi.PresubmitJob && pj.Spec.Type != prowapi.BatchJob {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tfn := poolKey(pj.Spec.Refs.Org, pj.Spec.Refs.Repo, pj.Spec.Refs.BaseRef)\r\n\t\tif sps[fn] == nil || pj.Spec.Refs.BaseSHA != sps[fn].sha {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tsps[fn].pjs = append(sps[fn].pjs, pj)\r\n\t}\r\n\treturn sps, nil\r\n}","code-length":553,"reference":"\/\/ dividePool splits up the list of pull requests and prow jobs into a group\n\/\/ per repo and branch. It only keeps ProwJobs that match the latest branch.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AggregateProfiles(profiles [][]*cover.Profile) ([]*cover.Profile, error) {\r\n\tsetProfiles := make([][]*cover.Profile, 0, len(profiles))\r\n\tfor _, p := range profiles {\r\n\t\tc := countToBoolean(p)\r\n\t\tsetProfiles = append(setProfiles, c)\r\n\t}\r\n\taggregateProfiles, err := MergeMultipleProfiles(setProfiles)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn aggregateProfiles, nil\r\n}","code-length":137,"reference":"\/\/ AggregateProfiles takes multiple coverage profiles and produces a new\n\/\/ coverage profile that counts the number of profiles that hit a block at least\n\/\/ once.","result":"Aggregate multiple profiles.","score":[0.0001,0.0203]}
{"code":"\/*is used to<extra_id_0>\r\nfunc countToBoolean(profile []*cover.Profile) []*cover.Profile {\r\n\tsetProfile := make([]*cover.Profile, 0, len(profile))\r\n\tfor _, p := range profile {\r\n\t\tpc := deepCopyProfile(*p)\r\n\t\tfor i := range pc.Blocks {\r\n\t\t\tif pc.Blocks[i].Count > 0 {\r\n\t\t\t\tpc.Blocks[i].Count = 1\r\n\t\t\t}\r\n\t\t}\r\n\t\tsetProfile = append(setProfile, &pc)\r\n\t}\r\n\treturn setProfile\r\n}","code-length":146,"reference":"\/\/ countToBoolean converts a profile containing hit counts to instead contain\n\/\/ only 1s or 0s.","result":"Convert the count to boolean.","score":[0.0266,0.1715]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewStorage(r storage.PersistenceLayer, storage string) (*Storage, error) {\r\n\ts := &Storage{\r\n\t\tresources: r,\r\n\t}\r\n\tif storage != \"\" {\r\n\t\tvar data struct {\r\n\t\t\tResources []common.Resource\r\n\t\t}\r\n\t\tbuf, err := ioutil.ReadFile(storage)\r\n\t\tif err == nil {\r\n\t\t\tlogrus.Infof(\"Current state: %s.\", string(buf))\r\n\t\t\terr = json.Unmarshal(buf, &data)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t} else if !os.IsNotExist(err) {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tlogrus.Info(\"Before adding resource loop\")\r\n\t\tfor _, res := range data.Resources {\r\n\t\t\tif err := s.AddResource(res); err != nil {\r\n\t\t\t\tlogrus.WithError(err).Errorf(\"Failed Adding Resources: %s - %s.\", res.Name, res.State)\r\n\t\t\t}\r\n\t\t\tlogrus.Infof(\"Successfully Added Resources: %s - %s.\", res.Name, res.State)\r\n\t\t}\r\n\t}\r\n\treturn s, nil\r\n}","code-length":321,"reference":"\/\/ NewStorage instantiates a new Storage with a PersistenceLayer implementation\n\/\/ If storage string is not empty, it will read resource data from the file","result":"Create a new storage object.","score":[0.0069,0.0652]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) AddResource(resource common.Resource) error {\r\n\treturn s.resources.Add(resource)\r\n}","code-length":40,"reference":"\/\/ AddResource adds a new resource","result":"Generate the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) DeleteResource(name string) error {\r\n\treturn s.resources.Delete(name)\r\n}","code-length":38,"reference":"\/\/ DeleteResource deletes a resource if it exists, errors otherwise","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) UpdateResource(resource common.Resource) error {\r\n\treturn s.resources.Update(resource)\r\n}","code-length":40,"reference":"\/\/ UpdateResource updates a resource if it exists, errors otherwise","result":"Store the file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) GetResource(name string) (common.Resource, error) {\r\n\ti, err := s.resources.Get(name)\r\n\tif err != nil {\r\n\t\treturn common.Resource{}, err\r\n\t}\r\n\tvar res common.Resource\r\n\tres, err = common.ItemToResource(i)\r\n\tif err != nil {\r\n\t\treturn common.Resource{}, err\r\n\t}\r\n\treturn res, nil\r\n}","code-length":122,"reference":"\/\/ GetResource gets an existing resource, errors otherwise","result":"Retrieve the resource from storage.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) GetResources() ([]common.Resource, error) {\r\n\tvar resources []common.Resource\r\n\titems, err := s.resources.List()\r\n\tif err != nil {\r\n\t\treturn resources, err\r\n\t}\r\n\tfor _, i := range items {\r\n\t\tvar res common.Resource\r\n\t\tres, err = common.ItemToResource(i)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tresources = append(resources, res)\r\n\t}\r\n\tsort.Stable(common.ResourceByUpdateTime(resources))\r\n\treturn resources, nil\r\n}","code-length":169,"reference":"\/\/ GetResources list all resources","result":"Get the list of resources in the storage.","score":[0.1652,0.1887]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) SyncResources(data []common.Resource) error {\r\n\ts.resourcesLock.Lock()\r\n\tdefer s.resourcesLock.Unlock()\r\n\tresources, err := s.GetResources()\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Error(\"cannot find resources\")\r\n\t\treturn err\r\n\t}\r\n\tvar finalError error\r\n\t\r\n\tvalid := 0\r\n\tfor _, res := range resources {\r\n\t\t\r\n\t\tif res.Owner != \"\" {\r\n\t\t\tresources[valid] = res\r\n\t\t\tvalid++\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\ttoDelete := true\r\n\t\tfor _, newRes := range data {\r\n\t\t\tif res.Name == newRes.Name {\r\n\t\t\t\tresources[valid] = res\r\n\t\t\t\tvalid++\r\n\t\t\t\ttoDelete = false\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif toDelete {\r\n\t\t\tlogrus.Infof(\"Deleting resource %s\", res.Name)\r\n\t\t\tif err := s.DeleteResource(res.Name); err != nil {\r\n\t\t\t\tfinalError = multierror.Append(finalError, err)\r\n\t\t\t\tlogrus.WithError(err).Errorf(\"unable to delete resource %s\", res.Name)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tresources = resources[:valid]\r\n\t\r\n\tfor _, p := range data {\r\n\t\tfound := false\r\n\t\tfor idx := range resources {\r\n\t\t\texist := resources[idx]\r\n\t\t\tif p.Name == exist.Name {\r\n\t\t\t\tfound = true\r\n\t\t\t\tlogrus.Infof(\"Keeping resource %s\", p.Name)\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif !found {\r\n\t\t\tif p.State == \"\" {\r\n\t\t\t\tp.State = common.Free\r\n\t\t\t}\r\n\t\t\tlogrus.Infof(\"Adding resource %s\", p.Name)\r\n\t\t\tresources = append(resources, p)\r\n\t\t\tif err := s.AddResource(p); err != nil {\r\n\t\t\t\tlogrus.WithError(err).Errorf(\"unable to add resource %s\", p.Name)\r\n\t\t\t\tfinalError = multierror.Append(finalError, err)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn finalError\r\n}","code-length":588,"reference":"\/\/ SyncResources will update resources every 10 mins.\n\/\/ It will append newly added resources to ranch.Resources,\n\/\/ And try to remove newly deleted resources from ranch.Resources.\n\/\/ If the newly deleted resource is currently held by a user, the deletion will\n\/\/ yield to next update cycle.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ParseConfig(configPath string) ([]common.Resource, error) {\r\n\tfile, err := ioutil.ReadFile(configPath)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar data common.BoskosConfig\r\n\terr = yaml.Unmarshal(file, &data)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar resources []common.Resource\r\n\tfor _, entry := range data.Resources {\r\n\t\tresources = append(resources, common.NewResourcesFromConfig(entry)...)\r\n\t}\r\n\treturn resources, nil\r\n}","code-length":162,"reference":"\/\/ ParseConfig reads in configPath and returns a list of resource objects\n\/\/ on success.","result":"Parse the config file.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc problemsInFiles(r *git.Repo, files map[string]string) (map[string][]string, error) {\r\n\tproblems := make(map[string][]string)\r\n\tfor f := range files {\r\n\t\tsrc, err := ioutil.ReadFile(filepath.Join(r.Dir, f))\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\t\r\n\t\trrorf(\"parsing as Bazel file %v\", err)\r\n\t\t}\r\n\t\tbeforeRewrite := build.Format(content)\r\n\t\tvar info build.RewriteInfo\r\n\t\tbuild.Rewrite(content, &info)\r\n\t\tndata := build.Format(content)\r\n\t\tif !bytes.Equal(src, ndata) && !bytes.Equal(src, beforeRewrite) {\r\n\t\t\t\r\n\t\t\tproblems[f] = uniqProblems(info.Log)\r\n\t\t}\r\n\t}\r\n\treturn problems, nil\r\n}","code-length":246,"reference":"\/\/ problemsInFiles runs buildifier on the files. It returns a map from the file to\n\/\/ a list of problems with that file.","result":"Detect problems in files.","score":[0.0033,0.0474]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewPodLogArtifact(jobName string, buildID string, sizeLimit int64, ja jobAgent) (*PodLogArtifact, error) {\r\n\tif jobName == \"\" {\r\n\t\treturn nil, errInsufficientJobInfo\r\n\t}\r\n\tif buildID == \"\" {\r\n\t\treturn nil, errInsufficientJobInfo\r\n\t}\r\n\tif sizeLimit < 0 {\r\n\t\treturn nil, errInvalidSizeLimit\r\n\t}\r\n\treturn &PodLogArtifact{\r\n\t\tname:      jobName,\r\n\t\tbuildID:   buildID,\r\n\t\tsizeLimit: sizeLimit,\r\n\t\tjobAgent:  ja,\r\n\t}, nil\r\n}","code-length":170,"reference":"\/\/ NewPodLogArtifact creates a new PodLogArtifact","result":"Create a new artifact.","score":[0.274,0.5077]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *PodLogArtifact) CanonicalLink() string {\r\n\tq := url.Values{\r\n\t\t\"job\": []string{a.name},\r\n\t\t\"id\":  []string{a.buildID},\r\n\t}\r\n\tu := url.URL{\r\n\t\tPath:     \"\/log\",\r\n\t\tRawQuery: q.Encode(),\r\n\t}\r\n\treturn u.String()\r\n}","code-length":110,"reference":"\/\/ CanonicalLink returns a link to where pod logs are streamed","result":"Generate the canonical link.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *PodLogArtifact) ReadAt(p []byte, off int64) (n int, err error) {\r\n\tlogs, err := a.jobAgent.GetJobLog(a.name, a.buildID)\r\n\tif err != nil {\r\n\t\treturn 0, fmt.Errorf(\"error getting pod log: %v\", err)\r\n\t}\r\n\tr := bytes.NewReader(logs)\r\n\treadBytes, err := r.ReadAt(p, off)\r\n\tif err == io.EOF {\r\n\t\treturn readBytes, io.EOF\r\n\t}\r\n\tif err != nil {\r\n\t\treturn 0, fmt.Errorf(\"error reading pod logs: %v\", err)\r\n\t}\r\n\treturn readBytes, nil\r\n}","code-length":190,"reference":"\/\/ ReadAt implements reading a range of bytes from the pod logs endpoint","result":"Read the pod log file.","score":[0.0686,0.3074]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *PodLogArtifact) ReadAll() ([]byte, error) {\r\n\tsize, err := a.Size()\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error getting pod log size: %v\", err)\r\n\t}\r\n\tif size > a.sizeLimit {\r\n\t\treturn nil, lenses.ErrFileTooLarge\r\n\t}\r\n\tlogs, err := a.jobAgent.GetJobLog(a.name, a.buildID)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error getting pod log: %v\", err)\r\n\t}\r\n\treturn logs, nil\r\n}","code-length":168,"reference":"\/\/ ReadAll reads all available pod logs, failing if they are too large","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *PodLogArtifact) ReadAtMost(n int64) ([]byte, error) {\r\n\tlogs, err := a.jobAgent.GetJobLog(a.name, a.buildID)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error getting pod log: %v\", err)\r\n\t}\r\n\treader := bytes.NewReader(logs)\r\n\tvar byteCount int64\r\n\tvar p []byte\r\n\tfor byteCount < n {\r\n\t\tb, err := reader.ReadByte()\r\n\t\tif err == io.EOF {\r\n\t\t\treturn p, io.EOF\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"error reading pod log: %v\", err)\r\n\t\t}\r\n\t\tp = append(p, b)\r\n\t\tbyteCount++\r\n\t}\r\n\treturn p, nil\r\n}","code-length":231,"reference":"\/\/ ReadAtMost reads at most n bytes","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (a *PodLogArtifact) ReadTail(n int64) ([]byte, error) {\r\n\tlogs, err := a.jobAgent.GetJobLog(a.name, a.buildID)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error getting pod log tail: %v\", err)\r\n\t}\r\n\tsize := int64(len(logs))\r\n\tvar off int64\r\n\tif n > size {\r\n\t\toff = 0\r\n\t} else {\r\n\t\toff = size - n\r\n\t}\r\n\tp := make([]byte, n)\r\n\treadBytes, err := bytes.NewReader(logs).ReadAt(p, off)\r\n\tif err != nil && err != io.EOF {\r\n\t\treturn nil, fmt.Errorf(\"error reading pod log tail: %v\", err)\r\n\t}\r\n\treturn p[:readBytes], nil\r\n}","code-length":230,"reference":"\/\/ ReadTail reads the last n bytes of the pod log","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newProblems(cs []github.ReviewComment, ps map[string]map[int]lint.Problem) map[string]map[int]lint.Problem {\r\n\t\r\n\tres := make(map[string]map[int]lint.Problem)\r\n\tfor f, ls := range ps {\r\n\t\tres[f] = make(map[int]lint.Problem)\r\n\t\tfor l, p := range ls {\r\n\t\t\tres[f][l] = p\r\n\t\t}\r\n\t}\r\n\tfor _, c := range cs {\r\n\t\tif c.Position == nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif !strings.Contains(c.Body, commentTag) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tdelete(res[c.Path], *c.Position)\r\n\t}\r\n\treturn res\r\n}","code-length":220,"reference":"\/\/ newProblems compares the list of problems with the list of past comments on\n\/\/ the PR to decide which are new.","result":"Map[string]map[int]lint.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc problemsInFiles(r *git.Repo, files map[string]string) (map[string]map[int]lint.Problem, []github.DraftReviewComment) {\r\n\tproblems := make(map[string]map[int]lint.Problem)\r\n\tvar lintErrorComments []github.DraftReviewComment\r\n\tl := new(lint.Linter)\r\n\tfor f, patch := range files {\r\n\t\tproblems[f] = make(map[int]lint.Problem)\r\n\t\tsrc, err := ioutil.ReadFile(filepath.Join(r.Dir, f))\r\n\t\tif err != nil {\r\n\t\t\tlintErrorComments = append(lintErrorComments, github.DraftReviewComment{\r\n\t\t\t\tPath: f,\r\n\t\t\t\tBody: fmt.Sprintf(\"%v\", err),\r\n\t\t\t})\r\n\t\t}\r\n\t\tps, err := l.Lint(f, src)\r\n\t\tif err != nil {\r\n\t\t\t\r\n\t\t\terrLineIndexStart := strings.LastIndex(err.Error(), f) + len(f)\r\n\t\t\treNumber := regexp.MustCompile(`:([0-9]+):`)\r\n\t\t\tmatches := reNumber.FindStringSubmatch(err.Error()[errLineIndexStart:])\r\n\t\t\tnewComment := github.DraftReviewComment{\r\n\t\t\t\tPath: f,\r\n\t\t\t\tBody: err.Error(),\r\n\t\t\t}\r\n\t\t\tif len(matches) > 1 {\r\n\t\t\t\terrLineString := matches[1]\r\n\t\t\t\terrLine, errAtoi := strconv.Atoi(errLineString)\r\n\t\t\t\tif errAtoi == nil {\r\n\t\t\t\t\tnewComment.Position = errLine\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\treTrimError := regexp.MustCompile(`(:[0-9]+:[0-9]+: )`)\r\n\t\t\t\tmatches = reTrimError.FindStringSubmatch(err.Error())\r\n\t\t\t\tif len(matches) > 0 {\r\n\t\t\t\t\tnewComment.Body = err.Error()[len(matches[0])+errLineIndexStart:]\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tlintErrorComments = append(lintErrorComments, newComment)\r\n\t\t}\r\n\t\tal, err := AddedLines(patch)\r\n\t\tif err != nil {\r\n\t\t\tlintErrorComments = append(lintErrorComments,\r\n\t\t\t\tgithub.DraftReviewComment{\r\n\t\t\t\t\tPath: f,\r\n\t\t\t\t\tBody: fmt.Sprintf(\"computing added lines in %s: %v\", f, err),\r\n\t\t\t\t})\r\n\t\t}\r\n\t\tfor _, p := range ps {\r\n\t\t\tif pl, ok := al[p.Position.Line]; ok {\r\n\t\t\t\tproblems[f][pl] = p\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn problems, lintErrorComments\r\n}","code-length":689,"reference":"\/\/ problemsInFiles runs golint on the files. It returns a map from the file to\n\/\/ a map from the line in the patch to the problem.","result":"Code too long,keep in 512.","score":[0.003,0.0202]}
{"code":"\/*is used to<extra_id_0>\r\nfunc undoPreset(preset *config.Preset, labels map[string]string, pod *coreapi.PodSpec) {\r\n\t\r\n\tfor l, v := range preset.Labels {\r\n\t\tif v2, ok := labels[l]; !ok || v2 != v {\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n\t\r\n\tremoveEnvNames := sets.NewString()\r\n\tfor _, e1 := range preset.Env {\r\n\t\tremoveEnvNames.Insert(e1.Name)\r\n\t}\r\n\tremoveVolumeNames := sets.NewString()\r\n\tfor _, volume := range preset.Volumes {\r\n\t\tremoveVolumeNames.Insert(volume.Name)\r\n\t}\r\n\tremoveVolumeMountNames := sets.NewString()\r\n\tfor _, volumeMount := range preset.VolumeMounts {\r\n\t\tremoveVolumeMountNames.Insert(volumeMount.Name)\r\n\t}\r\n\t\r\n\tfilteredVolumes := []coreapi.Volume{}\r\n\tfor _, volume := range pod.Volumes {\r\n\t\tif !removeVolumeNames.Has(volume.Name) {\r\n\t\t\tfilteredVolumes = append(filteredVolumes, volume)\r\n\t\t}\r\n\t}\r\n\tpod.Volumes = filteredVolumes\r\n\t\r\n\tfor i := range pod.Containers {\r\n\t\tfilteredEnv := []coreapi.EnvVar{}\r\n\t\tfor _, env := range pod.Containers[i].Env {\r\n\t\t\tif !removeEnvNames.Has(env.Name) {\r\n\t\t\t\tfilteredEnv = append(filteredEnv, env)\r\n\t\t\t}\r\n\t\t}\r\n\t\tpod.Containers[i].Env = filteredEnv\r\n\t\tfilteredVolumeMounts := []coreapi.VolumeMount{}\r\n\t\tfor _, mount := range pod.Containers[i].VolumeMounts {\r\n\t\t\tif !removeVolumeMountNames.Has(mount.Name) {\r\n\t\t\t\tfilteredVolumeMounts = append(filteredVolumeMounts, mount)\r\n\t\t\t}\r\n\t\t}\r\n\t\tpod.Containers[i].VolumeMounts = filteredVolumeMounts\r\n\t}\r\n}","code-length":505,"reference":"\/\/ remove merged presets from a podspec","result":"UndoPreset is used to undo the preset.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc undoPresubmitPresets(presets []config.Preset, presubmit *config.Presubmit) {\r\n\tif presubmit.Spec == nil {\r\n\t\treturn\r\n\t}\r\n\tfor _, preset := range presets {\r\n\t\tundoPreset(&preset, presubmit.Labels, presubmit.Spec)\r\n\t}\r\n}","code-length":95,"reference":"\/\/ undo merged presets from loaded presubmit and its children","result":"Undo presubmit presets.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc yamlBytesStripNulls(yamlBytes []byte) []byte {\r\n\tnullRE := regexp.MustCompile(\"(?m)[\\n]+^[^\\n]+: null$\")\r\n\treturn nullRE.ReplaceAll(yamlBytes, []byte{})\r\n}","code-length":68,"reference":"\/\/ these are unnecessary, and make the config larger so we strip them out","result":"Strip nulls from yamlBytes.","score":[0,0.0385]}
{"code":"\/*is used to<extra_id_0>\r\nfunc monitorDiskAndEvict(\r\n\tc *diskcache.Cache,\r\n\tinterval time.Duration,\r\n\tminPercentBlocksFree, evictUntilPercentBlocksFree float64,\r\n) {\r\n\tdiskRoot := c.DiskRoot()\r\n\t\r\n\tticker := time.NewTicker(interval)\r\n\tfor ; true; <-ticker.C {\r\n\t\tblocksFree, _, _, err := diskutil.GetDiskUsage(diskRoot)\r\n\t\tif err != nil {\r\n\t\t\tlogrus.WithError(err).Error(\"Failed to get disk usage!\")\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tlogger := logrus.WithFields(logrus.Fields{\r\n\t\t\t\"sync-loop\":   \"MonitorDiskAndEvict\",\r\n\t\t\t\"blocks-free\": blocksFree,\r\n\t\t})\r\n\t\tlogger.Info(\"tick\")\r\n\t\t\r\n\t\tif blocksFree < minPercentBlocksFree {\r\n\t\t\tlogger.Warn(\"Eviction triggered\")\r\n\t\t\t\r\n\t\t\t\r\n\t\t\tfiles := c.GetEntries()\r\n\t\t\tsort.Slice(files, func(i, j int) bool {\r\n\t\t\t\treturn files[i].LastAccess.Before(files[j].LastAccess)\r\n\t\t\t})\r\n\t\t\t\r\n\t\t\tfor blocksFree < evictUntilPercentBlocksFree {\r\n\t\t\t\tif len(files) < 1 {\r\n\t\t\t\t\tlogger.Fatal(\"Failed to find entries to evict!\")\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\tvar entry diskcache.EntryInfo\r\n\t\t\t\tentry, files = files[0], files[1:]\r\n\t\t\t\terr = c.Delete(c.PathToKey(entry.Path))\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tlogger.WithError(err).Errorf(\"Error deleting entry at path: %v\", entry.Path)\r\n\t\t\t\t} else {\r\n\t\t\t\t\tpromMetrics.FilesEvicted.Inc()\r\n\t\t\t\t\tpromMetrics.LastEvictedAccessAge.Set(time.Now().Sub(entry.LastAccess).Hours())\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\tblocksFree, _, _, err = diskutil.GetDiskUsage(diskRoot)\r\n\t\t\t\tlogger = logrus.WithFields(logrus.Fields{\r\n\t\t\t\t\t\"sync-loop\":   \"MonitorDiskAndEvict\",\r\n\t\t\t\t\t\"blocks-free\": blocksFree,\r\n\t\t\t\t})\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tlogrus.WithError(err).Error(\"Failed to get disk usage!\")\r\n\t\t\t\t\tcontinue\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tlogger.Info(\"Done evicting\")\r\n\t\t}\r\n\t}\r\n}","code-length":634,"reference":"\/\/ monitorDiskAndEvict loops monitoring the disk, evicting cache entries\n\/\/ when the disk passes either minPercentBlocksFree until the disk is above\n\/\/ evictUntilPercentBlocksFree","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *orgRepoConfig) difference(c2 *orgRepoConfig) *orgRepoConfig {\r\n\tres := &orgRepoConfig{\r\n\t\torgExceptions: make(map[string]sets.String),\r\n\t\trepos:         sets.NewString().Union(c.repos),\r\n\t}\r\n\tfor org, excepts1 := range c.orgExceptions {\r\n\t\tif excepts2, ok := c2.orgExceptions[org]; ok {\r\n\t\t\tres.repos.Insert(excepts2.Difference(excepts1).UnsortedList()...)\r\n\t\t} else {\r\n\t\t\texcepts := sets.NewString().Union(excepts1)\r\n\t\t\t\r\n\t\t\tfor _, repo := range c2.repos.UnsortedList() {\r\n\t\t\t\tif parts := strings.SplitN(repo, \"\/\", 2); len(parts) == 2 && parts[0] == org {\r\n\t\t\t\t\texcepts.Insert(repo)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tres.orgExceptions[org] = excepts\r\n\t\t}\r\n\t}\r\n\tres.repos = res.repos.Difference(c2.repos)\r\n\tfor _, repo := range res.repos.UnsortedList() {\r\n\t\tif parts := strings.SplitN(repo, \"\/\", 2); len(parts) == 2 {\r\n\t\t\tif excepts2, ok := c2.orgExceptions[parts[0]]; ok && !excepts2.Has(repo) {\r\n\t\t\t\tres.repos.Delete(repo)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn res\r\n}","code-length":395,"reference":"\/\/ difference returns a new orgRepoConfig that represents the set difference of\n\/\/ the repos specified by the receiver and the parameter orgRepoConfigs.","result":"Create a new config file to be merged into one.","score":[0.0418,0.0864]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *orgRepoConfig) union(c2 *orgRepoConfig) *orgRepoConfig {\r\n\tres := &orgRepoConfig{\r\n\t\torgExceptions: make(map[string]sets.String),\r\n\t\trepos:         sets.NewString(),\r\n\t}\r\n\tfor org, excepts1 := range c.orgExceptions {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tpruned := excepts1.Difference(c2.repos)\r\n\t\tif excepts2, ok := c2.orgExceptions[org]; ok {\r\n\t\t\tres.orgExceptions[org] = pruned.Intersection(excepts2.Difference(c.repos))\r\n\t\t} else {\r\n\t\t\tres.orgExceptions[org] = pruned\r\n\t\t}\r\n\t}\r\n\tfor org, excepts2 := range c2.orgExceptions {\r\n\t\t\r\n\t\tif _, exists := res.orgExceptions[org]; !exists {\r\n\t\t\tres.orgExceptions[org] = excepts2.Difference(c.repos)\r\n\t\t}\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tfor _, repo := range c.repos.Union(c2.repos).UnsortedList() {\r\n\t\tparts := strings.SplitN(repo, \"\/\", 2)\r\n\t\tif len(parts) != 2 {\r\n\t\t\tlogrus.Warnf(\"org\/repo %q is formatted incorrectly\", repo)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif _, exists := res.orgExceptions[parts[0]]; !exists {\r\n\t\t\tres.repos.Insert(repo)\r\n\t\t}\r\n\t}\r\n\treturn res\r\n}","code-length":411,"reference":"\/\/ union returns a new orgRepoConfig that represents the set union of the\n\/\/ repos specified by the receiver and the parameter orgRepoConfigs","result":"Merge two configs.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc clearStaleComments(gc githubClient, log *logrus.Entry, pr *github.PullRequestEvent, prLabels sets.String, comments []github.IssueComment) error {\r\n\t\r\n\tif prMustFollowRelNoteProcess(gc, log, pr, prLabels, false) && !releaseNoteAlreadyAdded(prLabels) {\r\n\t\treturn nil\r\n\t}\r\n\tbotName, err := gc.BotName()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn gc.DeleteStaleComments(\r\n\t\tpr.Repo.Owner.Login,\r\n\t\tpr.Repo.Name,\r\n\t\tpr.Number,\r\n\t\tcomments,\r\n\t\tfunc(c github.IssueComment) bool {\r\n\t\t\treturn c.User.Login == botName &&\r\n\t\t\t\t(strings.Contains(c.Body, releaseNoteBody) ||\r\n\t\t\t\t\tstrings.Contains(c.Body, parentReleaseNoteBody))\r\n\t\t},\r\n\t)\r\n}","code-length":245,"reference":"\/\/ clearStaleComments deletes old comments that are no longer applicable.","result":"Clear stale comments.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc determineReleaseNoteLabel(body string) string {\r\n\tcomposedReleaseNote := strings.ToLower(strings.TrimSpace(getReleaseNote(body)))\r\n\tif composedReleaseNote == \"\" {\r\n\t\treturn ReleaseNoteLabelNeeded\r\n\t}\r\n\tif noneRe.MatchString(composedReleaseNote) {\r\n\t\treturn releaseNoteNone\r\n\t}\r\n\tif strings.Contains(composedReleaseNote, actionRequiredNote) {\r\n\t\treturn releaseNoteActionRequired\r\n\t}\r\n\treturn releaseNote\r\n}","code-length":135,"reference":"\/\/ determineReleaseNoteLabel returns the label to be added based on the contents of the 'release-note'\n\/\/ section of a PR's body text.","result":"Determine the release note label.","score":[0.008,0.0246]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getReleaseNote(body string) string {\r\n\tpotentialMatch := noteMatcherRE.FindStringSubmatch(body)\r\n\tif potentialMatch == nil {\r\n\t\treturn \"\"\r\n\t}\r\n\treturn strings.TrimSpace(potentialMatch[1])\r\n}","code-length":71,"reference":"\/\/ getReleaseNote returns the release note from a PR body\n\/\/ assumes that the PR body followed the PR template","result":"Generate the release notes.","score":[0.0083,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(boskosClient boskosClient) *Client {\r\n\treturn &Client{\r\n\t\tbasic:     boskosClient,\r\n\t\tresources: map[string]common.Resource{},\r\n\t}\r\n}","code-length":66,"reference":"\/\/ NewClient creates a new client from a boskosClient interface","result":"Create a client.","score":[0.0396,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Acquire(rtype, state, dest string) (*common.Resource, error) {\r\n\tvar resourcesToRelease []common.Resource\r\n\treleaseOnFailure := func() {\r\n\t\tfor _, r := range resourcesToRelease {\r\n\t\t\tif err := c.basic.ReleaseOne(r.Name, common.Dirty); err != nil {\r\n\t\t\t\tlogrus.WithError(err).Warningf(\"failed to release resource %s\", r.Name)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tres, err := c.basic.Acquire(rtype, state, dest)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tvar leasedResources common.LeasedResources\r\n\tif err = res.UserData.Extract(LeasedResources, &leasedResources); err != nil {\r\n\t\tif _, ok := err.(*common.UserDataNotFound); !ok {\r\n\t\t\tlogrus.WithError(err).Errorf(\"cannot parse %s from User Data\", LeasedResources)\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\tresourcesToRelease = append(resourcesToRelease, *res)\r\n\tresources, err := c.basic.AcquireByState(res.Name, dest, leasedResources)\r\n\tif err != nil {\r\n\t\treleaseOnFailure()\r\n\t\treturn nil, err\r\n\t}\r\n\tresourcesToRelease = append(resourcesToRelease, resources...)\r\n\tc.updateResource(*res)\r\n\treturn res, nil\r\n}","code-length":377,"reference":"\/\/ Acquire gets a resource with associated leased resources","result":"Create a new resource.","score":[0.0915,0.0588]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) ReleaseOne(name, dest string) (allErrors error) {\r\n\tres, err := c.getResource(name)\r\n\tif err != nil {\r\n\t\tallErrors = err\r\n\t\treturn\r\n\t}\r\n\tresourceNames := []string{name}\r\n\tvar leasedResources common.LeasedResources\r\n\tif err := res.UserData.Extract(LeasedResources, &leasedResources); err != nil {\r\n\t\tif _, ok := err.(*common.UserDataNotFound); !ok {\r\n\t\t\tlogrus.WithError(err).Errorf(\"cannot parse %s from User Data\", LeasedResources)\r\n\t\t\tallErrors = multierror.Append(allErrors, err)\r\n\t\t\tif err := c.basic.ReleaseOne(name, dest); err != nil {\r\n\t\t\t\tlogrus.WithError(err).Warningf(\"failed to release resource %s\", name)\r\n\t\t\t\tallErrors = multierror.Append(allErrors, err)\r\n\t\t\t}\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n\tresourceNames = append(resourceNames, leasedResources...)\r\n\tfor _, n := range resourceNames {\r\n\t\tif err := c.basic.ReleaseOne(n, dest); err != nil {\r\n\t\t\tlogrus.WithError(err).Warningf(\"failed to release resource %s\", n)\r\n\t\t\tallErrors = multierror.Append(allErrors, err)\r\n\t\t}\r\n\t}\r\n\tc.deleteResource(name)\r\n\treturn\r\n}","code-length":371,"reference":"\/\/ ReleaseOne will release a resource as well as leased resources associated to it","result":"Release a resource.","score":[0.0104,0.1453]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) UpdateAll(state string) error {\r\n\treturn c.basic.UpdateAll(state)\r\n}","code-length":39,"reference":"\/\/ UpdateAll updates all the acquired resources with a given state","result":"Generate the code.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetGitHubClient(token string) *github.Client {\r\n\treturn github.NewClient(\r\n\t\toauth2.NewClient(\r\n\t\t\toauth2.NoContext,\r\n\t\t\toauth2.StaticTokenSource(&oauth2.Token{AccessToken: token}),\r\n\t\t),\r\n\t)\r\n}","code-length":83,"reference":"\/\/ GetGitHubClient creates a client for each token","result":"Get the github client.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetUsername(client *github.Client) (string, error) {\r\n\tuser, _, err := client.Users.Get(context.Background(), \"\")\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tif user.Login == nil {\r\n\t\treturn \"\", errors.New(\"Users.Get(\\\"\\\") returned empty login\")\r\n\t}\r\n\treturn *user.Login, nil\r\n}","code-length":112,"reference":"\/\/ GetUsername finds the login for each token","result":"Get the username of the user.","score":[0.1383,0.1282]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CreateTokenHandler(tokenStream io.Reader, influxdb *InfluxDB) (*TokenHandler, error) {\r\n\ttoken, err := ioutil.ReadAll(tokenStream)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tclient := GetGitHubClient(strings.TrimSpace(string(token)))\r\n\tlogin, err := GetUsername(client)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &TokenHandler{\r\n\t\tgClient:  client,\r\n\t\tlogin:    login,\r\n\t\tinfluxdb: influxdb,\r\n\t}, nil\r\n}","code-length":163,"reference":"\/\/ CreateTokenHandler parses the token and create a handler","result":"Create a token handler.","score":[0.1088,0.3007]}
{"code":"\/*is used to<extra_id_0>\r\nfunc CreateTokenHandlers(tokenFiles []string, influxdb *InfluxDB) ([]TokenHandler, error) {\r\n\ttokens := []TokenHandler{}\r\n\tfor _, tokenFile := range tokenFiles {\r\n\t\tf, err := os.Open(tokenFile)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"Can't open token-file (%s): %s\", tokenFile, err)\r\n\t\t}\r\n\t\ttoken, err := CreateTokenHandler(f, influxdb)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"Failed to create token (%s): %s\", tokenFile, err)\r\n\t\t}\r\n\t\ttokens = append(tokens, *token)\r\n\t}\r\n\treturn tokens, nil\r\n}","code-length":195,"reference":"\/\/ CreateTokenHandlers goes through the list of token files, and create handlers","result":"Create the token handlers.","score":[0.0514,0.1339]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *jobIndentifier) String() string {\r\n\treturn fmt.Sprintf(\"%s %s\/%s#%d\", i.job, i.organization, i.repository, i.pullRequest)\r\n}","code-length":59,"reference":"\/\/ String returns the string representation of a prow job identifier","result":"Generate the job name.","score":[0.066,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc TerminateOlderPresubmitJobs(pjc prowClient, log *logrus.Entry, pjs []prowapi.ProwJob,\r\n\tcleanup ProwJobResourcesCleanup) error {\r\n\tdupes := map[jobIndentifier]int{}\r\n\tfor i, pj := range pjs {\r\n\t\tif pj.Complete() || pj.Spec.Type != prowapi.PresubmitJob {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tji := jobIndentifier{\r\n\t\t\tjob:          pj.Spec.Job,\r\n\t\t\torganization: pj.Spec.Refs.Org,\r\n\t\t\trepository:   pj.Spec.Refs.Repo,\r\n\t\t\tpullRequest:  pj.Spec.Refs.Pulls[0].Number,\r\n\t\t}\r\n\t\tprev, ok := dupes[ji]\r\n\t\tif !ok {\r\n\t\t\tdupes[ji] = i\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tcancelIndex := i\r\n\t\tif (&pjs[prev].Status.StartTime).Before(&pj.Status.StartTime) {\r\n\t\t\tcancelIndex = prev\r\n\t\t\tdupes[ji] = i\r\n\t\t}\r\n\t\ttoCancel := pjs[cancelIndex]\r\n\t\t\r\n\t\t\r\n\t\tWithFields(ProwJobFields(&toCancel)).Warn(\"Cannot clean up job resources\")\r\n\t\t}\r\n\t\ttoCancel.SetComplete()\r\n\t\tprevState := toCancel.Status.State\r\n\t\ttoCancel.Status.State = prowapi.AbortedState\r\n\t\tlog.WithFields(ProwJobFields(&toCancel)).\r\n\t\t\tWithField(\"from\", prevState).\r\n\t\t\tWithField(\"to\", toCancel.Status.State).Info(\"Transitioning states\")\r\n\t\tnpj, err := pjc.ReplaceProwJob(toCancel.ObjectMeta.Name, toCancel)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tpjs[cancelIndex] = npj\r\n\t}\r\n\treturn nil\r\n}","code-length":519,"reference":"\/\/ TerminateOlderPresubmitJobs aborts all presubmit jobs from the given list that have a newer version. It calls\n\/\/ the cleanup callback for each job before updating its status as aborted.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PushMetrics(component, endpoint string, interval time.Duration) {\r\n\tsig := make(chan os.Signal, 1)\r\n\tsignal.Notify(sig, os.Interrupt, syscall.SIGTERM)\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase <-time.Tick(interval):\r\n\t\t\tif err := push.FromGatherer(component, push.HostnameGroupingKey(), endpoint, prometheus.DefaultGatherer); err != nil {\r\n\t\t\t\tlogrus.WithField(\"component\", component).WithError(err).Error(\"Failed to push metrics.\")\r\n\t\t\t}\r\n\t\tcase <-sig:\r\n\t\t\tlogrus.WithField(\"component\", component).Infof(\"Metrics pusher shutting down...\")\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":192,"reference":"\/\/ PushMetrics is meant to run in a goroutine and continuously push\n\/\/ metrics to the provided endpoint.","result":"Push metrics to the metrics server.","score":[0.0538,0.1879]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RateLimiter(controllerName string) workqueue.RateLimitingInterface {\r\n\trl := workqueue.NewMaxOfRateLimiter(\r\n\t\tworkqueue.NewItemExponentialFailureRateLimiter(5*time.Millisecond, 120*time.Second),\r\n\t\t&workqueue.BucketRateLimiter{Limiter: rate.NewLimiter(rate.Limit(1000), 50000)},\r\n\t)\r\n\treturn workqueue.NewNamedRateLimitingQueue(rl, controllerName)\r\n}","code-length":120,"reference":"\/\/ RateLimiter creates a ratelimiting queue for a given prow controller.","result":"Generate the controller name.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkExistingStatus(gc gitHubClient, l *logrus.Entry, org, repo, sha string) (string, error) {\r\n\tstatuses, err := gc.ListStatuses(org, repo, sha)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"error listing pull request statuses: %v\", err)\r\n\t}\r\n\texistingStatus := \"\"\r\n\tfor _, status := range statuses {\r\n\t\tif status.Context != dcoContextName {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\texistingStatus = status.State\r\n\t\tbreak\r\n\t}\r\n\tl.Debugf(\"Existing DCO status context status is %q\", existingStatus)\r\n\treturn existingStatus, nil\r\n}","code-length":182,"reference":"\/\/ checkExistingStatus will retrieve the current status of the DCO context for\n\/\/ the provided SHA.","result":"Check if the existing status context status is already set.","score":[0.0784,0.0974]}
{"code":"\/*is used to<extra_id_0>\r\nfunc checkExistingLabels(gc gitHubClient, l *logrus.Entry, org, repo string, number int) (hasYesLabel, hasNoLabel bool, err error) {\r\n\tlabels, err := gc.GetIssueLabels(org, repo, number)\r\n\tif err != nil {\r\n\t\treturn false, false, fmt.Errorf(\"error getting pull request labels: %v\", err)\r\n\t}\r\n\tfor _, l := range labels {\r\n\t\tif l.Name == dcoYesLabel {\r\n\t\t\thasYesLabel = true\r\n\t\t}\r\n\t\tif l.Name == dcoNoLabel {\r\n\t\t\thasNoLabel = true\r\n\t\t}\r\n\t}\r\n\treturn hasYesLabel, hasNoLabel, nil\r\n}","code-length":190,"reference":"\/\/ checkExistingLabels will check the provided PR for the dco sign off labels,\n\/\/ returning bool's indicating whether the 'yes' and the 'no' label are present.","result":"Check existing labels.","score":[0,0.0211]}
{"code":"\/*is used to<extra_id_0>\r\nfunc handle(gc gitHubClient, cp commentPruner, log *logrus.Entry, org, repo string, pr github.PullRequest, addComment bool) error {\r\n\tl := log.WithField(\"pr\", pr.Number)\r\n\tcommitsMissingDCO, err := checkCommitMessages(gc, l, org, repo, pr.Number)\r\n\tif err != nil {\r\n\t\tl.WithError(err).Infof(\"Error running DCO check against commits in PR\")\r\n\t\treturn err\r\n\t}\r\n\texistingStatus, err := checkExistingStatus(gc, l, org, repo, pr.Head.SHA)\r\n\tif err != nil {\r\n\t\tl.WithError(err).Infof(\"Error checking existing PR status\")\r\n\t\treturn err\r\n\t}\r\n\thasYesLabel, hasNoLabel, err := checkExistingLabels(gc, l, org, repo, pr.Number)\r\n\tif err != nil {\r\n\t\tl.WithError(err).Infof(\"Error checking existing PR labels\")\r\n\t\treturn err\r\n\t}\r\n\treturn takeAction(gc, cp, l, org, repo, pr, commitsMissingDCO, existingStatus, hasYesLabel, hasNoLabel, addComment)\r\n}","code-length":298,"reference":"\/\/ 1. Check commit messages in the pull request for the sign-off string\n\/\/ 2. Check the existing status context value\n\/\/ 3. Check the existing PR labels\n\/\/ 4. If signed off, apply appropriate labels and status context.\n\/\/ 5. If not signed off, apply appropriate labels and status context and add a comment.","result":"Handle PRs with DCO.","score":[0,0.01]}
{"code":"\/*is used to<extra_id_0>\r\nfunc MarkdownSHAList(org, repo string, list []github.GitCommit) string {\r\n\tlines := make([]string, len(list))\r\n\tlineFmt := \"- [%s](https:\r\n\tfor i, commit := range list {\r\n\t\tif commit.SHA == \"\" {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\tshortSHA := commit.SHA\r\n\t\tif len(shortSHA) > 7 {\r\n\t\t\tshortSHA = shortSHA[:7]\r\n\t\t}\r\n\t\t\r\n\t\tmessage := strings.Split(commit.Message, \"\\n\")[0]\r\n\t\tlines[i] = fmt.Sprintf(lineFmt, shortSHA, org, repo, commit.SHA, message)\r\n\t}\r\n\treturn strings.Join(lines, \"\\n\")\r\n}","code-length":205,"reference":"\/\/ MardkownSHAList prints the list of commits in a markdown-friendly way.","result":"Generate the markdown.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc PathForSpec(spec *downwardapi.JobSpec, pathSegment RepoPathBuilder) string {\r\n\tswitch spec.Type {\r\n\tcase prowapi.PeriodicJob, prowapi.PostsubmitJob:\r\n\t\treturn path.Join(NonPRLogs, spec.Job, spec.BuildID)\r\n\tcase prowapi.PresubmitJob:\r\n\t\treturn path.Join(PRLogs, \"pull\", pathSegment(spec.Refs.Org, spec.Refs.Repo), strconv.Itoa(spec.Refs.Pulls[0].Number), spec.Job, spec.BuildID)\r\n\tcase prowapi.BatchJob:\r\n\t\treturn path.Join(PRLogs, \"pull\", \"batch\", spec.Job, spec.BuildID)\r\n\tdefault:\r\n\t\tlogrus.Fatalf(\"unknown job spec type: %v\", spec.Type)\r\n\t}\r\n\treturn \"\"\r\n}","code-length":225,"reference":"\/\/ PathForSpec determines the GCS path prefix for files uploaded\n\/\/ for a specific job spec","result":"Generate the path for the job spec.","score":[0.0631,0.1325]}
{"code":"\/*is used to<extra_id_0>\r\nfunc AliasForSpec(spec *downwardapi.JobSpec) string {\r\n\tswitch spec.Type {\r\n\tcase prowapi.PeriodicJob, prowapi.PostsubmitJob, prowapi.BatchJob:\r\n\t\treturn \"\"\r\n\tcase prowapi.PresubmitJob:\r\n\t\treturn path.Join(PRLogs, \"directory\", spec.Job, fmt.Sprintf(\"%s.txt\", spec.BuildID))\r\n\tdefault:\r\n\t\tlogrus.Fatalf(\"unknown job spec type: %v\", spec.Type)\r\n\t}\r\n\treturn \"\"\r\n}","code-length":150,"reference":"\/\/ AliasForSpec determines the GCS path aliases for a job spec","result":"Generate the alias for the job spec.","score":[0.12,0.1415]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RootForSpec(spec *downwardapi.JobSpec) string {\r\n\tswitch spec.Type {\r\n\tcase prowapi.PeriodicJob, prowapi.PostsubmitJob:\r\n\t\treturn path.Join(NonPRLogs, spec.Job)\r\n\tcase prowapi.PresubmitJob, prowapi.BatchJob:\r\n\t\treturn path.Join(PRLogs, \"directory\", spec.Job)\r\n\tdefault:\r\n\t\tlogrus.Errorf(\"unknown job spec type: %v\", spec.Type)\r\n\t}\r\n\treturn \"\"\r\n}","code-length":146,"reference":"\/\/ RootForSpec determines the root GCS path for storing artifacts about\n\/\/ the provided job.","result":"Generate the root for the job.","score":[0.0766,0.2638]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewSingleDefaultRepoPathBuilder(defaultOrg, defaultRepo string) RepoPathBuilder {\r\n\treturn func(org, repo string) string {\r\n\t\tif org == defaultOrg && repo == defaultRepo {\r\n\t\t\treturn \"\"\r\n\t\t}\r\n\t\t\r\n\t\trepo = strings.Replace(repo, \"\/\", \"_\", -1)\r\n\t\treturn fmt.Sprintf(\"%s_%s\", org, repo)\r\n\t}\r\n}","code-length":114,"reference":"\/\/ NewSingleDefaultRepoPathBuilder returns a builder that handles the legacy path\n\/\/ encoding where a path will contain org and repo for all but one default repo","result":"Create a single default repo path builder.","score":[0.018,0.131]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewExplicitRepoPathBuilder() RepoPathBuilder {\r\n\treturn func(org, repo string) string {\r\n\t\t\r\n\t\trepo = strings.Replace(repo, \"\/\", \"_\", -1)\r\n\t\treturn fmt.Sprintf(\"%s_%s\", org, repo)\r\n\t}\r\n}","code-length":80,"reference":"\/\/ NewExplicitRepoPathBuilder returns a builder that handles the path encoding\n\/\/ where a path will always have an explicit \"org_repo\" path segment","result":"Create a new RepoPathBuilder.","score":[0.0035,0.0248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc RegisterSourceOrDie(name string, src IssueSource) {\r\n\tif _, ok := sources[name]; ok {\r\n\t\tglog.Fatalf(\"Cannot register an IssueSource with name %q, already exists!\", name)\r\n\t}\r\n\tsources[name] = src\r\n\tglog.Infof(\"Registered issue source '%s'.\", name)\r\n}","code-length":96,"reference":"\/\/ RegisterSourceOrDie registers a source of auto-filed issues.","result":"Register a source.","score":[0.0771,0.25]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *IssueCreator) CreateAndSync() {\r\n\tvar err error\r\n\tif err = c.initialize(); err != nil {\r\n\t\tglog.Fatalf(\"Error initializing IssueCreator: %v.\", err)\r\n\t}\r\n\tglog.Info(\"IssueCreator initialization complete.\")\r\n\tfor srcName, src := range sources {\r\n\t\tglog.Infof(\"Generating issues from source: %s.\", srcName)\r\n\t\tvar issues []Issue\r\n\t\tif issues, err = src.Issues(c); err != nil {\r\n\t\t\tglog.Errorf(\"Error generating issues. Source: %s Msg: %v.\", srcName, err)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tglog.Infof(\"Syncing issues from source: %s.\", srcName)\r\n\t\tcreated := 0\r\n\t\tfor _, issue := range issues {\r\n\t\t\tif c.sync(issue) {\r\n\t\t\t\tcreated++\r\n\t\t\t}\r\n\t\t}\r\n\t\tglog.Infof(\r\n\t\t\t\"Created issues for %d of the %d issues synced from source: %s.\",\r\n\t\t\tcreated,\r\n\t\t\tlen(issues),\r\n\t\t\tsrcName,\r\n\t\t)\r\n\t}\r\n}","code-length":327,"reference":"\/\/ CreateAndSync is the main workhorse function of IssueCreator. It initializes the IssueCreator,\n\/\/ asks each source for its issues to sync, and syncs the issues.","result":"Generate code for the generated code.","score":[0.0082,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *IssueCreator) loadCache() error {\r\n\tuser, err := c.client.GetUser(\"\")\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to fetch the User struct for the current authenticated user. errmsg: %v\", err)\r\n\t}\r\n\tif user == nil {\r\n\t\treturn fmt.Errorf(\"received a nil User struct pointer when trying to look up the currently authenticated user\")\r\n\t}\r\n\tif user.Login == nil {\r\n\t\treturn fmt.Errorf(\"the user struct for the currently authenticated user does not specify a login\")\r\n\t}\r\n\tc.authorName = *user.Login\r\n\t\r\n\tif validLabels, err := c.client.GetRepoLabels(c.org, c.project); err != nil {\r\n\t\tc.validLabels = nil\r\n\t\tglog.Errorf(\"Failed to retrieve the list of valid labels for repo '%s\/%s'. Allowing all labels. errmsg: %v\\n\", c.org, c.project, err)\r\n\t} else {\r\n\t\tc.validLabels = make([]string, 0, len(validLabels))\r\n\t\tfor _, label := range validLabels {\r\n\t\t\tif label.Name != nil && *label.Name != \"\" {\r\n\t\t\t\tc.validLabels = append(c.validLabels, *label.Name)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\tif collaborators, err := c.client.GetCollaborators(c.org, c.project); err != nil {\r\n\t\tc.Collaborators = nil\r\n\t\tglog.Errorf(\"Failed to retrieve the list of valid collaborators for repo '%s\/%s'. Allowing all assignees. errmsg: %v\\n\", c.org, c.project, err)\r\n\t} else {\r\n\t\tc.Collaborators = make([]string, 0, len(collaborators))\r\n\t\tfor _, user := range collaborators {\r\n\t\t\tif user.Login != nil && *user.Login != \"\" {\r\n\t\t\t\tc.Collaborators = append(c.Collaborators, strings.ToLower(*user.Login))\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\tissues, err := c.client.GetIssues(\r\n\t\tc.org,\r\n\t\tc.project,\r\n\t\t&github.IssueListByRepoOptions{\r\n\t\t\tState:   \"all\",\r\n\t\t\tCreator: c.authorName,\r\n\t\t},\r\n\t)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to refresh the list of all issues created by %s in repo '%s\/%s'. errmsg: %v\", c.authorName, c.org, c.project, err)\r\n\t}\r\n\tif len(issues) == 0 {\r\n\t\tglog.Warningf(\"IssueCreator found no issues in the repo '%s\/%s' authored by '%s'.\\n\", c.org, c.project, c.authorName)\r\n\t}\r\n\tc.allIssues = make(map[int]*github.Issue)\r\n\tfor _, i := range issues {\r\n\t\tc.allIssues[*i.Number] = i\r\n\t}\r\n\treturn nil\r\n}","code-length":784,"reference":"\/\/ loadCache loads the valid labels for the repo, the currently authenticated user, and the issue cache from github.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc setIntersect(a, b []string) (filtered, removed []string) {\r\n\tfor _, elemA := range a {\r\n\t\tfound := false\r\n\t\tfor _, elemB := range b {\r\n\t\t\tif elemA == elemB {\r\n\t\t\t\tfound = true\r\n\t\t\t\tbreak\r\n\t\t\t}\r\n\t\t}\r\n\t\tif found {\r\n\t\t\tfiltered = append(filtered, elemA)\r\n\t\t} else {\r\n\t\t\tremoved = append(removed, elemA)\r\n\t\t}\r\n\t}\r\n\treturn\r\n}","code-length":148,"reference":"\/\/ setIntersect removes any elements from the first list that are not in the second, returning the\n\/\/ new set and the removed elements.","result":"Set the intersection of two sets.","score":[0.0096,0.045]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *IssueCreator) sync(issue Issue) bool {\r\n\t\r\n\tid := issue.ID()\r\n\tvar closedIssues []*github.Issue\r\n\tfor _, i := range c.allIssues {\r\n\t\tif strings.Contains(*i.Body, id) {\r\n\t\t\tswitch *i.State {\r\n\t\t\tcase \"open\":\r\n\t\t\t\t\r\n\t\t\t\treturn false\r\n\t\t\tcase \"closed\":\r\n\t\t\t\tclosedIssues = append(closedIssues, i)\r\n\t\t\tdefault:\r\n\t\t\t\tglog.Errorf(\"Unrecognized issue state '%s' for issue #%d. Ignoring this issue.\\n\", *i.State, *i.Number)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\t\r\n\tbody := issue.Body(closedIssues)\r\n\tif body == \"\" {\r\n\t\t\r\n\t\tglog.Infof(\"Issue aborted sync by providing \\\"\\\" (empty) body. ID: %s.\", id)\r\n\t\treturn false\r\n\t}\r\n\tif !strings.Contains(body, id) {\r\n\t\tglog.Fatalf(\"Programmer error: The following body text does not contain id '%s'.\\n%s\\n\", id, body)\r\n\t}\r\n\ttitle := issue.Title()\r\n\towners := issue.Owners()\r\n\tif c.Collaborators != nil {\r\n\t\tvar removedOwners []string\r\n\t\towners, removedOwners = setIntersect(owners, c.Collaborators)\r\n\t\tif len(removedOwners) > 0 {\r\n\t\t\tglog.Errorf(\"Filtered the following invalid assignees from issue %q: %q.\", title, removedOwners)\r\n\t\t}\r\n\t}\r\n\tlabels := issue.Labels()\r\n\tif prio, ok := issue.Priority(); ok {\r\n\t\tlabels = append(labels, \"priority\/\"+prio)\r\n\t}\r\n\tif c.validLabels != nil {\r\n\t\tvar removedLabels []string\r\n\t\tlabels, removedLabels = setIntersect(labels, c.validLabels)\r\n\t\tif len(removedLabels) > 0 {\r\n\t\t\tglog.Errorf(\"Filtered the following invalid labels from issue %q: %q.\", title, removedLabels)\r\n\t\t}\r\n\t}\r\n\tglog.Infof(\"Create Issue: %q Assigned to: %q\\n\", title, owners)\r\n\tif c.dryRun {\r\n\t\treturn true\r\n\t}\r\n\tcreated, err := c.client.CreateIssue(c.org, c.project, title, body, labels, owners)\r\n\tif err != nil {\r\n\t\tglog.Errorf(\"Failed to create a new github issue for issue ID '%s'.\\n\", id)\r\n\t\treturn false\r\n\t}\r\n\tc.allIssues[*created.Number] = created\r\n\treturn true\r\n}","code-length":696,"reference":"\/\/ sync checks to see if an issue is already on github and tries to create a new issue for it if it is not.\n\/\/ True is returned iff a new issue is created.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetAWSCreds(r *common.Resource) (credentials.Value, error) {\r\n\tval := credentials.Value{}\r\n\tif r.Type != ResourceType {\r\n\t\treturn val, fmt.Errorf(\"Wanted resource of type %q, got %q\", ResourceType, r.Type)\r\n\t}\r\n\taccessKey, ok := r.UserData.Map.Load(UserDataAccessIDKey)\r\n\tif !ok {\r\n\t\treturn val, errors.New(\"No Access Key ID in UserData\")\r\n\t}\r\n\tsecretKey, ok := r.UserData.Map.Load(UserDataSecretAccessKey)\r\n\tif !ok {\r\n\t\treturn val, errors.New(\"No Secret Access Key in UserData\")\r\n\t}\r\n\tval.AccessKeyID = accessKey.(string)\r\n\tval.SecretAccessKey = secretKey.(string)\r\n\treturn val, nil\r\n}","code-length":217,"reference":"\/\/ GetAWSCreds tries to fetch AWS credentials from a resource","result":"Get the AWS credentials from the service provider.","score":[0.2228,0.3827]}
{"code":"\/*is used to<extra_id_0>\r\nfunc stopper() chan struct{} {\r\n\tstop := make(chan struct{})\r\n\tc := make(chan os.Signal, 2)\r\n\tsignal.Notify(c, os.Interrupt, syscall.SIGTERM)\r\n\tgo func() {\r\n\t\t<-c\r\n\t\tlogrus.Warn(\"Interrupt received, attempting clean shutdown...\")\r\n\t\tclose(stop)\r\n\t\t<-c\r\n\t\tlogrus.Error(\"Second interrupt received, force exiting...\")\r\n\t\tos.Exit(1)\r\n\t}()\r\n\treturn stop\r\n}","code-length":146,"reference":"\/\/ stopper returns a channel that remains open until an interrupt is received.","result":"Stop the server.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newPipelineConfig(cfg rest.Config, stop chan struct{}) (*pipelineConfig, error) {\r\n\tbc, err := pipelineset.NewForConfig(&cfg)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\t\r\n\tif _, err := bc.TektonV1alpha1().PipelineRuns(\"\").List(metav1.ListOptions{Limit: 1}); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tbif := pipelineinfo.NewSharedInformerFactory(bc, 30*time.Minute)\r\n\tbif.Tekton().V1alpha1().PipelineRuns().Lister()\r\n\tgo bif.Start(stop)\r\n\treturn &pipelineConfig{\r\n\t\tclient:   bc,\r\n\t\tinformer: bif.Tekton().V1alpha1().PipelineRuns(),\r\n\t}, nil\r\n}","code-length":227,"reference":"\/\/ newPipelineConfig returns a client and informer capable of mutating and monitoring the specified config.","result":"Create a new pipeline config.","score":[0.0387,0.0714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *KubernetesClientOptions) KubeClient() (kubernetes.Interface, error) {\r\n\treturn kube.GetKubernetesClient(o.masterURL, o.kubeConfig)\r\n}","code-length":55,"reference":"\/\/ KubeClient returns a Kubernetes client.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *KubernetesClientOptions) ProwJobClient() (versioned.Interface, error) {\r\n\treturn kube.GetProwJobClient(o.masterURL, o.kubeConfig)\r\n}","code-length":57,"reference":"\/\/ ProwJobClient returns a Kubernetes client.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (bucket gcsBucket) resolveSymLink(symLink string) (string, error) {\r\n\tdata, err := bucket.readObject(symLink)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"failed to read %s: %v\", symLink, err)\r\n\t}\r\n\tplaceAllString(u, \"\"), nil\r\n}","code-length":94,"reference":"\/\/ resolve sym links into the actual log directory for a particular test run","result":"Resolve the symlink.","score":[0.0104,0.0775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc readJSON(bucket storageBucket, key string, data interface{}) error {\r\n\trawData, err := bucket.readObject(key)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to read %s: %v\", key, err)\r\n\t}\r\n\terr = json.Unmarshal(rawData, &data)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to parse %s: %v\", key, err)\r\n\t}\r\n\treturn nil\r\n}","code-length":132,"reference":"\/\/ reads specified JSON file in to `data`","result":"Read a JSON object.","score":[0.1175,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (bucket gcsBucket) listSubDirs(prefix string) ([]string, error) {\r\n\tif !strings.HasSuffix(prefix, \"\/\") {\r\n\t\tprefix += \"\/\"\r\n\t}\r\n\tdirs := []string{}\r\n\tit := bucket.Objects(context.Background(), &storage.Query{\r\n\t\tPrefix:    prefix,\r\n\t\tDelimiter: \"\/\",\r\n\t})\r\n\tfor {\r\n\t\tattrs, err := it.Next()\r\n\t\tif err == iterator.Done {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn dirs, err\r\n\t\t}\r\n\t\tif attrs.Prefix != \"\" {\r\n\t\t\tdirs = append(dirs, attrs.Prefix)\r\n\t\t}\r\n\t}\r\n\treturn dirs, nil\r\n}","code-length":206,"reference":"\/\/ Lists the GCS \"directory paths\" immediately under prefix.","result":"List subdirectories in a bucket.","score":[0,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (bucket gcsBucket) listAll(prefix string) ([]string, error) {\r\n\tkeys := []string{}\r\n\tit := bucket.Objects(context.Background(), &storage.Query{\r\n\t\tPrefix: prefix,\r\n\t})\r\n\tfor {\r\n\t\tattrs, err := it.Next()\r\n\t\tif err == iterator.Done {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn keys, err\r\n\t\t}\r\n\t\tkeys = append(keys, attrs.Name)\r\n\t}\r\n\treturn keys, nil\r\n}","code-length":153,"reference":"\/\/ Lists all GCS keys with given prefix.","result":"List all objects in a bucket.","score":[0.1383,0.2404]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (bucket gcsBucket) listBuildIDs(root string) ([]int64, error) {\r\n\tids := []int64{}\r\n\tif strings.HasPrefix(root, logsPrefix) {\r\n\t\tdirs, err := bucket.listSubDirs(root)\r\n\t\tif err != nil {\r\n\t\t\treturn ids, fmt.Errorf(\"failed to list GCS directories: %v\", err)\r\n\t\t}\r\n\t\tfor _, dir := range dirs {\r\n\t\t\ti, err := strconv.ParseInt(path.Base(dir), 10, 64)\r\n\t\t\tif err == nil {\r\n\t\t\t\tids = append(ids, i)\r\n\t\t\t} else {\r\n\t\t\t\tlogrus.Warningf(\"unrecognized directory name (expected int64): %s\", dir)\r\n\t\t\t}\r\n\t\t}\r\n\t} else {\r\n\t\tkeys, err := bucket.listAll(root)\r\n\t\tif err != nil {\r\n\t\t\treturn ids, fmt.Errorf(\"failed to list GCS keys: %v\", err)\r\n\t\t}\r\n\t\tfor _, key := range keys {\r\n\t\t\tmatches := linkRe.FindStringSubmatch(key)\r\n\t\t\tif len(matches) == 2 {\r\n\t\t\t\ti, err := strconv.ParseInt(matches[1], 10, 64)\r\n\t\t\t\tif err == nil {\r\n\t\t\t\t\tids = append(ids, i)\r\n\t\t\t\t} else {\r\n\t\t\t\t\tlogrus.Warningf(\"unrecognized file name (expected <int64>.txt): %s\", key)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn ids, nil\r\n}","code-length":404,"reference":"\/\/ Gets all build ids for a job.","result":"List build IDs in the bucket.","score":[0.1383,0.2404]}
{"code":"\/*is used to<extra_id_0>\r\nfunc FilterProfilePaths(profile []*cover.Profile, paths []string, include bool) ([]*cover.Profile, error) {\r\n\tparenPaths := make([]string, len(paths))\r\n\tfor i, path := range paths {\r\n\t\tparenPaths[i] = \"(\" + path + \")\"\r\n\t}\r\n\tjoined := strings.Join(parenPaths, \"|\")\r\n\tre, err := regexp.Compile(joined)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tresult := make([]*cover.Profile, 0, len(profile))\r\n\tfor _, p := range profile {\r\n\t\tif re.MatchString(p.FileName) == include {\r\n\t\t\tresult = append(result, p)\r\n\t\t}\r\n\t}\r\n\treturn result, nil\r\n}","code-length":208,"reference":"\/\/ FilterProfilePaths produces a new profile that removes either everything matching or everything\n\/\/ not matching the provided paths, depending on the value of include.\n\/\/ Paths are interpreted as regular expressions.\n\/\/ If include is true, paths is treated as a whitelist; otherwise it is treated as a blacklist.","result":"Filter profile by path.","score":[0.0,0.011]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadSecrets(paths []string) (map[string][]byte, error) {\r\n\tsecretsMap := make(map[string][]byte, len(paths))\r\n\tfor _, path := range paths {\r\n\t\tsecretValue, err := LoadSingleSecret(path)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tsecretsMap[path] = secretValue\r\n\t}\r\n\treturn secretsMap, nil\r\n}","code-length":124,"reference":"\/\/ LoadSecrets loads multiple paths of secrets and add them in a map.","result":"Load secrets.","score":[0,0.042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LoadSingleSecret(path string) ([]byte, error) {\r\n\tb, err := ioutil.ReadFile(path)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"error reading %s: %v\", path, err)\r\n\t}\r\n\treturn bytes.TrimSpace(b), nil\r\n}","code-length":88,"reference":"\/\/ LoadSingleSecret reads and returns the value of a single file.","result":"Load a single secret.","score":[0.0785,0.182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (b *Bool) Set(s string) error {\r\n\tv, err := strconv.ParseBool(s)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tb.Explicit = true\r\n\tb.Value = v\r\n\treturn nil\r\n}","code-length":78,"reference":"\/\/ Set the bool according to the string.","result":"Set the value of the field.","score":[0.2165,0.3276]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewOpener(ctx context.Context, creds string) (Opener, error) {\r\n\tvar options []option.ClientOption\r\n\tif creds != \"\" {\r\n\t\toptions = append(options, option.WithCredentialsFile(creds))\r\n\t}\r\n\tclient, err := storage.NewClient(ctx, options...)\r\n\tif err != nil {\r\n\t\tif creds != \"\" {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tlogrus.WithError(err).Debug(\"Cannot load application default gcp credentials\")\r\n\t\tclient = nil\r\n\t}\r\n\treturn opener{gcs: client}, nil\r\n}","code-length":161,"reference":"\/\/ NewOpener returns an opener that can read GCS and local paths.","result":"Create a new opener.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc IsNotExist(err error) bool {\r\n\treturn os.IsNotExist(err) || err == storage.ErrObjectNotExist\r\n}","code-length":39,"reference":"\/\/ IsNotExist will return true if the error is because the object does not exist.","result":"Detect the error type.","score":[0.0289,0.0719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc LogClose(c io.Closer) {\r\n\tif err := c.Close(); err != nil {\r\n\t\tlogrus.WithError(err).Error(\"Failed to close\")\r\n\t}\r\n}","code-length":57,"reference":"\/\/ LogClose will attempt a close an log any error","result":"Log the close of a file.","score":[0.1179,0.1562]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o opener) Writer(ctx context.Context, path string) (io.WriteCloser, error) {\r\n\tg, err := o.openGCS(path)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"bad gcs path: %v\", err)\r\n\t}\r\n\tif g == nil {\r\n\t\treturn os.Create(path)\r\n\t}\r\n\treturn g.NewWriter(ctx), nil\r\n}","code-length":118,"reference":"\/\/ Writer returns a writer that overwrites the path.","result":"Create a file.","score":[0.0553,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (gac *GitHubOAuthConfig) InitGitHubOAuthConfig(cookie *sessions.CookieStore) {\r\n\tgob.Register(&oauth2.Token{})\r\n\tgac.CookieStore = cookie\r\n}","code-length":59,"reference":"\/\/ InitGitHubOAuthConfig creates an OAuthClient using GitHubOAuth config and a Cookie Store\n\/\/ to retain user credentials.","result":"Initialize github oauth config.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc deltaDisplayed(change *coverageChange) string {\r\n\tif change.baseRatio < 0 {\r\n\t\treturn \"\"\r\n\t}\r\n\treturn fmt.Sprintf(\"%.1f\", (change.newRatio-change.baseRatio)*100)\r\n}","code-length":71,"reference":"\/\/ deltaDisplayed converts a coverage ratio delta into a string value to be displayed by coverage robot","result":"Calculate the delta displayed.","score":[0.0124,0.0318]}
{"code":"\/*is used to<extra_id_0>\r\nfunc makeTable(baseCovList, newCovList *calculation.CoverageList, coverageThreshold float32) (string, bool) {\r\n\tvar rows []string\r\n\tisCoverageLow := false\r\n\tfor _, change := range findChanges(baseCovList, newCovList) {\r\n\t\tfilePath := change.name\r\n\t\trows = append(rows, fmt.Sprintf(\"%s | %s | %s | %s\",\r\n\t\t\tfilePath,\r\n\t\t\tformatPercentage(change.baseRatio),\r\n\t\t\tformatPercentage(change.newRatio),\r\n\t\t\tdeltaDisplayed(change)))\r\n\t\tif change.newRatio < coverageThreshold {\r\n\t\t\tisCoverageLow = true\r\n\t\t}\r\n\t}\r\n\treturn strings.Join(rows, \"\\n\"), isCoverageLow\r\n}","code-length":203,"reference":"\/\/ makeTable checks each coverage change and produce the table content for coverage bot post\n\/\/ It also report on whether any coverage fells below the given threshold","result":"Generate the table .","score":[0.0011,0.0391]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ContentForGitHubPost(baseProfiles, newProfiles []*cover.Profile, jobName string, coverageThreshold float32) (\r\n\tstring, bool) {\r\n\trows := []string{\r\n\t\t\"The following is the code coverage report\",\r\n\t\tfmt.Sprintf(\"Say `\/test %s` to re-run this coverage report\", jobName),\r\n\t\t\"\",\r\n\t\t\"File | Old Coverage | New Coverage | Delta\",\r\n\t\t\"---- |:------------:|:------------:|:-----:\",\r\n\t}\r\n\ttable, isCoverageLow := makeTable(calculation.ProduceCovList(baseProfiles), calculation.ProduceCovList(newProfiles), coverageThreshold)\r\n\tif table == \"\" {\r\n\t\treturn \"\", false\r\n\t}\r\n\trows = append(rows, table)\r\n\trows = append(rows, \"\")\r\n\treturn strings.Join(rows, \"\\n\"), isCoverageLow\r\n}","code-length":231,"reference":"\/\/ ContentForGitHubPost constructs the message covbot posts","result":"Generate the code coverage report.","score":[0.1611,0.0735]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (client *Client) AddFlags(cmd *cobra.Command) {\r\n\tcmd.PersistentFlags().StringVar(&client.Token, \"token\", \"\",\r\n\t\t\"The OAuth Token to use for requests.\")\r\n\tcmd.PersistentFlags().StringVar(&client.TokenFile, \"token-file\", \"\",\r\n\t\t\"The file containing the OAuth Token to use for requests.\")\r\n\tcmd.PersistentFlags().StringVar(&client.Org, \"organization\", \"\",\r\n\t\t\"The github organization to scan\")\r\n\tcmd.PersistentFlags().StringVar(&client.Project, \"project\", \"\",\r\n\t\t\"The github project to scan\")\r\n}","code-length":166,"reference":"\/\/ AddFlags parses options for github client","result":"Add flags to a command.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (client *Client) CheckFlags() error {\r\n\tif client.Org == \"\" {\r\n\t\treturn fmt.Errorf(\"organization flag must be set\")\r\n\t}\r\n\tclient.Org = strings.ToLower(client.Org)\r\n\tif client.Project == \"\" {\r\n\t\treturn fmt.Errorf(\"project flag must be set\")\r\n\t}\r\n\tclient.Project = strings.ToLower(client.Project)\r\n\treturn nil\r\n}","code-length":118,"reference":"\/\/ CheckFlags looks for organization and project flags to configure the client","result":"Check flags.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (client *Client) getGitHubClient() (*github.Client, error) {\r\n\tif client.githubClient != nil {\r\n\t\treturn client.githubClient, nil\r\n\t}\r\n\ttoken := client.Token\r\n\tif len(token) == 0 && len(client.TokenFile) != 0 {\r\n\t\tdata, err := ioutil.ReadFile(client.TokenFile)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\ttoken = strings.TrimSpace(string(data))\r\n\t}\r\n\tif len(token) > 0 {\r\n\t\tts := oauth2.StaticTokenSource(&oauth2.Token{AccessToken: token})\r\n\t\ttc := oauth2.NewClient(oauth2.NoContext, ts)\r\n\t\tclient.githubClient = github.NewClient(tc)\r\n\t} else {\r\n\t\tclient.githubClient = github.NewClient(nil)\r\n\t}\r\n\treturn client.githubClient, nil\r\n}","code-length":249,"reference":"\/\/ getGitHubClient create the github client that we use to communicate with github","result":"Create a github client.","score":[0.0337,0.0826]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (client *Client) limitsCheckAndWait() {\r\n\tvar sleep time.Duration\r\n\tgithubClient, err := client.getGitHubClient()\r\n\tif err != nil {\r\n\t\tglog.Error(\"Failed to get RateLimits: \", err)\r\n\t\tsleep = time.Minute\r\n\t} else {\r\n\t\tlimits, _, err := githubClient.RateLimits(context.Background())\r\n\t\tif err != nil {\r\n\t\t\tglog.Error(\"Failed to get RateLimits:\", err)\r\n\t\t\tsleep = time.Minute\r\n\t\t}\r\n\t\tif limits != nil && limits.Core != nil && limits.Core.Remaining < tokenLimit {\r\n\t\t\tsleep = limits.Core.Reset.Sub(time.Now())\r\n\t\t\tglog.Warning(\"RateLimits: reached. Sleeping for \", sleep)\r\n\t\t}\r\n\t}\r\n\ttime.Sleep(sleep)\r\n}","code-length":228,"reference":"\/\/ limitsCheckAndWait make sure we have not reached the limit or wait","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (client *Client) FetchIssues(latest time.Time, c chan *github.Issue) {\r\n\topt := &github.IssueListByRepoOptions{Since: latest, Sort: \"updated\", State: \"all\", Direction: \"asc\"}\r\n\tgithubClient, err := client.getGitHubClient()\r\n\tif err != nil {\r\n\t\tclose(c)\r\n\t\tglog.Error(err)\r\n\t\treturn\r\n\t}\r\n\tcount := 0\r\n\tfor {\r\n\t\tclient.limitsCheckAndWait()\r\n\t\tissues, resp, err := githubClient.Issues.ListByRepo(\r\n\t\t\tcontext.Background(),\r\n\t\t\tclient.Org,\r\n\t\t\tclient.Project,\r\n\t\t\topt,\r\n\t\t)\r\n\t\tif err != nil {\r\n\t\t\tclose(c)\r\n\t\t\tglog.Error(err)\r\n\t\t\treturn\r\n\t\t}\r\n\t\tfor _, issue := range issues {\r\n\t\t\tc <- issue\r\n\t\t\tcount++\r\n\t\t}\r\n\t\tif resp.NextPage == 0 {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\topt.ListOptions.Page = resp.NextPage\r\n\t}\r\n\tglog.Infof(\"Fetched %d issues updated issue since %v.\", count, latest)\r\n\tclose(c)\r\n}","code-length":331,"reference":"\/\/ FetchIssues from GitHub, until 'latest' time","result":"Fetch issues updated issue since the last.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc hasID(events []*github.IssueEvent, id int) bool {\r\n\tfor _, event := range events {\r\n\t\tif *event.ID == int64(id) {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":76,"reference":"\/\/ hasID look for a specific id in a list of events","result":"Check if an issue event has an ID.","score":[0,0.0431]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (client *Client) FetchIssueEvents(issueID int, latest *int, c chan *github.IssueEvent) {\r\n\topt := &github.ListOptions{PerPage: 100}\r\n\tgithubClient, err := client.getGitHubClient()\r\n\tif err != nil {\r\n\t\tclose(c)\r\n\t\tglog.Error(err)\r\n\t\treturn\r\n\t}\r\n\tcount := 0\r\n\tfor {\r\n\t\tclient.limitsCheckAndWait()\r\n\t\tevents, resp, err := githubClient.Issues.ListIssueEvents(\r\n\t\t\tcontext.Background(),\r\n\t\t\tclient.Org,\r\n\t\t\tclient.Project,\r\n\t\t\tissueID,\r\n\t\t\topt,\r\n\t\t)\r\n\t\tif err != nil {\r\n\t\t\tglog.Errorf(\"ListIssueEvents failed: %s. Retrying...\", err)\r\n\t\t\ttime.Sleep(time.Second)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tfor _, event := range events {\r\n\t\t\tc <- event\r\n\t\t\tcount++\r\n\t\t}\r\n\t\tif resp.NextPage == 0 || (latest != nil && hasID(events, *latest)) {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\topt.Page = resp.NextPage\r\n\t}\r\n\tglog.Infof(\"Fetched %d events.\", count)\r\n\tclose(c)\r\n}","code-length":344,"reference":"\/\/ FetchIssueEvents from github and return the full list, until it matches 'latest'\n\/\/ The entire last page will be included so you can have redundancy.","result":"Fetch events from github.","score":[0.0013,0.021]}
{"code":"\/*is used to<extra_id_0>\r\nfunc isPRChanged(pe github.PullRequestEvent) bool {\r\n\tswitch pe.Action {\r\n\tcase github.PullRequestActionOpened:\r\n\t\treturn true\r\n\tcase github.PullRequestActionReopened:\r\n\t\treturn true\r\n\tcase github.PullRequestActionSynchronize:\r\n\t\treturn true\r\n\tcase github.PullRequestActionEdited:\r\n\t\treturn true\r\n\tdefault:\r\n\t\treturn false\r\n\t}\r\n}","code-length":115,"reference":"\/\/ These are the only actions indicating the code diffs may have changed.","result":"Detect PR changes.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFetcher(repository string) *Fetcher {\r\n\treturn &Fetcher{\r\n\t\tIssuesChannel:         make(chan sql.Issue, 100),\r\n\t\tEventsCommentsChannel: make(chan interface{}, 100),\r\n\t\trepository:            repository,\r\n\t}\r\n}","code-length":75,"reference":"\/\/ NewFetcher creates a new Fetcher and initializes the output channels","result":"Create a fetcher.","score":[0.0284,0.1838]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *Fetcher) fetchRecentIssues(db *gorm.DB) error {\r\n\tglog.Infof(\"Fetching issues updated after %s\", f.lastIssue)\r\n\tvar issues []sql.Issue\r\n\tquery := db.\r\n\t\tWhere(\"issue_updated_at >= ?\", f.lastIssue).\r\n\t\tWhere(\"repository = ?\", f.repository).\r\n\t\tOrder(\"issue_updated_at\").\r\n\t\tPreload(\"Labels\").\r\n\t\tFind(&issues)\r\n\tif query.Error != nil {\r\n\t\treturn query.Error\r\n\t}\r\n\tcount := len(issues)\r\n\tfor _, issue := range issues {\r\n\t\tf.IssuesChannel <- issue\r\n\t\tf.lastIssue = issue.IssueUpdatedAt\r\n\t}\r\n\tglog.Infof(\"Found and pushed %d updated\/new issues\", count)\r\n\treturn nil\r\n}","code-length":226,"reference":"\/\/ fetchRecentIssues retrieves issues from DB, but only fetches issues modified since last call","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *Fetcher) fetchRecentEventsAndComments(db *gorm.DB) error {\r\n\tglog.Infof(\"Fetching issue-events with id bigger than %s\", f.lastEvent)\r\n\tglog.Infof(\"Fetching comments with id bigger than %s\", f.lastComment)\r\n\teventRows, err := db.\r\n\t\tModel(sql.IssueEvent{}).\r\n\t\tWhere(\"repository = ?\", f.repository).\r\n\t\tWhere(\"event_created_at > ?\", f.lastEvent).\r\n\t\tOrder(\"event_created_at asc\").\r\n\t\tRows()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"Failed to query events from database: %s\", err)\r\n\t}\r\n\tcommentRows, err := db.\r\n\t\tModel(sql.Comment{}).\r\n\t\tWhere(\"repository = ?\", f.repository).\r\n\t\tWhere(\"comment_created_at > ?\", f.lastComment).\r\n\t\tOrder(\"comment_created_at asc\").\r\n\t\tRows()\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"Failed to query comments from database: %s\", err)\r\n\t}\r\n\tcount := 0\r\n\tcomment := &sql.Comment{}\r\n\tif commentRows.Next() {\r\n\t\tdb.ScanRows(commentRows, comment)\r\n\t} else {\r\n\t\tcomment = nil\r\n\t}\r\n\tevent := &sql.IssueEvent{}\r\n\tif eventRows.Next() {\r\n\t\tdb.ScanRows(eventRows, event)\r\n\t} else {\r\n\t\tevent = nil\r\n\t}\r\n\tfor event != nil || comment != nil {\r\n\t\tif event == nil || (comment != nil && comment.CommentCreatedAt.Before(event.EventCreatedAt)) {\r\n\t\t\tf.EventsCommentsChannel <- *comment\r\n\t\t\tf.lastComment = comment.CommentCreatedAt\r\n\t\t\tif commentRows.Next() {\r\n\t\t\t\tdb.ScanRows(commentRows, comment)\r\n\t\t\t} else {\r\n\t\t\t\tcomment = nil\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\tf.EventsCommentsChannel <- *event\r\n\t\t\tf.lastEvent = event.EventCreatedAt\r\n\t\t\tif eventRows.Next() {\r\n\t\t\t\tdb.ScanRows(eventRows, event)\r\n\t\t\t} else {\r\n\t\t\t\tevent = nil\r\n\t\t\t}\r\n\t\t}\r\n\t\tcount++\r\n\t}\r\n\tglog.Infof(\"Found and pushed %d new events\/comments\", count)\r\n\treturn nil\r\n}","code-length":628,"reference":"\/\/ fetchRecentEventsAndComments retrieves events from DB, but only fetches events created since last call","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *Fetcher) Fetch(db *gorm.DB) error {\r\n\tif err := f.fetchRecentIssues(db); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif err := f.fetchRecentEventsAndComments(db); err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":92,"reference":"\/\/ Fetch retrieves all types of events, and push them to output channels","result":"Fetch the content.","score":[0.0146,0.0417]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (fjr *FlakyJobReporter) Issues(c *creator.IssueCreator) ([]creator.Issue, error) {\r\n\tfjr.creator = c\r\n\tjson, err := ReadHTTP(fjr.flakyJobDataURL)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tflakyJobs, err := fjr.parseFlakyJobs(json)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tcount := fjr.syncCount\r\n\tif len(flakyJobs) < count {\r\n\t\tcount = len(flakyJobs)\r\n\t}\r\n\tissues := make([]creator.Issue, 0, count)\r\n\tfor _, fj := range flakyJobs[0:count] {\r\n\t\tissues = append(issues, fj)\r\n\t}\r\n\treturn issues, nil\r\n}","code-length":231,"reference":"\/\/ Issues is the main work method of FlakyJobReporter. It fetches and parses flaky job data,\n\/\/ then syncs the top issues to github with the IssueCreator.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (fj *FlakyJob) Title() string {\r\n\treturn fmt.Sprintf(\"%s flaked %d times in the past week\", fj.Name, *fj.FlakeCount)\r\n}","code-length":58,"reference":"\/\/ Title yields the initial title text of the github issue.","result":"Generate title.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (fj *FlakyJob) Labels() []string {\r\n\tlabels := []string{\"kind\/flake\"}\r\n\t\r\n\tfor sig := range fj.reporter.creator.TestsSIGs(fj.TestsSorted()) {\r\n\t\tlabels = append(labels, \"sig\/\"+sig)\r\n\t}\r\n\treturn labels\r\n}","code-length":93,"reference":"\/\/ Labels returns the labels to apply to the issue created for this flaky job on github.","result":"Get the labels of the flaky job.","score":[0.0651,0.1973]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ReadHTTP(url string) ([]byte, error) {\r\n\tvar err error\r\n\tretryDelay := time.Duration(2) * time.Second\r\n\tfor retryCount := 0; retryCount < 5; retryCount++ {\r\n\t\tif retryCount > 0 {\r\n\t\t\ttime.Sleep(retryDelay)\r\n\t\t\tretryDelay *= time.Duration(2)\r\n\t\t}\r\n\t\tresp, err := http.Get(url)\r\n\t\tif resp != nil && resp.StatusCode >= 500 {\r\n\t\t\t\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tdefer resp.Body.Close()\r\n\t\tbody, err := ioutil.ReadAll(resp.Body)\r\n\t\tif err != nil {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\treturn body, nil\r\n\t}\r\n\treturn nil, fmt.Errorf(\"ran out of retries reading from '%s'. Last error was %v\", url, err)\r\n}","code-length":253,"reference":"\/\/ ReadHTTP fetches file contents from a URL with retries.","result":"Read a file from a URL .","score":[0.2329,0.3866]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (l linesByTimestamp) String() string {\r\n\tsort.Sort(l)\r\n\tvar log string\r\n\tfor i, line := range l {\r\n\t\tswitch i {\r\n\t\tcase len(l) - 1:\r\n\t\t\tlog += string(line.actual)\r\n\t\tdefault:\r\n\t\t\t\r\n\t\t\tlog += fmt.Sprintf(\"%s,\\n\", strings.TrimSuffix(string(line.actual), \"\\n\"))\r\n\t\t}\r\n\t}\r\n\treturn fmt.Sprintf(\"[%s]\", log)\r\n}","code-length":143,"reference":"\/\/ Return valid json.","result":"Print log lines by timestamp.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewJobSpec(spec prowapi.ProwJobSpec, buildID, prowJobID string) JobSpec {\r\n\treturn JobSpec{\r\n\t\tType:      spec.Type,\r\n\t\tJob:       spec.Job,\r\n\t\tBuildID:   buildID,\r\n\t\tProwJobID: prowJobID,\r\n\t\tRefs:      spec.Refs,\r\n\t\tExtraRefs: spec.ExtraRefs,\r\n\t\tagent:     spec.Agent,\r\n\t}\r\n}","code-length":131,"reference":"\/\/ NewJobSpec converts a prowapi.ProwJobSpec invocation into a JobSpec","result":"Create a new job spec.","score":[0.108,0.0581]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ResolveSpecFromEnv() (*JobSpec, error) {\r\n\tspecEnv, ok := os.LookupEnv(JobSpecEnv)\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"$%s unset\", JobSpecEnv)\r\n\t}\r\n\tspec := &JobSpec{}\r\n\tif err := json.Unmarshal([]byte(specEnv), spec); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"malformed $%s: %v\", JobSpecEnv, err)\r\n\t}\r\n\treturn spec, nil\r\n}","code-length":142,"reference":"\/\/ ResolveSpecFromEnv will determine the Refs being\n\/\/ tested in by parsing Prow environment variable contents","result":"Resolve job spec from environment variables.","score":[0.0365,0.0333]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EnvForSpec(spec JobSpec) (map[string]string, error) {\r\n\tenv := map[string]string{\r\n\t\tjobNameEnv:   spec.Job,\r\n\t\tbuildIDEnv:   spec.BuildID,\r\n\t\tprowJobIDEnv: spec.ProwJobID,\r\n\t\tjobTypeEnv:   string(spec.Type),\r\n\t}\r\n\t\r\n\t\r\n\t\r\n\tif spec.agent == prowapi.KubernetesAgent {\r\n\t\tenv[prowBuildIDEnv] = spec.BuildID\r\n\t}\r\n\traw, err := json.Marshal(spec)\r\n\tif err != nil {\r\n\t\treturn env, fmt.Errorf(\"failed to marshal job spec: %v\", err)\r\n\t}\r\n\tenv[JobSpecEnv] = string(raw)\r\n\tif spec.Type == prowapi.PeriodicJob {\r\n\t\treturn env, nil\r\n\t}\r\n\tenv[repoOwnerEnv] = spec.Refs.Org\r\n\tenv[repoNameEnv] = spec.Refs.Repo\r\n\tenv[pullBaseRefEnv] = spec.Refs.BaseRef\r\n\tenv[pullBaseShaEnv] = spec.Refs.BaseSHA\r\n\tenv[pullRefsEnv] = spec.Refs.String()\r\n\tif spec.Type == prowapi.PostsubmitJob || spec.Type == prowapi.BatchJob {\r\n\t\treturn env, nil\r\n\t}\r\n\tenv[pullNumberEnv] = strconv.Itoa(spec.Refs.Pulls[0].Number)\r\n\tenv[pullPullShaEnv] = spec.Refs.Pulls[0].SHA\r\n\treturn env, nil\r\n}","code-length":412,"reference":"\/\/ EnvForSpec returns a mapping of environment variables\n\/\/ to their values that should be available for a job spec","result":"Generate the job env .","score":[0.012,0.027]}
{"code":"\/*is used to<extra_id_0>\r\nfunc EnvForType(jobType prowapi.ProwJobType) []string {\r\n\tbaseEnv := []string{jobNameEnv, JobSpecEnv, jobTypeEnv, prowJobIDEnv, buildIDEnv, prowBuildIDEnv}\r\n\trefsEnv := []string{repoOwnerEnv, repoNameEnv, pullBaseRefEnv, pullBaseShaEnv, pullRefsEnv}\r\n\tpullEnv := []string{pullNumberEnv, pullPullShaEnv}\r\n\tswitch jobType {\r\n\tcase prowapi.PeriodicJob:\r\n\t\treturn baseEnv\r\n\tcase prowapi.PostsubmitJob, prowapi.BatchJob:\r\n\t\treturn append(baseEnv, refsEnv...)\r\n\tcase prowapi.PresubmitJob:\r\n\t\treturn append(append(baseEnv, refsEnv...), pullEnv...)\r\n\tdefault:\r\n\t\treturn []string{}\r\n\t}\r\n}","code-length":222,"reference":"\/\/ EnvForType returns the slice of environment variables to export for jobType","result":"Generate the environment variables for the job.","score":[0.133,0.2745]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getRevisionFromRef(refs *prowapi.Refs) string {\r\n\tif len(refs.Pulls) > 0 {\r\n\t\treturn refs.Pulls[0].SHA\r\n\t}\r\n\tif refs.BaseSHA != \"\" {\r\n\t\treturn refs.BaseSHA\r\n\t}\r\n\treturn refs.BaseRef\r\n}","code-length":90,"reference":"\/\/ getRevisionFromRef returns a ref or sha from a refs object","result":"Generate the revision from ref.","score":[0.0724,0.0481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetRevisionFromSpec(spec *JobSpec) string {\r\n\tif spec.Refs != nil {\r\n\t\treturn getRevisionFromRef(spec.Refs)\r\n\t} else if len(spec.ExtraRefs) > 0 {\r\n\t\treturn getRevisionFromRef(&spec.ExtraRefs[0])\r\n\t}\r\n\treturn \"\"\r\n}","code-length":90,"reference":"\/\/ GetRevisionFromSpec returns a main ref or sha from a spec object","result":"Generate the revision string for the job.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc helpProvider(config *plugins.Configuration, enabledRepos []string) (*pluginhelp.PluginHelp, error) {\r\n\t\r\n\treturn &pluginhelp.PluginHelp{\r\n\t\tDescription: fmt.Sprintf(\"The merge commit blocker plugin adds the %s label to pull requests that contain merge commits\", labels.MergeCommits),\r\n\t}, nil\r\n}","code-length":92,"reference":"\/\/ helpProvider provides information on the plugin","result":"Provide the help for the plugin.","score":[0.1634,0.1449]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Group) load(r io.Reader) ([]string, error) {\r\n\tvar repoPaths []string\r\n\ts := bufio.NewScanner(r)\r\n\tfor s.Scan() {\r\n\t\tl := strings.TrimSpace(s.Text())\r\n\t\tif l == \"\" || l[0] == '#' {\r\n\t\t\t\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tfs := strings.Fields(l)\r\n\t\tif len(fs) != 2 {\r\n\t\t\treturn repoPaths, &ParseError{line: l}\r\n\t\t}\r\n\t\tswitch fs[0] {\r\n\t\tcase \"prefix\", \"path-prefix\":\r\n\t\t\tg.PathPrefixes[fs[1]] = true\r\n\t\tcase \"file-prefix\":\r\n\t\t\tg.FilePrefixes[fs[1]] = true\r\n\t\tcase \"file-name\":\r\n\t\t\tg.FileNames[fs[1]] = true\r\n\t\tcase \"path\":\r\n\t\t\tg.FileNames[fs[1]] = true\r\n\t\tcase \"paths-from-repo\":\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\trepoPaths = append(repoPaths, fs[1])\r\n\t\tdefault:\r\n\t\t\treturn repoPaths, &ParseError{line: l}\r\n\t\t}\r\n\t}\r\n\tif err := s.Err(); err != nil {\r\n\t\treturn repoPaths, err\r\n\t}\r\n\treturn repoPaths, nil\r\n}","code-length":362,"reference":"\/\/ Use load to read a generated files config file, and populate g with the commands.\n\/\/ \"paths-from-repo\" commands are aggregated into repoPaths. It is the caller's\n\/\/ responsibility to fetch these and load them via g.loadPaths.","result":"Load the file.","score":[0.0,0.0298]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Group) loadPaths(r io.Reader) error {\r\n\ts := bufio.NewScanner(r)\r\n\tfor s.Scan() {\r\n\t\tl := strings.TrimSpace(s.Text())\r\n\t\tif l == \"\" || l[0] == '#' {\r\n\t\t\t\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tg.Paths[l] = true\r\n\t}\r\n\tif err := s.Err(); err != nil {\r\n\t\treturn fmt.Errorf(\"scan error: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":149,"reference":"\/\/ Use loadPaths to load a file of new-line delimited paths, such as\n\/\/ resolving file data referenced in a \"paths-from-repo\" command.","result":"Load paths in the file.","score":[0.008,0.0493]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Group) Match(path string) bool {\r\n\tif g.Paths[path] {\r\n\t\treturn true\r\n\t}\r\n\tfor prefix := range g.PathPrefixes {\r\n\t\tif strings.HasPrefix(path, prefix) {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\tbase := filepath.Base(path)\r\n\tif g.FileNames[base] {\r\n\t\treturn true\r\n\t}\r\n\tfor prefix := range g.FilePrefixes {\r\n\t\tif strings.HasPrefix(base, prefix) {\r\n\t\t\treturn true\r\n\t\t}\r\n\t}\r\n\treturn false\r\n}","code-length":168,"reference":"\/\/ Match determines whether a file, given here by its full path\n\/\/ is included in the generated files group.","result":"Match the path.","score":[0.0017,0.0546]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (config *InfluxConfig) CreateDatabase(tags map[string]string, measurement string) (*InfluxDB, error) {\r\n\tclient, err := influxdb.NewHTTPClient(influxdb.HTTPConfig{\r\n\t\tAddr:     config.Host,\r\n\t\tUsername: config.User,\r\n\t\tPassword: config.Password,\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\terr = dropSeries(client, measurement, config.DB, tags)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tbp, err := influxdb.NewBatchPoints(influxdb.BatchPointsConfig{\r\n\t\tDatabase:  config.DB,\r\n\t\tPrecision: \"s\",\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn &InfluxDB{\r\n\t\tclient:      client,\r\n\t\tdatabase:    config.DB,\r\n\t\tbatch:       bp,\r\n\t\ttags:        tags,\r\n\t\tmeasurement: measurement,\r\n\t}, err\r\n}","code-length":277,"reference":"\/\/ CreateDatabase creates and connects a new instance of an InfluxDB\n\/\/ It is created based on the fields set in the configuration.","result":"Create a new database.","score":[0.0039,0.1211]}
{"code":"\/*is used to<extra_id_0>\r\nfunc mergeTags(defaultTags, extraTags map[string]string) map[string]string {\r\n\tnewTags := map[string]string{}\r\n\tfor k, v := range defaultTags {\r\n\t\tnewTags[k] = v\r\n\t}\r\n\tfor k, v := range extraTags {\r\n\t\tnewTags[k] = v\r\n\t}\r\n\treturn newTags\r\n}","code-length":105,"reference":"\/\/ mergeTags merges the default tags with the exta tags. Default will be overridden if it conflicts.","result":"Merge default and extra tags.","score":[0.0259,0.0949]}
{"code":"\/*is used to<extra_id_0>\r\nfunc tagsToWhere(tags map[string]string) string {\r\n\tif len(tags) == 0 {\r\n\t\treturn \"\"\r\n\t}\r\n\tsortedKeys := []string{}\r\n\tfor k := range tags {\r\n\t\tsortedKeys = append(sortedKeys, k)\r\n\t}\r\n\tsort.Strings(sortedKeys)\r\n\tconditions := []string{}\r\n\tfor _, key := range sortedKeys {\r\n\t\tconditions = append(conditions, fmt.Sprintf(`\"%s\" = '%v'`, key, tags[key]))\r\n\t}\r\n\treturn \"WHERE \" + strings.Join(conditions, \" AND \")\r\n}","code-length":164,"reference":"\/\/ tagsToWhere creates a where query to match tags element","result":"Generate the tagsToWhere function.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (i *InfluxDB) Push(tags map[string]string, fields map[string]interface{}, date time.Time) error {\r\n\tpt, err := influxdb.NewPoint(i.measurement, mergeTags(i.tags, tags), fields, date)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ti.batch.AddPoint(pt)\r\n\ti.batchSize++\r\n\treturn nil\r\n}","code-length":116,"reference":"\/\/ Push a point to the database. This appends to current batchpoint","result":"Push metrics to the influxdb.","score":[0.0927,0.1327]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (af *PodLogArtifactFetcher) artifact(jobName, buildID string, sizeLimit int64) (lenses.Artifact, error) {\r\n\tpodLog, err := NewPodLogArtifact(jobName, buildID, sizeLimit, af.jobAgent)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"Error accessing pod log from given source: %v\", err)\r\n\t}\r\n\treturn podLog, nil\r\n}","code-length":115,"reference":"\/\/ artifact constructs an artifact handle for the given job build","result":"Fetch the pod log artifact from given source.","score":[0.1256,0.1402]}
{"code":"\/*is used to<extra_id_0>\r\nfunc serve() {\r\n\thttp.Handle(\"\/metrics\", promhttp.Handler())\r\n\tlogrus.WithError(http.ListenAndServe(\":8080\", nil)).Fatal(\"ListenAndServe returned.\")\r\n}","code-length":58,"reference":"\/\/ serve starts a http server and serves prometheus metrics.\n\/\/ Meant to be called inside a goroutine.","result":"Serve the metrics.","score":[0.0028,0.0606]}
{"code":"\/*is used to<extra_id_0>\r\nfunc gather(c *plank.Controller) {\r\n\ttick := time.Tick(30 * time.Second)\r\n\tsig := make(chan os.Signal, 1)\r\n\tsignal.Notify(sig, os.Interrupt, syscall.SIGTERM)\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase <-tick:\r\n\t\t\tstart := time.Now()\r\n\t\t\tc.SyncMetrics()\r\n\t\t\tlogrus.WithField(\"metrics-duration\", fmt.Sprintf(\"%v\", time.Since(start))).Debug(\"Metrics synced\")\r\n\t\tcase <-sig:\r\n\t\t\tlogrus.Debug(\"Plank gatherer is shutting down...\")\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":181,"reference":"\/\/ gather metrics from plank.\n\/\/ Meant to be called inside a goroutine.","result":"Gather metrics from the plank controller.","score":[0.085,0.2394]}
{"code":"\/*is used to<extra_id_0>\r\nfunc makeRequest(policy branchprotection.Policy) github.BranchProtectionRequest {\r\n\treturn github.BranchProtectionRequest{\r\n\t\tEnforceAdmins:              makeAdmins(policy.Admins),\r\n\t\tRequiredPullRequestReviews: makeReviews(policy.RequiredPullRequestReviews),\r\n\t\tRequiredStatusChecks:       makeChecks(policy.RequiredStatusChecks),\r\n\t\tRestrictions:               makeRestrictions(policy.Restrictions),\r\n\t}\r\n}","code-length":113,"reference":"\/\/ makeRequest renders a branch protection policy into the corresponding GitHub api request.","result":"Create a branch protection request.","score":[0.1074,0.3074]}
{"code":"\/*is used to<extra_id_0>\r\nfunc makeReviews(rp *branchprotection.ReviewPolicy) *github.RequiredPullRequestReviews {\r\n\tswitch {\r\n\tcase rp == nil:\r\n\t\treturn nil\r\n\tcase rp.Approvals == nil:\r\n\t\tlogrus.Warn(\"WARNING: required_pull_request_reviews policy does not specify required_approving_review_count, disabling\")\r\n\t\treturn nil\r\n\tcase *rp.Approvals == 0:\r\n\t\treturn nil\r\n\t}\r\n\trprr := github.RequiredPullRequestReviews{\r\n\t\tDismissStaleReviews:          makeBool(rp.DismissStale),\r\n\t\tRequireCodeOwnerReviews:      makeBool(rp.RequireOwners),\r\n\t\tRequiredApprovingReviewCount: *rp.Approvals,\r\n\t}\r\n\tif rp.DismissalRestrictions != nil {\r\n\t\trprr.DismissalRestrictions = *makeRestrictions(rp.DismissalRestrictions)\r\n\t}\r\n\treturn &rprr\r\n}","code-length":247,"reference":"\/\/ makeReviews renders review policy into the corresponding GitHub api object.\n\/\/\n\/\/ Returns nil if the policy is nil, or approvals is nil or 0.","result":"Create reviews for a.","score":[0,0.021]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lens Lens) Header(artifacts []lenses.Artifact, resourceDir string) string {\r\n\treturn executeTemplate(resourceDir, \"header\", BuildLogsView{})\r\n}","code-length":51,"reference":"\/\/ Header executes the \"header\" section of the template.","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (lens Lens) Callback(artifacts []lenses.Artifact, resourceDir string, data string) string {\r\n\tvar request LineRequest\r\n\terr := json.Unmarshal([]byte(data), &request)\r\n\tif err != nil {\r\n\t\treturn \"failed to unmarshal request\"\r\n\t}\r\n\tartifact, ok := artifactByName(artifacts, request.Artifact)\r\n\tif !ok {\r\n\t\treturn \"no artifact named \" + request.Artifact\r\n\t}\r\n\tvar lines []string\r\n\tif request.Offset == 0 && request.Length == -1 {\r\n\t\tlines, err = logLinesAll(artifact)\r\n\t} else {\r\n\t\tlines, err = logLines(artifact, request.Offset, request.Length)\r\n\t}\r\n\tif err != nil {\r\n\t\treturn fmt.Sprintf(\"failed to retrieve log lines: %v\", err)\r\n\t}\r\n\tlogLines := highlightLines(lines, request.StartLine)\r\n\treturn executeTemplate(resourceDir, \"line group\", logLines)\r\n}","code-length":259,"reference":"\/\/ Callback is used to retrieve new log segments","result":"Retrieve log lines.","score":[0.0553,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc logLinesAll(artifact lenses.Artifact) ([]string, error) {\r\n\tread, err := artifact.ReadAll()\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"failed to read log %q: %v\", artifact.JobPath(), err)\r\n\t}\r\n\tlogLines := strings.Split(string(read), \"\\n\")\r\n\treturn logLines, nil\r\n}","code-length":107,"reference":"\/\/ logLinesAll reads all of an artifact and splits it into lines.","result":"Read log lines from a artifact.","score":[0,0.0439]}
{"code":"\/*is used to<extra_id_0>\r\nfunc executeTemplate(resourceDir, templateName string, data interface{}) string {\r\n\tt := template.New(\"template.html\")\r\n\t_, err := t.ParseFiles(filepath.Join(resourceDir, \"template.html\"))\r\n\tif err != nil {\r\n\t\treturn fmt.Sprintf(\"Failed to load template: %v\", err)\r\n\t}\r\n\tvar buf bytes.Buffer\r\n\tif err := t.ExecuteTemplate(&buf, templateName, data); err != nil {\r\n\t\tlogrus.WithError(err).Error(\"Error executing template.\")\r\n\t}\r\n\treturn buf.String()\r\n}","code-length":158,"reference":"\/\/ LogViewTemplate executes the log viewer template ready for rendering","result":"Execute a template.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ResourceObject) DeepCopyObject() runtime.Object {\r\n\tif c := in.deepCopy(); c != nil {\r\n\t\treturn c\r\n\t}\r\n\treturn nil\r\n}","code-length":56,"reference":"\/\/ DeepCopyObject implements runtime.Object interface","result":"Avoid deep copy.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ResourceObject) FromItem(i common.Item) {\r\n\tr, err := common.ItemToResource(i)\r\n\tif err == nil {\r\n\t\tin.fromResource(r)\r\n\t}\r\n}","code-length":66,"reference":"\/\/ FromItem implements Object interface","result":"Construct the resource object.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ResourceCollection) SetItems(objects []Object) {\r\n\tvar items []*ResourceObject\r\n\tfor _, b := range objects {\r\n\t\titems = append(items, b.(*ResourceObject))\r\n\t}\r\n\tin.Items = items\r\n}","code-length":75,"reference":"\/\/ SetItems implements Collection interface","result":"Set items of a resource collection.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ResourceCollection) DeepCopyObject() runtime.Object {\r\n\tif c := in.deepCopy(); c != nil {\r\n\t\treturn c\r\n\t}\r\n\treturn nil\r\n}","code-length":56,"reference":"\/\/ DeepCopyObject implements Collection interface","result":"Avoid deep copy.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc useContext(o options, ctx string) error {\r\n\t_, cmd := command(\"kubectl\", \"config\", \"use-context\", ctx)\r\n\treturn cmd.Run()\r\n}","code-length":55,"reference":"\/\/ useContext calls kubectl config use-context ctx","result":"Set the context in the config file.","score":[0.1615,0.0714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc currentContext(o options) (string, error) {\r\n\t_, cmd := command(\"kubectl\", \"config\", \"current-context\")\r\n\tb, err := cmd.Output()\r\n\treturn strings.TrimSpace(string(b)), err\r\n}","code-length":71,"reference":"\/\/ currentContext returns kubectl config current-context","result":"Get the current context from the current context.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc command(bin string, args ...string) ([]string, *exec.Cmd) {\r\n\tcmd := exec.Command(bin, args...)\r\n\tcmd.Stderr = os.Stderr\r\n\treturn append([]string{bin}, args...), cmd\r\n}","code-length":70,"reference":"\/\/ command creates an exec.Cmd with Stderr piped to os.Stderr and returns the args","result":"Execute commands.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc describeCluster(o options) (*describe, error) {\r\n\tif o.account != \"\" {\r\n\t\tact, err := getAccount()\r\n\t\tif err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"get current account: %v\", err)\r\n\t\t}\r\n\t\tdefer setAccount(act)\r\n\t\tif err = setAccount(o.account); err != nil {\r\n\t\t\treturn nil, fmt.Errorf(\"set account %s: %v\", o.account, err)\r\n\t\t}\r\n\t}\r\n\targs, cmd := command(\r\n\t\t\"gcloud\", \"container\", \"clusters\", \"describe\", o.cluster,\r\n\t\t\"--project\", o.project,\r\n\t\t\"--zone\", o.zone,\r\n\t\t\"--format=yaml\",\r\n\t)\r\n\tdata, err := cmd.Output()\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"%s: %v\", strings.Join(args, \" \"), err)\r\n\t}\r\n\tvar d describe\r\n\tif yaml.Unmarshal(data, &d); err != nil {\r\n\t\treturn nil, fmt.Errorf(\"unmarshal gcloud: %v\", err)\r\n\t}\r\n\tif d.Endpoint == \"\" {\r\n\t\treturn nil, errors.New(\"empty endpoint\")\r\n\t}\r\n\tif len(d.Auth.ClusterCACertificate) == 0 {\r\n\t\treturn nil, errors.New(\"empty clusterCaCertificate\")\r\n\t}\r\n\tif len(d.Auth.ClientKey) == 0 {\r\n\t\treturn nil, errors.New(\"empty clientKey, consider running with --get-client-cert\")\r\n\t}\r\n\tif len(d.Auth.ClientCertificate) == 0 {\r\n\t\treturn nil, errors.New(\"empty clientCertificate, consider running with --get-client-cert\")\r\n\t}\r\n\treturn &d, nil\r\n}","code-length":471,"reference":"\/\/ describeCluster returns details from gcloud container clusters describe.","result":"Describe cluster.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ss *strslice) Set(value string) error {\r\n\t*ss = append(*ss, value)\r\n\treturn nil\r\n}","code-length":43,"reference":"\/\/ Set appends a value onto the strslice.","result":"Set the slice values.","score":[0.1398,0.1316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc parseXML(body []byte, object string) (*gcsDir, error) {\r\n\tdir := new(gcsDir)\r\n\tif err := xml.Unmarshal(body, &dir); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\t\r\n\tisDir := object == \"\/\" || len(dir.Contents)+len(dir.CommonPrefixes) > 0\r\n\tselfIndex := -1\r\n\tfor i := range dir.Contents {\r\n\t\trec := &dir.Contents[i]\r\n\t\tname := strings.TrimPrefix(rec.Name, object)\r\n\t\tif name == \"\" {\r\n\t\t\tselfIndex = i\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\trec.Name = name\r\n\t\tif strings.HasSuffix(name, \"\/\") {\r\n\t\t\trec.isDir = true\r\n\t\t}\r\n\t}\r\n\tfor i := range dir.CommonPrefixes {\r\n\t\tcp := &dir.CommonPrefixes[i]\r\n\t\tcp.Prefix = strings.TrimPrefix(cp.Prefix, object)\r\n\t}\r\n\tif !isDir {\r\n\t\treturn nil, nil\r\n\t}\r\n\tif selfIndex >= 0 {\r\n\t\t\r\n\t\tdir.Contents = append(dir.Contents[:selfIndex], dir.Contents[selfIndex+1:]...)\r\n\t}\r\n\treturn dir, nil\r\n}","code-length":343,"reference":"\/\/ parseXML extracts a gcsDir object from XML.  If this returns a nil gcsDir,\n\/\/ the XML indicated that this was not a directory at all.","result":"Parse XML file.","score":[0.0002,0.0211]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (dir *gcsDir) Render(out http.ResponseWriter, inPath string) {\r\n\thtmlPageHeader(out, dir.Name)\r\n\tif !strings.HasSuffix(inPath, \"\/\") {\r\n\t\tinPath += \"\/\"\r\n\t}\r\n\thtmlContentHeader(out, dir.Name, inPath)\r\n\tif dir.NextMarker != \"\" {\r\n\t\thtmlNextButton(out, gcsPath+inPath, dir.NextMarker)\r\n\t}\r\n\thtmlGridHeader(out)\r\n\tif parent := dirname(inPath); parent != \"\" {\r\n\t\turl := gcsPath + parent\r\n\t\thtmlGridItem(out, iconBack, url, \"..\", \"-\", \"-\")\r\n\t}\r\n\tfor i := range dir.CommonPrefixes {\r\n\t\tdir.CommonPrefixes[i].Render(out, inPath)\r\n\t}\r\n\tfor i := range dir.Contents {\r\n\t\tdir.Contents[i].Render(out, inPath)\r\n\t}\r\n\tif dir.NextMarker != \"\" {\r\n\t\thtmlNextButton(out, gcsPath+inPath, dir.NextMarker)\r\n\t}\r\n\thtmlContentFooter(out)\r\n\thtmlPageFooter(out)\r\n}","code-length":306,"reference":"\/\/ Render writes HTML representing this gcsDir to the provided output.","result":"Render the directory.","score":[0.0337,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (rec *Record) Render(out http.ResponseWriter, inPath string) {\r\n\tmtime := \"<unknown>\"\r\n\tts, err := time.Parse(time.RFC3339, rec.MTime)\r\n\tif err == nil {\r\n\t\tmtime = ts.Format(\"02 Jan 2006 15:04:05\")\r\n\t}\r\n\tvar url, size string\r\n\tif rec.isDir {\r\n\t\turl = gcsPath + inPath + rec.Name\r\n\t\tsize = \"-\"\r\n\t} else {\r\n\t\turl = gcsBaseURL + inPath + rec.Name\r\n\t\tsize = fmt.Sprintf(\"%v\", rec.Size)\r\n\t}\r\n\thtmlGridItem(out, iconFile, url, rec.Name, size, mtime)\r\n}","code-length":194,"reference":"\/\/ Render writes HTML representing this Record to the provided output.","result":"Render the record.","score":[0.0337,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (pfx *Prefix) Render(out http.ResponseWriter, inPath string) {\r\n\turl := gcsPath + inPath + pfx.Prefix\r\n\thtmlGridItem(out, iconDir, url, pfx.Prefix, \"-\", \"-\")\r\n}","code-length":68,"reference":"\/\/ Render writes HTML representing this Prefix to the provided output.","result":"Render the prefix.","score":[0.0337,0.098]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (tl txnLogger) Printf(fmt string, args ...interface{}) {\r\n\targs = append([]interface{}{tl.nonce}, args...)\r\n\tlog.Printf(\"[txn-%s] \"+fmt, args...)\r\n}","code-length":63,"reference":"\/\/ Printf logs a formatted line to the logging output.","result":"Print to the console.","score":[0.1008,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(instances map[string][]string) (*Client, error) {\r\n\tc := &Client{\r\n\t\thandlers: map[string]*gerritInstanceHandler{},\r\n\t}\r\n\tfor instance := range instances {\r\n\t\tgc, err := gerrit.NewClient(instance, nil)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tc.handlers[instance] = &gerritInstanceHandler{\r\n\t\t\tinstance:       instance,\r\n\t\t\tprojects:       instances[instance],\r\n\t\t\tauthService:    gc.Authentication,\r\n\t\t\taccountService: gc.Accounts,\r\n\t\t\tchangeService:  gc.Changes,\r\n\t\t\tprojectService: gc.Projects,\r\n\t\t}\r\n\t}\r\n\treturn c, nil\r\n}","code-length":205,"reference":"\/\/ NewClient returns a new gerrit client","result":"Create a new client .","score":[0.2521,0.3758]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) SetReview(instance, id, revision, message string, labels map[string]string) error {\r\n\th, ok := c.handlers[instance]\r\n\tif !ok {\r\n\t\treturn fmt.Errorf(\"not activated gerrit instance: %s\", instance)\r\n\t}\r\n\tif _, _, err := h.changeService.SetReview(id, revision, &gerrit.ReviewInput{\r\n\t\tMessage: message,\r\n\t\tLabels:  labels,\r\n\t}); err != nil {\r\n\t\treturn fmt.Errorf(\"cannot comment to gerrit: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":166,"reference":"\/\/ SetReview writes a review comment base on the change id + revision","result":"Comment to gerrit instance.","score":[0,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) GetBranchRevision(instance, project, branch string) (string, error) {\r\n\th, ok := c.handlers[instance]\r\n\tif !ok {\r\n\t\treturn \"\", fmt.Errorf(\"not activated gerrit instance: %s\", instance)\r\n\t}\r\n\tres, _, err := h.projectService.GetBranch(project, branch)\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn res.Revision, nil\r\n}","code-length":129,"reference":"\/\/ GetBranchRevision returns SHA of HEAD of a branch","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (h *gerritInstanceHandler) queryAllChanges(lastUpdate time.Time, rateLimit int) []gerrit.ChangeInfo {\r\n\tresult := []gerrit.ChangeInfo{}\r\n\tfor _, project := range h.projects {\r\n\t\tchanges, err := h.queryChangesForProject(project, lastUpdate, rateLimit)\r\n\t\tif err != nil {\r\n\t\t\t\r\n\t\t\tlogrus.WithError(err).Errorf(\"fail to query changes for project %s\", project)\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tresult = append(result, changes...)\r\n\t}\r\n\treturn result\r\n}","code-length":157,"reference":"\/\/ private handler implementation details","result":"Query all changes for all projects.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewTypeFilterWrapperPlugin(plugin Plugin) *TypeFilterWrapperPlugin {\r\n\treturn &TypeFilterWrapperPlugin{\r\n\t\tplugin: plugin,\r\n\t\tpass:   map[string]bool{},\r\n\t}\r\n}","code-length":64,"reference":"\/\/ NewTypeFilterWrapperPlugin is the constructor of TypeFilterWrapperPlugin","result":"Wrap plugin types.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *TypeFilterWrapperPlugin) AddFlags(cmd *cobra.Command) {\r\n\tcmd.Flags().BoolVar(&t.pullRequests, \"no-pull-requests\", false, \"Ignore pull-requests\")\r\n\tcmd.Flags().BoolVar(&t.issues, \"no-issues\", false, \"Ignore issues\")\r\n}","code-length":90,"reference":"\/\/ AddFlags adds \"no-pull-requests\" and \"no-issues\" to the command help","result":"Add flags.","score":[0,0.0543]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (t *TypeFilterWrapperPlugin) CheckFlags() error {\r\n\tif t.pullRequests && t.issues {\r\n\t\treturn fmt.Errorf(\r\n\t\t\t\"you can't ignore both pull-requests and issues\")\r\n\t}\r\n\treturn nil\r\n}","code-length":73,"reference":"\/\/ CheckFlags makes sure not both PR and issues are ignored","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *KubernetesClientOptions) AddFlags(fs *flag.FlagSet) {\r\n\tfs.StringVar(&o.namespace, \"namespace\", v1.NamespaceDefault, \"namespace to install on\")\r\n\tfs.StringVar(&o.kubeConfig, \"kubeconfig\", \"\", \"absolute path to the kubeConfig file\")\r\n\tfs.BoolVar(&o.inMemory, \"in_memory\", false, \"Use in memory client instead of CRD\")\r\n}","code-length":120,"reference":"\/\/ AddFlags adds kube client flags to existing FlagSet.","result":"Add flags to the client.","score":[0.1527,0.2972]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *KubernetesClientOptions) Validate() error {\r\n\tif o.kubeConfig != \"\" {\r\n\t\tif _, err := os.Stat(o.kubeConfig); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":80,"reference":"\/\/ Validate validates Kubernetes client options.","result":"Validate the generated code.","score":[0.1938,0.0862]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *KubernetesClientOptions) Client(t Type) (ClientInterface, error) {\r\n\tif o.inMemory {\r\n\t\treturn newDummyClient(t), nil\r\n\t}\r\n\treturn o.newCRDClient(t)\r\n}","code-length":71,"reference":"\/\/ Client returns a ClientInterface based on the flags provided.","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o *KubernetesClientOptions) newCRDClient(t Type) (*Client, error) {\r\n\tconfig, scheme, err := createRESTConfig(o.kubeConfig, t)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err = registerResource(config, t); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tvar restClient *rest.RESTClient\r\n\trestClient, err = rest.RESTClientFor(config)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\trc := Client{cl: restClient, ns: o.namespace, t: t,\r\n\t\tcodec: runtime.NewParameterCodec(scheme)}\r\n\treturn &rc, nil\r\n}","code-length":198,"reference":"\/\/ newClientFromFlags creates a CRD rest client from provided flags.","result":"Create a new CRDClient.","score":[0.0713,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc createRESTConfig(kubeconfig string, t Type) (config *rest.Config, types *runtime.Scheme, err error) {\r\n\tif kubeconfig == \"\" {\r\n\t\tconfig, err = rest.InClusterConfig()\r\n\t} else {\r\n\t\tconfig, err = clientcmd.BuildConfigFromFlags(\"\", kubeconfig)\r\n\t}\r\n\tif err != nil {\r\n\t\treturn\r\n\t}\r\n\tversion := schema.GroupVersion{\r\n\t\tGroup:   group,\r\n\t\tVersion: version,\r\n\t}\r\n\tconfig.GroupVersion = &version\r\n\tconfig.APIPath = \"\/apis\"\r\n\tconfig.ContentType = runtime.ContentTypeJSON\r\n\ttypes = runtime.NewScheme()\r\n\tschemeBuilder := runtime.NewSchemeBuilder(\r\n\t\tfunc(scheme *runtime.Scheme) error {\r\n\t\t\tscheme.AddKnownTypes(version, t.Object, t.Collection)\r\n\t\t\tv1.AddToGroupVersion(scheme, version)\r\n\t\t\treturn nil\r\n\t\t})\r\n\terr = schemeBuilder.AddToScheme(types)\r\n\tconfig.NegotiatedSerializer = serializer.DirectCodecFactory{CodecFactory: serializer.NewCodecFactory(types)}\r\n\treturn\r\n}","code-length":295,"reference":"\/\/ createRESTConfig for cluster API server, pass empty config file for in-cluster","result":"Create a new rest config.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc registerResource(config *rest.Config, t Type) error {\r\n\tc, err := apiextensionsclient.NewForConfig(config)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tcrd := &apiextensionsv1beta1.CustomResourceDefinition{\r\n\t\tObjectMeta: v1.ObjectMeta{\r\n\t\t\tName: fmt.Sprintf(\"%s.%s\", t.Plural, group),\r\n\t\t},\r\n\t\tSpec: apiextensionsv1beta1.CustomResourceDefinitionSpec{\r\n\t\t\tGroup:   group,\r\n\t\t\tVersion: version,\r\n\t\t\tScope:   apiextensionsv1beta1.NamespaceScoped,\r\n\t\t\tNames: apiextensionsv1beta1.CustomResourceDefinitionNames{\r\n\t\t\t\tSingular: t.Singular,\r\n\t\t\t\tPlural:   t.Plural,\r\n\t\t\t\tKind:     t.Kind,\r\n\t\t\t\tListKind: t.ListKind,\r\n\t\t\t},\r\n\t\t},\r\n\t}\r\n\tif _, err := c.ApiextensionsV1beta1().CustomResourceDefinitions().Create(crd); err != nil && !apierrors.IsAlreadyExists(err) {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":299,"reference":"\/\/ registerResource sends a request to create CRDs and waits for them to initialize","result":"Register a resource.","score":[0.0104,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newDummyClient(t Type) *dummyClient {\r\n\tc := &dummyClient{\r\n\t\tt:       t,\r\n\t\tobjects: make(map[string]Object),\r\n\t}\r\n\treturn c\r\n}","code-length":65,"reference":"\/\/ newDummyClient creates a in memory client representation for testing, such that we do not need to use a kubernetes API Server.","result":"Create a new client.","score":[0.0035,0.0495]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *dummyClient) Update(obj Object) (Object, error) {\r\n\t_, ok := c.objects[obj.GetName()]\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"cannot find object %s\", obj.GetName())\r\n\t}\r\n\tc.objects[obj.GetName()] = obj\r\n\treturn obj, nil\r\n}","code-length":102,"reference":"\/\/ Update implements ClientInterface","result":"Update the object in the client.","score":[0.193,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc TrustedPullRequest(ghc githubClient, trigger plugins.Trigger, author, org, repo string, num int, l []github.Label) ([]github.Label, bool, error) {\r\n\t\r\n\tif orgMember, err := TrustedUser(ghc, trigger, author, org, repo); err != nil {\r\n\t\treturn l, false, fmt.Errorf(\"error checking %s for trust: %v\", author, err)\r\n\t} else if orgMember {\r\n\t\treturn l, true, nil\r\n\t}\r\n\t\r\n\tif l == nil {\r\n\t\tvar err error\r\n\t\tl, err = ghc.GetIssueLabels(org, repo, num)\r\n\t\tif err != nil {\r\n\t\t\treturn l, false, err\r\n\t\t}\r\n\t}\r\n\treturn l, github.HasLabel(labels.OkToTest, l), nil\r\n}","code-length":220,"reference":"\/\/ TrustedPullRequest returns whether or not the given PR should be tested.\n\/\/ It first checks if the author is in the org, then looks for \"ok-to-test\" label.","result":"Check if the PR is already trusted.","score":[0.0135,0.1436]}
{"code":"\/*is used to<extra_id_0>\r\nfunc buildAll(c Client, pr *github.PullRequest, eventGUID string, elideSkippedContexts bool) error {\r\n\torg, repo, number, branch := pr.Base.Repo.Owner.Login, pr.Base.Repo.Name, pr.Number, pr.Base.Ref\r\n\tchanges := config.NewGitHubDeferredChangedFilesProvider(c.GitHubClient, org, repo, number)\r\n\ttoTest, toSkipSuperset, err := pjutil.FilterPresubmits(pjutil.TestAllFilter(), changes, branch, c.Config.Presubmits[pr.Base.Repo.FullName], c.Logger)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\ttoSkip := determineSkippedPresubmits(toTest, toSkipSuperset, c.Logger)\r\n\treturn runAndSkipJobs(c, pr, toTest, toSkip, eventGUID, elideSkippedContexts)\r\n}","code-length":223,"reference":"\/\/ buildAll ensures that all builds that should run and will be required are built","result":"Build all jobs.","score":[0.0075,0.0725]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Options) Run(ctx context.Context) (int, error) {\r\n\tspec, err := downwardapi.ResolveSpecFromEnv()\r\n\tif err != nil {\r\n\t\treturn 0, fmt.Errorf(\"could not resolve job spec: %v\", err)\r\n\t}\r\n\tctx, cancel := context.WithCancel(ctx)\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tinterrupt := make(chan os.Signal)\r\n\tsignal.Notify(interrupt, os.Interrupt, syscall.SIGTERM)\r\n\tgo func() {\r\n\t\tselect {\r\n\t\tcase s := <-interrupt:\r\n\t\t\tlogrus.Errorf(\"Received an interrupt: %s, cancelling...\", s)\r\n\t\t\tcancel()\r\n\t\tcase <-ctx.Done():\r\n\t\t}\r\n\t}()\r\n\tif o.DeprecatedWrapperOptions != nil {\r\n\t\t\r\n\t\tlogrus.Warnf(\"Using deprecated wrapper_options instead of entries. Please update prow\/pod-utils\/decorate before June 2019\")\r\n\t}\r\n\tentries := o.entries()\r\n\tpassed, aborted, failures := wait(ctx, entries)\r\n\tcancel()\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tsignal.Ignore(os.Interrupt, syscall.SIGTERM)\r\n\tbuildLog := logReader(entries)\r\n\tmetadata := combineMetadata(entries)\r\n\treturn failures, o.doUpload(spec, passed, aborted, metadata, buildLog)\r\n}","code-length":371,"reference":"\/\/ Run will watch for the process being wrapped to exit\n\/\/ and then post the status of that process and any artifacts\n\/\/ to cloud storage.","result":"Run the job .","score":[0.0012,0.0405]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) AddConfig(conf common.ResourcesConfig) error {\r\n\treturn s.configs.Add(conf)\r\n}","code-length":41,"reference":"\/\/ AddConfig adds a new config","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) DeleteConfig(name string) error {\r\n\treturn s.configs.Delete(name)\r\n}","code-length":38,"reference":"\/\/ DeleteConfig deletes an existing config if it exists or fail otherwise","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) UpdateConfig(conf common.ResourcesConfig) error {\r\n\treturn s.configs.Update(conf)\r\n}","code-length":41,"reference":"\/\/ UpdateConfig updates a given if it exists or fail otherwise","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) GetConfig(name string) (common.ResourcesConfig, error) {\r\n\ti, err := s.configs.Get(name)\r\n\tif err != nil {\r\n\t\treturn common.ResourcesConfig{}, err\r\n\t}\r\n\tvar conf common.ResourcesConfig\r\n\tconf, err = common.ItemToResourcesConfig(i)\r\n\tif err != nil {\r\n\t\treturn common.ResourcesConfig{}, err\r\n\t}\r\n\treturn conf, nil\r\n}","code-length":127,"reference":"\/\/ GetConfig returns an existing if it exists errors out otherwise","result":"Avoid the need for the function to be executed.","score":[0,0.0463]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) GetConfigs() ([]common.ResourcesConfig, error) {\r\n\tvar configs []common.ResourcesConfig\r\n\titems, err := s.configs.List()\r\n\tif err != nil {\r\n\t\treturn configs, err\r\n\t}\r\n\tfor _, i := range items {\r\n\t\tvar conf common.ResourcesConfig\r\n\t\tconf, err = common.ItemToResourcesConfig(i)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tconfigs = append(configs, conf)\r\n\t}\r\n\treturn configs, nil\r\n}","code-length":157,"reference":"\/\/ GetConfigs returns all configs","result":"Get all the configs from the storage.","score":[0.1921,0.1923]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Storage) SyncConfigs(newConfigs []common.ResourcesConfig) error {\r\n\ts.configsLock.Lock()\r\n\tdefer s.configsLock.Unlock()\r\n\tcurrentConfigs, err := s.GetConfigs()\r\n\tif err != nil {\r\n\t\tlogrus.WithError(err).Error(\"cannot find configs\")\r\n\t\treturn err\r\n\t}\r\n\tcurrentSet := mapset.NewSet()\r\n\tnewSet := mapset.NewSet()\r\n\ttoUpdate := mapset.NewSet()\r\n\tconfigs := map[string]common.ResourcesConfig{}\r\n\tfor _, c := range currentConfigs {\r\n\t\tcurrentSet.Add(c.Name)\r\n\t\tconfigs[c.Name] = c\r\n\t}\r\n\tfor _, c := range newConfigs {\r\n\t\tnewSet.Add(c.Name)\r\n\t\tif old, exists := configs[c.Name]; exists {\r\n\t\t\tif !reflect.DeepEqual(old, c) {\r\n\t\t\t\ttoUpdate.Add(c.Name)\r\n\t\t\t\tconfigs[c.Name] = c\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\tconfigs[c.Name] = c\r\n\t\t}\r\n\t}\r\n\tvar finalError error\r\n\ttoDelete := currentSet.Difference(newSet)\r\n\ttoAdd := newSet.Difference(currentSet)\r\n\tfor _, n := range toDelete.ToSlice() {\r\n\t\tlogrus.Infof(\"Deleting config %s\", n.(string))\r\n\t\tif err := s.DeleteConfig(n.(string)); err != nil {\r\n\t\t\tlogrus.WithError(err).Errorf(\"failed to delete config %s\", n)\r\n\t\t\tfinalError = multierror.Append(finalError, err)\r\n\t\t}\r\n\t}\r\n\tfor _, n := range toAdd.ToSlice() {\r\n\t\trc := configs[n.(string)]\r\n\t\tlogrus.Infof(\"Adding config %s\", n.(string))\r\n\t\tif err := s.AddConfig(rc); err != nil {\r\n\t\t\tlogrus.WithError(err).Errorf(\"failed to create resources %s\", n)\r\n\t\t\tfinalError = multierror.Append(finalError, err)\r\n\t\t}\r\n\t}\r\n\tfor _, n := range toUpdate.ToSlice() {\r\n\t\trc := configs[n.(string)]\r\n\t\tlogrus.Infof(\"Updating config %s\", n.(string))\r\n\t\tif err := s.UpdateConfig(rc); err != nil {\r\n\t\t\tlogrus.WithError(err).Errorf(\"failed to update resources %s\", n)\r\n\t\t\tfinalError = multierror.Append(finalError, err)\r\n\t\t}\r\n\t}\r\n\treturn finalError\r\n}","code-length":680,"reference":"\/\/ SyncConfigs syncs new configs","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc addKnownTypes(scheme *runtime.Scheme) error {\r\n\tscheme.AddKnownTypes(SchemeGroupVersion,\r\n\t\t&ProwJob{},\r\n\t\t&ProwJobList{},\r\n\t)\r\n\tmetav1.AddToGroupVersion(scheme, SchemeGroupVersion)\r\n\treturn nil\r\n}","code-length":83,"reference":"\/\/ Adds the list of known types to the Scheme.","result":"Add custom types to the scheme.","score":[0.2042,0.5042]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewController(continueOnError bool, addedPresubmitBlacklist sets.String, prowJobClient prowv1.ProwJobInterface, githubClient *github.Client, configAgent *config.Agent, pluginAgent *plugins.ConfigAgent) *Controller {\r\n\treturn &Controller{\r\n\t\tcontinueOnError:         continueOnError,\r\n\t\taddedPresubmitBlacklist: addedPresubmitBlacklist,\r\n\t\tprowJobTriggerer: &kubeProwJobTriggerer{\r\n\t\t\tprowJobClient: prowJobClient,\r\n\t\t\tgithubClient:  githubClient,\r\n\t\t\tconfigAgent:   configAgent,\r\n\t\t},\r\n\t\tgithubClient: githubClient,\r\n\t\tstatusMigrator: &gitHubMigrator{\r\n\t\t\tgithubClient:    githubClient,\r\n\t\t\tcontinueOnError: continueOnError,\r\n\t\t},\r\n\t\ttrustedChecker: &githubTrustedChecker{\r\n\t\t\tgithubClient: githubClient,\r\n\t\t\tpluginAgent:  pluginAgent,\r\n\t\t},\r\n\t}\r\n}","code-length":253,"reference":"\/\/ NewController constructs a new controller to reconcile stauses on config change","result":"Create a new controller.","score":[0.0611,0.1674]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) Run(stop <-chan os.Signal, changes <-chan config.Delta) {\r\n\tfor {\r\n\t\tselect {\r\n\t\tcase change := <-changes:\r\n\t\t\tstart := time.Now()\r\n\t\t\tif err := c.reconcile(change); err != nil {\r\n\t\t\t\tlogrus.WithError(err).Error(\"Error reconciling statuses.\")\r\n\t\t\t}\r\n\t\t\tlogrus.WithField(\"duration\", fmt.Sprintf(\"%v\", time.Since(start))).Info(\"Statuses reconciled\")\r\n\t\tcase <-stop:\r\n\t\t\tlogrus.Info(\"status-reconciler is shutting down...\")\r\n\t\t\treturn\r\n\t\t}\r\n\t}\r\n}","code-length":182,"reference":"\/\/ Run monitors the incoming configuration changes to determine when statuses need to be\n\/\/ reconciled on PRs in flight when blocking presubmits change","result":"Generate code for the generated code.","score":[0.0096,0.0225]}
{"code":"\/*is used to<extra_id_0>\r\nfunc addedBlockingPresubmits(old, new map[string][]config.Presubmit) map[string][]config.Presubmit {\r\n\tadded := map[string][]config.Presubmit{}\r\n\tfor repo, oldPresubmits := range old {\r\n\t\tadded[repo] = []config.Presubmit{}\r\n\t\tfor _, newPresubmit := range new[repo] {\r\n\t\t\tif !newPresubmit.ContextRequired() || newPresubmit.NeedsExplicitTrigger() {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tvar found bool\r\n\t\t\tfor _, oldPresubmit := range oldPresubmits {\r\n\t\t\t\tif oldPresubmit.Name == newPresubmit.Name {\r\n\t\t\t\t\tif oldPresubmit.SkipReport && !newPresubmit.SkipReport {\r\n\t\t\t\t\t\tadded[repo] = append(added[repo], newPresubmit)\r\n\t\t\t\t\t\tlogrus.WithFields(logrus.Fields{\r\n\t\t\t\t\t\t\t\"repo\": repo,\r\n\t\t\t\t\t\t\t\"name\": oldPresubmit.Name,\r\n\t\t\t\t\t\t}).Debug(\"Identified a newly-reporting blocking presubmit.\")\r\n\t\t\t\t\t}\r\n\t\t\t\t\tif oldPresubmit.RunIfChanged != newPresubmit.RunIfChanged {\r\n\t\t\t\t\t\tadded[repo] = append(added[repo], newPresubmit)\r\n\t\t\t\t\t\tlogrus.WithFields(logrus.Fields{\r\n\t\t\t\t\t\t\t\"repo\": repo,\r\n\t\t\t\t\t\t\t\"name\": oldPresubmit.Name,\r\n\t\t\t\t\t\t}).Debug(\"Identified a blocking presubmit running over a different set of files.\")\r\n\t\t\t\t\t}\r\n\t\t\t\t\tfound = true\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tif !found {\r\n\t\t\t\tadded[repo] = append(added[repo], newPresubmit)\r\n\t\t\t\tlogrus.WithFields(logrus.Fields{\r\n\t\t\t\t\t\"repo\": repo,\r\n\t\t\t\t\t\"name\": newPresubmit.Name,\r\n\t\t\t\t}).Debug(\"Identified an added blocking presubmit.\")\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tvar numAdded int\r\n\tfor _, presubmits := range added {\r\n\t\tnumAdded += len(presubmits)\r\n\t}\r\n\tlogrus.Infof(\"Identified %d added blocking presubmits.\", numAdded)\r\n\treturn added\r\n}","code-length":591,"reference":"\/\/ addedBlockingPresubmits determines new blocking presubmits based on a\n\/\/ config update. New blocking presubmits are either brand-new presubmits\n\/\/ or extant presubmits that are now reporting. Previous presubmits that\n\/\/ reported but were optional that are no longer optional require no action\n\/\/ as their contexts will already exist on PRs.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc removedBlockingPresubmits(old, new map[string][]config.Presubmit) map[string][]config.Presubmit {\r\n\tremoved := map[string][]config.Presubmit{}\r\n\tfor repo, oldPresubmits := range old {\r\n\t\tremoved[repo] = []config.Presubmit{}\r\n\t\tfor _, oldPresubmit := range oldPresubmits {\r\n\t\t\tif !oldPresubmit.ContextRequired() {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tvar found bool\r\n\t\t\tfor _, newPresubmit := range new[repo] {\r\n\t\t\t\tif oldPresubmit.Name == newPresubmit.Name {\r\n\t\t\t\t\tfound = true\r\n\t\t\t\t\tbreak\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tif !found {\r\n\t\t\t\tremoved[repo] = append(removed[repo], oldPresubmit)\r\n\t\t\t\tlogrus.WithFields(logrus.Fields{\r\n\t\t\t\t\t\"repo\": repo,\r\n\t\t\t\t\t\"name\": oldPresubmit.Name,\r\n\t\t\t\t}).Debug(\"Identified a removed blocking presubmit.\")\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tvar numRemoved int\r\n\tfor _, presubmits := range removed {\r\n\t\tnumRemoved += len(presubmits)\r\n\t}\r\n\tlogrus.Infof(\"Identified %d removed blocking presubmits.\", numRemoved)\r\n\treturn removed\r\n}","code-length":362,"reference":"\/\/ removedBlockingPresubmits determines stale blocking presubmits based on a\n\/\/ config update. Presubmits that are no longer blocking due to no longer\n\/\/ reporting or being optional require no action as Tide will honor those\n\/\/ statuses correctly.","result":"Identify removed blocking presubmits.","score":[0.0001,0.0145]}
{"code":"\/*is used to<extra_id_0>\r\nfunc migratedBlockingPresubmits(old, new map[string][]config.Presubmit) map[string][]presubmitMigration {\r\n\tmigrated := map[string][]presubmitMigration{}\r\n\tfor repo, oldPresubmits := range old {\r\n\t\tmigrated[repo] = []presubmitMigration{}\r\n\t\tfor _, newPresubmit := range new[repo] {\r\n\t\t\tif !newPresubmit.ContextRequired() {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\tfor _, oldPresubmit := range oldPresubmits {\r\n\t\t\t\tif oldPresubmit.Context != newPresubmit.Context && oldPresubmit.Name == newPresubmit.Name {\r\n\t\t\t\t\tmigrated[repo] = append(migrated[repo], presubmitMigration{from: oldPresubmit, to: newPresubmit})\r\n\t\t\t\t\tlogrus.WithFields(logrus.Fields{\r\n\t\t\t\t\t\t\"repo\": repo,\r\n\t\t\t\t\t\t\"name\": oldPresubmit.Name,\r\n\t\t\t\t\t\t\"from\": oldPresubmit.Context,\r\n\t\t\t\t\t\t\"to\":   newPresubmit.Context,\r\n\t\t\t\t\t}).Debug(\"Identified a migrated blocking presubmit.\")\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tvar numMigrated int\r\n\tfor _, presubmits := range migrated {\r\n\t\tnumMigrated += len(presubmits)\r\n\t}\r\n\tlogrus.Infof(\"Identified %d migrated blocking presubmits.\", numMigrated)\r\n\treturn migrated\r\n}","code-length":395,"reference":"\/\/ migratedBlockingPresubmits determines blocking presubmits that have had\n\/\/ their status contexts migrated. This is a best-effort evaluation as we\n\/\/ can only track a presubmit between configuration versions by its name.\n\/\/ A presubmit \"migration\" that had its underlying job and context changed\n\/\/ will be treated as a deletion and creation.","result":"Identify the migrated blocking presubmits.","score":[0.0,0.0104]}
{"code":"\/*is used to<extra_id_0>\r\nfunc Load(loader OptionLoader) error {\r\n\tif jsonConfig, provided := os.LookupEnv(loader.ConfigVar()); provided {\r\n\t\tif err := loader.LoadConfig(jsonConfig); err != nil {\r\n\t\t\treturn fmt.Errorf(\"could not load config from JSON var %s: %v\", loader.ConfigVar(), err)\r\n\t\t}\r\n\t\treturn nil\r\n\t}\r\n\tfs := flag.NewFlagSet(os.Args[0], flag.ExitOnError)\r\n\tloader.AddFlags(fs)\r\n\tfs.Parse(os.Args[1:])\r\n\tloader.Complete(fs.Args())\r\n\treturn nil\r\n}","code-length":167,"reference":"\/\/ Load loads the set of options, preferring to use\n\/\/ JSON config from an env var, but falling back to\n\/\/ command line flags if not possible.","result":"Load options from JSON env vars.","score":[0.007,0.0775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) canExecuteConcurrently(pj *prowapi.ProwJob) bool {\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tif max := c.config().MaxConcurrency; max > 0 {\r\n\t\tvar running int\r\n\t\tfor _, num := range c.pendingJobs {\r\n\t\t\trunning += num\r\n\t\t}\r\n\t\tif running >= max {\r\n\t\t\tc.log.WithFields(pjutil.ProwJobFields(pj)).Debugf(\"Not starting another job, already %d running.\", running)\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\tif pj.Spec.MaxConcurrency == 0 {\r\n\t\tc.pendingJobs[pj.Spec.Job]++\r\n\t\treturn true\r\n\t}\r\n\tnumPending := c.pendingJobs[pj.Spec.Job]\r\n\tif numPending >= pj.Spec.MaxConcurrency {\r\n\t\tc.log.WithFields(pjutil.ProwJobFields(pj)).Debugf(\"Not starting another instance of %s, already %d running.\", pj.Spec.Job, numPending)\r\n\t\treturn false\r\n\t}\r\n\tc.pendingJobs[pj.Spec.Job]++\r\n\treturn true\r\n}","code-length":324,"reference":"\/\/ canExecuteConcurrently checks whether the provided ProwJob can\n\/\/ be executed concurrently.","result":"Prevent infinite loops.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getJenkinsJobs(pjs []prowapi.ProwJob) []BuildQueryParams {\r\n\tjenkinsJobs := []BuildQueryParams{}\r\n\tfor _, pj := range pjs {\r\n\t\tif pj.Complete() {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tjenkinsJobs = append(jenkinsJobs, BuildQueryParams{\r\n\t\t\tJobName:   getJobName(&pj.Spec),\r\n\t\t\tProwJobID: pj.Name,\r\n\t\t})\r\n\t}\r\n\treturn jenkinsJobs\r\n}","code-length":140,"reference":"\/\/ getJenkinsJobs returns all the Jenkins jobs for all active\n\/\/ prowjobs from the provided list. It handles deduplication.","result":"Get the Jenkins jobs from the API.","score":[0.0731,0.2719]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Controller) terminateDupes(pjs []prowapi.ProwJob, jbs map[string]Build) error {\r\n\t\r\n\tdupes := make(map[string]int)\r\n\tfor i, pj := range pjs {\r\n\t\tif pj.Complete() || pj.Spec.Type != prowapi.PresubmitJob {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tn := fmt.Sprintf(\"%s %s\/%s#%d\", pj.Spec.Job, pj.Spec.Refs.Org, pj.Spec.Refs.Repo, pj.Spec.Refs.Pulls[0].Number)\r\n\t\tprev, ok := dupes[n]\r\n\t\tif !ok {\r\n\t\t\tdupes[n] = i\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tcancelIndex := i\r\n\t\tif (&pjs[prev].Status.StartTime).Before(&pj.Status.StartTime) {\r\n\t\t\tcancelIndex = prev\r\n\t\t\tdupes[n] = i\r\n\t\t}\r\n\t\ttoCancel := pjs[cancelIndex]\r\n\t\t\r\n\t\t\r\n\t\tif c.config().AllowCancellations {\r\n\t\t\tbuild, buildExists := jbs[toCancel.ObjectMeta.Name]\r\n\t\t\t\r\n\t\t\tif buildExists && build.IsEnqueued() {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif buildExists {\r\n\t\t\t\tif err := c.jc.Abort(getJobName(&toCancel.Spec), &build); err != nil {\r\n\t\t\t\t\tc.log.WithError(err).WithFields(pjutil.ProwJobFields(&toCancel)).Warn(\"Cannot cancel Jenkins build\")\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\ttoCancel.SetComplete()\r\n\t\tprevState := toCancel.Status.State\r\n\t\ttoCancel.Status.State = prowapi.AbortedState\r\n\t\tc.log.WithFields(pjutil.ProwJobFields(&toCancel)).\r\n\t\t\tWithField(\"from\", prevState).\r\n\t\t\tWithField(\"to\", toCancel.Status.State).Info(\"Transitioning states.\")\r\n\t\tnpj, err := c.prowJobClient.Update(&toCancel)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tpjs[cancelIndex] = *npj\r\n\t}\r\n\treturn nil\r\n}","code-length":608,"reference":"\/\/ terminateDupes aborts presubmits that have a newer version. It modifies pjs\n\/\/ in-place when it aborts.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) Throttle(hourlyTokens, burst int) {\r\n\tc.log(\"Throttle\", hourlyTokens, burst)\r\n\tc.throttle.lock.Lock()\r\n\tdefer c.throttle.lock.Unlock()\r\n\tpreviouslyThrottled := c.throttle.ticker != nil\r\n\tif hourlyTokens <= 0 || burst <= 0 {\r\n\t\tif previouslyThrottled {\r\n\t\t\tc.client = c.throttle.http\r\n\t\t\tc.gqlc = c.throttle.graph\r\n\t\t\tc.throttle.ticker.Stop()\r\n\t\t\tc.throttle.ticker = nil\r\n\t\t}\r\n\t\treturn\r\n\t}\r\n\trate := time.Hour \/ time.Duration(hourlyTokens)\r\n\tticker := time.NewTicker(rate)\r\n\tthrottle := make(chan time.Time, burst)\r\n\tfor i := 0; i < burst; i++ {\r\n\t\tthrottle <- time.Now()\r\n\t}\r\n\tgo func() {\r\n\t\t\r\n\t\tfor t := range ticker.C {\r\n\t\t\tselect {\r\n\t\t\tcase throttle <- t:\r\n\t\t\tdefault:\r\n\t\t\t}\r\n\t\t}\r\n\t}()\r\n\tif !previouslyThrottled {\r\n\t\tc.throttle.http = c.client\r\n\t\tc.throttle.graph = c.gqlc\r\n\t\tc.client = &c.throttle\r\n\t\tc.gqlc = &c.throttle\r\n\t}\r\n\tc.throttle.ticker = ticker\r\n\tc.throttle.throttle = throttle\r\n}","code-length":407,"reference":"\/\/ Throttle client to a rate of at most hourlyTokens requests per hour,\n\/\/ allowing burst tokens.","result":"Set up the throttle function.","score":[0,0.0316]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClientWithFields(fields logrus.Fields, getToken func() []byte, graphqlEndpoint string, bases ...string) *Client {\r\n\treturn &Client{\r\n\t\tlogger: logrus.WithFields(fields).WithField(\"client\", \"github\"),\r\n\t\ttime:   &standardTime{},\r\n\t\tgqlc: githubql.NewEnterpriseClient(\r\n\t\t\tgraphqlEndpoint,\r\n\t\t\t&http.Client{\r\n\t\t\t\tTimeout:   maxRequestTime,\r\n\t\t\t\tTransport: &oauth2.Transport{Source: newReloadingTokenSource(getToken)},\r\n\t\t\t}),\r\n\t\tclient:   &http.Client{Timeout: maxRequestTime},\r\n\t\tbases:    bases,\r\n\t\tgetToken: getToken,\r\n\t\tdry:      false,\r\n\t}\r\n}","code-length":202,"reference":"\/\/ NewClientWithFields creates a new fully operational GitHub client. With\n\/\/ added logging fields.\n\/\/ 'getToken' is a generator for the GitHub access token to use.\n\/\/ 'bases' is a variadic slice of endpoints to use in order of preference.\n\/\/   An endpoint is used when all preceding endpoints have returned a conn err.\n\/\/   This should be used when using the ghproxy GitHub proxy cache to allow\n\/\/   this client to bypass the cache if it is temporarily unavailable.","result":"Create a new client with fields.","score":[0.0,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(getToken func() []byte, graphqlEndpoint string, bases ...string) *Client {\r\n\treturn NewClientWithFields(logrus.Fields{}, getToken, graphqlEndpoint, bases...)\r\n}","code-length":54,"reference":"\/\/ NewClient creates a new fully operational GitHub client.","result":"Generate the client code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewDryRunClient(getToken func() []byte, graphqlEndpoint string, bases ...string) *Client {\r\n\treturn NewDryRunClientWithFields(logrus.Fields{}, getToken, graphqlEndpoint, bases...)\r\n}","code-length":58,"reference":"\/\/ NewDryRunClient creates a new client that will not perform mutating actions\n\/\/ such as setting statuses or commenting, but it will still query GitHub and\n\/\/ use up API tokens.\n\/\/ 'getToken' is a generator the GitHub access token to use.\n\/\/ 'bases' is a variadic slice of endpoints to use in order of preference.\n\/\/   An endpoint is used when all preceding endpoints have returned a conn err.\n\/\/   This should be used when using the ghproxy GitHub proxy cache to allow\n\/\/   this client to bypass the cache if it is temporarily unavailable.","result":"GraphqlEndpoint string.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewFakeClient() *Client {\r\n\treturn &Client{\r\n\t\tlogger: logrus.WithField(\"client\", \"github\"),\r\n\t\ttime:   &standardTime{},\r\n\t\tfake:   true,\r\n\t\tdry:    true,\r\n\t}\r\n}","code-length":78,"reference":"\/\/ NewFakeClient creates a new client that will not perform any actions at all.","result":"Create a new client.","score":[0.0371,0.2265]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) request(r *request, ret interface{}) (int, error) {\r\n\tstatusCode, b, err := c.requestRaw(r)\r\n\tif err != nil {\r\n\t\treturn statusCode, err\r\n\t}\r\n\tif ret != nil {\r\n\t\tif err := json.Unmarshal(b, ret); err != nil {\r\n\t\t\treturn statusCode, err\r\n\t\t}\r\n\t}\r\n\treturn statusCode, nil\r\n}","code-length":121,"reference":"\/\/ Make a request with retries. If ret is not nil, unmarshal the response body\n\/\/ into it. Returns an error if the exit code is not one of the provided codes.","result":"Call the client to send a request.","score":[0.0054,0.0339]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) requestRaw(r *request) (int, []byte, error) {\r\n\tif c.fake || (c.dry && r.method != http.MethodGet) {\r\n\t\treturn r.exitCodes[0], nil, nil\r\n\t}\r\n\tresp, err := c.requestRetry(r.method, r.path, r.accept, r.requestBody)\r\n\tif err != nil {\r\n\t\treturn 0, nil, err\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\tb, err := ioutil.ReadAll(resp.Body)\r\n\tif err != nil {\r\n\t\treturn 0, nil, err\r\n\t}\r\n\tvar okCode bool\r\n\tfor _, code := range r.exitCodes {\r\n\t\tif code == resp.StatusCode {\r\n\t\t\tokCode = true\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif !okCode {\r\n\t\tclientError := unmarshalClientError(b)\r\n\t\terr = requestError{\r\n\t\t\tClientError: clientError,\r\n\t\t\tErrorString: fmt.Sprintf(\"status code %d not one of %v, body: %s\", resp.StatusCode, r.exitCodes, string(b)),\r\n\t\t}\r\n\t}\r\n\treturn resp.StatusCode, b, err\r\n}","code-length":330,"reference":"\/\/ requestRaw makes a request with retries and returns the response body.\n\/\/ Returns an error if the exit code is not one of the provided codes.","result":"Generate the code.","score":[0.0001,0.0203]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) getUserData() error {\r\n\tc.log(\"User\")\r\n\tvar u User\r\n\t_, err := c.request(&request{\r\n\t\tmethod:    http.MethodGet,\r\n\t\tpath:      \"\/user\",\r\n\t\texitCodes: []int{200},\r\n\t}, &u)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tc.botName = u.Login\r\n\t\r\n\t\r\n\t","code-length":128,"reference":"\/\/ Not thread-safe - callers need to hold c.mut.","result":"Get user data from bot.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) readPaginatedResultsWithValues(path string, values url.Values, accept string, newObj func() interface{}, accumulate func(interface{})) error {\r\n\tpagedPath := path\r\n\tif len(values) > 0 {\r\n\t\tpagedPath += \"?\" + values.Encode()\r\n\t}\r\n\tfor {\r\n\t\tresp, err := c.requestRetry(http.MethodGet, pagedPath, accept, nil)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdefer resp.Body.Close()\r\n\t\tif resp.StatusCode < 200 || resp.StatusCode > 299 {\r\n\t\t\treturn fmt.Errorf(\"return code not 2XX: %s\", resp.Status)\r\n\t\t}\r\n\t\tb, err := ioutil.ReadAll(resp.Body)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tobj := newObj()\r\n\t\tif err := json.Unmarshal(b, obj); err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\taccumulate(obj)\r\n\t\tlink := parseLinks(resp.Header.Get(\"Link\"))[\"next\"]\r\n\t\tif link == \"\" {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tu, err := url.Parse(link)\r\n\t\tif err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed to parse 'next' link: %v\", err)\r\n\t\t}\r\n\t\tpagedPath = u.RequestURI()\r\n\t}\r\n\treturn nil\r\n}","code-length":389,"reference":"\/\/ readPaginatedResultsWithValues is an override that allows control over the query string.","result":"Return paginated results.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) UpdatePullRequest(org, repo string, number int, title, body *string, open *bool, branch *string, canModify *bool) error {\r\n\tc.log(\"UpdatePullRequest\", org, repo, title)\r\n\tdata := struct {\r\n\t\tState *string `json:\"state,omitempty\"`\r\n\t\tTitle *string `json:\"title,omitempty\"`\r\n\t\tBody  *string `json:\"body,omitempty\"`\r\n\t\tBase  *string `json:\"base,omitempty\"`\r\n\t\t\r\n\t\t\r\n\t\tMaintainerCanModify *bool `json:\"maintainer_can_modify,omitempty\"`\r\n\t}{\r\n\t\tTitle:               title,\r\n\t\tBody:                body,\r\n\t\tBase:                branch,\r\n\t\tMaintainerCanModify: canModify,\r\n\t}\r\n\tif open != nil && *open {\r\n\t\top := \"open\"\r\n\t\tdata.State = &op\r\n\t} else if open != nil {\r\n\t\tcl := \"clossed\"\r\n\t\tdata.State = &cl\r\n\t}\r\n\t_, err := c.request(&request{\r\n\t\t\r\n\t\tatch,\r\n\t\tpath:        fmt.Sprintf(\"\/repos\/%s\/%s\/pulls\/%d\", org, repo, number),\r\n\t\trequestBody: &data,\r\n\t\texitCodes:   []int{200},\r\n\t}, nil)\r\n\treturn err\r\n}","code-length":361,"reference":"\/\/ UpdatePullRequest modifies the title, body, open state","result":"Update a pull request.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) getLabels(path string) ([]Label, error) {\r\n\tvar labels []Label\r\n\tif c.fake {\r\n\t\treturn labels, nil\r\n\t}\r\n\terr := c.readPaginatedResults(\r\n\t\tpath,\r\n\t\t\"application\/vnd.github.symmetra-preview+json\",\r\n\t\t\tlabels = append(labels, *(obj.(*[]Label))...)\r\n\t\t},\r\n\t)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn labels, nil\r\n}","code-length":150,"reference":"\/\/ getLabels is a helper function that retrieves a paginated list of labels from a github URI path.","result":"Fetch labels.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc stateCannotBeChangedOrOriginalError(err error) error {\r\n\trequestErr, ok := err.(requestError)\r\n\tif ok {\r\n\t\tfor _, errorMsg := range requestErr.ErrorMessages() {\r\n\t\t\tif strings.Contains(errorMsg, stateCannotBeChangedMessagePrefix) {\r\n\t\t\t\treturn StateCannotBeChanged{\r\n\t\t\t\t\tMessage: errorMsg,\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\treturn err\r\n}","code-length":125,"reference":"\/\/ convert to a StateCannotBeChanged if appropriate or else return the original error","result":"Detect state cannot be changed or original error.","score":[0.0884,0.08]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) IsMergeable(org, repo string, number int, SHA string) (bool, error) {\r\n\tbackoff := time.Second * 3\r\n\tmaxTries := 3\r\n\tfor try := 0; try < maxTries; try++ {\r\n\t\tpr, err := c.GetPullRequest(org, repo, number)\r\n\t\tif err != nil {\r\n\t\t\treturn false, err\r\n\t\t}\r\n\t\tif pr.Head.SHA != SHA {\r\n\t\t\treturn false, fmt.Errorf(\"pull request head changed while checking mergeability (%s -> %s)\", SHA, pr.Head.SHA)\r\n\t\t}\r\n\t\tif pr.Merged {\r\n\t\t\treturn false, errors.New(\"pull request was merged while checking mergeability\")\r\n\t\t}\r\n\t\tif pr.Mergable != nil {\r\n\t\t\treturn *pr.Mergable, nil\r\n\t\t}\r\n\t\tif try+1 < maxTries {\r\n\t\t\tc.time.Sleep(backoff)\r\n\t\t\tbackoff *= 2\r\n\t\t}\r\n\t}\r\n\treturn false, fmt.Errorf(\"reached maximum number of retries (%d) checking mergeability\", maxTries)\r\n}","code-length":297,"reference":"\/\/ IsMergeable determines if a PR can be merged.\n\/\/ Mergeability is calculated by a background job on GitHub and is not immediately available when\n\/\/ new commits are added so the PR must be polled until the background job completes.","result":"Check if a file is merged.","score":[0.001,0.0533]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *reloadingTokenSource) Token() (*oauth2.Token, error) {\r\n\treturn &oauth2.Token{\r\n\t\tAccessToken: string(s.getToken()),\r\n\t}, nil\r\n}","code-length":62,"reference":"\/\/ Token is an implementation for oauth2.TokenSource interface.","result":"Reload token.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Spyglass) ListArtifacts(src string) ([]string, error) {\r\n\tkeyType, key, err := splitSrc(src)\r\n\tif err != nil {\r\n\t\treturn []string{}, fmt.Errorf(\"error parsing src: %v\", err)\r\n\t}\r\n\tgcsKey := \"\"\r\n\tswitch keyType {\r\n\tcase gcsKeyType:\r\n\t\tgcsKey = key\r\n\tcase prowKeyType:\r\n\t\tif gcsKey, err = s.prowToGCS(key); err != nil {\r\n\t\t\tlogrus.Warningf(\"Failed to get gcs source for prow job: %v\", err)\r\n\t\t}\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"Unrecognized key type for src: %v\", src)\r\n\t}\r\n\tartifactNames, err := s.GCSArtifactFetcher.artifacts(gcsKey)\r\n\tlogFound := false\r\n\tfor _, name := range artifactNames {\r\n\t\tif name == \"build-log.txt\" {\r\n\t\t\tlogFound = true\r\n\t\t\tbreak\r\n\t\t}\r\n\t}\r\n\tif err != nil || !logFound {\r\n\t\tartifactNames = append(artifactNames, \"build-log.txt\")\r\n\t}\r\n\treturn artifactNames, nil\r\n}","code-length":326,"reference":"\/\/ ListArtifacts gets the names of all artifacts available from the given source","result":"List all the artifacts in the package.","score":[0.0969,0.2016]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (*Spyglass) KeyToJob(src string) (jobName string, buildID string, err error) {\r\n\tsrc = strings.Trim(src, \"\/\")\r\n\tparsed := strings.Split(src, \"\/\")\r\n\tif len(parsed) < 2 {\r\n\t\treturn \"\", \"\", fmt.Errorf(\"expected at least two path components in %q\", src)\r\n\t}\r\n\tjobName = parsed[len(parsed)-2]\r\n\tbuildID = parsed[len(parsed)-1]\r\n\treturn jobName, buildID, nil\r\n}","code-length":142,"reference":"\/\/ KeyToJob takes a spyglass URL and returns the jobName and buildID.","result":"Convert a string to a job name.","score":[0.0791,0.0435]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Spyglass) prowToGCS(prowKey string) (string, error) {\r\n\tjobName, buildID, err := s.KeyToJob(prowKey)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"could not get GCS src: %v\", err)\r\n\t}\r\n\tjob, err := s.jobAgent.GetProwJob(jobName, buildID)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"Failed to get prow job from src %q: %v\", prowKey, err)\r\n\t}\r\n\turl := job.Status.URL\r\n\tprefix := s.config().Plank.GetJobURLPrefix(job.Spec.Refs)\r\n\tif !strings.HasPrefix(url, prefix) {\r\n\t\treturn \"\", fmt.Errorf(\"unexpected job URL %q when finding GCS path: expected something starting with %q\", url, prefix)\r\n\t}\r\n\treturn url[len(prefix):], nil\r\n}","code-length":252,"reference":"\/\/ prowToGCS returns the GCS key corresponding to the given prow key","result":"Generate code for generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *Spyglass) FetchArtifacts(src string, podName string, sizeLimit int64, artifactNames []string) ([]lenses.Artifact, error) {\r\n\tartStart := time.Now()\r\n\tarts := []lenses.Artifact{}\r\n\tkeyType, key, err := splitSrc(src)\r\n\tif err != nil {\r\n\t\treturn arts, fmt.Errorf(\"error parsing src: %v\", err)\r\n\t}\r\n\tjobName, buildID, err := s.KeyToJob(src)\r\n\tif err != nil {\r\n\t\treturn arts, fmt.Errorf(\"could not derive job: %v\", err)\r\n\t}\r\n\tgcsKey := \"\"\r\n\tswitch keyType {\r\n\tcase gcsKeyType:\r\n\t\tgcsKey = strings.TrimSuffix(key, \"\/\")\r\n\tcase prowKeyType:\r\n\t\tif gcsKey, err = s.prowToGCS(key); err != nil {\r\n\t\t\tlogrus.Warningln(err)\r\n\t\t}\r\n\tdefault:\r\n\t\treturn nil, fmt.Errorf(\"invalid src: %v\", src)\r\n\t}\r\n\tpodLogNeeded := false\r\n\tfor _, name := range artifactNames {\r\n\t\tart, err := s.GCSArtifactFetcher.artifact(gcsKey, name, sizeLimit)\r\n\t\tif err == nil {\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t_, err = art.Size()\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\tif name == \"build-log.txt\" {\r\n\t\t\t\tpodLogNeeded = true\r\n\t\t\t}\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tarts = append(arts, art)\r\n\t}\r\n\tif podLogNeeded {\r\n\t\tart, err := s.PodLogArtifactFetcher.artifact(jobName, buildID, sizeLimit)\r\n\t\tif err != nil {\r\n\t\t\tlogrus.Errorf(\"Failed to fetch pod log: %v\", err)\r\n\t\t} else {\r\n\t\t\tarts = append(arts, art)\r\n\t\t}\r\n\t}\r\n\tlogrus.WithField(\"duration\", time.Since(artStart)).Infof(\"Retrieved artifacts for %v\", src)\r\n\treturn arts, nil\r\n}","code-length":568,"reference":"\/\/ FetchArtifacts constructs and returns Artifact objects for each artifact name in the list.\n\/\/ This includes getting any handles needed for read write operations, direct artifact links, etc.","result":"Code too long,keep in 512.","score":[0.002,0.0188]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *DecorationConfig) DeepCopy() *DecorationConfig {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(DecorationConfig)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":70,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new DecorationConfig.","result":"Avoid deep copy.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *GCSConfiguration) DeepCopy() *GCSConfiguration {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(GCSConfiguration)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":70,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new GCSConfiguration.","result":"Create a deep copy of the objects.","score":[0.0707,0.2373]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *JenkinsSpec) DeepCopy() *JenkinsSpec {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(JenkinsSpec)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":70,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new JenkinsSpec.","result":"Create a deep copy of the same object.","score":[0.078,0.2355]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ProwJob) DeepCopy() *ProwJob {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(ProwJob)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":70,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new ProwJob.","result":"Avoid deep copy.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ProwJobList) DeepCopy() *ProwJobList {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(ProwJobList)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":73,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new ProwJobList.","result":"Avoid deep copy.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ProwJobSpec) DeepCopy() *ProwJobSpec {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(ProwJobSpec)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":73,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new ProwJobSpec.","result":"Create a deep copy of the same object.","score":[0.078,0.2355]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *ProwJobStatus) DeepCopy() *ProwJobStatus {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(ProwJobStatus)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":70,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new ProwJobStatus.","result":"Create a deep copy of the same object.","score":[0.078,0.2355]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *Pull) DeepCopy() *Pull {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(Pull)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":64,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new Pull.","result":"Avoid deep copy.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *Refs) DeepCopy() *Refs {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(Refs)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":64,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new Refs.","result":"Avoid deep copy.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (in *UtilityImages) DeepCopy() *UtilityImages {\r\n\tif in == nil {\r\n\t\treturn nil\r\n\t}\r\n\tout := new(UtilityImages)\r\n\tin.DeepCopyInto(out)\r\n\treturn out\r\n}","code-length":67,"reference":"\/\/ DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new UtilityImages.","result":"Copy library functions.","score":[0,0.0388]}
{"code":"\/*is used to<extra_id_0>\r\nfunc upload(rsClient *resultstore.Client, inv resultstore.Invocation, target resultstore.Target, test resultstore.Test) (string, error) {\r\n\ttargetID := test.Name\r\n\tconst configID = resultstore.Default\r\n\tinvName, err := rsClient.Invocations().Create(inv)\r\n\tif err != nil {\r\n\t\treturn \"\", fmt.Errorf(\"create invocation: %v\", err)\r\n\t}\r\n\ttargetName, err := rsClient.Targets(invName).Create(targetID, target)\r\n\tif err != nil {\r\n\t\treturn resultstore.URL(invName), fmt.Errorf(\"create target: %v\", err)\r\n\t}\r\n\turl := resultstore.URL(targetName)\r\n\t_, err = rsClient.Configurations(invName).Create(configID)\r\n\tif err != nil {\r\n\t\treturn url, fmt.Errorf(\"create configuration: %v\", err)\r\n\t}\r\n\tctName, err := rsClient.ConfiguredTargets(targetName, configID).Create(test.Action)\r\n\tif err != nil {\r\n\t\treturn url, fmt.Errorf(\"create configured target: %v\", err)\r\n\t}\r\n\t_, err = rsClient.Actions(ctName).Create(\"primary\", test)\r\n\tif err != nil {\r\n\t\treturn url, fmt.Errorf(\"create action: %v\", err)\r\n\t}\r\n\treturn url, nil\r\n}","code-length":356,"reference":"\/\/ upload the result downloaded from path into project.","result":"Upload result to resultstore.","score":[0.0915,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DecorationConfig) ApplyDefault(def *DecorationConfig) *DecorationConfig {\r\n\tif d == nil && def == nil {\r\n\t\treturn nil\r\n\t}\r\n\tvar merged DecorationConfig\r\n\tif d != nil {\r\n\t\tmerged = *d\r\n\t} else {\r\n\t\tmerged = *def\r\n\t}\r\n\tif d == nil || def == nil {\r\n\t\treturn &merged\r\n\t}\r\n\tmerged.UtilityImages = merged.UtilityImages.ApplyDefault(def.UtilityImages)\r\n\tmerged.GCSConfiguration = merged.GCSConfiguration.ApplyDefault(def.GCSConfiguration)\r\n\tif merged.Timeout.Duration == 0 {\r\n\t\tmerged.Timeout = def.Timeout\r\n\t}\r\n\tif merged.GracePeriod.Duration == 0 {\r\n\t\tmerged.GracePeriod = def.GracePeriod\r\n\t}\r\n\tif merged.GCSCredentialsSecret == \"\" {\r\n\t\tmerged.GCSCredentialsSecret = def.GCSCredentialsSecret\r\n\t}\r\n\tif len(merged.SSHKeySecrets) == 0 {\r\n\t\tmerged.SSHKeySecrets = def.SSHKeySecrets\r\n\t}\r\n\tif len(merged.SSHHostFingerprints) == 0 {\r\n\t\tmerged.SSHHostFingerprints = def.SSHHostFingerprints\r\n\t}\r\n\tif merged.SkipCloning == nil {\r\n\t\tmerged.SkipCloning = def.SkipCloning\r\n\t}\r\n\tif merged.CookiefileSecret == \"\" {\r\n\t\tmerged.CookiefileSecret = def.CookiefileSecret\r\n\t}\r\n\treturn &merged\r\n}","code-length":396,"reference":"\/\/ ApplyDefault applies the defaults for the ProwJob decoration. If a field has a zero value, it\n\/\/ replaces that with the value set in def.","result":"Apply default values to the decorated images.","score":[0.0107,0.083]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (d *DecorationConfig) Validate() error {\r\n\tif d.UtilityImages == nil {\r\n\t\treturn errors.New(\"utility image config is not specified\")\r\n\t}\r\n\tvar missing []string\r\n\tif d.UtilityImages.CloneRefs == \"\" {\r\n\t\tmissing = append(missing, \"clonerefs\")\r\n\t}\r\n\tif d.UtilityImages.InitUpload == \"\" {\r\n\t\tmissing = append(missing, \"initupload\")\r\n\t}\r\n\tif d.UtilityImages.Entrypoint == \"\" {\r\n\t\tmissing = append(missing, \"entrypoint\")\r\n\t}\r\n\tif d.UtilityImages.Sidecar == \"\" {\r\n\t\tmissing = append(missing, \"sidecar\")\r\n\t}\r\n\tif len(missing) > 0 {\r\n\t\treturn fmt.Errorf(\"the following utility images are not specified: %q\", missing)\r\n\t}\r\n\tif d.GCSConfiguration == nil {\r\n\t\treturn errors.New(\"GCS upload configuration is not specified\")\r\n\t}\r\n\tif d.GCSCredentialsSecret == \"\" {\r\n\t\treturn errors.New(\"GCS upload credential secret is not specified\")\r\n\t}\r\n\tif err := d.GCSConfiguration.Validate(); err != nil {\r\n\t\treturn fmt.Errorf(\"GCS configuration is invalid: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":345,"reference":"\/\/ Validate ensures all the values set in the DecorationConfig are valid.","result":"Validate the code.","score":[0.0242,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (u *UtilityImages) ApplyDefault(def *UtilityImages) *UtilityImages {\r\n\tif u == nil {\r\n\t\treturn def\r\n\t} else if def == nil {\r\n\t\treturn u\r\n\t}\r\n\tmerged := *u\r\n\tif merged.CloneRefs == \"\" {\r\n\t\tmerged.CloneRefs = def.CloneRefs\r\n\t}\r\n\tif merged.InitUpload == \"\" {\r\n\t\tmerged.InitUpload = def.InitUpload\r\n\t}\r\n\tif merged.Entrypoint == \"\" {\r\n\t\tmerged.Entrypoint = def.Entrypoint\r\n\t}\r\n\tif merged.Sidecar == \"\" {\r\n\t\tmerged.Sidecar = def.Sidecar\r\n\t}\r\n\treturn &merged\r\n}","code-length":190,"reference":"\/\/ ApplyDefault applies the defaults for the UtilityImages decorations. If a field has a zero value,\n\/\/ it replaces that with the value set in def.","result":"Apply default values.","score":[0,0.0422]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *GCSConfiguration) ApplyDefault(def *GCSConfiguration) *GCSConfiguration {\r\n\tif g == nil && def == nil {\r\n\t\treturn nil\r\n\t}\r\n\tvar merged GCSConfiguration\r\n\tif g != nil {\r\n\t\tmerged = *g\r\n\t} else {\r\n\t\tmerged = *def\r\n\t}\r\n\tif g == nil || def == nil {\r\n\t\treturn &merged\r\n\t}\r\n\tif merged.Bucket == \"\" {\r\n\t\tmerged.Bucket = def.Bucket\r\n\t}\r\n\tif merged.PathPrefix == \"\" {\r\n\t\tmerged.PathPrefix = def.PathPrefix\r\n\t}\r\n\tif merged.PathStrategy == \"\" {\r\n\t\tmerged.PathStrategy = def.PathStrategy\r\n\t}\r\n\tif merged.DefaultOrg == \"\" {\r\n\t\tmerged.DefaultOrg = def.DefaultOrg\r\n\t}\r\n\tif merged.DefaultRepo == \"\" {\r\n\t\tmerged.DefaultRepo = def.DefaultRepo\r\n\t}\r\n\treturn &merged\r\n}","code-length":260,"reference":"\/\/ ApplyDefault applies the defaults for GCSConfiguration decorations. If a field has a zero value,\n\/\/ it replaces that with the value set in def.","result":"Apply default values to GCSConfiguration objects.","score":[0.0081,0.0866]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *GCSConfiguration) Validate() error {\r\n\tif g.PathStrategy != PathStrategyLegacy && g.PathStrategy != PathStrategyExplicit && g.PathStrategy != PathStrategySingle {\r\n\t\treturn fmt.Errorf(\"gcs_path_strategy must be one of %q, %q, or %q\", PathStrategyLegacy, PathStrategyExplicit, PathStrategySingle)\r\n\t}\r\n\tif g.PathStrategy != PathStrategyExplicit && (g.DefaultOrg == \"\" || g.DefaultRepo == \"\") {\r\n\t\treturn fmt.Errorf(\"default org and repo must be provided for GCS strategy %q\", g.PathStrategy)\r\n\t}\r\n\treturn nil\r\n}","code-length":165,"reference":"\/\/ Validate ensures all the values set in the GCSConfiguration are valid.","result":"Validate the configuration .","score":[0.0514,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (j *ProwJob) ClusterAlias() string {\r\n\tif j.Spec.Cluster == \"\" {\r\n\t\treturn DefaultClusterAlias\r\n\t}\r\n\treturn j.Spec.Cluster\r\n}","code-length":58,"reference":"\/\/ ClusterAlias specifies the key in the clusters map to use.\n\/\/\n\/\/ This allows scheduling a prow job somewhere aside from the default build cluster.","result":"Generate the generated code.","score":[0.0013,0.021]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewResource(name, rtype, state, owner string, t time.Time) Resource {\r\n\treturn Resource{\r\n\t\tName:       name,\r\n\t\tType:       rtype,\r\n\t\tState:      state,\r\n\t\tOwner:      owner,\r\n\t\tLastUpdate: t,\r\n\t\tUserData:   &UserData{},\r\n\t}\r\n}","code-length":98,"reference":"\/\/ NewResource creates a new Boskos Resource.","result":"Create a new resource.","score":[0.2134,0.5597]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewResourcesFromConfig(e ResourceEntry) []Resource {\r\n\tvar resources []Resource\r\n\tfor _, name := range e.Names {\r\n\t\tresources = append(resources, NewResource(name, e.Type, e.State, \"\", time.Time{}))\r\n\t}\r\n\treturn resources\r\n}","code-length":82,"reference":"\/\/ NewResourcesFromConfig parse the a ResourceEntry into a list of resources","result":"Create a new resource.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UserDataFromMap(m UserDataMap) *UserData {\r\n\tud := &UserData{}\r\n\tfor k, v := range m {\r\n\t\tud.Store(k, v)\r\n\t}\r\n\treturn ud\r\n}","code-length":63,"reference":"\/\/ UserDataFromMap returns a UserData from a map","result":"Create a user data object.","score":[0.1319,0.0649]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *CommaSeparatedStrings) Set(value string) error {\r\n\tif len(*r) > 0 {\r\n\t\treturn errors.New(\"resTypes flag already set\")\r\n\t}\r\n\tfor _, rtype := range strings.Split(value, \",\") {\r\n\t\t*r = append(*r, rtype)\r\n\t}\r\n\treturn nil\r\n}","code-length":97,"reference":"\/\/ Set parses the flag value into a CommaSeparatedStrings","result":"Set the resTypes flag.","score":[0.1088,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ud *UserData) UnmarshalJSON(data []byte) error {\r\n\ttmpMap := UserDataMap{}\r\n\tif err := json.Unmarshal(data, &tmpMap); err != nil {\r\n\t\treturn err\r\n\t}\r\n\tud.FromMap(tmpMap)\r\n\treturn nil\r\n}","code-length":80,"reference":"\/\/ UnmarshalJSON implements JSON Unmarshaler interface","result":"Unmarshal JSON.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ud *UserData) Extract(id string, out interface{}) error {\r\n\tcontent, ok := ud.Load(id)\r\n\tif !ok {\r\n\t\treturn &UserDataNotFound{id}\r\n\t}\r\n\treturn yaml.Unmarshal([]byte(content.(string)), out)\r\n}","code-length":83,"reference":"\/\/ Extract unmarshalls a string a given struct if it exists","result":"Extract data from a user data.","score":[0.0998,0.0952]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ud *UserData) Set(id string, in interface{}) error {\r\n\tb, err := yaml.Marshal(in)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tud.Store(id, string(b))\r\n\treturn nil\r\n}","code-length":78,"reference":"\/\/ User Data are used to store custom information mainly by Mason and Masonable implementation.\n\/\/ Mason used a LeasedResource keys to store information about other resources that used to\n\/\/ create the given resource.\n\/\/ Set marshalls a struct to a string into the UserData","result":"Set the value of a user data.","score":[0.0008,0.0475]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ud *UserData) Update(new *UserData) {\r\n\tif new == nil {\r\n\t\treturn\r\n\t}\r\n\tnew.Range(func(key, value interface{}) bool {\r\n\t\tif value.(string) != \"\" {\r\n\t\t\tud.Store(key, value)\r\n\t\t} else {\r\n\t\t\tud.Delete(key)\r\n\t\t}\r\n\t\treturn true\r\n\t})\r\n}","code-length":116,"reference":"\/\/ Update updates existing UserData with new UserData.\n\/\/ If a key as an empty string, the key will be deleted","result":"Update the user data.","score":[0.0054,0.0518]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ud *UserData) ToMap() UserDataMap {\r\n\tm := UserDataMap{}\r\n\tud.Range(func(key, value interface{}) bool {\r\n\t\tm[key.(string)] = value.(string)\r\n\t\treturn true\r\n\t})\r\n\treturn m\r\n}","code-length":81,"reference":"\/\/ ToMap converts a UserData to UserDataMap","result":"Convert UserData to UserDataMap.","score":[0.2134,0.3814]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ud *UserData) FromMap(m UserDataMap) {\r\n\tfor key, value := range m {\r\n\t\tud.Store(key, value)\r\n\t}\r\n}","code-length":53,"reference":"\/\/ FromMap feels updates user data from a map","result":"Generate code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ItemToResource(i Item) (Resource, error) {\r\n\tres, ok := i.(Resource)\r\n\tif !ok {\r\n\t\treturn Resource{}, fmt.Errorf(\"cannot construct Resource from received object %v\", i)\r\n\t}\r\n\treturn res, nil\r\n}","code-length":79,"reference":"\/\/ ItemToResource casts a Item back to a Resource","result":"Convert Item to Resource.","score":[0.1088,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o Options) Run() error {\r\n\tvar env []string\r\n\tif len(o.KeyFiles) > 0 {\r\n\t\tvar err error\r\n\t\tenv, err = addSSHKeys(o.KeyFiles)\r\n\t\tif err != nil {\r\n\t\t\tlogrus.WithError(err).Error(\"Failed to add SSH keys.\")\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t\t\r\n\t\t}\r\n\t}\r\n\tif len(o.HostFingerprints) > 0 {\r\n\t\tif err := addHostFingerprints(o.HostFingerprints); err != nil {\r\n\t\t\tlogrus.WithError(err).Error(\"failed to add host fingerprints\")\r\n\t\t}\r\n\t}\r\n\tvar numWorkers int\r\n\tif o.MaxParallelWorkers != 0 {\r\n\t\tnumWorkers = o.MaxParallelWorkers\r\n\t} else {\r\n\t\tnumWorkers = len(o.GitRefs)\r\n\t}\r\n\twg := &sync.WaitGroup{}\r\n\twg.Add(numWorkers)\r\n\tinput := make(chan prowapi.Refs)\r\n\toutput := make(chan clone.Record, len(o.GitRefs))\r\n\tfor i := 0; i < numWorkers; i++ {\r\n\t\tgo func() {\r\n\t\t\tdefer wg.Done()\r\n\t\t\tfor ref := range input {\r\n\t\t\t\toutput <- cloneFunc(ref, o.SrcRoot, o.GitUserName, o.GitUserEmail, o.CookiePath, env)\r\n\t\t\t}\r\n\t\t}()\r\n\t}\r\n\tfor _, ref := range o.GitRefs {\r\n\t\tinput <- ref\r\n\t}\r\n\tclose(input)\r\n\twg.Wait()\r\n\tclose(output)\r\n\tvar results []clone.Record\r\n\tfor record := range output {\r\n\t\tresults = append(results, record)\r\n\t}\r\n\tlogData, err := json.Marshal(results)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed to marshal clone records: %v\", err)\r\n\t}\r\n\tif err := ioutil.WriteFile(o.Log, logData, 0755); err != nil {\r\n\t\treturn fmt.Errorf(\"failed to write clone records: %v\", err)\r\n\t}\r\n\treturn nil\r\n}","code-length":562,"reference":"\/\/ Run clones the configured refs","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc addSSHKeys(paths []string) ([]string, error) {\r\n\tvars, err := exec.Command(\"ssh-agent\").CombinedOutput()\r\n\tif err != nil {\r\n\t\treturn []string{}, fmt.Errorf(\"failed to start ssh-agent: %v\", err)\r\n\t}\r\n\tlogrus.Info(\"Started SSH agent\")\r\n\t\r\n\t\r\n\t\r\n\t\r\n\t\r\n\tparts := strings.Split(string(vars), \";\")\r\n\tenv := []string{strings.TrimSpace(parts[0]), strings.TrimSpace(parts[2])}\r\n\tfor _, keyPath := range paths {\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tif err := filepath.Walk(keyPath, func(path string, info os.FileInfo, err error) error {\r\n\t\t\tif strings.HasPrefix(info.Name(), \"..\") {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\tif info.IsDir() {\r\n\t\t\t\t\treturn filepath.SkipDir\r\n\t\t\t\t}\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\tif info.IsDir() {\r\n\t\t\t\treturn nil\r\n\t\t\t}\r\n\t\t\tcmd := exec.Command(\"ssh-add\", path)\r\n\t\t\tcmd.Env = append(cmd.Env, env...)\r\n\t\t\tif output, err := cmd.CombinedOutput(); err != nil {\r\n\t\t\t\treturn fmt.Errorf(\"failed to add ssh key at %s: %v: %s\", path, err, output)\r\n\t\t\t}\r\n\t\t\tlogrus.Infof(\"Added SSH key at %s\", path)\r\n\t\t\treturn nil\r\n\t\t}); err != nil {\r\n\t\t\treturn env, fmt.Errorf(\"error walking path %q: %v\", keyPath, err)\r\n\t\t}\r\n\t}\r\n\treturn env, nil\r\n}","code-length":444,"reference":"\/\/ addSSHKeys will start the ssh-agent and add all the specified\n\/\/ keys, returning the ssh-agent environment variables for reuse","result":"Add ssh keys to the host.","score":[0.0187,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *TriageFiler) Issues(c *creator.IssueCreator) ([]creator.Issue, error) {\r\n\tf.creator = c\r\n\trawjson, err := ReadHTTP(clusterDataURL)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tclusters, err := f.loadClusters(rawjson)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\ttopclusters := topClusters(clusters, f.topClustersCount)\r\n\tissues := make([]creator.Issue, 0, len(topclusters))\r\n\tfor _, clust := range topclusters {\r\n\t\tissues = append(issues, clust)\r\n\t}\r\n\treturn issues, nil\r\n}","code-length":191,"reference":"\/\/ Issues is the main work function of the TriageFiler.  It fetches and parses cluster data,\n\/\/ then syncs the top issues to github with the IssueCreator.","result":"Generate issue.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (f *TriageFiler) loadClusters(jsonIn []byte) ([]*Cluster, error) {\r\n\tvar err error\r\n\tf.data, err = parseTriageData(jsonIn)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif err = f.filterAndValidate(f.windowDays); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tfor _, clust := range f.data.Clustered {\r\n\t\tclust.filer = f\r\n\t\tclust.jobs = make(map[string][]int)\r\n\t\tfor _, test := range clust.Tests {\r\n\t\t\tfor _, job := range test.Jobs {\r\n\t\t\t\tfor _, buildnum := range job.Builds {\r\n\t\t\t\t\tfound := false\r\n\t\t\t\t\tfor _, oldBuild := range clust.jobs[job.Name] {\r\n\t\t\t\t\t\tif oldBuild == buildnum {\r\n\t\t\t\t\t\t\tfound = true\r\n\t\t\t\t\t\t\tbreak\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t}\r\n\t\t\t\t\tif !found {\r\n\t\t\t\t\t\tclust.jobs[job.Name] = append(clust.jobs[job.Name], buildnum)\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\tclust.totalJobs = len(clust.jobs)\r\n\t\tclust.totalTests = len(clust.Tests)\r\n\t\tclust.totalBuilds = 0\r\n\t\tfor _, builds := range clust.jobs {\r\n\t\t\tclust.totalBuilds += len(builds)\r\n\t\t}\r\n\t}\r\n\treturn f.data.Clustered, nil\r\n}","code-length":418,"reference":"\/\/ loadClusters parses and filters the json data, then populates every Cluster struct with\n\/\/ aggregated job data and totals. The job data specifies all jobs that failed in a cluster and the\n\/\/ builds that failed for each job, independent of which tests the jobs or builds failed.","result":"Load the cluster data.","score":[0.0,0.0225]}
{"code":"\/*is used to<extra_id_0>\r\nfunc parseTriageData(jsonIn []byte) (*triageData, error) {\r\n\tvar data triageData\r\n\tif err := json.Unmarshal(jsonIn, &data); err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif data.Builds.Cols.Started == nil {\r\n\t\treturn nil, fmt.Errorf(\"triage data json is missing the builds.cols.started key\")\r\n\t}\r\n\tif data.Builds.JobsRaw == nil {\r\n\t\treturn nil, fmt.Errorf(\"triage data is missing the builds.jobs key\")\r\n\t}\r\n\tif data.Builds.JobPaths == nil {\r\n\t\treturn nil, fmt.Errorf(\"triage data is missing the builds.job_paths key\")\r\n\t}\r\n\tif data.Clustered == nil {\r\n\t\treturn nil, fmt.Errorf(\"triage data is missing the clustered key\")\r\n\t}\r\n\t\r\n\tdata.Builds.Jobs = make(map[string]BuildIndexer)\r\n\tfor jobID, mapper := range data.Builds.JobsRaw {\r\n\t\tswitch mapper := mapper.(type) {\r\n\t\tcase []interface{}:\r\n\t\t\t\r\n\t\t\tdata.Builds.Jobs[jobID] = ContigIndexer{\r\n\t\t\t\tstartBuild: int(mapper[0].(float64)),\r\n\t\t\t\tcount:      int(mapper[1].(float64)),\r\n\t\t\t\tstartRow:   int(mapper[2].(float64)),\r\n\t\t\t}\r\n\t\tcase map[string]interface{}:\r\n\t\t\t\r\n\t\t\tdata.Builds.Jobs[jobID] = DictIndexer(mapper)\r\n\t\tdefault:\r\n\t\t\treturn nil, fmt.Errorf(\"the build number to row index mapping for job '%s' is not an accepted type. Type is: %v\", jobID, reflect.TypeOf(mapper))\r\n\t\t}\r\n\t}\r\n\treturn &data, nil\r\n}","code-length":472,"reference":"\/\/ parseTriageData unmarshals raw json data into a triageData struct and creates a BuildIndexer for\n\/\/ every job.","result":"Parse the triage data json.","score":[0.0178,0.0299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc topClusters(clusters []*Cluster, count int) []*Cluster {\r\n\tless := func(i, j int) bool { return clusters[i].totalBuilds > clusters[j].totalBuilds }\r\n\tsort.SliceStable(clusters, less)\r\n\tif len(clusters) < count {\r\n\t\tcount = len(clusters)\r\n\t}\r\n\treturn clusters[0:count]\r\n}","code-length":104,"reference":"\/\/ topClusters gets the 'count' most important clusters from a slice of clusters based on number of build failures.","result":"Generate the code.","score":[0.002,0.0287]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) topJobsFailed(count int) []*Job {\r\n\tslice := make([]*Job, len(c.jobs))\r\n\ti := 0\r\n\tfor jobName, builds := range c.jobs {\r\n\t\tslice[i] = &Job{Name: jobName, Builds: builds}\r\n\t\ti++\r\n\t}\r\n\tless := func(i, j int) bool { return len(slice[i].Builds) > len(slice[j].Builds) }\r\n\tsort.SliceStable(slice, less)\r\n\tif len(slice) < count {\r\n\t\tcount = len(slice)\r\n\t}\r\n\treturn slice[0:count]\r\n}","code-length":175,"reference":"\/\/ topJobsFailed returns the top 'count' job names sorted by number of failing builds.","result":"Get the list of failed jobs.","score":[0.0605,0.2841]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) Title() string {\r\n\treturn fmt.Sprintf(\"Failure cluster [%s...] failed %d builds, %d jobs, and %d tests over %d days\",\r\n\t\tc.Identifier[0:6],\r\n\t\tc.totalBuilds,\r\n\t\tc.totalJobs,\r\n\t\tc.totalTests,\r\n\t\tc.filer.windowDays,\r\n\t)\r\n}","code-length":109,"reference":"\/\/ Title is the string to use as the github issue title.","result":"Generate the title.","score":[0.0242,0.0901]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) Labels() []string {\r\n\tlabels := []string{\"kind\/flake\"}\r\n\ttopTests := make([]string, len(c.Tests))\r\n\tfor i, test := range c.topTestsFailed(len(c.Tests)) {\r\n\t\ttopTests[i] = test.Name\r\n\t}\r\n\tfor sig := range c.filer.creator.TestsSIGs(topTests) {\r\n\t\tlabels = append(labels, \"sig\/\"+sig)\r\n\t}\r\n\treturn labels\r\n}","code-length":138,"reference":"\/\/ Labels returns the labels to apply to the issue created for this cluster on github.","result":"Get labels from the cluster.","score":[0.0317,0.0671]}
{"code":"\/*is used to<extra_id_0>\r\nfunc New() *Cron {\r\n\treturn &Cron{\r\n\t\tcronAgent: cron.New(),\r\n\t\tjobs:      map[string]*jobStatus{},\r\n\t\tlogger:    logrus.WithField(\"client\", \"cron\"),\r\n\t}\r\n}","code-length":73,"reference":"\/\/ New makes a new Cron object","result":"Create a new cron agent.","score":[0.2278,0.433]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cron) QueuedJobs() []string {\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\tres := []string{}\r\n\tfor k, v := range c.jobs {\r\n\t\tif v.triggered {\r\n\t\t\tres = append(res, k)\r\n\t\t}\r\n\t\tc.jobs[k].triggered = false\r\n\t}\r\n\treturn res\r\n}","code-length":115,"reference":"\/\/ QueuedJobs returns a list of jobs that need to be triggered\n\/\/ and reset trigger in jobStatus","result":"Get the list of queued jobs.","score":[0.0369,0.1116]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cron) HasJob(name string) bool {\r\n\tc.lock.Lock()\r\n\tdefer c.lock.Unlock()\r\n\t_, ok := c.jobs[name]\r\n\treturn ok\r\n}","code-length":63,"reference":"\/\/ HasJob returns if a job has been scheduled in cronAgent or not","result":"Check if the job exists in the cron .","score":[0.1028,0.119]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cron) addJob(name, cron string) error {\r\n\tid, err := c.cronAgent.AddFunc(\"TZ=UTC \"+cron, func() {\r\n\t\tc.lock.Lock()\r\n\t\tdefer c.lock.Unlock()\r\n\t\tc.jobs[name].triggered = true\r\n\t\tc.logger.Infof(\"Triggering cron job %s.\", name)\r\n\t})\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"cronAgent fails to add job %s with cron %s: %v\", name, cron, err)\r\n\t}\r\n\tc.jobs[name] = &jobStatus{\r\n\t\tentryID: id,\r\n\t\tcronStr: cron,\r\n\t\t\r\n\t\ttriggered: strings.HasPrefix(cron, \"@every\"),\r\n\t}\r\n\tc.logger.Infof(\"Added new cron job %s with trigger %s.\", name, cron)\r\n\treturn nil\r\n}","code-length":243,"reference":"\/\/ addJob adds a cron entry for a job to cronAgent","result":"Add a new cron job.","score":[0.0861,0.1442]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cron) removeJob(name string) error {\r\n\tjob, ok := c.jobs[name]\r\n\tif !ok {\r\n\t\treturn fmt.Errorf(\"job %s has not been added to cronAgent yet\", name)\r\n\t}\r\n\tc.cronAgent.Remove(job.entryID)\r\n\tdelete(c.jobs, name)\r\n\tc.logger.Infof(\"Removed previous cron job %s.\", name)\r\n\treturn nil\r\n}","code-length":124,"reference":"\/\/ removeJob removes the job from cronAgent","result":"Remove a job from the cron agent.","score":[0.2528,0.4509]}
{"code":"\/*is used to<extra_id_0>\r\nfunc UpdateComments(issueID int, pullRequest bool, db *gorm.DB, client ClientInterface) {\r\n\tlatest := findLatestCommentUpdate(issueID, db, client.RepositoryName())\r\n\tupdateIssueComments(issueID, latest, db, client)\r\n\tif pullRequest {\r\n\t\tupdatePullComments(issueID, latest, db, client)\r\n\t}\r\n}","code-length":100,"reference":"\/\/ UpdateComments downloads issue and pull-request comments and save in DB","result":"Update comments.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GatherProwJobMetrics(pjs []prowapi.ProwJob) {\r\n\t\r\n\tmetricMap := make(map[string]map[string]map[string]float64)\r\n\tfor _, pj := range pjs {\r\n\t\tif metricMap[pj.Spec.Job] == nil {\r\n\t\t\tmetricMap[pj.Spec.Job] = make(map[string]map[string]float64)\r\n\t\t}\r\n\t\tif metricMap[pj.Spec.Job][string(pj.Spec.Type)] == nil {\r\n\t\t\tmetricMap[pj.Spec.Job][string(pj.Spec.Type)] = make(map[string]float64)\r\n\t\t}\r\n\t\tmetricMap[pj.Spec.Job][string(pj.Spec.Type)][string(pj.Status.State)]++\r\n\t}\r\n\t\r\n\t\r\n\tprowJobs.Reset()\r\n\tfor job, jobMap := range metricMap {\r\n\t\tfor jobType, typeMap := range jobMap {\r\n\t\t\tfor state, count := range typeMap {\r\n\t\t\t\tprowJobs.WithLabelValues(job, jobType, state).Set(count)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}","code-length":316,"reference":"\/\/ GatherProwJobMetrics gathers prometheus metrics for prowjobs.","result":"Gather metrics for all ProwJobs.","score":[0.2278,0.4642]}
{"code":"\/*is used to<extra_id_0>\r\nfunc optionOrDefault(option, defaultValue time.Duration) time.Duration {\r\n\tif option == 0 {\r\n\t\treturn defaultValue\r\n\t}\r\n\treturn option\r\n}","code-length":50,"reference":"\/\/ optionOrDefault defaults to a value if option\n\/\/ is the zero value","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newGCSJobSource(src string) (*gcsJobSource, error) {\r\n\tgcsURL, err := url.Parse(fmt.Sprintf(\"gs:\r\n\tif err != nil {\r\n\t\treturn &gcsJobSource{}, ErrCannotParseSource\r\n\t}\r\n\tgcsPath := &gcs.Path{}\r\n\terr = gcsPath.SetURL(gcsURL)\r\n\tif err != nil {\r\n\t\treturn &gcsJobSource{}, ErrCannotParseSource\r\n\t}\r\n\ttokens := strings.FieldsFunc(gcsPath.Object(), func(c rune) bool { return c == '\/' })\r\n\tif len(tokens) < 2 {\r\n\t\treturn &gcsJobSource{}, ErrCannotParseSource\r\n\t}\r\n\tbuildID := tokens[len(tokens)-1]\r\n\tname := tokens[len(tokens)-2]\r\n\treturn &gcsJobSource{\r\n\t\tsource:     src,\r\n\t\tlinkPrefix: \"gs:\r\n\t\tbucket:     gcsPath.Bucket(),\r\n\t\tjobPrefix:  path.Clean(gcsPath.Object()) + \"\/\",\r\n\t\tjobName:    name,\r\n\t\tbuildID:    buildID,\r\n\t}, nil\r\n}","code-length":311,"reference":"\/\/ newGCSJobSource creates a new gcsJobSource from a given bucket and jobPrefix","result":"Create a job source.","score":[0.0432,0.0893]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (af *GCSArtifactFetcher) artifacts(key string) ([]string, error) {\r\n\tsrc, err := newGCSJobSource(key)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"Failed to get GCS job source from %s: %v\", key, err)\r\n\t}\r\n\tlistStart := time.Now()\r\n\tbucketName, prefix := extractBucketPrefixPair(src.jobPath())\r\n\tartifacts := []string{}\r\n\tbkt := af.client.Bucket(bucketName)\r\n\tq := storage.Query{\r\n\t\tPrefix:   prefix,\r\n\t\tVersions: false,\r\n\t}\r\n\tobjIter := bkt.Objects(context.Background(), &q)\r\n\twait := []time.Duration{16, 32, 64, 128, 256, 256, 512, 512}\r\n\tfor i := 0; ; {\r\n\t\toAttrs, err := objIter.Next()\r\n\t\tif err == iterator.Done {\r\n\t\t\tbreak\r\n\t\t}\r\n\t\tif err != nil {\r\n\t\t\tlogrus.WithFields(fieldsForJob(src)).WithError(err).Error(\"Error accessing GCS artifact.\")\r\n\t\t\tif i >= len(wait) {\r\n\t\t\t\treturn artifacts, fmt.Errorf(\"timed out: error accessing GCS artifact: %v\", err)\r\n\t\t\t}\r\n\t\t\ttime.Sleep((wait[i] + time.Duration(rand.Intn(10))) * time.Millisecond)\r\n\t\t\ti++\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tartifacts = append(artifacts, strings.TrimPrefix(oAttrs.Name, prefix))\r\n\t\ti = 0\r\n\t}\r\n\tlistElapsed := time.Since(listStart)\r\n\tlogrus.WithField(\"duration\", listElapsed).Infof(\"Listed %d artifacts.\", len(artifacts))\r\n\treturn artifacts, nil\r\n}","code-length":465,"reference":"\/\/ Artifacts lists all artifacts available for the given job source","result":"Fetch artifacts from GCS.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (src *gcsJobSource) canonicalLink() string {\r\n\treturn path.Join(src.linkPrefix, src.bucket, src.jobPrefix)\r\n}","code-length":48,"reference":"\/\/ CanonicalLink gets a link to the location of job-specific artifacts in GCS","result":"Generate the generated code.","score":[0.0337,0.0413]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (src *gcsJobSource) jobPath() string {\r\n\treturn fmt.Sprintf(\"%s\/%s\", src.bucket, src.jobPrefix)\r\n}","code-length":48,"reference":"\/\/ JobPath gets the prefix to all artifacts in GCS in the job","result":"Generate the job path.","score":[0.0476,0.155]}
{"code":"\/*is used to<extra_id_0>\r\nfunc targetURL(c config.Getter, pr *PullRequest, log *logrus.Entry) string {\r\n\tvar link string\r\n\tif tideURL := c().Tide.TargetURL; tideURL != \"\" {\r\n\t\tlink = tideURL\r\n\t} else if baseURL := c().Tide.PRStatusBaseURL; baseURL != \"\" {\r\n\t\tparseURL, err := url.Parse(baseURL)\r\n\t\tif err != nil {\r\n\t\t\tlog.WithError(err).Error(\"Failed to parse PR status base URL\")\r\n\t\t} else {\r\n\t\t\tprQuery := fmt.Sprintf(\"is:pr repo:%s author:%s head:%s\", pr.Repository.NameWithOwner, pr.Author.Login, pr.HeadRefName)\r\n\t\t\tvalues := parseURL.Query()\r\n\t\t\tvalues.Set(\"query\", prQuery)\r\n\t\t\tparseURL.RawQuery = values.Encode()\r\n\t\t\tlink = parseURL.String()\r\n\t\t}\r\n\t}\r\n\treturn link\r\n}","code-length":252,"reference":"\/\/ targetURL determines the URL used for more details in the status\n\/\/ context on GitHub. If no PR dashboard is configured, we will use\n\/\/ the administrative Prow overview.","result":"Generate the target URL.","score":[0.0005,0.0182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc newBuildConfig(cfg rest.Config, stop chan struct{}) (*buildConfig, error) {\r\n\tbc, err := buildset.NewForConfig(&cfg)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\t\r\n\t_, err = bc.BuildV1alpha1().Builds(\"\").List(metav1.ListOptions{Limit: 1})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tbif := buildinfo.NewSharedInformerFactory(bc, 30*time.Minute)\r\n\tbif.Build().V1alpha1().Builds().Lister()\r\n\tgo bif.Start(stop)\r\n\treturn &buildConfig{\r\n\t\tclient:   bc,\r\n\t\tinformer: bif.Build().V1alpha1().Builds(),\r\n\t}, nil\r\n}","code-length":221,"reference":"\/\/ newBuildConfig returns a client and informer capable of mutating and monitoring the specified config.","result":"Create a new build config.","score":[0.0387,0.0714]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewClient(token string, dryRun bool) *Client {\r\n\thttpClient := &http.Client{\r\n\t\tTransport: &oauth2.Transport{\r\n\t\t\tBase:   http.DefaultTransport,\r\n\t\t\tSource: oauth2.ReuseTokenSource(nil, oauth2.StaticTokenSource(&oauth2.Token{AccessToken: token})),\r\n\t\t},\r\n\t}\r\n\tclient := github.NewClient(httpClient)\r\n\treturn &Client{\r\n\t\tissueService:        client.Issues,\r\n\t\tprService:           client.PullRequests,\r\n\t\trepoService:         client.Repositories,\r\n\t\tuserService:         client.Users,\r\n\t\tretries:             5,\r\n\t\tretryInitialBackoff: time.Second,\r\n\t\ttokenReserve:        50,\r\n\t\tdryRun:              dryRun,\r\n\t}\r\n}","code-length":215,"reference":"\/\/ NewClient makes a new Client with the specified token and dry-run status.","result":"Create a new client.","score":[0.0476,0.155]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) retry(action string, call func() (*github.Response, error)) (*github.Response, error) {\r\n\tvar err error\r\n\tvar resp *github.Response\r\n\tfor retryCount := 0; retryCount <= c.retries; retryCount++ {\r\n\t\tif resp, err = call(); err == nil {\r\n\t\t\tc.limitRate(&resp.Rate)\r\n\t\t\treturn resp, nil\r\n\t\t}\r\n\t\tswitch err := err.(type) {\r\n\t\tcase *github.RateLimitError:\r\n\t\t\tc.limitRate(&err.Rate)\r\n\t\tcase *github.TwoFactorAuthError:\r\n\t\t\treturn resp, err\r\n\t\tcase *retryAbort:\r\n\t\t\treturn resp, err\r\n\t\t}\r\n\t\tif retryCount == c.retries {\r\n\t\t\treturn resp, err\r\n\t\t}\r\n\t\tglog.Errorf(\"error %s: %v. Will retry.\\n\", action, err)\r\n\t\tc.sleepForAttempt(retryCount)\r\n\t}\r\n\treturn resp, err\r\n}","code-length":271,"reference":"\/\/ retry handles rate limiting and retry logic for a github API call.","result":"Avoid the need for the function to be called multiple times.","score":[0.0816,0.0391]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Client) depaginate(action string, opts *github.ListOptions, call func() ([]interface{}, *github.Response, error)) ([]interface{}, error) {\r\n\tvar allItems []interface{}\r\n\twrapper := func() (*github.Response, error) {\r\n\t\titems, resp, err := call()\r\n\t\tif err == nil {\r\n\t\t\tallItems = append(allItems, items...)\r\n\t\t}\r\n\t\treturn resp, err\r\n\t}\r\n\topts.Page = 1\r\n\topts.PerPage = 100\r\n\tlastPage := 1\r\n\tfor ; opts.Page <= lastPage; opts.Page++ {\r\n\t\tresp, err := c.retry(action, wrapper)\r\n\t\tif err != nil {\r\n\t\t\treturn allItems, fmt.Errorf(\"error while depaginating page %d\/%d: %v\", opts.Page, lastPage, err)\r\n\t\t}\r\n\t\tif resp.LastPage > 0 {\r\n\t\t\tlastPage = resp.LastPage\r\n\t\t}\r\n\t}\r\n\treturn allItems, nil\r\n}","code-length":275,"reference":"\/\/ depaginate adds depagination on top of the retry and rate limiting logic provided by retry.","result":"Avoid the need for the function to be executed.","score":[0.056,0.0327]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NewHelpAgent(pa pluginAgent, ghc githubClient) *HelpAgent {\r\n\tl := logrus.WithField(\"client\", \"plugin-help\")\r\n\treturn &HelpAgent{\r\n\t\tlog: l,\r\n\t\tpa:  pa,\r\n\t\toa:  newOrgAgent(l, ghc, newRepoDetectionLimit),\r\n\t}\r\n}","code-length":97,"reference":"\/\/ NewHelpAgent constructs a new HelpAgent.","result":"Create a new help agent.","score":[0.2782,0.3178]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (ha *HelpAgent) GeneratePluginHelp() *pluginhelp.Help {\r\n\tconfig := ha.pa.Config()\r\n\torgToRepos := ha.oa.orgToReposMap(config)\r\n\tnormalRevMap, externalRevMap := reversePluginMaps(config, orgToRepos)\r\n\tallPlugins, pluginHelp := ha.generateNormalPluginHelp(config, normalRevMap)\r\n\tallExternalPlugins, externalPluginHelp := ha.generateExternalPluginHelp(config, externalRevMap)\r\n\t\r\n\trepoPlugins := map[string][]string{\r\n\t\t\"\": allPlugins,\r\n\t}\r\n\tfor repo, plugins := range config.Plugins {\r\n\t\trepoPlugins[repo] = plugins\r\n\t}\r\n\trepoExternalPlugins := map[string][]string{\r\n\t\t\"\": allExternalPlugins,\r\n\t}\r\n\tfor repo, exts := range config.ExternalPlugins {\r\n\t\tfor _, ext := range exts {\r\n\t\t\trepoExternalPlugins[repo] = append(repoExternalPlugins[repo], ext.Name)\r\n\t\t}\r\n\t}\r\n\treturn &pluginhelp.Help{\r\n\t\tAllRepos:            allRepos(config, orgToRepos),\r\n\t\tRepoPlugins:         repoPlugins,\r\n\t\tRepoExternalPlugins: repoExternalPlugins,\r\n\t\tPluginHelp:          pluginHelp,\r\n\t\tExternalPluginHelp:  externalPluginHelp,\r\n\t}\r\n}","code-length":346,"reference":"\/\/ GeneratePluginHelp compiles and returns the help information for all plugins.","result":"Generate plugin help.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getPullCommitHash(pull string) (string, error) {\r\n\tmatch := pullCommitRe.FindStringSubmatch(pull)\r\n\tif len(match) != 2 {\r\n\t\texpected := \"branch:hash,pullNumber:hash\"\r\n\t\treturn \"\", fmt.Errorf(\"unable to parse pull %q (expected %q)\", pull, expected)\r\n\t}\r\n\treturn match[1], nil\r\n}","code-length":108,"reference":"\/\/ gets the pull commit hash from metadata","result":"Parse the pull commit hash.","score":[0.2716,0.3824]}
{"code":"\/*is used to<extra_id_0>\r\nfunc listJobBuilds(bucket storageBucket, jobPrefixes []string) []jobBuilds {\r\n\tjobch := make(chan jobBuilds)\r\n\tdefer close(jobch)\r\n\tfor i, jobPrefix := range jobPrefixes {\r\n\t\tgo func(i int, jobPrefix string) {\r\n\t\t\tbuildPrefixes, err := bucket.listSubDirs(jobPrefix)\r\n\t\t\tif err != nil {\r\n\t\t\t\tlogrus.WithError(err).Warningf(\"Error getting builds for job %s\", jobPrefix)\r\n\t\t\t}\r\n\t\t\tjobch <- jobBuilds{\r\n\t\t\t\tname:          path.Base(jobPrefix),\r\n\t\t\t\tbuildPrefixes: buildPrefixes,\r\n\t\t\t}\r\n\t\t}(i, jobPrefix)\r\n\t}\r\n\tjobs := []jobBuilds{}\r\n\tfor range jobPrefixes {\r\n\t\tjob := <-jobch\r\n\t\tjobs = append(jobs, job)\r\n\t}\r\n\treturn jobs\r\n}","code-length":237,"reference":"\/\/ listJobBuilds concurrently lists builds for the given job prefixes that have been run on a PR","result":"List job builds in storage.","score":[0.0259,0.0949]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getPRBuildData(bucket storageBucket, jobs []jobBuilds) []buildData {\r\n\tbuildch := make(chan buildData)\r\n\tdefer close(buildch)\r\n\texpected := 0\r\n\tfor _, job := range jobs {\r\n\t\tfor j, buildPrefix := range job.buildPrefixes {\r\n\t\t\tgo func(j int, jobName, buildPrefix string) {\r\n\t\t\t\tbuild, err := getBuildData(bucket, buildPrefix)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\tlogrus.WithError(err).Warningf(\"build %s information incomplete\", buildPrefix)\r\n\t\t\t\t}\r\n\t\t\t\tsplit := strings.Split(strings.TrimSuffix(buildPrefix, \"\/\"), \"\/\")\r\n\t\t\t\tbuild.SpyglassLink = path.Join(spyglassPrefix, bucket.getName(), buildPrefix)\r\n\t\t\t\tbuild.ID = split[len(split)-1]\r\n\t\t\t\tbuild.jobName = jobName\r\n\t\t\t\tbuild.prefix = buildPrefix\r\n\t\t\t\tbuild.index = j\r\n\t\t\t\tbuildch <- build\r\n\t\t\t}(j, job.name, buildPrefix)\r\n\t\t\texpected++\r\n\t\t}\r\n\t}\r\n\tbuilds := []buildData{}\r\n\tfor k := 0; k < expected; k++ {\r\n\t\tbuild := <-buildch\r\n\t\tbuilds = append(builds, build)\r\n\t}\r\n\treturn builds\r\n}","code-length":341,"reference":"\/\/ getPRBuildData concurrently fetches metadata on each build of each job run on a PR","result":"Fetch build data from the PR.","score":[0.0431,0.0709]}
{"code":"\/*is used to<extra_id_0>\r\nfunc getGCSDirsForPR(config *config.Config, org, repo string, pr int) (map[string]sets.String, error) {\r\n\ttoSearch := make(map[string]sets.String)\r\n\tfullRepo := org + \"\/\" + repo\r\n\tpresubmits, ok := config.Presubmits[fullRepo]\r\n\tif !ok {\r\n\t\treturn toSearch, fmt.Errorf(\"couldn't find presubmits for %q in config\", fullRepo)\r\n\t}\r\n\tfor _, presubmit := range presubmits {\r\n\t\tvar gcsConfig *v1.GCSConfiguration\r\n\t\tif presubmit.DecorationConfig != nil && presubmit.DecorationConfig.GCSConfiguration != nil {\r\n\t\t\tgcsConfig = presubmit.DecorationConfig.GCSConfiguration\r\n\t\t} else {\r\n\t\t\t\r\n\t\t\tgcsConfig = config.Plank.DefaultDecorationConfig.GCSConfiguration\r\n\t\t}\r\n\t\tgcsPath, _, _ := gcsupload.PathsForJob(gcsConfig, &downwardapi.JobSpec{\r\n\t\t\tType: v1.PresubmitJob,\r\n\t\t\tJob:  presubmit.Name,\r\n\t\t\tRefs: &v1.Refs{\r\n\t\t\t\tRepo: repo,\r\n\t\t\t\tOrg:  org,\r\n\t\t\t\tPulls: []v1.Pull{\r\n\t\t\t\t\t{Number: pr},\r\n\t\t\t\t},\r\n\t\t\t},\r\n\t\t}, \"\")\r\n\t\tgcsPath, _ = path.Split(path.Clean(gcsPath))\r\n\t\tif _, ok := toSearch[gcsConfig.Bucket]; !ok {\r\n\t\t\ttoSearch[gcsConfig.Bucket] = sets.String{}\r\n\t\t}\r\n\t\ttoSearch[gcsConfig.Bucket].Insert(gcsPath)\r\n\t}\r\n\treturn toSearch, nil\r\n}","code-length":465,"reference":"\/\/ getGCSDirsForPR returns a map from bucket names -> set of \"directories\" containing presubmit data","result":"Generate the gcs upload paths for a PR.","score":[0.0579,0.035]}
{"code":"\/*is used to<extra_id_0>\r\nfunc imageDeleteFromDisk(fingerprint string) {\r\n\t\r\n\tfname := shared.VarPath(\"images\", fingerprint)\r\n\tif shared.PathExists(fname) {\r\n\t\terr := os.Remove(fname)\r\n\t\tif err != nil && !os.IsNotExist(err) {\r\n\t\t\tlogger.Errorf(\"Error deleting image file %s: %s\", fname, err)\r\n\t\t}\r\n\t}\r\n\t\r\n\tfname = shared.VarPath(\"images\", fingerprint) + \".rootfs\"\r\n\tif shared.PathExists(fname) {\r\n\t\terr := os.Remove(fname)\r\n\t\tif err != nil && !os.IsNotExist(err) {\r\n\t\t\tlogger.Errorf(\"Error deleting image file %s: %s\", fname, err)\r\n\t\t}\r\n\t}\r\n}","code-length":207,"reference":"\/\/ Helper to delete an image file from the local images directory.","result":"Delete image from disk.","score":[0.0514,0.1339]}
{"code":"\/*is used to<extra_id_0>\r\nfunc doNetworksCreate(d *Daemon, req api.NetworksPost, withDatabase bool) error {\r\n\t\r\n\tn, err := networkLoadByName(d.State(), req.Name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = n.Start()\r\n\tif err != nil {\r\n\t\tn.Delete(withDatabase)\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":116,"reference":"\/\/ Create the network on the system. The withDatabase flag is used to decide\n\/\/ whether to cleanup the database if an error occurs.","result":"Create a new network.","score":[0.0022,0.0227]}
{"code":"\/*is used to<extra_id_0>\r\nfunc networkLoadByName(s *state.State, name string) (*network, error) {\r\n\tid, dbInfo, err := s.Cluster.NetworkGet(name)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tn := network{state: s, id: id, name: name, description: dbInfo.Description, config: dbInfo.Config}\r\n\treturn &n, nil\r\n}","code-length":113,"reference":"\/\/ The network structs and functions","result":"Load the network by name.","score":[0.1967,0.3178]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (n *Node) Transaction(f func(*NodeTx) error) error {\r\n\tnodeTx := &NodeTx{}\r\n\treturn query.Transaction(n.db, func(tx *sql.Tx) error {\r\n\t\tnodeTx.tx = tx\r\n\t\treturn f(nodeTx)\r\n\t})\r\n}","code-length":86,"reference":"\/\/ Transaction creates a new NodeTx object and transactionally executes the\n\/\/ node-level database interactions invoked by the given function. If the\n\/\/ function returns no error, all database changes are committed to the\n\/\/ node-level database, otherwise they are rolled back.","result":"Transaction the node.","score":[0.0,0.0262]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ForLocalInspectionWithPreparedStmts(db *sql.DB) (*Cluster, error) {\r\n\tc := ForLocalInspection(db)\r\n\tstmts, err := cluster.PrepareStmts(c.db)\r\n\tif err != nil {\r\n\t\treturn nil, errors.Wrap(err, \"Prepare database statements\")\r\n\t}\r\n\tc.stmts = stmts\r\n\treturn c, nil\r\n}","code-length":107,"reference":"\/\/ ForLocalInspectionWithPreparedStmts is the same as ForLocalInspection but it\n\/\/ also prepares the statements used in auto-generated database code.","result":"Create a cluster.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) SetDefaultTimeout(timeout time.Duration) {\r\n\tdriver := c.db.Driver().(*dqlite.Driver)\r\n\tdriver.SetContextTimeout(timeout)\r\n}","code-length":57,"reference":"\/\/ SetDefaultTimeout sets the default go-dqlite driver timeout.","result":"Set the default timeout.","score":[0.1839,0.4934]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) Transaction(f func(*ClusterTx) error) error {\r\n\tc.mu.RLock()\r\n\tdefer c.mu.RUnlock()\r\n\treturn c.transaction(f)\r\n}","code-length":61,"reference":"\/\/ Transaction creates a new ClusterTx object and transactionally executes the\n\/\/ cluster database interactions invoked by the given function. If the function\n\/\/ returns no error, all database changes are committed to the cluster database\n\/\/ database, otherwise they are rolled back.\n\/\/\n\/\/ If EnterExclusive has been called before, calling Transaction will block\n\/\/ until ExitExclusive has been called as well to release the lock.","result":"Avoid recursive calls.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) EnterExclusive() error {\r\n\tlogger.Debug(\"Acquiring exclusive lock on cluster db\")\r\n\tch := make(chan struct{})\r\n\tgo func() {\r\n\t\tc.mu.Lock()\r\n\t\tch <- struct{}{}\r\n\t}()\r\n\ttimeout := 20 * time.Second\r\n\tselect {\r\n\tcase <-ch:\r\n\t\treturn nil\r\n\tcase <-time.After(timeout):\r\n\t\treturn fmt.Errorf(\"timeout (%s)\", timeout)\r\n\t}\r\n}","code-length":140,"reference":"\/\/ EnterExclusive acquires a lock on the cluster db, so any successive call to\n\/\/ Transaction will block until ExitExclusive has been called.","result":"Enter exclusive lock on cluster db.","score":[0.0178,0.12]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ExitExclusive(f func(*ClusterTx) error) error {\r\n\tlogger.Debug(\"Releasing exclusive lock on cluster db\")\r\n\tdefer c.mu.Unlock()\r\n\treturn c.transaction(f)\r\n}","code-length":66,"reference":"\/\/ ExitExclusive runs the given transaction and then releases the lock acquired\n\/\/ with EnterExclusive.","result":"Avoid recursive call to the function.","score":[0.0431,0.0355]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) Close() error {\r\n\tfor _, stmt := range c.stmts {\r\n\t\tstmt.Close()\r\n\t}\r\n\treturn c.db.Close()\r\n}","code-length":57,"reference":"\/\/ Close the database facade.","result":"Close the cluster.","score":[0.2964,0.3906]}
{"code":"\/*is used to<extra_id_0>\r\nfunc TxCommit(tx *sql.Tx) error {\r\n\terr := tx.Commit()\r\n\tif err == nil || err == sql.ErrTxDone {\r\n\t\treturn nil\r\n\t}\r\n\treturn err\r\n}","code-length":64,"reference":"\/\/ TxCommit commits the given transaction.","result":"Commit the transaction.","score":[0.1786,0.4483]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) ParseRemote(raw string) (string, string, error) {\r\n\tresult := strings.SplitN(raw, \":\", 2)\r\n\tif len(result) == 1 {\r\n\t\treturn c.DefaultRemote, raw, nil\r\n\t}\r\n\t_, ok := c.Remotes[result[0]]\r\n\tif !ok {\r\n\t\t\r\n\t\tif shared.IsSnapshot(raw) && shared.IsSnapshot(result[0]) {\r\n\t\t\treturn c.DefaultRemote, raw, nil\r\n\t\t}\r\n\t\treturn \"\", \"\", fmt.Errorf(\"The remote \\\"%s\\\" doesn't exist\", result[0])\r\n\t}\r\n\treturn result[0], result[1], nil\r\n}","code-length":184,"reference":"\/\/ ParseRemote splits remote and object","result":"Parse the remote name and the remote.","score":[0.1921,0.1639]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) GetContainerServer(name string) (lxd.ContainerServer, error) {\r\n\t\r\n\tremote, ok := c.Remotes[name]\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"The remote \\\"%s\\\" doesn't exist\", name)\r\n\t}\r\n\t\r\n\tif remote.Public || remote.Protocol == \"simplestreams\" {\r\n\t\treturn nil, fmt.Errorf(\"The remote isn't a private LXD server\")\r\n\t}\r\n\t\r\n\targs, err := c.getConnectionArgs(name)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tif strings.HasPrefix(remote.Addr, \"unix:\") {\r\n\t\td, err := lxd.ConnectLXDUnix(strings.TrimPrefix(strings.TrimPrefix(remote.Addr, \"unix:\"), \"\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tif remote.Project != \"\" && remote.Project != \"default\" {\r\n\t\t\td = d.UseProject(remote.Project)\r\n\t\t}\r\n\t\tif c.ProjectOverride != \"\" {\r\n\t\t\td = d.UseProject(c.ProjectOverride)\r\n\t\t}\r\n\t\treturn d, nil\r\n\t}\r\n\t\r\n\tif remote.AuthType != \"candid\" && (args.TLSClientCert == \"\" || args.TLSClientKey == \"\") {\r\n\t\treturn nil, fmt.Errorf(\"Missing TLS client certificate and key\")\r\n\t}\r\n\td, err := lxd.ConnectLXD(remote.Addr, args)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif remote.Project != \"\" && remote.Project != \"default\" {\r\n\t\td = d.UseProject(remote.Project)\r\n\t}\r\n\tif c.ProjectOverride != \"\" {\r\n\t\td = d.UseProject(c.ProjectOverride)\r\n\t}\r\n\treturn d, nil\r\n}","code-length":504,"reference":"\/\/ GetContainerServer returns a ContainerServer struct for the remote","result":"Get the container server from the config.","score":[0.1214,0.0568]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Config) GetImageServer(name string) (lxd.ImageServer, error) {\r\n\t\r\n\tremote, ok := c.Remotes[name]\r\n\tif !ok {\r\n\t\treturn nil, fmt.Errorf(\"The remote \\\"%s\\\" doesn't exist\", name)\r\n\t}\r\n\t\r\n\targs, err := c.getConnectionArgs(name)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tif strings.HasPrefix(remote.Addr, \"unix:\") {\r\n\t\td, err := lxd.ConnectLXDUnix(strings.TrimPrefix(strings.TrimPrefix(remote.Addr, \"unix:\"), \"\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tif remote.Project != \"\" && remote.Project != \"default\" {\r\n\t\t\td = d.UseProject(remote.Project)\r\n\t\t}\r\n\t\tif c.ProjectOverride != \"\" {\r\n\t\t\td = d.UseProject(c.ProjectOverride)\r\n\t\t}\r\n\t\treturn d, nil\r\n\t}\r\n\t\r\n\tif remote.Protocol == \"simplestreams\" {\r\n\t\td, err := lxd.ConnectSimpleStreams(remote.Addr, args)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn d, nil\r\n\t}\r\n\t\r\n\tif remote.Public {\r\n\t\td, err := lxd.ConnectPublicLXD(remote.Addr, args)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn d, nil\r\n\t}\r\n\t\r\n\td, err := lxd.ConnectLXD(remote.Addr, args)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tif remote.Project != \"\" && remote.Project != \"default\" {\r\n\t\td = d.UseProject(remote.Project)\r\n\t}\r\n\tif c.ProjectOverride != \"\" {\r\n\t\td = d.UseProject(c.ProjectOverride)\r\n\t}\r\n\treturn d, nil\r\n}","code-length":543,"reference":"\/\/ GetImageServer returns a ImageServer struct for the remote","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (s *OS) initAppArmor() {\r\n\t\r\n\t_, err := exec.LookPath(\"apparmor_parser\")\r\n\tif os.Getenv(\"LXD_SECURITY_APPARMOR\") == \"false\" {\r\n\t\tlogger.Warnf(\"AppArmor support has been manually disabled\")\r\n\t} else if !shared.IsDir(\"\/sys\/kernel\/security\/apparmor\") {\r\n\t\tlogger.Warnf(\"AppArmor support has been disabled because of lack of kernel support\")\r\n\t} else if err != nil {\r\n\t\tlogger.Warnf(\"AppArmor support has been disabled because 'apparmor_parser' couldn't be found\")\r\n\t} else {\r\n\t\ts.AppArmorAvailable = true\r\n\t}\r\n\t\r\n\ts.AppArmorStacking = appArmorCanStack()\r\n\t\r\n\tif shared.PathExists(\"\/sys\/kernel\/security\/apparmor\/.ns_stacked\") {\r\n\t\tcontentBytes, err := ioutil.ReadFile(\"\/sys\/kernel\/security\/apparmor\/.ns_stacked\")\r\n\t\tif err == nil && string(contentBytes) == \"yes\\n\" {\r\n\t\t\ts.AppArmorStacked = true\r\n\t\t}\r\n\t}\r\n\t\r\n\tif !haveMacAdmin() {\r\n\t\tif s.AppArmorAvailable {\r\n\t\t\tlogger.Warnf(\"Per-container AppArmor profiles are disabled because the mac_admin capability is missing\")\r\n\t\t}\r\n\t} else if s.RunningInUserNS && !s.AppArmorStacked {\r\n\t\tif s.AppArmorAvailable {\r\n\t\t\tlogger.Warnf(\"Per-container AppArmor profiles are disabled because LXD is running in an unprivileged container without stacking\")\r\n\t\t}\r\n\t} else {\r\n\t\ts.AppArmorAdmin = true\r\n\t}\r\n\t\r\n\tprofile := util.AppArmorProfile()\r\n\tif profile != \"unconfined\" && profile != \"\" {\r\n\t\tif s.AppArmorAvailable {\r\n\t\t\tlogger.Warnf(\"Per-container AppArmor profiles are disabled because LXD is already protected by AppArmor\")\r\n\t\t}\r\n\t\ts.AppArmorConfined = true\r\n\t}\r\n}","code-length":569,"reference":"\/\/ Initialize AppArmor-specific attributes.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc appArmorCanStack() bool {\r\n\tcontentBytes, err := ioutil.ReadFile(\"\/sys\/kernel\/security\/apparmor\/features\/domain\/stack\")\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\tif string(contentBytes) != \"yes\\n\" {\r\n\t\treturn false\r\n\t}\r\n\tcontentBytes, err = ioutil.ReadFile(\"\/sys\/kernel\/security\/apparmor\/features\/domain\/version\")\r\n\tif err != nil {\r\n\t\treturn false\r\n\t}\r\n\tcontent := string(contentBytes)\r\n\tparts := strings.Split(strings.TrimSpace(content), \".\")\r\n\tif len(parts) == 0 {\r\n\t\tlogger.Warn(\"Unknown apparmor domain version\", log.Ctx{\"version\": content})\r\n\t\treturn false\r\n\t}\r\n\tmajor, err := strconv.Atoi(parts[0])\r\n\tif err != nil {\r\n\t\tlogger.Warn(\"Unknown apparmor domain version\", log.Ctx{\"version\": content})\r\n\t\treturn false\r\n\t}\r\n\tminor := 0\r\n\tif len(parts) == 2 {\r\n\t\tminor, err = strconv.Atoi(parts[1])\r\n\t\tif err != nil {\r\n\t\t\tlogger.Warn(\"Unknown apparmor domain version\", log.Ctx{\"version\": content})\r\n\t\t\treturn false\r\n\t\t}\r\n\t}\r\n\treturn major >= 1 && minor >= 2\r\n}","code-length":366,"reference":"\/\/ Returns true if AppArmor stacking support is available.","result":"Check if the domain can stack .","score":[0.1214,0.1136]}
{"code":"\/*is used to<extra_id_0>\r\nfunc containerDeviceAdd(client lxd.ContainerServer, name string, devName string, dev map[string]string) error {\r\n\t\r\n\tcontainer, etag, err := client.GetContainer(name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t_, ok := container.Devices[devName]\r\n\tif ok {\r\n\t\treturn fmt.Errorf(i18n.G(\"Device already exists: %s\"), devName)\r\n\t}\r\n\tcontainer.Devices[devName] = dev\r\n\top, err := client.UpdateContainer(name, container.Writable(), etag)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn op.Wait()\r\n}","code-length":188,"reference":"\/\/ Add a device to a container","result":"Add a new device to a container.","score":[0.4061,0.6914]}
{"code":"\/*is used to<extra_id_0>\r\nfunc profileDeviceAdd(client lxd.ContainerServer, name string, devName string, dev map[string]string) error {\r\n\t\r\n\tprofile, profileEtag, err := client.GetProfile(name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t_, ok := profile.Devices[devName]\r\n\tif ok {\r\n\t\treturn fmt.Errorf(i18n.G(\"Device already exists: %s\"), devName)\r\n\t}\r\n\t\r\n\tprofile.Devices[devName] = dev\r\n\terr = client.UpdateProfile(name, profile.Writable(), profileEtag)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":190,"reference":"\/\/ Add a device to a profile","result":"Add a new profile device.","score":[0.2521,0.2206]}
{"code":"\/*is used to<extra_id_0>\r\nfunc ensureImageAliases(client lxd.ContainerServer, aliases []api.ImageAlias, fingerprint string) error {\r\n\tif len(aliases) == 0 {\r\n\t\treturn nil\r\n\t}\r\n\tnames := make([]string, len(aliases))\r\n\tfor i, alias := range aliases {\r\n\t\tnames[i] = alias.Name\r\n\t}\r\n\tsort.Strings(names)\r\n\tresp, err := client.GetImageAliases()\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tfor _, alias := range GetExistingAliases(names, resp) {\r\n\t\terr := client.DeleteImageAlias(alias.Name)\r\n\t\tif err != nil {\r\n\t\t\tfmt.Println(fmt.Sprintf(i18n.G(\"Failed to remove alias %s\"), alias.Name))\r\n\t\t}\r\n\t}\r\n\t\r\n\tfor _, alias := range aliases {\r\n\t\taliasPost := api.ImageAliasesPost{}\r\n\t\taliasPost.Name = alias.Name\r\n\t\taliasPost.Target = fingerprint\r\n\t\terr := client.CreateImageAlias(aliasPost)\r\n\t\tif err != nil {\r\n\t\t\tfmt.Println(fmt.Sprintf(i18n.G(\"Failed to create alias %s\"), alias.Name))\r\n\t\t}\r\n\t}\r\n\treturn nil\r\n}","code-length":344,"reference":"\/\/ Create the specified image alises, updating those that already exist","result":"Ensure that the image alias fingerprint is valid.","score":[0.1256,0.1869]}
{"code":"\/*is used to<extra_id_0>\r\nfunc GetExistingAliases(aliases []string, allAliases []api.ImageAliasesEntry) []api.ImageAliasesEntry {\r\n\texisting := []api.ImageAliasesEntry{}\r\n\tfor _, alias := range allAliases {\r\n\t\tname := alias.Name\r\n\t\tpos := sort.SearchStrings(aliases, name)\r\n\t\tif pos < len(aliases) && aliases[pos] == name {\r\n\t\t\texisting = append(existing, alias)\r\n\t\t}\r\n\t}\r\n\treturn existing\r\n}","code-length":130,"reference":"\/\/ GetExistingAliases returns the intersection between a list of aliases and all the existing ones.","result":"Filter the aliases.","score":[0.0075,0.0362]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (o StatusCode) String() string {\r\n\treturn map[StatusCode]string{\r\n\t\tOperationCreated: \"Operation created\",\r\n\t\tStarted:          \"Started\",\r\n\t\tStopped:          \"Stopped\",\r\n\t\tRunning:          \"Running\",\r\n\t\tCancelling:       \"Cancelling\",\r\n\t\tPending:          \"Pending\",\r\n\t\tSuccess:          \"Success\",\r\n\t\tFailure:          \"Failure\",\r\n\t\tCancelled:        \"Cancelled\",\r\n\t\tStarting:         \"Starting\",\r\n\t\tStopping:         \"Stopping\",\r\n\t\tAborting:         \"Aborting\",\r\n\t\tFreezing:         \"Freezing\",\r\n\t\tFrozen:           \"Frozen\",\r\n\t\tThawed:           \"Thawed\",\r\n\t\tError:            \"Error\",\r\n\t}[o]\r\n}","code-length":214,"reference":"\/\/ String returns a suitable string representation for the status code","result":"Operation created.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImagesGetExpired(expiry int64) ([]string, error) {\r\n\tq := `SELECT fingerprint, last_use_date, upload_date FROM images WHERE cached=1`\r\n\tvar fpStr string\r\n\tvar useStr string\r\n\tvar uploadStr string\r\n\tinargs := []interface{}{}\r\n\toutfmt := []interface{}{fpStr, useStr, uploadStr}\r\n\tdbResults, err := queryScan(c.db, q, inargs, outfmt)\r\n\tif err != nil {\r\n\t\treturn []string{}, err\r\n\t}\r\n\tresults := []string{}\r\n\tfor _, r := range dbResults {\r\n\t\t\r\n\t\ttimestamp := r[2]\r\n\t\tif r[1] != \"\" {\r\n\t\t\ttimestamp = r[1]\r\n\t\t}\r\n\t\tvar imageExpiry time.Time\r\n\t\terr = imageExpiry.UnmarshalText([]byte(timestamp.(string)))\r\n\t\tif err != nil {\r\n\t\t\treturn []string{}, err\r\n\t\t}\r\n\t\timageExpiry = imageExpiry.Add(time.Duration(expiry*24) * time.Hour)\r\n\t\t\r\n\t\tif imageExpiry.After(time.Now()) {\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tresults = append(results, r[0].(string))\r\n\t}\r\n\treturn results, nil\r\n}","code-length":348,"reference":"\/\/ ImagesGetExpired returns the names of all images that have expired since the\n\/\/ given time.","result":"Generate the generated code.","score":[0.0159,0.0338]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageSourceInsert(id int, server string, protocol string, certificate string, alias string) error {\r\n\tstmt := `INSERT INTO images_source (image_id, server, protocol, certificate, alias) values (?, ?, ?, ?, ?)`\r\n\tprotocolInt := -1\r\n\tfor protoInt, protoString := range ImageSourceProtocol {\r\n\t\tif protoString == protocol {\r\n\t\t\tprotocolInt = protoInt\r\n\t\t}\r\n\t}\r\n\tif protocolInt == -1 {\r\n\t\treturn fmt.Errorf(\"Invalid protocol: %s\", protocol)\r\n\t}\r\n\terr := exec(c.db, stmt, id, server, protocolInt, certificate, alias)\r\n\treturn err\r\n}","code-length":182,"reference":"\/\/ ImageSourceInsert inserts a new image source.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageSourceGet(imageID int) (int, api.ImageSource, error) {\r\n\tq := `SELECT id, server, protocol, certificate, alias FROM images_source WHERE image_id=?`\r\n\tid := 0\r\n\tprotocolInt := -1\r\n\tresult := api.ImageSource{}\r\n\targ1 := []interface{}{imageID}\r\n\targ2 := []interface{}{&id, &result.Server, &protocolInt, &result.Certificate, &result.Alias}\r\n\terr := dbQueryRowScan(c.db, q, arg1, arg2)\r\n\tif err != nil {\r\n\t\tif err == sql.ErrNoRows {\r\n\t\t\treturn -1, api.ImageSource{}, ErrNoSuchObject\r\n\t\t}\r\n\t\treturn -1, api.ImageSource{}, err\r\n\t}\r\n\tprotocol, found := ImageSourceProtocol[protocolInt]\r\n\tif !found {\r\n\t\treturn -1, api.ImageSource{}, fmt.Errorf(\"Invalid protocol: %d\", protocolInt)\r\n\t}\r\n\tresult.Protocol = protocol\r\n\treturn id, result, nil\r\n}","code-length":285,"reference":"\/\/ ImageSourceGet returns the image source with the given ID.","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageExists(project string, fingerprint string) (bool, error) {\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tenabled, err := tx.ProjectHasImages(project)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Check if project has images\")\r\n\t\t}\r\n\t\tif !enabled {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\tvar exists bool\r\n\tquery := `\r\nSELECT COUNT(*) > 0\r\n  FROM images\r\n  JOIN projects ON projects.id = images.project_id\r\n WHERE projects.name = ? AND fingerprint=?\r\n`\r\n\tinargs := []interface{}{project, fingerprint}\r\n\toutargs := []interface{}{&exists}\r\n\terr = dbQueryRowScan(c.db, query, inargs, outargs)\r\n\tif err == sql.ErrNoRows {\r\n\t\treturn exists, ErrNoSuchObject\r\n\t}\r\n\treturn exists, err\r\n}","code-length":286,"reference":"\/\/ ImageExists returns whether an image with the given fingerprint exists.","result":"Check if an image exists in the project .","score":[0.1527,0.2366]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageGet(project, fingerprint string, public bool, strictMatching bool) (int, *api.Image, error) {\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tenabled, err := tx.ProjectHasImages(project)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Check if project has images\")\r\n\t\t}\r\n\t\tif !enabled {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn -1, nil, err\r\n\t}\r\n\tvar create, expire, used, upload *time.Time\r\n\t\r\n\timage := api.Image{}\r\n\tid := -1\r\n\tarch := -1\r\n\t\r\n\toutfmt := []interface{}{&id, &image.Fingerprint, &image.Filename,\r\n\t\t&image.Size, &image.Cached, &image.Public, &image.AutoUpdate, &arch,\r\n\t\t&create, &expire, &used, &upload}\r\n\tinargs := []interface{}{project}\r\n\tquery := `\r\n        SELECT\r\n            images.id, fingerprint, filename, size, cached, public, auto_update, architecture,\r\n            creation_date, expiry_date, last_use_date, upload_date\r\n        FROM images\r\n        JOIN projects ON projects.id = images.project_id\r\n       WHERE projects.name = ?`\r\n\tif strictMatching {\r\n\t\tinargs = append(inargs, fingerprint)\r\n\t\tquery += \" AND fingerprint = ?\"\r\n\t} else {\r\n\t\tinargs = append(inargs, fingerprint+\"%\")\r\n\t\tquery += \" AND fingerprint LIKE ?\"\r\n\t}\r\n\tif public {\r\n\t\tquery += \" AND public=1\"\r\n\t}\r\n\terr = dbQueryRowScan(c.db, query, inargs, outfmt)\r\n\tif err != nil {\r\n\t\tif err == sql.ErrNoRows {\r\n\t\t\treturn -1, nil, ErrNoSuchObject\r\n\t\t}\r\n\t\treturn -1, nil, err\r\n\t}\r\n\t\r\n\tif !strictMatching {\r\n\t\tquery = `\r\nSELECT COUNT(images.id)\r\n  FROM images\r\n  JOIN projects ON projects.id = images.project_id\r\n WHERE projects.name = ?\r\n   AND fingerprint LIKE ?\r\n`\r\n\t\tcount := 0\r\n\t\toutfmt := []interface{}{&count}\r\n\t\terr = dbQueryRowScan(c.db, query, inargs, outfmt)\r\n\t\tif err != nil {\r\n\t\t\treturn -1, nil, err\r\n\t\t}\r\n\t\tif count > 1 {\r\n\t\t\treturn -1, nil, fmt.Errorf(\"Partial fingerprint matches more than one image\")\r\n\t\t}\r\n\t}\r\n\terr = c.imageFill(id, &image, create, expire, used, upload, arch)\r\n\tif err != nil {\r\n\t\treturn -1, nil, errors.Wrapf(err, \"Fill image details\")\r\n\t}\r\n\treturn id, &image, nil\r\n}","code-length":781,"reference":"\/\/ ImageGet gets an Image object from the database.\n\/\/ If strictMatching is false, The fingerprint argument will be queried with a LIKE query, means you can\n\/\/ pass a shortform and will get the full fingerprint.\n\/\/ There can never be more than one image with a given fingerprint, as it is\n\/\/ enforced by a UNIQUE constraint in the schema.","result":"Code too long,keep in 512.","score":[0.0,0.0089]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageGetFromAnyProject(fingerprint string) (int, *api.Image, error) {\r\n\tvar create, expire, used, upload *time.Time\r\n\t\r\n\timage := api.Image{}\r\n\tid := -1\r\n\tarch := -1\r\n\t\r\n\toutfmt := []interface{}{&id, &image.Fingerprint, &image.Filename,\r\n\t\t&image.Size, &image.Cached, &image.Public, &image.AutoUpdate, &arch,\r\n\t\t&create, &expire, &used, &upload}\r\n\tinargs := []interface{}{fingerprint}\r\n\tquery := `\r\n        SELECT\r\n            images.id, fingerprint, filename, size, cached, public, auto_update, architecture,\r\n            creation_date, expiry_date, last_use_date, upload_date\r\n        FROM images\r\n        WHERE fingerprint = ?\r\n        LIMIT 1`\r\n\terr := dbQueryRowScan(c.db, query, inargs, outfmt)\r\n\tif err != nil {\r\n\t\tif err == sql.ErrNoRows {\r\n\t\t\treturn -1, nil, ErrNoSuchObject\r\n\t\t}\r\n\t\treturn -1, nil, err\r\n\t}\r\n\terr = c.imageFill(id, &image, create, expire, used, upload, arch)\r\n\tif err != nil {\r\n\t\treturn -1, nil, errors.Wrapf(err, \"Fill image details\")\r\n\t}\r\n\treturn id, &image, nil\r\n}","code-length":377,"reference":"\/\/ ImageGetFromAnyProject returns an image matching the given fingerprint, if\n\/\/ it exists in any project.","result":"Fetch image details from cluster.","score":[0.0266,0.0336]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) imageFill(id int, image *api.Image, create, expire, used, upload *time.Time, arch int) error {\r\n\t\r\n\tif create != nil {\r\n\t\timage.CreatedAt = *create\r\n\t} else {\r\n\t\timage.CreatedAt = time.Time{}\r\n\t}\r\n\tif expire != nil {\r\n\t\timage.ExpiresAt = *expire\r\n\t} else {\r\n\t\timage.ExpiresAt = time.Time{}\r\n\t}\r\n\tif used != nil {\r\n\t\timage.LastUsedAt = *used\r\n\t} else {\r\n\t\timage.LastUsedAt = time.Time{}\r\n\t}\r\n\timage.Architecture, _ = osarch.ArchitectureName(arch)\r\n\t\r\n\timage.UploadedAt = *upload\r\n\t\r\n\tq := \"SELECT key, value FROM images_properties where image_id=?\"\r\n\tvar key, value, name, desc string\r\n\tinargs := []interface{}{id}\r\n\toutfmt := []interface{}{key, value}\r\n\tresults, err := queryScan(c.db, q, inargs, outfmt)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tproperties := map[string]string{}\r\n\tfor _, r := range results {\r\n\t\tkey = r[0].(string)\r\n\t\tvalue = r[1].(string)\r\n\t\tproperties[key] = value\r\n\t}\r\n\timage.Properties = properties\r\n\t\r\n\tq = \"SELECT name, description FROM images_aliases WHERE image_id=?\"\r\n\tinargs = []interface{}{id}\r\n\toutfmt = []interface{}{name, desc}\r\n\tresults, err = queryScan(c.db, q, inargs, outfmt)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\taliases := []api.ImageAlias{}\r\n\tfor _, r := range results {\r\n\t\tname = r[0].(string)\r\n\t\tdesc = r[1].(string)\r\n\t\ta := api.ImageAlias{Name: name, Description: desc}\r\n\t\taliases = append(aliases, a)\r\n\t}\r\n\timage.Aliases = aliases\r\n\t_, source, err := c.ImageSourceGet(id)\r\n\tif err == nil {\r\n\t\timage.UpdateSource = &source\r\n\t}\r\n\treturn nil\r\n}","code-length":602,"reference":"\/\/ Fill extra image fields such as properties and alias. This is called after\n\/\/ fetching a single row from the images table.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageLocate(fingerprint string) (string, error) {\r\n\tstmt := `\r\nSELECT nodes.address FROM nodes\r\n  LEFT JOIN images_nodes ON images_nodes.node_id = nodes.id\r\n  LEFT JOIN images ON images_nodes.image_id = images.id\r\nWHERE images.fingerprint = ?\r\n`\r\n\tvar localAddress string\r\n\tvar addresses []string\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tofflineThreshold, err := tx.NodeOfflineThreshold()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tlocalAddress, err = tx.NodeAddress()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tallAddresses, err := query.SelectStrings(tx.tx, stmt, fingerprint)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tfor _, address := range allAddresses {\r\n\t\t\tnode, err := tx.NodeByAddress(address)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tif address != localAddress && node.IsOffline(offlineThreshold) {\r\n\t\t\t\tcontinue\r\n\t\t\t}\r\n\t\t\taddresses = append(addresses, address)\r\n\t\t}\r\n\t\treturn err\r\n\t})\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\tif len(addresses) == 0 {\r\n\t\treturn \"\", fmt.Errorf(\"image not available on any online node\")\r\n\t}\r\n\tfor _, address := range addresses {\r\n\t\tif address == localAddress {\r\n\t\t\treturn \"\", nil\r\n\t\t}\r\n\t}\r\n\treturn addresses[0], nil\r\n}","code-length":440,"reference":"\/\/ ImageLocate returns the address of an online node that has a local copy of\n\/\/ the given image, or an empty string if the image is already available on this\n\/\/ node.\n\/\/\n\/\/ If the image is not available on any online node, an error is returned.","result":"Fetch the image from the database.","score":[0.0002,0.0336]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageAssociateNode(project, fingerprint string) error {\r\n\timageID, _, err := c.ImageGet(project, fingerprint, false, true)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = c.Transaction(func(tx *ClusterTx) error {\r\n\t\t_, err := tx.tx.Exec(\"INSERT INTO images_nodes(image_id, node_id) VALUES(?, ?)\", imageID, c.nodeID)\r\n\t\treturn err\r\n\t})\r\n\treturn err\r\n}","code-length":145,"reference":"\/\/ ImageAssociateNode creates a new entry in the images_nodes table for\n\/\/ tracking that the current node has the given image.","result":"Create a new node in the cluster.","score":[0.043,0.2608]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageDelete(id int) error {\r\n\terr := exec(c.db, \"DELETE FROM images WHERE id=?\", id)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":70,"reference":"\/\/ ImageDelete deletes the image with the given ID.","result":"Delete the image from.","score":[0.1294,0.1765]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageAliasesGet(project string) ([]string, error) {\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tenabled, err := tx.ProjectHasImages(project)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Check if project has images\")\r\n\t\t}\r\n\t\tif !enabled {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tq := `\r\nSELECT images_aliases.name\r\n  FROM images_aliases\r\n  JOIN projects ON projects.id=images_aliases.project_id\r\n WHERE projects.name=?\r\n`\r\n\tvar name string\r\n\tinargs := []interface{}{project}\r\n\toutfmt := []interface{}{name}\r\n\tresults, err := queryScan(c.db, q, inargs, outfmt)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tnames := []string{}\r\n\tfor _, res := range results {\r\n\t\tnames = append(names, res[0].(string))\r\n\t}\r\n\treturn names, nil\r\n}","code-length":317,"reference":"\/\/ ImageAliasesGet returns the names of the aliases of all images.","result":"Generate the generated code.","score":[0.0555,0.0485]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageAliasGet(project, name string, isTrustedClient bool) (int, api.ImageAliasesEntry, error) {\r\n\tid := -1\r\n\tentry := api.ImageAliasesEntry{}\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tenabled, err := tx.ProjectHasImages(project)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Check if project has images\")\r\n\t\t}\r\n\t\tif !enabled {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn id, entry, err\r\n\t}\r\n\tq := `SELECT images_aliases.id, images.fingerprint, images_aliases.description\r\n\t\t\t FROM images_aliases\r\n\t\t\t INNER JOIN images\r\n\t\t\t ON images_aliases.image_id=images.id\r\n                         INNER JOIN projects\r\n                         ON images_aliases.project_id=projects.id\r\n\t\t\t WHERE projects.name=? AND images_aliases.name=?`\r\n\tif !isTrustedClient {\r\n\t\tq = q + ` AND images.public=1`\r\n\t}\r\n\tvar fingerprint, description string\r\n\targ1 := []interface{}{project, name}\r\n\targ2 := []interface{}{&id, &fingerprint, &description}\r\n\terr = dbQueryRowScan(c.db, q, arg1, arg2)\r\n\tif err != nil {\r\n\t\tif err == sql.ErrNoRows {\r\n\t\t\treturn -1, entry, ErrNoSuchObject\r\n\t\t}\r\n\t\treturn -1, entry, err\r\n\t}\r\n\tentry.Name = name\r\n\tentry.Target = fingerprint\r\n\tentry.Description = description\r\n\treturn id, entry, nil\r\n}","code-length":448,"reference":"\/\/ ImageAliasGet returns the alias with the given name in the given project.","result":"Fetch the image alias information.","score":[0.0577,0.082]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageAliasRename(id int, name string) error {\r\n\terr := exec(c.db, \"UPDATE images_aliases SET name=? WHERE id=?\", name, id)\r\n\treturn err\r\n}","code-length":62,"reference":"\/\/ ImageAliasRename renames the alias with the given ID.","result":"Rename alias in cluster.","score":[0.0915,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageAliasDelete(project, name string) error {\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tenabled, err := tx.ProjectHasImages(project)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Check if project has images\")\r\n\t\t}\r\n\t\tif !enabled {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = exec(c.db, `\r\nDELETE\r\n  FROM images_aliases\r\n WHERE project_id = (SELECT id FROM projects WHERE name = ?) AND name = ?\r\n`, project, name)\r\n\treturn err\r\n}","code-length":200,"reference":"\/\/ ImageAliasDelete deletes the alias with the given name.","result":"Delete the image alias.","score":[0.0915,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageAliasesMove(source int, destination int) error {\r\n\terr := exec(c.db, \"UPDATE images_aliases SET image_id=? WHERE image_id=?\", destination, source)\r\n\treturn err\r\n}","code-length":66,"reference":"\/\/ ImageAliasesMove changes the image ID associated with an alias.","result":"Move images aliases.","score":[0,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageAliasAdd(project, name string, imageID int, desc string) error {\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tenabled, err := tx.ProjectHasImages(project)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Check if project has images\")\r\n\t\t}\r\n\t\tif !enabled {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tstmt := `\r\nINSERT INTO images_aliases (name, image_id, description, project_id)\r\n     VALUES (?, ?, ?, (SELECT id FROM projects WHERE name = ?))\r\n`\r\n\terr = exec(c.db, stmt, name, imageID, desc, project)\r\n\treturn err\r\n}","code-length":226,"reference":"\/\/ ImageAliasAdd inserts an alias ento the database.","result":"Add an image alias to a project.","score":[0.1665,0.1266]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageAliasUpdate(id int, imageID int, desc string) error {\r\n\tstmt := `UPDATE images_aliases SET image_id=?, description=? WHERE id=?`\r\n\terr := exec(c.db, stmt, imageID, desc, id)\r\n\treturn err\r\n}","code-length":81,"reference":"\/\/ ImageAliasUpdate updates the alias with the given ID.","result":"Update the image alias in cluster.","score":[0.1392,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageLastAccessUpdate(fingerprint string, date time.Time) error {\r\n\tstmt := `UPDATE images SET last_use_date=? WHERE fingerprint=?`\r\n\terr := exec(c.db, stmt, date, fingerprint)\r\n\treturn err\r\n}","code-length":74,"reference":"\/\/ ImageLastAccessUpdate updates the last_use_date field of the image with the\n\/\/ given fingerprint.","result":"Update image last.","score":[0.0104,0.0775]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageLastAccessInit(fingerprint string) error {\r\n\tstmt := `UPDATE images SET cached=1, last_use_date=strftime(\"%s\") WHERE fingerprint=?`\r\n\terr := exec(c.db, stmt, fingerprint)\r\n\treturn err\r\n}","code-length":76,"reference":"\/\/ImageLastAccessInit inits the last_use_date field of the image with the given fingerprint.","result":"Initialize image last access.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageUpdate(id int, fname string, sz int64, public bool, autoUpdate bool, architecture string, createdAt time.Time, expiresAt time.Time, properties map[string]string) error {\r\n\tarch, err := osarch.ArchitectureId(architecture)\r\n\tif err != nil {\r\n\t\tarch = 0\r\n\t}\r\n\terr = c.Transaction(func(tx *ClusterTx) error {\r\n\t\tpublicInt := 0\r\n\t\tif public {\r\n\t\t\tpublicInt = 1\r\n\t\t}\r\n\t\tautoUpdateInt := 0\r\n\t\tif autoUpdate {\r\n\t\t\tautoUpdateInt = 1\r\n\t\t}\r\n\t\tstmt, err := tx.tx.Prepare(`UPDATE images SET filename=?, size=?, public=?, auto_update=?, architecture=?, creation_date=?, expiry_date=? WHERE id=?`)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdefer stmt.Close()\r\n\t\t_, err = stmt.Exec(fname, sz, publicInt, autoUpdateInt, arch, createdAt, expiresAt, id)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t_, err = tx.tx.Exec(`DELETE FROM images_properties WHERE image_id=?`, id)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tstmt2, err := tx.tx.Prepare(`INSERT INTO images_properties (image_id, type, key, value) VALUES (?, ?, ?, ?)`)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdefer stmt2.Close()\r\n\t\tfor key, value := range properties {\r\n\t\t\t_, err = stmt2.Exec(id, 0, key, value)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\treturn err\r\n}","code-length":494,"reference":"\/\/ ImageUpdate updates the image with the given ID.","result":"Update the properties of an image.","score":[0.1171,0.1149]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageInsert(project, fp string, fname string, sz int64, public bool, autoUpdate bool, architecture string, createdAt time.Time, expiresAt time.Time, properties map[string]string) error {\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tenabled, err := tx.ProjectHasImages(project)\r\n\t\tif err != nil {\r\n\t\t\treturn errors.Wrap(err, \"Check if project has images\")\r\n\t\t}\r\n\t\tif !enabled {\r\n\t\t\tproject = \"default\"\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tarch, err := osarch.ArchitectureId(architecture)\r\n\tif err != nil {\r\n\t\tarch = 0\r\n\t}\r\n\terr = c.Transaction(func(tx *ClusterTx) error {\r\n\t\tpublicInt := 0\r\n\t\tif public {\r\n\t\t\tpublicInt = 1\r\n\t\t}\r\n\t\tautoUpdateInt := 0\r\n\t\tif autoUpdate {\r\n\t\t\tautoUpdateInt = 1\r\n\t\t}\r\n\t\tstmt, err := tx.tx.Prepare(`INSERT INTO images (project_id, fingerprint, filename, size, public, auto_update, architecture, creation_date, expiry_date, upload_date) VALUES ((SELECT id FROM projects WHERE name = ?), ?, ?, ?, ?, ?, ?, ?, ?, ?)`)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tdefer stmt.Close()\r\n\t\tresult, err := stmt.Exec(project, fp, fname, sz, publicInt, autoUpdateInt, arch, createdAt, expiresAt, time.Now().UTC())\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tid64, err := result.LastInsertId()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tid := int(id64)\r\n\t\tif len(properties) > 0 {\r\n\t\t\tpstmt, err := tx.tx.Prepare(`INSERT INTO images_properties (image_id, type, key, value) VALUES (?, 0, ?, ?)`)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\tdefer pstmt.Close()\r\n\t\t\tfor k, v := range properties {\r\n\t\t\t\t\r\n\t\t\t\t\r\n\t\t\t\t_, err = pstmt.Exec(id, k, v)\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn err\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\t_, err = tx.tx.Exec(\"INSERT INTO images_nodes(image_id, node_id) VALUES(?, ?)\", id, c.nodeID)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\treturn err\r\n}","code-length":723,"reference":"\/\/ ImageInsert inserts a new image.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageGetPools(imageFingerprint string) ([]int64, error) {\r\n\tpoolID := int64(-1)\r\n\tquery := \"SELECT storage_pool_id FROM storage_volumes WHERE node_id=? AND name=? AND type=?\"\r\n\tinargs := []interface{}{c.nodeID, imageFingerprint, StoragePoolVolumeTypeImage}\r\n\toutargs := []interface{}{poolID}\r\n\tresult, err := queryScan(c.db, query, inargs, outargs)\r\n\tif err != nil {\r\n\t\treturn []int64{}, err\r\n\t}\r\n\tpoolIDs := []int64{}\r\n\tfor _, r := range result {\r\n\t\tpoolIDs = append(poolIDs, r[0].(int64))\r\n\t}\r\n\treturn poolIDs, nil\r\n}","code-length":207,"reference":"\/\/ ImageGetPools get the names of all storage pools on which a given image exists.","result":"Get the image pools from the storage.","score":[0.0678,0.1408]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageGetPoolNamesFromIDs(poolIDs []int64) ([]string, error) {\r\n\tvar poolName string\r\n\tquery := \"SELECT name FROM storage_pools WHERE id=?\"\r\n\tpoolNames := []string{}\r\n\tfor _, poolID := range poolIDs {\r\n\t\tinargs := []interface{}{poolID}\r\n\t\toutargs := []interface{}{poolName}\r\n\t\tresult, err := queryScan(c.db, query, inargs, outargs)\r\n\t\tif err != nil {\r\n\t\t\treturn []string{}, err\r\n\t\t}\r\n\t\tfor _, r := range result {\r\n\t\t\tpoolNames = append(poolNames, r[0].(string))\r\n\t\t}\r\n\t}\r\n\treturn poolNames, nil\r\n}","code-length":204,"reference":"\/\/ ImageGetPoolNamesFromIDs get the names of all storage pools on which a given image exists.","result":"Get pool names from image.","score":[0.0325,0.1071]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageUploadedAt(id int, uploadedAt time.Time) error {\r\n\terr := exec(c.db, \"UPDATE images SET upload_date=? WHERE id=?\", uploadedAt, id)\r\n\treturn err\r\n}","code-length":66,"reference":"\/\/ ImageUploadedAt updates the upload_date column and an image row.","result":"Update images uploaded.","score":[0,0.1075]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImagesGetOnCurrentNode() (map[string][]string, error) {\r\n\treturn c.ImagesGetByNodeID(c.nodeID)\r\n}","code-length":51,"reference":"\/\/ ImagesGetOnCurrentNode returns all images that the current LXD node instance has.","result":"Generate the generated code.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImagesGetByNodeID(id int64) (map[string][]string, error) {\r\n\timages := make(map[string][]string)\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tstmt := `\r\n    SELECT images.fingerprint, projects.name FROM images\r\n      LEFT JOIN images_nodes ON images.id = images_nodes.image_id\r\n\t\t\tLEFT JOIN nodes ON images_nodes.node_id = nodes.id\r\n\t\t\tLEFT JOIN projects ON images.project_id = projects.id\r\n    WHERE nodes.id = ?\r\n\t\t`\r\n\t\trows, err := tx.tx.Query(stmt, id)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tvar fingerprint string\r\n\t\tvar projectName string\r\n\t\tfor rows.Next() {\r\n\t\t\terr := rows.Scan(&fingerprint, &projectName)\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn err\r\n\t\t\t}\r\n\t\t\timages[fingerprint] = append(images[fingerprint], projectName)\r\n\t\t}\r\n\t\treturn rows.Err()\r\n\t})\r\n\treturn images, err\r\n}","code-length":301,"reference":"\/\/ ImagesGetByNodeID returns all images that the LXD node instance has with the given node id.","result":"Fetch images by node id.","score":[0.0417,0.1715]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageGetNodesWithImage(fingerprint string) ([]string, error) {\r\n\tq := `\r\nSELECT DISTINCT nodes.address FROM nodes\r\n  LEFT JOIN images_nodes ON images_nodes.node_id = nodes.id\r\n  LEFT JOIN images ON images_nodes.image_id = images.id\r\nWHERE images.fingerprint = ?\r\n\t`\r\n\treturn c.getNodesByImageFingerprint(q, fingerprint)\r\n}","code-length":115,"reference":"\/\/ ImageGetNodesWithImage returns the addresses of online nodes which already have the image.","result":"Fetch nodes with image .","score":[0.0485,0.041]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) ImageGetNodesWithoutImage(fingerprint string) ([]string, error) {\r\n\tq := `\r\nSELECT DISTINCT nodes.address FROM nodes WHERE nodes.address NOT IN (\r\n  SELECT DISTINCT nodes.address FROM nodes\r\n    LEFT JOIN images_nodes ON images_nodes.node_id = nodes.id\r\n    LEFT JOIN images ON images_nodes.image_id = images.id\r\n  WHERE images.fingerprint = ?)\r\n`\r\n\treturn c.getNodesByImageFingerprint(q, fingerprint)\r\n}","code-length":133,"reference":"\/\/ ImageGetNodesWithoutImage returns the addresses of online nodes which don't have the image.","result":"Fetch nodes without image.","score":[0.04,0.0826]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Group) Add(f Func, schedule Schedule) *Task {\r\n\ti := len(g.tasks)\r\n\tg.tasks = append(g.tasks, Task{\r\n\t\tf:        f,\r\n\t\tschedule: schedule,\r\n\t\treset:    make(chan struct{}, 16),\r\n\t})\r\n\treturn &g.tasks[i]\r\n}","code-length":102,"reference":"\/\/ Add a new task to the group, returning its index.","result":"Create a new task.","score":[0.0785,0.182]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (g *Group) Start() {\r\n\tctx := context.Background()\r\n\tctx, g.cancel = context.WithCancel(ctx)\r\n\tg.wg.Add(len(g.tasks))\r\n\tg.mu.Lock()\r\n\tif g.running == nil {\r\n\t\tg.running = make(map[int]bool)\r\n\t}\r\n\tg.mu.Unlock()\r\n\tfor i := range g.tasks {\r\n\t\tg.mu.Lock()\r\n\t\tif g.running[i] {\r\n\t\t\tg.mu.Unlock()\r\n\t\t\tcontinue\r\n\t\t}\r\n\t\tg.running[i] = true\r\n\t\ttask := g.tasks[i]\r\n\t\tg.mu.Unlock()\r\n\t\tgo func(i int) {\r\n\t\t\ttask.loop(ctx)\r\n\t\t\tg.wg.Done()\r\n\t\t\tg.mu.Lock()\r\n\t\t\tg.running[i] = false\r\n\t\t\tg.mu.Unlock()\r\n\t\t}(i)\r\n\t}\r\n}","code-length":271,"reference":"\/\/ Start all the tasks in the group.","result":"Start the group.","score":[0.1207,0.3407]}
{"code":"\/*is used to<extra_id_0>\r\nfunc zfsIsEnabled() bool {\r\n\tout, err := exec.LookPath(\"zfs\")\r\n\tif err != nil || len(out) == 0 {\r\n\t\treturn false\r\n\t}\r\n\treturn true\r\n}","code-length":65,"reference":"\/\/ zfsIsEnabled returns whether zfs backend is supported.","result":"Detect if zfs is enabled.","score":[0.1568,0.1299]}
{"code":"\/*is used to<extra_id_0>\r\nfunc zfsToolVersionGet() (string, error) {\r\n\t\r\n\t\r\n\tout, err := shared.RunCommand(\"dpkg-query\", \"--showformat=${Version}\", \"--show\", \"zfsutils-linux\")\r\n\tif err != nil {\r\n\t\treturn \"\", err\r\n\t}\r\n\treturn strings.TrimSpace(string(out)), nil\r\n}","code-length":100,"reference":"\/\/ zfsToolVersionGet returns the ZFS tools version","result":"Get the version of zfsutils.","score":[0.1915,0.1471]}
{"code":"\/*is used to<extra_id_0>\r\nfunc zfsModuleVersionGet() (string, error) {\r\n\tvar zfsVersion string\r\n\tif shared.PathExists(\"\/sys\/module\/zfs\/version\") {\r\n\t\tout, err := ioutil.ReadFile(\"\/sys\/module\/zfs\/version\")\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"Could not determine ZFS module version\")\r\n\t\t}\r\n\t\tzfsVersion = string(out)\r\n\t} else {\r\n\t\tout, err := shared.RunCommand(\"modinfo\", \"-F\", \"version\", \"zfs\")\r\n\t\tif err != nil {\r\n\t\t\treturn \"\", fmt.Errorf(\"Could not determine ZFS module version\")\r\n\t\t}\r\n\t\tzfsVersion = out\r\n\t}\r\n\treturn strings.TrimSpace(zfsVersion), nil\r\n}","code-length":211,"reference":"\/\/ zfsModuleVersionGet returns the ZFS module version","result":"Get the version of the zfs module.","score":[0.1921,0.3651]}
{"code":"\/*is used to<extra_id_0>\r\nfunc zfsPoolVolumeCreate(dataset string, properties ...string) (string, error) {\r\n\tcmd := []string{\"zfs\", \"create\"}\r\n\tfor _, prop := range properties {\r\n\t\tcmd = append(cmd, []string{\"-o\", prop}...)\r\n\t}\r\n\tcmd = append(cmd, []string{\"-p\", dataset}...)\r\n\treturn shared.RunCommand(cmd[0], cmd[1:]...)\r\n}","code-length":117,"reference":"\/\/ zfsPoolVolumeCreate creates a ZFS dataset with a set of given properties.","result":"Create a ZFS volume.","score":[0.0611,0.1339]}
{"code":"\/*is used to<extra_id_0>\r\nfunc zfsPoolVolumeExists(dataset string) (bool, error) {\r\n\toutput, err := shared.RunCommand(\r\n\t\t\"zfs\", \"list\", \"-Ho\", \"name\")\r\n\tif err != nil {\r\n\t\treturn false, err\r\n\t}\r\n\tfor _, name := range strings.Split(output, \"\\n\") {\r\n\t\tif name == dataset {\r\n\t\t\treturn true, nil\r\n\t\t}\r\n\t}\r\n\treturn false, nil\r\n}","code-length":130,"reference":"\/\/ zfsPoolVolumeExists verifies if a specific ZFS pool or volume exists.","result":"Check if a zfs volume exists.","score":[0.1562,0.4248]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NetworkIDsNotPending() (map[string]int64, error) {\r\n\tnetworks := []struct {\r\n\t\tid   int64\r\n\t\tname string\r\n\t}{}\r\n\tdest := func(i int) []interface{} {\r\n\t\tnetworks = append(networks, struct {\r\n\t\t\tid   int64\r\n\t\t\tname string\r\n\t\t}{})\r\n\t\treturn []interface{}{&networks[i].id, &networks[i].name}\r\n\t}\r\n\tstmt, err := c.tx.Prepare(\"SELECT id, name FROM networks WHERE NOT state=?\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer stmt.Close()\r\n\terr = query.SelectObjects(stmt, dest, networkPending)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tids := map[string]int64{}\r\n\tfor _, network := range networks {\r\n\t\tids[network.name] = network.id\r\n\t}\r\n\treturn ids, nil\r\n}","code-length":273,"reference":"\/\/ NetworkIDsNotPending returns a map associating each network name to its ID.\n\/\/\n\/\/ Pending networks are skipped.","result":"Generate code for the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NetworkConfigAdd(networkID, nodeID int64, config map[string]string) error {\r\n\treturn networkConfigAdd(c.tx, networkID, nodeID, config)\r\n}","code-length":58,"reference":"\/\/ NetworkConfigAdd adds a new entry in the networks_config table","result":"Generate the generated code.","score":[0.0713,0.0532]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NetworkNodeJoin(networkID, nodeID int64) error {\r\n\tcolumns := []string{\"network_id\", \"node_id\"}\r\n\tvalues := []interface{}{networkID, nodeID}\r\n\t_, err := query.UpsertObject(c.tx, \"networks_nodes\", columns, values)\r\n\treturn err\r\n}","code-length":94,"reference":"\/\/ NetworkNodeJoin adds a new entry in the networks_nodes table.\n\/\/\n\/\/ It should only be used when a new node joins the cluster, when it's safe to\n\/\/ assume that the relevant network has already been created on the joining node,\n\/\/ and we just need to track it.","result":"Join a node in a cluster.","score":[0.0002,0.0548]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NetworkCreatePending(node, name string, conf map[string]string) error {\r\n\t\r\n\t\r\n\tnetwork := struct {\r\n\t\tid    int64\r\n\t\tstate int\r\n\t}{}\r\n\tvar errConsistency error\r\n\tdest := func(i int) []interface{} {\r\n\t\t\r\n\t\tif i != 0 {\r\n\t\t\terrConsistency = fmt.Errorf(\"more than one network exists with the given name\")\r\n\t\t}\r\n\t\treturn []interface{}{&network.id, &network.state}\r\n\t}\r\n\tstmt, err := c.tx.Prepare(\"SELECT id, state FROM networks WHERE name=?\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tdefer stmt.Close()\r\n\terr = query.SelectObjects(stmt, dest, name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif errConsistency != nil {\r\n\t\treturn errConsistency\r\n\t}\r\n\tvar networkID = network.id\r\n\tif networkID == 0 {\r\n\t\t\r\n\t\t\r\n\t\tcolumns := []string{\"name\"}\r\n\t\tvalues := []interface{}{name}\r\n\t\tnetworkID, err = query.UpsertObject(c.tx, \"networks\", columns, values)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t} else {\r\n\t\t\r\n\t\tif network.state != networkPending {\r\n\t\t\treturn fmt.Errorf(\"network is not in pending state\")\r\n\t\t}\r\n\t}\r\n\t\r\n\tnodeInfo, err := c.NodeByName(node)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tcount, err := query.Count(\r\n\t\tc.tx, \"networks_nodes\", \"network_id=? AND node_id=?\", networkID, nodeInfo.ID)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tif count != 0 {\r\n\t\treturn ErrAlreadyDefined\r\n\t}\r\n\t\r\n\tcolumns := []string{\"network_id\", \"node_id\"}\r\n\tvalues := []interface{}{networkID, nodeInfo.ID}\r\n\t_, err = query.UpsertObject(c.tx, \"networks_nodes\", columns, values)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = c.NetworkConfigAdd(networkID, nodeInfo.ID, conf)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":636,"reference":"\/\/ NetworkCreatePending creates a new pending network on the node with\n\/\/ the given name.","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NetworkCreated(name string) error {\r\n\treturn c.networkState(name, networkCreated)\r\n}","code-length":41,"reference":"\/\/ NetworkCreated sets the state of the given network to \"Created\".","result":"Generate the code.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *ClusterTx) NetworkErrored(name string) error {\r\n\treturn c.networkState(name, networkErrored)\r\n}","code-length":43,"reference":"\/\/ NetworkErrored sets the state of the given network to \"Errored\".","result":"Generate the code.","score":[0.0284,0.049]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) NetworkGet(name string) (int64, *api.Network, error) {\r\n\tdescription := sql.NullString{}\r\n\tid := int64(-1)\r\n\tstate := 0\r\n\tq := \"SELECT id, description, state FROM networks WHERE name=?\"\r\n\targ1 := []interface{}{name}\r\n\targ2 := []interface{}{&id, &description, &state}\r\n\terr := dbQueryRowScan(c.db, q, arg1, arg2)\r\n\tif err != nil {\r\n\t\tif err == sql.ErrNoRows {\r\n\t\t\treturn -1, nil, ErrNoSuchObject\r\n\t\t}\r\n\t\treturn -1, nil, err\r\n\t}\r\n\tconfig, err := c.NetworkConfigGet(id)\r\n\tif err != nil {\r\n\t\treturn -1, nil, err\r\n\t}\r\n\tnetwork := api.Network{\r\n\t\tName:    name,\r\n\t\tManaged: true,\r\n\t\tType:    \"bridge\",\r\n\t}\r\n\tnetwork.Description = description.String\r\n\tnetwork.Config = config\r\n\tswitch state {\r\n\tcase networkPending:\r\n\t\tnetwork.Status = \"Pending\"\r\n\tcase networkCreated:\r\n\t\tnetwork.Status = \"Created\"\r\n\tdefault:\r\n\t\tnetwork.Status = \"Unknown\"\r\n\t}\r\n\tnodes, err := c.networkNodes(id)\r\n\tif err != nil {\r\n\t\treturn -1, nil, err\r\n\t}\r\n\tnetwork.Locations = nodes\r\n\treturn id, &network, nil\r\n}","code-length":399,"reference":"\/\/ NetworkGet returns the network with the given name.","result":"Get the network configuration.","score":[0.1294,0.1176]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) networkNodes(networkID int64) ([]string, error) {\r\n\tstmt := `\r\nSELECT nodes.name FROM nodes\r\n  JOIN networks_nodes ON networks_nodes.node_id = nodes.id\r\n  WHERE networks_nodes.network_id = ?\r\n`\r\n\tvar nodes []string\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tvar err error\r\n\t\tnodes, err = query.SelectStrings(tx.tx, stmt, networkID)\r\n\t\treturn err\r\n\t})\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn nodes, nil\r\n}","code-length":173,"reference":"\/\/ Return the names of the nodes the given network is defined on.","result":"Fetch the nodes from the database.","score":[0.0941,0.2078]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) NetworkGetInterface(devName string) (int64, *api.Network, error) {\r\n\tid := int64(-1)\r\n\tname := \"\"\r\n\tvalue := \"\"\r\n\tq := \"SELECT networks.id, networks.name, networks_config.value FROM networks LEFT JOIN networks_config ON networks.id=networks_config.network_id WHERE networks_config.key=\\\"bridge.external_interfaces\\\" AND networks_config.node_id=?\"\r\n\targ1 := []interface{}{c.nodeID}\r\n\targ2 := []interface{}{id, name, value}\r\n\tresult, err := queryScan(c.db, q, arg1, arg2)\r\n\tif err != nil {\r\n\t\treturn -1, nil, err\r\n\t}\r\n\tfor _, r := range result {\r\n\t\tfor _, entry := range strings.Split(r[2].(string), \",\") {\r\n\t\t\tentry = strings.TrimSpace(entry)\r\n\t\t\tif entry == devName {\r\n\t\t\t\tid = r[0].(int64)\r\n\t\t\t\tname = r[1].(string)\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n\tif id == -1 {\r\n\t\treturn -1, nil, fmt.Errorf(\"No network found for interface: %s\", devName)\r\n\t}\r\n\tconfig, err := c.NetworkConfigGet(id)\r\n\tif err != nil {\r\n\t\treturn -1, nil, err\r\n\t}\r\n\tnetwork := api.Network{\r\n\t\tName:    name,\r\n\t\tManaged: true,\r\n\t\tType:    \"bridge\",\r\n\t}\r\n\tnetwork.Config = config\r\n\treturn id, &network, nil\r\n}","code-length":431,"reference":"\/\/ NetworkGetInterface returns the network associated with the interface with\n\/\/ the given name.","result":"Get the network config from the cluster.","score":[0.093,0.1128]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) NetworkConfigGet(id int64) (map[string]string, error) {\r\n\tvar key, value string\r\n\tquery := `\r\n        SELECT\r\n            key, value\r\n        FROM networks_config\r\n\t\tWHERE network_id=?\r\n                AND (node_id=? OR node_id IS NULL)`\r\n\tinargs := []interface{}{id, c.nodeID}\r\n\toutfmt := []interface{}{key, value}\r\n\tresults, err := queryScan(c.db, query, inargs, outfmt)\r\n\tif err != nil {\r\n\t\treturn nil, fmt.Errorf(\"Failed to get network '%d'\", id)\r\n\t}\r\n\tif len(results) == 0 {\r\n\t\t\r\n\t\tquery := \"SELECT id FROM networks WHERE id=?\"\r\n\t\tvar r int\r\n\t\tresults, err := queryScan(c.db, query, []interface{}{id}, []interface{}{r})\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\tif len(results) == 0 {\r\n\t\t\treturn nil, ErrNoSuchObject\r\n\t\t}\r\n\t}\r\n\tconfig := map[string]string{}\r\n\tfor _, r := range results {\r\n\t\tkey = r[0].(string)\r\n\t\tvalue = r[1].(string)\r\n\t\tconfig[key] = value\r\n\t}\r\n\treturn config, nil\r\n}","code-length":364,"reference":"\/\/ NetworkConfigGet returns the config map of the network with the given ID.","result":"Get the network configuration from the database.","score":[0.1073,0.2061]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) NetworkCreate(name, description string, config map[string]string) (int64, error) {\r\n\tvar id int64\r\n\terr := c.Transaction(func(tx *ClusterTx) error {\r\n\t\tresult, err := tx.tx.Exec(\"INSERT INTO networks (name, description, state) VALUES (?, ?, ?)\", name, description, networkCreated)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\tid, err := result.LastInsertId()\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\t\r\n\t\tcolumns := []string{\"network_id\", \"node_id\"}\r\n\t\tvalues := []interface{}{id, c.nodeID}\r\n\t\t_, err = query.UpsertObject(tx.tx, \"networks_nodes\", columns, values)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\terr = networkConfigAdd(tx.tx, id, c.nodeID, config)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\tif err != nil {\r\n\t\tid = -1\r\n\t}\r\n\treturn id, err\r\n}","code-length":321,"reference":"\/\/ NetworkCreate creates a new network.","result":"Create a new network.","score":[0.3991,0.6843]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) NetworkUpdate(name, description string, config map[string]string) error {\r\n\tid, _, err := c.NetworkGet(name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = c.Transaction(func(tx *ClusterTx) error {\r\n\t\terr = NetworkUpdateDescription(tx.tx, id, description)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\terr = NetworkConfigClear(tx.tx, id, c.nodeID)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\terr = networkConfigAdd(tx.tx, id, c.nodeID, config)\r\n\t\tif err != nil {\r\n\t\t\treturn err\r\n\t\t}\r\n\t\treturn nil\r\n\t})\r\n\treturn err\r\n}","code-length":224,"reference":"\/\/ NetworkUpdate updates the network with the given name.","result":"Update the network configuration.","score":[0.1294,0.1765]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NetworkUpdateDescription(tx *sql.Tx, id int64, description string) error {\r\n\t_, err := tx.Exec(\"UPDATE networks SET description=? WHERE id=?\", description, id)\r\n\treturn err\r\n}","code-length":61,"reference":"\/\/ NetworkUpdateDescription updates the description of the network with the\n\/\/ given ID.","result":"Update the description of a network.","score":[0.1238,0.2566]}
{"code":"\/*is used to<extra_id_0>\r\nfunc NetworkConfigClear(tx *sql.Tx, networkID, nodeID int64) error {\r\n\t_, err := tx.Exec(\r\n\t\t\"DELETE FROM networks_config WHERE network_id=? AND (node_id=? OR node_id IS NULL)\",\r\n\t\tnetworkID, nodeID)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":104,"reference":"\/\/ NetworkConfigClear resets the config of the network with the given ID\n\/\/ associated with the node with the given ID.","result":"Clear the network config.","score":[0.0064,0.0518]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) NetworkDelete(name string) error {\r\n\tid, _, err := c.NetworkGet(name)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = exec(c.db, \"DELETE FROM networks WHERE id=?\", id)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":104,"reference":"\/\/ NetworkDelete deletes the network with the given name.","result":"Delete a network.","score":[0,0.0595]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (c *Cluster) NetworkRename(oldName string, newName string) error {\r\n\tid, _, err := c.NetworkGet(oldName)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\terr = c.Transaction(func(tx *ClusterTx) error {\r\n\t\t_, err = tx.tx.Exec(\"UPDATE networks SET name=? WHERE id=?\", newName, id)\r\n\t\treturn err\r\n\t})\r\n\treturn err\r\n}","code-length":125,"reference":"\/\/ NetworkRename renames a network.","result":"Replace the code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainers() ([]api.Container, error) {\r\n\tcontainers := []api.Container{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", \"\/containers?recursion=1\", nil, \"\", &containers)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn containers, nil\r\n}","code-length":99,"reference":"\/\/ GetContainers returns a list of containers","result":"Get the list of containers.","score":[0.2278,0.2757]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainersFull() ([]api.ContainerFull, error) {\r\n\tcontainers := []api.ContainerFull{}\r\n\tif !r.HasExtension(\"container_full\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"container_full\\\" API extension\")\r\n\t}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", \"\/containers?recursion=2\", nil, \"\", &containers)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn containers, nil\r\n}","code-length":146,"reference":"\/\/ GetContainersFull returns a list of containers including snapshots, backups and state","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainer(name string) (*api.Container, string, error) {\r\n\tcontainer := api.Container{}\r\n\t\r\n\tetag, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/containers\/%s\", url.QueryEscape(name)), nil, \"\", &container)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\treturn &container, etag, nil\r\n}","code-length":118,"reference":"\/\/ GetContainer returns the container entry for the provided name","result":"Get the container.","score":[0.0396,0.0538]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) CreateContainerFromBackup(args ContainerBackupArgs) (Operation, error) {\r\n\tif !r.HasExtension(\"container_backup\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"container_backup\\\" API extension\")\r\n\t}\r\n\tif args.PoolName == \"\" {\r\n\t\t\r\n\t\top, _, err := r.queryOperation(\"POST\", \"\/containers\", args.BackupFile, \"\")\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treturn op, nil\r\n\t}\r\n\tif !r.HasExtension(\"container_backup_override_pool\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"container_backup_override_pool\\\" API extension\")\r\n\t}\r\n\t\r\n\treqURL, err := r.setQueryAttributes(fmt.Sprintf(\"%s\/1.0\/containers\", r.httpHost))\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treq, err := http.NewRequest(\"POST\", reqURL, args.BackupFile)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treq.Header.Set(\"Content-Type\", \"application\/octet-stream\")\r\n\treq.Header.Set(\"X-LXD-pool\", args.PoolName)\r\n\t\r\n\tif r.httpUserAgent != \"\" {\r\n\t\treq.Header.Set(\"User-Agent\", r.httpUserAgent)\r\n\t}\r\n\t\r\n\tresp, err := r.do(req)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\tdefer resp.Body.Close()\r\n\t\r\n\tresponse, _, err := lxdParseResponse(resp)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\trespOperation, err := response.MetadataAsOperation()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\top := operation{\r\n\t\tOperation: *respOperation,\r\n\t\tr:         r,\r\n\t\tchActive:  make(chan bool),\r\n\t}\r\n\treturn &op, nil\r\n}","code-length":558,"reference":"\/\/ CreateContainerFromBackup is a convenience function to make it easier to\n\/\/ create a container from a backup","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) CreateContainer(container api.ContainersPost) (Operation, error) {\r\n\tif container.Source.ContainerOnly {\r\n\t\tif !r.HasExtension(\"container_only_migration\") {\r\n\t\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"container_only_migration\\\" API extension\")\r\n\t\t}\r\n\t}\r\n\t\r\n\top, _, err := r.queryOperation(\"POST\", \"\/containers\", container, \"\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":153,"reference":"\/\/ CreateContainer requests that LXD creates a new container","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) CreateContainerFromImage(source ImageServer, image api.Image, req api.ContainersPost) (RemoteOperation, error) {\r\n\t\r\n\treq.Source.Type = \"image\"\r\n\t\r\n\tif r == source {\r\n\t\t\r\n\t\treq.Source.Fingerprint = image.Fingerprint\r\n\t\treq.Source.Alias = \"\"\r\n\t\top, err := r.CreateContainer(req)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\trop := remoteOperation{\r\n\t\t\ttargetOp: op,\r\n\t\t\tchDone:   make(chan bool),\r\n\t\t}\r\n\t\t\r\n\t\tgo func() {\r\n\t\t\trop.err = rop.targetOp.Wait()\r\n\t\t\tclose(rop.chDone)\r\n\t\t}()\r\n\t\treturn &rop, nil\r\n\t}\r\n\t\r\n\treq.Source.Mode = \"pull\"\r\n\t\r\n\tif req.Source.Alias != \"\" && image.Public {\r\n\t\treq.Source.Fingerprint = \"\"\r\n\t} else {\r\n\t\treq.Source.Fingerprint = image.Fingerprint\r\n\t\treq.Source.Alias = \"\"\r\n\t}\r\n\t\r\n\tinfo, err := source.GetConnectionInfo()\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treq.Source.Protocol = info.Protocol\r\n\treq.Source.Certificate = info.Certificate\r\n\t\r\n\tif !image.Public {\r\n\t\tsecret, err := source.GetImageSecret(image.Fingerprint)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t\treq.Source.Secret = secret\r\n\t}\r\n\treturn r.tryCreateContainer(req, info.Addresses)\r\n}","code-length":452,"reference":"\/\/ CreateContainerFromImage is a convenience function to make it easier to create a container from an existing image","result":"Create a container from an image.","score":[0.0818,0.2964]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) UpdateContainer(name string, container api.ContainerPut, ETag string) (Operation, error) {\r\n\t\r\n\top, _, err := r.queryOperation(\"PUT\", fmt.Sprintf(\"\/containers\/%s\", url.QueryEscape(name)), container, ETag)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":109,"reference":"\/\/ UpdateContainer updates the container definition","result":"Update the container.","score":[0.1502,0.3289]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) RenameContainer(name string, container api.ContainerPost) (Operation, error) {\r\n\t\r\n\tif container.Migration {\r\n\t\treturn nil, fmt.Errorf(\"Can't ask for a migration through RenameContainer\")\r\n\t}\r\n\t\r\n\top, _, err := r.queryOperation(\"POST\", fmt.Sprintf(\"\/containers\/%s\", url.QueryEscape(name)), container, \"\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":142,"reference":"\/\/ RenameContainer requests that LXD renames the container","result":"Rename the container.","score":[0.0771,0.25]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) ExecContainer(containerName string, exec api.ContainerExecPost, args *ContainerExecArgs) (Operation, error) {\r\n\tif exec.RecordOutput {\r\n\t\tif !r.HasExtension(\"container_exec_recording\") {\r\n\t\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"container_exec_recording\\\" API extension\")\r\n\t\t}\r\n\t}\r\n\t\r\n\top, _, err := r.queryOperation(\"POST\", fmt.Sprintf(\"\/containers\/%s\/exec\", url.QueryEscape(containerName)), exec, \"\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\topAPI := op.Get()\r\n\t\r\n\tif args != nil {\r\n\t\t\r\n\t\tfds := map[string]string{}\r\n\t\tvalue, ok := opAPI.Metadata[\"fds\"]\r\n\t\tif ok {\r\n\t\t\tvalues := value.(map[string]interface{})\r\n\t\t\tfor k, v := range values {\r\n\t\t\t\tfds[k] = v.(string)\r\n\t\t\t}\r\n\t\t}\r\n\t\t\r\n\t\tif args.Control != nil && fds[\"control\"] != \"\" {\r\n\t\t\tconn, err := r.GetOperationWebsocket(opAPI.ID, fds[\"control\"])\r\n\t\t\tif err != nil {\r\n\t\t\t\treturn nil, err\r\n\t\t\t}\r\n\t\t\tgo args.Control(conn)\r\n\t\t}\r\n\t\tif exec.Interactive {\r\n\t\t\t\r\n\t\t\tif args.Stdin != nil && args.Stdout != nil {\r\n\t\t\t\t\r\n\t\t\t\tconn, err := r.GetOperationWebsocket(opAPI.ID, fds[\"0\"])\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn nil, err\r\n\t\t\t\t}\r\n\t\t\t\t\r\n\t\t\t\tgo func() {\r\n\t\t\t\t\tshared.WebsocketSendStream(conn, args.Stdin, -1)\r\n\t\t\t\t\t<-shared.WebsocketRecvStream(args.Stdout, conn)\r\n\t\t\t\t\tconn.Close()\r\n\t\t\t\t\tif args.DataDone != nil {\r\n\t\t\t\t\t\tclose(args.DataDone)\r\n\t\t\t\t\t}\r\n\t\t\t\t}()\r\n\t\t\t} else {\r\n\t\t\t\tif args.DataDone != nil {\r\n\t\t\t\t\tclose(args.DataDone)\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\t\r\n\t\t\tdones := map[int]chan bool{}\r\n\t\t\tconns := []*websocket.Conn{}\r\n\t\t\t\r\n\t\t\tif fds[\"0\"] != \"\" {\r\n\t\t\t\tconn, err := r.GetOperationWebsocket(opAPI.ID, fds[\"0\"])\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn nil, err\r\n\t\t\t\t}\r\n\t\t\t\tconns = append(conns, conn)\r\n\t\t\t\tdones[0] = shared.WebsocketSendStream(conn, args.Stdin, -1)\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif fds[\"1\"] != \"\" {\r\n\t\t\t\tconn, err := r.GetOperationWebsocket(opAPI.ID, fds[\"1\"])\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn nil, err\r\n\t\t\t\t}\r\n\t\t\t\tconns = append(conns, conn)\r\n\t\t\t\tdones[1] = shared.WebsocketRecvStream(args.Stdout, conn)\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tif fds[\"2\"] != \"\" {\r\n\t\t\t\tconn, err := r.GetOperationWebsocket(opAPI.ID, fds[\"2\"])\r\n\t\t\t\tif err != nil {\r\n\t\t\t\t\treturn nil, err\r\n\t\t\t\t}\r\n\t\t\t\tconns = append(conns, conn)\r\n\t\t\t\tdones[2] = shared.WebsocketRecvStream(args.Stderr, conn)\r\n\t\t\t}\r\n\t\t\t\r\n\t\t\tgo func() {\r\n\t\t\t\tfor i, chDone := range dones {\r\n\t\t\t\t\t\r\n\t\t\t\t\tif i == 0 {\r\n\t\t\t\t\t\tcontinue\r\n\t\t\t\t\t}\r\n\t\t\t\t\t<-chDone\r\n\t\t\t\t}\r\n\t\t\t\tif fds[\"0\"] != \"\" {\r\n\t\t\t\t\tif args.Stdin != nil {\r\n\t\t\t\t\t\targs.Stdin.Close()\r\n\t\t\t\t\t}\r\n\t\t\t\t\t\r\n\t\t\t\t\t\r\n\t\t\t\t\tgo func() {\r\n\t\t\t\t\t\t<-dones[0]\r\n\t\t\t\t\t}()\r\n\t\t\t\t}\r\n\t\t\t\tfor _, conn := range conns {\r\n\t\t\t\t\tconn.Close()\r\n\t\t\t\t}\r\n\t\t\t\tif args.DataDone != nil {\r\n\t\t\t\t\tclose(args.DataDone)\r\n\t\t\t\t}\r\n\t\t\t}()\r\n\t\t}\r\n\t}\r\n\treturn op, nil\r\n}","code-length":1149,"reference":"\/\/ ExecContainer requests that LXD spawns a command inside the container","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainerFile(containerName string, path string) (io.ReadCloser, *ContainerFileResponse, error) {\r\n\t\r\n\trequestURL, err := shared.URLEncode(\r\n\t\tfmt.Sprintf(\"%s\/1.0\/containers\/%s\/files\", r.httpHost, url.QueryEscape(containerName)),\r\n\t\tmap[string]string{\"path\": path})\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\trequestURL, err = r.setQueryAttributes(requestURL)\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\treq, err := http.NewRequest(\"GET\", requestURL, nil)\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\t\r\n\tif r.httpUserAgent != \"\" {\r\n\t\treq.Header.Set(\"User-Agent\", r.httpUserAgent)\r\n\t}\r\n\t\r\n\tresp, err := r.do(req)\r\n\tif err != nil {\r\n\t\treturn nil, nil, err\r\n\t}\r\n\t\r\n\tif resp.StatusCode != http.StatusOK {\r\n\t\t_, _, err := lxdParseResponse(resp)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, nil, err\r\n\t\t}\r\n\t}\r\n\t\r\n\tuid, gid, mode, fileType, _ := shared.ParseLXDFileHeaders(resp.Header)\r\n\tfileResp := ContainerFileResponse{\r\n\t\tUID:  uid,\r\n\t\tGID:  gid,\r\n\t\tMode: mode,\r\n\t\tType: fileType,\r\n\t}\r\n\tif fileResp.Type == \"directory\" {\r\n\t\t\r\n\t\tresponse := api.Response{}\r\n\t\tdecoder := json.NewDecoder(resp.Body)\r\n\t\terr = decoder.Decode(&response)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, nil, err\r\n\t\t}\r\n\t\t\r\n\t\tentries := []string{}\r\n\t\terr = response.MetadataAsStruct(&entries)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, nil, err\r\n\t\t}\r\n\t\tfileResp.Entries = entries\r\n\t\treturn nil, &fileResp, err\r\n\t}\r\n\treturn resp.Body, &fileResp, err\r\n}","code-length":592,"reference":"\/\/ GetContainerFile retrieves the provided path from the container","result":"Code too long,keep in 512.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) CreateContainerFile(containerName string, path string, args ContainerFileArgs) error {\r\n\tif args.Type == \"directory\" {\r\n\t\tif !r.HasExtension(\"directory_manipulation\") {\r\n\t\t\treturn fmt.Errorf(\"The server is missing the required \\\"directory_manipulation\\\" API extension\")\r\n\t\t}\r\n\t}\r\n\tif args.Type == \"symlink\" {\r\n\t\tif !r.HasExtension(\"file_symlinks\") {\r\n\t\t\treturn fmt.Errorf(\"The server is missing the required \\\"file_symlinks\\\" API extension\")\r\n\t\t}\r\n\t}\r\n\tif args.WriteMode == \"append\" {\r\n\t\tif !r.HasExtension(\"file_append\") {\r\n\t\t\treturn fmt.Errorf(\"The server is missing the required \\\"file_append\\\" API extension\")\r\n\t\t}\r\n\t}\r\n\t\r\n\trequestURL := fmt.Sprintf(\"%s\/1.0\/containers\/%s\/files?path=%s\", r.httpHost, url.QueryEscape(containerName), url.QueryEscape(path))\r\n\trequestURL, err := r.setQueryAttributes(requestURL)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treq, err := http.NewRequest(\"POST\", requestURL, args.Content)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\tif r.httpUserAgent != \"\" {\r\n\t\treq.Header.Set(\"User-Agent\", r.httpUserAgent)\r\n\t}\r\n\t\r\n\tif args.UID > -1 {\r\n\t\treq.Header.Set(\"X-LXD-uid\", fmt.Sprintf(\"%d\", args.UID))\r\n\t}\r\n\tif args.GID > -1 {\r\n\t\treq.Header.Set(\"X-LXD-gid\", fmt.Sprintf(\"%d\", args.GID))\r\n\t}\r\n\tif args.Mode > -1 {\r\n\t\treq.Header.Set(\"X-LXD-mode\", fmt.Sprintf(\"%04o\", args.Mode))\r\n\t}\r\n\tif args.Type != \"\" {\r\n\t\treq.Header.Set(\"X-LXD-type\", args.Type)\r\n\t}\r\n\tif args.WriteMode != \"\" {\r\n\t\treq.Header.Set(\"X-LXD-write\", args.WriteMode)\r\n\t}\r\n\t\r\n\tresp, err := r.do(req)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\t\r\n\t_, _, err = lxdParseResponse(resp)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":667,"reference":"\/\/ CreateContainerFile tells LXD to create a file in the container","result":"Code too long,keep in 512.","score":[0.0724,0.0481]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) DeleteContainerFile(containerName string, path string) error {\r\n\tif !r.HasExtension(\"file_delete\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"file_delete\\\" API extension\")\r\n\t}\r\n\t\r\n\t_, _, err := r.query(\"DELETE\", fmt.Sprintf(\"\/containers\/%s\/files?path=%s\", url.QueryEscape(containerName), url.QueryEscape(path)), nil, \"\")\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":152,"reference":"\/\/ DeleteContainerFile deletes a file in the container","result":"Delete a container file.","score":[0.1398,0.3363]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainerSnapshotNames(containerName string) ([]string, error) {\r\n\turls := []string{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/containers\/%s\/snapshots\", url.QueryEscape(containerName)), nil, \"\", &urls)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tnames := []string{}\r\n\tfor _, uri := range urls {\r\n\t\tfields := strings.Split(uri, fmt.Sprintf(\"\/containers\/%s\/snapshots\/\", url.QueryEscape(containerName)))\r\n\t\tnames = append(names, fields[len(fields)-1])\r\n\t}\r\n\treturn names, nil\r\n}","code-length":192,"reference":"\/\/ GetContainerSnapshotNames returns a list of snapshot names for the container","result":"Get the list of snapshots names for a container.","score":[0.201,0.6226]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainerSnapshots(containerName string) ([]api.ContainerSnapshot, error) {\r\n\tsnapshots := []api.ContainerSnapshot{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/containers\/%s\/snapshots?recursion=1\", url.QueryEscape(containerName)), nil, \"\", &snapshots)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn snapshots, nil\r\n}","code-length":124,"reference":"\/\/ GetContainerSnapshots returns a list of snapshots for the container","result":"Get the container snapshots.","score":[0.1008,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainerSnapshot(containerName string, name string) (*api.ContainerSnapshot, string, error) {\r\n\tsnapshot := api.ContainerSnapshot{}\r\n\t\r\n\tetag, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/containers\/%s\/snapshots\/%s\", url.QueryEscape(containerName), url.QueryEscape(name)), nil, \"\", &snapshot)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\treturn &snapshot, etag, nil\r\n}","code-length":137,"reference":"\/\/ GetContainerSnapshot returns a Snapshot struct for the provided container and snapshot names","result":"Get the snapshot from the container.","score":[0.0715,0.0813]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) CreateContainerSnapshot(containerName string, snapshot api.ContainerSnapshotsPost) (Operation, error) {\r\n\t\r\n\tif snapshot.ExpiresAt != nil && !r.HasExtension(\"snapshot_expiry_creation\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"snapshot_expiry_creation\\\" API extension\")\r\n\t}\r\n\t\r\n\top, _, err := r.queryOperation(\"POST\", fmt.Sprintf(\"\/containers\/%s\/snapshots\", url.QueryEscape(containerName)), snapshot, \"\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":170,"reference":"\/\/ CreateContainerSnapshot requests that LXD creates a new snapshot for the container","result":"Generate the generated code.","score":[0.0432,0.0446]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) MigrateContainerSnapshot(containerName string, name string, container api.ContainerSnapshotPost) (Operation, error) {\r\n\t\r\n\tif !container.Migration {\r\n\t\treturn nil, fmt.Errorf(\"Can't ask for a rename through MigrateContainerSnapshot\")\r\n\t}\r\n\t\r\n\top, _, err := r.queryOperation(\"POST\", fmt.Sprintf(\"\/containers\/%s\/snapshots\/%s\", url.QueryEscape(containerName), url.QueryEscape(name)), container, \"\")\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":162,"reference":"\/\/ MigrateContainerSnapshot requests that LXD prepares for a snapshot migration","result":"Create a new LXD instance.","score":[0.1051,0.1053]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) UpdateContainerSnapshot(containerName string, name string, container api.ContainerSnapshotPut, ETag string) (Operation, error) {\r\n\tif !r.HasExtension(\"snapshot_expiry\") {\r\n\t\treturn nil, fmt.Errorf(\"The server is missing the required \\\"snapshot_expiry\\\" API extension\")\r\n\t}\r\n\t\r\n\top, _, err := r.queryOperation(\"PUT\", fmt.Sprintf(\"\/containers\/%s\/snapshots\/%s\",\r\n\t\turl.QueryEscape(containerName), url.QueryEscape(name)), container, ETag)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":175,"reference":"\/\/ UpdateContainerSnapshot requests that LXD updates the container snapshot","result":"Update the snapshot on the server.","score":[0.1392,0.1724]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainerState(name string) (*api.ContainerState, string, error) {\r\n\tstate := api.ContainerState{}\r\n\t\r\n\tetag, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/containers\/%s\/state\", url.QueryEscape(name)), nil, \"\", &state)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\treturn &state, etag, nil\r\n}","code-length":123,"reference":"\/\/ GetContainerState returns a ContainerState entry for the provided container name","result":"Get the container state.","score":[0.066,0.0971]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) UpdateContainerState(name string, state api.ContainerStatePut, ETag string) (Operation, error) {\r\n\t\r\n\top, _, err := r.queryOperation(\"PUT\", fmt.Sprintf(\"\/containers\/%s\/state\", url.QueryEscape(name)), state, ETag)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treturn op, nil\r\n}","code-length":113,"reference":"\/\/ UpdateContainerState updates the container to match the requested state","result":"Update the container state.","score":[0.1008,0.1596]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainerLogfiles(name string) ([]string, error) {\r\n\turls := []string{}\r\n\t\r\n\t_, err := r.queryStruct(\"GET\", fmt.Sprintf(\"\/containers\/%s\/logs\", url.QueryEscape(name)), nil, \"\", &urls)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tlogfiles := []string{}\r\n\tfor _, uri := range logfiles {\r\n\t\tfields := strings.Split(uri, fmt.Sprintf(\"\/containers\/%s\/logs\/\", url.QueryEscape(name)))\r\n\t\tlogfiles = append(logfiles, fields[len(fields)-1])\r\n\t}\r\n\treturn logfiles, nil\r\n}","code-length":194,"reference":"\/\/ GetContainerLogfiles returns a list of logfiles for the container","result":"Get the container logfiles.","score":[0.1008,0.1995]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainerLogfile(name string, filename string) (io.ReadCloser, error) {\r\n\t\r\n\turl := fmt.Sprintf(\"%s\/1.0\/containers\/%s\/logs\/%s\", r.httpHost, url.QueryEscape(name), url.QueryEscape(filename))\r\n\turl, err := r.setQueryAttributes(url)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\treq, err := http.NewRequest(\"GET\", url, nil)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tif r.httpUserAgent != \"\" {\r\n\t\treq.Header.Set(\"User-Agent\", r.httpUserAgent)\r\n\t}\r\n\t\r\n\tresp, err := r.do(req)\r\n\tif err != nil {\r\n\t\treturn nil, err\r\n\t}\r\n\t\r\n\tif resp.StatusCode != http.StatusOK {\r\n\t\t_, _, err := lxdParseResponse(resp)\r\n\t\tif err != nil {\r\n\t\t\treturn nil, err\r\n\t\t}\r\n\t}\r\n\treturn resp.Body, err\r\n}","code-length":300,"reference":"\/\/ GetContainerLogfile returns the content of the requested logfile\n\/\/\n\/\/ Note that it's the caller's responsibility to close the returned ReadCloser","result":"Avoid the need for the following line.","score":[0.0225,0.0488]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) GetContainerMetadata(name string) (*api.ImageMetadata, string, error) {\r\n\tif !r.HasExtension(\"container_edit_metadata\") {\r\n\t\treturn nil, \"\", fmt.Errorf(\"The server is missing the required \\\"container_edit_metadata\\\" API extension\")\r\n\t}\r\n\tmetadata := api.ImageMetadata{}\r\n\turl := fmt.Sprintf(\"\/containers\/%s\/metadata\", url.QueryEscape(name))\r\n\tetag, err := r.queryStruct(\"GET\", url, nil, \"\", &metadata)\r\n\tif err != nil {\r\n\t\treturn nil, \"\", err\r\n\t}\r\n\treturn &metadata, etag, err\r\n}","code-length":175,"reference":"\/\/ GetContainerMetadata returns container metadata.","result":"Generate the generated code.","score":[0,0.0]}
{"code":"\/*is used to<extra_id_0>\r\nfunc (r *ProtocolLXD) SetContainerMetadata(name string, metadata api.ImageMetadata, ETag string) error {\r\n\tif !r.HasExtension(\"container_edit_metadata\") {\r\n\t\treturn fmt.Errorf(\"The server is missing the required \\\"container_edit_metadata\\\" API extension\")\r\n\t}\r\n\turl := fmt.Sprintf(\"\/containers\/%s\/metadata\", url.QueryEscape(name))\r\n\t_, _, err := r.query(\"PUT\", url, metadata, ETag)\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\treturn nil\r\n}","code-length":152,"reference":"\/\/ SetContainerMetadata sets the content of the container metadata file.","result":"Generate the generated code.","score":[0.0713,0.0532]}
